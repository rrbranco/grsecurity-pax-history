- fixed mm counter accounting for swap entries under SEGMEXEC/i386

diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/alpha/include/asm/atomic.h linux-3.2.71-pax/arch/alpha/include/asm/atomic.h
--- linux-3.2.71/arch/alpha/include/asm/atomic.h	2012-09-12 12:17:18.711311266 +0200
+++ linux-3.2.71-pax/arch/alpha/include/asm/atomic.h	2012-09-12 12:17:29.467311301 +0200
@@ -250,6 +250,16 @@ static __inline__ int atomic64_add_unles
 #define atomic_dec(v) atomic_sub(1,(v))
 #define atomic64_dec(v) atomic64_sub(1,(v))
 
+#define atomic64_read_unchecked(v)		atomic64_read(v)
+#define atomic64_set_unchecked(v, i)		atomic64_set((v), (i))
+#define atomic64_add_unchecked(a, v)		atomic64_add((a), (v))
+#define atomic64_add_return_unchecked(a, v)	atomic64_add_return((a), (v))
+#define atomic64_sub_unchecked(a, v)		atomic64_sub((a), (v))
+#define atomic64_inc_unchecked(v)		atomic64_inc(v)
+#define atomic64_inc_return_unchecked(v)	atomic64_inc_return(v)
+#define atomic64_dec_unchecked(v)		atomic64_dec(v)
+#define atomic64_cmpxchg_unchecked(v, o, n)	atomic64_cmpxchg((v), (o), (n))
+
 #define smp_mb__before_atomic_dec()	smp_mb()
 #define smp_mb__after_atomic_dec()	smp_mb()
 #define smp_mb__before_atomic_inc()	smp_mb()
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/alpha/include/asm/elf.h linux-3.2.71-pax/arch/alpha/include/asm/elf.h
--- linux-3.2.71/arch/alpha/include/asm/elf.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/alpha/include/asm/elf.h	2012-07-04 19:24:47.352062604 +0200
@@ -90,6 +90,13 @@ typedef elf_fpreg_t elf_fpregset_t[ELF_N
 
 #define ELF_ET_DYN_BASE		(TASK_UNMAPPED_BASE + 0x1000000)
 
+#ifdef CONFIG_PAX_ASLR
+#define PAX_ELF_ET_DYN_BASE	(current->personality & ADDR_LIMIT_32BIT ? 0x10000 : 0x120000000UL)
+
+#define PAX_DELTA_MMAP_LEN	(current->personality & ADDR_LIMIT_32BIT ? 14 : 28)
+#define PAX_DELTA_STACK_LEN	(current->personality & ADDR_LIMIT_32BIT ? 14 : 19)
+#endif
+
 /* $0 is set by ld.so to a pointer to a function which might be 
    registered using atexit.  This provides a mean for the dynamic
    linker to call DT_FINI functions for shared libraries that have
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/alpha/include/asm/pgalloc.h linux-3.2.71-pax/arch/alpha/include/asm/pgalloc.h
--- linux-3.2.71/arch/alpha/include/asm/pgalloc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/alpha/include/asm/pgalloc.h	2012-07-04 19:24:47.352062604 +0200
@@ -29,6 +29,12 @@ pgd_populate(struct mm_struct *mm, pgd_t
 	pgd_set(pgd, pmd);
 }
 
+static inline void
+pgd_populate_kernel(struct mm_struct *mm, pgd_t *pgd, pmd_t *pmd)
+{
+	pgd_populate(mm, pgd, pmd);
+}
+
 extern pgd_t *pgd_alloc(struct mm_struct *mm);
 
 static inline void
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/alpha/include/asm/pgtable.h linux-3.2.71-pax/arch/alpha/include/asm/pgtable.h
--- linux-3.2.71/arch/alpha/include/asm/pgtable.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/alpha/include/asm/pgtable.h	2012-07-04 19:24:47.356062733 +0200
@@ -101,6 +101,17 @@ struct vm_area_struct;
 #define PAGE_SHARED	__pgprot(_PAGE_VALID | __ACCESS_BITS)
 #define PAGE_COPY	__pgprot(_PAGE_VALID | __ACCESS_BITS | _PAGE_FOW)
 #define PAGE_READONLY	__pgprot(_PAGE_VALID | __ACCESS_BITS | _PAGE_FOW)
+
+#ifdef CONFIG_PAX_PAGEEXEC
+# define PAGE_SHARED_NOEXEC	__pgprot(_PAGE_VALID | __ACCESS_BITS | _PAGE_FOE)
+# define PAGE_COPY_NOEXEC	__pgprot(_PAGE_VALID | __ACCESS_BITS | _PAGE_FOW | _PAGE_FOE)
+# define PAGE_READONLY_NOEXEC	__pgprot(_PAGE_VALID | __ACCESS_BITS | _PAGE_FOW | _PAGE_FOE)
+#else
+# define PAGE_SHARED_NOEXEC	PAGE_SHARED
+# define PAGE_COPY_NOEXEC	PAGE_COPY
+# define PAGE_READONLY_NOEXEC	PAGE_READONLY
+#endif
+
 #define PAGE_KERNEL	__pgprot(_PAGE_VALID | _PAGE_ASM | _PAGE_KRE | _PAGE_KWE)
 
 #define _PAGE_NORMAL(x) __pgprot(_PAGE_VALID | __ACCESS_BITS | (x))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/alpha/kernel/module.c linux-3.2.71-pax/arch/alpha/kernel/module.c
--- linux-3.2.71/arch/alpha/kernel/module.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/alpha/kernel/module.c	2012-07-04 19:24:47.356062733 +0200
@@ -160,7 +160,7 @@ apply_relocate_add(Elf64_Shdr *sechdrs,
 
 	/* The small sections were sorted to the end of the segment.
 	   The following should definitely cover them.  */
-	gp = (u64)me->module_core + me->core_size - 0x8000;
+	gp = (u64)me->module_core_rw + me->core_size_rw - 0x8000;
 	got = sechdrs[me->arch.gotsecindex].sh_addr;
 
 	for (i = 0; i < n; i++) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/alpha/kernel/osf_sys.c linux-3.2.71-pax/arch/alpha/kernel/osf_sys.c
--- linux-3.2.71/arch/alpha/kernel/osf_sys.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/alpha/kernel/osf_sys.c	2013-07-05 02:14:08.217197536 +0200
@@ -1147,7 +1147,7 @@ arch_get_unmapped_area_1(unsigned long a
 		/* At this point:  (!vma || addr < vma->vm_end). */
 		if (limit - len < addr)
 			return -ENOMEM;
-		if (!vma || addr + len <= vma->vm_start)
+		if (check_heap_stack_gap(vma, &addr, len))
 			return addr;
 		addr = vma->vm_end;
 		vma = vma->vm_next;
@@ -1183,6 +1183,10 @@ arch_get_unmapped_area(struct file *filp
 	   merely specific addresses, but regions of memory -- perhaps
 	   this feature should be incorporated into all ports?  */
 
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(current->mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	if (addr) {
 		addr = arch_get_unmapped_area_1 (PAGE_ALIGN(addr), len, limit);
 		if (addr != (unsigned long) -ENOMEM)
@@ -1190,8 +1194,8 @@ arch_get_unmapped_area(struct file *filp
 	}
 
 	/* Next, try allocating at TASK_UNMAPPED_BASE.  */
-	addr = arch_get_unmapped_area_1 (PAGE_ALIGN(TASK_UNMAPPED_BASE),
-					 len, limit);
+	addr = arch_get_unmapped_area_1 (PAGE_ALIGN(current->mm->mmap_base), len, limit);
+
 	if (addr != (unsigned long) -ENOMEM)
 		return addr;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/alpha/mm/fault.c linux-3.2.71-pax/arch/alpha/mm/fault.c
--- linux-3.2.71/arch/alpha/mm/fault.c	2015-02-20 12:37:32.797178791 +0100
+++ linux-3.2.71-pax/arch/alpha/mm/fault.c	2015-02-20 12:37:41.805178310 +0100
@@ -54,6 +54,124 @@ __load_new_mm_context(struct mm_struct *
 	__reload_thread(pcb);
 }
 
+#ifdef CONFIG_PAX_PAGEEXEC
+/*
+ * PaX: decide what to do with offenders (regs->pc = fault address)
+ *
+ * returns 1 when task should be killed
+ *         2 when patched PLT trampoline was detected
+ *         3 when unpatched PLT trampoline was detected
+ */
+static int pax_handle_fetch_fault(struct pt_regs *regs)
+{
+
+#ifdef CONFIG_PAX_EMUPLT
+	int err;
+
+	do { /* PaX: patched PLT emulation #1 */
+		unsigned int ldah, ldq, jmp;
+
+		err = get_user(ldah, (unsigned int *)regs->pc);
+		err |= get_user(ldq, (unsigned int *)(regs->pc+4));
+		err |= get_user(jmp, (unsigned int *)(regs->pc+8));
+
+		if (err)
+			break;
+
+		if ((ldah & 0xFFFF0000U) == 0x277B0000U &&
+		    (ldq & 0xFFFF0000U) == 0xA77B0000U &&
+		    jmp == 0x6BFB0000U)
+		{
+			unsigned long r27, addr;
+			unsigned long addrh = (ldah | 0xFFFFFFFFFFFF0000UL) << 16;
+			unsigned long addrl = ldq | 0xFFFFFFFFFFFF0000UL;
+
+			addr = regs->r27 + ((addrh ^ 0x80000000UL) + 0x80000000UL) + ((addrl ^ 0x8000UL) + 0x8000UL);
+			err = get_user(r27, (unsigned long *)addr);
+			if (err)
+				break;
+
+			regs->r27 = r27;
+			regs->pc = r27;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: patched PLT emulation #2 */
+		unsigned int ldah, lda, br;
+
+		err = get_user(ldah, (unsigned int *)regs->pc);
+		err |= get_user(lda, (unsigned int *)(regs->pc+4));
+		err |= get_user(br, (unsigned int *)(regs->pc+8));
+
+		if (err)
+			break;
+
+		if ((ldah & 0xFFFF0000U) == 0x277B0000U &&
+		    (lda & 0xFFFF0000U) == 0xA77B0000U &&
+		    (br & 0xFFE00000U) == 0xC3E00000U)
+		{
+			unsigned long addr = br | 0xFFFFFFFFFFE00000UL;
+			unsigned long addrh = (ldah | 0xFFFFFFFFFFFF0000UL) << 16;
+			unsigned long addrl = lda | 0xFFFFFFFFFFFF0000UL;
+
+			regs->r27 += ((addrh ^ 0x80000000UL) + 0x80000000UL) + ((addrl ^ 0x8000UL) + 0x8000UL);
+			regs->pc += 12 + (((addr ^ 0x00100000UL) + 0x00100000UL) << 2);
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: unpatched PLT emulation */
+		unsigned int br;
+
+		err = get_user(br, (unsigned int *)regs->pc);
+
+		if (!err && (br & 0xFFE00000U) == 0xC3800000U) {
+			unsigned int br2, ldq, nop, jmp;
+			unsigned long addr = br | 0xFFFFFFFFFFE00000UL, resolver;
+
+			addr = regs->pc + 4 + (((addr ^ 0x00100000UL) + 0x00100000UL) << 2);
+			err = get_user(br2, (unsigned int *)addr);
+			err |= get_user(ldq, (unsigned int *)(addr+4));
+			err |= get_user(nop, (unsigned int *)(addr+8));
+			err |= get_user(jmp, (unsigned int *)(addr+12));
+			err |= get_user(resolver, (unsigned long *)(addr+16));
+
+			if (err)
+				break;
+
+			if (br2 == 0xC3600000U &&
+			    ldq == 0xA77B000CU &&
+			    nop == 0x47FF041FU &&
+			    jmp == 0x6B7B0000U)
+			{
+				regs->r28 = regs->pc+4;
+				regs->r27 = addr+16;
+				regs->pc = resolver;
+				return 3;
+			}
+		}
+	} while (0);
+#endif
+
+	return 1;
+}
+
+void pax_report_insns(struct pt_regs *regs, void *pc, void *sp)
+{
+	unsigned long i;
+
+	printk(KERN_ERR "PAX: bytes at PC: ");
+	for (i = 0; i < 5; i++) {
+		unsigned int c;
+		if (get_user(c, (unsigned int *)pc+i))
+			printk(KERN_CONT "???????? ");
+		else
+			printk(KERN_CONT "%08x ", c);
+	}
+	printk("\n");
+}
+#endif
 
 /*
  * This routine handles page faults.  It determines the address,
@@ -131,8 +249,29 @@ do_page_fault(unsigned long address, uns
  good_area:
 	si_code = SEGV_ACCERR;
 	if (cause < 0) {
-		if (!(vma->vm_flags & VM_EXEC))
+		if (!(vma->vm_flags & VM_EXEC)) {
+
+#ifdef CONFIG_PAX_PAGEEXEC
+			if (!(mm->pax_flags & MF_PAX_PAGEEXEC) || address != regs->pc)
+				goto bad_area;
+
+			up_read(&mm->mmap_sem);
+			switch (pax_handle_fetch_fault(regs)) {
+
+#ifdef CONFIG_PAX_EMUPLT
+			case 2:
+			case 3:
+				return;
+#endif
+
+			}
+			pax_report_fault(regs, (void *)regs->pc, (void *)rdusp());
+			do_group_exit(SIGKILL);
+#else
 			goto bad_area;
+#endif
+
+		}
 	} else if (!cause) {
 		/* Allow reads even for write-only mappings */
 		if (!(vma->vm_flags & (VM_READ | VM_WRITE)))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/include/asm/atomic.h linux-3.2.71-pax/arch/arm/include/asm/atomic.h
--- linux-3.2.71/arch/arm/include/asm/atomic.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/include/asm/atomic.h	2015-01-05 18:22:47.871593886 +0100
@@ -15,6 +15,10 @@
 #include <linux/types.h>
 #include <asm/system.h>
 
+#ifdef CONFIG_GENERIC_ATOMIC64
+#include <asm-generic/atomic64.h>
+#endif
+
 #define ATOMIC_INIT(i)	{ (i) }
 
 #ifdef __KERNEL__
@@ -25,7 +29,15 @@
  * atomic_set() is the clrex or dummy strex done on every exception return.
  */
 #define atomic_read(v)	(*(volatile int *)&(v)->counter)
+static inline int atomic_read_unchecked(const atomic_unchecked_t *v)
+{
+	return *(const volatile int *)&v->counter;
+}
 #define atomic_set(v,i)	(((v)->counter) = (i))
+static inline void atomic_set_unchecked(atomic_unchecked_t *v, int i)
+{
+	v->counter = i;
+}
 
 #if __LINUX_ARM_ARCH__ >= 6
 
@@ -40,6 +52,35 @@ static inline void atomic_add(int i, ato
 	int result;
 
 	__asm__ __volatile__("@ atomic_add\n"
+"1:	ldrex	%1, [%3]\n"
+"	adds	%0, %1, %4\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"	bvc	3f\n"
+"2:	bkpt	0xf103\n"
+"3:\n"
+#endif
+
+"	strex	%1, %0, [%3]\n"
+"	teq	%1, #0\n"
+"	bne	1b"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"\n4:\n"
+	_ASM_EXTABLE(2b, 4b)
+#endif
+
+	: "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)
+	: "r" (&v->counter), "Ir" (i)
+	: "cc");
+}
+
+static inline void atomic_add_unchecked(int i, atomic_unchecked_t *v)
+{
+	unsigned long tmp;
+	int result;
+
+	__asm__ __volatile__("@ atomic_add_unchecked\n"
 "1:	ldrex	%0, [%3]\n"
 "	add	%0, %0, %4\n"
 "	strex	%1, %0, [%3]\n"
@@ -58,6 +99,42 @@ static inline int atomic_add_return(int
 	smp_mb();
 
 	__asm__ __volatile__("@ atomic_add_return\n"
+"1:	ldrex	%1, [%3]\n"
+"	adds	%0, %1, %4\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"	bvc	3f\n"
+"	mov	%0, %1\n"
+"2:	bkpt	0xf103\n"
+"3:\n"
+#endif
+
+"	strex	%1, %0, [%3]\n"
+"	teq	%1, #0\n"
+"	bne	1b"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"\n4:\n"
+	_ASM_EXTABLE(2b, 4b)
+#endif
+
+	: "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)
+	: "r" (&v->counter), "Ir" (i)
+	: "cc");
+
+	smp_mb();
+
+	return result;
+}
+
+static inline int atomic_add_return_unchecked(int i, atomic_unchecked_t *v)
+{
+	unsigned long tmp;
+	int result;
+
+	smp_mb();
+
+	__asm__ __volatile__("@ atomic_add_return_unchecked\n"
 "1:	ldrex	%0, [%3]\n"
 "	add	%0, %0, %4\n"
 "	strex	%1, %0, [%3]\n"
@@ -78,6 +155,35 @@ static inline void atomic_sub(int i, ato
 	int result;
 
 	__asm__ __volatile__("@ atomic_sub\n"
+"1:	ldrex	%1, [%3]\n"
+"	subs	%0, %1, %4\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"	bvc	3f\n"
+"2:	bkpt	0xf103\n"
+"3:\n"
+#endif
+
+"	strex	%1, %0, [%3]\n"
+"	teq	%1, #0\n"
+"	bne	1b"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"\n4:\n"
+	_ASM_EXTABLE(2b, 4b)
+#endif
+
+	: "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)
+	: "r" (&v->counter), "Ir" (i)
+	: "cc");
+}
+
+static inline void atomic_sub_unchecked(int i, atomic_unchecked_t *v)
+{
+	unsigned long tmp;
+	int result;
+
+	__asm__ __volatile__("@ atomic_sub_unchecked\n"
 "1:	ldrex	%0, [%3]\n"
 "	sub	%0, %0, %4\n"
 "	strex	%1, %0, [%3]\n"
@@ -96,11 +202,25 @@ static inline int atomic_sub_return(int
 	smp_mb();
 
 	__asm__ __volatile__("@ atomic_sub_return\n"
-"1:	ldrex	%0, [%3]\n"
-"	sub	%0, %0, %4\n"
+"1:	ldrex	%1, [%3]\n"
+"	subs	%0, %1, %4\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"	bvc	3f\n"
+"	mov	%0, %1\n"
+"2:	bkpt	0xf103\n"
+"3:\n"
+#endif
+
 "	strex	%1, %0, [%3]\n"
 "	teq	%1, #0\n"
 "	bne	1b"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"\n4:\n"
+	_ASM_EXTABLE(2b, 4b)
+#endif
+
 	: "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)
 	: "r" (&v->counter), "Ir" (i)
 	: "cc");
@@ -132,6 +252,28 @@ static inline int atomic_cmpxchg(atomic_
 	return oldval;
 }
 
+static inline int atomic_cmpxchg_unchecked(atomic_unchecked_t *ptr, int old, int new)
+{
+	unsigned long oldval, res;
+
+	smp_mb();
+
+	do {
+		__asm__ __volatile__("@ atomic_cmpxchg_unchecked\n"
+		"ldrex	%1, [%3]\n"
+		"mov	%0, #0\n"
+		"teq	%1, %4\n"
+		"strexeq %0, %5, [%3]\n"
+		    : "=&r" (res), "=&r" (oldval), "+Qo" (ptr->counter)
+		    : "r" (&ptr->counter), "Ir" (old), "r" (new)
+		    : "cc");
+	} while (res);
+
+	smp_mb();
+
+	return oldval;
+}
+
 static inline void atomic_clear_mask(unsigned long mask, unsigned long *addr)
 {
 	unsigned long tmp, tmp2;
@@ -165,7 +307,17 @@ static inline int atomic_add_return(int
 
 	return val;
 }
+
+static inline int atomic_add_return_unchecked(int i, atomic_unchecked_t *v)
+{
+	return atomic_add_return(i, v);
+}
+
 #define atomic_add(i, v)	(void) atomic_add_return(i, v)
+static inline void atomic_add_unchecked(int i, atomic_unchecked_t *v)
+{
+	(void) atomic_add_return(i, v);
+}
 
 static inline int atomic_sub_return(int i, atomic_t *v)
 {
@@ -180,6 +332,10 @@ static inline int atomic_sub_return(int
 	return val;
 }
 #define atomic_sub(i, v)	(void) atomic_sub_return(i, v)
+static inline void atomic_sub_unchecked(int i, atomic_unchecked_t *v)
+{
+	(void) atomic_sub_return(i, v);
+}
 
 static inline int atomic_cmpxchg(atomic_t *v, int old, int new)
 {
@@ -195,6 +351,11 @@ static inline int atomic_cmpxchg(atomic_
 	return ret;
 }
 
+static inline int atomic_cmpxchg_unchecked(atomic_unchecked_t *v, int old, int new)
+{
+	return atomic_cmpxchg(v, old, new);
+}
+
 static inline void atomic_clear_mask(unsigned long mask, unsigned long *addr)
 {
 	unsigned long flags;
@@ -207,6 +368,10 @@ static inline void atomic_clear_mask(uns
 #endif /* __LINUX_ARM_ARCH__ */
 
 #define atomic_xchg(v, new) (xchg(&((v)->counter), new))
+static inline int atomic_xchg_unchecked(atomic_unchecked_t *v, int new)
+{
+	return xchg(&v->counter, new);
+}
 
 static inline int __atomic_add_unless(atomic_t *v, int a, int u)
 {
@@ -219,11 +384,27 @@ static inline int __atomic_add_unless(at
 }
 
 #define atomic_inc(v)		atomic_add(1, v)
+static inline void atomic_inc_unchecked(atomic_unchecked_t *v)
+{
+	atomic_add_unchecked(1, v);
+}
 #define atomic_dec(v)		atomic_sub(1, v)
+static inline void atomic_dec_unchecked(atomic_unchecked_t *v)
+{
+	atomic_sub_unchecked(1, v);
+}
 
 #define atomic_inc_and_test(v)	(atomic_add_return(1, v) == 0)
+static inline int atomic_inc_and_test_unchecked(atomic_unchecked_t *v)
+{
+	return atomic_add_return_unchecked(1, v) == 0;
+}
 #define atomic_dec_and_test(v)	(atomic_sub_return(1, v) == 0)
 #define atomic_inc_return(v)    (atomic_add_return(1, v))
+static inline int atomic_inc_return_unchecked(atomic_unchecked_t *v)
+{
+	return atomic_add_return_unchecked(1, v);
+}
 #define atomic_dec_return(v)    (atomic_sub_return(1, v))
 #define atomic_sub_and_test(i, v) (atomic_sub_return(i, v) == 0)
 
@@ -239,6 +420,14 @@ typedef struct {
 	u64 __aligned(8) counter;
 } atomic64_t;
 
+#ifdef CONFIG_PAX_REFCOUNT
+typedef struct {
+	u64 __aligned(8) counter;
+} atomic64_unchecked_t;
+#else
+typedef atomic64_t atomic64_unchecked_t;
+#endif
+
 #define ATOMIC64_INIT(i) { (i) }
 
 static inline u64 atomic64_read(atomic64_t *v)
@@ -254,6 +443,19 @@ static inline u64 atomic64_read(atomic64
 	return result;
 }
 
+static inline u64 atomic64_read_unchecked(atomic64_unchecked_t *v)
+{
+	u64 result;
+
+	__asm__ __volatile__("@ atomic64_read_unchecked\n"
+"	ldrexd	%0, %H0, [%1]"
+	: "=&r" (result)
+	: "r" (&v->counter), "Qo" (v->counter)
+	);
+
+	return result;
+}
+
 static inline void atomic64_set(atomic64_t *v, u64 i)
 {
 	u64 tmp;
@@ -268,6 +470,20 @@ static inline void atomic64_set(atomic64
 	: "cc");
 }
 
+static inline void atomic64_set_unchecked(atomic64_unchecked_t *v, u64 i)
+{
+	u64 tmp;
+
+	__asm__ __volatile__("@ atomic64_set_unchecked\n"
+"1:	ldrexd	%0, %H0, [%2]\n"
+"	strexd	%0, %3, %H3, [%2]\n"
+"	teq	%0, #0\n"
+"	bne	1b"
+	: "=&r" (tmp), "=Qo" (v->counter)
+	: "r" (&v->counter), "r" (i)
+	: "cc");
+}
+
 static inline void atomic64_add(u64 i, atomic64_t *v)
 {
 	u64 result;
@@ -276,6 +492,36 @@ static inline void atomic64_add(u64 i, a
 	__asm__ __volatile__("@ atomic64_add\n"
 "1:	ldrexd	%0, %H0, [%3]\n"
 "	adds	%0, %0, %4\n"
+"	adcs	%H0, %H0, %H4\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"	bvc	3f\n"
+"2:	bkpt	0xf103\n"
+"3:\n"
+#endif
+
+"	strexd	%1, %0, %H0, [%3]\n"
+"	teq	%1, #0\n"
+"	bne	1b"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"\n4:\n"
+	_ASM_EXTABLE(2b, 4b)
+#endif
+
+	: "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)
+	: "r" (&v->counter), "r" (i)
+	: "cc");
+}
+
+static inline void atomic64_add_unchecked(u64 i, atomic64_unchecked_t *v)
+{
+	u64 result;
+	unsigned long tmp;
+
+	__asm__ __volatile__("@ atomic64_add_unchecked\n"
+"1:	ldrexd	%0, %H0, [%3]\n"
+"	adds	%0, %0, %4\n"
 "	adc	%H0, %H0, %H4\n"
 "	strexd	%1, %0, %H0, [%3]\n"
 "	teq	%1, #0\n"
@@ -287,12 +533,49 @@ static inline void atomic64_add(u64 i, a
 
 static inline u64 atomic64_add_return(u64 i, atomic64_t *v)
 {
+	u64 result, tmp;
+
+	smp_mb();
+
+	__asm__ __volatile__("@ atomic64_add_return\n"
+"1:	ldrexd	%1, %H1, [%3]\n"
+"	adds	%0, %1, %4\n"
+"	adcs	%H0, %H1, %H4\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"	bvc	3f\n"
+"	mov	%0, %1\n"
+"	mov	%H0, %H1\n"
+"2:	bkpt	0xf103\n"
+"3:\n"
+#endif
+
+"	strexd	%1, %0, %H0, [%3]\n"
+"	teq	%1, #0\n"
+"	bne	1b"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"\n4:\n"
+	_ASM_EXTABLE(2b, 4b)
+#endif
+
+	: "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)
+	: "r" (&v->counter), "r" (i)
+	: "cc");
+
+	smp_mb();
+
+	return result;
+}
+
+static inline u64 atomic64_add_return_unchecked(u64 i, atomic64_unchecked_t *v)
+{
 	u64 result;
 	unsigned long tmp;
 
 	smp_mb();
 
-	__asm__ __volatile__("@ atomic64_add_return\n"
+	__asm__ __volatile__("@ atomic64_add_return_unchecked\n"
 "1:	ldrexd	%0, %H0, [%3]\n"
 "	adds	%0, %0, %4\n"
 "	adc	%H0, %H0, %H4\n"
@@ -316,23 +599,34 @@ static inline void atomic64_sub(u64 i, a
 	__asm__ __volatile__("@ atomic64_sub\n"
 "1:	ldrexd	%0, %H0, [%3]\n"
 "	subs	%0, %0, %4\n"
-"	sbc	%H0, %H0, %H4\n"
+"	sbcs	%H0, %H0, %H4\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"	bvc	3f\n"
+"2:	bkpt	0xf103\n"
+"3:\n"
+#endif
+
 "	strexd	%1, %0, %H0, [%3]\n"
 "	teq	%1, #0\n"
 "	bne	1b"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"\n4:\n"
+	_ASM_EXTABLE(2b, 4b)
+#endif
+
 	: "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)
 	: "r" (&v->counter), "r" (i)
 	: "cc");
 }
 
-static inline u64 atomic64_sub_return(u64 i, atomic64_t *v)
+static inline void atomic64_sub_unchecked(u64 i, atomic64_unchecked_t *v)
 {
 	u64 result;
 	unsigned long tmp;
 
-	smp_mb();
-
-	__asm__ __volatile__("@ atomic64_sub_return\n"
+	__asm__ __volatile__("@ atomic64_sub_unchecked\n"
 "1:	ldrexd	%0, %H0, [%3]\n"
 "	subs	%0, %0, %4\n"
 "	sbc	%H0, %H0, %H4\n"
@@ -342,6 +636,39 @@ static inline u64 atomic64_sub_return(u6
 	: "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)
 	: "r" (&v->counter), "r" (i)
 	: "cc");
+}
+
+static inline u64 atomic64_sub_return(u64 i, atomic64_t *v)
+{
+	u64 result, tmp;
+
+	smp_mb();
+
+	__asm__ __volatile__("@ atomic64_sub_return\n"
+"1:	ldrexd	%1, %H1, [%3]\n"
+"	subs	%0, %1, %4\n"
+"	sbcs	%H0, %H1, %H4\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"	bvc	3f\n"
+"	mov	%0, %1\n"
+"	mov	%H0, %H1\n"
+"2:	bkpt	0xf103\n"
+"3:\n"
+#endif
+
+"	strexd	%1, %0, %H0, [%3]\n"
+"	teq	%1, #0\n"
+"	bne	1b"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"\n4:\n"
+	_ASM_EXTABLE(2b, 4b)
+#endif
+
+	: "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)
+	: "r" (&v->counter), "r" (i)
+	: "cc");
 
 	smp_mb();
 
@@ -372,6 +699,30 @@ static inline u64 atomic64_cmpxchg(atomi
 	return oldval;
 }
 
+static inline u64 atomic64_cmpxchg_unchecked(atomic64_unchecked_t *ptr, u64 old, u64 new)
+{
+	u64 oldval;
+	unsigned long res;
+
+	smp_mb();
+
+	do {
+		__asm__ __volatile__("@ atomic64_cmpxchg_unchecked\n"
+		"ldrexd		%1, %H1, [%3]\n"
+		"mov		%0, #0\n"
+		"teq		%1, %4\n"
+		"teqeq		%H1, %H4\n"
+		"strexdeq	%0, %5, %H5, [%3]"
+		: "=&r" (res), "=&r" (oldval), "+Qo" (ptr->counter)
+		: "r" (&ptr->counter), "r" (old), "r" (new)
+		: "cc");
+	} while (res);
+
+	smp_mb();
+
+	return oldval;
+}
+
 static inline u64 atomic64_xchg(atomic64_t *ptr, u64 new)
 {
 	u64 result;
@@ -395,21 +746,34 @@ static inline u64 atomic64_xchg(atomic64
 
 static inline u64 atomic64_dec_if_positive(atomic64_t *v)
 {
-	u64 result;
-	unsigned long tmp;
+	u64 result, tmp;
 
 	smp_mb();
 
 	__asm__ __volatile__("@ atomic64_dec_if_positive\n"
-"1:	ldrexd	%0, %H0, [%3]\n"
-"	subs	%0, %0, #1\n"
-"	sbc	%H0, %H0, #0\n"
+"1:	ldrexd	%1, %H1, [%3]\n"
+"	subs	%0, %1, #1\n"
+"	sbcs	%H0, %H1, #0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"	bvc	3f\n"
+"	mov	%0, %1\n"
+"	mov	%H0, %H1\n"
+"2:	bkpt	0xf103\n"
+"3:\n"
+#endif
+
 "	teq	%H0, #0\n"
-"	bmi	2f\n"
+"	bmi	4f\n"
 "	strexd	%1, %0, %H0, [%3]\n"
 "	teq	%1, #0\n"
 "	bne	1b\n"
-"2:"
+"4:\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+	_ASM_EXTABLE(2b, 4b)
+#endif
+
 	: "=&r" (result), "=&r" (tmp), "+Qo" (v->counter)
 	: "r" (&v->counter)
 	: "cc");
@@ -432,13 +796,25 @@ static inline int atomic64_add_unless(at
 "	teq	%0, %5\n"
 "	teqeq	%H0, %H5\n"
 "	moveq	%1, #0\n"
-"	beq	2f\n"
+"	beq	4f\n"
 "	adds	%0, %0, %6\n"
-"	adc	%H0, %H0, %H6\n"
+"	adcs	%H0, %H0, %H6\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"	bvc	3f\n"
+"2:	bkpt	0xf103\n"
+"3:\n"
+#endif
+
 "	strexd	%2, %0, %H0, [%4]\n"
 "	teq	%2, #0\n"
 "	bne	1b\n"
-"2:"
+"4:\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+	_ASM_EXTABLE(2b, 4b)
+#endif
+
 	: "=&r" (val), "+r" (ret), "=&r" (tmp), "+Qo" (v->counter)
 	: "r" (&v->counter), "r" (u), "r" (a)
 	: "cc");
@@ -451,10 +827,13 @@ static inline int atomic64_add_unless(at
 
 #define atomic64_add_negative(a, v)	(atomic64_add_return((a), (v)) < 0)
 #define atomic64_inc(v)			atomic64_add(1LL, (v))
+#define atomic64_inc_unchecked(v)	atomic64_add_unchecked(1LL, (v))
 #define atomic64_inc_return(v)		atomic64_add_return(1LL, (v))
+#define atomic64_inc_return_unchecked(v)	atomic64_add_return_unchecked(1LL, (v))
 #define atomic64_inc_and_test(v)	(atomic64_inc_return(v) == 0)
 #define atomic64_sub_and_test(a, v)	(atomic64_sub_return((a), (v)) == 0)
 #define atomic64_dec(v)			atomic64_sub(1LL, (v))
+#define atomic64_dec_unchecked(v)	atomic64_sub_unchecked(1LL, (v))
 #define atomic64_dec_return(v)		atomic64_sub_return(1LL, (v))
 #define atomic64_dec_and_test(v)	(atomic64_dec_return((v)) == 0)
 #define atomic64_inc_not_zero(v)	atomic64_add_unless((v), 1LL, 0LL)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/include/asm/cacheflush.h linux-3.2.71-pax/arch/arm/include/asm/cacheflush.h
--- linux-3.2.71/arch/arm/include/asm/cacheflush.h	2014-04-02 03:15:40.395672618 +0200
+++ linux-3.2.71-pax/arch/arm/include/asm/cacheflush.h	2014-04-02 03:15:49.067672155 +0200
@@ -108,7 +108,7 @@ struct cpu_cache_fns {
 	void (*dma_unmap_area)(const void *, size_t, int);
 
 	void (*dma_flush_range)(const void *, const void *);
-};
+} __no_const;
 
 /*
  * Select the calling method
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/include/asm/cache.h linux-3.2.71-pax/arch/arm/include/asm/cache.h
--- linux-3.2.71/arch/arm/include/asm/cache.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/include/asm/cache.h	2013-03-28 04:34:44.839853365 +0100
@@ -4,8 +4,10 @@
 #ifndef __ASMARM_CACHE_H
 #define __ASMARM_CACHE_H
 
+#include <linux/const.h>
+
 #define L1_CACHE_SHIFT		CONFIG_ARM_L1_CACHE_SHIFT
-#define L1_CACHE_BYTES		(1 << L1_CACHE_SHIFT)
+#define L1_CACHE_BYTES		(_AC(1,UL) << L1_CACHE_SHIFT)
 
 /*
  * Memory returned by kmalloc() may be used for DMA, so we must make
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/include/asm/elf.h linux-3.2.71-pax/arch/arm/include/asm/elf.h
--- linux-3.2.71/arch/arm/include/asm/elf.h	2015-08-07 11:37:20.271789885 +0200
+++ linux-3.2.71-pax/arch/arm/include/asm/elf.h	2012-07-04 19:24:47.364063058 +0200
@@ -116,7 +116,14 @@ int dump_task_regs(struct task_struct *t
    the loader.  We need to make sure that it is out of the way of the program
    that it will "exec", and that there is sufficient room for the brk.  */
 
-#define ELF_ET_DYN_BASE	(TASK_SIZE / 3 * 2)
+#define ELF_ET_DYN_BASE		(TASK_SIZE / 3 * 2)
+
+#ifdef CONFIG_PAX_ASLR
+#define PAX_ELF_ET_DYN_BASE	0x00008000UL
+
+#define PAX_DELTA_MMAP_LEN	((current->personality == PER_LINUX_32BIT) ? 16 : 10)
+#define PAX_DELTA_STACK_LEN	((current->personality == PER_LINUX_32BIT) ? 16 : 10)
+#endif
 
 /* When the program starts, a1 contains a pointer to a function to be 
    registered with atexit, as per the SVR4 ABI.  A value of 0 means we 
@@ -126,10 +133,6 @@ int dump_task_regs(struct task_struct *t
 extern void elf_set_personality(const struct elf32_hdr *);
 #define SET_PERSONALITY(ex)	elf_set_personality(&(ex))
 
-struct mm_struct;
-extern unsigned long arch_randomize_brk(struct mm_struct *mm);
-#define arch_randomize_brk arch_randomize_brk
-
 extern int vectors_user_mapping(void);
 #define arch_setup_additional_pages(bprm, uses_interp) vectors_user_mapping()
 #define ARCH_HAS_SETUP_ADDITIONAL_PAGES
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/include/asm/kmap_types.h linux-3.2.71-pax/arch/arm/include/asm/kmap_types.h
--- linux-3.2.71/arch/arm/include/asm/kmap_types.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/include/asm/kmap_types.h	2012-07-04 19:24:47.364063058 +0200
@@ -21,6 +21,7 @@ enum km_type {
 	KM_L1_CACHE,
 	KM_L2_CACHE,
 	KM_KDB,
+	KM_CLEARPAGE,
 	KM_TYPE_NR
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/include/asm/outercache.h linux-3.2.71-pax/arch/arm/include/asm/outercache.h
--- linux-3.2.71/arch/arm/include/asm/outercache.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/include/asm/outercache.h	2012-07-04 19:24:47.364063058 +0200
@@ -35,7 +35,7 @@ struct outer_cache_fns {
 #endif
 	void (*set_debug)(unsigned long);
 	void (*resume)(void);
-};
+} __no_const;
 
 #ifdef CONFIG_OUTER_CACHE
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/include/asm/page.h linux-3.2.71-pax/arch/arm/include/asm/page.h
--- linux-3.2.71/arch/arm/include/asm/page.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/include/asm/page.h	2014-03-18 00:29:59.297306750 +0100
@@ -23,6 +23,7 @@
 
 #else
 
+#include <linux/compiler.h>
 #include <asm/glue.h>
 
 /*
@@ -123,7 +124,7 @@ struct cpu_user_fns {
 	void (*cpu_clear_user_highpage)(struct page *page, unsigned long vaddr);
 	void (*cpu_copy_user_highpage)(struct page *to, struct page *from,
 			unsigned long vaddr, struct vm_area_struct *vma);
-};
+} __no_const;
 
 #ifdef MULTI_USER
 extern struct cpu_user_fns cpu_user;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/include/asm/pgalloc.h linux-3.2.71-pax/arch/arm/include/asm/pgalloc.h
--- linux-3.2.71/arch/arm/include/asm/pgalloc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/include/asm/pgalloc.h	2013-03-07 22:26:18.244091812 +0100
@@ -31,6 +31,7 @@
 #define pmd_alloc_one(mm,addr)		({ BUG(); ((pmd_t *)2); })
 #define pmd_free(mm, pmd)		do { } while (0)
 #define pgd_populate(mm,pmd,pte)	BUG()
+#define pgd_populate_kernel(mm,pmd,pte)	BUG()
 
 extern pgd_t *pgd_alloc(struct mm_struct *mm);
 extern void pgd_free(struct mm_struct *mm, pgd_t *pgd);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/include/asm/pgtable.h linux-3.2.71-pax/arch/arm/include/asm/pgtable.h
--- linux-3.2.71/arch/arm/include/asm/pgtable.h	2014-04-30 18:53:44.888223432 +0200
+++ linux-3.2.71-pax/arch/arm/include/asm/pgtable.h	2014-04-30 18:53:50.372223420 +0200
@@ -26,6 +26,9 @@
 
 #include <asm/pgtable-2level.h>
 
+#define ktla_ktva(addr)		(addr)
+#define ktva_ktla(addr)		(addr)
+
 /*
  * Just any arbitrary offset to the start of the vmalloc VM area: the
  * current 8MB value just means that there will be a 8MB "hole" after the
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/include/asm/ptrace.h linux-3.2.71-pax/arch/arm/include/asm/ptrace.h
--- linux-3.2.71/arch/arm/include/asm/ptrace.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/include/asm/ptrace.h	2013-01-22 12:36:49.385509715 +0100
@@ -72,7 +72,7 @@
  * ARMv7 groups of PSR bits
  */
 #define APSR_MASK	0xf80f0000	/* N, Z, C, V, Q and GE flags */
-#define PSR_ISET_MASK	0x01000010	/* ISA state (J, T) mask */
+#define PSR_ISET_MASK	0x01000020	/* ISA state (J, T) mask */
 #define PSR_IT_MASK	0x0600fc00	/* If-Then execution state mask */
 #define PSR_ENDIAN_MASK	0x00000200	/* Endianness state mask */
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/include/asm/system.h linux-3.2.71-pax/arch/arm/include/asm/system.h
--- linux-3.2.71/arch/arm/include/asm/system.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/include/asm/system.h	2012-07-04 19:24:47.364063058 +0200
@@ -90,6 +90,8 @@ void hook_ifault_code(int nr, int (*fn)(
 
 #define xchg(ptr,x) \
 	((__typeof__(*(ptr)))__xchg((unsigned long)(x),(ptr),sizeof(*(ptr))))
+#define xchg_unchecked(ptr,x) \
+	((__typeof__(*(ptr)))__xchg((unsigned long)(x),(ptr),sizeof(*(ptr))))
 
 extern asmlinkage void c_backtrace(unsigned long fp, int pmode);
 
@@ -101,7 +103,7 @@ extern int __pure cpu_architecture(void)
 extern void cpu_init(void);
 
 void arm_machine_restart(char mode, const char *cmd);
-extern void (*arm_pm_restart)(char str, const char *cmd);
+extern void (*arm_pm_restart)(char str, const char *cmd) __noreturn;
 
 #define UDBG_UNDEFINED	(1 << 0)
 #define UDBG_SYSCALL	(1 << 1)
@@ -526,6 +528,13 @@ static inline unsigned long long __cmpxc
 
 #endif	/* __LINUX_ARM_ARCH__ >= 6 */
 
+#define _ASM_EXTABLE(from, to)		\
+"	.pushsection __ex_table,\"a\"\n"\
+"	.align	3\n"			\
+"	.long	" #from ", " #to"\n"	\
+"	.popsection"
+
+
 #endif /* __ASSEMBLY__ */
 
 #define arch_align_stack(x) (x)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/include/asm/uaccess.h linux-3.2.71-pax/arch/arm/include/asm/uaccess.h
--- linux-3.2.71/arch/arm/include/asm/uaccess.h	2014-07-12 17:42:33.664954216 +0200
+++ linux-3.2.71-pax/arch/arm/include/asm/uaccess.h	2014-07-12 17:42:44.720954191 +0200
@@ -202,6 +202,7 @@ static inline void set_fs(mm_segment_t f
 
 #endif /* CONFIG_MMU */
 
+#define access_ok_noprefault(type,addr,size) access_ok((type),(addr),(size))
 #define access_ok(type,addr,size)	(__range_ok(addr,size) == 0)
 
 /*
@@ -402,8 +403,21 @@ do {									\
 
 
 #ifdef CONFIG_MMU
-extern unsigned long __must_check __copy_from_user(void *to, const void __user *from, unsigned long n);
-extern unsigned long __must_check __copy_to_user(void __user *to, const void *from, unsigned long n);
+extern unsigned long __must_check ___copy_from_user(void *to, const void __user *from, unsigned long n);
+extern unsigned long __must_check ___copy_to_user(void __user *to, const void *from, unsigned long n);
+
+static inline unsigned long __must_check __copy_from_user(void *to, const void __user *from, unsigned long n)
+{
+	check_object_size(to, n, false);
+	return ___copy_from_user(to, from, n);
+}
+
+static inline unsigned long __must_check __copy_to_user(void __user *to, const void *from, unsigned long n)
+{
+	check_object_size(from, n, true);
+	return ___copy_to_user(to, from, n);
+}
+
 extern unsigned long __must_check __copy_to_user_std(void __user *to, const void *from, unsigned long n);
 extern unsigned long __must_check __clear_user(void __user *addr, unsigned long n);
 extern unsigned long __must_check __clear_user_std(void __user *addr, unsigned long n);
@@ -418,6 +432,9 @@ extern unsigned long __must_check __strn
 
 static inline unsigned long __must_check copy_from_user(void *to, const void __user *from, unsigned long n)
 {
+	if ((long)n < 0)
+		return n;
+
 	if (access_ok(VERIFY_READ, from, n))
 		n = __copy_from_user(to, from, n);
 	else /* security hole - plug it */
@@ -427,6 +444,9 @@ static inline unsigned long __must_check
 
 static inline unsigned long __must_check copy_to_user(void __user *to, const void *from, unsigned long n)
 {
+	if ((long)n < 0)
+		return n;
+
 	if (access_ok(VERIFY_WRITE, to, n))
 		n = __copy_to_user(to, from, n);
 	return n;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/kernel/armksyms.c linux-3.2.71-pax/arch/arm/kernel/armksyms.c
--- linux-3.2.71/arch/arm/kernel/armksyms.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/kernel/armksyms.c	2012-07-04 19:24:47.368063184 +0200
@@ -95,8 +95,8 @@ EXPORT_SYMBOL(__strncpy_from_user);
 #ifdef CONFIG_MMU
 EXPORT_SYMBOL(copy_page);
 
-EXPORT_SYMBOL(__copy_from_user);
-EXPORT_SYMBOL(__copy_to_user);
+EXPORT_SYMBOL(___copy_from_user);
+EXPORT_SYMBOL(___copy_to_user);
 EXPORT_SYMBOL(__clear_user);
 
 EXPORT_SYMBOL(__get_user_1);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/kernel/head.S linux-3.2.71-pax/arch/arm/kernel/head.S
--- linux-3.2.71/arch/arm/kernel/head.S	2013-02-09 01:12:40.716782284 +0100
+++ linux-3.2.71-pax/arch/arm/kernel/head.S	2013-02-09 01:12:46.960782468 +0100
@@ -46,7 +46,9 @@
 	.equ	swapper_pg_dir, KERNEL_RAM_VADDR - PG_DIR_SIZE
 
 	.macro	pgtbl, rd, phys
-	add	\rd, \phys, #TEXT_OFFSET - PG_DIR_SIZE
+	mov	\rd, #TEXT_OFFSET
+	sub	\rd, #PG_DIR_SIZE
+	add	\rd, \rd, \phys
 	.endm
 
 #ifdef CONFIG_XIP_KERNEL
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/kernel/hw_breakpoint.c linux-3.2.71-pax/arch/arm/kernel/hw_breakpoint.c
--- linux-3.2.71/arch/arm/kernel/hw_breakpoint.c	2012-09-20 01:42:17.046672773 +0200
+++ linux-3.2.71-pax/arch/arm/kernel/hw_breakpoint.c	2013-02-20 01:19:12.190027519 +0100
@@ -986,7 +986,7 @@ static int __cpuinit dbg_reset_notify(st
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata dbg_reset_nb = {
+static struct notifier_block dbg_reset_nb = {
 	.notifier_call = dbg_reset_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/kernel/module.c linux-3.2.71-pax/arch/arm/kernel/module.c
--- linux-3.2.71/arch/arm/kernel/module.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/kernel/module.c	2013-02-09 00:50:12.520742645 +0100
@@ -39,6 +39,8 @@
 #ifdef CONFIG_MMU
 void *module_alloc(unsigned long size)
 {
+	if (!size || PAGE_ALIGN(size) > MODULES_END - MODULES_VADDR)
+		return NULL;
 	return __vmalloc_node_range(size, 1, MODULES_VADDR, MODULES_END,
 				GFP_KERNEL, PAGE_KERNEL_EXEC, -1,
 				__builtin_return_address(0));
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/kernel/process.c linux-3.2.71-pax/arch/arm/kernel/process.c
--- linux-3.2.71/arch/arm/kernel/process.c	2014-01-03 15:48:44.520070590 +0100
+++ linux-3.2.71-pax/arch/arm/kernel/process.c	2014-01-03 15:48:49.468070325 +0100
@@ -28,7 +28,6 @@
 #include <linux/tick.h>
 #include <linux/utsname.h>
 #include <linux/uaccess.h>
-#include <linux/random.h>
 #include <linux/hw_breakpoint.h>
 #include <linux/cpuidle.h>
 
@@ -92,7 +91,7 @@ static int __init hlt_setup(char *__unus
 __setup("nohlt", nohlt_setup);
 __setup("hlt", hlt_setup);
 
-void arm_machine_restart(char mode, const char *cmd)
+__noreturn void arm_machine_restart(char mode, const char *cmd)
 {
 	/* Disable interrupts first */
 	local_irq_disable();
@@ -135,7 +134,7 @@ void arm_machine_restart(char mode, cons
 void (*pm_power_off)(void);
 EXPORT_SYMBOL(pm_power_off);
 
-void (*arm_pm_restart)(char str, const char *cmd) = arm_machine_restart;
+void (*arm_pm_restart)(char str, const char *cmd) __noreturn = arm_machine_restart;
 EXPORT_SYMBOL_GPL(arm_pm_restart);
 
 static void do_nothing(void *unused)
@@ -250,6 +249,7 @@ void machine_power_off(void)
 	machine_shutdown();
 	if (pm_power_off)
 		pm_power_off();
+	BUG();
 }
 
 void machine_restart(char *cmd)
@@ -489,12 +489,6 @@ unsigned long get_wchan(struct task_stru
 	return 0;
 }
 
-unsigned long arch_randomize_brk(struct mm_struct *mm)
-{
-	unsigned long range_end = mm->brk + 0x02000000;
-	return randomize_range(mm->brk, range_end, 0) ? : mm->brk;
-}
-
 #ifdef CONFIG_MMU
 /*
  * The vectors page is always readable from user space for the
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/lib/copy_from_user.S linux-3.2.71-pax/arch/arm/lib/copy_from_user.S
--- linux-3.2.71/arch/arm/lib/copy_from_user.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/lib/copy_from_user.S	2012-07-04 19:24:47.368063184 +0200
@@ -16,7 +16,7 @@
 /*
  * Prototype:
  *
- *	size_t __copy_from_user(void *to, const void *from, size_t n)
+ *	size_t ___copy_from_user(void *to, const void *from, size_t n)
  *
  * Purpose:
  *
@@ -84,11 +84,11 @@
 
 	.text
 
-ENTRY(__copy_from_user)
+ENTRY(___copy_from_user)
 
 #include "copy_template.S"
 
-ENDPROC(__copy_from_user)
+ENDPROC(___copy_from_user)
 
 	.pushsection .fixup,"ax"
 	.align 0
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/lib/copy_page.S linux-3.2.71-pax/arch/arm/lib/copy_page.S
--- linux-3.2.71/arch/arm/lib/copy_page.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/lib/copy_page.S	2012-07-04 19:24:47.368063184 +0200
@@ -10,6 +10,7 @@
  *  ASM optimised string functions
  */
 #include <linux/linkage.h>
+#include <linux/const.h>
 #include <asm/assembler.h>
 #include <asm/asm-offsets.h>
 #include <asm/cache.h>
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/lib/copy_to_user.S linux-3.2.71-pax/arch/arm/lib/copy_to_user.S
--- linux-3.2.71/arch/arm/lib/copy_to_user.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/lib/copy_to_user.S	2012-07-04 19:24:47.368063184 +0200
@@ -16,7 +16,7 @@
 /*
  * Prototype:
  *
- *	size_t __copy_to_user(void *to, const void *from, size_t n)
+ *	size_t ___copy_to_user(void *to, const void *from, size_t n)
  *
  * Purpose:
  *
@@ -88,11 +88,11 @@
 	.text
 
 ENTRY(__copy_to_user_std)
-WEAK(__copy_to_user)
+WEAK(___copy_to_user)
 
 #include "copy_template.S"
 
-ENDPROC(__copy_to_user)
+ENDPROC(___copy_to_user)
 ENDPROC(__copy_to_user_std)
 
 	.pushsection .fixup,"ax"
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/lib/uaccess.S linux-3.2.71-pax/arch/arm/lib/uaccess.S
--- linux-3.2.71/arch/arm/lib/uaccess.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/lib/uaccess.S	2012-07-04 19:24:47.368063184 +0200
@@ -20,7 +20,7 @@
 
 #define PAGE_SHIFT 12
 
-/* Prototype: int __copy_to_user(void *to, const char *from, size_t n)
+/* Prototype: int ___copy_to_user(void *to, const char *from, size_t n)
  * Purpose  : copy a block to user memory from kernel memory
  * Params   : to   - user memory
  *          : from - kernel memory
@@ -40,7 +40,7 @@ USER(		T(strgtb) r3, [r0], #1)			@ May f
 		sub	r2, r2, ip
 		b	.Lc2u_dest_aligned
 
-ENTRY(__copy_to_user)
+ENTRY(___copy_to_user)
 		stmfd	sp!, {r2, r4 - r7, lr}
 		cmp	r2, #4
 		blt	.Lc2u_not_enough
@@ -278,14 +278,14 @@ USER(		T(strgeb) r3, [r0], #1)			@ May f
 		ldrgtb	r3, [r1], #0
 USER(		T(strgtb) r3, [r0], #1)			@ May fault
 		b	.Lc2u_finished
-ENDPROC(__copy_to_user)
+ENDPROC(___copy_to_user)
 
 		.pushsection .fixup,"ax"
 		.align	0
 9001:		ldmfd	sp!, {r0, r4 - r7, pc}
 		.popsection
 
-/* Prototype: unsigned long __copy_from_user(void *to,const void *from,unsigned long n);
+/* Prototype: unsigned long ___copy_from_user(void *to,const void *from,unsigned long n);
  * Purpose  : copy a block from user memory to kernel memory
  * Params   : to   - kernel memory
  *          : from - user memory
@@ -304,7 +304,7 @@ USER(		T(ldrgtb) r3, [r1], #1)			@ May f
 		sub	r2, r2, ip
 		b	.Lcfu_dest_aligned
 
-ENTRY(__copy_from_user)
+ENTRY(___copy_from_user)
 		stmfd	sp!, {r0, r2, r4 - r7, lr}
 		cmp	r2, #4
 		blt	.Lcfu_not_enough
@@ -544,7 +544,7 @@ USER(		T(ldrgeb) r3, [r1], #1)			@ May f
 USER(		T(ldrgtb) r3, [r1], #1)			@ May fault
 		strgtb	r3, [r0], #1
 		b	.Lcfu_finished
-ENDPROC(__copy_from_user)
+ENDPROC(___copy_from_user)
 
 		.pushsection .fixup,"ax"
 		.align	0
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/lib/uaccess_with_memcpy.c linux-3.2.71-pax/arch/arm/lib/uaccess_with_memcpy.c
--- linux-3.2.71/arch/arm/lib/uaccess_with_memcpy.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/lib/uaccess_with_memcpy.c	2012-07-04 19:24:47.372063240 +0200
@@ -104,7 +104,7 @@ out:
 }
 
 unsigned long
-__copy_to_user(void __user *to, const void *from, unsigned long n)
+___copy_to_user(void __user *to, const void *from, unsigned long n)
 {
 	/*
 	 * This test is stubbed out of the main function above to keep
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/mach-omap2/board-n8x0.c linux-3.2.71-pax/arch/arm/mach-omap2/board-n8x0.c
--- linux-3.2.71/arch/arm/mach-omap2/board-n8x0.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/mach-omap2/board-n8x0.c	2012-07-04 19:24:47.372063240 +0200
@@ -593,7 +593,7 @@ static int n8x0_menelaus_late_init(struc
 }
 #endif
 
-static struct menelaus_platform_data n8x0_menelaus_platform_data __initdata = {
+static struct menelaus_platform_data n8x0_menelaus_platform_data __initconst = {
 	.late_init = n8x0_menelaus_late_init,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/mach-omap2/smartreflex.h linux-3.2.71-pax/arch/arm/mach-omap2/smartreflex.h
--- linux-3.2.71/arch/arm/mach-omap2/smartreflex.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/mach-omap2/smartreflex.h	2013-01-16 23:36:37.318657332 +0100
@@ -183,7 +183,7 @@ struct omap_sr_class_data {
 	int (*notify)(struct voltagedomain *voltdm, u32 status);
 	u8 notify_flags;
 	u8 class_type;
-};
+} __do_const;
 
 /**
  * struct omap_sr_nvalue_table	- Smartreflex n-target value info
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/mm/fault.c linux-3.2.71-pax/arch/arm/mm/fault.c
--- linux-3.2.71/arch/arm/mm/fault.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/mm/fault.c	2013-04-03 23:39:44.868174118 +0200
@@ -386,6 +386,33 @@ do_page_fault(unsigned long addr, unsign
 }
 #endif					/* CONFIG_MMU */
 
+#ifdef CONFIG_PAX_PAGEEXEC
+void pax_report_insns(struct pt_regs *regs, void *pc, void *sp)
+{
+	long i;
+
+	printk(KERN_ERR "PAX: bytes at PC: ");
+	for (i = 0; i < 20; i++) {
+		unsigned char c;
+		if (get_user(c, (__force unsigned char __user *)pc+i))
+			printk(KERN_CONT "?? ");
+		else
+			printk(KERN_CONT "%02x ", c);
+	}
+	printk("\n");
+
+	printk(KERN_ERR "PAX: bytes at SP-4: ");
+	for (i = -1; i < 20; i++) {
+		unsigned long c;
+		if (get_user(c, (__force unsigned long __user *)sp+i))
+			printk(KERN_CONT "???????? ");
+		else
+			printk(KERN_CONT "%08lx ", c);
+	}
+	printk("\n");
+}
+#endif
+
 /*
  * First Level Translation Fault Handler
  *
@@ -630,6 +657,20 @@ do_PrefetchAbort(unsigned long addr, uns
 	const struct fsr_info *inf = ifsr_info + fsr_fs(ifsr);
 	struct siginfo info;
 
+#ifdef CONFIG_PAX_REFCOUNT
+	if (fsr_fs(ifsr) == 2) {
+		unsigned int bkpt;
+
+		if (!probe_kernel_address((unsigned int *)addr, bkpt) && bkpt == 0xe12f1073) {
+			current->thread.error_code = ifsr;
+			current->thread.trap_no = 0;
+			pax_report_refcount_overflow(regs);
+			fixup_exception(regs);
+			return;
+		}
+	}
+#endif
+
 	if (!inf->fn(addr, ifsr | FSR_LNX_PF, regs))
 		return;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/mm/mmap.c linux-3.2.71-pax/arch/arm/mm/mmap.c
--- linux-3.2.71/arch/arm/mm/mmap.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/mm/mmap.c	2013-07-05 02:05:38.353224758 +0200
@@ -54,6 +54,10 @@ arch_get_unmapped_area(struct file *filp
 	if (len > TASK_SIZE)
 		return -ENOMEM;
 
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	if (addr) {
 		if (do_align)
 			addr = COLOUR_ALIGN(addr, pgoff);
@@ -61,16 +65,20 @@ arch_get_unmapped_area(struct file *filp
 			addr = PAGE_ALIGN(addr);
 
 		vma = find_vma(mm, addr);
-		if (TASK_SIZE - len >= addr &&
-		    (!vma || addr + len <= vma->vm_start))
+		if (TASK_SIZE - len >= addr && check_heap_stack_gap(vma, &addr, len))
 			return addr;
 	}
 	if (len > mm->cached_hole_size) {
-	        start_addr = addr = mm->free_area_cache;
+		start_addr = addr = mm->free_area_cache;
 	} else {
-	        start_addr = addr = TASK_UNMAPPED_BASE;
-	        mm->cached_hole_size = 0;
+		start_addr = addr = mm->mmap_base;
+		mm->cached_hole_size = 0;
 	}
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(current->mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	/* 8 bits of randomness in 20 address space bits */
 	if ((current->flags & PF_RANDOMIZE) &&
 	    !(current->personality & ADDR_NO_RANDOMIZE))
@@ -89,14 +97,14 @@ full_search:
 			 * Start a new search - just in case we missed
 			 * some holes.
 			 */
-			if (start_addr != TASK_UNMAPPED_BASE) {
-				start_addr = addr = TASK_UNMAPPED_BASE;
+			if (start_addr != mm->mmap_base) {
+				start_addr = addr = mm->mmap_base;
 				mm->cached_hole_size = 0;
 				goto full_search;
 			}
 			return -ENOMEM;
 		}
-		if (!vma || addr + len <= vma->vm_start) {
+		if (check_heap_stack_gap(vma, &addr, len)) {
 			/*
 			 * Remember the place where we stopped the search:
 			 */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/plat-samsung/include/plat/dma-ops.h linux-3.2.71-pax/arch/arm/plat-samsung/include/plat/dma-ops.h
--- linux-3.2.71/arch/arm/plat-samsung/include/plat/dma-ops.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/plat-samsung/include/plat/dma-ops.h	2012-07-04 19:24:47.372063240 +0200
@@ -41,7 +41,7 @@ struct samsung_dma_ops {
 	int (*started)(unsigned ch);
 	int (*flush)(unsigned ch);
 	int (*stop)(unsigned ch);
-};
+} __no_const;
 
 extern void *samsung_dmadev_get_ops(void);
 extern void *s3c_dma_get_ops(void);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/arm/plat-samsung/include/plat/ehci.h linux-3.2.71-pax/arch/arm/plat-samsung/include/plat/ehci.h
--- linux-3.2.71/arch/arm/plat-samsung/include/plat/ehci.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/arm/plat-samsung/include/plat/ehci.h	2012-07-04 19:24:47.372063240 +0200
@@ -14,7 +14,7 @@
 struct s5p_ehci_platdata {
 	int (*phy_init)(struct platform_device *pdev, int type);
 	int (*phy_exit)(struct platform_device *pdev, int type);
-};
+} __no_const;
 
 extern void s5p_ehci_set_platdata(struct s5p_ehci_platdata *pd);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/avr32/include/asm/elf.h linux-3.2.71-pax/arch/avr32/include/asm/elf.h
--- linux-3.2.71/arch/avr32/include/asm/elf.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/avr32/include/asm/elf.h	2012-07-04 19:24:47.372063240 +0200
@@ -84,8 +84,14 @@ typedef struct user_fpu_struct elf_fpreg
    the loader.  We need to make sure that it is out of the way of the program
    that it will "exec", and that there is sufficient room for the brk.  */
 
-#define ELF_ET_DYN_BASE         (2 * TASK_SIZE / 3)
+#define ELF_ET_DYN_BASE		(TASK_SIZE / 3 * 2)
 
+#ifdef CONFIG_PAX_ASLR
+#define PAX_ELF_ET_DYN_BASE	0x00001000UL
+
+#define PAX_DELTA_MMAP_LEN	15
+#define PAX_DELTA_STACK_LEN	15
+#endif
 
 /* This yields a mask that user programs can use to figure out what
    instruction set this CPU supports.  This could be done in user space,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/avr32/include/asm/kmap_types.h linux-3.2.71-pax/arch/avr32/include/asm/kmap_types.h
--- linux-3.2.71/arch/avr32/include/asm/kmap_types.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/avr32/include/asm/kmap_types.h	2012-07-04 19:24:47.376063175 +0200
@@ -22,7 +22,8 @@ D(10)	KM_IRQ0,
 D(11)	KM_IRQ1,
 D(12)	KM_SOFTIRQ0,
 D(13)	KM_SOFTIRQ1,
-D(14)	KM_TYPE_NR
+D(14)	KM_CLEARPAGE,
+D(15)	KM_TYPE_NR
 };
 
 #undef D
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/avr32/mm/fault.c linux-3.2.71-pax/arch/avr32/mm/fault.c
--- linux-3.2.71/arch/avr32/mm/fault.c	2015-02-20 12:37:32.837178789 +0100
+++ linux-3.2.71-pax/arch/avr32/mm/fault.c	2015-02-20 12:37:41.809178310 +0100
@@ -41,6 +41,23 @@ static inline int notify_page_fault(stru
 
 int exception_trace = 1;
 
+#ifdef CONFIG_PAX_PAGEEXEC
+void pax_report_insns(struct pt_regs *regs, void *pc, void *sp)
+{
+	unsigned long i;
+
+	printk(KERN_ERR "PAX: bytes at PC: ");
+	for (i = 0; i < 20; i++) {
+		unsigned char c;
+		if (get_user(c, (unsigned char *)pc+i))
+			printk(KERN_CONT "???????? ");
+		else
+			printk(KERN_CONT "%02x ", c);
+	}
+	printk("\n");
+}
+#endif
+
 /*
  * This routine handles page faults. It determines the address and the
  * problem, and then passes it off to one of the appropriate routines.
@@ -158,6 +175,16 @@ bad_area:
 	up_read(&mm->mmap_sem);
 
 	if (user_mode(regs)) {
+
+#ifdef CONFIG_PAX_PAGEEXEC
+		if (mm->pax_flags & MF_PAX_PAGEEXEC) {
+			if (ecr == ECR_PROTECTION_X || ecr == ECR_TLB_MISS_X) {
+				pax_report_fault(regs, (void *)regs->pc, (void *)regs->sp);
+				do_group_exit(SIGKILL);
+			}
+		}
+#endif
+
 		if (exception_trace && printk_ratelimit())
 			printk("%s%s[%d]: segfault at %08lx pc %08lx "
 			       "sp %08lx ecr %lu\n",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/frv/include/asm/atomic.h linux-3.2.71-pax/arch/frv/include/asm/atomic.h
--- linux-3.2.71/arch/frv/include/asm/atomic.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/frv/include/asm/atomic.h	2012-07-04 19:24:47.376063175 +0200
@@ -241,6 +241,16 @@ extern uint32_t __xchg_32(uint32_t i, vo
 #define atomic64_cmpxchg(v, old, new)	(__cmpxchg_64(old, new, &(v)->counter))
 #define atomic64_xchg(v, new)		(__xchg_64(new, &(v)->counter))
 
+#define atomic64_read_unchecked(v)		atomic64_read(v)
+#define atomic64_set_unchecked(v, i)		atomic64_set((v), (i))
+#define atomic64_add_unchecked(a, v)		atomic64_add((a), (v))
+#define atomic64_add_return_unchecked(a, v)	atomic64_add_return((a), (v))
+#define atomic64_sub_unchecked(a, v)		atomic64_sub((a), (v))
+#define atomic64_inc_unchecked(v)		atomic64_inc(v)
+#define atomic64_inc_return_unchecked(v)	atomic64_inc_return(v)
+#define atomic64_dec_unchecked(v)		atomic64_dec(v)
+#define atomic64_cmpxchg_unchecked(v, o, n)	atomic64_cmpxchg((v), (o), (n))
+
 static __inline__ int __atomic_add_unless(atomic_t *v, int a, int u)
 {
 	int c, old;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/frv/include/asm/kmap_types.h linux-3.2.71-pax/arch/frv/include/asm/kmap_types.h
--- linux-3.2.71/arch/frv/include/asm/kmap_types.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/frv/include/asm/kmap_types.h	2012-07-04 19:24:47.376063175 +0200
@@ -23,6 +23,7 @@ enum km_type {
 	KM_IRQ1,
 	KM_SOFTIRQ0,
 	KM_SOFTIRQ1,
+	KM_CLEARPAGE,
 	KM_TYPE_NR
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/frv/mm/elf-fdpic.c linux-3.2.71-pax/arch/frv/mm/elf-fdpic.c
--- linux-3.2.71/arch/frv/mm/elf-fdpic.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/frv/mm/elf-fdpic.c	2013-07-05 02:13:50.553198479 +0200
@@ -73,8 +73,7 @@ unsigned long arch_get_unmapped_area(str
 	if (addr) {
 		addr = PAGE_ALIGN(addr);
 		vma = find_vma(current->mm, addr);
-		if (TASK_SIZE - len >= addr &&
-		    (!vma || addr + len <= vma->vm_start))
+		if (TASK_SIZE - len >= addr && check_heap_stack_gap(vma, &addr, len))
 			goto success;
 	}
 
@@ -89,7 +88,7 @@ unsigned long arch_get_unmapped_area(str
 			for (; vma; vma = vma->vm_next) {
 				if (addr > limit)
 					break;
-				if (addr + len <= vma->vm_start)
+				if (check_heap_stack_gap(vma, &addr, len))
 					goto success;
 				addr = vma->vm_end;
 			}
@@ -104,7 +103,7 @@ unsigned long arch_get_unmapped_area(str
 		for (; vma; vma = vma->vm_next) {
 			if (addr > limit)
 				break;
-			if (addr + len <= vma->vm_start)
+			if (check_heap_stack_gap(vma, &addr, len))
 				goto success;
 			addr = vma->vm_end;
 		}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/include/asm/atomic.h linux-3.2.71-pax/arch/ia64/include/asm/atomic.h
--- linux-3.2.71/arch/ia64/include/asm/atomic.h	2012-08-12 12:28:42.733231782 +0200
+++ linux-3.2.71-pax/arch/ia64/include/asm/atomic.h	2012-08-12 12:28:56.889230243 +0200
@@ -209,6 +209,16 @@ atomic64_add_negative (__s64 i, atomic64
 #define atomic64_inc(v)			atomic64_add(1, (v))
 #define atomic64_dec(v)			atomic64_sub(1, (v))
 
+#define atomic64_read_unchecked(v)		atomic64_read(v)
+#define atomic64_set_unchecked(v, i)		atomic64_set((v), (i))
+#define atomic64_add_unchecked(a, v)		atomic64_add((a), (v))
+#define atomic64_add_return_unchecked(a, v)	atomic64_add_return((a), (v))
+#define atomic64_sub_unchecked(a, v)		atomic64_sub((a), (v))
+#define atomic64_inc_unchecked(v)		atomic64_inc(v)
+#define atomic64_inc_return_unchecked(v)	atomic64_inc_return(v)
+#define atomic64_dec_unchecked(v)		atomic64_dec(v)
+#define atomic64_cmpxchg_unchecked(v, o, n)	atomic64_cmpxchg((v), (o), (n))
+
 /* Atomic operations are already serializing */
 #define smp_mb__before_atomic_dec()	barrier()
 #define smp_mb__after_atomic_dec()	barrier()
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/include/asm/elf.h linux-3.2.71-pax/arch/ia64/include/asm/elf.h
--- linux-3.2.71/arch/ia64/include/asm/elf.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/include/asm/elf.h	2012-07-04 19:24:47.376063175 +0200
@@ -42,6 +42,13 @@
  */
 #define ELF_ET_DYN_BASE		(TASK_UNMAPPED_BASE + 0x800000000UL)
 
+#ifdef CONFIG_PAX_ASLR
+#define PAX_ELF_ET_DYN_BASE	(current->personality == PER_LINUX32 ? 0x08048000UL : 0x4000000000000000UL)
+
+#define PAX_DELTA_MMAP_LEN	(current->personality == PER_LINUX32 ? 16 : 3*PAGE_SHIFT - 13)
+#define PAX_DELTA_STACK_LEN	(current->personality == PER_LINUX32 ? 16 : 3*PAGE_SHIFT - 13)
+#endif
+
 #define PT_IA_64_UNWIND		0x70000001
 
 /* IA-64 relocations: */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/include/asm/pgalloc.h linux-3.2.71-pax/arch/ia64/include/asm/pgalloc.h
--- linux-3.2.71/arch/ia64/include/asm/pgalloc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/include/asm/pgalloc.h	2012-07-04 19:24:47.376063175 +0200
@@ -39,6 +39,12 @@ pgd_populate(struct mm_struct *mm, pgd_t
 	pgd_val(*pgd_entry) = __pa(pud);
 }
 
+static inline void
+pgd_populate_kernel(struct mm_struct *mm, pgd_t * pgd_entry, pud_t * pud)
+{
+	pgd_populate(mm, pgd_entry, pud);
+}
+
 static inline pud_t *pud_alloc_one(struct mm_struct *mm, unsigned long addr)
 {
 	return quicklist_alloc(0, GFP_KERNEL, NULL);
@@ -57,6 +63,12 @@ pud_populate(struct mm_struct *mm, pud_t
 	pud_val(*pud_entry) = __pa(pmd);
 }
 
+static inline void
+pud_populate_kernel(struct mm_struct *mm, pud_t * pud_entry, pmd_t * pmd)
+{
+	pud_populate(mm, pud_entry, pmd);
+}
+
 static inline pmd_t *pmd_alloc_one(struct mm_struct *mm, unsigned long addr)
 {
 	return quicklist_alloc(0, GFP_KERNEL, NULL);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/include/asm/pgtable.h linux-3.2.71-pax/arch/ia64/include/asm/pgtable.h
--- linux-3.2.71/arch/ia64/include/asm/pgtable.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/include/asm/pgtable.h	2012-07-04 19:24:47.380063064 +0200
@@ -12,7 +12,7 @@
  *	David Mosberger-Tang <davidm@hpl.hp.com>
  */
 
-
+#include <linux/const.h>
 #include <asm/mman.h>
 #include <asm/page.h>
 #include <asm/processor.h>
@@ -143,6 +143,17 @@
 #define PAGE_READONLY	__pgprot(__ACCESS_BITS | _PAGE_PL_3 | _PAGE_AR_R)
 #define PAGE_COPY	__pgprot(__ACCESS_BITS | _PAGE_PL_3 | _PAGE_AR_R)
 #define PAGE_COPY_EXEC	__pgprot(__ACCESS_BITS | _PAGE_PL_3 | _PAGE_AR_RX)
+
+#ifdef CONFIG_PAX_PAGEEXEC
+# define PAGE_SHARED_NOEXEC	__pgprot(__ACCESS_BITS | _PAGE_PL_3 | _PAGE_AR_RW)
+# define PAGE_READONLY_NOEXEC	__pgprot(__ACCESS_BITS | _PAGE_PL_3 | _PAGE_AR_R)
+# define PAGE_COPY_NOEXEC	__pgprot(__ACCESS_BITS | _PAGE_PL_3 | _PAGE_AR_R)
+#else
+# define PAGE_SHARED_NOEXEC	PAGE_SHARED
+# define PAGE_READONLY_NOEXEC	PAGE_READONLY
+# define PAGE_COPY_NOEXEC	PAGE_COPY
+#endif
+
 #define PAGE_GATE	__pgprot(__ACCESS_BITS | _PAGE_PL_0 | _PAGE_AR_X_RX)
 #define PAGE_KERNEL	__pgprot(__DIRTY_BITS  | _PAGE_PL_0 | _PAGE_AR_RWX)
 #define PAGE_KERNELRX	__pgprot(__ACCESS_BITS | _PAGE_PL_0 | _PAGE_AR_RX)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/include/asm/spinlock.h linux-3.2.71-pax/arch/ia64/include/asm/spinlock.h
--- linux-3.2.71/arch/ia64/include/asm/spinlock.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/include/asm/spinlock.h	2012-07-04 19:24:47.380063064 +0200
@@ -72,7 +72,7 @@ static __always_inline void __ticket_spi
 	unsigned short	*p = (unsigned short *)&lock->lock + 1, tmp;
 
 	asm volatile ("ld2.bias %0=[%1]" : "=r"(tmp) : "r"(p));
-	ACCESS_ONCE(*p) = (tmp + 2) & ~1;
+	ACCESS_ONCE_RW(*p) = (tmp + 2) & ~1;
 }
 
 static __always_inline void __ticket_spin_unlock_wait(arch_spinlock_t *lock)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/include/asm/uaccess.h linux-3.2.71-pax/arch/ia64/include/asm/uaccess.h
--- linux-3.2.71/arch/ia64/include/asm/uaccess.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/include/asm/uaccess.h	2014-03-23 21:07:50.736059889 +0100
@@ -70,6 +70,7 @@
 	 && ((segment).seg == KERNEL_DS.seg						\
 	     || likely(REGION_OFFSET((unsigned long) (addr)) < RGN_MAP_LIMIT)));	\
 })
+#define access_ok_noprefault(type, addr, size) access_ok((type), (addr), (size))
 #define access_ok(type, addr, size)	__access_ok((addr), (size), get_fs())
 
 /*
@@ -240,12 +241,24 @@ extern unsigned long __must_check __copy
 static inline unsigned long
 __copy_to_user (void __user *to, const void *from, unsigned long count)
 {
+	if (count > INT_MAX)
+		return count;
+
+	if (!__builtin_constant_p(count))
+		check_object_size(from, count, true);
+
 	return __copy_user(to, (__force void __user *) from, count);
 }
 
 static inline unsigned long
 __copy_from_user (void *to, const void __user *from, unsigned long count)
 {
+	if (count > INT_MAX)
+		return count;
+
+	if (!__builtin_constant_p(count))
+		check_object_size(to, count, false);
+
 	return __copy_user((__force void __user *) to, from, count);
 }
 
@@ -255,10 +268,13 @@ __copy_from_user (void *to, const void _
 ({											\
 	void __user *__cu_to = (to);							\
 	const void *__cu_from = (from);							\
-	long __cu_len = (n);								\
+	unsigned long __cu_len = (n);							\
 											\
-	if (__access_ok(__cu_to, __cu_len, get_fs()))					\
+	if (__cu_len <= INT_MAX && __access_ok(__cu_to, __cu_len, get_fs())) {		\
+		if (!__builtin_constant_p(n))						\
+			check_object_size(__cu_from, __cu_len, true);			\
 		__cu_len = __copy_user(__cu_to, (__force void __user *) __cu_from, __cu_len);	\
+	}										\
 	__cu_len;									\
 })
 
@@ -266,11 +282,14 @@ __copy_from_user (void *to, const void _
 ({											\
 	void *__cu_to = (to);								\
 	const void __user *__cu_from = (from);						\
-	long __cu_len = (n);								\
+	unsigned long __cu_len = (n);							\
 											\
 	__chk_user_ptr(__cu_from);							\
-	if (__access_ok(__cu_from, __cu_len, get_fs()))					\
+	if (__cu_len <= INT_MAX  && __access_ok(__cu_from, __cu_len, get_fs())) {	\
+		if (!__builtin_constant_p(n))						\
+			check_object_size(__cu_to, __cu_len, false);			\
 		__cu_len = __copy_user((__force void __user *) __cu_to, __cu_from, __cu_len);	\
+	}										\
 	__cu_len;									\
 })
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/kernel/err_inject.c linux-3.2.71-pax/arch/ia64/kernel/err_inject.c
--- linux-3.2.71/arch/ia64/kernel/err_inject.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/kernel/err_inject.c	2013-02-20 01:19:14.946027372 +0100
@@ -256,7 +256,7 @@ static int __cpuinit err_inject_cpu_call
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata err_inject_cpu_notifier =
+static struct notifier_block err_inject_cpu_notifier =
 {
 	.notifier_call = err_inject_cpu_callback,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/kernel/mca.c linux-3.2.71-pax/arch/ia64/kernel/mca.c
--- linux-3.2.71/arch/ia64/kernel/mca.c	2013-05-14 13:33:40.444285682 +0200
+++ linux-3.2.71-pax/arch/ia64/kernel/mca.c	2013-05-14 13:33:46.504285358 +0200
@@ -1919,7 +1919,7 @@ static int __cpuinit mca_cpu_callback(st
 	return NOTIFY_OK;
 }
 
-static struct notifier_block mca_cpu_notifier __cpuinitdata = {
+static struct notifier_block mca_cpu_notifier = {
 	.notifier_call = mca_cpu_callback
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/kernel/module.c linux-3.2.71-pax/arch/ia64/kernel/module.c
--- linux-3.2.71/arch/ia64/kernel/module.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/kernel/module.c	2012-07-04 19:24:47.380063064 +0200
@@ -307,8 +307,7 @@ plt_target (struct plt_entry *plt)
 void
 module_free (struct module *mod, void *module_region)
 {
-	if (mod && mod->arch.init_unw_table &&
-	    module_region == mod->module_init) {
+	if (mod && mod->arch.init_unw_table && module_region == mod->module_init_rx) {
 		unw_remove_unwind_table(mod->arch.init_unw_table);
 		mod->arch.init_unw_table = NULL;
 	}
@@ -494,15 +493,39 @@ module_frob_arch_sections (Elf_Ehdr *ehd
 }
 
 static inline int
+in_init_rx (const struct module *mod, uint64_t addr)
+{
+	return addr - (uint64_t) mod->module_init_rx < mod->init_size_rx;
+}
+
+static inline int
+in_init_rw (const struct module *mod, uint64_t addr)
+{
+	return addr - (uint64_t) mod->module_init_rw < mod->init_size_rw;
+}
+
+static inline int
 in_init (const struct module *mod, uint64_t addr)
 {
-	return addr - (uint64_t) mod->module_init < mod->init_size;
+	return in_init_rx(mod, addr) || in_init_rw(mod, addr);
+}
+
+static inline int
+in_core_rx (const struct module *mod, uint64_t addr)
+{
+	return addr - (uint64_t) mod->module_core_rx < mod->core_size_rx;
+}
+
+static inline int
+in_core_rw (const struct module *mod, uint64_t addr)
+{
+	return addr - (uint64_t) mod->module_core_rw < mod->core_size_rw;
 }
 
 static inline int
 in_core (const struct module *mod, uint64_t addr)
 {
-	return addr - (uint64_t) mod->module_core < mod->core_size;
+	return in_core_rx(mod, addr) || in_core_rw(mod, addr);
 }
 
 static inline int
@@ -685,7 +708,14 @@ do_reloc (struct module *mod, uint8_t r_
 		break;
 
 	      case RV_BDREL:
-		val -= (uint64_t) (in_init(mod, val) ? mod->module_init : mod->module_core);
+		if (in_init_rx(mod, val))
+			val -= (uint64_t) mod->module_init_rx;
+		else if (in_init_rw(mod, val))
+			val -= (uint64_t) mod->module_init_rw;
+		else if (in_core_rx(mod, val))
+			val -= (uint64_t) mod->module_core_rx;
+		else if (in_core_rw(mod, val))
+			val -= (uint64_t) mod->module_core_rw;
 		break;
 
 	      case RV_LTV:
@@ -820,15 +850,15 @@ apply_relocate_add (Elf64_Shdr *sechdrs,
 		 *     addresses have been selected...
 		 */
 		uint64_t gp;
-		if (mod->core_size > MAX_LTOFF)
+		if (mod->core_size_rx + mod->core_size_rw > MAX_LTOFF)
 			/*
 			 * This takes advantage of fact that SHF_ARCH_SMALL gets allocated
 			 * at the end of the module.
 			 */
-			gp = mod->core_size - MAX_LTOFF / 2;
+			gp = mod->core_size_rx + mod->core_size_rw - MAX_LTOFF / 2;
 		else
-			gp = mod->core_size / 2;
-		gp = (uint64_t) mod->module_core + ((gp + 7) & -8);
+			gp = (mod->core_size_rx + mod->core_size_rw) / 2;
+		gp = (uint64_t) mod->module_core_rx + ((gp + 7) & -8);
 		mod->arch.gp = gp;
 		DEBUGP("%s: placing gp at 0x%lx\n", __func__, gp);
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/kernel/palinfo.c linux-3.2.71-pax/arch/ia64/kernel/palinfo.c
--- linux-3.2.71/arch/ia64/kernel/palinfo.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/kernel/palinfo.c	2013-02-20 01:19:14.954027372 +0100
@@ -1045,7 +1045,7 @@ static int __cpuinit palinfo_cpu_callbac
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __refdata palinfo_cpu_notifier =
+static struct notifier_block palinfo_cpu_notifier =
 {
 	.notifier_call = palinfo_cpu_callback,
 	.priority = 0,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/kernel/perfmon.c linux-3.2.71-pax/arch/ia64/kernel/perfmon.c
--- linux-3.2.71/arch/ia64/kernel/perfmon.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/kernel/perfmon.c	2013-03-28 04:47:34.043812296 +0100
@@ -2370,7 +2370,6 @@ pfm_smpl_buffer_alloc(struct task_struct
 	 */
 	insert_vm_struct(mm, vma);
 
-	mm->total_vm  += size >> PAGE_SHIFT;
 	vm_stat_account(vma->vm_mm, vma->vm_flags, vma->vm_file,
 							vma_pages(vma));
 	up_write(&task->mm->mmap_sem);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/kernel/salinfo.c linux-3.2.71-pax/arch/ia64/kernel/salinfo.c
--- linux-3.2.71/arch/ia64/kernel/salinfo.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/kernel/salinfo.c	2013-02-20 01:19:14.954027372 +0100
@@ -616,7 +616,7 @@ salinfo_cpu_callback(struct notifier_blo
 	return NOTIFY_OK;
 }
 
-static struct notifier_block salinfo_cpu_notifier __cpuinitdata =
+static struct notifier_block salinfo_cpu_notifier =
 {
 	.notifier_call = salinfo_cpu_callback,
 	.priority = 0,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/kernel/sys_ia64.c linux-3.2.71-pax/arch/ia64/kernel/sys_ia64.c
--- linux-3.2.71/arch/ia64/kernel/sys_ia64.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/kernel/sys_ia64.c	2013-07-05 02:14:31.425196296 +0200
@@ -43,6 +43,13 @@ arch_get_unmapped_area (struct file *fil
 	if (REGION_NUMBER(addr) == RGN_HPAGE)
 		addr = 0;
 #endif
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (mm->pax_flags & MF_PAX_RANDMMAP)
+		addr = mm->free_area_cache;
+	else
+#endif
+
 	if (!addr)
 		addr = mm->free_area_cache;
 
@@ -61,14 +68,14 @@ arch_get_unmapped_area (struct file *fil
 	for (vma = find_vma(mm, addr); ; vma = vma->vm_next) {
 		/* At this point:  (!vma || addr < vma->vm_end). */
 		if (TASK_SIZE - len < addr || RGN_MAP_LIMIT - len < REGION_OFFSET(addr)) {
-			if (start_addr != TASK_UNMAPPED_BASE) {
+			if (start_addr != mm->mmap_base) {
 				/* Start a new search --- just in case we missed some holes.  */
-				addr = TASK_UNMAPPED_BASE;
+				addr = mm->mmap_base;
 				goto full_search;
 			}
 			return -ENOMEM;
 		}
-		if (!vma || addr + len <= vma->vm_start) {
+		if (check_heap_stack_gap(vma, &addr, len)) {
 			/* Remember the address where we stopped this search:  */
 			mm->free_area_cache = addr + len;
 			return addr;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/kernel/topology.c linux-3.2.71-pax/arch/ia64/kernel/topology.c
--- linux-3.2.71/arch/ia64/kernel/topology.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/kernel/topology.c	2013-02-20 01:23:29.846013763 +0100
@@ -444,7 +444,7 @@ static int __cpuinit cache_cpu_callback(
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata cache_cpu_notifier =
+static struct notifier_block cache_cpu_notifier =
 {
 	.notifier_call = cache_cpu_callback
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/kernel/vmlinux.lds.S linux-3.2.71-pax/arch/ia64/kernel/vmlinux.lds.S
--- linux-3.2.71/arch/ia64/kernel/vmlinux.lds.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/kernel/vmlinux.lds.S	2012-07-04 19:24:47.380063064 +0200
@@ -199,7 +199,7 @@ SECTIONS {
 	/* Per-cpu data: */
 	. = ALIGN(PERCPU_PAGE_SIZE);
 	PERCPU_VADDR(SMP_CACHE_BYTES, PERCPU_ADDR, :percpu)
-	__phys_per_cpu_start = __per_cpu_load;
+	__phys_per_cpu_start = per_cpu_load;
 	/*
 	 * ensure percpu data fits
 	 * into percpu page size
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/Makefile linux-3.2.71-pax/arch/ia64/Makefile
--- linux-3.2.71/arch/ia64/Makefile	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/Makefile	2014-09-14 14:53:42.990375922 +0200
@@ -101,5 +101,6 @@ endef
 archprepare: make_nr_irqs_h FORCE
 PHONY += make_nr_irqs_h FORCE
 
+make_nr_irqs_h: KBUILD_CFLAGS := $(filter-out $(GCC_PLUGINS_CFLAGS),$(KBUILD_CFLAGS))
 make_nr_irqs_h: FORCE
 	$(Q)$(MAKE) $(build)=arch/ia64/kernel include/generated/nr-irqs.h
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/mm/fault.c linux-3.2.71-pax/arch/ia64/mm/fault.c
--- linux-3.2.71/arch/ia64/mm/fault.c	2015-02-20 12:37:32.853178788 +0100
+++ linux-3.2.71-pax/arch/ia64/mm/fault.c	2015-02-20 12:37:41.809178310 +0100
@@ -73,6 +73,23 @@ mapped_kernel_page_is_present (unsigned
 	return pte_present(pte);
 }
 
+#ifdef CONFIG_PAX_PAGEEXEC
+void pax_report_insns(struct pt_regs *regs, void *pc, void *sp)
+{
+	unsigned long i;
+
+	printk(KERN_ERR "PAX: bytes at PC: ");
+	for (i = 0; i < 8; i++) {
+		unsigned int c;
+		if (get_user(c, (unsigned int *)pc+i))
+			printk(KERN_CONT "???????? ");
+		else
+			printk(KERN_CONT "%08x ", c);
+	}
+	printk("\n");
+}
+#endif
+
 void __kprobes
 ia64_do_page_fault (unsigned long address, unsigned long isr, struct pt_regs *regs)
 {
@@ -146,9 +163,23 @@ ia64_do_page_fault (unsigned long addres
 	mask = (  (((isr >> IA64_ISR_X_BIT) & 1UL) << VM_EXEC_BIT)
 		| (((isr >> IA64_ISR_W_BIT) & 1UL) << VM_WRITE_BIT));
 
-	if ((vma->vm_flags & mask) != mask)
+	if ((vma->vm_flags & mask) != mask) {
+
+#ifdef CONFIG_PAX_PAGEEXEC
+		if (!(vma->vm_flags & VM_EXEC) && (mask & VM_EXEC)) {
+			if (!(mm->pax_flags & MF_PAX_PAGEEXEC) || address != regs->cr_iip)
+				goto bad_area;
+
+			up_read(&mm->mmap_sem);
+			pax_report_fault(regs, (void *)regs->cr_iip, (void *)regs->r12);
+			do_group_exit(SIGKILL);
+		}
+#endif
+
 		goto bad_area;
 
+	}
+
 	/*
 	 * If for any reason at all we couldn't handle the fault, make
 	 * sure we exit gracefully rather than endlessly redo the
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/mm/hugetlbpage.c linux-3.2.71-pax/arch/ia64/mm/hugetlbpage.c
--- linux-3.2.71/arch/ia64/mm/hugetlbpage.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/mm/hugetlbpage.c	2013-07-05 02:14:44.977195573 +0200
@@ -171,7 +171,7 @@ unsigned long hugetlb_get_unmapped_area(
 		/* At this point:  (!vmm || addr < vmm->vm_end). */
 		if (REGION_OFFSET(addr) + len > RGN_MAP_LIMIT)
 			return -ENOMEM;
-		if (!vmm || (addr + len) <= vmm->vm_start)
+		if (check_heap_stack_gap(vmm, &addr, len))
 			return addr;
 		addr = ALIGN(vmm->vm_end, HPAGE_SIZE);
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/ia64/mm/init.c linux-3.2.71-pax/arch/ia64/mm/init.c
--- linux-3.2.71/arch/ia64/mm/init.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/ia64/mm/init.c	2012-07-04 19:24:47.384063003 +0200
@@ -120,6 +120,19 @@ ia64_init_addr_space (void)
 		vma->vm_start = current->thread.rbs_bot & PAGE_MASK;
 		vma->vm_end = vma->vm_start + PAGE_SIZE;
 		vma->vm_flags = VM_DATA_DEFAULT_FLAGS|VM_GROWSUP|VM_ACCOUNT;
+
+#ifdef CONFIG_PAX_PAGEEXEC
+		if (current->mm->pax_flags & MF_PAX_PAGEEXEC) {
+			vma->vm_flags &= ~VM_EXEC;
+
+#ifdef CONFIG_PAX_MPROTECT
+			if (current->mm->pax_flags & MF_PAX_MPROTECT)
+				vma->vm_flags &= ~VM_MAYEXEC;
+#endif
+
+		}
+#endif
+
 		vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
 		down_write(&current->mm->mmap_sem);
 		if (insert_vm_struct(current->mm, vma)) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/m32r/lib/usercopy.c linux-3.2.71-pax/arch/m32r/lib/usercopy.c
--- linux-3.2.71/arch/m32r/lib/usercopy.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/m32r/lib/usercopy.c	2012-07-04 19:24:47.384063003 +0200
@@ -14,6 +14,9 @@
 unsigned long
 __generic_copy_to_user(void __user *to, const void *from, unsigned long n)
 {
+	if ((long)n < 0)
+		return n;
+
 	prefetch(from);
 	if (access_ok(VERIFY_WRITE, to, n))
 		__copy_user(to,from,n);
@@ -23,6 +26,9 @@ __generic_copy_to_user(void __user *to,
 unsigned long
 __generic_copy_from_user(void *to, const void __user *from, unsigned long n)
 {
+	if ((long)n < 0)
+		return n;
+
 	prefetchw(to);
 	if (access_ok(VERIFY_READ, from, n))
 		__copy_user_zeroing(to,from,n);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/include/asm/atomic.h linux-3.2.71-pax/arch/mips/include/asm/atomic.h
--- linux-3.2.71/arch/mips/include/asm/atomic.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/include/asm/atomic.h	2012-07-04 19:24:47.384063003 +0200
@@ -21,6 +21,10 @@
 #include <asm/war.h>
 #include <asm/system.h>
 
+#ifdef CONFIG_GENERIC_ATOMIC64
+#include <asm-generic/atomic64.h>
+#endif
+
 #define ATOMIC_INIT(i)    { (i) }
 
 /*
@@ -765,6 +769,16 @@ static __inline__ int atomic64_add_unles
  */
 #define atomic64_add_negative(i, v) (atomic64_add_return(i, (v)) < 0)
 
+#define atomic64_read_unchecked(v)		atomic64_read(v)
+#define atomic64_set_unchecked(v, i)		atomic64_set((v), (i))
+#define atomic64_add_unchecked(a, v)		atomic64_add((a), (v))
+#define atomic64_add_return_unchecked(a, v)	atomic64_add_return((a), (v))
+#define atomic64_sub_unchecked(a, v)		atomic64_sub((a), (v))
+#define atomic64_inc_unchecked(v)		atomic64_inc(v)
+#define atomic64_inc_return_unchecked(v)	atomic64_inc_return(v)
+#define atomic64_dec_unchecked(v)		atomic64_dec(v)
+#define atomic64_cmpxchg_unchecked(v, o, n)	atomic64_cmpxchg((v), (o), (n))
+
 #endif /* CONFIG_64BIT */
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/include/asm/elf.h linux-3.2.71-pax/arch/mips/include/asm/elf.h
--- linux-3.2.71/arch/mips/include/asm/elf.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/include/asm/elf.h	2012-07-04 19:24:47.384063003 +0200
@@ -372,13 +372,16 @@ extern const char *__elf_platform;
 #define ELF_ET_DYN_BASE         (TASK_SIZE / 3 * 2)
 #endif
 
+#ifdef CONFIG_PAX_ASLR
+#define PAX_ELF_ET_DYN_BASE	(TASK_IS_32BIT_ADDR ? 0x00400000UL : 0x00400000UL)
+
+#define PAX_DELTA_MMAP_LEN	(TASK_IS_32BIT_ADDR ? 27-PAGE_SHIFT : 36-PAGE_SHIFT)
+#define PAX_DELTA_STACK_LEN	(TASK_IS_32BIT_ADDR ? 27-PAGE_SHIFT : 36-PAGE_SHIFT)
+#endif
+
 #define ARCH_HAS_SETUP_ADDITIONAL_PAGES 1
 struct linux_binprm;
 extern int arch_setup_additional_pages(struct linux_binprm *bprm,
 				       int uses_interp);
 
-struct mm_struct;
-extern unsigned long arch_randomize_brk(struct mm_struct *mm);
-#define arch_randomize_brk arch_randomize_brk
-
 #endif /* _ASM_ELF_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/include/asm/hw_irq.h linux-3.2.71-pax/arch/mips/include/asm/hw_irq.h
--- linux-3.2.71/arch/mips/include/asm/hw_irq.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/include/asm/hw_irq.h	2014-03-14 14:11:22.596407023 +0100
@@ -10,7 +10,7 @@
 
 #include <linux/atomic.h>
 
-extern atomic_t irq_err_count;
+extern atomic_unchecked_t irq_err_count;
 
 /*
  * interrupt-retrigger: NOP for now. This may not be appropriate for all
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/include/asm/local.h linux-3.2.71-pax/arch/mips/include/asm/local.h
--- linux-3.2.71/arch/mips/include/asm/local.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/include/asm/local.h	2014-03-23 21:07:50.736059889 +0100
@@ -12,15 +12,25 @@ typedef struct
 	atomic_long_t a;
 } local_t;
 
+typedef struct {
+	atomic_long_unchecked_t a;
+} local_unchecked_t;
+
 #define LOCAL_INIT(i)	{ ATOMIC_LONG_INIT(i) }
 
 #define local_read(l)	atomic_long_read(&(l)->a)
+#define local_read_unchecked(l)	atomic_long_read_unchecked(&(l)->a)
 #define local_set(l, i)	atomic_long_set(&(l)->a, (i))
+#define local_set_unchecked(l, i)	atomic_long_set_unchecked(&(l)->a, (i))
 
 #define local_add(i, l)	atomic_long_add((i), (&(l)->a))
+#define local_add_unchecked(i, l)	atomic_long_add_unchecked((i), (&(l)->a))
 #define local_sub(i, l)	atomic_long_sub((i), (&(l)->a))
+#define local_sub_unchecked(i, l)	atomic_long_sub_unchecked((i), (&(l)->a))
 #define local_inc(l)	atomic_long_inc(&(l)->a)
+#define local_inc_unchecked(l)	atomic_long_inc_unchecked(&(l)->a)
 #define local_dec(l)	atomic_long_dec(&(l)->a)
+#define local_dec_unchecked(l)	atomic_long_dec_unchecked(&(l)->a)
 
 /*
  * Same as above, but return the result value
@@ -69,6 +79,7 @@ static __inline__ long local_add_return(
 
 	return result;
 }
+#define local_add_return_unchecked(i, l) atomic_long_add_return_unchecked((i), (&(l)->a))
 
 static __inline__ long local_sub_return(long i, local_t * l)
 {
@@ -114,9 +125,12 @@ static __inline__ long local_sub_return(
 
 	return result;
 }
+#define local_sub_return_unchecked(i, l) atomic_long_sub_return_unchecked((i), (&(l)->a))
 
 #define local_cmpxchg(l, o, n) \
 	((long)cmpxchg_local(&((l)->a.counter), (o), (n)))
+#define local_cmpxchg_unchecked(l, o, n) \
+	((long)cmpxchg_local(&((l)->a.counter), (o), (n)))
 #define local_xchg(l, n) (atomic_long_xchg((&(l)->a), (n)))
 
 /**
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/include/asm/page.h linux-3.2.71-pax/arch/mips/include/asm/page.h
--- linux-3.2.71/arch/mips/include/asm/page.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/include/asm/page.h	2012-07-04 19:24:47.388062945 +0200
@@ -93,7 +93,7 @@ extern void copy_user_highpage(struct pa
   #ifdef CONFIG_CPU_MIPS32
     typedef struct { unsigned long pte_low, pte_high; } pte_t;
     #define pte_val(x)    ((x).pte_low | ((unsigned long long)(x).pte_high << 32))
-    #define __pte(x)      ({ pte_t __pte = {(x), ((unsigned long long)(x)) >> 32}; __pte; })
+    #define __pte(x)      ({ pte_t __pte = {(x), (x) >> 32}; __pte; })
   #else
      typedef struct { unsigned long long pte; } pte_t;
      #define pte_val(x)	((x).pte)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/include/asm/pgalloc.h linux-3.2.71-pax/arch/mips/include/asm/pgalloc.h
--- linux-3.2.71/arch/mips/include/asm/pgalloc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/include/asm/pgalloc.h	2012-07-04 19:24:47.388062945 +0200
@@ -37,6 +37,11 @@ static inline void pud_populate(struct m
 {
 	set_pud(pud, __pud((unsigned long)pmd));
 }
+
+static inline void pud_populate_kernel(struct mm_struct *mm, pud_t *pud, pmd_t *pmd)
+{
+	pud_populate(mm, pud, pmd);
+}
 #endif
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/include/asm/pgtable.h linux-3.2.71-pax/arch/mips/include/asm/pgtable.h
--- linux-3.2.71/arch/mips/include/asm/pgtable.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/include/asm/pgtable.h	2014-03-23 21:07:50.736059889 +0100
@@ -18,6 +18,9 @@
 #include <asm/io.h>
 #include <asm/pgtable-bits.h>
 
+#define ktla_ktva(addr)		(addr)
+#define ktva_ktla(addr)		(addr)
+
 struct mm_struct;
 struct vm_area_struct;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/include/asm/system.h linux-3.2.71-pax/arch/mips/include/asm/system.h
--- linux-3.2.71/arch/mips/include/asm/system.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/include/asm/system.h	2012-07-04 19:24:47.388062945 +0200
@@ -230,6 +230,6 @@ extern void per_cpu_trap_init(void);
  */
 #define __ARCH_WANT_UNLOCKED_CTXSW
 
-extern unsigned long arch_align_stack(unsigned long sp);
+#define arch_align_stack(x) ((x) & ~0xfUL)
 
 #endif /* _ASM_SYSTEM_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/include/asm/uaccess.h linux-3.2.71-pax/arch/mips/include/asm/uaccess.h
--- linux-3.2.71/arch/mips/include/asm/uaccess.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/include/asm/uaccess.h	2014-03-23 21:07:50.736059889 +0100
@@ -119,6 +119,7 @@ extern u64 __ua_limit;
 	__ok == 0;							\
 })
 
+#define access_ok_noprefault(type, addr, size) access_ok((type), (addr), (size))
 #define access_ok(type, addr, size)					\
 	likely(__access_ok((addr), (size), __access_mask))
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/kernel/binfmt_elfn32.c linux-3.2.71-pax/arch/mips/kernel/binfmt_elfn32.c
--- linux-3.2.71/arch/mips/kernel/binfmt_elfn32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/kernel/binfmt_elfn32.c	2012-07-04 19:24:47.388062945 +0200
@@ -50,6 +50,13 @@ typedef elf_fpreg_t elf_fpregset_t[ELF_N
 #undef ELF_ET_DYN_BASE
 #define ELF_ET_DYN_BASE         (TASK32_SIZE / 3 * 2)
 
+#ifdef CONFIG_PAX_ASLR
+#define PAX_ELF_ET_DYN_BASE	(TASK_IS_32BIT_ADDR ? 0x00400000UL : 0x00400000UL)
+
+#define PAX_DELTA_MMAP_LEN	(TASK_IS_32BIT_ADDR ? 27-PAGE_SHIFT : 36-PAGE_SHIFT)
+#define PAX_DELTA_STACK_LEN	(TASK_IS_32BIT_ADDR ? 27-PAGE_SHIFT : 36-PAGE_SHIFT)
+#endif
+
 #include <asm/processor.h>
 #include <linux/module.h>
 #include <linux/elfcore.h>
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/kernel/binfmt_elfo32.c linux-3.2.71-pax/arch/mips/kernel/binfmt_elfo32.c
--- linux-3.2.71/arch/mips/kernel/binfmt_elfo32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/kernel/binfmt_elfo32.c	2012-07-04 19:24:47.388062945 +0200
@@ -52,6 +52,13 @@ typedef elf_fpreg_t elf_fpregset_t[ELF_N
 #undef ELF_ET_DYN_BASE
 #define ELF_ET_DYN_BASE         (TASK32_SIZE / 3 * 2)
 
+#ifdef CONFIG_PAX_ASLR
+#define PAX_ELF_ET_DYN_BASE	(TASK_IS_32BIT_ADDR ? 0x00400000UL : 0x00400000UL)
+
+#define PAX_DELTA_MMAP_LEN	(TASK_IS_32BIT_ADDR ? 27-PAGE_SHIFT : 36-PAGE_SHIFT)
+#define PAX_DELTA_STACK_LEN	(TASK_IS_32BIT_ADDR ? 27-PAGE_SHIFT : 36-PAGE_SHIFT)
+#endif
+
 #include <asm/processor.h>
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/kernel/i8259.c linux-3.2.71-pax/arch/mips/kernel/i8259.c
--- linux-3.2.71/arch/mips/kernel/i8259.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/kernel/i8259.c	2014-03-14 14:11:22.596407023 +0100
@@ -205,7 +205,7 @@ spurious_8259A_irq:
 			printk(KERN_DEBUG "spurious 8259A interrupt: IRQ%d.\n", irq);
 			spurious_irq_mask |= irqmask;
 		}
-		atomic_inc(&irq_err_count);
+		atomic_inc_unchecked(&irq_err_count);
 		/*
 		 * Theoretically we do not have to handle this IRQ,
 		 * but in Linux this does not cause problems and is
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/kernel/irq-gt641xx.c linux-3.2.71-pax/arch/mips/kernel/irq-gt641xx.c
--- linux-3.2.71/arch/mips/kernel/irq-gt641xx.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/kernel/irq-gt641xx.c	2014-03-14 14:11:22.596407023 +0100
@@ -110,7 +110,7 @@ void gt641xx_irq_dispatch(void)
 		}
 	}
 
-	atomic_inc(&irq_err_count);
+	atomic_inc_unchecked(&irq_err_count);
 }
 
 void __init gt641xx_irq_init(void)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/kernel/process.c linux-3.2.71-pax/arch/mips/kernel/process.c
--- linux-3.2.71/arch/mips/kernel/process.c	2013-01-03 19:05:12.616036799 +0100
+++ linux-3.2.71-pax/arch/mips/kernel/process.c	2013-01-03 19:05:22.032037076 +0100
@@ -479,15 +479,3 @@ unsigned long get_wchan(struct task_stru
 out:
 	return pc;
 }
-
-/*
- * Don't forget that the stack pointer must be aligned on a 8 bytes
- * boundary for 32-bits ABI and 16 bytes for 64-bits ABI.
- */
-unsigned long arch_align_stack(unsigned long sp)
-{
-	if (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)
-		sp -= get_random_int() & ~PAGE_MASK;
-
-	return sp & ALMASK;
-}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/kernel/reset.c linux-3.2.71-pax/arch/mips/kernel/reset.c
--- linux-3.2.71/arch/mips/kernel/reset.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/kernel/reset.c	2014-03-14 14:11:22.596407023 +0100
@@ -13,6 +13,7 @@
 #include <linux/reboot.h>
 
 #include <asm/reboot.h>
+#include <asm/bug.h>
 
 /*
  * Urgs ...  Too many MIPS machines to handle this in a generic way.
@@ -29,16 +30,19 @@ void machine_restart(char *command)
 {
 	if (_machine_restart)
 		_machine_restart(command);
+	BUG();
 }
 
 void machine_halt(void)
 {
 	if (_machine_halt)
 		_machine_halt();
+	BUG();
 }
 
 void machine_power_off(void)
 {
 	if (pm_power_off)
 		pm_power_off();
+	BUG();
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/mm/fault.c linux-3.2.71-pax/arch/mips/mm/fault.c
--- linux-3.2.71/arch/mips/mm/fault.c	2015-02-20 12:37:32.873178787 +0100
+++ linux-3.2.71-pax/arch/mips/mm/fault.c	2015-02-20 12:37:41.813178310 +0100
@@ -28,6 +28,23 @@
 #include <asm/highmem.h>		/* For VMALLOC_END */
 #include <linux/kdebug.h>
 
+#ifdef CONFIG_PAX_PAGEEXEC
+void pax_report_insns(struct pt_regs *regs, void *pc, void *sp)
+{
+	unsigned long i;
+
+	printk(KERN_ERR "PAX: bytes at PC: ");
+	for (i = 0; i < 5; i++) {
+		unsigned int c;
+		if (get_user(c, (unsigned int *)pc+i))
+			printk(KERN_CONT "???????? ");
+		else
+			printk(KERN_CONT "%08x ", c);
+	}
+	printk("\n");
+}
+#endif
+
 /*
  * This routine handles page faults.  It determines the address,
  * and the problem, and then passes it off to one of the appropriate
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/mm/mmap.c linux-3.2.71-pax/arch/mips/mm/mmap.c
--- linux-3.2.71/arch/mips/mm/mmap.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/mm/mmap.c	2014-03-14 14:12:04.100404807 +0100
@@ -95,6 +95,11 @@ static unsigned long arch_get_unmapped_a
 		do_color_align = 1;
 
 	/* requesting a specific address */
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(current->mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	if (addr) {
 		if (do_color_align)
 			addr = COLOUR_ALIGN(addr, pgoff);
@@ -102,8 +107,7 @@ static unsigned long arch_get_unmapped_a
 			addr = PAGE_ALIGN(addr);
 
 		vma = find_vma(mm, addr);
-		if (TASK_SIZE - len >= addr &&
-		    (!vma || addr + len <= vma->vm_start))
+		if (TASK_SIZE - len >= addr && check_heap_stack_gap(vma, &addr, len))
 			return addr;
 	}
 
@@ -118,7 +122,7 @@ static unsigned long arch_get_unmapped_a
 			/* At this point:  (!vma || addr < vma->vm_end). */
 			if (TASK_SIZE - len < addr)
 				return -ENOMEM;
-			if (!vma || addr + len <= vma->vm_start)
+			if (check_heap_stack_gap(vma, &addr, len))
 				return addr;
 			addr = vma->vm_end;
 			if (do_color_align)
@@ -144,10 +148,11 @@ static unsigned long arch_get_unmapped_a
 
 		/* make sure it can fit in the remaining address space */
 		if (likely(addr > len)) {
-			vma = find_vma(mm, addr - len);
-			if (!vma || addr <= vma->vm_start) {
+			addr -= len;
+			vma = find_vma(mm, addr);
+			if (check_heap_stack_gap(vma, &addr, len))
 				/* cache the address as a hint for next time */
-				return mm->free_area_cache = addr - len;
+				return mm->free_area_cache = addr;
 			}
 		}
 
@@ -155,17 +160,17 @@ static unsigned long arch_get_unmapped_a
 			goto bottomup;
 
 		addr = mm->mmap_base - len;
-		if (do_color_align)
-			addr = COLOUR_ALIGN_DOWN(addr, pgoff);
 
 		do {
+			if (do_color_align)
+				addr = COLOUR_ALIGN_DOWN(addr, pgoff);
 			/*
 			 * Lookup failure means no vma is above this address,
 			 * else if new region fits below vma->vm_start,
 			 * return with success:
 			 */
 			vma = find_vma(mm, addr);
-			if (likely(!vma || addr + len <= vma->vm_start)) {
+			if (check_heap_stack_gap(vma, &addr, len)) {
 				/* cache the address as a hint for next time */
 				return mm->free_area_cache = addr;
 			}
@@ -175,10 +180,8 @@ static unsigned long arch_get_unmapped_a
 				mm->cached_hole_size = vma->vm_start - addr;
 
 			/* try just below the current vma->vm_start */
-			addr = vma->vm_start - len;
-			if (do_color_align)
-				addr = COLOUR_ALIGN_DOWN(addr, pgoff);
-		} while (likely(len < vma->vm_start));
+			addr = skip_heap_stack_gap(vma, len);
+		} while (!IS_ERR_VALUE(addr));
 
 bottomup:
 		/*
@@ -223,6 +226,10 @@ void arch_pick_mmap_layout(struct mm_str
 {
 	unsigned long random_factor = 0UL;
 
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(current->mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	if (current->flags & PF_RANDOMIZE) {
 		random_factor = get_random_int();
 		random_factor = random_factor << PAGE_SHIFT;
@@ -234,38 +241,23 @@ void arch_pick_mmap_layout(struct mm_str
 
 	if (mmap_is_legacy()) {
 		mm->mmap_base = TASK_UNMAPPED_BASE + random_factor;
+
+#ifdef CONFIG_PAX_RANDMMAP
+		if (mm->pax_flags & MF_PAX_RANDMMAP)
+			mm->mmap_base += mm->delta_mmap;
+#endif
+
 		mm->get_unmapped_area = arch_get_unmapped_area;
 		mm->unmap_area = arch_unmap_area;
 	} else {
 		mm->mmap_base = mmap_base(random_factor);
+
+#ifdef CONFIG_PAX_RANDMMAP
+		if (mm->pax_flags & MF_PAX_RANDMMAP)
+			mm->mmap_base -= mm->delta_mmap + mm->delta_stack;
+#endif
+
 		mm->get_unmapped_area = arch_get_unmapped_area_topdown;
 		mm->unmap_area = arch_unmap_area_topdown;
 	}
 }
-
-static inline unsigned long brk_rnd(void)
-{
-	unsigned long rnd = get_random_int();
-
-	rnd = rnd << PAGE_SHIFT;
-	/* 8MB for 32bit, 256MB for 64bit */
-	if (TASK_IS_32BIT_ADDR)
-		rnd = rnd & 0x7ffffful;
-	else
-		rnd = rnd & 0xffffffful;
-
-	return rnd;
-}
-
-unsigned long arch_randomize_brk(struct mm_struct *mm)
-{
-	unsigned long base = mm->brk;
-	unsigned long ret;
-
-	ret = PAGE_ALIGN(base + brk_rnd());
-
-	if (ret < mm->brk)
-		return mm->brk;
-
-	return ret;
-}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/pci/pcie-octeon.c linux-3.2.71-pax/arch/mips/pci/pcie-octeon.c
--- linux-3.2.71/arch/mips/pci/pcie-octeon.c	2015-08-07 11:37:20.331789886 +0200
+++ linux-3.2.71-pax/arch/mips/pci/pcie-octeon.c	2015-08-07 11:37:42.991790553 +0200
@@ -1235,8 +1235,8 @@ static int octeon_pcie1_write_config(str
 }
 
 static struct pci_ops octeon_pcie0_ops = {
-	octeon_pcie0_read_config,
-	octeon_pcie0_write_config,
+	.read = octeon_pcie0_read_config,
+	.write = octeon_pcie0_write_config,
 };
 
 static struct resource octeon_pcie0_mem_resource = {
@@ -1256,8 +1256,8 @@ static struct pci_controller octeon_pcie
 };
 
 static struct pci_ops octeon_pcie1_ops = {
-	octeon_pcie1_read_config,
-	octeon_pcie1_write_config,
+	.read = octeon_pcie1_read_config,
+	.write = octeon_pcie1_write_config,
 };
 
 static struct resource octeon_pcie1_mem_resource = {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/pci/pci-octeon.c linux-3.2.71-pax/arch/mips/pci/pci-octeon.c
--- linux-3.2.71/arch/mips/pci/pci-octeon.c	2015-08-07 11:37:20.331789886 +0200
+++ linux-3.2.71-pax/arch/mips/pci/pci-octeon.c	2015-08-07 11:37:42.987790553 +0200
@@ -329,8 +329,8 @@ static int octeon_write_config(struct pc
 
 
 static struct pci_ops octeon_pci_ops = {
-	octeon_read_config,
-	octeon_write_config,
+	.read = octeon_read_config,
+	.write = octeon_write_config,
 };
 
 static struct resource octeon_pci_mem_resource = {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/sni/rm200.c linux-3.2.71-pax/arch/mips/sni/rm200.c
--- linux-3.2.71/arch/mips/sni/rm200.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/sni/rm200.c	2014-03-14 14:11:22.600407023 +0100
@@ -270,7 +270,7 @@ spurious_8259A_irq:
 			       "spurious RM200 8259A interrupt: IRQ%d.\n", irq);
 			spurious_irq_mask |= irqmask;
 		}
-		atomic_inc(&irq_err_count);
+		atomic_inc_unchecked(&irq_err_count);
 		/*
 		 * Theoretically we do not have to handle this IRQ,
 		 * but in Linux this does not cause problems and is
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/vr41xx/common/icu.c linux-3.2.71-pax/arch/mips/vr41xx/common/icu.c
--- linux-3.2.71/arch/mips/vr41xx/common/icu.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/vr41xx/common/icu.c	2014-03-14 14:11:22.600407023 +0100
@@ -653,7 +653,7 @@ static int icu_get_irq(unsigned int irq)
 
 	printk(KERN_ERR "spurious ICU interrupt: %04x,%04x\n", pend1, pend2);
 
-	atomic_inc(&irq_err_count);
+	atomic_inc_unchecked(&irq_err_count);
 
 	return -1;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/mips/vr41xx/common/irq.c linux-3.2.71-pax/arch/mips/vr41xx/common/irq.c
--- linux-3.2.71/arch/mips/vr41xx/common/irq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/mips/vr41xx/common/irq.c	2014-03-14 14:11:22.600407023 +0100
@@ -65,7 +65,7 @@ static void irq_dispatch(unsigned int ir
 	irq_cascade_t *cascade;
 
 	if (irq >= NR_IRQS) {
-		atomic_inc(&irq_err_count);
+		atomic_inc_unchecked(&irq_err_count);
 		return;
 	}
 
@@ -85,7 +85,7 @@ static void irq_dispatch(unsigned int ir
 		ret = cascade->get_irq(irq);
 		irq = ret;
 		if (ret < 0)
-			atomic_inc(&irq_err_count);
+			atomic_inc_unchecked(&irq_err_count);
 		else
 			irq_dispatch(irq);
 		if (!irqd_irq_disabled(idata) && chip->irq_unmask)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/parisc/include/asm/atomic.h linux-3.2.71-pax/arch/parisc/include/asm/atomic.h
--- linux-3.2.71/arch/parisc/include/asm/atomic.h	2012-09-20 01:42:17.130672773 +0200
+++ linux-3.2.71-pax/arch/parisc/include/asm/atomic.h	2012-09-20 01:42:29.882672813 +0200
@@ -335,6 +335,16 @@ static __inline__ int atomic64_add_unles
 
 #define atomic64_inc_not_zero(v) atomic64_add_unless((v), 1, 0)
 
+#define atomic64_read_unchecked(v)		atomic64_read(v)
+#define atomic64_set_unchecked(v, i)		atomic64_set((v), (i))
+#define atomic64_add_unchecked(a, v)		atomic64_add((a), (v))
+#define atomic64_add_return_unchecked(a, v)	atomic64_add_return((a), (v))
+#define atomic64_sub_unchecked(a, v)		atomic64_sub((a), (v))
+#define atomic64_inc_unchecked(v)		atomic64_inc(v)
+#define atomic64_inc_return_unchecked(v)	atomic64_inc_return(v)
+#define atomic64_dec_unchecked(v)		atomic64_dec(v)
+#define atomic64_cmpxchg_unchecked(v, o, n)	atomic64_cmpxchg((v), (o), (n))
+
 #endif /* !CONFIG_64BIT */
 
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/parisc/include/asm/elf.h linux-3.2.71-pax/arch/parisc/include/asm/elf.h
--- linux-3.2.71/arch/parisc/include/asm/elf.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/parisc/include/asm/elf.h	2012-07-04 19:24:47.392062922 +0200
@@ -342,6 +342,13 @@ struct pt_regs;	/* forward declaration..
 
 #define ELF_ET_DYN_BASE         (TASK_UNMAPPED_BASE + 0x01000000)
 
+#ifdef CONFIG_PAX_ASLR
+#define PAX_ELF_ET_DYN_BASE	0x10000UL
+
+#define PAX_DELTA_MMAP_LEN	16
+#define PAX_DELTA_STACK_LEN	16
+#endif
+
 /* This yields a mask that user programs can use to figure out what
    instruction set this CPU supports.  This could be done in user space,
    but it's not easy, and we've already done it here.  */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/parisc/include/asm/pgalloc.h linux-3.2.71-pax/arch/parisc/include/asm/pgalloc.h
--- linux-3.2.71/arch/parisc/include/asm/pgalloc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/parisc/include/asm/pgalloc.h	2012-07-04 19:24:47.392062922 +0200
@@ -61,6 +61,11 @@ static inline void pgd_populate(struct m
 		        (__u32)(__pa((unsigned long)pmd) >> PxD_VALUE_SHIFT));
 }
 
+static inline void pgd_populate_kernel(struct mm_struct *mm, pgd_t *pgd, pmd_t *pmd)
+{
+	pgd_populate(mm, pgd, pmd);
+}
+
 static inline pmd_t *pmd_alloc_one(struct mm_struct *mm, unsigned long address)
 {
 	pmd_t *pmd = (pmd_t *)__get_free_pages(GFP_KERNEL|__GFP_REPEAT,
@@ -93,6 +98,7 @@ static inline void pmd_free(struct mm_st
 #define pmd_alloc_one(mm, addr)		({ BUG(); ((pmd_t *)2); })
 #define pmd_free(mm, x)			do { } while (0)
 #define pgd_populate(mm, pmd, pte)	BUG()
+#define pgd_populate_kernel(mm, pmd, pte)	BUG()
 
 #endif
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/parisc/include/asm/pgtable.h linux-3.2.71-pax/arch/parisc/include/asm/pgtable.h
--- linux-3.2.71/arch/parisc/include/asm/pgtable.h	2013-03-29 02:18:29.951676751 +0100
+++ linux-3.2.71-pax/arch/parisc/include/asm/pgtable.h	2013-03-29 02:19:01.951675042 +0100
@@ -216,6 +216,17 @@ extern void purge_tlb_entries(struct mm_
 #define PAGE_EXECREAD   __pgprot(_PAGE_PRESENT | _PAGE_USER | _PAGE_READ | _PAGE_EXEC |_PAGE_ACCESSED)
 #define PAGE_COPY       PAGE_EXECREAD
 #define PAGE_RWX        __pgprot(_PAGE_PRESENT | _PAGE_USER | _PAGE_READ | _PAGE_WRITE | _PAGE_EXEC |_PAGE_ACCESSED)
+
+#ifdef CONFIG_PAX_PAGEEXEC
+# define PAGE_SHARED_NOEXEC	__pgprot(_PAGE_PRESENT | _PAGE_USER | _PAGE_READ | _PAGE_WRITE | _PAGE_ACCESSED)
+# define PAGE_COPY_NOEXEC	__pgprot(_PAGE_PRESENT | _PAGE_USER | _PAGE_READ | _PAGE_ACCESSED)
+# define PAGE_READONLY_NOEXEC	__pgprot(_PAGE_PRESENT | _PAGE_USER | _PAGE_READ | _PAGE_ACCESSED)
+#else
+# define PAGE_SHARED_NOEXEC	PAGE_SHARED
+# define PAGE_COPY_NOEXEC	PAGE_COPY
+# define PAGE_READONLY_NOEXEC	PAGE_READONLY
+#endif
+
 #define PAGE_KERNEL	__pgprot(_PAGE_KERNEL)
 #define PAGE_KERNEL_EXEC	__pgprot(_PAGE_KERNEL_EXEC)
 #define PAGE_KERNEL_RWX	__pgprot(_PAGE_KERNEL_RWX)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/parisc/include/asm/uaccess.h linux-3.2.71-pax/arch/parisc/include/asm/uaccess.h
--- linux-3.2.71/arch/parisc/include/asm/uaccess.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/parisc/include/asm/uaccess.h	2012-07-04 19:24:47.392062922 +0200
@@ -253,10 +253,10 @@ static inline unsigned long __must_check
                                           const void __user *from,
                                           unsigned long n)
 {
-        int sz = __compiletime_object_size(to);
+        size_t sz = __compiletime_object_size(to);
         int ret = -EFAULT;
 
-        if (likely(sz == -1 || !__builtin_constant_p(n) || sz >= n))
+        if (likely(sz == (size_t)-1 || !__builtin_constant_p(n) || sz >= n))
                 ret = __copy_from_user(to, from, n);
         else
                 copy_from_user_overflow();
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/parisc/kernel/module.c linux-3.2.71-pax/arch/parisc/kernel/module.c
--- linux-3.2.71/arch/parisc/kernel/module.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/parisc/kernel/module.c	2012-07-04 19:24:47.396062963 +0200
@@ -98,16 +98,38 @@
 
 /* three functions to determine where in the module core
  * or init pieces the location is */
+static inline int in_init_rx(struct module *me, void *loc)
+{
+	return (loc >= me->module_init_rx &&
+		loc < (me->module_init_rx + me->init_size_rx));
+}
+
+static inline int in_init_rw(struct module *me, void *loc)
+{
+	return (loc >= me->module_init_rw &&
+		loc < (me->module_init_rw + me->init_size_rw));
+}
+
 static inline int in_init(struct module *me, void *loc)
 {
-	return (loc >= me->module_init &&
-		loc <= (me->module_init + me->init_size));
+	return in_init_rx(me, loc) || in_init_rw(me, loc);
+}
+
+static inline int in_core_rx(struct module *me, void *loc)
+{
+	return (loc >= me->module_core_rx &&
+		loc < (me->module_core_rx + me->core_size_rx));
+}
+
+static inline int in_core_rw(struct module *me, void *loc)
+{
+	return (loc >= me->module_core_rw &&
+		loc < (me->module_core_rw + me->core_size_rw));
 }
 
 static inline int in_core(struct module *me, void *loc)
 {
-	return (loc >= me->module_core &&
-		loc <= (me->module_core + me->core_size));
+	return in_core_rx(me, loc) || in_core_rw(me, loc);
 }
 
 static inline int in_local(struct module *me, void *loc)
@@ -373,13 +395,13 @@ int module_frob_arch_sections(CONST Elf_
 	}
 
 	/* align things a bit */
-	me->core_size = ALIGN(me->core_size, 16);
-	me->arch.got_offset = me->core_size;
-	me->core_size += gots * sizeof(struct got_entry);
-
-	me->core_size = ALIGN(me->core_size, 16);
-	me->arch.fdesc_offset = me->core_size;
-	me->core_size += fdescs * sizeof(Elf_Fdesc);
+	me->core_size_rw = ALIGN(me->core_size_rw, 16);
+	me->arch.got_offset = me->core_size_rw;
+	me->core_size_rw += gots * sizeof(struct got_entry);
+
+	me->core_size_rw = ALIGN(me->core_size_rw, 16);
+	me->arch.fdesc_offset = me->core_size_rw;
+	me->core_size_rw += fdescs * sizeof(Elf_Fdesc);
 
 	me->arch.got_max = gots;
 	me->arch.fdesc_max = fdescs;
@@ -397,7 +419,7 @@ static Elf64_Word get_got(struct module
 
 	BUG_ON(value == 0);
 
-	got = me->module_core + me->arch.got_offset;
+	got = me->module_core_rw + me->arch.got_offset;
 	for (i = 0; got[i].addr; i++)
 		if (got[i].addr == value)
 			goto out;
@@ -415,7 +437,7 @@ static Elf64_Word get_got(struct module
 #ifdef CONFIG_64BIT
 static Elf_Addr get_fdesc(struct module *me, unsigned long value)
 {
-	Elf_Fdesc *fdesc = me->module_core + me->arch.fdesc_offset;
+	Elf_Fdesc *fdesc = me->module_core_rw + me->arch.fdesc_offset;
 
 	if (!value) {
 		printk(KERN_ERR "%s: zero OPD requested!\n", me->name);
@@ -433,7 +455,7 @@ static Elf_Addr get_fdesc(struct module
 
 	/* Create new one */
 	fdesc->addr = value;
-	fdesc->gp = (Elf_Addr)me->module_core + me->arch.got_offset;
+	fdesc->gp = (Elf_Addr)me->module_core_rw + me->arch.got_offset;
 	return (Elf_Addr)fdesc;
 }
 #endif /* CONFIG_64BIT */
@@ -845,7 +867,7 @@ register_unwind_table(struct module *me,
 
 	table = (unsigned char *)sechdrs[me->arch.unwind_section].sh_addr;
 	end = table + sechdrs[me->arch.unwind_section].sh_size;
-	gp = (Elf_Addr)me->module_core + me->arch.got_offset;
+	gp = (Elf_Addr)me->module_core_rw + me->arch.got_offset;
 
 	DEBUGP("register_unwind_table(), sect = %d at 0x%p - 0x%p (gp=0x%lx)\n",
 	       me->arch.unwind_section, table, end, gp);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/parisc/kernel/sys_parisc.c linux-3.2.71-pax/arch/parisc/kernel/sys_parisc.c
--- linux-3.2.71/arch/parisc/kernel/sys_parisc.c	2012-12-06 19:03:21.331216059 +0100
+++ linux-3.2.71-pax/arch/parisc/kernel/sys_parisc.c	2013-07-05 02:14:19.897196912 +0200
@@ -43,7 +43,7 @@ static unsigned long get_unshared_area(u
 		/* At this point:  (!vma || addr < vma->vm_end). */
 		if (TASK_SIZE - len < addr)
 			return -ENOMEM;
-		if (!vma || addr + len <= vma->vm_start)
+		if (check_heap_stack_gap(vma, &addr, len))
 			return addr;
 		addr = vma->vm_end;
 	}
@@ -81,7 +81,7 @@ static unsigned long get_shared_area(str
 		/* At this point:  (!vma || addr < vma->vm_end). */
 		if (TASK_SIZE - len < addr)
 			return -ENOMEM;
-		if (!vma || addr + len <= vma->vm_start)
+		if (check_heap_stack_gap(vma, &addr, len))
 			return addr;
 		addr = DCACHE_ALIGN(vma->vm_end - offset) + offset;
 		if (addr < vma->vm_end) /* handle wraparound */
@@ -100,7 +100,7 @@ unsigned long arch_get_unmapped_area(str
 	if (flags & MAP_FIXED)
 		return addr;
 	if (!addr)
-		addr = TASK_UNMAPPED_BASE;
+		addr = current->mm->mmap_base;
 
 	if (filp) {
 		addr = get_shared_area(filp->f_mapping, addr, len, pgoff);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/parisc/kernel/traps.c linux-3.2.71-pax/arch/parisc/kernel/traps.c
--- linux-3.2.71/arch/parisc/kernel/traps.c	2013-11-29 01:58:28.526491615 +0100
+++ linux-3.2.71-pax/arch/parisc/kernel/traps.c	2013-11-29 01:58:37.638491883 +0100
@@ -733,9 +733,7 @@ void notrace handle_interruption(int cod
 
 			down_read(&current->mm->mmap_sem);
 			vma = find_vma(current->mm,regs->iaoq[0]);
-			if (vma && (regs->iaoq[0] >= vma->vm_start)
-				&& (vma->vm_flags & VM_EXEC)) {
-
+			if (vma && (regs->iaoq[0] >= vma->vm_start)) {
 				fault_address = regs->iaoq[0];
 				fault_space = regs->iasq[0];
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/parisc/mm/fault.c linux-3.2.71-pax/arch/parisc/mm/fault.c
--- linux-3.2.71/arch/parisc/mm/fault.c	2015-02-20 12:37:32.893178786 +0100
+++ linux-3.2.71-pax/arch/parisc/mm/fault.c	2015-02-20 12:37:41.813178310 +0100
@@ -15,6 +15,7 @@
 #include <linux/sched.h>
 #include <linux/interrupt.h>
 #include <linux/module.h>
+#include <linux/unistd.h>
 
 #include <asm/uaccess.h>
 #include <asm/traps.h>
@@ -52,7 +53,7 @@ DEFINE_PER_CPU(struct exception_data, ex
 static unsigned long
 parisc_acctyp(unsigned long code, unsigned int inst)
 {
-	if (code == 6 || code == 16)
+	if (code == 6 || code == 7 || code == 16)
 	    return VM_EXEC;
 
 	switch (inst & 0xf0000000) {
@@ -138,6 +139,116 @@ parisc_acctyp(unsigned long code, unsign
 			}
 #endif
 
+#ifdef CONFIG_PAX_PAGEEXEC
+/*
+ * PaX: decide what to do with offenders (instruction_pointer(regs) = fault address)
+ *
+ * returns 1 when task should be killed
+ *         2 when rt_sigreturn trampoline was detected
+ *         3 when unpatched PLT trampoline was detected
+ */
+static int pax_handle_fetch_fault(struct pt_regs *regs)
+{
+
+#ifdef CONFIG_PAX_EMUPLT
+	int err;
+
+	do { /* PaX: unpatched PLT emulation */
+		unsigned int bl, depwi;
+
+		err = get_user(bl, (unsigned int *)instruction_pointer(regs));
+		err |= get_user(depwi, (unsigned int *)(instruction_pointer(regs)+4));
+
+		if (err)
+			break;
+
+		if (bl == 0xEA9F1FDDU && depwi == 0xD6801C1EU) {
+			unsigned int ldw, bv, ldw2, addr = instruction_pointer(regs)-12;
+
+			err = get_user(ldw, (unsigned int *)addr);
+			err |= get_user(bv, (unsigned int *)(addr+4));
+			err |= get_user(ldw2, (unsigned int *)(addr+8));
+
+			if (err)
+				break;
+
+			if (ldw == 0x0E801096U &&
+			    bv == 0xEAC0C000U &&
+			    ldw2 == 0x0E881095U)
+			{
+				unsigned int resolver, map;
+
+				err = get_user(resolver, (unsigned int *)(instruction_pointer(regs)+8));
+				err |= get_user(map, (unsigned int *)(instruction_pointer(regs)+12));
+				if (err)
+					break;
+
+				regs->gr[20] = instruction_pointer(regs)+8;
+				regs->gr[21] = map;
+				regs->gr[22] = resolver;
+				regs->iaoq[0] = resolver | 3UL;
+				regs->iaoq[1] = regs->iaoq[0] + 4;
+				return 3;
+			}
+		}
+	} while (0);
+#endif
+
+#ifdef CONFIG_PAX_EMUTRAMP
+
+#ifndef CONFIG_PAX_EMUSIGRT
+	if (!(current->mm->pax_flags & MF_PAX_EMUTRAMP))
+		return 1;
+#endif
+
+	do { /* PaX: rt_sigreturn emulation */
+		unsigned int ldi1, ldi2, bel, nop;
+
+		err = get_user(ldi1, (unsigned int *)instruction_pointer(regs));
+		err |= get_user(ldi2, (unsigned int *)(instruction_pointer(regs)+4));
+		err |= get_user(bel, (unsigned int *)(instruction_pointer(regs)+8));
+		err |= get_user(nop, (unsigned int *)(instruction_pointer(regs)+12));
+
+		if (err)
+			break;
+
+		if ((ldi1 == 0x34190000U || ldi1 == 0x34190002U) &&
+		    ldi2 == 0x3414015AU &&
+		    bel == 0xE4008200U &&
+		    nop == 0x08000240U)
+		{
+			regs->gr[25] = (ldi1 & 2) >> 1;
+			regs->gr[20] = __NR_rt_sigreturn;
+			regs->gr[31] = regs->iaoq[1] + 16;
+			regs->sr[0] = regs->iasq[1];
+			regs->iaoq[0] = 0x100UL;
+			regs->iaoq[1] = regs->iaoq[0] + 4;
+			regs->iasq[0] = regs->sr[2];
+			regs->iasq[1] = regs->sr[2];
+			return 2;
+		}
+	} while (0);
+#endif
+
+	return 1;
+}
+
+void pax_report_insns(struct pt_regs *regs, void *pc, void *sp)
+{
+	unsigned long i;
+
+	printk(KERN_ERR "PAX: bytes at PC: ");
+	for (i = 0; i < 5; i++) {
+		unsigned int c;
+		if (get_user(c, (unsigned int *)pc+i))
+			printk(KERN_CONT "???????? ");
+		else
+			printk(KERN_CONT "%08x ", c);
+	}
+	printk("\n");
+}
+#endif
+
 int fixup_exception(struct pt_regs *regs)
 {
 	const struct exception_table_entry *fix;
@@ -192,8 +303,33 @@ good_area:
 
 	acc_type = parisc_acctyp(code,regs->iir);
 
-	if ((vma->vm_flags & acc_type) != acc_type)
+	if ((vma->vm_flags & acc_type) != acc_type) {
+
+#ifdef CONFIG_PAX_PAGEEXEC
+		if ((mm->pax_flags & MF_PAX_PAGEEXEC) && (acc_type & VM_EXEC) &&
+		    (address & ~3UL) == instruction_pointer(regs))
+		{
+			up_read(&mm->mmap_sem);
+			switch (pax_handle_fetch_fault(regs)) {
+
+#ifdef CONFIG_PAX_EMUPLT
+			case 3:
+				return;
+#endif
+
+#ifdef CONFIG_PAX_EMUTRAMP
+			case 2:
+				return;
+#endif
+
+			}
+			pax_report_fault(regs, (void *)instruction_pointer(regs), (void *)regs->gr[30]);
+			do_group_exit(SIGKILL);
+		}
+#endif
+
 		goto bad_area;
+	}
 
 	/*
 	 * If for any reason at all we couldn't handle the fault, make
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/atomic.h linux-3.2.71-pax/arch/powerpc/include/asm/atomic.h
--- linux-3.2.71/arch/powerpc/include/asm/atomic.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/atomic.h	2012-07-04 19:24:47.396062963 +0200
@@ -469,6 +469,16 @@ static __inline__ int atomic64_add_unles
 
 #define atomic64_inc_not_zero(v) atomic64_add_unless((v), 1, 0)
 
+#define atomic64_read_unchecked(v)		atomic64_read(v)
+#define atomic64_set_unchecked(v, i)		atomic64_set((v), (i))
+#define atomic64_add_unchecked(a, v)		atomic64_add((a), (v))
+#define atomic64_add_return_unchecked(a, v)	atomic64_add_return((a), (v))
+#define atomic64_sub_unchecked(a, v)		atomic64_sub((a), (v))
+#define atomic64_inc_unchecked(v)		atomic64_inc(v)
+#define atomic64_inc_return_unchecked(v)	atomic64_inc_return(v)
+#define atomic64_dec_unchecked(v)		atomic64_dec(v)
+#define atomic64_cmpxchg_unchecked(v, o, n)	atomic64_cmpxchg((v), (o), (n))
+
 #endif /* __powerpc64__ */
 
 #endif /* __KERNEL__ */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/elf.h linux-3.2.71-pax/arch/powerpc/include/asm/elf.h
--- linux-3.2.71/arch/powerpc/include/asm/elf.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/elf.h	2012-07-04 19:24:47.396062963 +0200
@@ -178,8 +178,19 @@ typedef elf_fpreg_t elf_vsrreghalf_t32[E
    the loader.  We need to make sure that it is out of the way of the program
    that it will "exec", and that there is sufficient room for the brk.  */
 
-extern unsigned long randomize_et_dyn(unsigned long base);
-#define ELF_ET_DYN_BASE		(randomize_et_dyn(0x20000000))
+#define ELF_ET_DYN_BASE		(0x20000000)
+
+#ifdef CONFIG_PAX_ASLR
+#define PAX_ELF_ET_DYN_BASE	(0x10000000UL)
+
+#ifdef __powerpc64__
+#define PAX_DELTA_MMAP_LEN	(is_32bit_task() ? 16 : 28)
+#define PAX_DELTA_STACK_LEN	(is_32bit_task() ? 16 : 28)
+#else
+#define PAX_DELTA_MMAP_LEN	15
+#define PAX_DELTA_STACK_LEN	15
+#endif
+#endif
 
 /*
  * Our registers are always unsigned longs, whether we're a 32 bit
@@ -274,9 +285,6 @@ extern int arch_setup_additional_pages(s
 	(0x7ff >> (PAGE_SHIFT - 12)) : \
 	(0x3ffff >> (PAGE_SHIFT - 12)))
 
-extern unsigned long arch_randomize_brk(struct mm_struct *mm);
-#define arch_randomize_brk arch_randomize_brk
-
 #endif /* __KERNEL__ */
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/kmap_types.h linux-3.2.71-pax/arch/powerpc/include/asm/kmap_types.h
--- linux-3.2.71/arch/powerpc/include/asm/kmap_types.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/kmap_types.h	2012-07-04 19:24:47.400063033 +0200
@@ -27,6 +27,7 @@ enum km_type {
 	KM_PPC_SYNC_PAGE,
 	KM_PPC_SYNC_ICACHE,
 	KM_KDB,
+	KM_CLEARPAGE,
 	KM_TYPE_NR
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/local.h linux-3.2.71-pax/arch/powerpc/include/asm/local.h
--- linux-3.2.71/arch/powerpc/include/asm/local.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/local.h	2014-03-23 21:07:50.736059889 +0100
@@ -9,15 +9,26 @@ typedef struct
 	atomic_long_t a;
 } local_t;
 
+typedef struct
+{
+	atomic_long_unchecked_t a;
+} local_unchecked_t;
+
 #define LOCAL_INIT(i)	{ ATOMIC_LONG_INIT(i) }
 
 #define local_read(l)	atomic_long_read(&(l)->a)
+#define local_read_unchecked(l)	atomic_long_read_unchecked(&(l)->a)
 #define local_set(l,i)	atomic_long_set(&(l)->a, (i))
+#define local_set_unchecked(l,i)	atomic_long_set_unchecked(&(l)->a, (i))
 
 #define local_add(i,l)	atomic_long_add((i),(&(l)->a))
+#define local_add_unchecked(i,l)	atomic_long_add_unchecked((i),(&(l)->a))
 #define local_sub(i,l)	atomic_long_sub((i),(&(l)->a))
+#define local_sub_unchecked(i,l)	atomic_long_sub_unchecked((i),(&(l)->a))
 #define local_inc(l)	atomic_long_inc(&(l)->a)
+#define local_inc_unchecked(l)	atomic_long_inc_unchecked(&(l)->a)
 #define local_dec(l)	atomic_long_dec(&(l)->a)
+#define local_dec_unchecked(l)	atomic_long_dec_unchecked(&(l)->a)
 
 static __inline__ long local_add_return(long a, local_t *l)
 {
@@ -35,6 +46,7 @@ static __inline__ long local_add_return(
 
 	return t;
 }
+#define local_add_return_unchecked(i, l) atomic_long_add_return_unchecked((i), (&(l)->a))
 
 #define local_add_negative(a, l)	(local_add_return((a), (l)) < 0)
 
@@ -54,6 +66,7 @@ static __inline__ long local_sub_return(
 
 	return t;
 }
+#define local_sub_return_unchecked(i, l) atomic_long_sub_return_unchecked((i), (&(l)->a))
 
 static __inline__ long local_inc_return(local_t *l)
 {
@@ -101,6 +114,8 @@ static __inline__ long local_dec_return(
 
 #define local_cmpxchg(l, o, n) \
 	(cmpxchg_local(&((l)->a.counter), (o), (n)))
+#define local_cmpxchg_unchecked(l, o, n) \
+	(cmpxchg_local(&((l)->a.counter), (o), (n)))
 #define local_xchg(l, n) (xchg_local(&((l)->a.counter), (n)))
 
 /**
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/mman.h linux-3.2.71-pax/arch/powerpc/include/asm/mman.h
--- linux-3.2.71/arch/powerpc/include/asm/mman.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/mman.h	2012-07-04 19:24:47.400063033 +0200
@@ -44,7 +44,7 @@ static inline unsigned long arch_calc_vm
 }
 #define arch_calc_vm_prot_bits(prot) arch_calc_vm_prot_bits(prot)
 
-static inline pgprot_t arch_vm_get_page_prot(unsigned long vm_flags)
+static inline pgprot_t arch_vm_get_page_prot(vm_flags_t vm_flags)
 {
 	return (vm_flags & VM_SAO) ? __pgprot(_PAGE_SAO) : __pgprot(0);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/page_64.h linux-3.2.71-pax/arch/powerpc/include/asm/page_64.h
--- linux-3.2.71/arch/powerpc/include/asm/page_64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/page_64.h	2012-07-04 19:24:47.400063033 +0200
@@ -144,15 +144,18 @@ do {						\
  * stack by default, so in the absence of a PT_GNU_STACK program header
  * we turn execute permission off.
  */
-#define VM_STACK_DEFAULT_FLAGS32	(VM_READ | VM_WRITE | VM_EXEC | \
-					 VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
+#define VM_STACK_DEFAULT_FLAGS32 \
+	(((current->personality & READ_IMPLIES_EXEC) ? VM_EXEC : 0) | \
+	 VM_READ | VM_WRITE | VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
 
 #define VM_STACK_DEFAULT_FLAGS64	(VM_READ | VM_WRITE | \
 					 VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
 
+#ifndef CONFIG_PAX_PAGEEXEC
 #define VM_STACK_DEFAULT_FLAGS \
 	(is_32bit_task() ? \
 	 VM_STACK_DEFAULT_FLAGS32 : VM_STACK_DEFAULT_FLAGS64)
+#endif
 
 #include <asm-generic/getorder.h>
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/page.h linux-3.2.71-pax/arch/powerpc/include/asm/page.h
--- linux-3.2.71/arch/powerpc/include/asm/page.h	2013-09-10 17:24:55.269739130 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/page.h	2013-09-10 17:24:58.989738931 +0200
@@ -151,8 +151,9 @@ extern phys_addr_t kernstart_addr;
  * and needs to be executable.  This means the whole heap ends
  * up being executable.
  */
-#define VM_DATA_DEFAULT_FLAGS32	(VM_READ | VM_WRITE | VM_EXEC | \
-				 VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
+#define VM_DATA_DEFAULT_FLAGS32 \
+	(((current->personality & READ_IMPLIES_EXEC) ? VM_EXEC : 0) | \
+	 VM_READ | VM_WRITE | VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
 
 #define VM_DATA_DEFAULT_FLAGS64	(VM_READ | VM_WRITE | \
 				 VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
@@ -180,6 +181,9 @@ extern phys_addr_t kernstart_addr;
 #define is_kernel_addr(x)	((x) >= PAGE_OFFSET)
 #endif
 
+#define ktla_ktva(addr)		(addr)
+#define ktva_ktla(addr)		(addr)
+
 /*
  * Use the top bit of the higher-level page table entries to indicate whether
  * the entries we point to contain hugepages.  This works because we know that
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/pgalloc-64.h linux-3.2.71-pax/arch/powerpc/include/asm/pgalloc-64.h
--- linux-3.2.71/arch/powerpc/include/asm/pgalloc-64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/pgalloc-64.h	2012-07-04 19:24:47.400063033 +0200
@@ -50,6 +50,7 @@ static inline void pgd_free(struct mm_st
 #ifndef CONFIG_PPC_64K_PAGES
 
 #define pgd_populate(MM, PGD, PUD)	pgd_set(PGD, PUD)
+#define pgd_populate_kernel(MM, PGD, PUD)	pgd_populate((MM), (PGD), (PUD))
 
 static inline pud_t *pud_alloc_one(struct mm_struct *mm, unsigned long addr)
 {
@@ -67,6 +68,11 @@ static inline void pud_populate(struct m
 	pud_set(pud, (unsigned long)pmd);
 }
 
+static inline void pud_populate_kernel(struct mm_struct *mm, pud_t *pud, pmd_t *pmd)
+{
+	pud_populate(mm, pud, pmd);
+}
+
 #define pmd_populate(mm, pmd, pte_page) \
 	pmd_populate_kernel(mm, pmd, page_address(pte_page))
 #define pmd_populate_kernel(mm, pmd, pte) pmd_set(pmd, (unsigned long)(pte))
@@ -76,6 +82,7 @@ static inline void pud_populate(struct m
 #else /* CONFIG_PPC_64K_PAGES */
 
 #define pud_populate(mm, pud, pmd)	pud_set(pud, (unsigned long)pmd)
+#define pud_populate_kernel(mm, pud, pmd)	pud_populate((mm), (pud), (pmd))
 
 static inline void pmd_populate_kernel(struct mm_struct *mm, pmd_t *pmd,
 				       pte_t *pte)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/pgtable.h linux-3.2.71-pax/arch/powerpc/include/asm/pgtable.h
--- linux-3.2.71/arch/powerpc/include/asm/pgtable.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/pgtable.h	2012-07-04 19:24:47.400063033 +0200
@@ -2,6 +2,7 @@
 #define _ASM_POWERPC_PGTABLE_H
 #ifdef __KERNEL__
 
+#include <linux/const.h>
 #ifndef __ASSEMBLY__
 #include <asm/processor.h>		/* For TASK_SIZE */
 #include <asm/mmu.h>
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/pte-hash32.h linux-3.2.71-pax/arch/powerpc/include/asm/pte-hash32.h
--- linux-3.2.71/arch/powerpc/include/asm/pte-hash32.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/pte-hash32.h	2012-07-04 19:24:47.400063033 +0200
@@ -21,6 +21,7 @@
 #define _PAGE_FILE	0x004	/* when !present: nonlinear file mapping */
 #define _PAGE_USER	0x004	/* usermode access allowed */
 #define _PAGE_GUARDED	0x008	/* G: prohibit speculative access */
+#define _PAGE_EXEC	_PAGE_GUARDED
 #define _PAGE_COHERENT	0x010	/* M: enforce memory coherence (SMP systems) */
 #define _PAGE_NO_CACHE	0x020	/* I: cache inhibit */
 #define _PAGE_WRITETHRU	0x040	/* W: cache write-through */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/reg.h linux-3.2.71-pax/arch/powerpc/include/asm/reg.h
--- linux-3.2.71/arch/powerpc/include/asm/reg.h	2012-08-03 01:53:46.966140458 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/reg.h	2012-08-03 01:53:52.642140152 +0200
@@ -212,6 +212,7 @@
 #define SPRN_DBCR	0x136	/* e300 Data Breakpoint Control Reg */
 #define SPRN_DSISR	0x012	/* Data Storage Interrupt Status Register */
 #define   DSISR_NOHPTE		0x40000000	/* no translation found */
+#define   DSISR_GUARDED		0x10000000	/* fetch from guarded storage */
 #define   DSISR_PROTFAULT	0x08000000	/* protection fault */
 #define   DSISR_ISSTORE		0x02000000	/* access was a store */
 #define   DSISR_DABRMATCH	0x00400000	/* hit data breakpoint */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/smp.h linux-3.2.71-pax/arch/powerpc/include/asm/smp.h
--- linux-3.2.71/arch/powerpc/include/asm/smp.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/smp.h	2013-04-30 00:30:43.679760713 +0200
@@ -50,7 +50,7 @@ struct smp_ops_t {
 	int   (*cpu_disable)(void);
 	void  (*cpu_die)(unsigned int nr);
 	int   (*cpu_bootable)(unsigned int nr);
-};
+} __no_const;
 
 extern void smp_send_debugger_break(void);
 extern void start_secondary_resume(void);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/system.h linux-3.2.71-pax/arch/powerpc/include/asm/system.h
--- linux-3.2.71/arch/powerpc/include/asm/system.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/system.h	2012-07-04 19:24:47.404063053 +0200
@@ -530,7 +530,7 @@ __cmpxchg_local(volatile void *ptr, unsi
 #define cmpxchg64_local(ptr, o, n) __cmpxchg64_local_generic((ptr), (o), (n))
 #endif
 
-extern unsigned long arch_align_stack(unsigned long sp);
+#define arch_align_stack(x) ((x) & ~0xfUL)
 
 /* Used in very early kernel initialization. */
 extern unsigned long reloc_offset(void);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/include/asm/uaccess.h linux-3.2.71-pax/arch/powerpc/include/asm/uaccess.h
--- linux-3.2.71/arch/powerpc/include/asm/uaccess.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/include/asm/uaccess.h	2014-03-23 21:07:50.740059889 +0100
@@ -56,6 +56,7 @@
 
 #endif
 
+#define access_ok_noprefault(type, addr, size) access_ok((type), (addr), (size))
 #define access_ok(type, addr, size)		\
 	(__chk_user_ptr(addr),			\
 	 __access_ok((__force unsigned long)(addr), (size), get_fs()))
@@ -327,52 +328,6 @@ do {								\
 extern unsigned long __copy_tofrom_user(void __user *to,
 		const void __user *from, unsigned long size);
 
-#ifndef __powerpc64__
-
-static inline unsigned long copy_from_user(void *to,
-		const void __user *from, unsigned long n)
-{
-	unsigned long over;
-
-	if (access_ok(VERIFY_READ, from, n))
-		return __copy_tofrom_user((__force void __user *)to, from, n);
-	if ((unsigned long)from < TASK_SIZE) {
-		over = (unsigned long)from + n - TASK_SIZE;
-		return __copy_tofrom_user((__force void __user *)to, from,
-				n - over) + over;
-	}
-	return n;
-}
-
-static inline unsigned long copy_to_user(void __user *to,
-		const void *from, unsigned long n)
-{
-	unsigned long over;
-
-	if (access_ok(VERIFY_WRITE, to, n))
-		return __copy_tofrom_user(to, (__force void __user *)from, n);
-	if ((unsigned long)to < TASK_SIZE) {
-		over = (unsigned long)to + n - TASK_SIZE;
-		return __copy_tofrom_user(to, (__force void __user *)from,
-				n - over) + over;
-	}
-	return n;
-}
-
-#else /* __powerpc64__ */
-
-#define __copy_in_user(to, from, size) \
-	__copy_tofrom_user((to), (from), (size))
-
-extern unsigned long copy_from_user(void *to, const void __user *from,
-				    unsigned long n);
-extern unsigned long copy_to_user(void __user *to, const void *from,
-				  unsigned long n);
-extern unsigned long copy_in_user(void __user *to, const void __user *from,
-				  unsigned long n);
-
-#endif /* __powerpc64__ */
-
 static inline unsigned long __copy_from_user_inatomic(void *to,
 		const void __user *from, unsigned long n)
 {
@@ -396,6 +351,10 @@ static inline unsigned long __copy_from_
 		if (ret == 0)
 			return 0;
 	}
+
+	if (!__builtin_constant_p(n))
+		check_object_size(to, n, false);
+
 	return __copy_tofrom_user((__force void __user *)to, from, n);
 }
 
@@ -422,6 +381,10 @@ static inline unsigned long __copy_to_us
 		if (ret == 0)
 			return 0;
 	}
+
+	if (!__builtin_constant_p(n))
+		check_object_size(from, n, true);
+
 	return __copy_tofrom_user(to, (__force const void __user *)from, n);
 }
 
@@ -439,6 +402,92 @@ static inline unsigned long __copy_to_us
 	return __copy_to_user_inatomic(to, from, size);
 }
 
+#ifndef __powerpc64__
+
+static inline unsigned long __must_check copy_from_user(void *to,
+		const void __user *from, unsigned long n)
+{
+	unsigned long over;
+
+	if ((long)n < 0)
+		return n;
+
+	if (access_ok(VERIFY_READ, from, n)) {
+		if (!__builtin_constant_p(n))
+			check_object_size(to, n, false);
+		return __copy_tofrom_user((__force void __user *)to, from, n);
+	}
+	if ((unsigned long)from < TASK_SIZE) {
+		over = (unsigned long)from + n - TASK_SIZE;
+		if (!__builtin_constant_p(n - over))
+			check_object_size(to, n - over, false);
+		return __copy_tofrom_user((__force void __user *)to, from,
+				n - over) + over;
+	}
+	return n;
+}
+
+static inline unsigned long __must_check copy_to_user(void __user *to,
+		const void *from, unsigned long n)
+{
+	unsigned long over;
+
+	if ((long)n < 0)
+		return n;
+
+	if (access_ok(VERIFY_WRITE, to, n)) {
+		if (!__builtin_constant_p(n))
+			check_object_size(from, n, true);
+		return __copy_tofrom_user(to, (__force void __user *)from, n);
+	}
+	if ((unsigned long)to < TASK_SIZE) {
+		over = (unsigned long)to + n - TASK_SIZE;
+		if (!__builtin_constant_p(n))
+			check_object_size(from, n - over, true);
+		return __copy_tofrom_user(to, (__force void __user *)from,
+				n - over) + over;
+	}
+	return n;
+}
+
+#else /* __powerpc64__ */
+
+#define __copy_in_user(to, from, size) \
+	__copy_tofrom_user((to), (from), (size))
+
+static inline unsigned long __must_check copy_from_user(void *to, const void __user *from, unsigned long n)
+{
+	if ((long)n < 0 || n > INT_MAX)
+		return n;
+
+	if (!__builtin_constant_p(n))
+		check_object_size(to, n, false);
+
+	if (likely(access_ok(VERIFY_READ, from, n)))
+		n = __copy_from_user(to, from, n);
+	else
+		memset(to, 0, n);
+	return n;
+}
+
+static inline unsigned long __must_check copy_to_user(void __user *to, const void *from, unsigned long n)
+{
+	if ((long)n < 0 || n > INT_MAX)
+		return n;
+
+	if (likely(access_ok(VERIFY_WRITE, to, n))) {
+		if (!__builtin_constant_p(n))
+			check_object_size(from, n, true);
+		n = __copy_to_user(to, from, n);
+	}
+	return n;
+}
+
+extern unsigned long copy_in_user(void __user *to, const void __user *from,
+				  unsigned long n);
+
+#endif /* __powerpc64__ */
+
 extern unsigned long __clear_user(void __user *addr, unsigned long size);
 
 static inline unsigned long clear_user(void __user *addr, unsigned long size)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/kernel/exceptions-64e.S linux-3.2.71-pax/arch/powerpc/kernel/exceptions-64e.S
--- linux-3.2.71/arch/powerpc/kernel/exceptions-64e.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/kernel/exceptions-64e.S	2012-07-04 19:24:47.404063053 +0200
@@ -587,6 +587,7 @@ storage_fault_common:
 	std	r14,_DAR(r1)
 	std	r15,_DSISR(r1)
 	addi	r3,r1,STACK_FRAME_OVERHEAD
+	bl	.save_nvgprs
 	mr	r4,r14
 	mr	r5,r15
 	ld	r14,PACA_EXGEN+EX_R14(r13)
@@ -596,8 +597,7 @@ storage_fault_common:
 	cmpdi	r3,0
 	bne-	1f
 	b	.ret_from_except_lite
-1:	bl	.save_nvgprs
-	mr	r5,r3
+1:	mr	r5,r3
 	addi	r3,r1,STACK_FRAME_OVERHEAD
 	ld	r4,_DAR(r1)
 	bl	.bad_page_fault
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/kernel/exceptions-64s.S linux-3.2.71-pax/arch/powerpc/kernel/exceptions-64s.S
--- linux-3.2.71/arch/powerpc/kernel/exceptions-64s.S	2013-06-21 21:22:07.574352284 +0200
+++ linux-3.2.71-pax/arch/powerpc/kernel/exceptions-64s.S	2013-06-21 21:21:57.278352834 +0200
@@ -1004,10 +1004,10 @@ handle_page_fault:
 11:	ld	r4,_DAR(r1)
 	ld	r5,_DSISR(r1)
 	addi	r3,r1,STACK_FRAME_OVERHEAD
+	bl	.save_nvgprs
 	bl	.do_page_fault
 	cmpdi	r3,0
 	beq+	13f
-	bl	.save_nvgprs
 	mr	r5,r3
 	addi	r3,r1,STACK_FRAME_OVERHEAD
 	lwz	r4,_DAR(r1)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/kernel/irq.c linux-3.2.71-pax/arch/powerpc/kernel/irq.c
--- linux-3.2.71/arch/powerpc/kernel/irq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/kernel/irq.c	2012-07-04 19:24:47.408063045 +0200
@@ -547,9 +547,6 @@ struct irq_host *irq_alloc_host(struct d
 	host->ops = ops;
 	host->of_node = of_node_get(of_node);
 
-	if (host->ops->match == NULL)
-		host->ops->match = default_irq_host_match;
-
 	raw_spin_lock_irqsave(&irq_big_lock, flags);
 
 	/* If it's a legacy controller, check for duplicates and
@@ -622,7 +619,12 @@ struct irq_host *irq_find_host(struct de
 	 */
 	raw_spin_lock_irqsave(&irq_big_lock, flags);
 	list_for_each_entry(h, &irq_hosts, link)
-		if (h->ops->match(h, node)) {
+		if (h->ops->match) {
+			if (h->ops->match(h, node)) {
+				found = h;
+				break;
+			}
+		} else if (default_irq_host_match(h, node)) {
 			found = h;
 			break;
 		}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/kernel/Makefile linux-3.2.71-pax/arch/powerpc/kernel/Makefile
--- linux-3.2.71/arch/powerpc/kernel/Makefile	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/kernel/Makefile	2015-03-11 16:19:01.563127726 +0100
@@ -14,6 +14,11 @@ CFLAGS_prom_init.o      += -fPIC
 CFLAGS_btext.o		+= -fPIC
 endif
 
+CFLAGS_REMOVE_cputable.o = $(LATENT_ENTROPY_PLUGIN_CFLAGS)
+CFLAGS_REMOVE_prom_init.o = $(LATENT_ENTROPY_PLUGIN_CFLAGS)
+CFLAGS_REMOVE_btext.o = $(LATENT_ENTROPY_PLUGIN_CFLAGS)
+CFLAGS_REMOVE_prom.o = $(LATENT_ENTROPY_PLUGIN_CFLAGS)
+
 ifdef CONFIG_FUNCTION_TRACER
 # Do not trace early boot code
 CFLAGS_REMOVE_cputable.o = -pg -mno-sched-epilog
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/kernel/module_32.c linux-3.2.71-pax/arch/powerpc/kernel/module_32.c
--- linux-3.2.71/arch/powerpc/kernel/module_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/kernel/module_32.c	2014-01-16 02:55:45.870178862 +0100
@@ -162,7 +162,7 @@ int module_frob_arch_sections(Elf32_Ehdr
 			me->arch.core_plt_section = i;
 	}
 	if (!me->arch.core_plt_section || !me->arch.init_plt_section) {
-		printk("Module doesn't contain .plt or .init.plt sections.\n");
+		printk("Module %s doesn't contain .plt or .init.plt sections.\n", me->name);
 		return -ENOEXEC;
 	}
 
@@ -192,11 +192,16 @@ static uint32_t do_plt_call(void *locati
 
 	DEBUGP("Doing plt for call to 0x%x at 0x%x\n", val, (unsigned int)location);
 	/* Init, or core PLT? */
-	if (location >= mod->module_core
-	    && location < mod->module_core + mod->core_size)
+	if ((location >= mod->module_core_rx && location < mod->module_core_rx + mod->core_size_rx) ||
+	    (location >= mod->module_core_rw && location < mod->module_core_rw + mod->core_size_rw))
 		entry = (void *)sechdrs[mod->arch.core_plt_section].sh_addr;
-	else
+	else if ((location >= mod->module_init_rx && location < mod->module_init_rx + mod->init_size_rx) ||
+		 (location >= mod->module_init_rw && location < mod->module_init_rw + mod->init_size_rw))
 		entry = (void *)sechdrs[mod->arch.init_plt_section].sh_addr;
+	else {
+		printk(KERN_ERR "%s: invalid R_PPC_REL24 entry found\n", mod->name);
+		return ~0UL;
+	}
 
 	/* Find this entry, or if that fails, the next avail. entry */
 	while (entry->jump[0]) {
@@ -300,7 +305,7 @@ int apply_relocate_add(Elf32_Shdr *sechd
 	}
 #ifdef CONFIG_DYNAMIC_FTRACE
 	module->arch.tramp =
-		do_plt_call(module->module_core,
+		do_plt_call(module->module_core_rx,
 			    (unsigned long)ftrace_caller,
 			    sechdrs, module);
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/kernel/process.c linux-3.2.71-pax/arch/powerpc/kernel/process.c
--- linux-3.2.71/arch/powerpc/kernel/process.c	2012-09-20 01:42:17.146672774 +0200
+++ linux-3.2.71-pax/arch/powerpc/kernel/process.c	2015-03-11 16:18:23.455127606 +0100
@@ -1250,63 +1250,8 @@ void free_thread_info(struct thread_info
 void thread_info_cache_init(void)
 {
 	thread_info_cache = kmem_cache_create("thread_info", THREAD_SIZE,
-					      THREAD_SIZE, 0, NULL);
+					      THREAD_SIZE, SLAB_USERCOPY, NULL);
 	BUG_ON(thread_info_cache == NULL);
 }
 
 #endif /* THREAD_SHIFT < PAGE_SHIFT */
-
-unsigned long arch_align_stack(unsigned long sp)
-{
-	if (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)
-		sp -= get_random_int() & ~PAGE_MASK;
-	return sp & ~0xf;
-}
-
-static inline unsigned long brk_rnd(void)
-{
-        unsigned long rnd = 0;
-
-	/* 8MB for 32bit, 1GB for 64bit */
-	if (is_32bit_task())
-		rnd = (long)(get_random_int() % (1<<(23-PAGE_SHIFT)));
-	else
-		rnd = (long)(get_random_int() % (1<<(30-PAGE_SHIFT)));
-
-	return rnd << PAGE_SHIFT;
-}
-
-unsigned long arch_randomize_brk(struct mm_struct *mm)
-{
-	unsigned long base = mm->brk;
-	unsigned long ret;
-
-#ifdef CONFIG_PPC_STD_MMU_64
-	/*
-	 * If we are using 1TB segments and we are allowed to randomise
-	 * the heap, we can put it above 1TB so it is backed by a 1TB
-	 * segment. Otherwise the heap will be in the bottom 1TB
-	 * which always uses 256MB segments and this may result in a
-	 * performance penalty.
-	 */
-	if (!is_32bit_task() && (mmu_highuser_ssize == MMU_SEGSIZE_1T))
-		base = max_t(unsigned long, mm->brk, 1UL << SID_SHIFT_1T);
-#endif
-
-	ret = PAGE_ALIGN(base + brk_rnd());
-
-	if (ret < mm->brk)
-		return mm->brk;
-
-	return ret;
-}
-
-unsigned long randomize_et_dyn(unsigned long base)
-{
-	unsigned long ret = PAGE_ALIGN(base + brk_rnd());
-
-	if (ret < base)
-		return base;
-
-	return ret;
-}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/kernel/signal_32.c linux-3.2.71-pax/arch/powerpc/kernel/signal_32.c
--- linux-3.2.71/arch/powerpc/kernel/signal_32.c	2014-01-03 15:48:44.608070585 +0100
+++ linux-3.2.71-pax/arch/powerpc/kernel/signal_32.c	2014-01-03 15:48:49.480070325 +0100
@@ -865,7 +865,7 @@ int handle_rt_signal32(unsigned long sig
 	/* Save user registers on the stack */
 	frame = &rt_sf->uc.uc_mcontext;
 	addr = frame;
-	if (vdso32_rt_sigtramp && current->mm->context.vdso_base) {
+	if (vdso32_rt_sigtramp && current->mm->context.vdso_base != ~0UL) {
 		if (save_user_regs(regs, frame, 0, 1))
 			goto badframe;
 		regs->link = current->mm->context.vdso_base + vdso32_rt_sigtramp;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/kernel/signal_64.c linux-3.2.71-pax/arch/powerpc/kernel/signal_64.c
--- linux-3.2.71/arch/powerpc/kernel/signal_64.c	2014-01-03 15:48:44.608070585 +0100
+++ linux-3.2.71-pax/arch/powerpc/kernel/signal_64.c	2014-01-03 15:48:49.484070325 +0100
@@ -435,7 +435,7 @@ int handle_rt_signal64(int signr, struct
 	current->thread.fpscr.val = 0;
 
 	/* Set up to return from userspace. */
-	if (vdso64_rt_sigtramp && current->mm->context.vdso_base) {
+	if (vdso64_rt_sigtramp && current->mm->context.vdso_base != ~0UL) {
 		regs->link = current->mm->context.vdso_base + vdso64_rt_sigtramp;
 	} else {
 		err |= setup_trampoline(__NR_rt_sigreturn, &frame->tramp[0]);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/kernel/sysfs.c linux-3.2.71-pax/arch/powerpc/kernel/sysfs.c
--- linux-3.2.71/arch/powerpc/kernel/sysfs.c	2013-10-27 17:59:56.360642432 +0100
+++ linux-3.2.71-pax/arch/powerpc/kernel/sysfs.c	2013-10-27 18:00:09.424641735 +0100
@@ -531,7 +531,7 @@ static int __cpuinit sysfs_cpu_notify(st
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata sysfs_cpu_nb = {
+static struct notifier_block sysfs_cpu_nb = {
 	.notifier_call	= sysfs_cpu_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/kernel/vdso.c linux-3.2.71-pax/arch/powerpc/kernel/vdso.c
--- linux-3.2.71/arch/powerpc/kernel/vdso.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/kernel/vdso.c	2012-07-04 19:24:47.412063027 +0200
@@ -35,6 +35,7 @@
 #include <asm/firmware.h>
 #include <asm/vdso.h>
 #include <asm/vdso_datapage.h>
+#include <asm/mman.h>
 
 #include "setup.h"
 
@@ -219,7 +220,7 @@ int arch_setup_additional_pages(struct l
 	vdso_base = VDSO32_MBASE;
 #endif
 
-	current->mm->context.vdso_base = 0;
+	current->mm->context.vdso_base = ~0UL;
 
 	/* vDSO has a problem and was disabled, just don't "enable" it for the
 	 * process
@@ -239,7 +240,7 @@ int arch_setup_additional_pages(struct l
 	vdso_base = get_unmapped_area(NULL, vdso_base,
 				      (vdso_pages << PAGE_SHIFT) +
 				      ((VDSO_ALIGNMENT - 1) & PAGE_MASK),
-				      0, 0);
+				      0, MAP_PRIVATE | MAP_EXECUTABLE);
 	if (IS_ERR_VALUE(vdso_base)) {
 		rc = vdso_base;
 		goto fail_mmapsem;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/kvm/powerpc.c linux-3.2.71-pax/arch/powerpc/kvm/powerpc.c
--- linux-3.2.71/arch/powerpc/kvm/powerpc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/kvm/powerpc.c	2014-03-23 21:07:50.740059889 +0100
@@ -730,7 +730,7 @@ out:
 	return r;
 }
 
-int kvm_arch_init(void *opaque)
+int kvm_arch_init(const void *opaque)
 {
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/lib/usercopy_64.c linux-3.2.71-pax/arch/powerpc/lib/usercopy_64.c
--- linux-3.2.71/arch/powerpc/lib/usercopy_64.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/lib/usercopy_64.c	2012-07-04 19:24:47.412063027 +0200
@@ -9,22 +9,6 @@
 #include <linux/module.h>
 #include <asm/uaccess.h>
 
-unsigned long copy_from_user(void *to, const void __user *from, unsigned long n)
-{
-	if (likely(access_ok(VERIFY_READ, from, n)))
-		n = __copy_from_user(to, from, n);
-	else
-		memset(to, 0, n);
-	return n;
-}
-
-unsigned long copy_to_user(void __user *to, const void *from, unsigned long n)
-{
-	if (likely(access_ok(VERIFY_WRITE, to, n)))
-		n = __copy_to_user(to, from, n);
-	return n;
-}
-
 unsigned long copy_in_user(void __user *to, const void __user *from,
 			   unsigned long n)
 {
@@ -35,7 +19,5 @@ unsigned long copy_in_user(void __user *
 	return n;
 }
 
-EXPORT_SYMBOL(copy_from_user);
-EXPORT_SYMBOL(copy_to_user);
 EXPORT_SYMBOL(copy_in_user);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/mm/fault.c linux-3.2.71-pax/arch/powerpc/mm/fault.c
--- linux-3.2.71/arch/powerpc/mm/fault.c	2015-02-20 12:37:32.897178786 +0100
+++ linux-3.2.71-pax/arch/powerpc/mm/fault.c	2015-02-20 12:37:41.813178310 +0100
@@ -32,6 +32,10 @@
 #include <linux/perf_event.h>
 #include <linux/magic.h>
 #include <linux/ratelimit.h>
+#include <linux/slab.h>
+#include <linux/pagemap.h>
+#include <linux/compiler.h>
+#include <linux/unistd.h>
 
 #include <asm/firmware.h>
 #include <asm/page.h>
@@ -43,6 +47,7 @@
 #include <asm/tlbflush.h>
 #include <asm/siginfo.h>
 #include <mm/mmu_decl.h>
+#include <asm/ptrace.h>
 
 #ifdef CONFIG_KPROBES
 static inline int notify_page_fault(struct pt_regs *regs)
@@ -66,6 +71,33 @@ static inline int notify_page_fault(stru
 }
 #endif
 
+#ifdef CONFIG_PAX_PAGEEXEC
+/*
+ * PaX: decide what to do with offenders (regs->nip = fault address)
+ *
+ * returns 1 when task should be killed
+ */
+static int pax_handle_fetch_fault(struct pt_regs *regs)
+{
+	return 1;
+}
+
+void pax_report_insns(struct pt_regs *regs, void *pc, void *sp)
+{
+	unsigned long i;
+
+	printk(KERN_ERR "PAX: bytes at PC: ");
+	for (i = 0; i < 5; i++) {
+		unsigned int c;
+		if (get_user(c, (unsigned int __user *)pc+i))
+			printk(KERN_CONT "???????? ");
+		else
+			printk(KERN_CONT "%08x ", c);
+	}
+	printk("\n");
+}
+#endif
+
 /*
  * Check whether the instruction at regs->nip is a store using
  * an update addressing form which will update r1.
@@ -136,7 +168,7 @@ int __kprobes do_page_fault(struct pt_re
 	 * indicate errors in DSISR but can validly be set in SRR1.
 	 */
 	if (trap == 0x400)
-		error_code &= 0x48200000;
+		error_code &= 0x58200000;
 	else
 		is_write = error_code & DSISR_ISSTORE;
 #else
@@ -259,7 +291,7 @@ good_area:
          * "undefined".  Of those that can be set, this is the only
          * one which seems bad.
          */
-	if (error_code & 0x10000000)
+	if (error_code & DSISR_GUARDED)
                 /* Guarded storage error. */
 		goto bad_area;
 #endif /* CONFIG_8xx */
@@ -274,7 +306,7 @@ good_area:
 		 * processors use the same I/D cache coherency mechanism
 		 * as embedded.
 		 */
-		if (error_code & DSISR_PROTFAULT)
+		if (error_code & (DSISR_PROTFAULT | DSISR_GUARDED))
 			goto bad_area;
 #endif /* CONFIG_PPC_STD_MMU */
 
@@ -345,6 +377,23 @@ bad_area:
 bad_area_nosemaphore:
 	/* User mode accesses cause a SIGSEGV */
 	if (user_mode(regs)) {
+
+#ifdef CONFIG_PAX_PAGEEXEC
+		if (mm->pax_flags & MF_PAX_PAGEEXEC) {
+#ifdef CONFIG_PPC_STD_MMU
+			if (is_exec && (error_code & (DSISR_PROTFAULT | DSISR_GUARDED))) {
+#else
+			if (is_exec && regs->nip == address) {
+#endif
+				switch (pax_handle_fetch_fault(regs)) {
+				}
+
+				pax_report_fault(regs, (void *)regs->nip, (void *)regs->gpr[PT_R1]);
+				do_group_exit(SIGKILL);
+			}
+		}
+#endif
+
 		_exception(SIGSEGV, regs, code, address);
 		return 0;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/mm/mmap_64.c linux-3.2.71-pax/arch/powerpc/mm/mmap_64.c
--- linux-3.2.71/arch/powerpc/mm/mmap_64.c	2015-08-07 11:37:20.351789887 +0200
+++ linux-3.2.71-pax/arch/powerpc/mm/mmap_64.c	2015-08-07 11:41:46.271797706 +0200
@@ -53,10 +53,14 @@ static inline int mmap_is_legacy(void)
 	return sysctl_legacy_va_layout;
 }
 
-static unsigned long mmap_rnd(void)
+static unsigned long mmap_rnd(struct mm_struct *mm)
 {
 	unsigned long rnd = 0;
 
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	if (current->flags & PF_RANDOMIZE) {
 		/* 8MB for 32bit, 1GB for 64bit */
 		if (is_32bit_task())
@@ -67,7 +71,7 @@ static unsigned long mmap_rnd(void)
 	return rnd << PAGE_SHIFT;
 }
 
-static inline unsigned long mmap_base(void)
+static inline unsigned long mmap_base(struct mm_struct *mm)
 {
 	unsigned long gap = rlimit(RLIMIT_STACK);
 
@@ -76,7 +80,7 @@ static inline unsigned long mmap_base(vo
 	else if (gap > MAX_GAP)
 		gap = MAX_GAP;
 
-	return PAGE_ALIGN(TASK_SIZE - gap - mmap_rnd());
+	return PAGE_ALIGN(TASK_SIZE - gap - mmap_rnd(mm));
 }
 
 /*
@@ -91,10 +95,22 @@ void arch_pick_mmap_layout(struct mm_str
 	 */
 	if (mmap_is_legacy()) {
 		mm->mmap_base = TASK_UNMAPPED_BASE;
+
+#ifdef CONFIG_PAX_RANDMMAP
+		if (mm->pax_flags & MF_PAX_RANDMMAP)
+			mm->mmap_base += mm->delta_mmap;
+#endif
+
 		mm->get_unmapped_area = arch_get_unmapped_area;
 		mm->unmap_area = arch_unmap_area;
 	} else {
-		mm->mmap_base = mmap_base();
+		mm->mmap_base = mmap_base(mm);
+
+#ifdef CONFIG_PAX_RANDMMAP
+		if (mm->pax_flags & MF_PAX_RANDMMAP)
+			mm->mmap_base -= mm->delta_mmap + mm->delta_stack;
+#endif
+
 		mm->get_unmapped_area = arch_get_unmapped_area_topdown;
 		mm->unmap_area = arch_unmap_area_topdown;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/mm/mmu_context_nohash.c linux-3.2.71-pax/arch/powerpc/mm/mmu_context_nohash.c
--- linux-3.2.71/arch/powerpc/mm/mmu_context_nohash.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/mm/mmu_context_nohash.c	2013-02-20 01:19:14.954027372 +0100
@@ -370,7 +370,7 @@ static int __cpuinit mmu_context_cpu_not
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata mmu_context_cpu_nb = {
+static struct notifier_block mmu_context_cpu_nb = {
 	.notifier_call	= mmu_context_cpu_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/mm/numa.c linux-3.2.71-pax/arch/powerpc/mm/numa.c
--- linux-3.2.71/arch/powerpc/mm/numa.c	2014-09-14 14:10:57.826117052 +0200
+++ linux-3.2.71-pax/arch/powerpc/mm/numa.c	2014-09-14 14:11:25.826138252 +0200
@@ -659,7 +659,7 @@ static void __init parse_drconf_memory(s
 	unsigned int n, rc, ranges, is_kexec_kdump = 0;
 	unsigned long lmb_size, base, size, sz;
 	int nid;
-	struct assoc_arrays aa;
+	struct assoc_arrays aa = { .arrays = NULL };
 
 	n = of_get_drconf_memory(memory, &dm);
 	if (!n)
@@ -964,7 +964,7 @@ static void __init *careful_zallocation(
 	return ret;
 }
 
-static struct notifier_block __cpuinitdata ppc64_numa_nb = {
+static struct notifier_block ppc64_numa_nb = {
 	.notifier_call = cpu_numa_callback,
 	.priority = 1 /* Must run before sched domains notifier. */
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/mm/slice.c linux-3.2.71-pax/arch/powerpc/mm/slice.c
--- linux-3.2.71/arch/powerpc/mm/slice.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/mm/slice.c	2013-07-05 02:13:34.417199340 +0200
@@ -98,7 +98,7 @@ static int slice_area_is_free(struct mm_
 	if ((mm->task_size - len) < addr)
 		return 0;
 	vma = find_vma(mm, addr);
-	return (!vma || (addr + len) <= vma->vm_start);
+	return check_heap_stack_gap(vma, &addr, len);
 }
 
 static int slice_low_has_vma(struct mm_struct *mm, unsigned long slice)
@@ -256,7 +256,7 @@ full_search:
 				addr = _ALIGN_UP(addr + 1,  1ul << SLICE_HIGH_SHIFT);
 			continue;
 		}
-		if (!vma || addr + len <= vma->vm_start) {
+		if (check_heap_stack_gap(vma, &addr, len)) {
 			/*
 			 * Remember the place where we stopped the search:
 			 */
@@ -313,10 +313,14 @@ static unsigned long slice_find_area_top
 		}
 	}
 
-	addr = mm->mmap_base;
-	while (addr > len) {
+	if (mm->mmap_base < len)
+		addr = -ENOMEM;
+	else
+		addr = mm->mmap_base - len;
+
+	while (!IS_ERR_VALUE(addr)) {
 		/* Go down by chunk size */
-		addr = _ALIGN_DOWN(addr - len, 1ul << pshift);
+		addr = _ALIGN_DOWN(addr, 1ul << pshift);
 
 		/* Check for hit with different page size */
 		mask = slice_range_to_mask(addr, len);
@@ -336,7 +340,7 @@ static unsigned long slice_find_area_top
 		 * return with success:
 		 */
 		vma = find_vma(mm, addr);
-		if (!vma || (addr + len) <= vma->vm_start) {
+		if (check_heap_stack_gap(vma, &addr, len)) {
 			/* remember the address as a hint for next time */
 			if (use_cache)
 				mm->free_area_cache = addr;
@@ -348,7 +352,7 @@ static unsigned long slice_find_area_top
 		        mm->cached_hole_size = vma->vm_start - addr;
 
 		/* try just below the current vma->vm_start */
-		addr = vma->vm_start;
+		addr = skip_heap_stack_gap(vma, len);
 	}
 
 	/*
@@ -426,6 +430,11 @@ unsigned long slice_get_unmapped_area(un
 	if (fixed && addr > (mm->task_size - len))
 		return -EINVAL;
 
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!fixed && (mm->pax_flags & MF_PAX_RANDMMAP))
+		addr = 0;
+#endif
+
 	/* If hint, make sure it matches our alignment restrictions */
 	if (!fixed && addr) {
 		addr = _ALIGN_UP(addr, 1ul << pshift);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/platforms/cell/spufs/file.c linux-3.2.71-pax/arch/powerpc/platforms/cell/spufs/file.c
--- linux-3.2.71/arch/powerpc/platforms/cell/spufs/file.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/platforms/cell/spufs/file.c	2013-04-05 19:58:05.768903585 +0200
@@ -281,9 +281,9 @@ spufs_mem_mmap_fault(struct vm_area_stru
 	return VM_FAULT_NOPAGE;
 }
 
-static int spufs_mem_mmap_access(struct vm_area_struct *vma,
+static ssize_t spufs_mem_mmap_access(struct vm_area_struct *vma,
 				unsigned long address,
-				void *buf, int len, int write)
+				void *buf, size_t len, int write)
 {
 	struct spu_context *ctx = vma->vm_file->private_data;
 	unsigned long offset = address - vma->vm_start;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/platforms/powermac/smp.c linux-3.2.71-pax/arch/powerpc/platforms/powermac/smp.c
--- linux-3.2.71/arch/powerpc/platforms/powermac/smp.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/platforms/powermac/smp.c	2013-02-20 01:19:14.958027372 +0100
@@ -886,7 +886,7 @@ static int smp_core99_cpu_notify(struct
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata smp_core99_cpu_nb = {
+static struct notifier_block smp_core99_cpu_nb = {
 	.notifier_call	= smp_core99_cpu_notify,
 };
 #endif /* CONFIG_HOTPLUG_CPU */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/powerpc/platforms/pseries/eeh_event.c linux-3.2.71-pax/arch/powerpc/platforms/pseries/eeh_event.c
--- linux-3.2.71/arch/powerpc/platforms/pseries/eeh_event.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/powerpc/platforms/pseries/eeh_event.c	2014-03-23 21:07:50.740059889 +0100
@@ -61,7 +61,7 @@ static int eeh_event_handler(void * dumm
 	struct eeh_event	*event;
 	struct pci_dn *pdn;
 
-	daemonize ("eehd");
+	set_task_comm(current, "eehd");
 	set_current_state(TASK_INTERRUPTIBLE);
 
 	spin_lock_irqsave(&eeh_eventlist_lock, flags);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/s390/appldata/appldata_base.c linux-3.2.71-pax/arch/s390/appldata/appldata_base.c
--- linux-3.2.71/arch/s390/appldata/appldata_base.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/s390/appldata/appldata_base.c	2013-02-20 01:23:21.906014187 +0100
@@ -610,7 +610,7 @@ static int __cpuinit appldata_cpu_notify
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata appldata_nb = {
+static struct notifier_block appldata_nb = {
 	.notifier_call = appldata_cpu_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/s390/include/asm/atomic.h linux-3.2.71-pax/arch/s390/include/asm/atomic.h
--- linux-3.2.71/arch/s390/include/asm/atomic.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/s390/include/asm/atomic.h	2012-07-04 19:24:47.416063009 +0200
@@ -326,6 +326,16 @@ static inline long long atomic64_dec_if_
 #define atomic64_dec_and_test(_v)	(atomic64_sub_return(1, _v) == 0)
 #define atomic64_inc_not_zero(v)	atomic64_add_unless((v), 1, 0)
 
+#define atomic64_read_unchecked(v)		atomic64_read(v)
+#define atomic64_set_unchecked(v, i)		atomic64_set((v), (i))
+#define atomic64_add_unchecked(a, v)		atomic64_add((a), (v))
+#define atomic64_add_return_unchecked(a, v)	atomic64_add_return((a), (v))
+#define atomic64_sub_unchecked(a, v)		atomic64_sub((a), (v))
+#define atomic64_inc_unchecked(v)		atomic64_inc(v)
+#define atomic64_inc_return_unchecked(v)	atomic64_inc_return(v)
+#define atomic64_dec_unchecked(v)		atomic64_dec(v)
+#define atomic64_cmpxchg_unchecked(v, o, n)	atomic64_cmpxchg((v), (o), (n))
+
 #define smp_mb__before_atomic_dec()	smp_mb()
 #define smp_mb__after_atomic_dec()	smp_mb()
 #define smp_mb__before_atomic_inc()	smp_mb()
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/s390/include/asm/elf.h linux-3.2.71-pax/arch/s390/include/asm/elf.h
--- linux-3.2.71/arch/s390/include/asm/elf.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/s390/include/asm/elf.h	2012-07-04 19:24:47.416063009 +0200
@@ -162,8 +162,14 @@ extern unsigned int vdso_enabled;
    the loader.  We need to make sure that it is out of the way of the program
    that it will "exec", and that there is sufficient room for the brk.  */
 
-extern unsigned long randomize_et_dyn(unsigned long base);
-#define ELF_ET_DYN_BASE		(randomize_et_dyn(STACK_TOP / 3 * 2))
+#define ELF_ET_DYN_BASE		(STACK_TOP / 3 * 2)
+
+#ifdef CONFIG_PAX_ASLR
+#define PAX_ELF_ET_DYN_BASE	(test_thread_flag(TIF_31BIT) ? 0x10000UL : 0x80000000UL)
+
+#define PAX_DELTA_MMAP_LEN	(test_thread_flag(TIF_31BIT) ? 15 : 26)
+#define PAX_DELTA_STACK_LEN	(test_thread_flag(TIF_31BIT) ? 15 : 26)
+#endif
 
 /* This yields a mask that user programs can use to figure out what
    instruction set this CPU supports. */
@@ -211,7 +217,4 @@ struct linux_binprm;
 #define ARCH_HAS_SETUP_ADDITIONAL_PAGES 1
 int arch_setup_additional_pages(struct linux_binprm *, int);
 
-extern unsigned long arch_randomize_brk(struct mm_struct *mm);
-#define arch_randomize_brk arch_randomize_brk
-
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/s390/include/asm/system.h linux-3.2.71-pax/arch/s390/include/asm/system.h
--- linux-3.2.71/arch/s390/include/asm/system.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/s390/include/asm/system.h	2012-07-04 19:24:47.416063009 +0200
@@ -262,7 +262,7 @@ extern void (*_machine_restart)(char *co
 extern void (*_machine_halt)(void);
 extern void (*_machine_power_off)(void);
 
-extern unsigned long arch_align_stack(unsigned long sp);
+#define arch_align_stack(x) ((x) & ~0xfUL)
 
 static inline int tprot(unsigned long addr)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/s390/include/asm/uaccess.h linux-3.2.71-pax/arch/s390/include/asm/uaccess.h
--- linux-3.2.71/arch/s390/include/asm/uaccess.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/s390/include/asm/uaccess.h	2014-03-23 21:07:50.740059889 +0100
@@ -55,6 +55,7 @@
 	1;			\
 })
 
+#define access_ok_noprefault(type, addr, size) access_ok((type), (addr), (size))
 #define access_ok(type, addr, size) __access_ok(addr, size)
 
 /*
@@ -235,6 +236,10 @@ static inline unsigned long __must_check
 copy_to_user(void __user *to, const void *from, unsigned long n)
 {
 	might_fault();
+
+	if ((long)n < 0)
+		return n;
+
 	if (access_ok(VERIFY_WRITE, to, n))
 		n = __copy_to_user(to, from, n);
 	return n;
@@ -260,6 +265,9 @@ copy_to_user(void __user *to, const void
 static inline unsigned long __must_check
 __copy_from_user(void *to, const void __user *from, unsigned long n)
 {
+	if ((long)n < 0)
+		return n;
+
 	if (__builtin_constant_p(n) && (n <= 256))
 		return uaccess.copy_from_user_small(n, from, to);
 	else
@@ -291,10 +299,14 @@ __compiletime_warning("copy_from_user()
 static inline unsigned long __must_check
 copy_from_user(void *to, const void __user *from, unsigned long n)
 {
-	unsigned int sz = __compiletime_object_size(to);
+	size_t sz = __compiletime_object_size(to);
 
 	might_fault();
-	if (unlikely(sz != -1 && sz < n)) {
+
+	if ((long)n < 0)
+		return n;
+
+	if (unlikely(sz != (size_t)-1 && sz < n)) {
 		copy_from_user_overflow();
 		return n;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/s390/kernel/module.c linux-3.2.71-pax/arch/s390/kernel/module.c
--- linux-3.2.71/arch/s390/kernel/module.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/s390/kernel/module.c	2012-07-04 19:24:47.420062992 +0200
@@ -161,11 +161,11 @@ module_frob_arch_sections(Elf_Ehdr *hdr,
 
 	/* Increase core size by size of got & plt and set start
 	   offsets for got and plt. */
-	me->core_size = ALIGN(me->core_size, 4);
-	me->arch.got_offset = me->core_size;
-	me->core_size += me->arch.got_size;
-	me->arch.plt_offset = me->core_size;
-	me->core_size += me->arch.plt_size;
+	me->core_size_rw = ALIGN(me->core_size_rw, 4);
+	me->arch.got_offset = me->core_size_rw;
+	me->core_size_rw += me->arch.got_size;
+	me->arch.plt_offset = me->core_size_rx;
+	me->core_size_rx += me->arch.plt_size;
 	return 0;
 }
 
@@ -242,7 +242,7 @@ apply_rela(Elf_Rela *rela, Elf_Addr base
 		if (info->got_initialized == 0) {
 			Elf_Addr *gotent;
 
-			gotent = me->module_core + me->arch.got_offset +
+			gotent = me->module_core_rw + me->arch.got_offset +
 				info->got_offset;
 			*gotent = val;
 			info->got_initialized = 1;
@@ -266,7 +266,7 @@ apply_rela(Elf_Rela *rela, Elf_Addr base
 		else if (r_type == R_390_GOTENT ||
 			 r_type == R_390_GOTPLTENT)
 			*(unsigned int *) loc =
-				(val + (Elf_Addr) me->module_core - loc) >> 1;
+				(val + (Elf_Addr) me->module_core_rw - loc) >> 1;
 		else if (r_type == R_390_GOT64 ||
 			 r_type == R_390_GOTPLT64)
 			*(unsigned long *) loc = val;
@@ -280,7 +280,7 @@ apply_rela(Elf_Rela *rela, Elf_Addr base
 	case R_390_PLTOFF64:	/* 16 bit offset from GOT to PLT. */
 		if (info->plt_initialized == 0) {
 			unsigned int *ip;
-			ip = me->module_core + me->arch.plt_offset +
+			ip = me->module_core_rx + me->arch.plt_offset +
 				info->plt_offset;
 #ifndef CONFIG_64BIT
 			ip[0] = 0x0d105810; /* basr 1,0; l 1,6(1); br 1 */
@@ -305,7 +305,7 @@ apply_rela(Elf_Rela *rela, Elf_Addr base
 			       val - loc + 0xffffUL < 0x1ffffeUL) ||
 			      (r_type == R_390_PLT32DBL &&
 			       val - loc + 0xffffffffULL < 0x1fffffffeULL)))
-				val = (Elf_Addr) me->module_core +
+				val = (Elf_Addr) me->module_core_rx +
 					me->arch.plt_offset +
 					info->plt_offset;
 			val += rela->r_addend - loc;
@@ -327,7 +327,7 @@ apply_rela(Elf_Rela *rela, Elf_Addr base
 	case R_390_GOTOFF32:	/* 32 bit offset to GOT.  */
 	case R_390_GOTOFF64:	/* 64 bit offset to GOT. */
 		val = val + rela->r_addend -
-			((Elf_Addr) me->module_core + me->arch.got_offset);
+			((Elf_Addr) me->module_core_rw + me->arch.got_offset);
 		if (r_type == R_390_GOTOFF16)
 			*(unsigned short *) loc = val;
 		else if (r_type == R_390_GOTOFF32)
@@ -337,7 +337,7 @@ apply_rela(Elf_Rela *rela, Elf_Addr base
 		break;
 	case R_390_GOTPC:	/* 32 bit PC relative offset to GOT. */
 	case R_390_GOTPCDBL:	/* 32 bit PC rel. off. to GOT shifted by 1. */
-		val = (Elf_Addr) me->module_core + me->arch.got_offset +
+		val = (Elf_Addr) me->module_core_rw + me->arch.got_offset +
 			rela->r_addend - loc;
 		if (r_type == R_390_GOTPC)
 			*(unsigned int *) loc = val;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/s390/kernel/process.c linux-3.2.71-pax/arch/s390/kernel/process.c
--- linux-3.2.71/arch/s390/kernel/process.c	2015-08-14 21:48:35.020707928 +0200
+++ linux-3.2.71-pax/arch/s390/kernel/process.c	2015-08-14 21:48:45.548707366 +0200
@@ -320,39 +320,3 @@ unsigned long get_wchan(struct task_stru
 	}
 	return 0;
 }
-
-unsigned long arch_align_stack(unsigned long sp)
-{
-	if (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)
-		sp -= get_random_int() & ~PAGE_MASK;
-	return sp & ~0xf;
-}
-
-static inline unsigned long brk_rnd(void)
-{
-	/* 8MB for 32bit, 1GB for 64bit */
-	if (is_32bit_task())
-		return (get_random_int() & 0x7ffUL) << PAGE_SHIFT;
-	else
-		return (get_random_int() & 0x3ffffUL) << PAGE_SHIFT;
-}
-
-unsigned long arch_randomize_brk(struct mm_struct *mm)
-{
-	unsigned long ret = PAGE_ALIGN(mm->brk + brk_rnd());
-
-	if (ret < mm->brk)
-		return mm->brk;
-	return ret;
-}
-
-unsigned long randomize_et_dyn(unsigned long base)
-{
-	unsigned long ret = PAGE_ALIGN(base + brk_rnd());
-
-	if (!(current->flags & PF_RANDOMIZE))
-		return base;
-	if (ret < base)
-		return base;
-	return ret;
-}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/s390/kernel/smp.c linux-3.2.71-pax/arch/s390/kernel/smp.c
--- linux-3.2.71/arch/s390/kernel/smp.c	2012-08-03 01:53:47.030140455 +0200
+++ linux-3.2.71-pax/arch/s390/kernel/smp.c	2013-02-20 01:23:25.846013976 +0100
@@ -1035,7 +1035,7 @@ static int __cpuinit smp_cpu_notify(stru
 	return notifier_from_errno(err);
 }
 
-static struct notifier_block __cpuinitdata smp_cpu_nb = {
+static struct notifier_block smp_cpu_nb = {
 	.notifier_call = smp_cpu_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/s390/mm/mmap.c linux-3.2.71-pax/arch/s390/mm/mmap.c
--- linux-3.2.71/arch/s390/mm/mmap.c	2012-08-12 12:28:42.589231633 +0200
+++ linux-3.2.71-pax/arch/s390/mm/mmap.c	2015-06-26 17:57:12.058478695 +0200
@@ -60,6 +60,12 @@ static inline int mmap_is_legacy(void)
 
 static unsigned long mmap_rnd(void)
 {
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (current->mm->pax_flags & MF_PAX_RANDMMAP)
+		return 0;
+#endif
+
 	if (!(current->flags & PF_RANDOMIZE))
 		return 0;
 	/* 8MB randomization for mmap_base */
@@ -92,10 +98,22 @@ void arch_pick_mmap_layout(struct mm_str
 	 */
 	if (mmap_is_legacy()) {
 		mm->mmap_base = TASK_UNMAPPED_BASE;
+
+#ifdef CONFIG_PAX_RANDMMAP
+		if (mm->pax_flags & MF_PAX_RANDMMAP)
+			mm->mmap_base += mm->delta_mmap;
+#endif
+
 		mm->get_unmapped_area = arch_get_unmapped_area;
 		mm->unmap_area = arch_unmap_area;
 	} else {
 		mm->mmap_base = mmap_base();
+
+#ifdef CONFIG_PAX_RANDMMAP
+		if (mm->pax_flags & MF_PAX_RANDMMAP)
+			mm->mmap_base -= mm->delta_mmap + mm->delta_stack;
+#endif
+
 		mm->get_unmapped_area = arch_get_unmapped_area_topdown;
 		mm->unmap_area = arch_unmap_area_topdown;
 	}
@@ -175,10 +193,22 @@ void arch_pick_mmap_layout(struct mm_str
 	 */
 	if (mmap_is_legacy()) {
 		mm->mmap_base = TASK_UNMAPPED_BASE;
+
+#ifdef CONFIG_PAX_RANDMMAP
+		if (mm->pax_flags & MF_PAX_RANDMMAP)
+			mm->mmap_base += mm->delta_mmap;
+#endif
+
 		mm->get_unmapped_area = s390_get_unmapped_area;
 		mm->unmap_area = arch_unmap_area;
 	} else {
 		mm->mmap_base = mmap_base();
+
+#ifdef CONFIG_PAX_RANDMMAP
+		if (mm->pax_flags & MF_PAX_RANDMMAP)
+			mm->mmap_base -= mm->delta_mmap + mm->delta_stack;
+#endif
+
 		mm->get_unmapped_area = s390_get_unmapped_area_topdown;
 		mm->unmap_area = arch_unmap_area_topdown;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/score/include/asm/system.h linux-3.2.71-pax/arch/score/include/asm/system.h
--- linux-3.2.71/arch/score/include/asm/system.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/score/include/asm/system.h	2012-07-04 19:24:47.420062992 +0200
@@ -17,7 +17,7 @@ do {								\
 #define finish_arch_switch(prev)	do {} while (0)
 
 typedef void (*vi_handler_t)(void);
-extern unsigned long arch_align_stack(unsigned long sp);
+#define arch_align_stack(x) (x)
 
 #define mb()		barrier()
 #define rmb()		barrier()
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/score/kernel/process.c linux-3.2.71-pax/arch/score/kernel/process.c
--- linux-3.2.71/arch/score/kernel/process.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/score/kernel/process.c	2012-07-04 19:24:47.420062992 +0200
@@ -161,8 +161,3 @@ unsigned long get_wchan(struct task_stru
 
 	return task_pt_regs(task)->cp0_epc;
 }
-
-unsigned long arch_align_stack(unsigned long sp)
-{
-	return sp;
-}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sh/kernel/cpu/sh4a/smp-shx3.c linux-3.2.71-pax/arch/sh/kernel/cpu/sh4a/smp-shx3.c
--- linux-3.2.71/arch/sh/kernel/cpu/sh4a/smp-shx3.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sh/kernel/cpu/sh4a/smp-shx3.c	2013-02-20 01:19:14.958027372 +0100
@@ -143,7 +143,7 @@ shx3_cpu_callback(struct notifier_block
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata shx3_cpu_notifier = {
+static struct notifier_block shx3_cpu_notifier = {
 	.notifier_call		= shx3_cpu_callback,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sh/mm/mmap.c linux-3.2.71-pax/arch/sh/mm/mmap.c
--- linux-3.2.71/arch/sh/mm/mmap.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sh/mm/mmap.c	2013-07-05 02:13:17.157200262 +0200
@@ -74,8 +74,7 @@ unsigned long arch_get_unmapped_area(str
 			addr = PAGE_ALIGN(addr);
 
 		vma = find_vma(mm, addr);
-		if (TASK_SIZE - len >= addr &&
-		    (!vma || addr + len <= vma->vm_start))
+		if (TASK_SIZE - len >= addr && check_heap_stack_gap(vma, &addr, len))
 			return addr;
 	}
 
@@ -106,7 +105,7 @@ full_search:
 			}
 			return -ENOMEM;
 		}
-		if (likely(!vma || addr + len <= vma->vm_start)) {
+		if (likely(check_heap_stack_gap(vma, &addr, len))) {
 			/*
 			 * Remember the place where we stopped the search:
 			 */
@@ -157,8 +156,7 @@ arch_get_unmapped_area_topdown(struct fi
 			addr = PAGE_ALIGN(addr);
 
 		vma = find_vma(mm, addr);
-		if (TASK_SIZE - len >= addr &&
-		    (!vma || addr + len <= vma->vm_start))
+		if (TASK_SIZE - len >= addr && check_heap_stack_gap(vma, &addr, len))
 			return addr;
 	}
 
@@ -178,28 +176,29 @@ arch_get_unmapped_area_topdown(struct fi
 
 	/* make sure it can fit in the remaining address space */
 	if (likely(addr > len)) {
-		vma = find_vma(mm, addr-len);
-		if (!vma || addr <= vma->vm_start) {
+		addr -= len;
+		vma = find_vma(mm, addr);
+		if (check_heap_stack_gap(vma, &addr, len)) {
 			/* remember the address as a hint for next time */
-			return (mm->free_area_cache = addr-len);
+			return (mm->free_area_cache = addr);
 		}
 	}
 
 	if (unlikely(mm->mmap_base < len))
 		goto bottomup;
 
-	addr = mm->mmap_base-len;
-	if (do_colour_align)
-		addr = COLOUR_ALIGN_DOWN(addr, pgoff);
+	addr = mm->mmap_base - len;
 
 	do {
+		if (do_colour_align)
+			addr = COLOUR_ALIGN_DOWN(addr, pgoff);
 		/*
 		 * Lookup failure means no vma is above this address,
 		 * else if new region fits below vma->vm_start,
 		 * return with success:
 		 */
 		vma = find_vma(mm, addr);
-		if (likely(!vma || addr+len <= vma->vm_start)) {
+		if (likely(check_heap_stack_gap(vma, &addr, len))) {
 			/* remember the address as a hint for next time */
 			return (mm->free_area_cache = addr);
 		}
@@ -209,10 +208,8 @@ arch_get_unmapped_area_topdown(struct fi
 		        mm->cached_hole_size = vma->vm_start - addr;
 
 		/* try just below the current vma->vm_start */
-		addr = vma->vm_start-len;
-		if (do_colour_align)
-			addr = COLOUR_ALIGN_DOWN(addr, pgoff);
-	} while (likely(len < vma->vm_start));
+		addr = skip_heap_stack_gap(vma, len);
+	} while (!IS_ERR_VALUE(addr));
 
 bottomup:
 	/*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/atomic_32.h linux-3.2.71-pax/arch/sparc/include/asm/atomic_32.h
--- linux-3.2.71/arch/sparc/include/asm/atomic_32.h	2013-09-10 17:24:55.281739129 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/atomic_32.h	2013-09-10 17:24:58.993738931 +0200
@@ -13,6 +13,8 @@
 
 #include <linux/types.h>
 
+#include <asm-generic/atomic64.h>
+
 #ifdef __KERNEL__
 
 #include <asm-generic/atomic64.h>
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/atomic_64.h linux-3.2.71-pax/arch/sparc/include/asm/atomic_64.h
--- linux-3.2.71/arch/sparc/include/asm/atomic_64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/atomic_64.h	2015-01-05 18:23:51.071624566 +0100
@@ -14,18 +14,40 @@
 #define ATOMIC64_INIT(i)	{ (i) }
 
 #define atomic_read(v)		(*(volatile int *)&(v)->counter)
+static inline int atomic_read_unchecked(const atomic_unchecked_t *v)
+{
+	return *(const volatile int *)&v->counter;
+}
 #define atomic64_read(v)	(*(volatile long *)&(v)->counter)
+static inline long atomic64_read_unchecked(const atomic64_unchecked_t *v)
+{
+	return *(const volatile long *)&v->counter;
+}
 
 #define atomic_set(v, i)	(((v)->counter) = i)
+static inline void atomic_set_unchecked(atomic_unchecked_t *v, int i)
+{
+	v->counter = i;
+}
 #define atomic64_set(v, i)	(((v)->counter) = i)
+static inline void atomic64_set_unchecked(atomic64_unchecked_t *v, long i)
+{
+	v->counter = i;
+}
 
 extern void atomic_add(int, atomic_t *);
+extern void atomic_add_unchecked(int, atomic_unchecked_t *);
 extern void atomic64_add(long, atomic64_t *);
+extern void atomic64_add_unchecked(long, atomic64_unchecked_t *);
 extern void atomic_sub(int, atomic_t *);
+extern void atomic_sub_unchecked(int, atomic_unchecked_t *);
 extern void atomic64_sub(long, atomic64_t *);
+extern void atomic64_sub_unchecked(long, atomic64_unchecked_t *);
 
 extern int atomic_add_ret(int, atomic_t *);
+extern int atomic_add_ret_unchecked(int, atomic_unchecked_t *);
 extern long atomic64_add_ret(long, atomic64_t *);
+extern long atomic64_add_ret_unchecked(long, atomic64_unchecked_t *);
 extern int atomic_sub_ret(int, atomic_t *);
 extern long atomic64_sub_ret(long, atomic64_t *);
 
@@ -33,13 +55,29 @@ extern long atomic64_sub_ret(long, atomi
 #define atomic64_dec_return(v) atomic64_sub_ret(1, v)
 
 #define atomic_inc_return(v) atomic_add_ret(1, v)
+static inline int atomic_inc_return_unchecked(atomic_unchecked_t *v)
+{
+	return atomic_add_ret_unchecked(1, v);
+}
 #define atomic64_inc_return(v) atomic64_add_ret(1, v)
+static inline long atomic64_inc_return_unchecked(atomic64_unchecked_t *v)
+{
+	return atomic64_add_ret_unchecked(1, v);
+}
 
 #define atomic_sub_return(i, v) atomic_sub_ret(i, v)
 #define atomic64_sub_return(i, v) atomic64_sub_ret(i, v)
 
 #define atomic_add_return(i, v) atomic_add_ret(i, v)
+static inline int atomic_add_return_unchecked(int i, atomic_unchecked_t *v)
+{
+	return atomic_add_ret_unchecked(i, v);
+}
 #define atomic64_add_return(i, v) atomic64_add_ret(i, v)
+static inline long atomic64_add_return_unchecked(long i, atomic64_unchecked_t *v)
+{
+	return atomic64_add_ret_unchecked(i, v);
+}
 
 /*
  * atomic_inc_and_test - increment and test
@@ -50,6 +88,10 @@ extern long atomic64_sub_ret(long, atomi
  * other cases.
  */
 #define atomic_inc_and_test(v) (atomic_inc_return(v) == 0)
+static inline int atomic_inc_and_test_unchecked(atomic_unchecked_t *v)
+{
+	return atomic_inc_return_unchecked(v) == 0;
+}
 #define atomic64_inc_and_test(v) (atomic64_inc_return(v) == 0)
 
 #define atomic_sub_and_test(i, v) (atomic_sub_ret(i, v) == 0)
@@ -59,25 +101,60 @@ extern long atomic64_sub_ret(long, atomi
 #define atomic64_dec_and_test(v) (atomic64_sub_ret(1, v) == 0)
 
 #define atomic_inc(v) atomic_add(1, v)
+static inline void atomic_inc_unchecked(atomic_unchecked_t *v)
+{
+	atomic_add_unchecked(1, v);
+}
 #define atomic64_inc(v) atomic64_add(1, v)
+static inline void atomic64_inc_unchecked(atomic64_unchecked_t *v)
+{
+	atomic64_add_unchecked(1, v);
+}
 
 #define atomic_dec(v) atomic_sub(1, v)
+static inline void atomic_dec_unchecked(atomic_unchecked_t *v)
+{
+	atomic_sub_unchecked(1, v);
+}
 #define atomic64_dec(v) atomic64_sub(1, v)
+static inline void atomic64_dec_unchecked(atomic64_unchecked_t *v)
+{
+	atomic64_sub_unchecked(1, v);
+}
 
 #define atomic_add_negative(i, v) (atomic_add_ret(i, v) < 0)
 #define atomic64_add_negative(i, v) (atomic64_add_ret(i, v) < 0)
 
 #define atomic_cmpxchg(v, o, n) (cmpxchg(&((v)->counter), (o), (n)))
+static inline int atomic_cmpxchg_unchecked(atomic_unchecked_t *v, int old, int new)
+{
+	return cmpxchg(&v->counter, old, new);
+}
 #define atomic_xchg(v, new) (xchg(&((v)->counter), new))
+static inline int atomic_xchg_unchecked(atomic_unchecked_t *v, int new)
+{
+	return xchg(&v->counter, new);
+}
 
 static inline int __atomic_add_unless(atomic_t *v, int a, int u)
 {
-	int c, old;
+	int c, old, new;
 	c = atomic_read(v);
 	for (;;) {
-		if (unlikely(c == (u)))
+		if (unlikely(c == u))
 			break;
-		old = atomic_cmpxchg((v), c, c + (a));
+
+		asm volatile("addcc %2, %0, %0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+			     "tvs %%icc, 6\n"
+#endif
+
+			     : "=r" (new)
+			     : "0" (c), "ir" (a)
+			     : "cc");
+
+		old = atomic_cmpxchg(v, c, new);
 		if (likely(old == c))
 			break;
 		c = old;
@@ -89,20 +166,35 @@ static inline int __atomic_add_unless(at
 #define atomic64_cmpxchg(v, o, n) \
 	((__typeof__((v)->counter))cmpxchg(&((v)->counter), (o), (n)))
 #define atomic64_xchg(v, new) (xchg(&((v)->counter), new))
+static inline long atomic64_xchg_unchecked(atomic64_unchecked_t *v, long new)
+{
+	return xchg(&v->counter, new);
+}
 
 static inline long atomic64_add_unless(atomic64_t *v, long a, long u)
 {
-	long c, old;
+	long c, old, new;
 	c = atomic64_read(v);
 	for (;;) {
-		if (unlikely(c == (u)))
+		if (unlikely(c == u))
 			break;
-		old = atomic64_cmpxchg((v), c, c + (a));
+
+		asm volatile("addcc %2, %0, %0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+			     "tvs %%xcc, 6\n"
+#endif
+
+			     : "=r" (new)
+			     : "0" (c), "ir" (a)
+			     : "cc");
+
+		old = atomic64_cmpxchg(v, c, new);
 		if (likely(old == c))
 			break;
 		c = old;
 	}
-	return c != (u);
+	return c != u;
 }
 
 #define atomic64_inc_not_zero(v) atomic64_add_unless((v), 1, 0)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/cache.h linux-3.2.71-pax/arch/sparc/include/asm/cache.h
--- linux-3.2.71/arch/sparc/include/asm/cache.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/cache.h	2012-07-04 19:24:47.424062984 +0200
@@ -10,7 +10,7 @@
 #define ARCH_SLAB_MINALIGN	__alignof__(unsigned long long)
 
 #define L1_CACHE_SHIFT 5
-#define L1_CACHE_BYTES 32
+#define L1_CACHE_BYTES 32UL
 
 #ifdef CONFIG_SPARC32
 #define SMP_CACHE_BYTES_SHIFT 5
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/elf_32.h linux-3.2.71-pax/arch/sparc/include/asm/elf_32.h
--- linux-3.2.71/arch/sparc/include/asm/elf_32.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/elf_32.h	2012-07-04 19:24:47.424062984 +0200
@@ -114,6 +114,13 @@ typedef struct {
 
 #define ELF_ET_DYN_BASE         (TASK_UNMAPPED_BASE)
 
+#ifdef CONFIG_PAX_ASLR
+#define PAX_ELF_ET_DYN_BASE	0x10000UL
+
+#define PAX_DELTA_MMAP_LEN	16
+#define PAX_DELTA_STACK_LEN	16
+#endif
+
 /* This yields a mask that user programs can use to figure out what
    instruction set this cpu supports.  This can NOT be done in userspace
    on Sparc.  */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/elf_64.h linux-3.2.71-pax/arch/sparc/include/asm/elf_64.h
--- linux-3.2.71/arch/sparc/include/asm/elf_64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/elf_64.h	2012-07-04 19:24:47.424062984 +0200
@@ -180,6 +180,13 @@ typedef struct {
 #define ELF_ET_DYN_BASE		0x0000010000000000UL
 #define COMPAT_ELF_ET_DYN_BASE	0x0000000070000000UL
 
+#ifdef CONFIG_PAX_ASLR
+#define PAX_ELF_ET_DYN_BASE	(test_thread_flag(TIF_32BIT) ? 0x10000UL : 0x100000UL)
+
+#define PAX_DELTA_MMAP_LEN	(test_thread_flag(TIF_32BIT) ? 14 : 28)
+#define PAX_DELTA_STACK_LEN	(test_thread_flag(TIF_32BIT) ? 15 : 29)
+#endif
+
 extern unsigned long sparc64_elf_hwcap;
 #define ELF_HWCAP	sparc64_elf_hwcap
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/page_32.h linux-3.2.71-pax/arch/sparc/include/asm/page_32.h
--- linux-3.2.71/arch/sparc/include/asm/page_32.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/page_32.h	2012-07-04 19:24:47.424062984 +0200
@@ -8,6 +8,8 @@
 #ifndef _SPARC_PAGE_H
 #define _SPARC_PAGE_H
 
+#include <linux/const.h>
+
 #define PAGE_SHIFT   12
 
 #ifndef __ASSEMBLY__
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/pgalloc_32.h linux-3.2.71-pax/arch/sparc/include/asm/pgalloc_32.h
--- linux-3.2.71/arch/sparc/include/asm/pgalloc_32.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/pgalloc_32.h	2012-07-04 19:24:47.424062984 +0200
@@ -37,6 +37,7 @@ BTFIXUPDEF_CALL(void, free_pgd_fast, pgd
 BTFIXUPDEF_CALL(void, pgd_set, pgd_t *, pmd_t *)
 #define pgd_set(pgdp,pmdp) BTFIXUP_CALL(pgd_set)(pgdp,pmdp)
 #define pgd_populate(MM, PGD, PMD)      pgd_set(PGD, PMD)
+#define pgd_populate_kernel(MM, PGD, PMD)      pgd_populate((MM), (PGD), (PMD))
 
 BTFIXUPDEF_CALL(pmd_t *, pmd_alloc_one, struct mm_struct *, unsigned long)
 #define pmd_alloc_one(mm, address)	BTFIXUP_CALL(pmd_alloc_one)(mm, address)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/pgalloc_64.h linux-3.2.71-pax/arch/sparc/include/asm/pgalloc_64.h
--- linux-3.2.71/arch/sparc/include/asm/pgalloc_64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/pgalloc_64.h	2012-07-04 19:24:47.424062984 +0200
@@ -26,6 +26,7 @@ static inline void pgd_free(struct mm_st
 }
 
 #define pud_populate(MM, PUD, PMD)	pud_set(PUD, PMD)
+#define pud_populate_kernel(MM, PUD, PMD)	pud_populate((MM), (PUD), (PMD))
 
 static inline pmd_t *pmd_alloc_one(struct mm_struct *mm, unsigned long addr)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/pgtable_32.h linux-3.2.71-pax/arch/sparc/include/asm/pgtable_32.h
--- linux-3.2.71/arch/sparc/include/asm/pgtable_32.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/pgtable_32.h	2012-07-04 19:24:47.428062988 +0200
@@ -45,6 +45,13 @@ BTFIXUPDEF_SIMM13(user_ptrs_per_pgd)
 BTFIXUPDEF_INT(page_none)
 BTFIXUPDEF_INT(page_copy)
 BTFIXUPDEF_INT(page_readonly)
+
+#ifdef CONFIG_PAX_PAGEEXEC
+BTFIXUPDEF_INT(page_shared_noexec)
+BTFIXUPDEF_INT(page_copy_noexec)
+BTFIXUPDEF_INT(page_readonly_noexec)
+#endif
+
 BTFIXUPDEF_INT(page_kernel)
 
 #define PMD_SHIFT		SUN4C_PMD_SHIFT
@@ -66,6 +73,16 @@ extern pgprot_t PAGE_SHARED;
 #define PAGE_COPY      __pgprot(BTFIXUP_INT(page_copy))
 #define PAGE_READONLY  __pgprot(BTFIXUP_INT(page_readonly))
 
+#ifdef CONFIG_PAX_PAGEEXEC
+extern pgprot_t PAGE_SHARED_NOEXEC;
+# define PAGE_COPY_NOEXEC	__pgprot(BTFIXUP_INT(page_copy_noexec))
+# define PAGE_READONLY_NOEXEC	__pgprot(BTFIXUP_INT(page_readonly_noexec))
+#else
+# define PAGE_SHARED_NOEXEC	PAGE_SHARED
+# define PAGE_COPY_NOEXEC	PAGE_COPY
+# define PAGE_READONLY_NOEXEC	PAGE_READONLY
+#endif
+
 extern unsigned long page_kernel;
 
 #ifdef MODULE
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/pgtable.h linux-3.2.71-pax/arch/sparc/include/asm/pgtable.h
--- linux-3.2.71/arch/sparc/include/asm/pgtable.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/pgtable.h	2014-03-23 21:07:50.740059889 +0100
@@ -5,4 +5,8 @@
 #else
 #include <asm/pgtable_32.h>
 #endif
+
+#define ktla_ktva(addr)		(addr)
+#define ktva_ktla(addr)		(addr)
+
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/pgtsrmmu.h linux-3.2.71-pax/arch/sparc/include/asm/pgtsrmmu.h
--- linux-3.2.71/arch/sparc/include/asm/pgtsrmmu.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/pgtsrmmu.h	2012-07-04 19:24:47.428062988 +0200
@@ -115,6 +115,13 @@
 				    SRMMU_EXEC | SRMMU_REF)
 #define SRMMU_PAGE_RDONLY  __pgprot(SRMMU_VALID | SRMMU_CACHE | \
 				    SRMMU_EXEC | SRMMU_REF)
+
+#ifdef CONFIG_PAX_PAGEEXEC
+#define SRMMU_PAGE_SHARED_NOEXEC	__pgprot(SRMMU_VALID | SRMMU_CACHE | SRMMU_WRITE | SRMMU_REF)
+#define SRMMU_PAGE_COPY_NOEXEC	__pgprot(SRMMU_VALID | SRMMU_CACHE | SRMMU_REF)
+#define SRMMU_PAGE_RDONLY_NOEXEC	__pgprot(SRMMU_VALID | SRMMU_CACHE | SRMMU_REF)
+#endif
+
 #define SRMMU_PAGE_KERNEL  __pgprot(SRMMU_VALID | SRMMU_CACHE | SRMMU_PRIV | \
 				    SRMMU_DIRTY | SRMMU_REF)
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/spinlock_64.h linux-3.2.71-pax/arch/sparc/include/asm/spinlock_64.h
--- linux-3.2.71/arch/sparc/include/asm/spinlock_64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/spinlock_64.h	2012-07-04 19:24:47.428062988 +0200
@@ -92,14 +92,19 @@ static inline void arch_spin_lock_flags(
 
 /* Multi-reader locks, these are much saner than the 32-bit Sparc ones... */
 
-static void inline arch_read_lock(arch_rwlock_t *lock)
+static inline void arch_read_lock(arch_rwlock_t *lock)
 {
 	unsigned long tmp1, tmp2;
 
 	__asm__ __volatile__ (
 "1:	ldsw		[%2], %0\n"
 "	brlz,pn		%0, 2f\n"
-"4:	 add		%0, 1, %1\n"
+"4:	 addcc		%0, 1, %1\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"	tvs		%%icc, 6\n"
+#endif
+
 "	cas		[%2], %0, %1\n"
 "	cmp		%0, %1\n"
 "	bne,pn		%%icc, 1b\n"
@@ -112,10 +117,10 @@ static void inline arch_read_lock(arch_r
 "	.previous"
 	: "=&r" (tmp1), "=&r" (tmp2)
 	: "r" (lock)
-	: "memory");
+	: "memory", "cc");
 }
 
-static int inline arch_read_trylock(arch_rwlock_t *lock)
+static inline int arch_read_trylock(arch_rwlock_t *lock)
 {
 	int tmp1, tmp2;
 
@@ -123,7 +128,12 @@ static int inline arch_read_trylock(arch
 "1:	ldsw		[%2], %0\n"
 "	brlz,a,pn	%0, 2f\n"
 "	 mov		0, %0\n"
-"	add		%0, 1, %1\n"
+"	addcc		%0, 1, %1\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"	tvs		%%icc, 6\n"
+#endif
+
 "	cas		[%2], %0, %1\n"
 "	cmp		%0, %1\n"
 "	bne,pn		%%icc, 1b\n"
@@ -136,13 +146,18 @@ static int inline arch_read_trylock(arch
 	return tmp1;
 }
 
-static void inline arch_read_unlock(arch_rwlock_t *lock)
+static inline void arch_read_unlock(arch_rwlock_t *lock)
 {
 	unsigned long tmp1, tmp2;
 
 	__asm__ __volatile__(
 "1:	lduw	[%2], %0\n"
-"	sub	%0, 1, %1\n"
+"	subcc	%0, 1, %1\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+"	tvs	%%icc, 6\n"
+#endif
+
 "	cas	[%2], %0, %1\n"
 "	cmp	%0, %1\n"
 "	bne,pn	%%xcc, 1b\n"
@@ -152,7 +167,7 @@ static void inline arch_read_unlock(arch
 	: "memory");
 }
 
-static void inline arch_write_lock(arch_rwlock_t *lock)
+static inline void arch_write_lock(arch_rwlock_t *lock)
 {
 	unsigned long mask, tmp1, tmp2;
 
@@ -177,7 +192,7 @@ static void inline arch_write_lock(arch_
 	: "memory");
 }
 
-static void inline arch_write_unlock(arch_rwlock_t *lock)
+static inline void arch_write_unlock(arch_rwlock_t *lock)
 {
 	__asm__ __volatile__(
 "	stw		%%g0, [%0]"
@@ -186,7 +201,7 @@ static void inline arch_write_unlock(arc
 	: "memory");
 }
 
-static int inline arch_write_trylock(arch_rwlock_t *lock)
+static inline int arch_write_trylock(arch_rwlock_t *lock)
 {
 	unsigned long mask, tmp1, tmp2, result;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/thread_info_32.h linux-3.2.71-pax/arch/sparc/include/asm/thread_info_32.h
--- linux-3.2.71/arch/sparc/include/asm/thread_info_32.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/thread_info_32.h	2012-07-04 19:24:47.428062988 +0200
@@ -50,6 +50,8 @@ struct thread_info {
 	unsigned long		w_saved;
 
 	struct restart_block	restart_block;
+
+	unsigned long		lowest_stack;
 };
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/thread_info_64.h linux-3.2.71-pax/arch/sparc/include/asm/thread_info_64.h
--- linux-3.2.71/arch/sparc/include/asm/thread_info_64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/thread_info_64.h	2012-07-04 19:24:47.428062988 +0200
@@ -63,6 +63,8 @@ struct thread_info {
 	struct pt_regs		*kern_una_regs;
 	unsigned int		kern_una_insn;
 
+	unsigned long		lowest_stack;
+
 	unsigned long		fpregs[0] __attribute__ ((aligned(64)));
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/uaccess_32.h linux-3.2.71-pax/arch/sparc/include/asm/uaccess_32.h
--- linux-3.2.71/arch/sparc/include/asm/uaccess_32.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/uaccess_32.h	2015-04-03 01:50:03.580410342 +0200
@@ -46,6 +46,7 @@
 #define __user_ok(addr, size) ({ (void)(size); (addr) < STACK_TOP; })
 #define __kernel_ok (segment_eq(get_fs(), KERNEL_DS))
 #define __access_ok(addr,size) (__user_ok((addr) & get_fs().seg,(size)))
+#define access_ok_noprefault(type, addr, size) access_ok((type), (addr), (size))
 #define access_ok(type, addr, size)					\
 	({ (void)(type); __access_ok((unsigned long)(addr), size); })
 
@@ -249,27 +250,46 @@ extern unsigned long __copy_user(void __
 
 static inline unsigned long copy_to_user(void __user *to, const void *from, unsigned long n)
 {
-	if (n && __access_ok((unsigned long) to, n))
+	if ((long)n < 0)
+		return n;
+
+	if (n && __access_ok((unsigned long) to, n)) {
+		if (!__builtin_constant_p(n))
+			check_object_size(from, n, true);
 		return __copy_user(to, (__force void __user *) from, n);
-	else
+	} else
 		return n;
 }
 
 static inline unsigned long __copy_to_user(void __user *to, const void *from, unsigned long n)
 {
+	if ((long)n < 0)
+		return n;
+
+	if (!__builtin_constant_p(n))
+		check_object_size(from, n, true);
+
 	return __copy_user(to, (__force void __user *) from, n);
 }
 
 static inline unsigned long copy_from_user(void *to, const void __user *from, unsigned long n)
 {
-	if (n && __access_ok((unsigned long) from, n))
+	if ((long)n < 0)
+		return n;
+
+	if (n && __access_ok((unsigned long) from, n)) {
+		if (!__builtin_constant_p(n))
+			check_object_size(to, n, false);
 		return __copy_user((__force void __user *) to, from, n);
-	else
+	} else
 		return n;
 }
 
 static inline unsigned long __copy_from_user(void *to, const void __user *from, unsigned long n)
 {
+	if ((long)n < 0)
+		return n;
+
 	return __copy_user((__force void __user *) to, from, n);
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/uaccess_64.h linux-3.2.71-pax/arch/sparc/include/asm/uaccess_64.h
--- linux-3.2.71/arch/sparc/include/asm/uaccess_64.h	2014-04-30 18:53:45.056223432 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/uaccess_64.h	2015-04-03 01:50:17.768411113 +0200
@@ -10,6 +10,7 @@
 #include <linux/compiler.h>
 #include <linux/string.h>
 #include <linux/thread_info.h>
+#include <linux/kernel.h>
 #include <asm/asi.h>
 #include <asm/system.h>
 #include <asm/spitfire.h>
@@ -53,6 +54,11 @@ static inline int __access_ok(const void
 	return 1;
 }
 
+static inline int access_ok_noprefault(int type, const void __user * addr, unsigned long size)
+{
+	return 1;
+}
+
 static inline int access_ok(int type, const void __user * addr, unsigned long size)
 {
 	return 1;
@@ -213,8 +219,15 @@ extern unsigned long copy_from_user_fixu
 static inline unsigned long __must_check
 copy_from_user(void *to, const void __user *from, unsigned long size)
 {
-	unsigned long ret = ___copy_from_user(to, from, size);
+	unsigned long ret;
 
+	if ((long)size < 0 || size > INT_MAX)
+		return size;
+
+	if (!__builtin_constant_p(size))
+		check_object_size(to, size, false);
+
+	ret = ___copy_from_user(to, from, size);
 	if (unlikely(ret))
 		ret = copy_from_user_fixup(to, from, size);
 
@@ -230,8 +243,15 @@ extern unsigned long copy_to_user_fixup(
 static inline unsigned long __must_check
 copy_to_user(void __user *to, const void *from, unsigned long size)
 {
-	unsigned long ret = ___copy_to_user(to, from, size);
+	unsigned long ret;
+
+	if ((long)size < 0 || size > INT_MAX)
+		return size;
+
+	if (!__builtin_constant_p(size))
+		check_object_size(from, size, true);
 
+	ret = ___copy_to_user(to, from, size);
 	if (unlikely(ret))
 		ret = copy_to_user_fixup(to, from, size);
 	return ret;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/include/asm/uaccess.h linux-3.2.71-pax/arch/sparc/include/asm/uaccess.h
--- linux-3.2.71/arch/sparc/include/asm/uaccess.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/include/asm/uaccess.h	2013-04-09 01:05:28.445748689 +0200
@@ -1,5 +1,6 @@
 #ifndef ___ASM_SPARC_UACCESS_H
 #define ___ASM_SPARC_UACCESS_H
+
 #if defined(__sparc__) && defined(__arch64__)
 #include <asm/uaccess_64.h>
 #else
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/kernel/Makefile linux-3.2.71-pax/arch/sparc/kernel/Makefile
--- linux-3.2.71/arch/sparc/kernel/Makefile	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/kernel/Makefile	2012-07-04 19:24:47.432063007 +0200
@@ -3,7 +3,7 @@
 #
 
 asflags-y := -ansi
-ccflags-y := -Werror
+#ccflags-y := -Werror
 
 extra-y     := head_$(BITS).o
 extra-y     += init_task.o
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/kernel/prom_common.c linux-3.2.71-pax/arch/sparc/kernel/prom_common.c
--- linux-3.2.71/arch/sparc/kernel/prom_common.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/kernel/prom_common.c	2013-04-09 01:05:28.449748689 +0200
@@ -144,7 +144,7 @@ static int __init prom_common_nextprop(p
 
 unsigned int prom_early_allocated __initdata;
 
-static struct of_pdt_ops prom_sparc_ops __initdata = {
+static struct of_pdt_ops prom_sparc_ops __initconst = {
 	.nextprop = prom_common_nextprop,
 	.getproplen = prom_getproplen,
 	.getproperty = prom_getproperty,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/kernel/smp_64.c linux-3.2.71-pax/arch/sparc/kernel/smp_64.c
--- linux-3.2.71/arch/sparc/kernel/smp_64.c	2014-09-14 14:10:57.914117119 +0200
+++ linux-3.2.71-pax/arch/sparc/kernel/smp_64.c	2014-09-14 14:11:25.862138280 +0200
@@ -871,8 +871,8 @@ extern unsigned long xcall_flush_dcache_
 extern unsigned long xcall_flush_dcache_page_spitfire;
 
 #ifdef CONFIG_DEBUG_DCFLUSH
-extern atomic_t dcpage_flushes;
-extern atomic_t dcpage_flushes_xcall;
+extern atomic_unchecked_t dcpage_flushes;
+extern atomic_unchecked_t dcpage_flushes_xcall;
 #endif
 
 static inline void __local_flush_dcache_page(struct page *page)
@@ -896,7 +896,7 @@ void smp_flush_dcache_page_impl(struct p
 		return;
 
 #ifdef CONFIG_DEBUG_DCFLUSH
-	atomic_inc(&dcpage_flushes);
+	atomic_inc_unchecked(&dcpage_flushes);
 #endif
 
 	this_cpu = get_cpu();
@@ -920,7 +920,7 @@ void smp_flush_dcache_page_impl(struct p
 			xcall_deliver(data0, __pa(pg_addr),
 				      (u64) pg_addr, cpumask_of(cpu));
 #ifdef CONFIG_DEBUG_DCFLUSH
-			atomic_inc(&dcpage_flushes_xcall);
+			atomic_inc_unchecked(&dcpage_flushes_xcall);
 #endif
 		}
 	}
@@ -939,7 +939,7 @@ void flush_dcache_page_all(struct mm_str
 	preempt_disable();
 
 #ifdef CONFIG_DEBUG_DCFLUSH
-	atomic_inc(&dcpage_flushes);
+	atomic_inc_unchecked(&dcpage_flushes);
 #endif
 	data0 = 0;
 	pg_addr = page_address(page);
@@ -956,7 +956,7 @@ void flush_dcache_page_all(struct mm_str
 		xcall_deliver(data0, __pa(pg_addr),
 			      (u64) pg_addr, cpu_online_mask);
 #ifdef CONFIG_DEBUG_DCFLUSH
-		atomic_inc(&dcpage_flushes_xcall);
+		atomic_inc_unchecked(&dcpage_flushes_xcall);
 #endif
 	}
 	__local_flush_dcache_page(page);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/kernel/sysfs.c linux-3.2.71-pax/arch/sparc/kernel/sysfs.c
--- linux-3.2.71/arch/sparc/kernel/sysfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/kernel/sysfs.c	2013-02-20 01:19:15.014027369 +0100
@@ -266,7 +266,7 @@ static int __cpuinit sysfs_cpu_notify(st
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata sysfs_cpu_nb = {
+static struct notifier_block sysfs_cpu_nb = {
 	.notifier_call	= sysfs_cpu_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/kernel/sys_sparc_32.c linux-3.2.71-pax/arch/sparc/kernel/sys_sparc_32.c
--- linux-3.2.71/arch/sparc/kernel/sys_sparc_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/kernel/sys_sparc_32.c	2013-07-05 02:11:12.001206944 +0200
@@ -56,7 +56,7 @@ unsigned long arch_get_unmapped_area(str
 	if (ARCH_SUN4C && len > 0x20000000)
 		return -ENOMEM;
 	if (!addr)
-		addr = TASK_UNMAPPED_BASE;
+		addr = current->mm->mmap_base;
 
 	if (flags & MAP_SHARED)
 		addr = COLOUR_ALIGN(addr);
@@ -71,7 +71,7 @@ unsigned long arch_get_unmapped_area(str
 		}
 		if (TASK_SIZE - PAGE_SIZE - len < addr)
 			return -ENOMEM;
-		if (!vmm || addr + len <= vmm->vm_start)
+		if (check_heap_stack_gap(vmm, &addr, len))
 			return addr;
 		addr = vmm->vm_end;
 		if (flags & MAP_SHARED)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/kernel/sys_sparc_64.c linux-3.2.71-pax/arch/sparc/kernel/sys_sparc_64.c
--- linux-3.2.71/arch/sparc/kernel/sys_sparc_64.c	2015-08-07 11:37:20.371789888 +0200
+++ linux-3.2.71-pax/arch/sparc/kernel/sys_sparc_64.c	2015-08-07 11:37:42.991790553 +0200
@@ -124,7 +124,7 @@ unsigned long arch_get_unmapped_area(str
 		/* We do not accept a shared mapping if it would violate
 		 * cache aliasing constraints.
 		 */
-		if ((flags & MAP_SHARED) &&
+		if ((filp || (flags & MAP_SHARED)) &&
 		    ((addr - (pgoff << PAGE_SHIFT)) & (SHMLBA - 1)))
 			return -EINVAL;
 		return addr;
@@ -139,6 +139,10 @@ unsigned long arch_get_unmapped_area(str
 	if (filp || (flags & MAP_SHARED))
 		do_color_align = 1;
 
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	if (addr) {
 		if (do_color_align)
 			addr = COLOUR_ALIGN(addr, pgoff);
@@ -146,15 +150,14 @@ unsigned long arch_get_unmapped_area(str
 			addr = PAGE_ALIGN(addr);
 
 		vma = find_vma(mm, addr);
-		if (task_size - len >= addr &&
-		    (!vma || addr + len <= vma->vm_start))
+		if (task_size - len >= addr && check_heap_stack_gap(vma, &addr, len))
 			return addr;
 	}
 
 	if (len > mm->cached_hole_size) {
-	        start_addr = addr = mm->free_area_cache;
+		start_addr = addr = mm->free_area_cache;
 	} else {
-	        start_addr = addr = TASK_UNMAPPED_BASE;
+		start_addr = addr = mm->mmap_base;
 	        mm->cached_hole_size = 0;
 	}
 
@@ -174,14 +177,14 @@ full_search:
 			vma = find_vma(mm, VA_EXCLUDE_END);
 		}
 		if (unlikely(task_size < addr)) {
-			if (start_addr != TASK_UNMAPPED_BASE) {
-				start_addr = addr = TASK_UNMAPPED_BASE;
+			if (start_addr != mm->mmap_base) {
+				start_addr = addr = mm->mmap_base;
 				mm->cached_hole_size = 0;
 				goto full_search;
 			}
 			return -ENOMEM;
 		}
-		if (likely(!vma || addr + len <= vma->vm_start)) {
+		if (likely(check_heap_stack_gap(vma, &addr, len))) {
 			/*
 			 * Remember the place where we stopped the search:
 			 */
@@ -215,7 +218,7 @@ arch_get_unmapped_area_topdown(struct fi
 		/* We do not accept a shared mapping if it would violate
 		 * cache aliasing constraints.
 		 */
-		if ((flags & MAP_SHARED) &&
+		if ((filp || (flags & MAP_SHARED)) &&
 		    ((addr - (pgoff << PAGE_SHIFT)) & (SHMLBA - 1)))
 			return -EINVAL;
 		return addr;
@@ -236,8 +239,7 @@ arch_get_unmapped_area_topdown(struct fi
 			addr = PAGE_ALIGN(addr);
 
 		vma = find_vma(mm, addr);
-		if (task_size - len >= addr &&
-		    (!vma || addr + len <= vma->vm_start))
+		if (task_size - len >= addr && check_heap_stack_gap(vma, &addr, len))
 			return addr;
 	}
 
@@ -257,28 +259,29 @@ arch_get_unmapped_area_topdown(struct fi
 
 	/* make sure it can fit in the remaining address space */
 	if (likely(addr > len)) {
-		vma = find_vma(mm, addr-len);
-		if (!vma || addr <= vma->vm_start) {
+		addr -= len;
+		vma = find_vma(mm, addr);
+		if (check_heap_stack_gap(vma, &addr, len)) {
 			/* remember the address as a hint for next time */
-			return (mm->free_area_cache = addr-len);
+			return (mm->free_area_cache = addr);
 		}
 	}
 
 	if (unlikely(mm->mmap_base < len))
 		goto bottomup;
 
-	addr = mm->mmap_base-len;
-	if (do_color_align)
-		addr = COLOUR_ALIGN_DOWN(addr, pgoff);
+	addr = mm->mmap_base - len;
 
 	do {
+		if (do_color_align)
+			addr = COLOUR_ALIGN_DOWN(addr, pgoff);
 		/*
 		 * Lookup failure means no vma is above this address,
 		 * else if new region fits below vma->vm_start,
 		 * return with success:
 		 */
 		vma = find_vma(mm, addr);
-		if (likely(!vma || addr+len <= vma->vm_start)) {
+		if (likely(check_heap_stack_gap(vma, &addr, len))) {
 			/* remember the address as a hint for next time */
 			return (mm->free_area_cache = addr);
 		}
@@ -288,10 +291,8 @@ arch_get_unmapped_area_topdown(struct fi
  		        mm->cached_hole_size = vma->vm_start - addr;
 
 		/* try just below the current vma->vm_start */
-		addr = vma->vm_start-len;
-		if (do_color_align)
-			addr = COLOUR_ALIGN_DOWN(addr, pgoff);
-	} while (likely(len < vma->vm_start));
+		addr = skip_heap_stack_gap(vma, len);
+	} while (!IS_ERR_VALUE(addr));
 
 bottomup:
 	/*
@@ -361,10 +362,14 @@ unsigned long get_fb_unmapped_area(struc
 EXPORT_SYMBOL(get_fb_unmapped_area);
 
 /* Essentially the same as PowerPC.  */
-static unsigned long mmap_rnd(void)
+static unsigned long mmap_rnd(struct mm_struct *mm)
 {
 	unsigned long rnd = 0UL;
 
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	if (current->flags & PF_RANDOMIZE) {
 		unsigned long val = get_random_int();
 		if (test_thread_flag(TIF_32BIT))
@@ -377,7 +382,7 @@ static unsigned long mmap_rnd(void)
 
 void arch_pick_mmap_layout(struct mm_struct *mm)
 {
-	unsigned long random_factor = mmap_rnd();
+	unsigned long random_factor = mmap_rnd(mm);
 	unsigned long gap;
 
 	/*
@@ -390,6 +395,12 @@ void arch_pick_mmap_layout(struct mm_str
 	    gap == RLIM_INFINITY ||
 	    sysctl_legacy_va_layout) {
 		mm->mmap_base = TASK_UNMAPPED_BASE + random_factor;
+
+#ifdef CONFIG_PAX_RANDMMAP
+		if (mm->pax_flags & MF_PAX_RANDMMAP)
+			mm->mmap_base += mm->delta_mmap;
+#endif
+
 		mm->get_unmapped_area = arch_get_unmapped_area;
 		mm->unmap_area = arch_unmap_area;
 	} else {
@@ -402,6 +413,12 @@ void arch_pick_mmap_layout(struct mm_str
 			gap = (task_size / 6 * 5);
 
 		mm->mmap_base = PAGE_ALIGN(task_size - gap - random_factor);
+
+#ifdef CONFIG_PAX_RANDMMAP
+		if (mm->pax_flags & MF_PAX_RANDMMAP)
+			mm->mmap_base -= mm->delta_mmap + mm->delta_stack;
+#endif
+
 		mm->get_unmapped_area = arch_get_unmapped_area_topdown;
 		mm->unmap_area = arch_unmap_area_topdown;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/kernel/traps_64.c linux-3.2.71-pax/arch/sparc/kernel/traps_64.c
--- linux-3.2.71/arch/sparc/kernel/traps_64.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/kernel/traps_64.c	2013-08-31 16:23:51.470033007 +0200
@@ -95,6 +95,12 @@ void bad_trap(struct pt_regs *regs, long
 
 	lvl -= 0x100;
 	if (regs->tstate & TSTATE_PRIV) {
+
+#ifdef CONFIG_PAX_REFCOUNT
+		if (lvl == 6)
+			pax_report_refcount_overflow(regs);
+#endif
+
 		sprintf(buffer, "Kernel bad sw trap %lx", lvl);
 		die_if_kernel(buffer, regs);
 	}
@@ -113,11 +119,16 @@ void bad_trap(struct pt_regs *regs, long
 void bad_trap_tl1(struct pt_regs *regs, long lvl)
 {
 	char buffer[32];
-	
+
 	if (notify_die(DIE_TRAP_TL1, "bad trap tl1", regs,
 		       0, lvl, SIGTRAP) == NOTIFY_STOP)
 		return;
 
+#ifdef CONFIG_PAX_REFCOUNT
+	if (lvl == 6)
+		pax_report_refcount_overflow(regs);
+#endif
+
 	dump_tl1_traplog((struct tl1_traplog *)(regs + 1));
 
 	sprintf (buffer, "Bad trap %lx at tl>0", lvl);
@@ -1786,8 +1797,8 @@ struct sun4v_error_entry {
 	u16		err_pad;
 };
 
-static atomic_t sun4v_resum_oflow_cnt = ATOMIC_INIT(0);
-static atomic_t sun4v_nonresum_oflow_cnt = ATOMIC_INIT(0);
+static atomic_unchecked_t sun4v_resum_oflow_cnt = ATOMIC_INIT(0);
+static atomic_unchecked_t sun4v_nonresum_oflow_cnt = ATOMIC_INIT(0);
 
 static const char *sun4v_err_type_to_str(u32 type)
 {
@@ -1807,7 +1818,7 @@ static const char *sun4v_err_type_to_str
 	}
 }
 
-static void sun4v_log_error(struct pt_regs *regs, struct sun4v_error_entry *ent, int cpu, const char *pfx, atomic_t *ocnt)
+static void sun4v_log_error(struct pt_regs *regs, struct sun4v_error_entry *ent, int cpu, const char *pfx, atomic_unchecked_t *ocnt)
 {
 	int cnt;
 
@@ -1842,8 +1853,8 @@ static void sun4v_log_error(struct pt_re
 
 	show_regs(regs);
 
-	if ((cnt = atomic_read(ocnt)) != 0) {
-		atomic_set(ocnt, 0);
+	if ((cnt = atomic_read_unchecked(ocnt)) != 0) {
+		atomic_set_unchecked(ocnt, 0);
 		wmb();
 		printk("%s: Queue overflowed %d times.\n",
 		       pfx, cnt);
@@ -1895,7 +1906,7 @@ void sun4v_resum_error(struct pt_regs *r
  */
 void sun4v_resum_overflow(struct pt_regs *regs)
 {
-	atomic_inc(&sun4v_resum_oflow_cnt);
+	atomic_inc_unchecked(&sun4v_resum_oflow_cnt);
 }
 
 /* We run with %pil set to PIL_NORMAL_MAX and PSTATE_IE enabled in %pstate.
@@ -1948,7 +1959,7 @@ void sun4v_nonresum_overflow(struct pt_r
 	/* XXX Actually even this can make not that much sense.  Perhaps
 	 * XXX we should just pull the plug and panic directly from here?
 	 */
-	atomic_inc(&sun4v_nonresum_oflow_cnt);
+	atomic_inc_unchecked(&sun4v_nonresum_oflow_cnt);
 }
 
 unsigned long sun4v_err_itlb_vaddr;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/kernel/us3_cpufreq.c linux-3.2.71-pax/arch/sparc/kernel/us3_cpufreq.c
--- linux-3.2.71/arch/sparc/kernel/us3_cpufreq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/kernel/us3_cpufreq.c	2013-05-10 01:14:35.699930484 +0200
@@ -18,14 +18,12 @@
 #include <asm/head.h>
 #include <asm/timer.h>
 
-static struct cpufreq_driver *cpufreq_us3_driver;
-
 struct us3_freq_percpu_info {
 	struct cpufreq_frequency_table table[4];
 };
 
 /* Indexed by cpu number. */
-static struct us3_freq_percpu_info *us3_freq_table;
+static struct us3_freq_percpu_info us3_freq_table[NR_CPUS];
 
 /* UltraSPARC-III has three dividers: 1, 2, and 32.  These are controlled
  * in the Safari config register.
@@ -191,12 +189,25 @@ static int __init us3_freq_cpu_init(stru
 
 static int us3_freq_cpu_exit(struct cpufreq_policy *policy)
 {
-	if (cpufreq_us3_driver)
-		us3_set_cpu_divider_index(policy->cpu, 0);
+	us3_set_cpu_divider_index(policy->cpu, 0);
 
 	return 0;
 }
 
+static int __init us3_freq_init(void);
+static void __exit us3_freq_exit(void);
+
+static struct cpufreq_driver cpufreq_us3_driver = {
+	.init	= us3_freq_cpu_init,
+	.verify	= us3_freq_verify,
+	.target	= us3_freq_target,
+	.get	= us3_freq_get,
+	.exit	= us3_freq_cpu_exit,
+	.owner	= THIS_MODULE,
+	.name	= "UltraSPARC-III",
+
+};
+
 static int __init us3_freq_init(void)
 {
 	unsigned long manuf, impl, ver;
@@ -213,57 +224,15 @@ static int __init us3_freq_init(void)
 	    (impl == CHEETAH_IMPL ||
 	     impl == CHEETAH_PLUS_IMPL ||
 	     impl == JAGUAR_IMPL ||
-	     impl == PANTHER_IMPL)) {
-		struct cpufreq_driver *driver;
-
-		ret = -ENOMEM;
-		driver = kzalloc(sizeof(struct cpufreq_driver), GFP_KERNEL);
-		if (!driver)
-			goto err_out;
-
-		us3_freq_table = kzalloc(
-			(NR_CPUS * sizeof(struct us3_freq_percpu_info)),
-			GFP_KERNEL);
-		if (!us3_freq_table)
-			goto err_out;
-
-		driver->init = us3_freq_cpu_init;
-		driver->verify = us3_freq_verify;
-		driver->target = us3_freq_target;
-		driver->get = us3_freq_get;
-		driver->exit = us3_freq_cpu_exit;
-		driver->owner = THIS_MODULE,
-		strcpy(driver->name, "UltraSPARC-III");
-
-		cpufreq_us3_driver = driver;
-		ret = cpufreq_register_driver(driver);
-		if (ret)
-			goto err_out;
-
-		return 0;
-
-err_out:
-		if (driver) {
-			kfree(driver);
-			cpufreq_us3_driver = NULL;
-		}
-		kfree(us3_freq_table);
-		us3_freq_table = NULL;
-		return ret;
-	}
+	     impl == PANTHER_IMPL))
+		return cpufreq_register_driver(&cpufreq_us3_driver);
 
 	return -ENODEV;
 }
 
 static void __exit us3_freq_exit(void)
 {
-	if (cpufreq_us3_driver) {
-		cpufreq_unregister_driver(cpufreq_us3_driver);
-		kfree(cpufreq_us3_driver);
-		cpufreq_us3_driver = NULL;
-		kfree(us3_freq_table);
-		us3_freq_table = NULL;
-	}
+	cpufreq_unregister_driver(&cpufreq_us3_driver);
 }
 
 MODULE_AUTHOR("David S. Miller <davem@redhat.com>");
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/lib/atomic_64.S linux-3.2.71-pax/arch/sparc/lib/atomic_64.S
--- linux-3.2.71/arch/sparc/lib/atomic_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/lib/atomic_64.S	2012-07-04 19:24:47.436063014 +0200
@@ -18,7 +18,12 @@
 atomic_add: /* %o0 = increment, %o1 = atomic_ptr */
 	BACKOFF_SETUP(%o2)
 1:	lduw	[%o1], %g1
-	add	%g1, %o0, %g7
+	addcc	%g1, %o0, %g7
+
+#ifdef CONFIG_PAX_REFCOUNT
+	tvs	%icc, 6
+#endif
+
 	cas	[%o1], %g1, %g7
 	cmp	%g1, %g7
 	bne,pn	%icc, BACKOFF_LABEL(2f, 1b)
@@ -28,12 +33,32 @@ atomic_add: /* %o0 = increment, %o1 = at
 2:	BACKOFF_SPIN(%o2, %o3, 1b)
 	.size	atomic_add, .-atomic_add
 
+	.globl	atomic_add_unchecked
+	.type	atomic_add_unchecked,#function
+atomic_add_unchecked: /* %o0 = increment, %o1 = atomic_ptr */
+	BACKOFF_SETUP(%o2)
+1:	lduw	[%o1], %g1
+	add	%g1, %o0, %g7
+	cas	[%o1], %g1, %g7
+	cmp	%g1, %g7
+	bne,pn	%icc, 2f
+	 nop
+	retl
+	 nop
+2:	BACKOFF_SPIN(%o2, %o3, 1b)
+	.size	atomic_add_unchecked, .-atomic_add_unchecked
+
 	.globl	atomic_sub
 	.type	atomic_sub,#function
 atomic_sub: /* %o0 = decrement, %o1 = atomic_ptr */
 	BACKOFF_SETUP(%o2)
 1:	lduw	[%o1], %g1
-	sub	%g1, %o0, %g7
+	subcc	%g1, %o0, %g7
+
+#ifdef CONFIG_PAX_REFCOUNT
+	tvs	%icc, 6
+#endif
+
 	cas	[%o1], %g1, %g7
 	cmp	%g1, %g7
 	bne,pn	%icc, BACKOFF_LABEL(2f, 1b)
@@ -43,12 +68,32 @@ atomic_sub: /* %o0 = decrement, %o1 = at
 2:	BACKOFF_SPIN(%o2, %o3, 1b)
 	.size	atomic_sub, .-atomic_sub
 
+	.globl	atomic_sub_unchecked
+	.type	atomic_sub_unchecked,#function
+atomic_sub_unchecked: /* %o0 = decrement, %o1 = atomic_ptr */
+	BACKOFF_SETUP(%o2)
+1:	lduw	[%o1], %g1
+	sub	%g1, %o0, %g7
+	cas	[%o1], %g1, %g7
+	cmp	%g1, %g7
+	bne,pn	%icc, 2f
+	 nop
+	retl
+	 nop
+2:	BACKOFF_SPIN(%o2, %o3, 1b)
+	.size	atomic_sub_unchecked, .-atomic_sub_unchecked
+
 	.globl	atomic_add_ret
 	.type	atomic_add_ret,#function
 atomic_add_ret: /* %o0 = increment, %o1 = atomic_ptr */
 	BACKOFF_SETUP(%o2)
 1:	lduw	[%o1], %g1
-	add	%g1, %o0, %g7
+	addcc	%g1, %o0, %g7
+
+#ifdef CONFIG_PAX_REFCOUNT
+	tvs	%icc, 6
+#endif
+
 	cas	[%o1], %g1, %g7
 	cmp	%g1, %g7
 	bne,pn	%icc, BACKOFF_LABEL(2f, 1b)
@@ -58,12 +103,33 @@ atomic_add_ret: /* %o0 = increment, %o1
 2:	BACKOFF_SPIN(%o2, %o3, 1b)
 	.size	atomic_add_ret, .-atomic_add_ret
 
+	.globl	atomic_add_ret_unchecked
+	.type	atomic_add_ret_unchecked,#function
+atomic_add_ret_unchecked: /* %o0 = increment, %o1 = atomic_ptr */
+	BACKOFF_SETUP(%o2)
+1:	lduw	[%o1], %g1
+	addcc	%g1, %o0, %g7
+	cas	[%o1], %g1, %g7
+	cmp	%g1, %g7
+	bne,pn	%icc, 2f
+	 add	%g7, %o0, %g7
+	sra	%g7, 0, %o0
+	retl
+	 nop
+2:	BACKOFF_SPIN(%o2, %o3, 1b)
+	.size	atomic_add_ret_unchecked, .-atomic_add_ret_unchecked
+
 	.globl	atomic_sub_ret
 	.type	atomic_sub_ret,#function
 atomic_sub_ret: /* %o0 = decrement, %o1 = atomic_ptr */
 	BACKOFF_SETUP(%o2)
 1:	lduw	[%o1], %g1
-	sub	%g1, %o0, %g7
+	subcc	%g1, %o0, %g7
+
+#ifdef CONFIG_PAX_REFCOUNT
+	tvs	%icc, 6
+#endif
+
 	cas	[%o1], %g1, %g7
 	cmp	%g1, %g7
 	bne,pn	%icc, BACKOFF_LABEL(2f, 1b)
@@ -78,7 +144,12 @@ atomic_sub_ret: /* %o0 = decrement, %o1
 atomic64_add: /* %o0 = increment, %o1 = atomic_ptr */
 	BACKOFF_SETUP(%o2)
 1:	ldx	[%o1], %g1
-	add	%g1, %o0, %g7
+	addcc	%g1, %o0, %g7
+
+#ifdef CONFIG_PAX_REFCOUNT
+	tvs	%xcc, 6
+#endif
+
 	casx	[%o1], %g1, %g7
 	cmp	%g1, %g7
 	bne,pn	%xcc, BACKOFF_LABEL(2f, 1b)
@@ -88,12 +159,32 @@ atomic64_add: /* %o0 = increment, %o1 =
 2:	BACKOFF_SPIN(%o2, %o3, 1b)
 	.size	atomic64_add, .-atomic64_add
 
+	.globl	atomic64_add_unchecked
+	.type	atomic64_add_unchecked,#function
+atomic64_add_unchecked: /* %o0 = increment, %o1 = atomic_ptr */
+	BACKOFF_SETUP(%o2)
+1:	ldx	[%o1], %g1
+	addcc	%g1, %o0, %g7
+	casx	[%o1], %g1, %g7
+	cmp	%g1, %g7
+	bne,pn	%xcc, 2f
+	 nop
+	retl
+	 nop
+2:	BACKOFF_SPIN(%o2, %o3, 1b)
+	.size	atomic64_add_unchecked, .-atomic64_add_unchecked
+
 	.globl	atomic64_sub
 	.type	atomic64_sub,#function
 atomic64_sub: /* %o0 = decrement, %o1 = atomic_ptr */
 	BACKOFF_SETUP(%o2)
 1:	ldx	[%o1], %g1
-	sub	%g1, %o0, %g7
+	subcc	%g1, %o0, %g7
+
+#ifdef CONFIG_PAX_REFCOUNT
+	tvs	%xcc, 6
+#endif
+
 	casx	[%o1], %g1, %g7
 	cmp	%g1, %g7
 	bne,pn	%xcc, BACKOFF_LABEL(2f, 1b)
@@ -103,12 +194,32 @@ atomic64_sub: /* %o0 = decrement, %o1 =
 2:	BACKOFF_SPIN(%o2, %o3, 1b)
 	.size	atomic64_sub, .-atomic64_sub
 
+	.globl	atomic64_sub_unchecked
+	.type	atomic64_sub_unchecked,#function
+atomic64_sub_unchecked: /* %o0 = decrement, %o1 = atomic_ptr */
+	BACKOFF_SETUP(%o2)
+1:	ldx	[%o1], %g1
+	subcc	%g1, %o0, %g7
+	casx	[%o1], %g1, %g7
+	cmp	%g1, %g7
+	bne,pn	%xcc, 2f
+	 nop
+	retl
+	 nop
+2:	BACKOFF_SPIN(%o2, %o3, 1b)
+	.size	atomic64_sub_unchecked, .-atomic64_sub_unchecked
+
 	.globl	atomic64_add_ret
 	.type	atomic64_add_ret,#function
 atomic64_add_ret: /* %o0 = increment, %o1 = atomic_ptr */
 	BACKOFF_SETUP(%o2)
 1:	ldx	[%o1], %g1
-	add	%g1, %o0, %g7
+	addcc	%g1, %o0, %g7
+
+#ifdef CONFIG_PAX_REFCOUNT
+	tvs	%xcc, 6
+#endif
+
 	casx	[%o1], %g1, %g7
 	cmp	%g1, %g7
 	bne,pn	%xcc, BACKOFF_LABEL(2f, 1b)
@@ -118,12 +229,33 @@ atomic64_add_ret: /* %o0 = increment, %o
 2:	BACKOFF_SPIN(%o2, %o3, 1b)
 	.size	atomic64_add_ret, .-atomic64_add_ret
 
+	.globl	atomic64_add_ret_unchecked
+	.type	atomic64_add_ret_unchecked,#function
+atomic64_add_ret_unchecked: /* %o0 = increment, %o1 = atomic_ptr */
+	BACKOFF_SETUP(%o2)
+1:	ldx	[%o1], %g1
+	addcc	%g1, %o0, %g7
+	casx	[%o1], %g1, %g7
+	cmp	%g1, %g7
+	bne,pn	%xcc, 2f
+	 add	%g7, %o0, %g7
+	mov	%g7, %o0
+	retl
+	 nop
+2:	BACKOFF_SPIN(%o2, %o3, 1b)
+	.size	atomic64_add_ret_unchecked, .-atomic64_add_ret_unchecked
+
 	.globl	atomic64_sub_ret
 	.type	atomic64_sub_ret,#function
 atomic64_sub_ret: /* %o0 = decrement, %o1 = atomic_ptr */
 	BACKOFF_SETUP(%o2)
 1:	ldx	[%o1], %g1
-	sub	%g1, %o0, %g7
+	subcc	%g1, %o0, %g7
+
+#ifdef CONFIG_PAX_REFCOUNT
+	tvs	%xcc, 6
+#endif
+
 	casx	[%o1], %g1, %g7
 	cmp	%g1, %g7
 	bne,pn	%xcc, BACKOFF_LABEL(2f, 1b)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/lib/ksyms.c linux-3.2.71-pax/arch/sparc/lib/ksyms.c
--- linux-3.2.71/arch/sparc/lib/ksyms.c	2013-10-27 17:59:56.492642425 +0100
+++ linux-3.2.71-pax/arch/sparc/lib/ksyms.c	2013-10-27 18:01:10.084638496 +0100
@@ -133,12 +133,18 @@ EXPORT_SYMBOL(__clear_user);
 
 /* Atomic counter implementation. */
 EXPORT_SYMBOL(atomic_add);
+EXPORT_SYMBOL(atomic_add_unchecked);
 EXPORT_SYMBOL(atomic_add_ret);
+EXPORT_SYMBOL(atomic_add_ret_unchecked);
 EXPORT_SYMBOL(atomic_sub);
+EXPORT_SYMBOL(atomic_sub_unchecked);
 EXPORT_SYMBOL(atomic_sub_ret);
 EXPORT_SYMBOL(atomic64_add);
+EXPORT_SYMBOL(atomic64_add_unchecked);
 EXPORT_SYMBOL(atomic64_add_ret);
+EXPORT_SYMBOL(atomic64_add_ret_unchecked);
 EXPORT_SYMBOL(atomic64_sub);
+EXPORT_SYMBOL(atomic64_sub_unchecked);
 EXPORT_SYMBOL(atomic64_sub_ret);
 
 /* Atomic bit operations. */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/lib/Makefile linux-3.2.71-pax/arch/sparc/lib/Makefile
--- linux-3.2.71/arch/sparc/lib/Makefile	2013-09-10 17:24:55.281739129 +0200
+++ linux-3.2.71-pax/arch/sparc/lib/Makefile	2013-09-10 17:24:58.993738931 +0200
@@ -2,7 +2,7 @@
 #
 
 asflags-y := -ansi -DST_DIV0=0x02
-ccflags-y := -Werror
+#ccflags-y := -Werror
 
 lib-$(CONFIG_SPARC32) += mul.o rem.o sdiv.o udiv.o umul.o urem.o ashrdi3.o
 lib-$(CONFIG_SPARC32) += memcpy.o memset.o
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/mm/fault_32.c linux-3.2.71-pax/arch/sparc/mm/fault_32.c
--- linux-3.2.71/arch/sparc/mm/fault_32.c	2015-02-20 12:37:32.961178782 +0100
+++ linux-3.2.71-pax/arch/sparc/mm/fault_32.c	2015-02-20 12:37:41.821178309 +0100
@@ -21,6 +21,9 @@
 #include <linux/perf_event.h>
 #include <linux/interrupt.h>
 #include <linux/kdebug.h>
+#include <linux/slab.h>
+#include <linux/pagemap.h>
+#include <linux/compiler.h>
 
 #include <asm/system.h>
 #include <asm/page.h>
@@ -208,6 +211,277 @@ static unsigned long compute_si_addr(str
 	return safe_compute_effective_address(regs, insn);
 }
 
+#ifdef CONFIG_PAX_PAGEEXEC
+#ifdef CONFIG_PAX_DLRESOLVE
+static void pax_emuplt_close(struct vm_area_struct *vma)
+{
+	vma->vm_mm->call_dl_resolve = 0UL;
+}
+
+static int pax_emuplt_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
+{
+	unsigned int *kaddr;
+
+	vmf->page = alloc_page(GFP_HIGHUSER);
+	if (!vmf->page)
+		return VM_FAULT_OOM;
+
+	kaddr = kmap(vmf->page);
+	memset(kaddr, 0, PAGE_SIZE);
+	kaddr[0] = 0x9DE3BFA8U; /* save */
+	flush_dcache_page(vmf->page);
+	kunmap(vmf->page);
+	return VM_FAULT_MAJOR;
+}
+
+static const struct vm_operations_struct pax_vm_ops = {
+	.close = pax_emuplt_close,
+	.fault = pax_emuplt_fault
+};
+
+static int pax_insert_vma(struct vm_area_struct *vma, unsigned long addr)
+{
+	int ret;
+
+	INIT_LIST_HEAD(&vma->anon_vma_chain);
+	vma->vm_mm = current->mm;
+	vma->vm_start = addr;
+	vma->vm_end = addr + PAGE_SIZE;
+	vma->vm_flags = VM_READ | VM_EXEC | VM_MAYREAD | VM_MAYEXEC;
+	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
+	vma->vm_ops = &pax_vm_ops;
+
+	ret = insert_vm_struct(current->mm, vma);
+	if (ret)
+		return ret;
+
+	++current->mm->total_vm;
+	return 0;
+}
+#endif
+
+/*
+ * PaX: decide what to do with offenders (regs->pc = fault address)
+ *
+ * returns 1 when task should be killed
+ *         2 when patched PLT trampoline was detected
+ *         3 when unpatched PLT trampoline was detected
+ */
+static int pax_handle_fetch_fault(struct pt_regs *regs)
+{
+
+#ifdef CONFIG_PAX_EMUPLT
+	int err;
+
+	do { /* PaX: patched PLT emulation #1 */
+		unsigned int sethi1, sethi2, jmpl;
+
+		err = get_user(sethi1, (unsigned int *)regs->pc);
+		err |= get_user(sethi2, (unsigned int *)(regs->pc+4));
+		err |= get_user(jmpl, (unsigned int *)(regs->pc+8));
+
+		if (err)
+			break;
+
+		if ((sethi1 & 0xFFC00000U) == 0x03000000U &&
+		    (sethi2 & 0xFFC00000U) == 0x03000000U &&
+		    (jmpl & 0xFFFFE000U) == 0x81C06000U)
+		{
+			unsigned int addr;
+
+			regs->u_regs[UREG_G1] = (sethi2 & 0x003FFFFFU) << 10;
+			addr = regs->u_regs[UREG_G1];
+			addr += (((jmpl | 0xFFFFE000U) ^ 0x00001000U) + 0x00001000U);
+			regs->pc = addr;
+			regs->npc = addr+4;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: patched PLT emulation #2 */
+		unsigned int ba;
+
+		err = get_user(ba, (unsigned int *)regs->pc);
+
+		if (err)
+			break;
+
+		if ((ba & 0xFFC00000U) == 0x30800000U || (ba & 0xFFF80000U) == 0x30480000U) {
+			unsigned int addr;
+
+			if ((ba & 0xFFC00000U) == 0x30800000U)
+				addr = regs->pc + ((((ba | 0xFFC00000U) ^ 0x00200000U) + 0x00200000U) << 2);
+			else
+				addr = regs->pc + ((((ba | 0xFFF80000U) ^ 0x00040000U) + 0x00040000U) << 2);
+			regs->pc = addr;
+			regs->npc = addr+4;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: patched PLT emulation #3 */
+		unsigned int sethi, bajmpl, nop;
+
+		err = get_user(sethi, (unsigned int *)regs->pc);
+		err |= get_user(bajmpl, (unsigned int *)(regs->pc+4));
+		err |= get_user(nop, (unsigned int *)(regs->pc+8));
+
+		if (err)
+			break;
+
+		if ((sethi & 0xFFC00000U) == 0x03000000U &&
+		    ((bajmpl & 0xFFFFE000U) == 0x81C06000U || (bajmpl & 0xFFF80000U) == 0x30480000U) &&
+		    nop == 0x01000000U)
+		{
+			unsigned int addr;
+
+			addr = (sethi & 0x003FFFFFU) << 10;
+			regs->u_regs[UREG_G1] = addr;
+			if ((bajmpl & 0xFFFFE000U) == 0x81C06000U)
+				addr += (((bajmpl | 0xFFFFE000U) ^ 0x00001000U) + 0x00001000U);
+			else
+				addr = regs->pc + ((((bajmpl | 0xFFF80000U) ^ 0x00040000U) + 0x00040000U) << 2);
+			regs->pc = addr;
+			regs->npc = addr+4;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: unpatched PLT emulation step 1 */
+		unsigned int sethi, ba, nop;
+
+		err = get_user(sethi, (unsigned int *)regs->pc);
+		err |= get_user(ba, (unsigned int *)(regs->pc+4));
+		err |= get_user(nop, (unsigned int *)(regs->pc+8));
+
+		if (err)
+			break;
+
+		if ((sethi & 0xFFC00000U) == 0x03000000U &&
+		    ((ba & 0xFFC00000U) == 0x30800000U || (ba & 0xFFF80000U) == 0x30680000U) &&
+		    nop == 0x01000000U)
+		{
+			unsigned int addr, save, call;
+
+			if ((ba & 0xFFC00000U) == 0x30800000U)
+				addr = regs->pc + 4 + ((((ba | 0xFFC00000U) ^ 0x00200000U) + 0x00200000U) << 2);
+			else
+				addr = regs->pc + 4 + ((((ba | 0xFFF80000U) ^ 0x00040000U) + 0x00040000U) << 2);
+
+			err = get_user(save, (unsigned int *)addr);
+			err |= get_user(call, (unsigned int *)(addr+4));
+			err |= get_user(nop, (unsigned int *)(addr+8));
+			if (err)
+				break;
+
+#ifdef CONFIG_PAX_DLRESOLVE
+			if (save == 0x9DE3BFA8U &&
+			    (call & 0xC0000000U) == 0x40000000U &&
+			    nop == 0x01000000U)
+			{
+				struct vm_area_struct *vma;
+				unsigned long call_dl_resolve;
+
+				down_read(&current->mm->mmap_sem);
+				call_dl_resolve = current->mm->call_dl_resolve;
+				up_read(&current->mm->mmap_sem);
+				if (likely(call_dl_resolve))
+					goto emulate;
+
+				vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+
+				down_write(&current->mm->mmap_sem);
+				if (current->mm->call_dl_resolve) {
+					call_dl_resolve = current->mm->call_dl_resolve;
+					up_write(&current->mm->mmap_sem);
+					if (vma)
+						kmem_cache_free(vm_area_cachep, vma);
+					goto emulate;
+				}
+
+				call_dl_resolve = get_unmapped_area(NULL, 0UL, PAGE_SIZE, 0UL, MAP_PRIVATE);
+				if (!vma || (call_dl_resolve & ~PAGE_MASK)) {
+					up_write(&current->mm->mmap_sem);
+					if (vma)
+						kmem_cache_free(vm_area_cachep, vma);
+					return 1;
+				}
+
+				if (pax_insert_vma(vma, call_dl_resolve)) {
+					up_write(&current->mm->mmap_sem);
+					kmem_cache_free(vm_area_cachep, vma);
+					return 1;
+				}
+
+				current->mm->call_dl_resolve = call_dl_resolve;
+				up_write(&current->mm->mmap_sem);
+
+emulate:
+				regs->u_regs[UREG_G1] = (sethi & 0x003FFFFFU) << 10;
+				regs->pc = call_dl_resolve;
+				regs->npc = addr+4;
+				return 3;
+			}
+#endif
+
+			/* PaX: glibc 2.4+ generates sethi/jmpl instead of save/call */
+			if ((save & 0xFFC00000U) == 0x05000000U &&
+			    (call & 0xFFFFE000U) == 0x85C0A000U &&
+			    nop == 0x01000000U)
+			{
+				regs->u_regs[UREG_G1] = (sethi & 0x003FFFFFU) << 10;
+				regs->u_regs[UREG_G2] = addr + 4;
+				addr = (save & 0x003FFFFFU) << 10;
+				addr += (((call | 0xFFFFE000U) ^ 0x00001000U) + 0x00001000U);
+				regs->pc = addr;
+				regs->npc = addr+4;
+				return 3;
+			}
+		}
+	} while (0);
+
+	do { /* PaX: unpatched PLT emulation step 2 */
+		unsigned int save, call, nop;
+
+		err = get_user(save, (unsigned int *)(regs->pc-4));
+		err |= get_user(call, (unsigned int *)regs->pc);
+		err |= get_user(nop, (unsigned int *)(regs->pc+4));
+		if (err)
+			break;
+
+		if (save == 0x9DE3BFA8U &&
+		    (call & 0xC0000000U) == 0x40000000U &&
+		    nop == 0x01000000U)
+		{
+			unsigned int dl_resolve = regs->pc + ((((call | 0xC0000000U) ^ 0x20000000U) + 0x20000000U) << 2);
+
+			regs->u_regs[UREG_RETPC] = regs->pc;
+			regs->pc = dl_resolve;
+			regs->npc = dl_resolve+4;
+			return 3;
+		}
+	} while (0);
+#endif
+
+	return 1;
+}
+
+void pax_report_insns(struct pt_regs *regs, void *pc, void *sp)
+{
+	unsigned long i;
+
+	printk(KERN_ERR "PAX: bytes at PC: ");
+	for (i = 0; i < 8; i++) {
+		unsigned int c;
+		if (get_user(c, (unsigned int *)pc+i))
+			printk(KERN_CONT "???????? ");
+		else
+			printk(KERN_CONT "%08x ", c);
+	}
+	printk("\n");
+}
+#endif
+
 static noinline void do_fault_siginfo(int code, int sig, struct pt_regs *regs,
 				      int text_fault)
 {
@@ -280,6 +554,24 @@ good_area:
 		if(!(vma->vm_flags & VM_WRITE))
 			goto bad_area;
 	} else {
+
+#ifdef CONFIG_PAX_PAGEEXEC
+		if ((mm->pax_flags & MF_PAX_PAGEEXEC) && text_fault && !(vma->vm_flags & VM_EXEC)) {
+			up_read(&mm->mmap_sem);
+			switch (pax_handle_fetch_fault(regs)) {
+
+#ifdef CONFIG_PAX_EMUPLT
+			case 2:
+			case 3:
+				return;
+#endif
+
+			}
+			pax_report_fault(regs, (void *)regs->pc, (void *)regs->u_regs[UREG_FP]);
+			do_group_exit(SIGKILL);
+		}
+#endif
+
 		/* Allow reads even for write-only mappings */
 		if(!(vma->vm_flags & (VM_READ | VM_EXEC)))
 			goto bad_area;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/mm/fault_64.c linux-3.2.71-pax/arch/sparc/mm/fault_64.c
--- linux-3.2.71/arch/sparc/mm/fault_64.c	2015-02-20 12:37:32.961178782 +0100
+++ linux-3.2.71-pax/arch/sparc/mm/fault_64.c	2015-02-20 12:37:41.821178309 +0100
@@ -21,6 +21,9 @@
 #include <linux/kprobes.h>
 #include <linux/kdebug.h>
 #include <linux/percpu.h>
+#include <linux/slab.h>
+#include <linux/pagemap.h>
+#include <linux/compiler.h>
 
 #include <asm/page.h>
 #include <asm/pgtable.h>
@@ -282,6 +285,466 @@ static void noinline __kprobes bogus_32b
 	show_regs(regs);
 }
 
+#ifdef CONFIG_PAX_PAGEEXEC
+#ifdef CONFIG_PAX_DLRESOLVE
+static void pax_emuplt_close(struct vm_area_struct *vma)
+{
+	vma->vm_mm->call_dl_resolve = 0UL;
+}
+
+static int pax_emuplt_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
+{
+	unsigned int *kaddr;
+
+	vmf->page = alloc_page(GFP_HIGHUSER);
+	if (!vmf->page)
+		return VM_FAULT_OOM;
+
+	kaddr = kmap(vmf->page);
+	memset(kaddr, 0, PAGE_SIZE);
+	kaddr[0] = 0x9DE3BFA8U; /* save */
+	flush_dcache_page(vmf->page);
+	kunmap(vmf->page);
+	return VM_FAULT_MAJOR;
+}
+
+static const struct vm_operations_struct pax_vm_ops = {
+	.close = pax_emuplt_close,
+	.fault = pax_emuplt_fault
+};
+
+static int pax_insert_vma(struct vm_area_struct *vma, unsigned long addr)
+{
+	int ret;
+
+	INIT_LIST_HEAD(&vma->anon_vma_chain);
+	vma->vm_mm = current->mm;
+	vma->vm_start = addr;
+	vma->vm_end = addr + PAGE_SIZE;
+	vma->vm_flags = VM_READ | VM_EXEC | VM_MAYREAD | VM_MAYEXEC;
+	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
+	vma->vm_ops = &pax_vm_ops;
+
+	ret = insert_vm_struct(current->mm, vma);
+	if (ret)
+		return ret;
+
+	++current->mm->total_vm;
+	return 0;
+}
+#endif
+
+/*
+ * PaX: decide what to do with offenders (regs->tpc = fault address)
+ *
+ * returns 1 when task should be killed
+ *         2 when patched PLT trampoline was detected
+ *         3 when unpatched PLT trampoline was detected
+ */
+static int pax_handle_fetch_fault(struct pt_regs *regs)
+{
+
+#ifdef CONFIG_PAX_EMUPLT
+	int err;
+
+	do { /* PaX: patched PLT emulation #1 */
+		unsigned int sethi1, sethi2, jmpl;
+
+		err = get_user(sethi1, (unsigned int *)regs->tpc);
+		err |= get_user(sethi2, (unsigned int *)(regs->tpc+4));
+		err |= get_user(jmpl, (unsigned int *)(regs->tpc+8));
+
+		if (err)
+			break;
+
+		if ((sethi1 & 0xFFC00000U) == 0x03000000U &&
+		    (sethi2 & 0xFFC00000U) == 0x03000000U &&
+		    (jmpl & 0xFFFFE000U) == 0x81C06000U)
+		{
+			unsigned long addr;
+
+			regs->u_regs[UREG_G1] = (sethi2 & 0x003FFFFFU) << 10;
+			addr = regs->u_regs[UREG_G1];
+			addr += (((jmpl | 0xFFFFFFFFFFFFE000UL) ^ 0x00001000UL) + 0x00001000UL);
+
+			if (test_thread_flag(TIF_32BIT))
+				addr &= 0xFFFFFFFFUL;
+
+			regs->tpc = addr;
+			regs->tnpc = addr+4;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: patched PLT emulation #2 */
+		unsigned int ba;
+
+		err = get_user(ba, (unsigned int *)regs->tpc);
+
+		if (err)
+			break;
+
+		if ((ba & 0xFFC00000U) == 0x30800000U || (ba & 0xFFF80000U) == 0x30480000U) {
+			unsigned long addr;
+
+			if ((ba & 0xFFC00000U) == 0x30800000U)
+				addr = regs->tpc + ((((ba | 0xFFFFFFFFFFC00000UL) ^ 0x00200000UL) + 0x00200000UL) << 2);
+			else
+				addr = regs->tpc + ((((ba | 0xFFFFFFFFFFF80000UL) ^ 0x00040000UL) + 0x00040000UL) << 2);
+
+			if (test_thread_flag(TIF_32BIT))
+				addr &= 0xFFFFFFFFUL;
+
+			regs->tpc = addr;
+			regs->tnpc = addr+4;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: patched PLT emulation #3 */
+		unsigned int sethi, bajmpl, nop;
+
+		err = get_user(sethi, (unsigned int *)regs->tpc);
+		err |= get_user(bajmpl, (unsigned int *)(regs->tpc+4));
+		err |= get_user(nop, (unsigned int *)(regs->tpc+8));
+
+		if (err)
+			break;
+
+		if ((sethi & 0xFFC00000U) == 0x03000000U &&
+		    ((bajmpl & 0xFFFFE000U) == 0x81C06000U || (bajmpl & 0xFFF80000U) == 0x30480000U) &&
+		    nop == 0x01000000U)
+		{
+			unsigned long addr;
+
+			addr = (sethi & 0x003FFFFFU) << 10;
+			regs->u_regs[UREG_G1] = addr;
+			if ((bajmpl & 0xFFFFE000U) == 0x81C06000U)
+				addr += (((bajmpl | 0xFFFFFFFFFFFFE000UL) ^ 0x00001000UL) + 0x00001000UL);
+			else
+				addr = regs->tpc + ((((bajmpl | 0xFFFFFFFFFFF80000UL) ^ 0x00040000UL) + 0x00040000UL) << 2);
+
+			if (test_thread_flag(TIF_32BIT))
+				addr &= 0xFFFFFFFFUL;
+
+			regs->tpc = addr;
+			regs->tnpc = addr+4;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: patched PLT emulation #4 */
+		unsigned int sethi, mov1, call, mov2;
+
+		err = get_user(sethi, (unsigned int *)regs->tpc);
+		err |= get_user(mov1, (unsigned int *)(regs->tpc+4));
+		err |= get_user(call, (unsigned int *)(regs->tpc+8));
+		err |= get_user(mov2, (unsigned int *)(regs->tpc+12));
+
+		if (err)
+			break;
+
+		if ((sethi & 0xFFC00000U) == 0x03000000U &&
+		    mov1 == 0x8210000FU &&
+		    (call & 0xC0000000U) == 0x40000000U &&
+		    mov2 == 0x9E100001U)
+		{
+			unsigned long addr;
+
+			regs->u_regs[UREG_G1] = regs->u_regs[UREG_RETPC];
+			addr = regs->tpc + 4 + ((((call | 0xFFFFFFFFC0000000UL) ^ 0x20000000UL) + 0x20000000UL) << 2);
+
+			if (test_thread_flag(TIF_32BIT))
+				addr &= 0xFFFFFFFFUL;
+
+			regs->tpc = addr;
+			regs->tnpc = addr+4;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: patched PLT emulation #5 */
+		unsigned int sethi, sethi1, sethi2, or1, or2, sllx, jmpl, nop;
+
+		err = get_user(sethi, (unsigned int *)regs->tpc);
+		err |= get_user(sethi1, (unsigned int *)(regs->tpc+4));
+		err |= get_user(sethi2, (unsigned int *)(regs->tpc+8));
+		err |= get_user(or1, (unsigned int *)(regs->tpc+12));
+		err |= get_user(or2, (unsigned int *)(regs->tpc+16));
+		err |= get_user(sllx, (unsigned int *)(regs->tpc+20));
+		err |= get_user(jmpl, (unsigned int *)(regs->tpc+24));
+		err |= get_user(nop, (unsigned int *)(regs->tpc+28));
+
+		if (err)
+			break;
+
+		if ((sethi & 0xFFC00000U) == 0x03000000U &&
+		    (sethi1 & 0xFFC00000U) == 0x03000000U &&
+		    (sethi2 & 0xFFC00000U) == 0x0B000000U &&
+		    (or1 & 0xFFFFE000U) == 0x82106000U &&
+		    (or2 & 0xFFFFE000U) == 0x8A116000U &&
+		    sllx == 0x83287020U &&
+		    jmpl == 0x81C04005U &&
+		    nop == 0x01000000U)
+		{
+			unsigned long addr;
+
+			regs->u_regs[UREG_G1] = ((sethi1 & 0x003FFFFFU) << 10) | (or1 & 0x000003FFU);
+			regs->u_regs[UREG_G1] <<= 32;
+			regs->u_regs[UREG_G5] = ((sethi2 & 0x003FFFFFU) << 10) | (or2 & 0x000003FFU);
+			addr = regs->u_regs[UREG_G1] + regs->u_regs[UREG_G5];
+			regs->tpc = addr;
+			regs->tnpc = addr+4;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: patched PLT emulation #6 */
+		unsigned int sethi, sethi1, sethi2, sllx, or,  jmpl, nop;
+
+		err = get_user(sethi, (unsigned int *)regs->tpc);
+		err |= get_user(sethi1, (unsigned int *)(regs->tpc+4));
+		err |= get_user(sethi2, (unsigned int *)(regs->tpc+8));
+		err |= get_user(sllx, (unsigned int *)(regs->tpc+12));
+		err |= get_user(or, (unsigned int *)(regs->tpc+16));
+		err |= get_user(jmpl, (unsigned int *)(regs->tpc+20));
+		err |= get_user(nop, (unsigned int *)(regs->tpc+24));
+
+		if (err)
+			break;
+
+		if ((sethi & 0xFFC00000U) == 0x03000000U &&
+		    (sethi1 & 0xFFC00000U) == 0x03000000U &&
+		    (sethi2 & 0xFFC00000U) == 0x0B000000U &&
+		    sllx == 0x83287020U &&
+		    (or & 0xFFFFE000U) == 0x8A116000U &&
+		    jmpl == 0x81C04005U &&
+		    nop == 0x01000000U)
+		{
+			unsigned long addr;
+
+			regs->u_regs[UREG_G1] = (sethi1 & 0x003FFFFFU) << 10;
+			regs->u_regs[UREG_G1] <<= 32;
+			regs->u_regs[UREG_G5] = ((sethi2 & 0x003FFFFFU) << 10) | (or & 0x3FFU);
+			addr = regs->u_regs[UREG_G1] + regs->u_regs[UREG_G5];
+			regs->tpc = addr;
+			regs->tnpc = addr+4;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: unpatched PLT emulation step 1 */
+		unsigned int sethi, ba, nop;
+
+		err = get_user(sethi, (unsigned int *)regs->tpc);
+		err |= get_user(ba, (unsigned int *)(regs->tpc+4));
+		err |= get_user(nop, (unsigned int *)(regs->tpc+8));
+
+		if (err)
+			break;
+
+		if ((sethi & 0xFFC00000U) == 0x03000000U &&
+		    ((ba & 0xFFC00000U) == 0x30800000U || (ba & 0xFFF80000U) == 0x30680000U) &&
+		    nop == 0x01000000U)
+		{
+			unsigned long addr;
+			unsigned int save, call;
+			unsigned int sethi1, sethi2, or1, or2, sllx, add, jmpl;
+
+			if ((ba & 0xFFC00000U) == 0x30800000U)
+				addr = regs->tpc + 4 + ((((ba | 0xFFFFFFFFFFC00000UL) ^ 0x00200000UL) + 0x00200000UL) << 2);
+			else
+				addr = regs->tpc + 4 + ((((ba | 0xFFFFFFFFFFF80000UL) ^ 0x00040000UL) + 0x00040000UL) << 2);
+
+			if (test_thread_flag(TIF_32BIT))
+				addr &= 0xFFFFFFFFUL;
+
+			err = get_user(save, (unsigned int *)addr);
+			err |= get_user(call, (unsigned int *)(addr+4));
+			err |= get_user(nop, (unsigned int *)(addr+8));
+			if (err)
+				break;
+
+#ifdef CONFIG_PAX_DLRESOLVE
+			if (save == 0x9DE3BFA8U &&
+			    (call & 0xC0000000U) == 0x40000000U &&
+			    nop == 0x01000000U)
+			{
+				struct vm_area_struct *vma;
+				unsigned long call_dl_resolve;
+
+				down_read(&current->mm->mmap_sem);
+				call_dl_resolve = current->mm->call_dl_resolve;
+				up_read(&current->mm->mmap_sem);
+				if (likely(call_dl_resolve))
+					goto emulate;
+
+				vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+
+				down_write(&current->mm->mmap_sem);
+				if (current->mm->call_dl_resolve) {
+					call_dl_resolve = current->mm->call_dl_resolve;
+					up_write(&current->mm->mmap_sem);
+					if (vma)
+						kmem_cache_free(vm_area_cachep, vma);
+					goto emulate;
+				}
+
+				call_dl_resolve = get_unmapped_area(NULL, 0UL, PAGE_SIZE, 0UL, MAP_PRIVATE);
+				if (!vma || (call_dl_resolve & ~PAGE_MASK)) {
+					up_write(&current->mm->mmap_sem);
+					if (vma)
+						kmem_cache_free(vm_area_cachep, vma);
+					return 1;
+				}
+
+				if (pax_insert_vma(vma, call_dl_resolve)) {
+					up_write(&current->mm->mmap_sem);
+					kmem_cache_free(vm_area_cachep, vma);
+					return 1;
+				}
+
+				current->mm->call_dl_resolve = call_dl_resolve;
+				up_write(&current->mm->mmap_sem);
+
+emulate:
+				regs->u_regs[UREG_G1] = (sethi & 0x003FFFFFU) << 10;
+				regs->tpc = call_dl_resolve;
+				regs->tnpc = addr+4;
+				return 3;
+			}
+#endif
+
+			/* PaX: glibc 2.4+ generates sethi/jmpl instead of save/call */
+			if ((save & 0xFFC00000U) == 0x05000000U &&
+			    (call & 0xFFFFE000U) == 0x85C0A000U &&
+			    nop == 0x01000000U)
+			{
+				regs->u_regs[UREG_G1] = (sethi & 0x003FFFFFU) << 10;
+				regs->u_regs[UREG_G2] = addr + 4;
+				addr = (save & 0x003FFFFFU) << 10;
+				addr += (((call | 0xFFFFFFFFFFFFE000UL) ^ 0x00001000UL) + 0x00001000UL);
+
+				if (test_thread_flag(TIF_32BIT))
+					addr &= 0xFFFFFFFFUL;
+
+				regs->tpc = addr;
+				regs->tnpc = addr+4;
+				return 3;
+			}
+
+			/* PaX: 64-bit PLT stub */
+			err = get_user(sethi1, (unsigned int *)addr);
+			err |= get_user(sethi2, (unsigned int *)(addr+4));
+			err |= get_user(or1, (unsigned int *)(addr+8));
+			err |= get_user(or2, (unsigned int *)(addr+12));
+			err |= get_user(sllx, (unsigned int *)(addr+16));
+			err |= get_user(add, (unsigned int *)(addr+20));
+			err |= get_user(jmpl, (unsigned int *)(addr+24));
+			err |= get_user(nop, (unsigned int *)(addr+28));
+			if (err)
+				break;
+
+			if ((sethi1 & 0xFFC00000U) == 0x09000000U &&
+			    (sethi2 & 0xFFC00000U) == 0x0B000000U &&
+			    (or1 & 0xFFFFE000U) == 0x88112000U &&
+			    (or2 & 0xFFFFE000U) == 0x8A116000U &&
+			    sllx == 0x89293020U &&
+			    add == 0x8A010005U &&
+			    jmpl == 0x89C14000U &&
+			    nop == 0x01000000U)
+			{
+				regs->u_regs[UREG_G1] = (sethi & 0x003FFFFFU) << 10;
+				regs->u_regs[UREG_G4] = ((sethi1 & 0x003FFFFFU) << 10) | (or1 & 0x000003FFU);
+				regs->u_regs[UREG_G4] <<= 32;
+				regs->u_regs[UREG_G5] = ((sethi2 & 0x003FFFFFU) << 10) | (or2 & 0x000003FFU);
+				regs->u_regs[UREG_G5] += regs->u_regs[UREG_G4];
+				regs->u_regs[UREG_G4] = addr + 24;
+				addr = regs->u_regs[UREG_G5];
+				regs->tpc = addr;
+				regs->tnpc = addr+4;
+				return 3;
+			}
+		}
+	} while (0);
+
+#ifdef CONFIG_PAX_DLRESOLVE
+	do { /* PaX: unpatched PLT emulation step 2 */
+		unsigned int save, call, nop;
+
+		err = get_user(save, (unsigned int *)(regs->tpc-4));
+		err |= get_user(call, (unsigned int *)regs->tpc);
+		err |= get_user(nop, (unsigned int *)(regs->tpc+4));
+		if (err)
+			break;
+
+		if (save == 0x9DE3BFA8U &&
+		    (call & 0xC0000000U) == 0x40000000U &&
+		    nop == 0x01000000U)
+		{
+			unsigned long dl_resolve = regs->tpc + ((((call | 0xFFFFFFFFC0000000UL) ^ 0x20000000UL) + 0x20000000UL) << 2);
+
+			if (test_thread_flag(TIF_32BIT))
+				dl_resolve &= 0xFFFFFFFFUL;
+
+			regs->u_regs[UREG_RETPC] = regs->tpc;
+			regs->tpc = dl_resolve;
+			regs->tnpc = dl_resolve+4;
+			return 3;
+		}
+	} while (0);
+#endif
+
+	do { /* PaX: patched PLT emulation #7, must be AFTER the unpatched PLT emulation */
+		unsigned int sethi, ba, nop;
+
+		err = get_user(sethi, (unsigned int *)regs->tpc);
+		err |= get_user(ba, (unsigned int *)(regs->tpc+4));
+		err |= get_user(nop, (unsigned int *)(regs->tpc+8));
+
+		if (err)
+			break;
+
+		if ((sethi & 0xFFC00000U) == 0x03000000U &&
+		    (ba & 0xFFF00000U) == 0x30600000U &&
+		    nop == 0x01000000U)
+		{
+			unsigned long addr;
+
+			addr = (sethi & 0x003FFFFFU) << 10;
+			regs->u_regs[UREG_G1] = addr;
+			addr = regs->tpc + ((((ba | 0xFFFFFFFFFFF80000UL) ^ 0x00040000UL) + 0x00040000UL) << 2);
+
+			if (test_thread_flag(TIF_32BIT))
+				addr &= 0xFFFFFFFFUL;
+
+			regs->tpc = addr;
+			regs->tnpc = addr+4;
+			return 2;
+		}
+	} while (0);
+
+#endif
+
+	return 1;
+}
+
+void pax_report_insns(struct pt_regs *regs, void *pc, void *sp)
+{
+	unsigned long i;
+
+	printk(KERN_ERR "PAX: bytes at PC: ");
+	for (i = 0; i < 8; i++) {
+		unsigned int c;
+		if (get_user(c, (unsigned int *)pc+i))
+			printk(KERN_CONT "???????? ");
+		else
+			printk(KERN_CONT "%08x ", c);
+	}
+	printk("\n");
+}
+#endif
+
 asmlinkage void __kprobes do_sparc64_fault(struct pt_regs *regs)
 {
 	struct mm_struct *mm = current->mm;
@@ -348,6 +811,29 @@ asmlinkage void __kprobes do_sparc64_fau
 	if (!vma)
 		goto bad_area;
 
+#ifdef CONFIG_PAX_PAGEEXEC
+	/* PaX: detect ITLB misses on non-exec pages */
+	if ((mm->pax_flags & MF_PAX_PAGEEXEC) && vma->vm_start <= address &&
+	    !(vma->vm_flags & VM_EXEC) && (fault_code & FAULT_CODE_ITLB))
+	{
+		if (address != regs->tpc)
+			goto good_area;
+
+		up_read(&mm->mmap_sem);
+		switch (pax_handle_fetch_fault(regs)) {
+
+#ifdef CONFIG_PAX_EMUPLT
+		case 2:
+		case 3:
+			return;
+#endif
+
+		}
+		pax_report_fault(regs, (void *)regs->tpc, (void *)(regs->u_regs[UREG_FP] + STACK_BIAS));
+		do_group_exit(SIGKILL);
+	}
+#endif
+
 	/* Pure DTLB misses do not tell us whether the fault causing
 	 * load/store/atomic was a write or not, it only says that there
 	 * was no match.  So in such a case we (carefully) read the
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/mm/hugetlbpage.c linux-3.2.71-pax/arch/sparc/mm/hugetlbpage.c
--- linux-3.2.71/arch/sparc/mm/hugetlbpage.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/mm/hugetlbpage.c	2013-07-05 02:12:32.969202621 +0200
@@ -67,7 +67,7 @@ full_search:
 			}
 			return -ENOMEM;
 		}
-		if (likely(!vma || addr + len <= vma->vm_start)) {
+		if (likely(check_heap_stack_gap(vma, &addr, len))) {
 			/*
 			 * Remember the place where we stopped the search:
 			 */
@@ -105,26 +105,28 @@ hugetlb_get_unmapped_area_topdown(struct
 
 	/* make sure it can fit in the remaining address space */
 	if (likely(addr > len)) {
-		vma = find_vma(mm, addr-len);
-		if (!vma || addr <= vma->vm_start) {
+		addr -= len;
+		vma = find_vma(mm, addr);
+		if (check_heap_stack_gap(vma, &addr, len)) {
 			/* remember the address as a hint for next time */
-			return (mm->free_area_cache = addr-len);
+			return (mm->free_area_cache = addr);
 		}
 	}
 
 	if (unlikely(mm->mmap_base < len))
 		goto bottomup;
 
-	addr = (mm->mmap_base-len) & HPAGE_MASK;
+	addr = mm->mmap_base - len;
 
 	do {
+		addr &= HPAGE_MASK;
 		/*
 		 * Lookup failure means no vma is above this address,
 		 * else if new region fits below vma->vm_start,
 		 * return with success:
 		 */
 		vma = find_vma(mm, addr);
-		if (likely(!vma || addr+len <= vma->vm_start)) {
+		if (likely(check_heap_stack_gap(vma, &addr, len))) {
 			/* remember the address as a hint for next time */
 			return (mm->free_area_cache = addr);
 		}
@@ -134,8 +136,8 @@ hugetlb_get_unmapped_area_topdown(struct
  		        mm->cached_hole_size = vma->vm_start - addr;
 
 		/* try just below the current vma->vm_start */
-		addr = (vma->vm_start-len) & HPAGE_MASK;
-	} while (likely(len < vma->vm_start));
+		addr = skip_heap_stack_gap(vma, len);
+	} while (!IS_ERR_VALUE(addr));
 
 bottomup:
 	/*
@@ -181,8 +183,7 @@ hugetlb_get_unmapped_area(struct file *f
 	if (addr) {
 		addr = ALIGN(addr, HPAGE_SIZE);
 		vma = find_vma(mm, addr);
-		if (task_size - len >= addr &&
-		    (!vma || addr + len <= vma->vm_start))
+		if (task_size - len >= addr && check_heap_stack_gap(vma, &addr, len))
 			return addr;
 	}
 	if (mm->get_unmapped_area == arch_get_unmapped_area)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/mm/init_32.c linux-3.2.71-pax/arch/sparc/mm/init_32.c
--- linux-3.2.71/arch/sparc/mm/init_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/mm/init_32.c	2012-07-04 19:24:47.440063015 +0200
@@ -316,6 +316,9 @@ extern void device_scan(void);
 pgprot_t PAGE_SHARED __read_mostly;
 EXPORT_SYMBOL(PAGE_SHARED);
 
+pgprot_t PAGE_SHARED_NOEXEC __read_mostly;
+EXPORT_SYMBOL(PAGE_SHARED_NOEXEC);
+
 void __init paging_init(void)
 {
 	switch(sparc_cpu_model) {
@@ -344,17 +347,17 @@ void __init paging_init(void)
 
 	/* Initialize the protection map with non-constant, MMU dependent values. */
 	protection_map[0] = PAGE_NONE;
-	protection_map[1] = PAGE_READONLY;
-	protection_map[2] = PAGE_COPY;
-	protection_map[3] = PAGE_COPY;
+	protection_map[1] = PAGE_READONLY_NOEXEC;
+	protection_map[2] = PAGE_COPY_NOEXEC;
+	protection_map[3] = PAGE_COPY_NOEXEC;
 	protection_map[4] = PAGE_READONLY;
 	protection_map[5] = PAGE_READONLY;
 	protection_map[6] = PAGE_COPY;
 	protection_map[7] = PAGE_COPY;
 	protection_map[8] = PAGE_NONE;
-	protection_map[9] = PAGE_READONLY;
-	protection_map[10] = PAGE_SHARED;
-	protection_map[11] = PAGE_SHARED;
+	protection_map[9] = PAGE_READONLY_NOEXEC;
+	protection_map[10] = PAGE_SHARED_NOEXEC;
+	protection_map[11] = PAGE_SHARED_NOEXEC;
 	protection_map[12] = PAGE_READONLY;
 	protection_map[13] = PAGE_READONLY;
 	protection_map[14] = PAGE_SHARED;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/mm/init_64.c linux-3.2.71-pax/arch/sparc/mm/init_64.c
--- linux-3.2.71/arch/sparc/mm/init_64.c	2014-09-14 14:10:57.958117153 +0200
+++ linux-3.2.71-pax/arch/sparc/mm/init_64.c	2014-09-14 14:11:25.902138310 +0200
@@ -170,9 +170,9 @@ unsigned long sparc64_kern_sec_context _
 int num_kernel_image_mappings;
 
 #ifdef CONFIG_DEBUG_DCFLUSH
-atomic_t dcpage_flushes = ATOMIC_INIT(0);
+atomic_unchecked_t dcpage_flushes = ATOMIC_INIT(0);
 #ifdef CONFIG_SMP
-atomic_t dcpage_flushes_xcall = ATOMIC_INIT(0);
+atomic_unchecked_t dcpage_flushes_xcall = ATOMIC_INIT(0);
 #endif
 #endif
 
@@ -180,7 +180,7 @@ inline void flush_dcache_page_impl(struc
 {
 	BUG_ON(tlb_type == hypervisor);
 #ifdef CONFIG_DEBUG_DCFLUSH
-	atomic_inc(&dcpage_flushes);
+	atomic_inc_unchecked(&dcpage_flushes);
 #endif
 
 #ifdef DCACHE_ALIASING_POSSIBLE
@@ -421,10 +421,10 @@ void mmu_info(struct seq_file *m)
 
 #ifdef CONFIG_DEBUG_DCFLUSH
 	seq_printf(m, "DCPageFlushes\t: %d\n",
-		   atomic_read(&dcpage_flushes));
+		   atomic_read_unchecked(&dcpage_flushes));
 #ifdef CONFIG_SMP
 	seq_printf(m, "DCPageFlushesXC\t: %d\n",
-		   atomic_read(&dcpage_flushes_xcall));
+		   atomic_read_unchecked(&dcpage_flushes_xcall));
 #endif /* CONFIG_SMP */
 #endif /* CONFIG_DEBUG_DCFLUSH */
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/mm/Makefile linux-3.2.71-pax/arch/sparc/mm/Makefile
--- linux-3.2.71/arch/sparc/mm/Makefile	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/mm/Makefile	2012-07-04 19:24:47.440063015 +0200
@@ -2,7 +2,7 @@
 #
 
 asflags-y := -ansi
-ccflags-y := -Werror
+#ccflags-y := -Werror
 
 obj-$(CONFIG_SPARC64)   += ultra.o tlb.o tsb.o gup.o
 obj-y                   += fault_$(BITS).o
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/sparc/mm/srmmu.c linux-3.2.71-pax/arch/sparc/mm/srmmu.c
--- linux-3.2.71/arch/sparc/mm/srmmu.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/sparc/mm/srmmu.c	2012-07-04 19:24:47.444063012 +0200
@@ -2200,6 +2200,13 @@ void __init ld_mmu_srmmu(void)
 	PAGE_SHARED = pgprot_val(SRMMU_PAGE_SHARED);
 	BTFIXUPSET_INT(page_copy, pgprot_val(SRMMU_PAGE_COPY));
 	BTFIXUPSET_INT(page_readonly, pgprot_val(SRMMU_PAGE_RDONLY));
+
+#ifdef CONFIG_PAX_PAGEEXEC
+	PAGE_SHARED_NOEXEC = pgprot_val(SRMMU_PAGE_SHARED_NOEXEC);
+	BTFIXUPSET_INT(page_copy_noexec, pgprot_val(SRMMU_PAGE_COPY_NOEXEC));
+	BTFIXUPSET_INT(page_readonly_noexec, pgprot_val(SRMMU_PAGE_RDONLY_NOEXEC));
+#endif
+
 	BTFIXUPSET_INT(page_kernel, pgprot_val(SRMMU_PAGE_KERNEL));
 	page_kernel = pgprot_val(SRMMU_PAGE_KERNEL);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/tile/include/asm/atomic_64.h linux-3.2.71-pax/arch/tile/include/asm/atomic_64.h
--- linux-3.2.71/arch/tile/include/asm/atomic_64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/tile/include/asm/atomic_64.h	2012-07-04 19:24:47.444063012 +0200
@@ -142,6 +142,16 @@ static inline long atomic64_add_unless(a
 
 #define atomic64_inc_not_zero(v)	atomic64_add_unless((v), 1, 0)
 
+#define atomic64_read_unchecked(v)		atomic64_read(v)
+#define atomic64_set_unchecked(v, i)		atomic64_set((v), (i))
+#define atomic64_add_unchecked(a, v)		atomic64_add((a), (v))
+#define atomic64_add_return_unchecked(a, v)	atomic64_add_return((a), (v))
+#define atomic64_sub_unchecked(a, v)		atomic64_sub((a), (v))
+#define atomic64_inc_unchecked(v)		atomic64_inc(v)
+#define atomic64_inc_return_unchecked(v)	atomic64_inc_return(v)
+#define atomic64_dec_unchecked(v)		atomic64_dec(v)
+#define atomic64_cmpxchg_unchecked(v, o, n)	atomic64_cmpxchg((v), (o), (n))
+
 /* Atomic dec and inc don't implement barrier, so provide them if needed. */
 #define smp_mb__before_atomic_dec()	smp_mb()
 #define smp_mb__after_atomic_dec()	smp_mb()
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/tile/include/asm/uaccess.h linux-3.2.71-pax/arch/tile/include/asm/uaccess.h
--- linux-3.2.71/arch/tile/include/asm/uaccess.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/tile/include/asm/uaccess.h	2012-07-04 19:24:47.444063012 +0200
@@ -361,9 +361,9 @@ static inline unsigned long __must_check
 					  const void __user *from,
 					  unsigned long n)
 {
-	int sz = __compiletime_object_size(to);
+	size_t sz = __compiletime_object_size(to);
 
-	if (likely(sz == -1 || sz >= n))
+	if (likely(sz == (size_t)-1 || sz >= n))
 		n = _copy_from_user(to, from, n);
 	else
 		copy_from_user_overflow();
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/um/include/asm/kmap_types.h linux-3.2.71-pax/arch/um/include/asm/kmap_types.h
--- linux-3.2.71/arch/um/include/asm/kmap_types.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/um/include/asm/kmap_types.h	2012-07-04 19:24:47.444063012 +0200
@@ -23,6 +23,7 @@ enum km_type {
 	KM_IRQ1,
 	KM_SOFTIRQ0,
 	KM_SOFTIRQ1,
+	KM_CLEARPAGE,
 	KM_TYPE_NR
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/um/include/asm/page.h linux-3.2.71-pax/arch/um/include/asm/page.h
--- linux-3.2.71/arch/um/include/asm/page.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/um/include/asm/page.h	2012-07-04 19:24:47.444063012 +0200
@@ -14,6 +14,9 @@
 #define PAGE_SIZE	(_AC(1, UL) << PAGE_SHIFT)
 #define PAGE_MASK	(~(PAGE_SIZE-1))
 
+#define ktla_ktva(addr)			(addr)
+#define ktva_ktla(addr)			(addr)
+
 #ifndef __ASSEMBLY__
 
 struct page;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/um/include/asm/pgtable-3level.h linux-3.2.71-pax/arch/um/include/asm/pgtable-3level.h
--- linux-3.2.71/arch/um/include/asm/pgtable-3level.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/um/include/asm/pgtable-3level.h	2012-07-04 19:24:47.444063012 +0200
@@ -58,6 +58,7 @@
 #define pud_present(x)	(pud_val(x) & _PAGE_PRESENT)
 #define pud_populate(mm, pud, pmd) \
 	set_pud(pud, __pud(_PAGE_TABLE + __pa(pmd)))
+#define pud_populate_kernel(mm, pud, pmd) pud_populate((mm), (pud), (pmd))
 
 #ifdef CONFIG_64BIT
 #define set_pud(pudptr, pudval) set_64bit((u64 *) (pudptr), pud_val(pudval))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/um/kernel/process.c linux-3.2.71-pax/arch/um/kernel/process.c
--- linux-3.2.71/arch/um/kernel/process.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/um/kernel/process.c	2012-07-04 19:24:47.448063009 +0200
@@ -406,22 +406,6 @@ int singlestepping(void * t)
 	return 2;
 }
 
-/*
- * Only x86 and x86_64 have an arch_align_stack().
- * All other arches have "#define arch_align_stack(x) (x)"
- * in their asm/system.h
- * As this is included in UML from asm-um/system-generic.h,
- * we can use it to behave as the subarch does.
- */
-#ifndef arch_align_stack
-unsigned long arch_align_stack(unsigned long sp)
-{
-	if (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)
-		sp -= get_random_int() % 8192;
-	return sp & ~0xf;
-}
-#endif
-
 unsigned long get_wchan(struct task_struct *p)
 {
 	unsigned long stack_page, sp, ip;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/um/Makefile linux-3.2.71-pax/arch/um/Makefile
--- linux-3.2.71/arch/um/Makefile	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/um/Makefile	2012-09-26 14:47:15.460342220 +0200
@@ -61,6 +61,10 @@ USER_CFLAGS = $(patsubst $(KERNEL_DEFINE
 	$(patsubst -I%,,$(KBUILD_CFLAGS)))) $(ARCH_INCLUDE) $(MODE_INCLUDE) \
 	$(filter -I%,$(CFLAGS)) -D_FILE_OFFSET_BITS=64 -idirafter include
 
+ifdef CONSTIFY_PLUGIN
+USER_CFLAGS	+= -fplugin-arg-constify_plugin-no-constify
+endif
+
 #This will adjust *FLAGS accordingly to the platform.
 include $(srctree)/$(ARCH_DIR)/Makefile-os-$(OS)
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/boot/bitops.h linux-3.2.71-pax/arch/x86/boot/bitops.h
--- linux-3.2.71/arch/x86/boot/bitops.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/boot/bitops.h	2012-07-04 19:24:47.448063009 +0200
@@ -26,7 +26,7 @@ static inline int variable_test_bit(int
 	u8 v;
 	const u32 *p = (const u32 *)addr;
 
-	asm("btl %2,%1; setc %0" : "=qm" (v) : "m" (*p), "Ir" (nr));
+	asm volatile("btl %2,%1; setc %0" : "=qm" (v) : "m" (*p), "Ir" (nr));
 	return v;
 }
 
@@ -37,7 +37,7 @@ static inline int variable_test_bit(int
 
 static inline void set_bit(int nr, void *addr)
 {
-	asm("btsl %1,%0" : "+m" (*(u32 *)addr) : "Ir" (nr));
+	asm volatile("btsl %1,%0" : "+m" (*(u32 *)addr) : "Ir" (nr));
 }
 
 #endif /* BOOT_BITOPS_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/boot/boot.h linux-3.2.71-pax/arch/x86/boot/boot.h
--- linux-3.2.71/arch/x86/boot/boot.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/boot/boot.h	2012-07-04 19:24:47.448063009 +0200
@@ -85,7 +85,7 @@ static inline void io_delay(void)
 static inline u16 ds(void)
 {
 	u16 seg;
-	asm("movw %%ds,%0" : "=rm" (seg));
+	asm volatile("movw %%ds,%0" : "=rm" (seg));
 	return seg;
 }
 
@@ -181,7 +181,7 @@ static inline void wrgs32(u32 v, addr_t
 static inline int memcmp(const void *s1, const void *s2, size_t len)
 {
 	u8 diff;
-	asm("repe; cmpsb; setnz %0"
+	asm volatile("repe; cmpsb; setnz %0"
 	    : "=qm" (diff), "+D" (s1), "+S" (s2), "+c" (len));
 	return diff;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/boot/compressed/head_32.S linux-3.2.71-pax/arch/x86/boot/compressed/head_32.S
--- linux-3.2.71/arch/x86/boot/compressed/head_32.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/boot/compressed/head_32.S	2012-07-04 19:24:47.448063009 +0200
@@ -76,7 +76,7 @@ ENTRY(startup_32)
 	notl	%eax
 	andl    %eax, %ebx
 #else
-	movl	$LOAD_PHYSICAL_ADDR, %ebx
+	movl	$____LOAD_PHYSICAL_ADDR, %ebx
 #endif
 
 	/* Target address to relocate to for decompression */
@@ -162,7 +162,7 @@ relocated:
  * and where it was actually loaded.
  */
 	movl	%ebp, %ebx
-	subl	$LOAD_PHYSICAL_ADDR, %ebx
+	subl	$____LOAD_PHYSICAL_ADDR, %ebx
 	jz	2f	/* Nothing to be done if loaded at compiled addr. */
 /*
  * Process relocations.
@@ -170,8 +170,7 @@ relocated:
 
 1:	subl	$4, %edi
 	movl	(%edi), %ecx
-	testl	%ecx, %ecx
-	jz	2f
+	jecxz	2f
 	addl	%ebx, -__PAGE_OFFSET(%ebx, %ecx)
 	jmp	1b
 2:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/boot/compressed/head_64.S linux-3.2.71-pax/arch/x86/boot/compressed/head_64.S
--- linux-3.2.71/arch/x86/boot/compressed/head_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/boot/compressed/head_64.S	2015-06-27 13:57:57.370527383 +0200
@@ -91,7 +91,7 @@ ENTRY(startup_32)
 	notl	%eax
 	andl	%eax, %ebx
 #else
-	movl	$LOAD_PHYSICAL_ADDR, %ebx
+	movl	$____LOAD_PHYSICAL_ADDR, %ebx
 #endif
 
 	/* Target address to relocate to for decompression */
@@ -233,7 +233,7 @@ ENTRY(startup_64)
 	notq	%rax
 	andq	%rax, %rbp
 #else
-	movq	$LOAD_PHYSICAL_ADDR, %rbp
+	movq	$____LOAD_PHYSICAL_ADDR, %rbp
 #endif
 
 	/* Target address to relocate to for decompression */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/boot/compressed/Makefile linux-3.2.71-pax/arch/x86/boot/compressed/Makefile
--- linux-3.2.71/arch/x86/boot/compressed/Makefile	2014-01-03 15:48:44.640070583 +0100
+++ linux-3.2.71-pax/arch/x86/boot/compressed/Makefile	2014-01-03 15:53:33.564055157 +0100
@@ -15,6 +15,9 @@ KBUILD_CFLAGS += $(cflags-y)
 KBUILD_CFLAGS += -mno-mmx -mno-sse
 KBUILD_CFLAGS += $(call cc-option,-ffreestanding)
 KBUILD_CFLAGS += $(call cc-option,-fno-stack-protector)
+ifdef CONSTIFY_PLUGIN
+KBUILD_CFLAGS += -fplugin-arg-constify_plugin-no-constify
+endif
 
 KBUILD_AFLAGS  := $(KBUILD_CFLAGS) -D__ASSEMBLY__
 GCOV_PROFILE := n
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/boot/compressed/misc.c linux-3.2.71-pax/arch/x86/boot/compressed/misc.c
--- linux-3.2.71/arch/x86/boot/compressed/misc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/boot/compressed/misc.c	2014-04-05 22:27:52.408781722 +0200
@@ -226,7 +226,7 @@ void __putstr(int error, const char *s)
 
 void *memset(void *s, int c, size_t n)
 {
-	int i;
+	size_t i;
 	char *ss = s;
 
 	for (i = 0; i < n; i++)
@@ -282,7 +282,7 @@ static void parse_elf(void *output)
 	Elf32_Ehdr ehdr;
 	Elf32_Phdr *phdrs, *phdr;
 #endif
-	void *dest;
+	void *dest, *prev;
 	int i;
 
 	memcpy(&ehdr, output, sizeof(ehdr));
@@ -310,13 +310,16 @@ static void parse_elf(void *output)
 		case PT_LOAD:
 #ifdef CONFIG_RELOCATABLE
 			dest = output;
-			dest += (phdr->p_paddr - LOAD_PHYSICAL_ADDR);
+			dest += (phdr->p_paddr - ____LOAD_PHYSICAL_ADDR);
 #else
 			dest = (void *)(phdr->p_paddr);
 #endif
 			memcpy(dest,
 			       output + phdr->p_offset,
 			       phdr->p_filesz);
+			if (i)
+				memset(prev, 0xff, dest - prev);
+			prev = dest + phdr->p_filesz;
 			break;
 		default: /* Ignore other PT_* */ break;
 		}
@@ -363,7 +366,7 @@ asmlinkage void decompress_kernel(void *
 		error("Destination address too large");
 #endif
 #ifndef CONFIG_RELOCATABLE
-	if ((unsigned long)output != LOAD_PHYSICAL_ADDR)
+	if ((unsigned long)output != ____LOAD_PHYSICAL_ADDR)
 		error("Wrong destination address");
 #endif
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/boot/cpucheck.c linux-3.2.71-pax/arch/x86/boot/cpucheck.c
--- linux-3.2.71/arch/x86/boot/cpucheck.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/boot/cpucheck.c	2012-07-04 19:24:47.452063003 +0200
@@ -74,7 +74,7 @@ static int has_fpu(void)
 	u16 fcw = -1, fsw = -1;
 	u32 cr0;
 
-	asm("movl %%cr0,%0" : "=r" (cr0));
+	asm volatile("movl %%cr0,%0" : "=r" (cr0));
 	if (cr0 & (X86_CR0_EM|X86_CR0_TS)) {
 		cr0 &= ~(X86_CR0_EM|X86_CR0_TS);
 		asm volatile("movl %0,%%cr0" : : "r" (cr0));
@@ -90,7 +90,7 @@ static int has_eflag(u32 mask)
 {
 	u32 f0, f1;
 
-	asm("pushfl ; "
+	asm volatile("pushfl ; "
 	    "pushfl ; "
 	    "popl %0 ; "
 	    "movl %0,%1 ; "
@@ -115,7 +115,7 @@ static void get_flags(void)
 		set_bit(X86_FEATURE_FPU, cpu.flags);
 
 	if (has_eflag(X86_EFLAGS_ID)) {
-		asm("cpuid"
+		asm volatile("cpuid"
 		    : "=a" (max_intel_level),
 		      "=b" (cpu_vendor[0]),
 		      "=d" (cpu_vendor[1]),
@@ -124,7 +124,7 @@ static void get_flags(void)
 
 		if (max_intel_level >= 0x00000001 &&
 		    max_intel_level <= 0x0000ffff) {
-			asm("cpuid"
+			asm volatile("cpuid"
 			    : "=a" (tfms),
 			      "=c" (cpu.flags[4]),
 			      "=d" (cpu.flags[0])
@@ -136,7 +136,7 @@ static void get_flags(void)
 				cpu.model += ((tfms >> 16) & 0xf) << 4;
 		}
 
-		asm("cpuid"
+		asm volatile("cpuid"
 		    : "=a" (max_amd_level)
 		    : "a" (0x80000000)
 		    : "ebx", "ecx", "edx");
@@ -144,7 +144,7 @@ static void get_flags(void)
 		if (max_amd_level >= 0x80000001 &&
 		    max_amd_level <= 0x8000ffff) {
 			u32 eax = 0x80000001;
-			asm("cpuid"
+			asm volatile("cpuid"
 			    : "+a" (eax),
 			      "=c" (cpu.flags[6]),
 			      "=d" (cpu.flags[1])
@@ -203,9 +203,9 @@ int check_cpu(int *cpu_level_ptr, int *r
 		u32 ecx = MSR_K7_HWCR;
 		u32 eax, edx;
 
-		asm("rdmsr" : "=a" (eax), "=d" (edx) : "c" (ecx));
+		asm volatile("rdmsr" : "=a" (eax), "=d" (edx) : "c" (ecx));
 		eax &= ~(1 << 15);
-		asm("wrmsr" : : "a" (eax), "d" (edx), "c" (ecx));
+		asm volatile("wrmsr" : : "a" (eax), "d" (edx), "c" (ecx));
 
 		get_flags();	/* Make sure it really did something */
 		err = check_flags();
@@ -218,9 +218,9 @@ int check_cpu(int *cpu_level_ptr, int *r
 		u32 ecx = MSR_VIA_FCR;
 		u32 eax, edx;
 
-		asm("rdmsr" : "=a" (eax), "=d" (edx) : "c" (ecx));
+		asm volatile("rdmsr" : "=a" (eax), "=d" (edx) : "c" (ecx));
 		eax |= (1<<1)|(1<<7);
-		asm("wrmsr" : : "a" (eax), "d" (edx), "c" (ecx));
+		asm volatile("wrmsr" : : "a" (eax), "d" (edx), "c" (ecx));
 
 		set_bit(X86_FEATURE_CX8, cpu.flags);
 		err = check_flags();
@@ -231,12 +231,12 @@ int check_cpu(int *cpu_level_ptr, int *r
 		u32 eax, edx;
 		u32 level = 1;
 
-		asm("rdmsr" : "=a" (eax), "=d" (edx) : "c" (ecx));
-		asm("wrmsr" : : "a" (~0), "d" (edx), "c" (ecx));
-		asm("cpuid"
+		asm volatile("rdmsr" : "=a" (eax), "=d" (edx) : "c" (ecx));
+		asm volatile("wrmsr" : : "a" (~0), "d" (edx), "c" (ecx));
+		asm volatile("cpuid"
 		    : "+a" (level), "=d" (cpu.flags[0])
 		    : : "ecx", "ebx");
-		asm("wrmsr" : : "a" (eax), "d" (edx), "c" (ecx));
+		asm volatile("wrmsr" : : "a" (eax), "d" (edx), "c" (ecx));
 
 		err = check_flags();
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/boot/header.S linux-3.2.71-pax/arch/x86/boot/header.S
--- linux-3.2.71/arch/x86/boot/header.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/boot/header.S	2012-08-04 00:02:33.282657300 +0200
@@ -224,10 +224,14 @@ setup_data:		.quad 0			# 64-bit physical
 						# single linked list of
 						# struct setup_data
 
-pref_address:		.quad LOAD_PHYSICAL_ADDR	# preferred load addr
+pref_address:		.quad ____LOAD_PHYSICAL_ADDR	# preferred load addr
 
 #define ZO_INIT_SIZE	(ZO__end - ZO_startup_32 + ZO_z_extract_offset)
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+#define VO_INIT_SIZE	(VO__end - VO__text - __PAGE_OFFSET - ____LOAD_PHYSICAL_ADDR)
+#else
 #define VO_INIT_SIZE	(VO__end - VO__text)
+#endif
 #if ZO_INIT_SIZE > VO_INIT_SIZE
 #define INIT_SIZE ZO_INIT_SIZE
 #else
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/boot/Makefile linux-3.2.71-pax/arch/x86/boot/Makefile
--- linux-3.2.71/arch/x86/boot/Makefile	2014-01-03 15:48:44.640070583 +0100
+++ linux-3.2.71-pax/arch/x86/boot/Makefile	2014-01-03 15:53:07.136056568 +0100
@@ -63,6 +63,9 @@ KBUILD_CFLAGS	:= $(LINUXINCLUDE) -m32 -g
 		   $(call cc-option, -fno-unit-at-a-time)) \
 		   $(call cc-option, -fno-stack-protector) \
 		   $(call cc-option, -mpreferred-stack-boundary=2)
+ifdef CONSTIFY_PLUGIN
+KBUILD_CFLAGS	+= -fplugin-arg-constify_plugin-no-constify
+endif
 KBUILD_AFLAGS	:= $(KBUILD_CFLAGS) -D__ASSEMBLY__
 GCOV_PROFILE := n
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/boot/memory.c linux-3.2.71-pax/arch/x86/boot/memory.c
--- linux-3.2.71/arch/x86/boot/memory.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/boot/memory.c	2012-07-04 19:24:47.452063003 +0200
@@ -19,7 +19,7 @@
 
 static int detect_memory_e820(void)
 {
-	int count = 0;
+	unsigned int count = 0;
 	struct biosregs ireg, oreg;
 	struct e820entry *desc = boot_params.e820_map;
 	static struct e820entry buf; /* static so it is zeroed */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/boot/video.c linux-3.2.71-pax/arch/x86/boot/video.c
--- linux-3.2.71/arch/x86/boot/video.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/boot/video.c	2012-07-04 19:24:47.452063003 +0200
@@ -96,7 +96,7 @@ static void store_mode_params(void)
 static unsigned int get_entry(void)
 {
 	char entry_buf[4];
-	int i, len = 0;
+	unsigned int i, len = 0;
 	int key;
 	unsigned int v;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/boot/video-vesa.c linux-3.2.71-pax/arch/x86/boot/video-vesa.c
--- linux-3.2.71/arch/x86/boot/video-vesa.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/boot/video-vesa.c	2012-07-04 19:24:47.456062997 +0200
@@ -200,6 +200,7 @@ static void vesa_store_pm_info(void)
 
 	boot_params.screen_info.vesapm_seg = oreg.es;
 	boot_params.screen_info.vesapm_off = oreg.di;
+	boot_params.screen_info.vesapm_size = oreg.cx;
 }
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/crypto/aesni-intel_asm.S linux-3.2.71-pax/arch/x86/crypto/aesni-intel_asm.S
--- linux-3.2.71/arch/x86/crypto/aesni-intel_asm.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/crypto/aesni-intel_asm.S	2013-12-10 22:56:57.643075551 +0100
@@ -31,6 +31,7 @@
 
 #include <linux/linkage.h>
 #include <asm/inst.h>
+#include <asm/alternative-asm.h>
 
 #ifdef __x86_64__
 .data
@@ -199,7 +200,7 @@ enc:        .octa 0x2
 * num_initial_blocks = b mod 4
 * encrypt the initial num_initial_blocks blocks and apply ghash on
 * the ciphertext
-* %r10, %r11, %r12, %rax, %xmm5, %xmm6, %xmm7, %xmm8, %xmm9 registers
+* %r10, %r11, %r15, %rax, %xmm5, %xmm6, %xmm7, %xmm8, %xmm9 registers
 * are clobbered
 * arg1, %arg2, %arg3, %r14 are used as a pointer only, not modified
 */
@@ -208,8 +209,8 @@ enc:        .octa 0x2
 .macro INITIAL_BLOCKS_DEC num_initial_blocks TMP1 TMP2 TMP3 TMP4 TMP5 XMM0 XMM1 \
 XMM2 XMM3 XMM4 XMMDst TMP6 TMP7 i i_seq operation
 	mov	   arg7, %r10           # %r10 = AAD
-	mov	   arg8, %r12           # %r12 = aadLen
-	mov	   %r12, %r11
+	mov	   arg8, %r15           # %r15 = aadLen
+	mov	   %r15, %r11
 	pxor	   %xmm\i, %xmm\i
 _get_AAD_loop\num_initial_blocks\operation:
 	movd	   (%r10), \TMP1
@@ -217,15 +218,15 @@ _get_AAD_loop\num_initial_blocks\operati
 	psrldq	   $4, %xmm\i
 	pxor	   \TMP1, %xmm\i
 	add	   $4, %r10
-	sub	   $4, %r12
+	sub	   $4, %r15
 	jne	   _get_AAD_loop\num_initial_blocks\operation
 	cmp	   $16, %r11
 	je	   _get_AAD_loop2_done\num_initial_blocks\operation
-	mov	   $16, %r12
+	mov	   $16, %r15
 _get_AAD_loop2\num_initial_blocks\operation:
 	psrldq	   $4, %xmm\i
-	sub	   $4, %r12
-	cmp	   %r11, %r12
+	sub	   $4, %r15
+	cmp	   %r11, %r15
 	jne	   _get_AAD_loop2\num_initial_blocks\operation
 _get_AAD_loop2_done\num_initial_blocks\operation:
         movdqa     SHUF_MASK(%rip), %xmm14
@@ -437,7 +438,7 @@ _initial_blocks_done\num_initial_blocks\
 * num_initial_blocks = b mod 4
 * encrypt the initial num_initial_blocks blocks and apply ghash on
 * the ciphertext
-* %r10, %r11, %r12, %rax, %xmm5, %xmm6, %xmm7, %xmm8, %xmm9 registers
+* %r10, %r11, %r15, %rax, %xmm5, %xmm6, %xmm7, %xmm8, %xmm9 registers
 * are clobbered
 * arg1, %arg2, %arg3, %r14 are used as a pointer only, not modified
 */
@@ -446,8 +447,8 @@ _initial_blocks_done\num_initial_blocks\
 .macro INITIAL_BLOCKS_ENC num_initial_blocks TMP1 TMP2 TMP3 TMP4 TMP5 XMM0 XMM1 \
 XMM2 XMM3 XMM4 XMMDst TMP6 TMP7 i i_seq operation
 	mov	   arg7, %r10           # %r10 = AAD
-	mov	   arg8, %r12           # %r12 = aadLen
-	mov	   %r12, %r11
+	mov	   arg8, %r15           # %r15 = aadLen
+	mov	   %r15, %r11
 	pxor	   %xmm\i, %xmm\i
 _get_AAD_loop\num_initial_blocks\operation:
 	movd	   (%r10), \TMP1
@@ -455,15 +456,15 @@ _get_AAD_loop\num_initial_blocks\operati
 	psrldq	   $4, %xmm\i
 	pxor	   \TMP1, %xmm\i
 	add	   $4, %r10
-	sub	   $4, %r12
+	sub	   $4, %r15
 	jne	   _get_AAD_loop\num_initial_blocks\operation
 	cmp	   $16, %r11
 	je	   _get_AAD_loop2_done\num_initial_blocks\operation
-	mov	   $16, %r12
+	mov	   $16, %r15
 _get_AAD_loop2\num_initial_blocks\operation:
 	psrldq	   $4, %xmm\i
-	sub	   $4, %r12
-	cmp	   %r11, %r12
+	sub	   $4, %r15
+	cmp	   %r11, %r15
 	jne	   _get_AAD_loop2\num_initial_blocks\operation
 _get_AAD_loop2_done\num_initial_blocks\operation:
         movdqa     SHUF_MASK(%rip), %xmm14
@@ -1264,7 +1265,7 @@ TMP7 XMM1 XMM2 XMM3 XMM4 XMMDst
 *****************************************************************************/
 
 ENTRY(aesni_gcm_dec)
-	push	%r12
+	push	%r15
 	push	%r13
 	push	%r14
 	mov	%rsp, %r14
@@ -1274,8 +1275,8 @@ ENTRY(aesni_gcm_dec)
 */
 	sub	$VARIABLE_OFFSET, %rsp
 	and	$~63, %rsp                        # align rsp to 64 bytes
-	mov	%arg6, %r12
-	movdqu	(%r12), %xmm13			  # %xmm13 = HashKey
+	mov	%arg6, %r15
+	movdqu	(%r15), %xmm13			  # %xmm13 = HashKey
         movdqa  SHUF_MASK(%rip), %xmm2
 	PSHUFB_XMM %xmm2, %xmm13
 
@@ -1303,10 +1304,10 @@ ENTRY(aesni_gcm_dec)
 	movdqa %xmm13, HashKey(%rsp)           # store HashKey<<1 (mod poly)
 	mov %arg4, %r13    # save the number of bytes of plaintext/ciphertext
 	and $-16, %r13                      # %r13 = %r13 - (%r13 mod 16)
-	mov %r13, %r12
-	and $(3<<4), %r12
+	mov %r13, %r15
+	and $(3<<4), %r15
 	jz _initial_num_blocks_is_0_decrypt
-	cmp $(2<<4), %r12
+	cmp $(2<<4), %r15
 	jb _initial_num_blocks_is_1_decrypt
 	je _initial_num_blocks_is_2_decrypt
 _initial_num_blocks_is_3_decrypt:
@@ -1356,16 +1357,16 @@ _zero_cipher_left_decrypt:
 	sub $16, %r11
 	add %r13, %r11
 	movdqu (%arg3,%r11,1), %xmm1   # receive the last <16 byte block
-	lea SHIFT_MASK+16(%rip), %r12
-	sub %r13, %r12
+	lea SHIFT_MASK+16(%rip), %r15
+	sub %r13, %r15
 # adjust the shuffle mask pointer to be able to shift 16-%r13 bytes
 # (%r13 is the number of bytes in plaintext mod 16)
-	movdqu (%r12), %xmm2           # get the appropriate shuffle mask
+	movdqu (%r15), %xmm2           # get the appropriate shuffle mask
 	PSHUFB_XMM %xmm2, %xmm1            # right shift 16-%r13 butes
 
 	movdqa  %xmm1, %xmm2
 	pxor %xmm1, %xmm0            # Ciphertext XOR E(K, Yn)
-	movdqu ALL_F-SHIFT_MASK(%r12), %xmm1
+	movdqu ALL_F-SHIFT_MASK(%r15), %xmm1
 	# get the appropriate mask to mask out top 16-%r13 bytes of %xmm0
 	pand %xmm1, %xmm0            # mask out top 16-%r13 bytes of %xmm0
 	pand    %xmm1, %xmm2
@@ -1394,9 +1395,9 @@ _less_than_8_bytes_left_decrypt:
 	sub	$1, %r13
 	jne	_less_than_8_bytes_left_decrypt
 _multiple_of_16_bytes_decrypt:
-	mov	arg8, %r12		  # %r13 = aadLen (number of bytes)
-	shl	$3, %r12		  # convert into number of bits
-	movd	%r12d, %xmm15		  # len(A) in %xmm15
+	mov	arg8, %r15		  # %r13 = aadLen (number of bytes)
+	shl	$3, %r15		  # convert into number of bits
+	movd	%r15d, %xmm15		  # len(A) in %xmm15
 	shl	$3, %arg4		  # len(C) in bits (*128)
 	MOVQ_R64_XMM	%arg4, %xmm1
 	pslldq	$8, %xmm15		  # %xmm15 = len(A)||0x0000000000000000
@@ -1435,8 +1436,10 @@ _return_T_done_decrypt:
 	mov	%r14, %rsp
 	pop	%r14
 	pop	%r13
-	pop	%r12
+	pop	%r15
+	pax_force_retaddr
 	ret
+ENDPROC(aesni_gcm_dec)
 
 
 /*****************************************************************************
@@ -1523,7 +1526,7 @@ _return_T_done_decrypt:
 * poly = x^128 + x^127 + x^126 + x^121 + 1
 ***************************************************************************/
 ENTRY(aesni_gcm_enc)
-	push	%r12
+	push	%r15
 	push	%r13
 	push	%r14
 	mov	%rsp, %r14
@@ -1533,8 +1536,8 @@ ENTRY(aesni_gcm_enc)
 #
 	sub	$VARIABLE_OFFSET, %rsp
 	and	$~63, %rsp
-	mov	%arg6, %r12
-	movdqu	(%r12), %xmm13
+	mov	%arg6, %r15
+	movdqu	(%r15), %xmm13
         movdqa  SHUF_MASK(%rip), %xmm2
 	PSHUFB_XMM %xmm2, %xmm13
 
@@ -1558,13 +1561,13 @@ ENTRY(aesni_gcm_enc)
 	movdqa	%xmm13, HashKey(%rsp)
 	mov	%arg4, %r13            # %xmm13 holds HashKey<<1 (mod poly)
 	and	$-16, %r13
-	mov	%r13, %r12
+	mov	%r13, %r15
 
         # Encrypt first few blocks
 
-	and	$(3<<4), %r12
+	and	$(3<<4), %r15
 	jz	_initial_num_blocks_is_0_encrypt
-	cmp	$(2<<4), %r12
+	cmp	$(2<<4), %r15
 	jb	_initial_num_blocks_is_1_encrypt
 	je	_initial_num_blocks_is_2_encrypt
 _initial_num_blocks_is_3_encrypt:
@@ -1617,14 +1620,14 @@ _zero_cipher_left_encrypt:
 	sub $16, %r11
 	add %r13, %r11
 	movdqu (%arg3,%r11,1), %xmm1     # receive the last <16 byte blocks
-	lea SHIFT_MASK+16(%rip), %r12
-	sub %r13, %r12
+	lea SHIFT_MASK+16(%rip), %r15
+	sub %r13, %r15
 	# adjust the shuffle mask pointer to be able to shift 16-r13 bytes
 	# (%r13 is the number of bytes in plaintext mod 16)
-	movdqu	(%r12), %xmm2           # get the appropriate shuffle mask
+	movdqu	(%r15), %xmm2           # get the appropriate shuffle mask
 	PSHUFB_XMM	%xmm2, %xmm1            # shift right 16-r13 byte
 	pxor	%xmm1, %xmm0            # Plaintext XOR Encrypt(K, Yn)
-	movdqu	ALL_F-SHIFT_MASK(%r12), %xmm1
+	movdqu	ALL_F-SHIFT_MASK(%r15), %xmm1
 	# get the appropriate mask to mask out top 16-r13 bytes of xmm0
 	pand	%xmm1, %xmm0            # mask out top 16-r13 bytes of xmm0
         movdqa SHUF_MASK(%rip), %xmm10
@@ -1657,9 +1660,9 @@ _less_than_8_bytes_left_encrypt:
 	sub $1, %r13
 	jne _less_than_8_bytes_left_encrypt
 _multiple_of_16_bytes_encrypt:
-	mov	arg8, %r12    # %r12 = addLen (number of bytes)
-	shl	$3, %r12
-	movd	%r12d, %xmm15       # len(A) in %xmm15
+	mov	arg8, %r15    # %r15 = addLen (number of bytes)
+	shl	$3, %r15
+	movd	%r15d, %xmm15       # len(A) in %xmm15
 	shl	$3, %arg4               # len(C) in bits (*128)
 	MOVQ_R64_XMM	%arg4, %xmm1
 	pslldq	$8, %xmm15          # %xmm15 = len(A)||0x0000000000000000
@@ -1698,8 +1701,10 @@ _return_T_done_encrypt:
 	mov	%r14, %rsp
 	pop	%r14
 	pop	%r13
-	pop	%r12
+	pop	%r15
+	pax_force_retaddr
 	ret
+ENDPROC(aesni_gcm_enc)
 
 #endif
 
@@ -1714,6 +1719,7 @@ _key_expansion_256a:
 	pxor %xmm1, %xmm0
 	movaps %xmm0, (TKEYP)
 	add $0x10, TKEYP
+	pax_force_retaddr
 	ret
 
 .align 4
@@ -1738,6 +1744,7 @@ _key_expansion_192a:
 	shufps $0b01001110, %xmm2, %xmm1
 	movaps %xmm1, 0x10(TKEYP)
 	add $0x20, TKEYP
+	pax_force_retaddr
 	ret
 
 .align 4
@@ -1757,6 +1764,7 @@ _key_expansion_192b:
 
 	movaps %xmm0, (TKEYP)
 	add $0x10, TKEYP
+	pax_force_retaddr
 	ret
 
 .align 4
@@ -1769,6 +1777,7 @@ _key_expansion_256b:
 	pxor %xmm1, %xmm2
 	movaps %xmm2, (TKEYP)
 	add $0x10, TKEYP
+	pax_force_retaddr
 	ret
 
 /*
@@ -1881,7 +1890,9 @@ ENTRY(aesni_set_key)
 #ifndef __x86_64__
 	popl KEYP
 #endif
+	pax_force_retaddr
 	ret
+ENDPROC(aesni_set_key)
 
 /*
  * void aesni_enc(struct crypto_aes_ctx *ctx, u8 *dst, const u8 *src)
@@ -1902,7 +1913,9 @@ ENTRY(aesni_enc)
 	popl KLEN
 	popl KEYP
 #endif
+	pax_force_retaddr
 	ret
+ENDPROC(aesni_enc)
 
 /*
  * _aesni_enc1:		internal ABI
@@ -1959,6 +1972,7 @@ _aesni_enc1:
 	AESENC KEY STATE
 	movaps 0x70(TKEYP), KEY
 	AESENCLAST KEY STATE
+	pax_force_retaddr
 	ret
 
 /*
@@ -2067,6 +2081,7 @@ _aesni_enc4:
 	AESENCLAST KEY STATE2
 	AESENCLAST KEY STATE3
 	AESENCLAST KEY STATE4
+	pax_force_retaddr
 	ret
 
 /*
@@ -2089,7 +2104,9 @@ ENTRY(aesni_dec)
 	popl KLEN
 	popl KEYP
 #endif
+	pax_force_retaddr
 	ret
+ENDPROC(aesni_dec)
 
 /*
  * _aesni_dec1:		internal ABI
@@ -2146,6 +2163,7 @@ _aesni_dec1:
 	AESDEC KEY STATE
 	movaps 0x70(TKEYP), KEY
 	AESDECLAST KEY STATE
+	pax_force_retaddr
 	ret
 
 /*
@@ -2254,6 +2272,7 @@ _aesni_dec4:
 	AESDECLAST KEY STATE2
 	AESDECLAST KEY STATE3
 	AESDECLAST KEY STATE4
+	pax_force_retaddr
 	ret
 
 /*
@@ -2311,7 +2330,9 @@ ENTRY(aesni_ecb_enc)
 	popl KEYP
 	popl LEN
 #endif
+	pax_force_retaddr
 	ret
+ENDPROC(aesni_ecb_enc)
 
 /*
  * void aesni_ecb_dec(struct crypto_aes_ctx *ctx, const u8 *dst, u8 *src,
@@ -2369,7 +2390,9 @@ ENTRY(aesni_ecb_dec)
 	popl KEYP
 	popl LEN
 #endif
+	pax_force_retaddr
 	ret
+ENDPROC(aesni_ecb_dec)
 
 /*
  * void aesni_cbc_enc(struct crypto_aes_ctx *ctx, const u8 *dst, u8 *src,
@@ -2410,7 +2433,9 @@ ENTRY(aesni_cbc_enc)
 	popl LEN
 	popl IVP
 #endif
+	pax_force_retaddr
 	ret
+ENDPROC(aesni_cbc_enc)
 
 /*
  * void aesni_cbc_dec(struct crypto_aes_ctx *ctx, const u8 *dst, u8 *src,
@@ -2500,7 +2525,9 @@ ENTRY(aesni_cbc_dec)
 	popl LEN
 	popl IVP
 #endif
+	pax_force_retaddr
 	ret
+ENDPROC(aesni_cbc_dec)
 
 #ifdef __x86_64__
 .align 16
@@ -2526,6 +2553,7 @@ _aesni_inc_init:
 	mov $1, TCTR_LOW
 	MOVQ_R64_XMM TCTR_LOW INC
 	MOVQ_R64_XMM CTR TCTR_LOW
+	pax_force_retaddr
 	ret
 
 /*
@@ -2554,6 +2582,7 @@ _aesni_inc:
 .Linc_low:
 	movaps CTR, IV
 	PSHUFB_XMM BSWAP_MASK IV
+	pax_force_retaddr
 	ret
 
 /*
@@ -2614,5 +2643,7 @@ ENTRY(aesni_ctr_enc)
 .Lctr_enc_ret:
 	movups IV, (IVP)
 .Lctr_enc_just_ret:
+	pax_force_retaddr
 	ret
+ENDPROC(aesni_ctr_enc)
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/crypto/aes-x86_64-asm_64.S linux-3.2.71-pax/arch/x86/crypto/aes-x86_64-asm_64.S
--- linux-3.2.71/arch/x86/crypto/aes-x86_64-asm_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/crypto/aes-x86_64-asm_64.S	2013-12-10 22:50:35.027095980 +0100
@@ -8,6 +8,8 @@
  * including this sentence is retained in full.
  */
 
+#include <asm/alternative-asm.h>
+
 .extern crypto_ft_tab
 .extern crypto_it_tab
 .extern crypto_fl_tab
@@ -71,6 +73,8 @@ FUNC:	movq	r1,r2;			\
 	je	B192;			\
 	leaq	32(r9),r9;
 
+#define ret	pax_force_retaddr; ret
+
 #define epilogue(r1,r2,r3,r4,r5,r6,r7,r8,r9) \
 	movq	r1,r2;			\
 	movq	r3,r4;			\
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/crypto/blowfish-x86_64-asm_64.S linux-3.2.71-pax/arch/x86/crypto/blowfish-x86_64-asm_64.S
--- linux-3.2.71/arch/x86/crypto/blowfish-x86_64-asm_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/crypto/blowfish-x86_64-asm_64.S	2013-12-10 22:47:41.435105248 +0100
@@ -20,6 +20,8 @@
  *
  */
 
+#include <asm/alternative-asm.h>
+
 .file "blowfish-x86_64-asm.S"
 .text
 
@@ -151,9 +153,11 @@ __blowfish_enc_blk:
 	jnz __enc_xor;
 
 	write_block();
+	pax_force_retaddr
 	ret;
 __enc_xor:
 	xor_block();
+	pax_force_retaddr
 	ret;
 
 .align 8
@@ -188,6 +192,7 @@ blowfish_dec_blk:
 
 	movq %r11, %rbp;
 
+	pax_force_retaddr
 	ret;
 
 /**********************************************************************
@@ -342,6 +347,7 @@ __blowfish_enc_blk_4way:
 
 	popq %rbx;
 	popq %rbp;
+	pax_force_retaddr
 	ret;
 
 __enc_xor4:
@@ -349,6 +355,7 @@ __enc_xor4:
 
 	popq %rbx;
 	popq %rbp;
+	pax_force_retaddr
 	ret;
 
 .align 8
@@ -386,5 +393,6 @@ blowfish_dec_blk_4way:
 	popq %rbx;
 	popq %rbp;
 
+	pax_force_retaddr
 	ret;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/crypto/salsa20-x86_64-asm_64.S linux-3.2.71-pax/arch/x86/crypto/salsa20-x86_64-asm_64.S
--- linux-3.2.71/arch/x86/crypto/salsa20-x86_64-asm_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/crypto/salsa20-x86_64-asm_64.S	2013-12-10 22:41:21.263125547 +0100
@@ -1,3 +1,5 @@
+#include <asm/alternative-asm.h>
+
 # enter ECRYPT_encrypt_bytes
 .text
 .p2align 5
@@ -790,6 +792,7 @@ ECRYPT_encrypt_bytes:
 	add	%r11,%rsp
 	mov	%rdi,%rax
 	mov	%rsi,%rdx
+	pax_force_retaddr
 	ret
 #   bytesatleast65:
 ._bytesatleast65:
@@ -891,6 +894,7 @@ ECRYPT_keysetup:
 	add	%r11,%rsp
 	mov	%rdi,%rax
 	mov	%rsi,%rdx
+	pax_force_retaddr
 	ret
 # enter ECRYPT_ivsetup
 .text
@@ -917,4 +921,5 @@ ECRYPT_ivsetup:
 	add	%r11,%rsp
 	mov	%rdi,%rax
 	mov	%rsi,%rdx
+	pax_force_retaddr
 	ret
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/crypto/sha1_ssse3_asm.S linux-3.2.71-pax/arch/x86/crypto/sha1_ssse3_asm.S
--- linux-3.2.71/arch/x86/crypto/sha1_ssse3_asm.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/crypto/sha1_ssse3_asm.S	2013-12-10 22:48:12.455103592 +0100
@@ -28,6 +28,8 @@
  * (at your option) any later version.
  */
 
+#include <asm/alternative-asm.h>
+
 #define CTX	%rdi	// arg1
 #define BUF	%rsi	// arg2
 #define CNT	%rdx	// arg3
@@ -75,9 +77,9 @@
 \name:
 	push	%rbx
 	push	%rbp
-	push	%r12
+	push	%r14
 
-	mov	%rsp, %r12
+	mov	%rsp, %r14
 	sub	$64, %rsp		# allocate workspace
 	and	$~15, %rsp		# align stack
 
@@ -99,11 +101,12 @@
 	xor	%rax, %rax
 	rep stosq
 
-	mov	%r12, %rsp		# deallocate workspace
+	mov	%r14, %rsp		# deallocate workspace
 
-	pop	%r12
+	pop	%r14
 	pop	%rbp
 	pop	%rbx
+	pax_force_retaddr
 	ret
 
 	.size	\name, .-\name
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/crypto/twofish-x86_64-asm_64-3way.S linux-3.2.71-pax/arch/x86/crypto/twofish-x86_64-asm_64-3way.S
--- linux-3.2.71/arch/x86/crypto/twofish-x86_64-asm_64-3way.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/crypto/twofish-x86_64-asm_64-3way.S	2013-12-10 22:47:03.579107270 +0100
@@ -20,6 +20,8 @@
  *
  */
 
+#include <asm/alternative-asm.h>
+
 .file "twofish-x86_64-asm-3way.S"
 .text
 
@@ -260,6 +262,7 @@ __twofish_enc_blk_3way:
 	popq %r13;
 	popq %r14;
 	popq %r15;
+	pax_force_retaddr
 	ret;
 
 __enc_xor3:
@@ -271,6 +274,7 @@ __enc_xor3:
 	popq %r13;
 	popq %r14;
 	popq %r15;
+	pax_force_retaddr
 	ret;
 
 .global twofish_dec_blk_3way
@@ -312,5 +316,6 @@ twofish_dec_blk_3way:
 	popq %r13;
 	popq %r14;
 	popq %r15;
+	pax_force_retaddr
 	ret;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/crypto/twofish-x86_64-asm_64.S linux-3.2.71-pax/arch/x86/crypto/twofish-x86_64-asm_64.S
--- linux-3.2.71/arch/x86/crypto/twofish-x86_64-asm_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/crypto/twofish-x86_64-asm_64.S	2013-12-10 22:45:23.067112636 +0100
@@ -21,6 +21,7 @@
 .text
 
 #include <asm/asm-offsets.h>
+#include <asm/alternative-asm.h>
 
 #define a_offset	0
 #define b_offset	4
@@ -268,6 +269,7 @@ twofish_enc_blk:
 
 	popq	R1
 	movq	$1,%rax
+	pax_force_retaddr
 	ret
 
 twofish_dec_blk:
@@ -319,4 +321,5 @@ twofish_dec_blk:
 
 	popq	R1
 	movq	$1,%rax
+	pax_force_retaddr
 	ret
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/ia32/ia32entry.S linux-3.2.71-pax/arch/x86/ia32/ia32entry.S
--- linux-3.2.71/arch/x86/ia32/ia32entry.S	2013-02-20 12:30:42.036171944 +0100
+++ linux-3.2.71-pax/arch/x86/ia32/ia32entry.S	2013-12-10 22:41:21.271125546 +0100
@@ -13,7 +13,9 @@
 #include <asm/thread_info.h>	
 #include <asm/segment.h>
 #include <asm/irqflags.h>
+#include <asm/pgtable.h>
 #include <linux/linkage.h>
+#include <asm/alternative-asm.h>
 
 /* Avoid __ASSEMBLER__'ifying <linux/audit.h> just for this.  */
 #include <linux/elf-em.h>
@@ -61,12 +63,12 @@
 	 */
 	.macro LOAD_ARGS32 offset, _r9=0
 	.if \_r9
-	movl \offset+16(%rsp),%r9d
+	movl \offset+R9(%rsp),%r9d
 	.endif
-	movl \offset+40(%rsp),%ecx
-	movl \offset+48(%rsp),%edx
-	movl \offset+56(%rsp),%esi
-	movl \offset+64(%rsp),%edi
+	movl \offset+RCX(%rsp),%ecx
+	movl \offset+RDX(%rsp),%edx
+	movl \offset+RSI(%rsp),%esi
+	movl \offset+RDI(%rsp),%edi
 	movl %eax,%eax			/* zero extension */
 	.endm
 	
@@ -95,6 +97,32 @@ ENTRY(native_irq_enable_sysexit)
 ENDPROC(native_irq_enable_sysexit)
 #endif
 
+	.macro pax_enter_kernel_user
+	pax_set_fptr_mask
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	call pax_enter_kernel_user
+#endif
+	.endm
+
+	.macro pax_exit_kernel_user
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	call pax_exit_kernel_user
+#endif
+#ifdef CONFIG_PAX_RANDKSTACK
+	pushq %rax
+	pushq %r11
+	call pax_randomize_kstack
+	popq %r11
+	popq %rax
+#endif
+	.endm
+
+.macro pax_erase_kstack
+#ifdef CONFIG_PAX_MEMORY_STACKLEAK
+	call pax_erase_kstack
+#endif
+.endm
+
 /*
  * 32bit SYSENTER instruction entry.
  *
@@ -121,12 +149,6 @@ ENTRY(ia32_sysenter_target)
 	CFI_REGISTER	rsp,rbp
 	SWAPGS_UNSAFE_STACK
 	movq	PER_CPU_VAR(kernel_stack), %rsp
-	addq	$(KERNEL_STACK_OFFSET),%rsp
-	/*
-	 * No need to follow this irqs on/off section: the syscall
-	 * disabled irqs, here we enable it straight after entry:
-	 */
-	ENABLE_INTERRUPTS(CLBR_NONE)
  	movl	%ebp,%ebp		/* zero extension */
 	pushq_cfi $__USER32_DS
 	/*CFI_REL_OFFSET ss,0*/
@@ -134,25 +156,44 @@ ENTRY(ia32_sysenter_target)
 	CFI_REL_OFFSET rsp,0
 	pushfq_cfi
 	/*CFI_REL_OFFSET rflags,0*/
-	movl	8*3-THREAD_SIZE+TI_sysenter_return(%rsp), %r10d
-	CFI_REGISTER rip,r10
+	orl	$X86_EFLAGS_IF,(%rsp)
+	GET_THREAD_INFO(%r11)
+	movl	TI_sysenter_return(%r11), %r11d
+	CFI_REGISTER rip,r11
 	pushq_cfi $__USER32_CS
 	/*CFI_REL_OFFSET cs,0*/
 	movl	%eax, %eax
-	pushq_cfi %r10
+	pushq_cfi %r11
 	CFI_REL_OFFSET rip,0
 	pushq_cfi %rax
 	cld
 	SAVE_ARGS 0,1,0
+	pax_enter_kernel_user
+
+#ifdef CONFIG_PAX_RANDKSTACK
+	pax_erase_kstack
+#endif
+
+	/*
+	 * No need to follow this irqs on/off section: the syscall
+	 * disabled irqs, here we enable it straight after entry:
+	 */
+	ENABLE_INTERRUPTS(CLBR_NONE)
  	/* no need to do an access_ok check here because rbp has been
  	   32bit zero extended */ 
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	mov pax_user_shadow_base,%r11
+	add %r11,%rbp
+#endif
+
 1:	movl	(%rbp),%ebp
  	.section __ex_table,"a"
  	.quad 1b,ia32_badarg
  	.previous	
-	GET_THREAD_INFO(%r10)
-	orl    $TS_COMPAT,TI_status(%r10)
-	testl  $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%r10)
+	GET_THREAD_INFO(%r11)
+	orl    $TS_COMPAT,TI_status(%r11)
+	testl  $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%r11)
 	CFI_REMEMBER_STATE
 	jnz  sysenter_tracesys
 	cmpq	$(IA32_NR_syscalls-1),%rax
@@ -162,16 +203,18 @@ sysenter_do_call:
 sysenter_dispatch:
 	call	*ia32_sys_call_table(,%rax,8)
 	movq	%rax,RAX-ARGOFFSET(%rsp)
-	GET_THREAD_INFO(%r10)
+	GET_THREAD_INFO(%r11)
 	DISABLE_INTERRUPTS(CLBR_NONE)
 	TRACE_IRQS_OFF
-	testl	$_TIF_ALLWORK_MASK,TI_flags(%r10)
+	testl	$_TIF_ALLWORK_MASK,TI_flags(%r11)
 	jnz	sysexit_audit
 sysexit_from_sys_call:
-	andl    $~TS_COMPAT,TI_status(%r10)
+	pax_exit_kernel_user
+	pax_erase_kstack
+	andl    $~TS_COMPAT,TI_status(%r11)
 	/* clear IF, that popfq doesn't enable interrupts early */
-	andl  $~0x200,EFLAGS-R11(%rsp) 
-	movl	RIP-R11(%rsp),%edx		/* User %eip */
+	andl  $~X86_EFLAGS_IF,EFLAGS(%rsp) 
+	movl	RIP(%rsp),%edx		/* User %eip */
 	CFI_REGISTER rip,rdx
 	RESTORE_ARGS 0,24,0,0,0,0
 	xorq	%r8,%r8
@@ -194,6 +237,9 @@ sysexit_from_sys_call:
 	movl %eax,%esi			/* 2nd arg: syscall number */
 	movl $AUDIT_ARCH_I386,%edi	/* 1st arg: audit arch */
 	call audit_syscall_entry
+
+	pax_erase_kstack
+
 	movl RAX-ARGOFFSET(%rsp),%eax	/* reload syscall number */
 	cmpq $(IA32_NR_syscalls-1),%rax
 	ja ia32_badsys
@@ -205,7 +251,7 @@ sysexit_from_sys_call:
 	.endm
 
 	.macro auditsys_exit exit
-	testl $(_TIF_ALLWORK_MASK & ~_TIF_SYSCALL_AUDIT),TI_flags(%r10)
+	testl $(_TIF_ALLWORK_MASK & ~_TIF_SYSCALL_AUDIT),TI_flags(%r11)
 	jnz ia32_ret_from_sys_call
 	TRACE_IRQS_ON
 	ENABLE_INTERRUPTS(CLBR_NONE)
@@ -215,12 +261,12 @@ sysexit_from_sys_call:
 	movzbl %al,%edi		/* zero-extend that into %edi */
 	inc %edi /* first arg, 0->1(AUDITSC_SUCCESS), 1->2(AUDITSC_FAILURE) */
 	call audit_syscall_exit
-	GET_THREAD_INFO(%r10)
+	GET_THREAD_INFO(%r11)
 	movl RAX-ARGOFFSET(%rsp),%eax	/* reload syscall return value */
 	movl $(_TIF_ALLWORK_MASK & ~_TIF_SYSCALL_AUDIT),%edi
 	DISABLE_INTERRUPTS(CLBR_NONE)
 	TRACE_IRQS_OFF
-	testl %edi,TI_flags(%r10)
+	testl %edi,TI_flags(%r11)
 	jz \exit
 	CLEAR_RREGS -ARGOFFSET
 	jmp int_with_check
@@ -238,7 +284,7 @@ sysexit_audit:
 
 sysenter_tracesys:
 #ifdef CONFIG_AUDITSYSCALL
-	testl	$(_TIF_WORK_SYSCALL_ENTRY & ~_TIF_SYSCALL_AUDIT),TI_flags(%r10)
+	testl	$(_TIF_WORK_SYSCALL_ENTRY & ~_TIF_SYSCALL_AUDIT),TI_flags(%r11)
 	jz	sysenter_auditsys
 #endif
 	SAVE_REST
@@ -250,6 +296,9 @@ sysenter_tracesys:
 	RESTORE_REST
 	cmpq	$(IA32_NR_syscalls-1),%rax
 	ja	int_ret_from_sys_call /* sysenter_tracesys has set RAX(%rsp) */
+
+	pax_erase_kstack
+
 	jmp	sysenter_do_call
 	CFI_ENDPROC
 ENDPROC(ia32_sysenter_target)
@@ -277,19 +326,25 @@ ENDPROC(ia32_sysenter_target)
 ENTRY(ia32_cstar_target)
 	CFI_STARTPROC32	simple
 	CFI_SIGNAL_FRAME
-	CFI_DEF_CFA	rsp,KERNEL_STACK_OFFSET
+	CFI_DEF_CFA	rsp,0
 	CFI_REGISTER	rip,rcx
 	/*CFI_REGISTER	rflags,r11*/
 	SWAPGS_UNSAFE_STACK
 	movl	%esp,%r8d
 	CFI_REGISTER	rsp,r8
 	movq	PER_CPU_VAR(kernel_stack),%rsp
+	SAVE_ARGS 8*6,0,0
+	pax_enter_kernel_user
+
+#ifdef CONFIG_PAX_RANDKSTACK
+	pax_erase_kstack
+#endif
+
 	/*
 	 * No need to follow this irqs on/off section: the syscall
 	 * disabled irqs and here we enable it straight after entry:
 	 */
 	ENABLE_INTERRUPTS(CLBR_NONE)
-	SAVE_ARGS 8,0,0
 	movl 	%eax,%eax	/* zero extension */
 	movq	%rax,ORIG_RAX-ARGOFFSET(%rsp)
 	movq	%rcx,RIP-ARGOFFSET(%rsp)
@@ -305,13 +360,19 @@ ENTRY(ia32_cstar_target)
 	/* no need to do an access_ok check here because r8 has been
 	   32bit zero extended */ 
 	/* hardware stack frame is complete now */	
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	mov pax_user_shadow_base,%r11
+	add %r11,%r8
+#endif
+
 1:	movl	(%r8),%r9d
 	.section __ex_table,"a"
 	.quad 1b,ia32_badarg
 	.previous	
-	GET_THREAD_INFO(%r10)
-	orl   $TS_COMPAT,TI_status(%r10)
-	testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%r10)
+	GET_THREAD_INFO(%r11)
+	orl   $TS_COMPAT,TI_status(%r11)
+	testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%r11)
 	CFI_REMEMBER_STATE
 	jnz   cstar_tracesys
 	cmpq $IA32_NR_syscalls-1,%rax
@@ -321,14 +382,16 @@ cstar_do_call:
 cstar_dispatch:
 	call *ia32_sys_call_table(,%rax,8)
 	movq %rax,RAX-ARGOFFSET(%rsp)
-	GET_THREAD_INFO(%r10)
+	GET_THREAD_INFO(%r11)
 	DISABLE_INTERRUPTS(CLBR_NONE)
 	TRACE_IRQS_OFF
-	testl $_TIF_ALLWORK_MASK,TI_flags(%r10)
+	testl $_TIF_ALLWORK_MASK,TI_flags(%r11)
 	jnz sysretl_audit
 sysretl_from_sys_call:
-	andl $~TS_COMPAT,TI_status(%r10)
-	RESTORE_ARGS 0,-ARG_SKIP,0,0,0
+	pax_exit_kernel_user
+	pax_erase_kstack
+	andl $~TS_COMPAT,TI_status(%r11)
+	RESTORE_ARGS 0,-ORIG_RAX,0,0,0
 	movl RIP-ARGOFFSET(%rsp),%ecx
 	CFI_REGISTER rip,rcx
 	movl EFLAGS-ARGOFFSET(%rsp),%r11d	
@@ -355,7 +418,7 @@ sysretl_audit:
 
 cstar_tracesys:
 #ifdef CONFIG_AUDITSYSCALL
-	testl $(_TIF_WORK_SYSCALL_ENTRY & ~_TIF_SYSCALL_AUDIT),TI_flags(%r10)
+	testl $(_TIF_WORK_SYSCALL_ENTRY & ~_TIF_SYSCALL_AUDIT),TI_flags(%r11)
 	jz cstar_auditsys
 #endif
 	xchgl %r9d,%ebp
@@ -369,6 +432,9 @@ cstar_tracesys:
 	xchgl %ebp,%r9d
 	cmpq $(IA32_NR_syscalls-1),%rax
 	ja int_ret_from_sys_call /* cstar_tracesys has set RAX(%rsp) */
+
+	pax_erase_kstack
+
 	jmp cstar_do_call
 END(ia32_cstar_target)
 				
@@ -409,20 +475,26 @@ ENTRY(ia32_syscall)
 	CFI_REL_OFFSET	rip,RIP-RIP
 	PARAVIRT_ADJUST_EXCEPTION_FRAME
 	SWAPGS
-	/*
-	 * No need to follow this irqs on/off section: the syscall
-	 * disabled irqs and here we enable it straight after entry:
-	 */
-	ENABLE_INTERRUPTS(CLBR_NONE)
 	movl %eax,%eax
 	pushq_cfi %rax
 	cld
 	/* note the registers are not zero extended to the sf.
 	   this could be a problem. */
 	SAVE_ARGS 0,1,0
-	GET_THREAD_INFO(%r10)
-	orl   $TS_COMPAT,TI_status(%r10)
-	testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%r10)
+	pax_enter_kernel_user
+
+#ifdef CONFIG_PAX_RANDKSTACK
+	pax_erase_kstack
+#endif
+
+	/*
+	 * No need to follow this irqs on/off section: the syscall
+	 * disabled irqs and here we enable it straight after entry:
+	 */
+	ENABLE_INTERRUPTS(CLBR_NONE)
+	GET_THREAD_INFO(%r11)
+	orl   $TS_COMPAT,TI_status(%r11)
+	testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%r11)
 	jnz ia32_tracesys
 	cmpq $(IA32_NR_syscalls-1),%rax
 	ja ia32_badsys
@@ -445,6 +517,9 @@ ia32_tracesys:
 	RESTORE_REST
 	cmpq $(IA32_NR_syscalls-1),%rax
 	ja  int_ret_from_sys_call	/* ia32_tracesys has set RAX(%rsp) */
+
+	pax_erase_kstack
+
 	jmp ia32_do_call
 END(ia32_syscall)
 
@@ -455,6 +530,7 @@ ia32_badsys:
 
 quiet_ni_syscall:
 	movq $-ENOSYS,%rax
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 	
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/ia32/ia32_signal.c linux-3.2.71-pax/arch/x86/ia32/ia32_signal.c
--- linux-3.2.71/arch/x86/ia32/ia32_signal.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/ia32/ia32_signal.c	2014-01-28 04:21:56.113073863 +0100
@@ -169,7 +169,7 @@ asmlinkage long sys32_sigaltstack(const
 	}
 	seg = get_fs();
 	set_fs(KERNEL_DS);
-	ret = do_sigaltstack(uss_ptr ? &uss : NULL, &uoss, regs->sp);
+	ret = do_sigaltstack(uss_ptr ? (const stack_t __force_user *)&uss : NULL, (stack_t __force_user *)&uoss, regs->sp);
 	set_fs(seg);
 	if (ret >= 0 && uoss_ptr)  {
 		if (!access_ok(VERIFY_WRITE, uoss_ptr, sizeof(stack_ia32_t)))
@@ -276,7 +276,7 @@ asmlinkage long sys32_sigreturn(struct p
 	if (__get_user(set.sig[0], &frame->sc.oldmask)
 	    || (_COMPAT_NSIG_WORDS > 1
 		&& __copy_from_user((((char *) &set.sig) + 4),
-				    &frame->extramask,
+				    frame->extramask,
 				    sizeof(frame->extramask))))
 		goto badframe;
 
@@ -370,7 +370,7 @@ static int ia32_setup_sigcontext(struct
  */
 static void __user *get_sigframe(struct k_sigaction *ka, struct pt_regs *regs,
 				 size_t frame_size,
-				 void **fpstate)
+				 void __user **fpstate)
 {
 	unsigned long sp;
 
@@ -391,7 +391,7 @@ static void __user *get_sigframe(struct
 
 	if (used_math()) {
 		sp = sp - sig_xstate_ia32_size;
-		*fpstate = (struct _fpstate_ia32 *) sp;
+		*fpstate = (struct _fpstate_ia32 __user *) sp;
 		if (save_i387_xstate_ia32(*fpstate) < 0)
 			return (void __user *) -1L;
 	}
@@ -399,7 +399,7 @@ static void __user *get_sigframe(struct
 	sp -= frame_size;
 	/* Align the stack pointer according to the i386 ABI,
 	 * i.e. so that on function entry ((sp + 4) & 15) == 0. */
-	sp = ((sp + 4) & -16ul) - 4;
+	sp = ((sp - 12) & -16ul) - 4;
 	return (void __user *) sp;
 }
 
@@ -447,7 +447,7 @@ int ia32_setup_frame(int sig, struct k_s
 			restorer = VDSO32_SYMBOL(current->mm->context.vdso,
 						 sigreturn);
 		else
-			restorer = &frame->retcode;
+			restorer = frame->retcode;
 	}
 
 	put_user_try {
@@ -457,7 +457,7 @@ int ia32_setup_frame(int sig, struct k_s
 		 * These are actually not used anymore, but left because some
 		 * gdb versions depend on them as a marker.
 		 */
-		put_user_ex(*((u64 *)&code), (u64 *)frame->retcode);
+		put_user_ex(*((const u64 *)&code), (u64 __user *)frame->retcode);
 	} put_user_catch(err);
 
 	if (err)
@@ -499,7 +499,7 @@ int ia32_setup_rt_frame(int sig, struct
 		0xb8,
 		__NR_ia32_rt_sigreturn,
 		0x80cd,
-		0,
+		0
 	};
 
 	frame = get_sigframe(ka, regs, sizeof(*frame), &fpstate);
@@ -529,16 +529,18 @@ int ia32_setup_rt_frame(int sig, struct
 
 		if (ka->sa.sa_flags & SA_RESTORER)
 			restorer = ka->sa.sa_restorer;
+		else if (current->mm->context.vdso)
+			/* Return stub is in 32bit vsyscall page */
+			restorer = VDSO32_SYMBOL(current->mm->context.vdso, rt_sigreturn);
 		else
-			restorer = VDSO32_SYMBOL(current->mm->context.vdso,
-						 rt_sigreturn);
+			restorer = frame->retcode;
 		put_user_ex(ptr_to_compat(restorer), &frame->pretcode);
 
 		/*
 		 * Not actually used anymore, but left because some gdb
 		 * versions need it.
 		 */
-		put_user_ex(*((u64 *)&code), (u64 *)frame->retcode);
+		put_user_ex(*((const u64 *)&code), (u64 __user *)frame->retcode);
 	} put_user_catch(err);
 
 	if (err)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/ia32/sys_ia32.c linux-3.2.71-pax/arch/x86/ia32/sys_ia32.c
--- linux-3.2.71/arch/x86/ia32/sys_ia32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/ia32/sys_ia32.c	2012-07-04 19:24:47.464063003 +0200
@@ -69,8 +69,8 @@ asmlinkage long sys32_ftruncate64(unsign
  */
 static int cp_stat64(struct stat64 __user *ubuf, struct kstat *stat)
 {
-	typeof(ubuf->st_uid) uid = 0;
-	typeof(ubuf->st_gid) gid = 0;
+	typeof(((struct stat64 *)0)->st_uid) uid = 0;
+	typeof(((struct stat64 *)0)->st_gid) gid = 0;
 	SET_UID(uid, stat->uid);
 	SET_GID(gid, stat->gid);
 	if (!access_ok(VERIFY_WRITE, ubuf, sizeof(struct stat64)) ||
@@ -308,8 +308,8 @@ asmlinkage long sys32_rt_sigprocmask(int
 	}
 	set_fs(KERNEL_DS);
 	ret = sys_rt_sigprocmask(how,
-				 set ? (sigset_t __user *)&s : NULL,
-				 oset ? (sigset_t __user *)&s : NULL,
+				 set ? (sigset_t __force_user *)&s : NULL,
+				 oset ? (sigset_t __force_user *)&s : NULL,
 				 sigsetsize);
 	set_fs(old_fs);
 	if (ret)
@@ -332,7 +332,7 @@ asmlinkage long sys32_alarm(unsigned int
 	return alarm_setitimer(seconds);
 }
 
-asmlinkage long sys32_waitpid(compat_pid_t pid, unsigned int *stat_addr,
+asmlinkage long sys32_waitpid(compat_pid_t pid, unsigned int __user *stat_addr,
 			      int options)
 {
 	return compat_sys_wait4(pid, stat_addr, options, NULL);
@@ -353,7 +353,7 @@ asmlinkage long sys32_sched_rr_get_inter
 	mm_segment_t old_fs = get_fs();
 
 	set_fs(KERNEL_DS);
-	ret = sys_sched_rr_get_interval(pid, (struct timespec __user *)&t);
+	ret = sys_sched_rr_get_interval(pid, (struct timespec __force_user *)&t);
 	set_fs(old_fs);
 	if (put_compat_timespec(&t, interval))
 		return -EFAULT;
@@ -369,7 +369,7 @@ asmlinkage long sys32_rt_sigpending(comp
 	mm_segment_t old_fs = get_fs();
 
 	set_fs(KERNEL_DS);
-	ret = sys_rt_sigpending((sigset_t __user *)&s, sigsetsize);
+	ret = sys_rt_sigpending((sigset_t __force_user *)&s, sigsetsize);
 	set_fs(old_fs);
 	if (!ret) {
 		switch (_NSIG_WORDS) {
@@ -394,7 +394,7 @@ asmlinkage long sys32_rt_sigqueueinfo(in
 	if (copy_siginfo_from_user32(&info, uinfo))
 		return -EFAULT;
 	set_fs(KERNEL_DS);
-	ret = sys_rt_sigqueueinfo(pid, sig, (siginfo_t __user *)&info);
+	ret = sys_rt_sigqueueinfo(pid, sig, (siginfo_t __force_user *)&info);
 	set_fs(old_fs);
 	return ret;
 }
@@ -439,7 +439,7 @@ asmlinkage long sys32_sendfile(int out_f
 		return -EFAULT;
 
 	set_fs(KERNEL_DS);
-	ret = sys_sendfile(out_fd, in_fd, offset ? (off_t __user *)&of : NULL,
+	ret = sys_sendfile(out_fd, in_fd, offset ? (off_t __force_user *)&of : NULL,
 			   count);
 	set_fs(old_fs);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/alternative-asm.h linux-3.2.71-pax/arch/x86/include/asm/alternative-asm.h
--- linux-3.2.71/arch/x86/include/asm/alternative-asm.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/alternative-asm.h	2013-12-10 22:41:21.275125546 +0100
@@ -4,10 +4,10 @@
 
 #ifdef CONFIG_SMP
 	.macro LOCK_PREFIX
-1:	lock
+672:	lock
 	.section .smp_locks,"a"
 	.balign 4
-	.long 1b - .
+	.long 672b - .
 	.previous
 	.endm
 #else
@@ -15,6 +15,45 @@
 	.endm
 #endif
 
+#ifdef KERNEXEC_PLUGIN
+	.macro pax_force_retaddr_bts rip=0
+	btsq $63,\rip(%rsp)
+	.endm
+#ifdef CONFIG_PAX_KERNEXEC_PLUGIN_METHOD_BTS
+	.macro pax_force_retaddr rip=0, reload=0
+	btsq $63,\rip(%rsp)
+	.endm
+	.macro pax_force_fptr ptr
+	btsq $63,\ptr
+	.endm
+	.macro pax_set_fptr_mask
+	.endm
+#endif
+#ifdef CONFIG_PAX_KERNEXEC_PLUGIN_METHOD_OR
+	.macro pax_force_retaddr rip=0, reload=0
+	.if \reload
+	pax_set_fptr_mask
+	.endif
+	orq %r12,\rip(%rsp)
+	.endm
+	.macro pax_force_fptr ptr
+	orq %r12,\ptr
+	.endm
+	.macro pax_set_fptr_mask
+	movabs $0x8000000000000000,%r12
+	.endm
+#endif
+#else
+	.macro pax_force_retaddr rip=0, reload=0
+	.endm
+	.macro pax_force_fptr ptr
+	.endm
+	.macro pax_force_retaddr_bts rip=0
+	.endm
+	.macro pax_set_fptr_mask
+	.endm
+#endif
+
 .macro altinstruction_entry orig alt feature orig_len alt_len
 	.long \orig - .
 	.long \alt - .
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/alternative.h linux-3.2.71-pax/arch/x86/include/asm/alternative.h
--- linux-3.2.71/arch/x86/include/asm/alternative.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/alternative.h	2012-07-04 19:24:47.464063003 +0200
@@ -89,7 +89,7 @@ static inline int alternatives_text_rese
       ".section .discard,\"aw\",@progbits\n"				\
       "	 .byte 0xff + (664f-663f) - (662b-661b)\n" /* rlen <= slen */	\
       ".previous\n"							\
-      ".section .altinstr_replacement, \"ax\"\n"			\
+      ".section .altinstr_replacement, \"a\"\n"			\
       "663:\n\t" newinstr "\n664:\n"		/* replacement     */	\
       ".previous"
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/apic.h linux-3.2.71-pax/arch/x86/include/asm/apic.h
--- linux-3.2.71/arch/x86/include/asm/apic.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/apic.h	2012-07-04 19:24:47.464063003 +0200
@@ -45,7 +45,7 @@ static inline void generic_apic_probe(vo
 
 #ifdef CONFIG_X86_LOCAL_APIC
 
-extern unsigned int apic_verbosity;
+extern int apic_verbosity;
 extern int local_apic_timer_c2_ok;
 
 extern int disable_apic;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/apm.h linux-3.2.71-pax/arch/x86/include/asm/apm.h
--- linux-3.2.71/arch/x86/include/asm/apm.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/apm.h	2012-07-04 19:24:47.464063003 +0200
@@ -34,7 +34,7 @@ static inline void apm_bios_call_asm(u32
 	__asm__ __volatile__(APM_DO_ZERO_SEGS
 		"pushl %%edi\n\t"
 		"pushl %%ebp\n\t"
-		"lcall *%%cs:apm_bios_entry\n\t"
+		"lcall *%%ss:apm_bios_entry\n\t"
 		"setc %%al\n\t"
 		"popl %%ebp\n\t"
 		"popl %%edi\n\t"
@@ -58,7 +58,7 @@ static inline u8 apm_bios_call_simple_as
 	__asm__ __volatile__(APM_DO_ZERO_SEGS
 		"pushl %%edi\n\t"
 		"pushl %%ebp\n\t"
-		"lcall *%%cs:apm_bios_entry\n\t"
+		"lcall *%%ss:apm_bios_entry\n\t"
 		"setc %%bl\n\t"
 		"popl %%ebp\n\t"
 		"popl %%edi\n\t"
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/atomic64_32.h linux-3.2.71-pax/arch/x86/include/asm/atomic64_32.h
--- linux-3.2.71/arch/x86/include/asm/atomic64_32.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/atomic64_32.h	2013-12-19 02:23:31.360763042 +0100
@@ -12,6 +12,14 @@ typedef struct {
 	u64 __aligned(8) counter;
 } atomic64_t;
 
+#ifdef CONFIG_PAX_REFCOUNT
+typedef struct {
+	u64 __aligned(8) counter;
+} atomic64_unchecked_t;
+#else
+typedef atomic64_t atomic64_unchecked_t;
+#endif
+
 #define ATOMIC64_INIT(val)	{ (val) }
 
 #ifdef CONFIG_X86_CMPXCHG64
@@ -38,6 +46,21 @@ static inline long long atomic64_cmpxchg
 }
 
 /**
+ * atomic64_cmpxchg_unchecked - cmpxchg atomic64 variable
+ * @p: pointer to type atomic64_unchecked_t
+ * @o: expected value
+ * @n: new value
+ *
+ * Atomically sets @v to @n if it was equal to @o and returns
+ * the old value.
+ */
+
+static inline long long atomic64_cmpxchg_unchecked(atomic64_unchecked_t *v, long long o, long long n)
+{
+	return cmpxchg64(&v->counter, o, n);
+}
+
+/**
  * atomic64_xchg - xchg atomic64 variable
  * @v: pointer to type atomic64_t
  * @n: value to assign
@@ -77,6 +100,24 @@ static inline void atomic64_set(atomic64
 }
 
 /**
+ * atomic64_set_unchecked - set atomic64 variable
+ * @v: pointer to type atomic64_unchecked_t
+ * @n: value to assign
+ *
+ * Atomically sets the value of @v to @n.
+ */
+static inline void atomic64_set_unchecked(atomic64_unchecked_t *v, long long i)
+{
+	unsigned high = (unsigned)(i >> 32);
+	unsigned low = (unsigned)i;
+	asm volatile(ATOMIC64_ALTERNATIVE(set)
+		     : "+b" (low), "+c" (high)
+		     : "S" (v)
+		     : "eax", "edx", "memory"
+		     );
+}
+
+/**
  * atomic64_read - read atomic64 variable
  * @v: pointer to type atomic64_t
  *
@@ -93,6 +134,22 @@ static inline long long atomic64_read(at
  }
 
 /**
+ * atomic64_read_unchecked - read atomic64 variable
+ * @v: pointer to type atomic64_unchecked_t
+ *
+ * Atomically reads the value of @v and returns it.
+ */
+static inline long long __intentional_overflow(-1) atomic64_read_unchecked(atomic64_unchecked_t *v)
+{
+	long long r;
+	asm volatile(ATOMIC64_ALTERNATIVE(read_unchecked)
+		     : "=A" (r), "+c" (v)
+		     : : "memory"
+		     );
+	return r;
+ }
+
+/**
  * atomic64_add_return - add and return
  * @i: integer value to add
  * @v: pointer to type atomic64_t
@@ -108,6 +165,22 @@ static inline long long atomic64_add_ret
 	return i;
 }
 
+/**
+ * atomic64_add_return_unchecked - add and return
+ * @i: integer value to add
+ * @v: pointer to type atomic64_unchecked_t
+ *
+ * Atomically adds @i to @v and returns @i + *@v
+ */
+static inline long long atomic64_add_return_unchecked(long long i, atomic64_unchecked_t *v)
+{
+	asm volatile(ATOMIC64_ALTERNATIVE(add_return_unchecked)
+		     : "+A" (i), "+c" (v)
+		     : : "memory"
+		     );
+	return i;
+}
+
 /*
  * Other variants with different arithmetic operators:
  */
@@ -131,6 +204,17 @@ static inline long long atomic64_inc_ret
 	return a;
 }
 
+static inline long long atomic64_inc_return_unchecked(atomic64_unchecked_t *v)
+{
+	long long a;
+	asm volatile(ATOMIC64_ALTERNATIVE(inc_return_unchecked)
+		     : "=A" (a)
+		     : "S" (v)
+		     : "memory", "ecx"
+		     );
+	return a;
+}
+
 static inline long long atomic64_dec_return(atomic64_t *v)
 {
 	long long a;
@@ -155,6 +239,22 @@ static inline long long atomic64_add(lon
 		     : "+A" (i), "+c" (v)
 		     : : "memory"
 		     );
+	return i;
+}
+
+/**
+ * atomic64_add_unchecked - add integer to atomic64 variable
+ * @i: integer value to add
+ * @v: pointer to type atomic64_unchecked_t
+ *
+ * Atomically adds @i to @v.
+ */
+static inline long long atomic64_add_unchecked(long long i, atomic64_unchecked_t *v)
+{
+	asm volatile(ATOMIC64_ALTERNATIVE_(add_unchecked, add_return_unchecked)
+		     : "+A" (i), "+c" (v)
+		     : : "memory"
+		     );
 	return i;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/atomic64_64.h linux-3.2.71-pax/arch/x86/include/asm/atomic64_64.h
--- linux-3.2.71/arch/x86/include/asm/atomic64_64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/atomic64_64.h	2013-12-19 02:23:50.512762020 +0100
@@ -18,7 +18,19 @@
  */
 static inline long atomic64_read(const atomic64_t *v)
 {
-	return (*(volatile long *)&(v)->counter);
+	return (*(volatile const long *)&(v)->counter);
+}
+
+/**
+ * atomic64_read_unchecked - read atomic64 variable
+ * @v: pointer of type atomic64_unchecked_t
+ *
+ * Atomically reads the value of @v.
+ * Doesn't imply a read memory barrier.
+ */
+static inline long __intentional_overflow(-1) atomic64_read_unchecked(const atomic64_unchecked_t *v)
+{
+	return (*(volatile const long *)&(v)->counter);
 }
 
 /**
@@ -34,6 +46,18 @@ static inline void atomic64_set(atomic64
 }
 
 /**
+ * atomic64_set_unchecked - set atomic64 variable
+ * @v: pointer to type atomic64_unchecked_t
+ * @i: required value
+ *
+ * Atomically sets the value of @v to @i.
+ */
+static inline void atomic64_set_unchecked(atomic64_unchecked_t *v, long i)
+{
+	v->counter = i;
+}
+
+/**
  * atomic64_add - add integer to atomic64 variable
  * @i: integer value to add
  * @v: pointer to type atomic64_t
@@ -42,6 +66,28 @@ static inline void atomic64_set(atomic64
  */
 static inline void atomic64_add(long i, atomic64_t *v)
 {
+	asm volatile(LOCK_PREFIX "addq %1,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "subq %1,%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     : "=m" (v->counter)
+		     : "er" (i), "m" (v->counter));
+}
+
+/**
+ * atomic64_add_unchecked - add integer to atomic64 variable
+ * @i: integer value to add
+ * @v: pointer to type atomic64_unchecked_t
+ *
+ * Atomically adds @i to @v.
+ */
+static inline void atomic64_add_unchecked(long i, atomic64_unchecked_t *v)
+{
 	asm volatile(LOCK_PREFIX "addq %1,%0"
 		     : "=m" (v->counter)
 		     : "er" (i), "m" (v->counter));
@@ -56,7 +102,29 @@ static inline void atomic64_add(long i,
  */
 static inline void atomic64_sub(long i, atomic64_t *v)
 {
-	asm volatile(LOCK_PREFIX "subq %1,%0"
+	asm volatile(LOCK_PREFIX "subq %1,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "addq %1,%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     : "=m" (v->counter)
+		     : "er" (i), "m" (v->counter));
+}
+
+/**
+ * atomic64_sub_unchecked - subtract the atomic64 variable
+ * @i: integer value to subtract
+ * @v: pointer to type atomic64_unchecked_t
+ *
+ * Atomically subtracts @i from @v.
+ */
+static inline void atomic64_sub_unchecked(long i, atomic64_unchecked_t *v)
+{
+	asm volatile(LOCK_PREFIX "subq %1,%0\n"
 		     : "=m" (v->counter)
 		     : "er" (i), "m" (v->counter));
 }
@@ -74,7 +142,16 @@ static inline int atomic64_sub_and_test(
 {
 	unsigned char c;
 
-	asm volatile(LOCK_PREFIX "subq %2,%0; sete %1"
+	asm volatile(LOCK_PREFIX "subq %2,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "addq %2,%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     "sete %1\n"
 		     : "=m" (v->counter), "=qm" (c)
 		     : "er" (i), "m" (v->counter) : "memory");
 	return c;
@@ -88,6 +165,27 @@ static inline int atomic64_sub_and_test(
  */
 static inline void atomic64_inc(atomic64_t *v)
 {
+	asm volatile(LOCK_PREFIX "incq %0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "decq %0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     : "=m" (v->counter)
+		     : "m" (v->counter));
+}
+
+/**
+ * atomic64_inc_unchecked - increment atomic64 variable
+ * @v: pointer to type atomic64_unchecked_t
+ *
+ * Atomically increments @v by 1.
+ */
+static inline void atomic64_inc_unchecked(atomic64_unchecked_t *v)
+{
 	asm volatile(LOCK_PREFIX "incq %0"
 		     : "=m" (v->counter)
 		     : "m" (v->counter));
@@ -101,7 +199,28 @@ static inline void atomic64_inc(atomic64
  */
 static inline void atomic64_dec(atomic64_t *v)
 {
-	asm volatile(LOCK_PREFIX "decq %0"
+	asm volatile(LOCK_PREFIX "decq %0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "incq %0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     : "=m" (v->counter)
+		     : "m" (v->counter));
+}
+
+/**
+ * atomic64_dec_unchecked - decrement atomic64 variable
+ * @v: pointer to type atomic64_t
+ *
+ * Atomically decrements @v by 1.
+ */
+static inline void atomic64_dec_unchecked(atomic64_unchecked_t *v)
+{
+	asm volatile(LOCK_PREFIX "decq %0\n"
 		     : "=m" (v->counter)
 		     : "m" (v->counter));
 }
@@ -118,7 +237,16 @@ static inline int atomic64_dec_and_test(
 {
 	unsigned char c;
 
-	asm volatile(LOCK_PREFIX "decq %0; sete %1"
+	asm volatile(LOCK_PREFIX "decq %0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "incq %0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     "sete %1\n"
 		     : "=m" (v->counter), "=qm" (c)
 		     : "m" (v->counter) : "memory");
 	return c != 0;
@@ -136,7 +264,16 @@ static inline int atomic64_inc_and_test(
 {
 	unsigned char c;
 
-	asm volatile(LOCK_PREFIX "incq %0; sete %1"
+	asm volatile(LOCK_PREFIX "incq %0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "decq %0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     "sete %1\n"
 		     : "=m" (v->counter), "=qm" (c)
 		     : "m" (v->counter) : "memory");
 	return c != 0;
@@ -155,7 +292,16 @@ static inline int atomic64_add_negative(
 {
 	unsigned char c;
 
-	asm volatile(LOCK_PREFIX "addq %2,%0; sets %1"
+	asm volatile(LOCK_PREFIX "addq %2,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "subq %2,%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     "sets %1\n"
 		     : "=m" (v->counter), "=qm" (c)
 		     : "er" (i), "m" (v->counter) : "memory");
 	return c;
@@ -170,6 +316,18 @@ static inline int atomic64_add_negative(
  */
 static inline long atomic64_add_return(long i, atomic64_t *v)
 {
+	return i + xadd_check_overflow(&v->counter, i);
+}
+
+/**
+ * atomic64_add_return_unchecked - add and return
+ * @i: integer value to add
+ * @v: pointer to type atomic64_unchecked_t
+ *
+ * Atomically adds @i to @v and returns @i + @v
+ */
+static inline long atomic64_add_return_unchecked(long i, atomic64_unchecked_t *v)
+{
 	return i + xadd(&v->counter, i);
 }
 
@@ -179,6 +337,10 @@ static inline long atomic64_sub_return(l
 }
 
 #define atomic64_inc_return(v)  (atomic64_add_return(1, (v)))
+static inline long atomic64_inc_return_unchecked(atomic64_unchecked_t *v)
+{
+	return atomic64_add_return_unchecked(1, v);
+}
 #define atomic64_dec_return(v)  (atomic64_sub_return(1, (v)))
 
 static inline long atomic64_cmpxchg(atomic64_t *v, long old, long new)
@@ -186,6 +348,11 @@ static inline long atomic64_cmpxchg(atom
 	return cmpxchg(&v->counter, old, new);
 }
 
+static inline long atomic64_cmpxchg_unchecked(atomic64_unchecked_t *v, long old, long new)
+{
+	return cmpxchg(&v->counter, old, new);
+}
+
 static inline long atomic64_xchg(atomic64_t *v, long new)
 {
 	return xchg(&v->counter, new);
@@ -202,17 +369,30 @@ static inline long atomic64_xchg(atomic6
  */
 static inline int atomic64_add_unless(atomic64_t *v, long a, long u)
 {
-	long c, old;
+	long c, old, new;
 	c = atomic64_read(v);
 	for (;;) {
-		if (unlikely(c == (u)))
+		if (unlikely(c == u))
 			break;
-		old = atomic64_cmpxchg((v), c, c + (a));
+
+		asm volatile("add %2,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+			     "jno 0f\n"
+			     "sub %2,%0\n"
+			     "int $4\n0:\n"
+			     _ASM_EXTABLE(0b, 0b)
+#endif
+
+			     : "=r" (new)
+			     : "0" (c), "ir" (a));
+
+		old = atomic64_cmpxchg(v, c, new);
 		if (likely(old == c))
 			break;
 		c = old;
 	}
-	return c != (u);
+	return c != u;
 }
 
 #define atomic64_inc_not_zero(v) atomic64_add_unless((v), 1, 0)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/atomic.h linux-3.2.71-pax/arch/x86/include/asm/atomic.h
--- linux-3.2.71/arch/x86/include/asm/atomic.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/atomic.h	2015-01-05 18:18:50.099480823 +0100
@@ -22,7 +22,18 @@
  */
 static inline int atomic_read(const atomic_t *v)
 {
-	return (*(volatile int *)&(v)->counter);
+	return (*(volatile const int *)&(v)->counter);
+}
+
+/**
+ * atomic_read_unchecked - read atomic variable
+ * @v: pointer of type atomic_unchecked_t
+ *
+ * Atomically reads the value of @v.
+ */
+static inline int __intentional_overflow(-1) atomic_read_unchecked(const atomic_unchecked_t *v)
+{
+	return (*(volatile const int *)&(v)->counter);
 }
 
 /**
@@ -38,6 +49,18 @@ static inline void atomic_set(atomic_t *
 }
 
 /**
+ * atomic_set_unchecked - set atomic variable
+ * @v: pointer of type atomic_unchecked_t
+ * @i: required value
+ *
+ * Atomically sets the value of @v to @i.
+ */
+static inline void atomic_set_unchecked(atomic_unchecked_t *v, int i)
+{
+	v->counter = i;
+}
+
+/**
  * atomic_add - add integer to atomic variable
  * @i: integer value to add
  * @v: pointer of type atomic_t
@@ -46,7 +69,29 @@ static inline void atomic_set(atomic_t *
  */
 static inline void atomic_add(int i, atomic_t *v)
 {
-	asm volatile(LOCK_PREFIX "addl %1,%0"
+	asm volatile(LOCK_PREFIX "addl %1,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "subl %1,%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     : "+m" (v->counter)
+		     : "ir" (i));
+}
+
+/**
+ * atomic_add_unchecked - add integer to atomic variable
+ * @i: integer value to add
+ * @v: pointer of type atomic_unchecked_t
+ *
+ * Atomically adds @i to @v.
+ */
+static inline void atomic_add_unchecked(int i, atomic_unchecked_t *v)
+{
+	asm volatile(LOCK_PREFIX "addl %1,%0\n"
 		     : "+m" (v->counter)
 		     : "ir" (i));
 }
@@ -60,7 +105,29 @@ static inline void atomic_add(int i, ato
  */
 static inline void atomic_sub(int i, atomic_t *v)
 {
-	asm volatile(LOCK_PREFIX "subl %1,%0"
+	asm volatile(LOCK_PREFIX "subl %1,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "addl %1,%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     : "+m" (v->counter)
+		     : "ir" (i));
+}
+
+/**
+ * atomic_sub_unchecked - subtract integer from atomic variable
+ * @i: integer value to subtract
+ * @v: pointer of type atomic_unchecked_t
+ *
+ * Atomically subtracts @i from @v.
+ */
+static inline void atomic_sub_unchecked(int i, atomic_unchecked_t *v)
+{
+	asm volatile(LOCK_PREFIX "subl %1,%0\n"
 		     : "+m" (v->counter)
 		     : "ir" (i));
 }
@@ -78,7 +145,16 @@ static inline int atomic_sub_and_test(in
 {
 	unsigned char c;
 
-	asm volatile(LOCK_PREFIX "subl %2,%0; sete %1"
+	asm volatile(LOCK_PREFIX "subl %2,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "addl %2,%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     "sete %1\n"
 		     : "+m" (v->counter), "=qm" (c)
 		     : "ir" (i) : "memory");
 	return c;
@@ -92,7 +168,27 @@ static inline int atomic_sub_and_test(in
  */
 static inline void atomic_inc(atomic_t *v)
 {
-	asm volatile(LOCK_PREFIX "incl %0"
+	asm volatile(LOCK_PREFIX "incl %0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "decl %0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     : "+m" (v->counter));
+}
+
+/**
+ * atomic_inc_unchecked - increment atomic variable
+ * @v: pointer of type atomic_unchecked_t
+ *
+ * Atomically increments @v by 1.
+ */
+static inline void atomic_inc_unchecked(atomic_unchecked_t *v)
+{
+	asm volatile(LOCK_PREFIX "incl %0\n"
 		     : "+m" (v->counter));
 }
 
@@ -104,7 +200,27 @@ static inline void atomic_inc(atomic_t *
  */
 static inline void atomic_dec(atomic_t *v)
 {
-	asm volatile(LOCK_PREFIX "decl %0"
+	asm volatile(LOCK_PREFIX "decl %0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "incl %0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     : "+m" (v->counter));
+}
+
+/**
+ * atomic_dec_unchecked - decrement atomic variable
+ * @v: pointer of type atomic_unchecked_t
+ *
+ * Atomically decrements @v by 1.
+ */
+static inline void atomic_dec_unchecked(atomic_unchecked_t *v)
+{
+	asm volatile(LOCK_PREFIX "decl %0\n"
 		     : "+m" (v->counter));
 }
 
@@ -120,7 +236,16 @@ static inline int atomic_dec_and_test(at
 {
 	unsigned char c;
 
-	asm volatile(LOCK_PREFIX "decl %0; sete %1"
+	asm volatile(LOCK_PREFIX "decl %0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "incl %0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     "sete %1\n"
 		     : "+m" (v->counter), "=qm" (c)
 		     : : "memory");
 	return c != 0;
@@ -138,7 +263,35 @@ static inline int atomic_inc_and_test(at
 {
 	unsigned char c;
 
-	asm volatile(LOCK_PREFIX "incl %0; sete %1"
+	asm volatile(LOCK_PREFIX "incl %0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "decl %0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     "sete %1\n"
+		     : "+m" (v->counter), "=qm" (c)
+		     : : "memory");
+	return c != 0;
+}
+
+/**
+ * atomic_inc_and_test_unchecked - increment and test
+ * @v: pointer of type atomic_unchecked_t
+ *
+ * Atomically increments @v by 1
+ * and returns true if the result is zero, or false for all
+ * other cases.
+ */
+static inline int atomic_inc_and_test_unchecked(atomic_unchecked_t *v)
+{
+	unsigned char c;
+
+	asm volatile(LOCK_PREFIX "incl %0\n"
+		     "sete %1\n"
 		     : "+m" (v->counter), "=qm" (c)
 		     : : "memory");
 	return c != 0;
@@ -157,7 +310,16 @@ static inline int atomic_add_negative(in
 {
 	unsigned char c;
 
-	asm volatile(LOCK_PREFIX "addl %2,%0; sets %1"
+	asm volatile(LOCK_PREFIX "addl %2,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX "subl %2,%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     "sets %1\n"
 		     : "+m" (v->counter), "=qm" (c)
 		     : "ir" (i) : "memory");
 	return c;
@@ -170,7 +332,7 @@ static inline int atomic_add_negative(in
  *
  * Atomically adds @i to @v and returns @i + @v
  */
-static inline int atomic_add_return(int i, atomic_t *v)
+static inline int __intentional_overflow(-1) atomic_add_return(int i, atomic_t *v)
 {
 #ifdef CONFIG_M386
 	int __i;
@@ -179,7 +341,7 @@ static inline int atomic_add_return(int
 		goto no_xadd;
 #endif
 	/* Modern 486+ processor */
-	return i + xadd(&v->counter, i);
+	return i + xadd_check_overflow(&v->counter, i);
 
 #ifdef CONFIG_M386
 no_xadd: /* Legacy 386 processor */
@@ -192,21 +354,58 @@ no_xadd: /* Legacy 386 processor */
 }
 
 /**
+ * atomic_add_return_unchecked - add integer and return
+ * @i: integer value to add
+ * @v: pointer of type atomic_unchecked_t
+ *
+ * Atomically adds @i to @v and returns @i + @v
+ */
+static inline int __intentional_overflow(-1) atomic_add_return_unchecked(int i, atomic_unchecked_t *v)
+{
+#ifdef CONFIG_M386
+	int __i;
+	unsigned long flags;
+	if (unlikely(boot_cpu_data.x86 <= 3))
+		goto no_xadd;
+#endif
+	/* Modern 486+ processor */
+	return i + xadd(&v->counter, i);
+
+#ifdef CONFIG_M386
+no_xadd: /* Legacy 386 processor */
+	raw_local_irq_save(flags);
+	__i = atomic_read_unchecked(v);
+	atomic_set_unchecked(v, i + __i);
+	raw_local_irq_restore(flags);
+	return i + __i;
+#endif
+}
+
+/**
  * atomic_sub_return - subtract integer and return
  * @v: pointer of type atomic_t
  * @i: integer value to subtract
  *
  * Atomically subtracts @i from @v and returns @v - @i
  */
-static inline int atomic_sub_return(int i, atomic_t *v)
+static inline int __intentional_overflow(-1) atomic_sub_return(int i, atomic_t *v)
 {
 	return atomic_add_return(-i, v);
 }
 
 #define atomic_inc_return(v)  (atomic_add_return(1, v))
+static inline int __intentional_overflow(-1) atomic_inc_return_unchecked(atomic_unchecked_t *v)
+{
+	return atomic_add_return_unchecked(1, v);
+}
 #define atomic_dec_return(v)  (atomic_sub_return(1, v))
 
-static inline int atomic_cmpxchg(atomic_t *v, int old, int new)
+static inline int __intentional_overflow(-1) atomic_cmpxchg(atomic_t *v, int old, int new)
+{
+	return cmpxchg(&v->counter, old, new);
+}
+
+static inline int atomic_cmpxchg_unchecked(atomic_unchecked_t *v, int old, int new)
 {
 	return cmpxchg(&v->counter, old, new);
 }
@@ -216,6 +415,11 @@ static inline int atomic_xchg(atomic_t *
 	return xchg(&v->counter, new);
 }
 
+static inline int atomic_xchg_unchecked(atomic_unchecked_t *v, int new)
+{
+	return xchg(&v->counter, new);
+}
+
 /**
  * __atomic_add_unless - add unless the number is already a given value
  * @v: pointer of type atomic_t
@@ -227,12 +431,25 @@ static inline int atomic_xchg(atomic_t *
  */
 static inline int __atomic_add_unless(atomic_t *v, int a, int u)
 {
-	int c, old;
+	int c, old, new;
 	c = atomic_read(v);
 	for (;;) {
-		if (unlikely(c == (u)))
+		if (unlikely(c == u))
 			break;
-		old = atomic_cmpxchg((v), c, c + (a));
+
+		asm volatile("addl %2,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+			     "jno 0f\n"
+			     "subl %2,%0\n"
+			     "int $4\n0:\n"
+			     _ASM_EXTABLE(0b, 0b)
+#endif
+
+			     : "=r" (new)
+			     : "0" (c), "ir" (a));
+
+		old = atomic_cmpxchg(v, c, new);
 		if (likely(old == c))
 			break;
 		c = old;
@@ -240,6 +457,48 @@ static inline int __atomic_add_unless(at
 	return c;
 }
 
+/**
+ * atomic_inc_not_zero_hint - increment if not null
+ * @v: pointer of type atomic_t
+ * @hint: probable value of the atomic before the increment
+ *
+ * This version of atomic_inc_not_zero() gives a hint of probable
+ * value of the atomic. This helps processor to not read the memory
+ * before doing the atomic read/modify/write cycle, lowering
+ * number of bus transactions on some arches.
+ *
+ * Returns: 0 if increment was not done, 1 otherwise.
+ */
+#define atomic_inc_not_zero_hint atomic_inc_not_zero_hint
+static inline int atomic_inc_not_zero_hint(atomic_t *v, int hint)
+{
+	int val, c = hint, new;
+
+	/* sanity test, should be removed by compiler if hint is a constant */
+	if (!hint)
+		return __atomic_add_unless(v, 1, 0);
+
+	do {
+		asm volatile("incl %0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+			     "jno 0f\n"
+			     "decl %0\n"
+			     "int $4\n0:\n"
+			     _ASM_EXTABLE(0b, 0b)
+#endif
+
+			     : "=r" (new)
+			     : "0" (c));
+
+		val = atomic_cmpxchg(v, c, new);
+		if (val == c)
+			return 1;
+		c = val;
+	} while (c);
+
+	return 0;
+}
 
 /*
  * atomic_dec_if_positive - decrement by 1 if old value positive
@@ -293,14 +552,37 @@ static inline void atomic_or_long(unsign
 #endif
 
 /* These are x86-specific, used by some header files */
-#define atomic_clear_mask(mask, addr)				\
-	asm volatile(LOCK_PREFIX "andl %0,%1"			\
-		     : : "r" (~(mask)), "m" (*(addr)) : "memory")
-
-#define atomic_set_mask(mask, addr)				\
-	asm volatile(LOCK_PREFIX "orl %0,%1"			\
-		     : : "r" ((unsigned)(mask)), "m" (*(addr))	\
-		     : "memory")
+static inline void atomic_clear_mask(unsigned int mask, atomic_t *v)
+{
+	asm volatile(LOCK_PREFIX "andl %1,%0"
+		     : "+m" (v->counter)
+		     : "r" (~(mask))
+		     : "memory");
+}
+
+static inline void atomic_clear_mask_unchecked(unsigned int mask, atomic_unchecked_t *v)
+{
+	asm volatile(LOCK_PREFIX "andl %1,%0"
+		     : "+m" (v->counter)
+		     : "r" (~(mask))
+		     : "memory");
+}
+
+static inline void atomic_set_mask(unsigned int mask, atomic_t *v)
+{
+	asm volatile(LOCK_PREFIX "orl %1,%0"
+		     : "+m" (v->counter)
+		     : "r" (mask)
+		     : "memory");
+}
+
+static inline void atomic_set_mask_unchecked(unsigned int mask, atomic_unchecked_t *v)
+{
+	asm volatile(LOCK_PREFIX "orl %1,%0"
+		     : "+m" (v->counter)
+		     : "r" (mask)
+		     : "memory");
+}
 
 /* Atomic operations are already serializing on x86 */
 #define smp_mb__before_atomic_dec()	barrier()
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/bitops.h linux-3.2.71-pax/arch/x86/include/asm/bitops.h
--- linux-3.2.71/arch/x86/include/asm/bitops.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/bitops.h	2013-12-03 02:19:10.938699987 +0100
@@ -38,7 +38,7 @@
  * a mask operation on a byte.
  */
 #define IS_IMMEDIATE(nr)		(__builtin_constant_p(nr))
-#define CONST_MASK_ADDR(nr, addr)	BITOP_ADDR((void *)(addr) + ((nr)>>3))
+#define CONST_MASK_ADDR(nr, addr)	BITOP_ADDR((volatile void *)(addr) + ((nr)>>3))
 #define CONST_MASK(nr)			(1 << ((nr) & 7))
 
 /**
@@ -344,7 +344,7 @@ static int test_bit(int nr, const volati
  *
  * Undefined if no bit exists, so code should check against 0 first.
  */
-static inline unsigned long __ffs(unsigned long word)
+static inline unsigned long __intentional_overflow(-1) __ffs(unsigned long word)
 {
 	asm("bsf %1,%0"
 		: "=r" (word)
@@ -358,7 +358,7 @@ static inline unsigned long __ffs(unsign
  *
  * Undefined if no zero exists, so code should check against ~0UL first.
  */
-static inline unsigned long ffz(unsigned long word)
+static inline unsigned long __intentional_overflow(-1) ffz(unsigned long word)
 {
 	asm("bsf %1,%0"
 		: "=r" (word)
@@ -372,7 +372,7 @@ static inline unsigned long ffz(unsigned
  *
  * Undefined if no set bit exists, so code should check against 0 first.
  */
-static inline unsigned long __fls(unsigned long word)
+static inline unsigned long __intentional_overflow(-1) __fls(unsigned long word)
 {
 	asm("bsr %1,%0"
 	    : "=r" (word)
@@ -419,7 +419,7 @@ static inline int ffs(int x)
  * set bit if value is nonzero. The last (most significant) bit is
  * at position 32.
  */
-static inline int fls(int x)
+static inline int __intentional_overflow(-1) fls(int x)
 {
 	int r;
 #ifdef CONFIG_X86_CMOV
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/boot.h linux-3.2.71-pax/arch/x86/include/asm/boot.h
--- linux-3.2.71/arch/x86/include/asm/boot.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/boot.h	2012-07-04 19:24:47.468063007 +0200
@@ -11,10 +11,15 @@
 #include <asm/pgtable_types.h>
 
 /* Physical address where kernel should be loaded. */
-#define LOAD_PHYSICAL_ADDR ((CONFIG_PHYSICAL_START \
+#define ____LOAD_PHYSICAL_ADDR ((CONFIG_PHYSICAL_START \
 				+ (CONFIG_PHYSICAL_ALIGN - 1)) \
 				& ~(CONFIG_PHYSICAL_ALIGN - 1))
 
+#ifndef __ASSEMBLY__
+extern unsigned char __LOAD_PHYSICAL_ADDR[];
+#define LOAD_PHYSICAL_ADDR ((unsigned long)__LOAD_PHYSICAL_ADDR)
+#endif
+
 /* Minimum kernel alignment, as a power of two */
 #ifdef CONFIG_X86_64
 #define MIN_KERNEL_ALIGN_LG2	PMD_SHIFT
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/cacheflush.h linux-3.2.71-pax/arch/x86/include/asm/cacheflush.h
--- linux-3.2.71/arch/x86/include/asm/cacheflush.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/cacheflush.h	2012-07-04 19:24:47.468063007 +0200
@@ -26,7 +26,7 @@ static inline unsigned long get_page_mem
 	unsigned long pg_flags = pg->flags & _PGMT_MASK;
 
 	if (pg_flags == _PGMT_DEFAULT)
-		return -1;
+		return ~0UL;
 	else if (pg_flags == _PGMT_WC)
 		return _PAGE_CACHE_WC;
 	else if (pg_flags == _PGMT_UC_MINUS)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/cache.h linux-3.2.71-pax/arch/x86/include/asm/cache.h
--- linux-3.2.71/arch/x86/include/asm/cache.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/cache.h	2013-09-19 00:29:52.269652797 +0200
@@ -5,12 +5,13 @@
 
 /* L1 cache line size */
 #define L1_CACHE_SHIFT	(CONFIG_X86_L1_CACHE_SHIFT)
-#define L1_CACHE_BYTES	(1 << L1_CACHE_SHIFT)
+#define L1_CACHE_BYTES	(_AC(1,UL) << L1_CACHE_SHIFT)
 
 #define __read_mostly __attribute__((__section__(".data..read_mostly")))
+#define __read_only __attribute__((__section__(".data..read_only")))
 
 #define INTERNODE_CACHE_SHIFT CONFIG_X86_INTERNODE_CACHE_SHIFT
-#define INTERNODE_CACHE_BYTES (1 << INTERNODE_CACHE_SHIFT)
+#define INTERNODE_CACHE_BYTES (_AC(1,UL) << INTERNODE_CACHE_SHIFT)
 
 #ifdef CONFIG_X86_VSMP
 #ifdef CONFIG_SMP
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/calling.h linux-3.2.71-pax/arch/x86/include/asm/calling.h
--- linux-3.2.71/arch/x86/include/asm/calling.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/calling.h	2013-12-14 03:50:54.017513148 +0100
@@ -82,103 +82,113 @@ For 32-bit we have the following convent
 #define RSP		(152)
 #define SS		(160)
 
-#define ARGOFFSET	R11
-#define SWFRAME		ORIG_RAX
+#define ARGOFFSET	R15
 
 	.macro SAVE_ARGS addskip=0, save_rcx=1, save_r891011=1
-	subq  $9*8+\addskip, %rsp
-	CFI_ADJUST_CFA_OFFSET	9*8+\addskip
-	movq_cfi rdi, 8*8
-	movq_cfi rsi, 7*8
-	movq_cfi rdx, 6*8
+	subq  $ORIG_RAX-ARGOFFSET+\addskip, %rsp
+	CFI_ADJUST_CFA_OFFSET	ORIG_RAX-ARGOFFSET+\addskip
+	movq_cfi rdi, RDI
+	movq_cfi rsi, RSI
+	movq_cfi rdx, RDX
 
 	.if \save_rcx
-	movq_cfi rcx, 5*8
+	movq_cfi rcx, RCX
 	.endif
 
-	movq_cfi rax, 4*8
+	movq_cfi rax, RAX
 
 	.if \save_r891011
-	movq_cfi r8,  3*8
-	movq_cfi r9,  2*8
-	movq_cfi r10, 1*8
-	movq_cfi r11, 0*8
+	movq_cfi r8,  R8
+	movq_cfi r9,  R9
+	movq_cfi r10, R10
+	movq_cfi r11, R11
 	.endif
 
+#ifdef CONFIG_PAX_KERNEXEC_PLUGIN_METHOD_OR
+	movq_cfi r12, R12
+#endif
+
 	.endm
 
-#define ARG_SKIP	(9*8)
+#define ARG_SKIP	ORIG_RAX
 
 	.macro RESTORE_ARGS rstor_rax=1, addskip=0, rstor_rcx=1, rstor_r11=1, \
 			    rstor_r8910=1, rstor_rdx=1
+
+#ifdef CONFIG_PAX_KERNEXEC_PLUGIN_METHOD_OR
+	movq_cfi_restore R12, r12
+#endif
+
 	.if \rstor_r11
-	movq_cfi_restore 0*8, r11
+	movq_cfi_restore R11, r11
 	.endif
 
 	.if \rstor_r8910
-	movq_cfi_restore 1*8, r10
-	movq_cfi_restore 2*8, r9
-	movq_cfi_restore 3*8, r8
+	movq_cfi_restore R10, r10
+	movq_cfi_restore R9, r9
+	movq_cfi_restore R8, r8
 	.endif
 
 	.if \rstor_rax
-	movq_cfi_restore 4*8, rax
+	movq_cfi_restore RAX, rax
 	.endif
 
 	.if \rstor_rcx
-	movq_cfi_restore 5*8, rcx
+	movq_cfi_restore RCX, rcx
 	.endif
 
 	.if \rstor_rdx
-	movq_cfi_restore 6*8, rdx
+	movq_cfi_restore RDX, rdx
 	.endif
 
-	movq_cfi_restore 7*8, rsi
-	movq_cfi_restore 8*8, rdi
+	movq_cfi_restore RSI, rsi
+	movq_cfi_restore RDI, rdi
 
-	.if ARG_SKIP+\addskip > 0
-	addq $ARG_SKIP+\addskip, %rsp
-	CFI_ADJUST_CFA_OFFSET	-(ARG_SKIP+\addskip)
+	.if ORIG_RAX+\addskip > 0
+	addq $ORIG_RAX+\addskip, %rsp
+	CFI_ADJUST_CFA_OFFSET	-(ORIG_RAX+\addskip)
 	.endif
 	.endm
 
-	.macro LOAD_ARGS offset, skiprax=0
-	movq \offset(%rsp),    %r11
-	movq \offset+8(%rsp),  %r10
-	movq \offset+16(%rsp), %r9
-	movq \offset+24(%rsp), %r8
-	movq \offset+40(%rsp), %rcx
-	movq \offset+48(%rsp), %rdx
-	movq \offset+56(%rsp), %rsi
-	movq \offset+64(%rsp), %rdi
+	.macro LOAD_ARGS skiprax=0
+	movq R11(%rsp),    %r11
+	movq R10(%rsp),  %r10
+	movq R9(%rsp), %r9
+	movq R8(%rsp), %r8
+	movq RCX(%rsp), %rcx
+	movq RDX(%rsp), %rdx
+	movq RSI(%rsp), %rsi
+	movq RDI(%rsp), %rdi
 	.if \skiprax
 	.else
-	movq \offset+72(%rsp), %rax
+	movq RAX(%rsp), %rax
 	.endif
 	.endm
 
-#define REST_SKIP	(6*8)
-
 	.macro SAVE_REST
-	subq $REST_SKIP, %rsp
-	CFI_ADJUST_CFA_OFFSET	REST_SKIP
-	movq_cfi rbx, 5*8
-	movq_cfi rbp, 4*8
-	movq_cfi r12, 3*8
-	movq_cfi r13, 2*8
-	movq_cfi r14, 1*8
-	movq_cfi r15, 0*8
+	movq_cfi rbx, RBX
+	movq_cfi rbp, RBP
+
+#ifndef CONFIG_PAX_KERNEXEC_PLUGIN_METHOD_OR
+	movq_cfi r12, R12
+#endif
+
+	movq_cfi r13, R13
+	movq_cfi r14, R14
+	movq_cfi r15, R15
 	.endm
 
 	.macro RESTORE_REST
-	movq_cfi_restore 0*8, r15
-	movq_cfi_restore 1*8, r14
-	movq_cfi_restore 2*8, r13
-	movq_cfi_restore 3*8, r12
-	movq_cfi_restore 4*8, rbp
-	movq_cfi_restore 5*8, rbx
-	addq $REST_SKIP, %rsp
-	CFI_ADJUST_CFA_OFFSET	-(REST_SKIP)
+	movq_cfi_restore R15, r15
+	movq_cfi_restore R14, r14
+	movq_cfi_restore R13, r13
+
+#ifndef CONFIG_PAX_KERNEXEC_PLUGIN_METHOD_OR
+	movq_cfi_restore R12, r12
+#endif
+
+	movq_cfi_restore RBP, rbp
+	movq_cfi_restore RBX, rbx
 	.endm
 
 	.macro SAVE_ALL
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/checksum_32.h linux-3.2.71-pax/arch/x86/include/asm/checksum_32.h
--- linux-3.2.71/arch/x86/include/asm/checksum_32.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/checksum_32.h	2012-07-04 19:24:47.468063007 +0200
@@ -31,6 +31,14 @@ asmlinkage __wsum csum_partial_copy_gene
 					    int len, __wsum sum,
 					    int *src_err_ptr, int *dst_err_ptr);
 
+asmlinkage __wsum csum_partial_copy_generic_to_user(const void *src, void *dst,
+						  int len, __wsum sum,
+						  int *src_err_ptr, int *dst_err_ptr);
+
+asmlinkage __wsum csum_partial_copy_generic_from_user(const void *src, void *dst,
+						  int len, __wsum sum,
+						  int *src_err_ptr, int *dst_err_ptr);
+
 /*
  *	Note: when you get a NULL pointer exception here this means someone
  *	passed in an incorrect kernel address to one of these functions.
@@ -50,7 +58,7 @@ static inline __wsum csum_partial_copy_f
 						 int *err_ptr)
 {
 	might_sleep();
-	return csum_partial_copy_generic((__force void *)src, dst,
+	return csum_partial_copy_generic_from_user((__force void *)src, dst,
 					 len, sum, err_ptr, NULL);
 }
 
@@ -178,7 +186,7 @@ static inline __wsum csum_and_copy_to_us
 {
 	might_sleep();
 	if (access_ok(VERIFY_WRITE, dst, len))
-		return csum_partial_copy_generic(src, (__force void *)dst,
+		return csum_partial_copy_generic_to_user(src, (__force void *)dst,
 						 len, sum, NULL, err_ptr);
 
 	if (len)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/cmpxchg.h linux-3.2.71-pax/arch/x86/include/asm/cmpxchg.h
--- linux-3.2.71/arch/x86/include/asm/cmpxchg.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/cmpxchg.h	2012-07-04 19:24:47.472063008 +0200
@@ -14,6 +14,8 @@ extern void __cmpxchg_wrong_size(void)
 	__compiletime_error("Bad argument size for cmpxchg");
 extern void __xadd_wrong_size(void)
 	__compiletime_error("Bad argument size for xadd");
+extern void __xadd_check_overflow_wrong_size(void)
+	__compiletime_error("Bad argument size for xadd_check_overflow");
 
 /*
  * Constants for operation sizes. On 32-bit, the 64-bit size it set to
@@ -195,6 +197,34 @@ extern void __xadd_wrong_size(void)
 		__ret;							\
 	})
 
+#define __xadd_check_overflow(ptr, inc, lock)				\
+	({								\
+	        __typeof__ (*(ptr)) __ret = (inc);			\
+		switch (sizeof(*(ptr))) {				\
+		case __X86_CASE_L:					\
+			asm volatile (lock "xaddl %0, %1\n"		\
+				      "jno 0f\n"			\
+				      "mov %0,%1\n"			\
+				      "int $4\n0:\n"			\
+				      _ASM_EXTABLE(0b, 0b)		\
+				      : "+r" (__ret), "+m" (*(ptr))	\
+				      : : "memory", "cc");		\
+			break;						\
+		case __X86_CASE_Q:					\
+			asm volatile (lock "xaddq %q0, %1\n"		\
+				      "jno 0f\n"			\
+				      "mov %0,%1\n"			\
+				      "int $4\n0:\n"			\
+				      _ASM_EXTABLE(0b, 0b)		\
+				      : "+r" (__ret), "+m" (*(ptr))	\
+				      : : "memory", "cc");		\
+			break;						\
+		default:						\
+			__xadd_check_overflow_wrong_size();		\
+		}							\
+		__ret;							\
+	})
+
 /*
  * xadd() adds "inc" to "*ptr" and atomically returns the previous
  * value of "*ptr".
@@ -207,4 +237,6 @@ extern void __xadd_wrong_size(void)
 #define xadd_sync(ptr, inc)	__xadd((ptr), (inc), "lock; ")
 #define xadd_local(ptr, inc)	__xadd((ptr), (inc), "")
 
+#define xadd_check_overflow(ptr, inc)	__xadd_check_overflow((ptr), (inc), LOCK_PREFIX)
+
 #endif	/* ASM_X86_CMPXCHG_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/compat.h linux-3.2.71-pax/arch/x86/include/asm/compat.h
--- linux-3.2.71/arch/x86/include/asm/compat.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/compat.h	2013-03-28 05:04:13.067758956 +0100
@@ -194,7 +194,7 @@ typedef struct user_regs_struct32 compat
  * as pointers because the syscall entry code will have
  * appropriately converted them already.
  */
-typedef	u32		compat_uptr_t;
+typedef u32		__user compat_uptr_t;
 
 static inline void __user *compat_ptr(compat_uptr_t uptr)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/cpufeature.h linux-3.2.71-pax/arch/x86/include/asm/cpufeature.h
--- linux-3.2.71/arch/x86/include/asm/cpufeature.h	2015-01-01 15:15:23.708069605 +0100
+++ linux-3.2.71-pax/arch/x86/include/asm/cpufeature.h	2015-01-01 15:15:28.816069738 +0100
@@ -198,8 +198,9 @@
 
 /* Intel-defined CPU features, CPUID level 0x00000007:0 (ebx), word 9 */
 #define X86_FEATURE_FSGSBASE	(9*32+ 0) /* {RD/WR}{FS/GS}BASE instructions*/
-#define X86_FEATURE_SMEP	(9*32+ 7) /* Supervisor Mode Execution Protection */
+#define X86_FEATURE_SMEP	(9*32+ 7) /* Supervisor Mode Execution Prevention */
 #define X86_FEATURE_ERMS	(9*32+ 9) /* Enhanced REP MOVSB/STOSB */
+#define X86_FEATURE_SMAP	(9*32+20) /* Supervisor Mode Access Prevention */
 
 #if defined(__KERNEL__) && !defined(__ASSEMBLY__)
 
@@ -364,7 +365,7 @@ static __always_inline __pure bool __sta
 			     ".section .discard,\"aw\",@progbits\n"
 			     " .byte 0xff + (4f-3f) - (2b-1b)\n" /* size check */
 			     ".previous\n"
-			     ".section .altinstr_replacement,\"ax\"\n"
+			     ".section .altinstr_replacement,\"a\"\n"
 			     "3: movb $1,%0\n"
 			     "4:\n"
 			     ".previous\n"
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/desc_defs.h linux-3.2.71-pax/arch/x86/include/asm/desc_defs.h
--- linux-3.2.71/arch/x86/include/asm/desc_defs.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/desc_defs.h	2012-07-04 19:24:47.472063008 +0200
@@ -31,6 +31,12 @@ struct desc_struct {
 			unsigned base1: 8, type: 4, s: 1, dpl: 2, p: 1;
 			unsigned limit: 4, avl: 1, l: 1, d: 1, g: 1, base2: 8;
 		};
+		struct {
+			u16 offset_low;
+			u16 seg;
+			unsigned reserved: 8, type: 4, s: 1, dpl: 2, p: 1;
+			unsigned offset_high: 16;
+		} gate;
 	};
 } __attribute__((packed));
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/desc.h linux-3.2.71-pax/arch/x86/include/asm/desc.h
--- linux-3.2.71/arch/x86/include/asm/desc.h	2015-02-20 12:37:32.977178781 +0100
+++ linux-3.2.71-pax/arch/x86/include/asm/desc.h	2015-02-20 12:41:20.013166659 +0100
@@ -4,6 +4,7 @@
 #include <asm/desc_defs.h>
 #include <asm/ldt.h>
 #include <asm/mmu.h>
+#include <asm/pgtable.h>
 
 #include <linux/smp.h>
 
@@ -16,6 +17,7 @@ static inline void fill_ldt(struct desc_
 
 	desc->type		= (info->read_exec_only ^ 1) << 1;
 	desc->type	       |= info->contents << 2;
+	desc->type	       |= info->seg_not_present ^ 1;
 
 	desc->s			= 1;
 	desc->dpl		= 0x3;
@@ -34,17 +36,12 @@ static inline void fill_ldt(struct desc_
 }
 
 extern struct desc_ptr idt_descr;
-extern gate_desc idt_table[];
-
-struct gdt_page {
-	struct desc_struct gdt[GDT_ENTRIES];
-} __attribute__((aligned(PAGE_SIZE)));
-
-DECLARE_PER_CPU_PAGE_ALIGNED(struct gdt_page, gdt_page);
+extern gate_desc idt_table[256];
 
+extern struct desc_struct cpu_gdt_table[NR_CPUS][PAGE_SIZE / sizeof(struct desc_struct)];
 static inline struct desc_struct *get_cpu_gdt_table(unsigned int cpu)
 {
-	return per_cpu(gdt_page, cpu).gdt;
+	return cpu_gdt_table[cpu];
 }
 
 #ifdef CONFIG_X86_64
@@ -69,8 +66,14 @@ static inline void pack_gate(gate_desc *
 			     unsigned long base, unsigned dpl, unsigned flags,
 			     unsigned short seg)
 {
-	gate->a = (seg << 16) | (base & 0xffff);
-	gate->b = (base & 0xffff0000) | (((0x80 | type | (dpl << 5)) & 0xff) << 8);
+	gate->gate.offset_low	= base;
+	gate->gate.seg		= seg;
+	gate->gate.reserved	= 0;
+	gate->gate.type		= type;
+	gate->gate.s		= 0;
+	gate->gate.dpl		= dpl;
+	gate->gate.p		= 1;
+	gate->gate.offset_high	= base >> 16;
 }
 
 #endif
@@ -115,12 +118,16 @@ static inline void paravirt_free_ldt(str
 
 static inline void native_write_idt_entry(gate_desc *idt, int entry, const gate_desc *gate)
 {
+	pax_open_kernel();
 	memcpy(&idt[entry], gate, sizeof(*gate));
+	pax_close_kernel();
 }
 
 static inline void native_write_ldt_entry(struct desc_struct *ldt, int entry, const void *desc)
 {
+	pax_open_kernel();
 	memcpy(&ldt[entry], desc, 8);
+	pax_close_kernel();
 }
 
 static inline void
@@ -134,7 +141,9 @@ native_write_gdt_entry(struct desc_struc
 	default:	size = sizeof(*gdt);		break;
 	}
 
+	pax_open_kernel();
 	memcpy(&gdt[entry], desc, size);
+	pax_close_kernel();
 }
 
 static inline void pack_descriptor(struct desc_struct *desc, unsigned long base,
@@ -207,7 +216,9 @@ static inline void native_set_ldt(const
 
 static inline void native_load_tr_desc(void)
 {
+	pax_open_kernel();
 	asm volatile("ltr %w0"::"q" (GDT_ENTRY_TSS*8));
+	pax_close_kernel();
 }
 
 static inline void native_load_gdt(const struct desc_ptr *dtr)
@@ -244,8 +255,10 @@ static inline void native_load_tls(struc
 	struct desc_struct *gdt = get_cpu_gdt_table(cpu);
 	unsigned int i;
 
+	pax_open_kernel();
 	for (i = 0; i < GDT_ENTRY_TLS_ENTRIES; i++)
 		gdt[GDT_ENTRY_TLS_MIN + i] = t->tls_array[i];
+	pax_close_kernel();
 }
 
 /* This intentionally ignores lm, since 32-bit apps don't have that field. */
@@ -292,7 +305,7 @@ static inline void load_LDT(mm_context_t
 	preempt_enable();
 }
 
-static inline unsigned long get_desc_base(const struct desc_struct *desc)
+static inline unsigned long __intentional_overflow(-1) get_desc_base(const struct desc_struct *desc)
 {
 	return (unsigned)(desc->base0 | ((desc->base1) << 16) | ((desc->base2) << 24));
 }
@@ -315,7 +328,7 @@ static inline void set_desc_limit(struct
 	desc->limit = (limit >> 16) & 0xf;
 }
 
-static inline void _set_gate(int gate, unsigned type, void *addr,
+static inline void _set_gate(int gate, unsigned type, const void *addr,
 			     unsigned dpl, unsigned ist, unsigned seg)
 {
 	gate_desc s;
@@ -334,7 +347,7 @@ static inline void _set_gate(int gate, u
  * Pentium F0 0F bugfix can have resulted in the mapped
  * IDT being write-protected.
  */
-static inline void set_intr_gate(unsigned int n, void *addr)
+static inline void set_intr_gate(unsigned int n, const void *addr)
 {
 	BUG_ON((unsigned)n > 0xFF);
 	_set_gate(n, GATE_INTERRUPT, addr, 0, 0, __KERNEL_CS);
@@ -364,19 +377,19 @@ static inline void alloc_intr_gate(unsig
 /*
  * This routine sets up an interrupt gate at directory privilege level 3.
  */
-static inline void set_system_intr_gate(unsigned int n, void *addr)
+static inline void set_system_intr_gate(unsigned int n, const void *addr)
 {
 	BUG_ON((unsigned)n > 0xFF);
 	_set_gate(n, GATE_INTERRUPT, addr, 0x3, 0, __KERNEL_CS);
 }
 
-static inline void set_system_trap_gate(unsigned int n, void *addr)
+static inline void set_system_trap_gate(unsigned int n, const void *addr)
 {
 	BUG_ON((unsigned)n > 0xFF);
 	_set_gate(n, GATE_TRAP, addr, 0x3, 0, __KERNEL_CS);
 }
 
-static inline void set_trap_gate(unsigned int n, void *addr)
+static inline void set_trap_gate(unsigned int n, const void *addr)
 {
 	BUG_ON((unsigned)n > 0xFF);
 	_set_gate(n, GATE_TRAP, addr, 0, 0, __KERNEL_CS);
@@ -385,19 +398,31 @@ static inline void set_trap_gate(unsigne
 static inline void set_task_gate(unsigned int n, unsigned int gdt_entry)
 {
 	BUG_ON((unsigned)n > 0xFF);
-	_set_gate(n, GATE_TASK, (void *)0, 0, 0, (gdt_entry<<3));
+	_set_gate(n, GATE_TASK, (const void *)0, 0, 0, (gdt_entry<<3));
 }
 
-static inline void set_intr_gate_ist(int n, void *addr, unsigned ist)
+static inline void set_intr_gate_ist(int n, const void *addr, unsigned ist)
 {
 	BUG_ON((unsigned)n > 0xFF);
 	_set_gate(n, GATE_INTERRUPT, addr, 0, ist, __KERNEL_CS);
 }
 
-static inline void set_system_intr_gate_ist(int n, void *addr, unsigned ist)
+static inline void set_system_intr_gate_ist(int n, const void *addr, unsigned ist)
 {
 	BUG_ON((unsigned)n > 0xFF);
 	_set_gate(n, GATE_INTERRUPT, addr, 0x3, ist, __KERNEL_CS);
 }
 
+#ifdef CONFIG_X86_32
+static inline void set_user_cs(unsigned long base, unsigned long limit, int cpu)
+{
+	struct desc_struct d;
+
+	if (likely(limit))
+		limit = (limit - 1UL) >> PAGE_SHIFT;
+	pack_descriptor(&d, base, limit, 0xFB, 0xC);
+	write_gdt_entry(get_cpu_gdt_table(cpu), GDT_ENTRY_DEFAULT_USER_CS, &d, DESCTYPE_S);
+}
+#endif
+
 #endif /* _ASM_X86_DESC_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/div64.h linux-3.2.71-pax/arch/x86/include/asm/div64.h
--- linux-3.2.71/arch/x86/include/asm/div64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/div64.h	2013-03-28 04:02:46.295955801 +0100
@@ -33,7 +33,7 @@
 	__mod;							\
 })
 
-static inline u64 div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)
+static inline u64 __intentional_overflow(-1) div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)
 {
 	union {
 		u64 v64;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/e820.h linux-3.2.71-pax/arch/x86/include/asm/e820.h
--- linux-3.2.71/arch/x86/include/asm/e820.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/e820.h	2012-07-04 19:24:47.472063008 +0200
@@ -69,7 +69,7 @@ struct e820map {
 #define ISA_START_ADDRESS	0xa0000
 #define ISA_END_ADDRESS		0x100000
 
-#define BIOS_BEGIN		0x000a0000
+#define BIOS_BEGIN		0x000c0000
 #define BIOS_END		0x00100000
 
 #define BIOS_ROM_BASE		0xffe00000
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/elf.h linux-3.2.71-pax/arch/x86/include/asm/elf.h
--- linux-3.2.71/arch/x86/include/asm/elf.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/elf.h	2012-07-04 19:24:47.472063008 +0200
@@ -238,7 +238,25 @@ extern int force_personality32;
    the loader.  We need to make sure that it is out of the way of the program
    that it will "exec", and that there is sufficient room for the brk.  */
 
+#ifdef CONFIG_PAX_SEGMEXEC
+#define ELF_ET_DYN_BASE		((current->mm->pax_flags & MF_PAX_SEGMEXEC) ? SEGMEXEC_TASK_SIZE/3*2 : TASK_SIZE/3*2)
+#else
 #define ELF_ET_DYN_BASE		(TASK_SIZE / 3 * 2)
+#endif
+
+#ifdef CONFIG_PAX_ASLR
+#ifdef CONFIG_X86_32
+#define PAX_ELF_ET_DYN_BASE	0x10000000UL
+
+#define PAX_DELTA_MMAP_LEN	(current->mm->pax_flags & MF_PAX_SEGMEXEC ? 15 : 16)
+#define PAX_DELTA_STACK_LEN	(current->mm->pax_flags & MF_PAX_SEGMEXEC ? 15 : 16)
+#else
+#define PAX_ELF_ET_DYN_BASE	0x400000UL
+
+#define PAX_DELTA_MMAP_LEN	((test_thread_flag(TIF_IA32)) ? 16 : TASK_SIZE_MAX_SHIFT - PAGE_SHIFT - 3)
+#define PAX_DELTA_STACK_LEN	((test_thread_flag(TIF_IA32)) ? 16 : TASK_SIZE_MAX_SHIFT - PAGE_SHIFT - 3)
+#endif
+#endif
 
 /* This yields a mask that user programs can use to figure out what
    instruction set this CPU supports.  This could be done in user space,
@@ -291,9 +309,7 @@ do {									\
 
 #define ARCH_DLINFO							\
 do {									\
-	if (vdso_enabled)						\
-		NEW_AUX_ENT(AT_SYSINFO_EHDR,				\
-			    (unsigned long)current->mm->context.vdso);	\
+	NEW_AUX_ENT(AT_SYSINFO_EHDR, current->mm->context.vdso);	\
 } while (0)
 
 #define AT_SYSINFO		32
@@ -304,7 +320,7 @@ do {									\
 
 #endif /* !CONFIG_X86_32 */
 
-#define VDSO_CURRENT_BASE	((unsigned long)current->mm->context.vdso)
+#define VDSO_CURRENT_BASE	(current->mm->context.vdso)
 
 #define VDSO_ENTRY							\
 	((unsigned long)VDSO32_SYMBOL(VDSO_CURRENT_BASE, vsyscall))
@@ -318,9 +334,6 @@ extern int arch_setup_additional_pages(s
 extern int syscall32_setup_pages(struct linux_binprm *, int exstack);
 #define compat_arch_setup_additional_pages	syscall32_setup_pages
 
-extern unsigned long arch_randomize_brk(struct mm_struct *mm);
-#define arch_randomize_brk arch_randomize_brk
-
 /*
  * True on X86_32 or when emulating IA32 on X86_64
  */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/emergency-restart.h linux-3.2.71-pax/arch/x86/include/asm/emergency-restart.h
--- linux-3.2.71/arch/x86/include/asm/emergency-restart.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/emergency-restart.h	2012-07-04 19:24:47.476063007 +0200
@@ -15,6 +15,6 @@ enum reboot_type {
 
 extern enum reboot_type reboot_type;
 
-extern void machine_emergency_restart(void);
+extern void machine_emergency_restart(void) __noreturn;
 
 #endif /* _ASM_X86_EMERGENCY_RESTART_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/futex.h linux-3.2.71-pax/arch/x86/include/asm/futex.h
--- linux-3.2.71/arch/x86/include/asm/futex.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/futex.h	2012-12-01 02:29:42.172012072 +0100
@@ -12,20 +12,22 @@
 #include <asm/system.h>
 
 #define __futex_atomic_op1(insn, ret, oldval, uaddr, oparg)	\
+	typecheck(u32 __user *, uaddr);				\
 	asm volatile("1:\t" insn "\n"				\
 		     "2:\t.section .fixup,\"ax\"\n"		\
 		     "3:\tmov\t%3, %1\n"			\
 		     "\tjmp\t2b\n"				\
 		     "\t.previous\n"				\
 		     _ASM_EXTABLE(1b, 3b)			\
-		     : "=r" (oldval), "=r" (ret), "+m" (*uaddr)	\
+		     : "=r" (oldval), "=r" (ret), "+m" (*(u32 __user *)____m(uaddr))\
 		     : "i" (-EFAULT), "0" (oparg), "1" (0))
 
 #define __futex_atomic_op2(insn, ret, oldval, uaddr, oparg)	\
+	typecheck(u32 __user *, uaddr);				\
 	asm volatile("1:\tmovl	%2, %0\n"			\
 		     "\tmovl\t%0, %3\n"				\
 		     "\t" insn "\n"				\
-		     "2:\t" LOCK_PREFIX "cmpxchgl %3, %2\n"	\
+		     "2:\t" LOCK_PREFIX __copyuser_seg"cmpxchgl %3, %2\n"	\
 		     "\tjnz\t1b\n"				\
 		     "3:\t.section .fixup,\"ax\"\n"		\
 		     "4:\tmov\t%5, %1\n"			\
@@ -34,7 +36,7 @@
 		     _ASM_EXTABLE(1b, 4b)			\
 		     _ASM_EXTABLE(2b, 4b)			\
 		     : "=&a" (oldval), "=&r" (ret),		\
-		       "+m" (*uaddr), "=&r" (tem)		\
+		       "+m" (*(u32 __user *)____m(uaddr)), "=&r" (tem)	\
 		     : "r" (oparg), "i" (-EFAULT), "1" (0))
 
 static inline int futex_atomic_op_inuser(int encoded_op, u32 __user *uaddr)
@@ -61,10 +63,10 @@ static inline int futex_atomic_op_inuser
 
 	switch (op) {
 	case FUTEX_OP_SET:
-		__futex_atomic_op1("xchgl %0, %2", ret, oldval, uaddr, oparg);
+		__futex_atomic_op1(__copyuser_seg"xchgl %0, %2", ret, oldval, uaddr, oparg);
 		break;
 	case FUTEX_OP_ADD:
-		__futex_atomic_op1(LOCK_PREFIX "xaddl %0, %2", ret, oldval,
+		__futex_atomic_op1(LOCK_PREFIX __copyuser_seg"xaddl %0, %2", ret, oldval,
 				   uaddr, oparg);
 		break;
 	case FUTEX_OP_OR:
@@ -123,13 +125,13 @@ static inline int futex_atomic_cmpxchg_i
 	if (!access_ok(VERIFY_WRITE, uaddr, sizeof(u32)))
 		return -EFAULT;
 
-	asm volatile("1:\t" LOCK_PREFIX "cmpxchgl %4, %2\n"
+	asm volatile("1:\t" LOCK_PREFIX __copyuser_seg"cmpxchgl %4, %2\n"
 		     "2:\t.section .fixup, \"ax\"\n"
 		     "3:\tmov     %3, %0\n"
 		     "\tjmp     2b\n"
 		     "\t.previous\n"
 		     _ASM_EXTABLE(1b, 3b)
-		     : "+r" (ret), "=a" (oldval), "+m" (*uaddr)
+		     : "+r" (ret), "=a" (oldval), "+m" (*(u32 __user *)____m(uaddr))
 		     : "i" (-EFAULT), "r" (newval), "1" (oldval)
 		     : "memory"
 	);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/hw_irq.h linux-3.2.71-pax/arch/x86/include/asm/hw_irq.h
--- linux-3.2.71/arch/x86/include/asm/hw_irq.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/hw_irq.h	2012-07-04 19:24:47.484063001 +0200
@@ -136,8 +136,8 @@ extern void setup_ioapic_dest(void);
 extern void enable_IO_APIC(void);
 
 /* Statistics */
-extern atomic_t irq_err_count;
-extern atomic_t irq_mis_count;
+extern atomic_unchecked_t irq_err_count;
+extern atomic_unchecked_t irq_mis_count;
 
 /* EISA */
 extern void eisa_set_level_irq(unsigned int irq);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/i387.h linux-3.2.71-pax/arch/x86/include/asm/i387.h
--- linux-3.2.71/arch/x86/include/asm/i387.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/i387.h	2012-12-04 23:38:24.971562110 +0100
@@ -88,10 +88,12 @@ static inline void sanitize_i387_state(s
 }
 
 #ifdef CONFIG_X86_64
-static inline int fxrstor_checking(struct i387_fxsave_struct *fx)
+static inline int fxrstor_checking(struct i387_fxsave_struct __user *fx)
 {
 	int err;
 
+	fx = (struct i387_fxsave_struct __user *)____m(fx);
+
 	/* See comment in fxsave() below. */
 #ifdef CONFIG_AS_FXSAVEQ
 	asm volatile("1:  fxrstorq %[fx]\n\t"
@@ -121,6 +123,8 @@ static inline int fxsave_user(struct i38
 {
 	int err;
 
+	fx = (struct i387_fxsave_struct __user *)____m(fx);
+
 	/*
 	 * Clear the bytes not touched by the fxsave and reserved
 	 * for the SW usage.
@@ -189,15 +193,15 @@ static inline void fpu_fxsave(struct fpu
 #else  /* CONFIG_X86_32 */
 
 /* perform fxrstor iff the processor has extended states, otherwise frstor */
-static inline int fxrstor_checking(struct i387_fxsave_struct *fx)
+static inline int fxrstor_checking(struct i387_fxsave_struct __user *fx)
 {
 	/*
 	 * The "nop" is needed to make the instructions the same
 	 * length.
 	 */
 	alternative_input(
-		"nop ; frstor %1",
-		"fxrstor %1",
+		__copyuser_seg" frstor %1; nop",
+		__copyuser_seg" fxrstor %1",
 		X86_FEATURE_FXSR,
 		"m" (*fx));
 
@@ -256,7 +260,14 @@ static inline int __save_init_fpu(struct
 
 static inline int fpu_fxrstor_checking(struct fpu *fpu)
 {
-	return fxrstor_checking(&fpu->state->fxsave);
+	int ret;
+	mm_segment_t fs;
+
+	fs = get_fs();
+	set_fs(KERNEL_DS);
+	ret = fxrstor_checking(&fpu->state->fxsave);
+	set_fs(fs);
+	return ret;
 }
 
 static inline int fpu_restore_checking(struct fpu *fpu)
@@ -424,7 +435,7 @@ static inline bool interrupted_kernel_fp
 static inline bool interrupted_user_mode(void)
 {
 	struct pt_regs *regs = get_irq_regs();
-	return regs && user_mode_vm(regs);
+	return regs && user_mode(regs);
 }
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/i8259.h linux-3.2.71-pax/arch/x86/include/asm/i8259.h
--- linux-3.2.71/arch/x86/include/asm/i8259.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/i8259.h	2013-03-28 01:35:23.236427951 +0100
@@ -62,7 +62,7 @@ struct legacy_pic {
 	void (*init)(int auto_eoi);
 	int (*irq_pending)(unsigned int irq);
 	void (*make_irq)(unsigned int irq);
-};
+} __do_const;
 
 extern struct legacy_pic *legacy_pic;
 extern struct legacy_pic null_legacy_pic;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/io.h linux-3.2.71-pax/arch/x86/include/asm/io.h
--- linux-3.2.71/arch/x86/include/asm/io.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/io.h	2013-03-28 04:03:32.111953354 +0100
@@ -51,12 +51,12 @@ static inline void name(type val, volati
 "m" (*(volatile type __force *)addr) barrier); }
 
 build_mmio_read(readb, "b", unsigned char, "=q", :"memory")
-build_mmio_read(readw, "w", unsigned short, "=r", :"memory")
-build_mmio_read(readl, "l", unsigned int, "=r", :"memory")
+build_mmio_read(__intentional_overflow(-1) readw, "w", unsigned short, "=r", :"memory")
+build_mmio_read(__intentional_overflow(-1) readl, "l", unsigned int, "=r", :"memory")
 
 build_mmio_read(__readb, "b", unsigned char, "=q", )
-build_mmio_read(__readw, "w", unsigned short, "=r", )
-build_mmio_read(__readl, "l", unsigned int, "=r", )
+build_mmio_read(__intentional_overflow(-1) __readw, "w", unsigned short, "=r", )
+build_mmio_read(__intentional_overflow(-1) __readl, "l", unsigned int, "=r", )
 
 build_mmio_write(writeb, "b", unsigned char, "q", :"memory")
 build_mmio_write(writew, "w", unsigned short, "r", :"memory")
@@ -184,7 +184,7 @@ static inline void __iomem *ioremap(reso
 	return ioremap_nocache(offset, size);
 }
 
-extern void iounmap(volatile void __iomem *addr);
+extern void iounmap(const volatile void __iomem *addr);
 
 extern void set_iounmap_nonlazy(void);
 
@@ -194,6 +194,17 @@ extern void set_iounmap_nonlazy(void);
 
 #include <linux/vmalloc.h>
 
+#define ARCH_HAS_VALID_PHYS_ADDR_RANGE
+static inline int valid_phys_addr_range(unsigned long addr, size_t count)
+{
+	return ((addr + count + PAGE_SIZE - 1) >> PAGE_SHIFT) < (1ULL << (boot_cpu_data.x86_phys_bits - PAGE_SHIFT)) ? 1 : 0;
+}
+
+static inline int valid_mmap_phys_addr_range(unsigned long pfn, size_t count)
+{
+	return (pfn + (count >> PAGE_SHIFT)) < (1ULL << (boot_cpu_data.x86_phys_bits - PAGE_SHIFT)) ? 1 : 0;
+}
+
 /*
  * Convert a virtual cached pointer to an uncached pointer
  */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/irqflags.h linux-3.2.71-pax/arch/x86/include/asm/irqflags.h
--- linux-3.2.71/arch/x86/include/asm/irqflags.h	2014-09-14 14:10:58.026117204 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/irqflags.h	2014-09-14 14:11:25.906138313 +0200
@@ -141,6 +141,11 @@ static inline notrace unsigned long arch
 	sti;					\
 	sysexit
 
+#define GET_CR0_INTO_RDI		mov %cr0, %rdi
+#define SET_RDI_INTO_CR0		mov %rdi, %cr0
+#define GET_CR3_INTO_RDI		mov %cr3, %rdi
+#define SET_RDI_INTO_CR3		mov %rdi, %cr3
+
 #else
 #define INTERRUPT_RETURN		iret
 #define ENABLE_INTERRUPTS_SYSEXIT	sti; sysexit
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/kprobes.h linux-3.2.71-pax/arch/x86/include/asm/kprobes.h
--- linux-3.2.71/arch/x86/include/asm/kprobes.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/kprobes.h	2012-07-04 19:24:47.492063003 +0200
@@ -37,13 +37,8 @@ typedef u8 kprobe_opcode_t;
 #define RELATIVEJUMP_SIZE 5
 #define RELATIVECALL_OPCODE 0xe8
 #define RELATIVE_ADDR_SIZE 4
-#define MAX_STACK_SIZE 64
-#define MIN_STACK_SIZE(ADDR)					       \
-	(((MAX_STACK_SIZE) < (((unsigned long)current_thread_info()) + \
-			      THREAD_SIZE - (unsigned long)(ADDR)))    \
-	 ? (MAX_STACK_SIZE)					       \
-	 : (((unsigned long)current_thread_info()) +		       \
-	    THREAD_SIZE - (unsigned long)(ADDR)))
+#define MAX_STACK_SIZE 64UL
+#define MIN_STACK_SIZE(ADDR)	min(MAX_STACK_SIZE, current->thread.sp0 - (unsigned long)(ADDR))
 
 #define flush_insn_slot(p)	do { } while (0)
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/kvm_host.h linux-3.2.71-pax/arch/x86/include/asm/kvm_host.h
--- linux-3.2.71/arch/x86/include/asm/kvm_host.h	2015-08-14 21:48:35.036707927 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/kvm_host.h	2015-08-14 21:48:45.548707366 +0200
@@ -460,7 +460,7 @@ struct kvm_arch {
 	unsigned int n_requested_mmu_pages;
 	unsigned int n_max_mmu_pages;
 	unsigned int indirect_shadow_pages;
-	atomic_t invlpg_counter;
+	atomic_unchecked_t invlpg_counter;
 	struct hlist_head mmu_page_hash[KVM_NUM_MMU_PAGES];
 	/*
 	 * Hash table of struct kvm_mmu_page.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/local.h linux-3.2.71-pax/arch/x86/include/asm/local.h
--- linux-3.2.71/arch/x86/include/asm/local.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/local.h	2012-12-14 19:33:31.785559574 +0100
@@ -11,33 +11,97 @@ typedef struct {
 	atomic_long_t a;
 } local_t;
 
+typedef struct {
+	atomic_long_unchecked_t a;
+} local_unchecked_t;
+
 #define LOCAL_INIT(i)	{ ATOMIC_LONG_INIT(i) }
 
 #define local_read(l)	atomic_long_read(&(l)->a)
+#define local_read_unchecked(l)	atomic_long_read_unchecked(&(l)->a)
 #define local_set(l, i)	atomic_long_set(&(l)->a, (i))
+#define local_set_unchecked(l, i)	atomic_long_set_unchecked(&(l)->a, (i))
 
 static inline void local_inc(local_t *l)
 {
-	asm volatile(_ASM_INC "%0"
+	asm volatile(_ASM_INC "%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     _ASM_DEC "%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     : "+m" (l->a.counter));
+}
+
+static inline void local_inc_unchecked(local_unchecked_t *l)
+{
+	asm volatile(_ASM_INC "%0\n"
 		     : "+m" (l->a.counter));
 }
 
 static inline void local_dec(local_t *l)
 {
-	asm volatile(_ASM_DEC "%0"
+	asm volatile(_ASM_DEC "%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     _ASM_INC "%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     : "+m" (l->a.counter));
+}
+
+static inline void local_dec_unchecked(local_unchecked_t *l)
+{
+	asm volatile(_ASM_DEC "%0\n"
 		     : "+m" (l->a.counter));
 }
 
 static inline void local_add(long i, local_t *l)
 {
-	asm volatile(_ASM_ADD "%1,%0"
+	asm volatile(_ASM_ADD "%1,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     _ASM_SUB "%1,%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     : "+m" (l->a.counter)
+		     : "ir" (i));
+}
+
+static inline void local_add_unchecked(long i, local_unchecked_t *l)
+{
+	asm volatile(_ASM_ADD "%1,%0\n"
 		     : "+m" (l->a.counter)
 		     : "ir" (i));
 }
 
 static inline void local_sub(long i, local_t *l)
 {
-	asm volatile(_ASM_SUB "%1,%0"
+	asm volatile(_ASM_SUB "%1,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     _ASM_ADD "%1,%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     : "+m" (l->a.counter)
+		     : "ir" (i));
+}
+
+static inline void local_sub_unchecked(long i, local_unchecked_t *l)
+{
+	asm volatile(_ASM_SUB "%1,%0\n"
 		     : "+m" (l->a.counter)
 		     : "ir" (i));
 }
@@ -55,7 +119,16 @@ static inline int local_sub_and_test(lon
 {
 	unsigned char c;
 
-	asm volatile(_ASM_SUB "%2,%0; sete %1"
+	asm volatile(_ASM_SUB "%2,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     _ASM_ADD "%2,%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     "sete %1\n"
 		     : "+m" (l->a.counter), "=qm" (c)
 		     : "ir" (i) : "memory");
 	return c;
@@ -73,7 +146,16 @@ static inline int local_dec_and_test(loc
 {
 	unsigned char c;
 
-	asm volatile(_ASM_DEC "%0; sete %1"
+	asm volatile(_ASM_DEC "%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     _ASM_INC "%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     "sete %1\n"
 		     : "+m" (l->a.counter), "=qm" (c)
 		     : : "memory");
 	return c != 0;
@@ -91,7 +173,16 @@ static inline int local_inc_and_test(loc
 {
 	unsigned char c;
 
-	asm volatile(_ASM_INC "%0; sete %1"
+	asm volatile(_ASM_INC "%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     _ASM_DEC "%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     "sete %1\n"
 		     : "+m" (l->a.counter), "=qm" (c)
 		     : : "memory");
 	return c != 0;
@@ -110,7 +201,16 @@ static inline int local_add_negative(lon
 {
 	unsigned char c;
 
-	asm volatile(_ASM_ADD "%2,%0; sets %1"
+	asm volatile(_ASM_ADD "%2,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     _ASM_SUB "%2,%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
+		     "sets %1\n"
 		     : "+m" (l->a.counter), "=qm" (c)
 		     : "ir" (i) : "memory");
 	return c;
@@ -133,7 +233,15 @@ static inline long local_add_return(long
 #endif
 	/* Modern 486+ processor */
 	__i = i;
-	asm volatile(_ASM_XADD "%0, %1;"
+	asm volatile(_ASM_XADD "%0, %1\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     _ASM_MOV "%0,%1\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
 		     : "+r" (i), "+m" (l->a.counter)
 		     : : "memory");
 	return i + __i;
@@ -148,6 +256,38 @@ no_xadd: /* Legacy 386 processor */
 #endif
 }
 
+/**
+ * local_add_return_unchecked - add and return
+ * @i: integer value to add
+ * @l: pointer to type local_unchecked_t
+ *
+ * Atomically adds @i to @l and returns @i + @l
+ */
+static inline long local_add_return_unchecked(long i, local_unchecked_t *l)
+{
+	long __i;
+#ifdef CONFIG_M386
+	unsigned long flags;
+	if (unlikely(boot_cpu_data.x86 <= 3))
+		goto no_xadd;
+#endif
+	/* Modern 486+ processor */
+	__i = i;
+	asm volatile(_ASM_XADD "%0, %1\n"
+		     : "+r" (i), "+m" (l->a.counter)
+		     : : "memory");
+	return i + __i;
+
+#ifdef CONFIG_M386
+no_xadd: /* Legacy 386 processor */
+	local_irq_save(flags);
+	__i = local_read_unchecked(l);
+	local_set_unchecked(l, i + __i);
+	local_irq_restore(flags);
+	return i + __i;
+#endif
+}
+
 static inline long local_sub_return(long i, local_t *l)
 {
 	return local_add_return(-i, l);
@@ -158,6 +298,8 @@ static inline long local_sub_return(long
 
 #define local_cmpxchg(l, o, n) \
 	(cmpxchg_local(&((l)->a.counter), (o), (n)))
+#define local_cmpxchg_unchecked(l, o, n) \
+	(cmpxchg_local(&((l)->a.counter), (o), (n)))
 /* Always has a lock prefix */
 #define local_xchg(l, n) (xchg(&((l)->a.counter), (n)))
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/mman.h linux-3.2.71-pax/arch/x86/include/asm/mman.h
--- linux-3.2.71/arch/x86/include/asm/mman.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/mman.h	2012-07-04 19:24:47.500063006 +0200
@@ -5,4 +5,14 @@
 
 #include <asm-generic/mman.h>
 
+#ifdef __KERNEL__
+#ifndef __ASSEMBLY__
+#ifdef CONFIG_X86_32
+#define arch_mmap_check	i386_mmap_check
+int i386_mmap_check(unsigned long addr, unsigned long len,
+		unsigned long flags);
+#endif
+#endif
+#endif
+
 #endif /* _ASM_X86_MMAN_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/mmu_context.h linux-3.2.71-pax/arch/x86/include/asm/mmu_context.h
--- linux-3.2.71/arch/x86/include/asm/mmu_context.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/mmu_context.h	2015-06-28 00:32:04.450442595 +0200
@@ -24,6 +24,18 @@ void destroy_context(struct mm_struct *m
 
 static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)
 {
+
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+	unsigned int i;
+	pgd_t *pgd;
+
+	pax_open_kernel();
+	pgd = get_cpu_pgd(smp_processor_id());
+	for (i = USER_PGD_PTRS; i < 2 * USER_PGD_PTRS; ++i)
+		set_pgd_batched(pgd+i, native_make_pgd(0));
+	pax_close_kernel();
+#endif
+
 #ifdef CONFIG_SMP
 	if (percpu_read(cpu_tlbstate.state) == TLBSTATE_OK)
 		percpu_write(cpu_tlbstate.state, TLBSTATE_LAZY);
@@ -34,16 +46,30 @@ static inline void switch_mm(struct mm_s
 			     struct task_struct *tsk)
 {
 	unsigned cpu = smp_processor_id();
+#if defined(CONFIG_X86_32) && defined(CONFIG_SMP) && (defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC))
+	int tlbstate = TLBSTATE_OK;
+#endif
 
 	if (likely(prev != next)) {
 #ifdef CONFIG_SMP
+#if defined(CONFIG_X86_32) && (defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC))
+		tlbstate = percpu_read(cpu_tlbstate.state);
+#endif
 		percpu_write(cpu_tlbstate.state, TLBSTATE_OK);
 		percpu_write(cpu_tlbstate.active_mm, next);
 #endif
 		cpumask_set_cpu(cpu, mm_cpumask(next));
 
 		/* Re-load page tables */
+#ifdef CONFIG_PAX_PER_CPU_PGD
+		pax_open_kernel();
+		__clone_user_pgds(get_cpu_pgd(cpu), next->pgd);
+		__shadow_user_pgds(get_cpu_pgd(cpu) + USER_PGD_PTRS, next->pgd);
+		pax_close_kernel();
+		load_cr3(get_cpu_pgd(cpu));
+#else
 		load_cr3(next->pgd);
+#endif
 
 		/* stop flush ipis for the previous mm */
 		cpumask_clear_cpu(cpu, mm_cpumask(prev));
@@ -53,9 +79,38 @@ static inline void switch_mm(struct mm_s
 		 */
 		if (unlikely(prev->context.ldt != next->context.ldt))
 			load_LDT_nolock(&next->context);
-	}
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_PAGEEXEC) && defined(CONFIG_SMP)
+		if (!(__supported_pte_mask & _PAGE_NX)) {
+			smp_mb__before_clear_bit();
+			cpumask_clear_cpu(cpu, &prev->context.cpu_user_cs_mask);
+			smp_mb__after_clear_bit();
+			cpumask_set_cpu(cpu, &next->context.cpu_user_cs_mask);
+		}
+#endif
+
+#if defined(CONFIG_X86_32) && (defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC))
+		if (unlikely(prev->context.user_cs_base != next->context.user_cs_base ||
+			     prev->context.user_cs_limit != next->context.user_cs_limit))
+			set_user_cs(next->context.user_cs_base, next->context.user_cs_limit, cpu);
 #ifdef CONFIG_SMP
+		else if (unlikely(tlbstate != TLBSTATE_OK))
+			set_user_cs(next->context.user_cs_base, next->context.user_cs_limit, cpu);
+#endif
+#endif
+
+	}
 	else {
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+		pax_open_kernel();
+		__clone_user_pgds(get_cpu_pgd(cpu), next->pgd);
+		__shadow_user_pgds(get_cpu_pgd(cpu) + USER_PGD_PTRS, next->pgd);
+		pax_close_kernel();
+		load_cr3(get_cpu_pgd(cpu));
+#endif
+
+#ifdef CONFIG_SMP
 		percpu_write(cpu_tlbstate.state, TLBSTATE_OK);
 		BUG_ON(percpu_read(cpu_tlbstate.active_mm) != next);
 
@@ -64,11 +119,28 @@ static inline void switch_mm(struct mm_s
 			 * tlb flush IPI delivery. We must reload CR3
 			 * to make sure to use no freed page tables.
 			 */
+
+#ifndef CONFIG_PAX_PER_CPU_PGD
 			load_cr3(next->pgd);
+#endif
+
 			load_LDT_nolock(&next->context);
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_PAGEEXEC)
+			if (!(__supported_pte_mask & _PAGE_NX))
+				cpumask_set_cpu(cpu, &next->context.cpu_user_cs_mask);
+#endif
+
+#if defined(CONFIG_X86_32) && (defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC))
+#ifdef CONFIG_PAX_PAGEEXEC
+			if (!((next->pax_flags & MF_PAX_PAGEEXEC) && (__supported_pte_mask & _PAGE_NX)))
+#endif
+				set_user_cs(next->context.user_cs_base, next->context.user_cs_limit, cpu);
+#endif
+
 		}
-	}
 #endif
+	}
 }
 
 #define activate_mm(prev, next)			\
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/mmu.h linux-3.2.71-pax/arch/x86/include/asm/mmu.h
--- linux-3.2.71/arch/x86/include/asm/mmu.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/mmu.h	2012-07-04 19:24:47.504063006 +0200
@@ -9,7 +9,7 @@
  * we put the segment information here.
  */
 typedef struct {
-	void *ldt;
+	struct desc_struct *ldt;
 	int size;
 
 #ifdef CONFIG_X86_64
@@ -18,7 +18,19 @@ typedef struct {
 #endif
 
 	struct mutex lock;
-	void *vdso;
+	unsigned long vdso;
+
+#ifdef CONFIG_X86_32
+#if defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC)
+	unsigned long user_cs_base;
+	unsigned long user_cs_limit;
+
+#if defined(CONFIG_PAX_PAGEEXEC) && defined(CONFIG_SMP)
+	cpumask_t cpu_user_cs_mask;
+#endif
+
+#endif
+#endif
 } mm_context_t;
 
 #ifdef CONFIG_SMP
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/module.h linux-3.2.71-pax/arch/x86/include/asm/module.h
--- linux-3.2.71/arch/x86/include/asm/module.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/module.h	2012-07-04 19:24:47.508063006 +0200
@@ -5,6 +5,7 @@
 
 #ifdef CONFIG_X86_64
 /* X86_64 does not define MODULE_PROC_FAMILY */
+#define MODULE_PROC_FAMILY ""
 #elif defined CONFIG_M386
 #define MODULE_PROC_FAMILY "386 "
 #elif defined CONFIG_M486
@@ -59,8 +60,20 @@
 #error unknown processor family
 #endif
 
-#ifdef CONFIG_X86_32
-# define MODULE_ARCH_VERMAGIC MODULE_PROC_FAMILY
+#ifdef CONFIG_PAX_KERNEXEC_PLUGIN_METHOD_BTS
+#define MODULE_PAX_KERNEXEC "KERNEXEC_BTS "
+#elif defined(CONFIG_PAX_KERNEXEC_PLUGIN_METHOD_OR)
+#define MODULE_PAX_KERNEXEC "KERNEXEC_OR "
+#else
+#define MODULE_PAX_KERNEXEC ""
 #endif
 
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+#define MODULE_PAX_UDEREF "UDEREF "
+#else
+#define MODULE_PAX_UDEREF ""
+#endif
+
+#define MODULE_ARCH_VERMAGIC MODULE_PROC_FAMILY MODULE_PAX_KERNEXEC MODULE_PAX_UDEREF
+
 #endif /* _ASM_X86_MODULE_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/page_32.h linux-3.2.71-pax/arch/x86/include/asm/page_32.h
--- linux-3.2.71/arch/x86/include/asm/page_32.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/page_32.h	2015-04-30 03:00:23.456519607 +0200
@@ -11,7 +11,7 @@
 
 #define __phys_addr_nodebug(x)	((x) - PAGE_OFFSET)
 #ifdef CONFIG_DEBUG_VIRTUAL
-extern unsigned long __phys_addr(unsigned long);
+extern unsigned long __intentional_overflow(-1) __phys_addr(unsigned long);
 #else
 #define __phys_addr(x)		__phys_addr_nodebug(x)
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/page_64_types.h linux-3.2.71-pax/arch/x86/include/asm/page_64_types.h
--- linux-3.2.71/arch/x86/include/asm/page_64_types.h	2014-12-14 21:13:44.974054653 +0100
+++ linux-3.2.71-pax/arch/x86/include/asm/page_64_types.h	2015-04-30 02:59:42.660518407 +0200
@@ -1,7 +1,7 @@
 #ifndef _ASM_X86_PAGE_64_DEFS_H
 #define _ASM_X86_PAGE_64_DEFS_H
 
-#define THREAD_ORDER	1
+#define THREAD_ORDER	2
 #define THREAD_SIZE  (PAGE_SIZE << THREAD_ORDER)
 #define CURRENT_MASK (~(THREAD_SIZE - 1))
 
@@ -55,9 +55,9 @@ void copy_page(void *to, void *from);
 
 /* duplicated to the one in bootmem.h */
 extern unsigned long max_pfn;
-extern unsigned long phys_base;
+extern const unsigned long phys_base;
 
-extern unsigned long __phys_addr(unsigned long);
+extern unsigned long __intentional_overflow(-1) __phys_addr(unsigned long);
 #define __phys_reloc_hide(x)	(x)
 
 #define vmemmap ((struct page *)VMEMMAP_START)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/paravirt.h linux-3.2.71-pax/arch/x86/include/asm/paravirt.h
--- linux-3.2.71/arch/x86/include/asm/paravirt.h	2013-04-30 00:45:09.439714488 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/paravirt.h	2013-04-30 00:45:13.139714290 +0200
@@ -601,7 +601,7 @@ static inline pmd_t __pmd(pmdval_t val)
 	return (pmd_t) { ret };
 }
 
-static inline pmdval_t pmd_val(pmd_t pmd)
+static inline __intentional_overflow(-1) pmdval_t pmd_val(pmd_t pmd)
 {
 	pmdval_t ret;
 
@@ -667,6 +667,18 @@ static inline void set_pgd(pgd_t *pgdp,
 			    val);
 }
 
+static inline void set_pgd_batched(pgd_t *pgdp, pgd_t pgd)
+{
+	pgdval_t val = native_pgd_val(pgd);
+
+	if (sizeof(pgdval_t) > sizeof(long))
+		PVOP_VCALL3(pv_mmu_ops.set_pgd_batched, pgdp,
+			    val, (u64)val >> 32);
+	else
+		PVOP_VCALL2(pv_mmu_ops.set_pgd_batched, pgdp,
+			    val);
+}
+
 static inline void pgd_clear(pgd_t *pgdp)
 {
 	set_pgd(pgdp, __pgd(0));
@@ -751,6 +763,21 @@ static inline void __set_fixmap(unsigned
 	pv_mmu_ops.set_fixmap(idx, phys, flags);
 }
 
+#ifdef CONFIG_PAX_KERNEXEC
+static inline unsigned long pax_open_kernel(void)
+{
+	return PVOP_CALL0(unsigned long, pv_mmu_ops.pax_open_kernel);
+}
+
+static inline unsigned long pax_close_kernel(void)
+{
+	return PVOP_CALL0(unsigned long, pv_mmu_ops.pax_close_kernel);
+}
+#else
+static inline unsigned long pax_open_kernel(void) { return 0; }
+static inline unsigned long pax_close_kernel(void) { return 0; }
+#endif
+
 #if defined(CONFIG_SMP) && defined(CONFIG_PARAVIRT_SPINLOCKS)
 
 static inline int arch_spin_is_locked(struct arch_spinlock *lock)
@@ -967,7 +994,7 @@ extern void default_banner(void);
 
 #define PARA_PATCH(struct, off)        ((PARAVIRT_PATCH_##struct + (off)) / 4)
 #define PARA_SITE(ptype, clobbers, ops) _PVSITE(ptype, clobbers, ops, .long, 4)
-#define PARA_INDIRECT(addr)	*%cs:addr
+#define PARA_INDIRECT(addr)	*%ss:addr
 #endif
 
 #define INTERRUPT_RETURN						\
@@ -1044,6 +1071,21 @@ extern void default_banner(void);
 	PARA_SITE(PARA_PATCH(pv_cpu_ops, PV_CPU_irq_enable_sysexit),	\
 		  CLBR_NONE,						\
 		  jmp PARA_INDIRECT(pv_cpu_ops+PV_CPU_irq_enable_sysexit))
+
+#define GET_CR0_INTO_RDI				\
+	call PARA_INDIRECT(pv_cpu_ops+PV_CPU_read_cr0);	\
+	mov %rax,%rdi
+
+#define SET_RDI_INTO_CR0				\
+	call PARA_INDIRECT(pv_cpu_ops+PV_CPU_write_cr0)
+
+#define GET_CR3_INTO_RDI				\
+	call PARA_INDIRECT(pv_mmu_ops+PV_MMU_read_cr3);	\
+	mov %rax,%rdi
+
+#define SET_RDI_INTO_CR3				\
+	call PARA_INDIRECT(pv_mmu_ops+PV_MMU_write_cr3)
+
 #endif	/* CONFIG_X86_32 */
 
 #endif /* __ASSEMBLY__ */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/paravirt_types.h linux-3.2.71-pax/arch/x86/include/asm/paravirt_types.h
--- linux-3.2.71/arch/x86/include/asm/paravirt_types.h	2013-04-30 00:45:09.439714488 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/paravirt_types.h	2013-04-30 00:45:13.139714290 +0200
@@ -84,7 +84,7 @@ struct pv_init_ops {
 	 */
 	unsigned (*patch)(u8 type, u16 clobber, void *insnbuf,
 			  unsigned long addr, unsigned len);
-};
+} __no_const;
 
 
 struct pv_lazy_ops {
@@ -98,7 +98,7 @@ struct pv_time_ops {
 	unsigned long long (*sched_clock)(void);
 	unsigned long long (*steal_clock)(int cpu);
 	unsigned long (*get_tsc_khz)(void);
-};
+} __no_const;
 
 struct pv_cpu_ops {
 	/* hooks for various privileged instructions */
@@ -194,7 +194,7 @@ struct pv_cpu_ops {
 
 	void (*start_context_switch)(struct task_struct *prev);
 	void (*end_context_switch)(struct task_struct *next);
-};
+} __no_const;
 
 struct pv_irq_ops {
 	/*
@@ -225,7 +225,7 @@ struct pv_apic_ops {
 				 unsigned long start_eip,
 				 unsigned long start_esp);
 #endif
-};
+} __no_const;
 
 struct pv_mmu_ops {
 	unsigned long (*read_cr2)(void);
@@ -314,6 +314,7 @@ struct pv_mmu_ops {
 	struct paravirt_callee_save make_pud;
 
 	void (*set_pgd)(pgd_t *pudp, pgd_t pgdval);
+	void (*set_pgd_batched)(pgd_t *pudp, pgd_t pgdval);
 #endif	/* PAGETABLE_LEVELS == 4 */
 #endif	/* PAGETABLE_LEVELS >= 3 */
 
@@ -325,6 +326,12 @@ struct pv_mmu_ops {
 	   an mfn.  We can tell which is which from the index. */
 	void (*set_fixmap)(unsigned /* enum fixed_addresses */ idx,
 			   phys_addr_t phys, pgprot_t flags);
+
+#ifdef CONFIG_PAX_KERNEXEC
+	unsigned long (*pax_open_kernel)(void);
+	unsigned long (*pax_close_kernel)(void);
+#endif
+
 };
 
 struct arch_spinlock;
@@ -335,7 +342,7 @@ struct pv_lock_ops {
 	void (*spin_lock_flags)(struct arch_spinlock *lock, unsigned long flags);
 	int (*spin_trylock)(struct arch_spinlock *lock);
 	void (*spin_unlock)(struct arch_spinlock *lock);
-};
+} __no_const;
 
 /* This contains all the paravirt structures: we get a convenient
  * number for each function using the offset which we use to indicate
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/pgalloc.h linux-3.2.71-pax/arch/x86/include/asm/pgalloc.h
--- linux-3.2.71/arch/x86/include/asm/pgalloc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/pgalloc.h	2012-07-04 19:24:47.516063003 +0200
@@ -63,6 +63,13 @@ static inline void pmd_populate_kernel(s
 				       pmd_t *pmd, pte_t *pte)
 {
 	paravirt_alloc_pte(mm, __pa(pte) >> PAGE_SHIFT);
+	set_pmd(pmd, __pmd(__pa(pte) | _KERNPG_TABLE));
+}
+
+static inline void pmd_populate_user(struct mm_struct *mm,
+				       pmd_t *pmd, pte_t *pte)
+{
+	paravirt_alloc_pte(mm, __pa(pte) >> PAGE_SHIFT);
 	set_pmd(pmd, __pmd(__pa(pte) | _PAGE_TABLE));
 }
 
@@ -99,12 +106,22 @@ static inline void __pmd_free_tlb(struct
 
 #ifdef CONFIG_X86_PAE
 extern void pud_populate(struct mm_struct *mm, pud_t *pudp, pmd_t *pmd);
+static inline void pud_populate_kernel(struct mm_struct *mm, pud_t *pudp, pmd_t *pmd)
+{
+	pud_populate(mm, pudp, pmd);
+}
 #else	/* !CONFIG_X86_PAE */
 static inline void pud_populate(struct mm_struct *mm, pud_t *pud, pmd_t *pmd)
 {
 	paravirt_alloc_pmd(mm, __pa(pmd) >> PAGE_SHIFT);
 	set_pud(pud, __pud(_PAGE_TABLE | __pa(pmd)));
 }
+
+static inline void pud_populate_kernel(struct mm_struct *mm, pud_t *pud, pmd_t *pmd)
+{
+	paravirt_alloc_pmd(mm, __pa(pmd) >> PAGE_SHIFT);
+	set_pud(pud, __pud(_KERNPG_TABLE | __pa(pmd)));
+}
 #endif	/* CONFIG_X86_PAE */
 
 #if PAGETABLE_LEVELS > 3
@@ -114,6 +131,12 @@ static inline void pgd_populate(struct m
 	set_pgd(pgd, __pgd(_PAGE_TABLE | __pa(pud)));
 }
 
+static inline void pgd_populate_kernel(struct mm_struct *mm, pgd_t *pgd, pud_t *pud)
+{
+	paravirt_alloc_pud(mm, __pa(pud) >> PAGE_SHIFT);
+	set_pgd(pgd, __pgd(_KERNPG_TABLE | __pa(pud)));
+}
+
 static inline pud_t *pud_alloc_one(struct mm_struct *mm, unsigned long addr)
 {
 	return (pud_t *)get_zeroed_page(GFP_KERNEL|__GFP_REPEAT);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/pgtable-2level.h linux-3.2.71-pax/arch/x86/include/asm/pgtable-2level.h
--- linux-3.2.71/arch/x86/include/asm/pgtable-2level.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/pgtable-2level.h	2012-07-04 19:24:47.516063003 +0200
@@ -18,7 +18,9 @@ static inline void native_set_pte(pte_t
 
 static inline void native_set_pmd(pmd_t *pmdp, pmd_t pmd)
 {
+	pax_open_kernel();
 	*pmdp = pmd;
+	pax_close_kernel();
 }
 
 static inline void native_set_pte_atomic(pte_t *ptep, pte_t pte)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/pgtable_32.h linux-3.2.71-pax/arch/x86/include/asm/pgtable_32.h
--- linux-3.2.71/arch/x86/include/asm/pgtable_32.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/pgtable_32.h	2012-07-04 19:24:47.516063003 +0200
@@ -25,9 +25,6 @@
 struct mm_struct;
 struct vm_area_struct;
 
-extern pgd_t swapper_pg_dir[1024];
-extern pgd_t initial_page_table[1024];
-
 static inline void pgtable_cache_init(void) { }
 static inline void check_pgt_cache(void) { }
 void paging_init(void);
@@ -48,6 +45,12 @@ extern void set_pmd_pfn(unsigned long, u
 # include <asm/pgtable-2level.h>
 #endif
 
+extern pgd_t swapper_pg_dir[PTRS_PER_PGD];
+extern pgd_t initial_page_table[PTRS_PER_PGD];
+#ifdef CONFIG_X86_PAE
+extern pmd_t swapper_pm_dir[PTRS_PER_PGD][PTRS_PER_PMD];
+#endif
+
 #if defined(CONFIG_HIGHPTE)
 #define pte_offset_map(dir, address)					\
 	((pte_t *)kmap_atomic(pmd_page(*(dir))) +		\
@@ -62,7 +65,9 @@ extern void set_pmd_pfn(unsigned long, u
 /* Clear a kernel PTE and flush it from the TLB */
 #define kpte_clear_flush(ptep, vaddr)		\
 do {						\
+	pax_open_kernel();			\
 	pte_clear(&init_mm, (vaddr), (ptep));	\
+	pax_close_kernel();			\
 	__flush_tlb_one((vaddr));		\
 } while (0)
 
@@ -74,6 +79,9 @@ do {						\
 
 #endif /* !__ASSEMBLY__ */
 
+#define HAVE_ARCH_UNMAPPED_AREA
+#define HAVE_ARCH_UNMAPPED_AREA_TOPDOWN
+
 /*
  * kern_addr_valid() is (1) for FLATMEM and (0) for
  * SPARSEMEM and DISCONTIGMEM
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/pgtable_32_types.h linux-3.2.71-pax/arch/x86/include/asm/pgtable_32_types.h
--- linux-3.2.71/arch/x86/include/asm/pgtable_32_types.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/pgtable_32_types.h	2012-07-04 19:24:47.516063003 +0200
@@ -8,7 +8,7 @@
  */
 #ifdef CONFIG_X86_PAE
 # include <asm/pgtable-3level_types.h>
-# define PMD_SIZE	(1UL << PMD_SHIFT)
+# define PMD_SIZE	(_AC(1, UL) << PMD_SHIFT)
 # define PMD_MASK	(~(PMD_SIZE - 1))
 #else
 # include <asm/pgtable-2level_types.h>
@@ -46,6 +46,19 @@ extern bool __vmalloc_start_set; /* set
 # define VMALLOC_END	(FIXADDR_START - 2 * PAGE_SIZE)
 #endif
 
+#ifdef CONFIG_PAX_KERNEXEC
+#ifndef __ASSEMBLY__
+extern unsigned char MODULES_EXEC_VADDR[];
+extern unsigned char MODULES_EXEC_END[];
+#endif
+#include <asm/boot.h>
+#define ktla_ktva(addr)		(addr + LOAD_PHYSICAL_ADDR + PAGE_OFFSET)
+#define ktva_ktla(addr)		(addr - LOAD_PHYSICAL_ADDR - PAGE_OFFSET)
+#else
+#define ktla_ktva(addr)		(addr)
+#define ktva_ktla(addr)		(addr)
+#endif
+
 #define MODULES_VADDR	VMALLOC_START
 #define MODULES_END	VMALLOC_END
 #define MODULES_LEN	(MODULES_VADDR - MODULES_END)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/pgtable-3level.h linux-3.2.71-pax/arch/x86/include/asm/pgtable-3level.h
--- linux-3.2.71/arch/x86/include/asm/pgtable-3level.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/pgtable-3level.h	2012-07-04 19:24:47.516063003 +0200
@@ -92,12 +92,16 @@ static inline void native_set_pte_atomic
 
 static inline void native_set_pmd(pmd_t *pmdp, pmd_t pmd)
 {
+	pax_open_kernel();
 	set_64bit((unsigned long long *)(pmdp), native_pmd_val(pmd));
+	pax_close_kernel();
 }
 
 static inline void native_set_pud(pud_t *pudp, pud_t pud)
 {
+	pax_open_kernel();
 	set_64bit((unsigned long long *)(pudp), native_pud_val(pud));
+	pax_close_kernel();
 }
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/pgtable_64.h linux-3.2.71-pax/arch/x86/include/asm/pgtable_64.h
--- linux-3.2.71/arch/x86/include/asm/pgtable_64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/pgtable_64.h	2013-01-18 02:59:48.283456828 +0100
@@ -16,10 +16,14 @@
 
 extern pud_t level3_kernel_pgt[512];
 extern pud_t level3_ident_pgt[512];
+extern pud_t level3_vmalloc_start_pgt[512];
+extern pud_t level3_vmalloc_end_pgt[512];
+extern pud_t level3_vmemmap_pgt[512];
+extern pud_t level2_vmemmap_pgt[512];
 extern pmd_t level2_kernel_pgt[512];
 extern pmd_t level2_fixmap_pgt[512];
-extern pmd_t level2_ident_pgt[512];
-extern pgd_t init_level4_pgt[];
+extern pmd_t level2_ident_pgt[512*2];
+extern pgd_t init_level4_pgt[512];
 
 #define swapper_pg_dir init_level4_pgt
 
@@ -61,7 +65,9 @@ static inline void native_set_pte_atomic
 
 static inline void native_set_pmd(pmd_t *pmdp, pmd_t pmd)
 {
+	pax_open_kernel();
 	*pmdp = pmd;
+	pax_close_kernel();
 }
 
 static inline void native_pmd_clear(pmd_t *pmd)
@@ -97,7 +103,9 @@ static inline pmd_t native_pmdp_get_and_
 
 static inline void native_set_pud(pud_t *pudp, pud_t pud)
 {
+	pax_open_kernel();
 	*pudp = pud;
+	pax_close_kernel();
 }
 
 static inline void native_pud_clear(pud_t *pud)
@@ -107,6 +115,13 @@ static inline void native_pud_clear(pud_
 
 static inline void native_set_pgd(pgd_t *pgdp, pgd_t pgd)
 {
+	pax_open_kernel();
+	*pgdp = pgd;
+	pax_close_kernel();
+}
+
+static inline void native_set_pgd_batched(pgd_t *pgdp, pgd_t pgd)
+{
 	*pgdp = pgd;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/pgtable_64_types.h linux-3.2.71-pax/arch/x86/include/asm/pgtable_64_types.h
--- linux-3.2.71/arch/x86/include/asm/pgtable_64_types.h	2014-09-14 14:10:58.034117210 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/pgtable_64_types.h	2014-09-14 14:20:48.081860738 +0200
@@ -59,7 +59,12 @@ typedef struct { pteval_t pte; } pte_t;
 #define MODULES_VADDR    _AC(0xffffffffa0000000, UL)
 #define MODULES_END      _AC(0xffffffffff000000, UL)
 #define MODULES_LEN   (MODULES_END - MODULES_VADDR)
+#define MODULES_EXEC_VADDR MODULES_VADDR
+#define MODULES_EXEC_END MODULES_END
 #define ESPFIX_PGD_ENTRY _AC(-2, UL)
 #define ESPFIX_BASE_ADDR (ESPFIX_PGD_ENTRY << PGDIR_SHIFT)
 
+#define ktla_ktva(addr)		(addr)
+#define ktva_ktla(addr)		(addr)
+
 #endif /* _ASM_X86_PGTABLE_64_DEFS_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/pgtable.h linux-3.2.71-pax/arch/x86/include/asm/pgtable.h
--- linux-3.2.71/arch/x86/include/asm/pgtable.h	2013-03-29 02:18:30.015676747 +0100
+++ linux-3.2.71-pax/arch/x86/include/asm/pgtable.h	2014-10-03 00:31:02.469569666 +0200
@@ -44,6 +44,7 @@ extern struct mm_struct *pgd_page_get_mm
 
 #ifndef __PAGETABLE_PUD_FOLDED
 #define set_pgd(pgdp, pgd)		native_set_pgd(pgdp, pgd)
+#define set_pgd_batched(pgdp, pgd)	native_set_pgd_batched(pgdp, pgd)
 #define pgd_clear(pgd)			native_pgd_clear(pgd)
 #endif
 
@@ -81,12 +82,53 @@ extern struct mm_struct *pgd_page_get_mm
 
 #define arch_end_context_switch(prev)	do {} while(0)
 
+#define pax_open_kernel()	native_pax_open_kernel()
+#define pax_close_kernel()	native_pax_close_kernel()
 #endif	/* CONFIG_PARAVIRT */
 
+#define  __HAVE_ARCH_PAX_OPEN_KERNEL
+#define  __HAVE_ARCH_PAX_CLOSE_KERNEL
+
+#ifdef CONFIG_PAX_KERNEXEC
+static inline unsigned long native_pax_open_kernel(void)
+{
+	unsigned long cr0;
+
+	preempt_disable();
+	barrier();
+	cr0 = read_cr0() ^ X86_CR0_WP;
+	BUG_ON(cr0 & X86_CR0_WP);
+	write_cr0(cr0);
+	barrier();
+	return cr0 ^ X86_CR0_WP;
+}
+
+static inline unsigned long native_pax_close_kernel(void)
+{
+	unsigned long cr0;
+
+	barrier();
+	cr0 = read_cr0() ^ X86_CR0_WP;
+	BUG_ON(!(cr0 & X86_CR0_WP));
+	write_cr0(cr0);
+	barrier();
+	preempt_enable_no_resched();
+	return cr0 ^ X86_CR0_WP;
+}
+#else
+static inline unsigned long native_pax_open_kernel(void) { return 0; }
+static inline unsigned long native_pax_close_kernel(void) { return 0; }
+#endif
+
 /*
  * The following only work if pte_present() is true.
  * Undefined behaviour if not..
  */
+static inline int pte_user(pte_t pte)
+{
+	return pte_val(pte) & _PAGE_USER;
+}
+
 static inline int pte_dirty(pte_t pte)
 {
 	return pte_flags(pte) & _PAGE_DIRTY;
@@ -147,6 +189,11 @@ static inline unsigned long pud_pfn(pud_
 	return (pud_val(pud) & PTE_PFN_MASK) >> PAGE_SHIFT;
 }
 
+static inline unsigned long pgd_pfn(pgd_t pgd)
+{
+	return (pgd_val(pgd) & PTE_PFN_MASK) >> PAGE_SHIFT;
+}
+
 #define pte_page(pte)	pfn_to_page(pte_pfn(pte))
 
 static inline int pmd_large(pmd_t pte)
@@ -200,9 +247,29 @@ static inline pte_t pte_wrprotect(pte_t
 	return pte_clear_flags(pte, _PAGE_RW);
 }
 
+static inline pte_t pte_mkread(pte_t pte)
+{
+	return __pte(pte_val(pte) | _PAGE_USER);
+}
+
 static inline pte_t pte_mkexec(pte_t pte)
 {
-	return pte_clear_flags(pte, _PAGE_NX);
+#ifdef CONFIG_X86_PAE
+	if (__supported_pte_mask & _PAGE_NX)
+		return pte_clear_flags(pte, _PAGE_NX);
+	else
+#endif
+		return pte_set_flags(pte, _PAGE_USER);
+}
+
+static inline pte_t pte_exprotect(pte_t pte)
+{
+#ifdef CONFIG_X86_PAE
+	if (__supported_pte_mask & _PAGE_NX)
+		return pte_set_flags(pte, _PAGE_NX);
+	else
+#endif
+		return pte_clear_flags(pte, _PAGE_USER);
 }
 
 static inline pte_t pte_mkdirty(pte_t pte)
@@ -394,6 +461,15 @@ pte_t *populate_extra_pte(unsigned long
 #endif
 
 #ifndef __ASSEMBLY__
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+extern pgd_t cpu_pgd[NR_CPUS][PTRS_PER_PGD];
+static inline pgd_t *get_cpu_pgd(unsigned int cpu)
+{
+	return cpu_pgd[cpu];
+}
+#endif
+
 #include <linux/mm_types.h>
 
 static inline int pte_none(pte_t pte)
@@ -515,7 +591,7 @@ static inline unsigned long pud_page_vad
  * Currently stuck as a macro due to indirect forward reference to
  * linux/mmzone.h's __section_mem_map_addr() definition:
  */
-#define pud_page(pud)		pfn_to_page(pud_val(pud) >> PAGE_SHIFT)
+#define pud_page(pud)		pfn_to_page((pud_val(pud) & PTE_PFN_MASK) >> PAGE_SHIFT)
 
 /* Find an entry in the second-level page table.. */
 static inline pmd_t *pmd_offset(pud_t *pud, unsigned long address)
@@ -555,7 +631,7 @@ static inline unsigned long pgd_page_vad
  * Currently stuck as a macro due to indirect forward reference to
  * linux/mmzone.h's __section_mem_map_addr() definition:
  */
-#define pgd_page(pgd)		pfn_to_page(pgd_val(pgd) >> PAGE_SHIFT)
+#define pgd_page(pgd)		pfn_to_page((pgd_val(pgd) & PTE_PFN_MASK) >> PAGE_SHIFT)
 
 /* to find an entry in a page-table-directory. */
 static inline unsigned long pud_index(unsigned long address)
@@ -570,7 +646,7 @@ static inline pud_t *pud_offset(pgd_t *p
 
 static inline int pgd_bad(pgd_t pgd)
 {
-	return (pgd_flags(pgd) & ~_PAGE_USER) != _KERNPG_TABLE;
+	return (pgd_flags(pgd) & ~(_PAGE_USER | _PAGE_NX)) != _KERNPG_TABLE;
 }
 
 static inline int pgd_none(pgd_t pgd)
@@ -593,7 +669,12 @@ static inline int pgd_none(pgd_t pgd)
  * pgd_offset() returns a (pgd_t *)
  * pgd_index() is used get the offset into the pgd page's array of pgd_t's;
  */
-#define pgd_offset(mm, address) ((mm)->pgd + pgd_index((address)))
+#define pgd_offset(mm, address) ((mm)->pgd + pgd_index(address))
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+#define pgd_offset_cpu(cpu, address) (get_cpu_pgd(cpu) + pgd_index(address))
+#endif
+
 /*
  * a shortcut which implies the use of the kernel's pgd, instead
  * of a process's
@@ -604,6 +685,22 @@ static inline int pgd_none(pgd_t pgd)
 #define KERNEL_PGD_BOUNDARY	pgd_index(PAGE_OFFSET)
 #define KERNEL_PGD_PTRS		(PTRS_PER_PGD - KERNEL_PGD_BOUNDARY)
 
+#ifdef CONFIG_X86_32
+#define USER_PGD_PTRS		KERNEL_PGD_BOUNDARY
+#else
+#define TASK_SIZE_MAX_SHIFT CONFIG_TASK_SIZE_MAX_SHIFT
+#define USER_PGD_PTRS		(_AC(1,UL) << (TASK_SIZE_MAX_SHIFT - PGDIR_SHIFT))
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+#ifdef __ASSEMBLY__
+#define pax_user_shadow_base	pax_user_shadow_base(%rip)
+#else
+extern unsigned long pax_user_shadow_base;
+#endif
+#endif
+
+#endif
+
 #ifndef __ASSEMBLY__
 
 extern int direct_gbpages;
@@ -768,11 +865,23 @@ static inline void pmdp_set_wrprotect(st
  * dst and src can be on the same page, but the range must not overlap,
  * and must not cross a page boundary.
  */
-static inline void clone_pgd_range(pgd_t *dst, pgd_t *src, int count)
+static inline void clone_pgd_range(pgd_t *dst, const pgd_t *src, int count)
 {
-       memcpy(dst, src, count * sizeof(pgd_t));
+	pax_open_kernel();
+	while (count--)
+		*dst++ = *src++;
+	pax_close_kernel();
 }
 
+#ifdef CONFIG_PAX_PER_CPU_PGD
+extern void __clone_user_pgds(pgd_t *dst, const pgd_t *src);
+#endif
+
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+extern void __shadow_user_pgds(pgd_t *dst, const pgd_t *src);
+#else
+static inline void __shadow_user_pgds(pgd_t *dst, const pgd_t *src) {}
+#endif
 
 #include <asm-generic/pgtable.h>
 #endif	/* __ASSEMBLY__ */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/pgtable_types.h linux-3.2.71-pax/arch/x86/include/asm/pgtable_types.h
--- linux-3.2.71/arch/x86/include/asm/pgtable_types.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/pgtable_types.h	2012-07-04 19:24:47.520063003 +0200
@@ -16,13 +16,12 @@
 #define _PAGE_BIT_PSE		7	/* 4 MB (or 2MB) page */
 #define _PAGE_BIT_PAT		7	/* on 4KB pages */
 #define _PAGE_BIT_GLOBAL	8	/* Global TLB entry PPro+ */
-#define _PAGE_BIT_UNUSED1	9	/* available for programmer */
+#define _PAGE_BIT_SPECIAL	9	/* special mappings, no associated struct page */
 #define _PAGE_BIT_IOMAP		10	/* flag used to indicate IO mapping */
 #define _PAGE_BIT_HIDDEN	11	/* hidden by kmemcheck */
 #define _PAGE_BIT_PAT_LARGE	12	/* On 2MB or 1GB pages */
-#define _PAGE_BIT_SPECIAL	_PAGE_BIT_UNUSED1
-#define _PAGE_BIT_CPA_TEST	_PAGE_BIT_UNUSED1
-#define _PAGE_BIT_SPLITTING	_PAGE_BIT_UNUSED1 /* only valid on a PSE pmd */
+#define _PAGE_BIT_CPA_TEST	_PAGE_BIT_SPECIAL
+#define _PAGE_BIT_SPLITTING	_PAGE_BIT_SPECIAL /* only valid on a PSE pmd */
 #define _PAGE_BIT_NX           63       /* No execute: only valid after cpuid check */
 
 /* If _PAGE_BIT_PRESENT is clear, we use these: */
@@ -40,7 +39,6 @@
 #define _PAGE_DIRTY	(_AT(pteval_t, 1) << _PAGE_BIT_DIRTY)
 #define _PAGE_PSE	(_AT(pteval_t, 1) << _PAGE_BIT_PSE)
 #define _PAGE_GLOBAL	(_AT(pteval_t, 1) << _PAGE_BIT_GLOBAL)
-#define _PAGE_UNUSED1	(_AT(pteval_t, 1) << _PAGE_BIT_UNUSED1)
 #define _PAGE_IOMAP	(_AT(pteval_t, 1) << _PAGE_BIT_IOMAP)
 #define _PAGE_PAT	(_AT(pteval_t, 1) << _PAGE_BIT_PAT)
 #define _PAGE_PAT_LARGE (_AT(pteval_t, 1) << _PAGE_BIT_PAT_LARGE)
@@ -57,8 +55,10 @@
 
 #if defined(CONFIG_X86_64) || defined(CONFIG_X86_PAE)
 #define _PAGE_NX	(_AT(pteval_t, 1) << _PAGE_BIT_NX)
-#else
+#elif defined(CONFIG_KMEMCHECK)
 #define _PAGE_NX	(_AT(pteval_t, 0))
+#else
+#define _PAGE_NX	(_AT(pteval_t, 1) << _PAGE_BIT_HIDDEN)
 #endif
 
 #define _PAGE_FILE	(_AT(pteval_t, 1) << _PAGE_BIT_FILE)
@@ -96,6 +96,9 @@
 #define PAGE_READONLY_EXEC	__pgprot(_PAGE_PRESENT | _PAGE_USER |	\
 					 _PAGE_ACCESSED)
 
+#define PAGE_READONLY_NOEXEC PAGE_READONLY
+#define PAGE_SHARED_NOEXEC PAGE_SHARED
+
 #define __PAGE_KERNEL_EXEC						\
 	(_PAGE_PRESENT | _PAGE_RW | _PAGE_DIRTY | _PAGE_ACCESSED | _PAGE_GLOBAL)
 #define __PAGE_KERNEL		(__PAGE_KERNEL_EXEC | _PAGE_NX)
@@ -106,7 +109,7 @@
 #define __PAGE_KERNEL_WC		(__PAGE_KERNEL | _PAGE_CACHE_WC)
 #define __PAGE_KERNEL_NOCACHE		(__PAGE_KERNEL | _PAGE_PCD | _PAGE_PWT)
 #define __PAGE_KERNEL_UC_MINUS		(__PAGE_KERNEL | _PAGE_PCD)
-#define __PAGE_KERNEL_VSYSCALL		(__PAGE_KERNEL_RX | _PAGE_USER)
+#define __PAGE_KERNEL_VSYSCALL		(__PAGE_KERNEL_RO | _PAGE_USER)
 #define __PAGE_KERNEL_VVAR		(__PAGE_KERNEL_RO | _PAGE_USER)
 #define __PAGE_KERNEL_VVAR_NOCACHE	(__PAGE_KERNEL_VVAR | _PAGE_PCD | _PAGE_PWT)
 #define __PAGE_KERNEL_LARGE		(__PAGE_KERNEL | _PAGE_PSE)
@@ -168,8 +171,8 @@
  * bits are combined, this will alow user to access the high address mapped
  * VDSO in the presence of CONFIG_COMPAT_VDSO
  */
-#define PTE_IDENT_ATTR	 0x003		/* PRESENT+RW */
-#define PDE_IDENT_ATTR	 0x067		/* PRESENT+RW+USER+DIRTY+ACCESSED */
+#define PTE_IDENT_ATTR	 0x063		/* PRESENT+RW+DIRTY+ACCESSED */
+#define PDE_IDENT_ATTR	 0x063		/* PRESENT+RW+DIRTY+ACCESSED */
 #define PGD_IDENT_ATTR	 0x001		/* PRESENT (no other attributes) */
 #endif
 
@@ -207,7 +210,17 @@ static inline pgdval_t pgd_flags(pgd_t p
 {
 	return native_pgd_val(pgd) & PTE_FLAGS_MASK;
 }
+#endif
 
+#if PAGETABLE_LEVELS == 3
+#include <asm-generic/pgtable-nopud.h>
+#endif
+
+#if PAGETABLE_LEVELS == 2
+#include <asm-generic/pgtable-nopmd.h>
+#endif
+
+#ifndef __ASSEMBLY__
 #if PAGETABLE_LEVELS > 3
 typedef struct { pudval_t pud; } pud_t;
 
@@ -221,8 +234,6 @@ static inline pudval_t native_pud_val(pu
 	return pud.pud;
 }
 #else
-#include <asm-generic/pgtable-nopud.h>
-
 static inline pudval_t native_pud_val(pud_t pud)
 {
 	return native_pgd_val(pud.pgd);
@@ -242,8 +253,6 @@ static inline pmdval_t native_pmd_val(pm
 	return pmd.pmd;
 }
 #else
-#include <asm-generic/pgtable-nopmd.h>
-
 static inline pmdval_t native_pmd_val(pmd_t pmd)
 {
 	return native_pgd_val(pmd.pud.pgd);
@@ -283,7 +292,6 @@ typedef struct page *pgtable_t;
 
 extern pteval_t __supported_pte_mask;
 extern void set_nx(void);
-extern int nx_enabled;
 
 #define pgprot_writecombine	pgprot_writecombine
 extern pgprot_t pgprot_writecombine(pgprot_t prot);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/processor-flags.h linux-3.2.71-pax/arch/x86/include/asm/processor-flags.h
--- linux-3.2.71/arch/x86/include/asm/processor-flags.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/processor-flags.h	2012-09-11 20:41:05.480019992 +0200
@@ -62,6 +62,7 @@
 #define X86_CR4_RDWRGSFS 0x00010000 /* enable RDWRGSFS support */
 #define X86_CR4_OSXSAVE 0x00040000 /* enable xsave and xrestore */
 #define X86_CR4_SMEP	0x00100000 /* enable SMEP support */
+#define X86_CR4_SMAP	0x00200000 /* enable SMAP support */
 
 /*
  * x86-64 Task Priority Register, CR8
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/processor.h linux-3.2.71-pax/arch/x86/include/asm/processor.h
--- linux-3.2.71/arch/x86/include/asm/processor.h	2012-08-12 12:28:37.769232285 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/processor.h	2013-11-23 18:07:03.453937068 +0100
@@ -266,7 +266,7 @@ struct tss_struct {
 
 } ____cacheline_aligned;
 
-DECLARE_PER_CPU_SHARED_ALIGNED(struct tss_struct, init_tss);
+extern struct tss_struct init_tss[NR_CPUS];
 
 /*
  * Save the original ist values for checking stack pointers during debugging
@@ -859,11 +859,18 @@ static inline void spin_lock_prefetch(co
  */
 #define TASK_SIZE		PAGE_OFFSET
 #define TASK_SIZE_MAX		TASK_SIZE
+
+#ifdef CONFIG_PAX_SEGMEXEC
+#define SEGMEXEC_TASK_SIZE	(TASK_SIZE / 2)
+#define STACK_TOP		((current->mm->pax_flags & MF_PAX_SEGMEXEC)?SEGMEXEC_TASK_SIZE:TASK_SIZE)
+#else
 #define STACK_TOP		TASK_SIZE
-#define STACK_TOP_MAX		STACK_TOP
+#endif
+
+#define STACK_TOP_MAX		TASK_SIZE
 
 #define INIT_THREAD  {							  \
-	.sp0			= sizeof(init_stack) + (long)&init_stack, \
+	.sp0			= sizeof(init_stack) + (long)&init_stack - 8, \
 	.vm86_info		= NULL,					  \
 	.sysenter_cs		= __KERNEL_CS,				  \
 	.io_bitmap_ptr		= NULL,					  \
@@ -877,7 +884,7 @@ static inline void spin_lock_prefetch(co
  */
 #define INIT_TSS  {							  \
 	.x86_tss = {							  \
-		.sp0		= sizeof(init_stack) + (long)&init_stack, \
+		.sp0		= sizeof(init_stack) + (long)&init_stack - 8, \
 		.ss0		= __KERNEL_DS,				  \
 		.ss1		= __KERNEL_CS,				  \
 		.io_bitmap_base	= INVALID_IO_BITMAP_OFFSET,		  \
@@ -888,11 +895,7 @@ static inline void spin_lock_prefetch(co
 extern unsigned long thread_saved_pc(struct task_struct *tsk);
 
 #define THREAD_SIZE_LONGS      (THREAD_SIZE/sizeof(unsigned long))
-#define KSTK_TOP(info)                                                 \
-({                                                                     \
-       unsigned long *__ptr = (unsigned long *)(info);                 \
-       (unsigned long)(&__ptr[THREAD_SIZE_LONGS]);                     \
-})
+#define KSTK_TOP(info)         ((container_of(info, struct task_struct, tinfo))->thread.sp0)
 
 /*
  * The below -8 is to reserve 8 bytes on top of the ring0 stack.
@@ -907,7 +910,7 @@ extern unsigned long thread_saved_pc(str
 #define task_pt_regs(task)                                             \
 ({                                                                     \
        struct pt_regs *__regs__;                                       \
-       __regs__ = (struct pt_regs *)(KSTK_TOP(task_stack_page(task))-8); \
+       __regs__ = (struct pt_regs *)((task)->thread.sp0);              \
        __regs__ - 1;                                                   \
 })
 
@@ -917,13 +920,13 @@ extern unsigned long thread_saved_pc(str
 /*
  * User space process size. 47bits minus one guard page.
  */
-#define TASK_SIZE_MAX	((1UL << 47) - PAGE_SIZE)
+#define TASK_SIZE_MAX	((1UL << TASK_SIZE_MAX_SHIFT) - PAGE_SIZE)
 
 /* This decides where the kernel will search for a free chunk of vm
  * space during mmap's.
  */
 #define IA32_PAGE_OFFSET	((current->personality & ADDR_LIMIT_3GB) ? \
-					0xc0000000 : 0xFFFFe000)
+					0xc0000000 : 0xFFFFf000)
 
 #define TASK_SIZE		(test_thread_flag(TIF_IA32) ? \
 					IA32_PAGE_OFFSET : TASK_SIZE_MAX)
@@ -934,11 +937,11 @@ extern unsigned long thread_saved_pc(str
 #define STACK_TOP_MAX		TASK_SIZE_MAX
 
 #define INIT_THREAD  { \
-	.sp0 = (unsigned long)&init_stack + sizeof(init_stack) \
+	.sp0 = (unsigned long)&init_stack + sizeof(init_stack) - 16 \
 }
 
 #define INIT_TSS  { \
-	.x86_tss.sp0 = (unsigned long)&init_stack + sizeof(init_stack) \
+	.x86_tss.sp0 = (unsigned long)&init_stack + sizeof(init_stack) - 16 \
 }
 
 /*
@@ -960,6 +963,10 @@ extern void start_thread(struct pt_regs
  */
 #define TASK_UNMAPPED_BASE	(PAGE_ALIGN(TASK_SIZE / 3))
 
+#ifdef CONFIG_PAX_SEGMEXEC
+#define SEGMEXEC_TASK_UNMAPPED_BASE	(PAGE_ALIGN(SEGMEXEC_TASK_SIZE / 3))
+#endif
+
 #define KSTK_EIP(task)		(task_pt_regs(task)->ip)
 
 /* Get/set a process' ability to use the timestamp counter instruction */
@@ -972,7 +979,8 @@ extern int set_tsc_mode(unsigned int val
 extern int amd_get_nb_id(int cpu);
 
 struct aperfmperf {
-	u64 aperf, mperf;
+	u64 aperf __intentional_overflow(-1);
+	u64 mperf __intentional_overflow(-1);
 };
 
 static inline void get_aperfmperf(struct aperfmperf *am)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/ptrace-abi.h linux-3.2.71-pax/arch/x86/include/asm/ptrace-abi.h
--- linux-3.2.71/arch/x86/include/asm/ptrace-abi.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/ptrace-abi.h	2013-12-10 22:41:07.167126299 +0100
@@ -49,7 +49,6 @@
 #define EFLAGS 144
 #define RSP 152
 #define SS 160
-#define ARGOFFSET R11
 #endif /* __ASSEMBLY__ */
 
 /* top of stack page */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/ptrace.h linux-3.2.71-pax/arch/x86/include/asm/ptrace.h
--- linux-3.2.71/arch/x86/include/asm/ptrace.h	2014-07-12 17:42:33.748954216 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/ptrace.h	2014-07-12 17:42:44.724954191 +0200
@@ -156,28 +156,29 @@ static inline unsigned long regs_return_
 }
 
 /*
- * user_mode_vm(regs) determines whether a register set came from user mode.
+ * user_mode(regs) determines whether a register set came from user mode.
  * This is true if V8086 mode was enabled OR if the register set was from
  * protected mode with RPL-3 CS value.  This tricky test checks that with
  * one comparison.  Many places in the kernel can bypass this full check
- * if they have already ruled out V8086 mode, so user_mode(regs) can be used.
+ * if they have already ruled out V8086 mode, so user_mode_novm(regs) can
+ * be used.
  */
-static inline int user_mode(struct pt_regs *regs)
+static inline int user_mode_novm(struct pt_regs *regs)
 {
 #ifdef CONFIG_X86_32
 	return (regs->cs & SEGMENT_RPL_MASK) == USER_RPL;
 #else
-	return !!(regs->cs & 3);
+	return !!(regs->cs & SEGMENT_RPL_MASK);
 #endif
 }
 
-static inline int user_mode_vm(struct pt_regs *regs)
+static inline int user_mode(struct pt_regs *regs)
 {
 #ifdef CONFIG_X86_32
 	return ((regs->cs & SEGMENT_RPL_MASK) | (regs->flags & X86_VM_MASK)) >=
 		USER_RPL;
 #else
-	return user_mode(regs);
+	return user_mode_novm(regs);
 #endif
 }
 
@@ -193,15 +194,16 @@ static inline int v8086_mode(struct pt_r
 #ifdef CONFIG_X86_64
 static inline bool user_64bit_mode(struct pt_regs *regs)
 {
+	unsigned long cs = regs->cs & 0xffff;
 #ifndef CONFIG_PARAVIRT
 	/*
 	 * On non-paravirt systems, this is the only long mode CPL 3
 	 * selector.  We do not allow long mode selectors in the LDT.
 	 */
-	return regs->cs == __USER_CS;
+	return cs == __USER_CS;
 #else
 	/* Headers are too twisted for this to go in paravirt.h. */
-	return regs->cs == __USER_CS || regs->cs == pv_info.extra_user_64bit_cs;
+	return cs == __USER_CS || cs == pv_info.extra_user_64bit_cs;
 #endif
 }
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/reboot.h linux-3.2.71-pax/arch/x86/include/asm/reboot.h
--- linux-3.2.71/arch/x86/include/asm/reboot.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/reboot.h	2013-02-17 16:28:46.212320258 +0100
@@ -6,19 +6,19 @@
 struct pt_regs;
 
 struct machine_ops {
-	void (*restart)(char *cmd);
-	void (*halt)(void);
-	void (*power_off)(void);
+	void (* __noreturn restart)(char *cmd);
+	void (* __noreturn halt)(void);
+	void (* __noreturn power_off)(void);
 	void (*shutdown)(void);
 	void (*crash_shutdown)(struct pt_regs *);
-	void (*emergency_restart)(void);
-};
+	void (* __noreturn emergency_restart)(void);
+} __no_const;
 
 extern struct machine_ops machine_ops;
 
 void native_machine_crash_shutdown(struct pt_regs *regs);
 void native_machine_shutdown(void);
-void machine_real_restart(unsigned int type);
+void __noreturn machine_real_restart(unsigned int type);
 /* These must match dispatch_table in reboot_32.S */
 #define MRR_BIOS	0
 #define MRR_APM		1
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/rwsem.h linux-3.2.71-pax/arch/x86/include/asm/rwsem.h
--- linux-3.2.71/arch/x86/include/asm/rwsem.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/rwsem.h	2012-07-04 19:24:47.532063005 +0200
@@ -64,6 +64,14 @@ static inline void __down_read(struct rw
 {
 	asm volatile("# beginning down_read\n\t"
 		     LOCK_PREFIX _ASM_INC "(%1)\n\t"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX _ASM_DEC "(%1)\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
 		     /* adds 0x00000001 */
 		     "  jns        1f\n"
 		     "  call call_rwsem_down_read_failed\n"
@@ -85,6 +93,14 @@ static inline int __down_read_trylock(st
 		     "1:\n\t"
 		     "  mov          %1,%2\n\t"
 		     "  add          %3,%2\n\t"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     "sub %3,%2\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
 		     "  jle	     2f\n\t"
 		     LOCK_PREFIX "  cmpxchg  %2,%0\n\t"
 		     "  jnz	     1b\n\t"
@@ -104,6 +120,14 @@ static inline void __down_write_nested(s
 	long tmp;
 	asm volatile("# beginning down_write\n\t"
 		     LOCK_PREFIX "  xadd      %1,(%2)\n\t"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     "mov %1,(%2)\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
 		     /* adds 0xffff0001, returns the old value */
 		     "  test      %1,%1\n\t"
 		     /* was the count 0 before? */
@@ -141,6 +165,14 @@ static inline void __up_read(struct rw_s
 	long tmp;
 	asm volatile("# beginning __up_read\n\t"
 		     LOCK_PREFIX "  xadd      %1,(%2)\n\t"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     "mov %1,(%2)\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
 		     /* subtracts 1, returns the old value */
 		     "  jns        1f\n\t"
 		     "  call call_rwsem_wake\n" /* expects old value in %edx */
@@ -159,6 +191,14 @@ static inline void __up_write(struct rw_
 	long tmp;
 	asm volatile("# beginning __up_write\n\t"
 		     LOCK_PREFIX "  xadd      %1,(%2)\n\t"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     "mov %1,(%2)\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
 		     /* subtracts 0xffff0001, returns the old value */
 		     "  jns        1f\n\t"
 		     "  call call_rwsem_wake\n" /* expects old value in %edx */
@@ -176,6 +216,14 @@ static inline void __downgrade_write(str
 {
 	asm volatile("# beginning __downgrade_write\n\t"
 		     LOCK_PREFIX _ASM_ADD "%2,(%1)\n\t"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX _ASM_SUB "%2,(%1)\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
 		     /*
 		      * transitions 0xZZZZ0001 -> 0xYYYY0001 (i386)
 		      *     0xZZZZZZZZ00000001 -> 0xYYYYYYYY00000001 (x86_64)
@@ -194,7 +242,15 @@ static inline void __downgrade_write(str
  */
 static inline void rwsem_atomic_add(long delta, struct rw_semaphore *sem)
 {
-	asm volatile(LOCK_PREFIX _ASM_ADD "%1,%0"
+	asm volatile(LOCK_PREFIX _ASM_ADD "%1,%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX _ASM_SUB "%1,%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
 		     : "+m" (sem->count)
 		     : "er" (delta));
 }
@@ -204,7 +260,7 @@ static inline void rwsem_atomic_add(long
  */
 static inline long rwsem_atomic_update(long delta, struct rw_semaphore *sem)
 {
-	return delta + xadd(&sem->count, delta);
+	return delta + xadd_check_overflow(&sem->count, delta);
 }
 
 #endif /* __KERNEL__ */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/segment.h linux-3.2.71-pax/arch/x86/include/asm/segment.h
--- linux-3.2.71/arch/x86/include/asm/segment.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/segment.h	2012-07-04 19:24:47.532063005 +0200
@@ -64,10 +64,15 @@
  *  26 - ESPFIX small SS
  *  27 - per-cpu			[ offset to per-cpu data area ]
  *  28 - stack_canary-20		[ for stack protector ]
- *  29 - unused
- *  30 - unused
+ *  29 - PCI BIOS CS
+ *  30 - PCI BIOS DS
  *  31 - TSS for double fault handler
  */
+#define GDT_ENTRY_KERNEXEC_EFI_CS	(1)
+#define GDT_ENTRY_KERNEXEC_EFI_DS	(2)
+#define __KERNEXEC_EFI_CS	(GDT_ENTRY_KERNEXEC_EFI_CS*8)
+#define __KERNEXEC_EFI_DS	(GDT_ENTRY_KERNEXEC_EFI_DS*8)
+
 #define GDT_ENTRY_TLS_MIN	6
 #define GDT_ENTRY_TLS_MAX 	(GDT_ENTRY_TLS_MIN + GDT_ENTRY_TLS_ENTRIES - 1)
 
@@ -79,6 +84,8 @@
 
 #define GDT_ENTRY_KERNEL_CS		(GDT_ENTRY_KERNEL_BASE+0)
 
+#define GDT_ENTRY_KERNEXEC_KERNEL_CS	(4)
+
 #define GDT_ENTRY_KERNEL_DS		(GDT_ENTRY_KERNEL_BASE+1)
 
 #define GDT_ENTRY_TSS			(GDT_ENTRY_KERNEL_BASE+4)
@@ -104,6 +111,12 @@
 #define __KERNEL_STACK_CANARY		0
 #endif
 
+#define GDT_ENTRY_PCIBIOS_CS		(GDT_ENTRY_KERNEL_BASE+17)
+#define __PCIBIOS_CS (GDT_ENTRY_PCIBIOS_CS * 8)
+
+#define GDT_ENTRY_PCIBIOS_DS		(GDT_ENTRY_KERNEL_BASE+18)
+#define __PCIBIOS_DS (GDT_ENTRY_PCIBIOS_DS * 8)
+
 #define GDT_ENTRY_DOUBLEFAULT_TSS	31
 
 /*
@@ -141,7 +154,7 @@
  */
 
 /* Matches PNP_CS32 and PNP_CS16 (they must be consecutive) */
-#define SEGMENT_IS_PNP_CODE(x)   (((x) & 0xf4) == GDT_ENTRY_PNPBIOS_BASE * 8)
+#define SEGMENT_IS_PNP_CODE(x)   (((x) & 0xFFFCU) == PNP_CS32 || ((x) & 0xFFFCU) == PNP_CS16)
 
 
 #else
@@ -165,6 +178,8 @@
 #define __USER32_CS   (GDT_ENTRY_DEFAULT_USER32_CS*8+3)
 #define __USER32_DS	__USER_DS
 
+#define GDT_ENTRY_KERNEXEC_KERNEL_CS 7
+
 #define GDT_ENTRY_TSS 8	/* needs two entries */
 #define GDT_ENTRY_LDT 10 /* needs two entries */
 #define GDT_ENTRY_TLS_MIN 12
@@ -185,6 +200,7 @@
 #endif
 
 #define __KERNEL_CS	(GDT_ENTRY_KERNEL_CS*8)
+#define __KERNEXEC_KERNEL_CS	(GDT_ENTRY_KERNEXEC_KERNEL_CS*8)
 #define __KERNEL_DS	(GDT_ENTRY_KERNEL_DS*8)
 #define __USER_DS	(GDT_ENTRY_DEFAULT_USER_DS*8+3)
 #define __USER_CS	(GDT_ENTRY_DEFAULT_USER_CS*8+3)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/smp.h linux-3.2.71-pax/arch/x86/include/asm/smp.h
--- linux-3.2.71/arch/x86/include/asm/smp.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/smp.h	2013-02-17 16:28:46.212320258 +0100
@@ -36,7 +36,7 @@ DECLARE_PER_CPU(cpumask_var_t, cpu_core_
 /* cpus sharing the last level cache: */
 DECLARE_PER_CPU(cpumask_var_t, cpu_llc_shared_map);
 DECLARE_PER_CPU(u16, cpu_llc_id);
-DECLARE_PER_CPU(int, cpu_number);
+DECLARE_PER_CPU(unsigned int, cpu_number);
 
 static inline struct cpumask *cpu_sibling_mask(int cpu)
 {
@@ -77,7 +77,7 @@ struct smp_ops {
 
 	void (*send_call_func_ipi)(const struct cpumask *mask);
 	void (*send_call_func_single_ipi)(int cpu);
-};
+} __no_const;
 
 /* Globals due to paravirt */
 extern void set_cpu_sibling_map(int cpu);
@@ -192,14 +192,8 @@ extern unsigned disabled_cpus __cpuinitd
 extern int safe_smp_processor_id(void);
 
 #elif defined(CONFIG_X86_64_SMP)
-#define raw_smp_processor_id() (percpu_read(cpu_number))
-
-#define stack_smp_processor_id()					\
-({								\
-	struct thread_info *ti;						\
-	__asm__("andq %%rsp,%0; ":"=r" (ti) : "0" (CURRENT_MASK));	\
-	ti->cpu;							\
-})
+#define raw_smp_processor_id()		(percpu_read(cpu_number))
+#define stack_smp_processor_id()	raw_smp_processor_id()
 #define safe_smp_processor_id()		smp_processor_id()
 
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/spinlock.h linux-3.2.71-pax/arch/x86/include/asm/spinlock.h
--- linux-3.2.71/arch/x86/include/asm/spinlock.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/spinlock.h	2012-07-04 19:24:47.540063002 +0200
@@ -188,6 +188,14 @@ static inline int arch_write_can_lock(ar
 static inline void arch_read_lock(arch_rwlock_t *rw)
 {
 	asm volatile(LOCK_PREFIX READ_LOCK_SIZE(dec) " (%0)\n\t"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX READ_LOCK_SIZE(inc) " (%0)\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
 		     "jns 1f\n"
 		     "call __read_lock_failed\n\t"
 		     "1:\n"
@@ -197,6 +205,14 @@ static inline void arch_read_lock(arch_r
 static inline void arch_write_lock(arch_rwlock_t *rw)
 {
 	asm volatile(LOCK_PREFIX WRITE_LOCK_SUB(%1) "(%0)\n\t"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX WRITE_LOCK_ADD(%1) "(%0)\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
 		     "jz 1f\n"
 		     "call __write_lock_failed\n\t"
 		     "1:\n"
@@ -226,13 +242,29 @@ static inline int arch_write_trylock(arc
 
 static inline void arch_read_unlock(arch_rwlock_t *rw)
 {
-	asm volatile(LOCK_PREFIX READ_LOCK_SIZE(inc) " %0"
+	asm volatile(LOCK_PREFIX READ_LOCK_SIZE(inc) " %0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX READ_LOCK_SIZE(dec) " %0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
 		     :"+m" (rw->lock) : : "memory");
 }
 
 static inline void arch_write_unlock(arch_rwlock_t *rw)
 {
-	asm volatile(LOCK_PREFIX WRITE_LOCK_ADD(%1) "%0"
+	asm volatile(LOCK_PREFIX WRITE_LOCK_ADD(%1) "%0\n"
+
+#ifdef CONFIG_PAX_REFCOUNT
+		     "jno 0f\n"
+		     LOCK_PREFIX WRITE_LOCK_SUB(%1) "%0\n"
+		     "int $4\n0:\n"
+		     _ASM_EXTABLE(0b, 0b)
+#endif
+
 		     : "+m" (rw->write) : "i" (RW_LOCK_BIAS) : "memory");
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/stackprotector.h linux-3.2.71-pax/arch/x86/include/asm/stackprotector.h
--- linux-3.2.71/arch/x86/include/asm/stackprotector.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/stackprotector.h	2012-07-04 19:24:47.540063002 +0200
@@ -48,7 +48,7 @@
  * head_32 for boot CPU and setup_per_cpu_areas() for others.
  */
 #define GDT_STACK_CANARY_INIT						\
-	[GDT_ENTRY_STACK_CANARY] = GDT_ENTRY_INIT(0x4090, 0, 0x18),
+	[GDT_ENTRY_STACK_CANARY] = GDT_ENTRY_INIT(0x4090, 0, 0x17),
 
 /*
  * Initialize the stackprotector canary value.
@@ -113,7 +113,7 @@ static inline void setup_stack_canary_se
 
 static inline void load_stack_canary_segment(void)
 {
-#ifdef CONFIG_X86_32
+#if defined(CONFIG_X86_32) && !defined(CONFIG_PAX_MEMORY_UDEREF)
 	asm volatile ("mov %0, %%gs" : : "r" (0));
 #endif
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/stacktrace.h linux-3.2.71-pax/arch/x86/include/asm/stacktrace.h
--- linux-3.2.71/arch/x86/include/asm/stacktrace.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/stacktrace.h	2012-07-04 19:24:47.540063002 +0200
@@ -11,28 +11,20 @@
 
 extern int kstack_depth_to_print;
 
-struct thread_info;
+struct task_struct;
 struct stacktrace_ops;
 
-typedef unsigned long (*walk_stack_t)(struct thread_info *tinfo,
-				      unsigned long *stack,
-				      unsigned long bp,
-				      const struct stacktrace_ops *ops,
-				      void *data,
-				      unsigned long *end,
-				      int *graph);
-
-extern unsigned long
-print_context_stack(struct thread_info *tinfo,
-		    unsigned long *stack, unsigned long bp,
-		    const struct stacktrace_ops *ops, void *data,
-		    unsigned long *end, int *graph);
-
-extern unsigned long
-print_context_stack_bp(struct thread_info *tinfo,
-		       unsigned long *stack, unsigned long bp,
-		       const struct stacktrace_ops *ops, void *data,
-		       unsigned long *end, int *graph);
+typedef unsigned long walk_stack_t(struct task_struct *task,
+				   void *stack_start,
+				   unsigned long *stack,
+				   unsigned long bp,
+				   const struct stacktrace_ops *ops,
+				   void *data,
+				   unsigned long *end,
+				   int *graph);
+
+extern walk_stack_t print_context_stack;
+extern walk_stack_t print_context_stack_bp;
 
 /* Generic stack tracer with callbacks */
 
@@ -40,7 +32,7 @@ struct stacktrace_ops {
 	void (*address)(void *data, unsigned long address, int reliable);
 	/* On negative return stop dumping */
 	int (*stack)(void *data, char *name);
-	walk_stack_t	walk_stack;
+	walk_stack_t	*walk_stack;
 };
 
 void dump_trace(struct task_struct *tsk, struct pt_regs *regs,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/sys_ia32.h linux-3.2.71-pax/arch/x86/include/asm/sys_ia32.h
--- linux-3.2.71/arch/x86/include/asm/sys_ia32.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/sys_ia32.h	2012-07-04 19:24:47.540063002 +0200
@@ -40,7 +40,7 @@ asmlinkage long sys32_rt_sigprocmask(int
 				     compat_sigset_t __user *, unsigned int);
 asmlinkage long sys32_alarm(unsigned int);
 
-asmlinkage long sys32_waitpid(compat_pid_t, unsigned int *, int);
+asmlinkage long sys32_waitpid(compat_pid_t, unsigned int __user *, int);
 asmlinkage long sys32_sysfs(int, u32, u32);
 
 asmlinkage long sys32_sched_rr_get_interval(compat_pid_t,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/system.h linux-3.2.71-pax/arch/x86/include/asm/system.h
--- linux-3.2.71/arch/x86/include/asm/system.h	2012-11-18 02:43:53.017506762 +0100
+++ linux-3.2.71-pax/arch/x86/include/asm/system.h	2012-11-18 02:44:28.653510534 +0100
@@ -125,7 +125,7 @@ do {									\
 	     "call __switch_to\n\t"					  \
 	     "movq "__percpu_arg([current_task])",%%rsi\n\t"		  \
 	     __switch_canary						  \
-	     "movq %P[thread_info](%%rsi),%%r8\n\t"			  \
+	     "movq "__percpu_arg([thread_info])",%%r8\n\t"		  \
 	     "movq %%rax,%%rdi\n\t" 					  \
 	     "testl  %[_tif_fork],%P[ti_flags](%%r8)\n\t"		  \
 	     "jnz   ret_from_fork\n\t"					  \
@@ -136,7 +136,7 @@ do {									\
 	       [threadrsp] "i" (offsetof(struct task_struct, thread.sp)), \
 	       [ti_flags] "i" (offsetof(struct thread_info, flags)),	  \
 	       [_tif_fork] "i" (_TIF_FORK),			  	  \
-	       [thread_info] "i" (offsetof(struct task_struct, stack)),   \
+	       [thread_info] "m" (current_tinfo),			  \
 	       [current_task] "m" (current_task)			  \
 	       __switch_canary_iparam					  \
 	     : "memory", "cc" __EXTRA_CLOBBER)
@@ -196,7 +196,7 @@ static inline unsigned long get_limit(un
 {
 	unsigned long __limit;
 	asm("lsll %1,%0" : "=r" (__limit) : "r" (segment));
-	return __limit + 1;
+	return __limit;
 }
 
 static inline void native_clts(void)
@@ -390,13 +390,13 @@ static inline void clflush(volatile void
 
 void cpu_idle_wait(void);
 
-extern unsigned long arch_align_stack(unsigned long sp);
+#define arch_align_stack(x) ((x) & ~0xfUL)
 extern void free_init_pages(char *what, unsigned long begin, unsigned long end);
 
 void default_idle(void);
 bool set_pm_idle_to_default(void);
 
-void stop_this_cpu(void *dummy);
+void stop_this_cpu(void *dummy) __noreturn;
 
 /*
  * Force strict CPU ordering.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/thread_info.h linux-3.2.71-pax/arch/x86/include/asm/thread_info.h
--- linux-3.2.71/arch/x86/include/asm/thread_info.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/thread_info.h	2014-03-13 17:08:14.683852326 +0100
@@ -10,6 +10,7 @@
 #include <linux/compiler.h>
 #include <asm/page.h>
 #include <asm/types.h>
+#include <asm/percpu.h>
 
 /*
  * low level task data that entry.S needs immediate access to
@@ -24,7 +25,6 @@ struct exec_domain;
 #include <linux/atomic.h>
 
 struct thread_info {
-	struct task_struct	*task;		/* main task structure */
 	struct exec_domain	*exec_domain;	/* execution domain */
 	__u32			flags;		/* low level flags */
 	__u32			status;		/* thread synchronous flags */
@@ -34,18 +34,12 @@ struct thread_info {
 	mm_segment_t		addr_limit;
 	struct restart_block    restart_block;
 	void __user		*sysenter_return;
-#ifdef CONFIG_X86_32
-	unsigned long           previous_esp;   /* ESP of the previous stack in
-						   case of nested (IRQ) stacks
-						*/
-	__u8			supervisor_stack[0];
-#endif
+	unsigned long		lowest_stack;
 	int			uaccess_err;
 };
 
-#define INIT_THREAD_INFO(tsk)			\
+#define INIT_THREAD_INFO			\
 {						\
-	.task		= &tsk,			\
 	.exec_domain	= &default_exec_domain,	\
 	.flags		= 0,			\
 	.cpu		= 0,			\
@@ -56,7 +50,7 @@ struct thread_info {
 	},					\
 }
 
-#define init_thread_info	(init_thread_union.thread_info)
+#define init_thread_info	(init_thread_union.stack)
 #define init_stack		(init_thread_union.stack)
 
 #else /* !__ASSEMBLY__ */
@@ -170,6 +164,23 @@ struct thread_info {
 	ret;								\
 })
 
+#ifdef __ASSEMBLY__
+/* how to get the thread information struct from ASM */
+#define GET_THREAD_INFO(reg)	 \
+	mov PER_CPU_VAR(current_tinfo), reg
+
+/* use this one if reg already contains %esp */
+#define GET_THREAD_INFO_WITH_ESP(reg) GET_THREAD_INFO(reg)
+#else
+/* how to get the thread information struct from C */
+DECLARE_PER_CPU(struct thread_info *, current_tinfo);
+
+static __always_inline struct thread_info *current_thread_info(void)
+{
+	return percpu_read_stable(current_tinfo);
+}
+#endif
+
 #ifdef CONFIG_X86_32
 
 #define STACK_WARN	(THREAD_SIZE/8)
@@ -180,35 +191,13 @@ struct thread_info {
  */
 #ifndef __ASSEMBLY__
 
-
 /* how to get the current stack pointer from C */
 register unsigned long current_stack_pointer asm("esp") __used;
 
-/* how to get the thread information struct from C */
-static inline struct thread_info *current_thread_info(void)
-{
-	return (struct thread_info *)
-		(current_stack_pointer & ~(THREAD_SIZE - 1));
-}
-
-#else /* !__ASSEMBLY__ */
-
-/* how to get the thread information struct from ASM */
-#define GET_THREAD_INFO(reg)	 \
-	movl $-THREAD_SIZE, reg; \
-	andl %esp, reg
-
-/* use this one if reg already contains %esp */
-#define GET_THREAD_INFO_WITH_ESP(reg) \
-	andl $-THREAD_SIZE, reg
-
 #endif
 
 #else /* X86_32 */
 
-#include <asm/percpu.h>
-#define KERNEL_STACK_OFFSET (5*8)
-
 /*
  * macros/functions for gaining access to the thread information structure
  * preempt_count needs to be 1 initially, until the scheduler is functional.
@@ -216,21 +205,8 @@ static inline struct thread_info *curren
 #ifndef __ASSEMBLY__
 DECLARE_PER_CPU(unsigned long, kernel_stack);
 
-static inline struct thread_info *current_thread_info(void)
-{
-	struct thread_info *ti;
-	ti = (void *)(percpu_read_stable(kernel_stack) +
-		      KERNEL_STACK_OFFSET - THREAD_SIZE);
-	return ti;
-}
-
-#else /* !__ASSEMBLY__ */
-
-/* how to get the thread information struct from ASM */
-#define GET_THREAD_INFO(reg) \
-	movq PER_CPU_VAR(kernel_stack),reg ; \
-	subq $(THREAD_SIZE-KERNEL_STACK_OFFSET),reg
-
+/* how to get the current stack pointer from C */
+register unsigned long current_stack_pointer asm("rsp") __used;
 #endif
 
 #endif /* !X86_32 */
@@ -264,5 +240,16 @@ extern void arch_task_cache_init(void);
 extern void free_thread_info(struct thread_info *ti);
 extern int arch_dup_task_struct(struct task_struct *dst, struct task_struct *src);
 #define arch_task_cache_init arch_task_cache_init
+
+#define __HAVE_THREAD_FUNCTIONS
+#define task_thread_info(task)	(&(task)->tinfo)
+#define task_stack_page(task)	((task)->stack)
+#define setup_thread_stack(p, org) do {} while (0)
+#define end_of_stack(p) ((unsigned long *)task_stack_page(p) + 1)
+
+#define __HAVE_ARCH_TASK_STRUCT_ALLOCATOR
+extern struct task_struct *alloc_task_struct_node(int node);
+extern void free_task_struct(struct task_struct *);
+
 #endif
 #endif /* _ASM_X86_THREAD_INFO_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/uaccess_32.h linux-3.2.71-pax/arch/x86/include/asm/uaccess_32.h
--- linux-3.2.71/arch/x86/include/asm/uaccess_32.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/uaccess_32.h	2013-11-23 18:07:03.461937068 +0100
@@ -43,6 +43,11 @@ unsigned long __must_check __copy_from_u
 static __always_inline unsigned long __must_check
 __copy_to_user_inatomic(void __user *to, const void *from, unsigned long n)
 {
+	if ((long)n < 0)
+		return n;
+
+	check_object_size(from, n, true);
+
 	if (__builtin_constant_p(n)) {
 		unsigned long ret;
 
@@ -82,12 +87,16 @@ static __always_inline unsigned long __m
 __copy_to_user(void __user *to, const void *from, unsigned long n)
 {
 	might_fault();
+
 	return __copy_to_user_inatomic(to, from, n);
 }
 
 static __always_inline unsigned long
 __copy_from_user_inatomic(void *to, const void __user *from, unsigned long n)
 {
+	if ((long)n < 0)
+		return n;
+
 	/* Avoid zeroing the tail if the copy fails..
 	 * If 'n' is constant and 1, 2, or 4, we do still zero on a failure,
 	 * but as the zeroing behaviour is only significant when n is not
@@ -137,6 +146,12 @@ static __always_inline unsigned long
 __copy_from_user(void *to, const void __user *from, unsigned long n)
 {
 	might_fault();
+
+	if ((long)n < 0)
+		return n;
+
+	check_object_size(to, n, false);
+
 	if (__builtin_constant_p(n)) {
 		unsigned long ret;
 
@@ -159,6 +174,10 @@ static __always_inline unsigned long __c
 				const void __user *from, unsigned long n)
 {
 	might_fault();
+
+	if ((long)n < 0)
+		return n;
+
 	if (__builtin_constant_p(n)) {
 		unsigned long ret;
 
@@ -181,15 +200,19 @@ static __always_inline unsigned long
 __copy_from_user_inatomic_nocache(void *to, const void __user *from,
 				  unsigned long n)
 {
-       return __copy_from_user_ll_nocache_nozero(to, from, n);
-}
+	if ((long)n < 0)
+		return n;
 
-unsigned long __must_check copy_to_user(void __user *to,
-					const void *from, unsigned long n);
-unsigned long __must_check _copy_from_user(void *to,
-					  const void __user *from,
-					  unsigned long n);
+	return __copy_from_user_ll_nocache_nozero(to, from, n);
+}
 
+extern void copy_to_user_overflow(void)
+#ifdef CONFIG_DEBUG_STRICT_USER_COPY_CHECKS
+	__compiletime_error("copy_to_user() buffer size is not provably correct")
+#else
+	__compiletime_warning("copy_to_user() buffer size is not provably correct")
+#endif
+;
 
 extern void copy_from_user_overflow(void)
 #ifdef CONFIG_DEBUG_STRICT_USER_COPY_CHECKS
@@ -199,17 +222,60 @@ extern void copy_from_user_overflow(void
 #endif
 ;
 
-static inline unsigned long __must_check copy_from_user(void *to,
-					  const void __user *from,
-					  unsigned long n)
-{
-	int sz = __compiletime_object_size(to);
-
-	if (likely(sz == -1 || sz >= n))
-		n = _copy_from_user(to, from, n);
-	else
-		copy_from_user_overflow();
+/**
+ * copy_to_user: - Copy a block of data into user space.
+ * @to:   Destination address, in user space.
+ * @from: Source address, in kernel space.
+ * @n:    Number of bytes to copy.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * Copy data from kernel space to user space.
+ *
+ * Returns number of bytes that could not be copied.
+ * On success, this will be zero.
+ */
+static inline unsigned long __must_check
+copy_to_user(void __user *to, const void *from, unsigned long n)
+{
+	size_t sz = __compiletime_object_size(from);
+
+	if (unlikely(sz != (size_t)-1 && sz < n))
+		copy_to_user_overflow();
+	else if (access_ok(VERIFY_WRITE, to, n))
+		n = __copy_to_user(to, from, n);
+	return n;
+}
+
+/**
+ * copy_from_user: - Copy a block of data from user space.
+ * @to:   Destination address, in kernel space.
+ * @from: Source address, in user space.
+ * @n:    Number of bytes to copy.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * Copy data from user space to kernel space.
+ *
+ * Returns number of bytes that could not be copied.
+ * On success, this will be zero.
+ *
+ * If some data could not be copied, this function will pad the copied
+ * data to the requested size using zero bytes.
+ */
+static inline unsigned long __must_check
+copy_from_user(void *to, const void __user *from, unsigned long n)
+{
+	size_t sz = __compiletime_object_size(to);
+
+	check_object_size(to, n, false);
 
+	if (unlikely(sz != (size_t)-1 && sz < n))
+		copy_from_user_overflow();
+	else if (access_ok(VERIFY_READ, from, n))
+		n = __copy_from_user(to, from, n);
+	else if ((long)n > 0)
+		memset(to, 0, n);
 	return n;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/uaccess_64.h linux-3.2.71-pax/arch/x86/include/asm/uaccess_64.h
--- linux-3.2.71/arch/x86/include/asm/uaccess_64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/uaccess_64.h	2014-03-23 21:07:50.740059889 +0100
@@ -10,6 +10,9 @@
 #include <asm/alternative.h>
 #include <asm/cpufeature.h>
 #include <asm/page.h>
+#include <asm/pgtable.h>
+
+#define set_fs(x)	(current_thread_info()->addr_limit = (x))
 
 /*
  * Copy To/From Userspace
@@ -17,12 +20,12 @@
 
 /* Handles exceptions in both to and from, but doesn't do access_ok */
 __must_check unsigned long
-copy_user_generic_string(void *to, const void *from, unsigned len);
+copy_user_generic_string(void *to, const void *from, unsigned long len) __size_overflow(3);
 __must_check unsigned long
-copy_user_generic_unrolled(void *to, const void *from, unsigned len);
+copy_user_generic_unrolled(void *to, const void *from, unsigned long len) __size_overflow(3);
 
 static __always_inline __must_check unsigned long
-copy_user_generic(void *to, const void *from, unsigned len)
+copy_user_generic(void *to, const void *from, unsigned long len)
 {
 	unsigned ret;
 
@@ -36,138 +39,200 @@ copy_user_generic(void *to, const void *
 	return ret;
 }
 
+static __always_inline __must_check unsigned long
+__copy_to_user(void __user *to, const void *from, unsigned long len);
+static __always_inline __must_check unsigned long
+__copy_from_user(void *to, const void __user *from, unsigned long len);
 __must_check unsigned long
-_copy_to_user(void __user *to, const void *from, unsigned len);
-__must_check unsigned long
-_copy_from_user(void *to, const void __user *from, unsigned len);
-__must_check unsigned long
-copy_in_user(void __user *to, const void __user *from, unsigned len);
+copy_in_user(void __user *to, const void __user *from, unsigned long len);
+
+extern void copy_to_user_overflow(void)
+#ifdef CONFIG_DEBUG_STRICT_USER_COPY_CHECKS
+	__compiletime_error("copy_to_user() buffer size is not provably correct")
+#else
+	__compiletime_warning("copy_to_user() buffer size is not provably correct")
+#endif
+;
+
+extern void copy_from_user_overflow(void)
+#ifdef CONFIG_DEBUG_STRICT_USER_COPY_CHECKS
+	__compiletime_error("copy_from_user() buffer size is not provably correct")
+#else
+	__compiletime_warning("copy_from_user() buffer size is not provably correct")
+#endif
+;
 
 static inline unsigned long __must_check copy_from_user(void *to,
 					  const void __user *from,
 					  unsigned long n)
 {
-	int sz = __compiletime_object_size(to);
-
 	might_fault();
-	if (likely(sz == -1 || sz >= n))
-		n = _copy_from_user(to, from, n);
-#ifdef CONFIG_DEBUG_VM
-	else
-		WARN(1, "Buffer overflow detected!\n");
-#endif
+
+	check_object_size(to, n, false);
+
+	if (access_ok(VERIFY_READ, from, n))
+		n = __copy_from_user(to, from, n);
+	else if (n < INT_MAX)
+		memset(to, 0, n);
 	return n;
 }
 
 static __always_inline __must_check
-int copy_to_user(void __user *dst, const void *src, unsigned size)
+int copy_to_user(void __user *dst, const void *src, unsigned long size)
 {
 	might_fault();
 
-	return _copy_to_user(dst, src, size);
+	if (access_ok(VERIFY_WRITE, dst, size))
+		size = __copy_to_user(dst, src, size);
+	return size;
 }
 
 static __always_inline __must_check
-int __copy_from_user(void *dst, const void __user *src, unsigned size)
+unsigned long __copy_from_user(void *dst, const void __user *src, unsigned long size)
 {
-	int ret = 0;
+	size_t sz = __compiletime_object_size(dst);
+	unsigned ret = 0;
 
 	might_fault();
+
+	if (size > INT_MAX)
+		return size;
+
+	check_object_size(dst, size, false);
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	if (!access_ok_noprefault(VERIFY_READ, src, size))
+		return size;
+#endif
+
+	if (unlikely(sz != (size_t)-1 && sz < size)) {
+		copy_from_user_overflow();
+		return size;
+	}
+
 	if (!__builtin_constant_p(size))
-		return copy_user_generic(dst, (__force void *)src, size);
+		return copy_user_generic(dst, (__force_kernel const void *)____m(src), size);
 	switch (size) {
-	case 1:__get_user_asm(*(u8 *)dst, (u8 __user *)src,
+	case 1:__get_user_asm(*(u8 *)dst, (const u8 __user *)src,
 			      ret, "b", "b", "=q", 1);
 		return ret;
-	case 2:__get_user_asm(*(u16 *)dst, (u16 __user *)src,
+	case 2:__get_user_asm(*(u16 *)dst, (const u16 __user *)src,
 			      ret, "w", "w", "=r", 2);
 		return ret;
-	case 4:__get_user_asm(*(u32 *)dst, (u32 __user *)src,
+	case 4:__get_user_asm(*(u32 *)dst, (const u32 __user *)src,
 			      ret, "l", "k", "=r", 4);
 		return ret;
-	case 8:__get_user_asm(*(u64 *)dst, (u64 __user *)src,
+	case 8:__get_user_asm(*(u64 *)dst, (const u64 __user *)src,
 			      ret, "q", "", "=r", 8);
 		return ret;
 	case 10:
-		__get_user_asm(*(u64 *)dst, (u64 __user *)src,
+		__get_user_asm(*(u64 *)dst, (const u64 __user *)src,
 			       ret, "q", "", "=r", 10);
 		if (unlikely(ret))
 			return ret;
 		__get_user_asm(*(u16 *)(8 + (char *)dst),
-			       (u16 __user *)(8 + (char __user *)src),
+			       (const u16 __user *)(8 + (const char __user *)src),
 			       ret, "w", "w", "=r", 2);
 		return ret;
 	case 16:
-		__get_user_asm(*(u64 *)dst, (u64 __user *)src,
+		__get_user_asm(*(u64 *)dst, (const u64 __user *)src,
 			       ret, "q", "", "=r", 16);
 		if (unlikely(ret))
 			return ret;
 		__get_user_asm(*(u64 *)(8 + (char *)dst),
-			       (u64 __user *)(8 + (char __user *)src),
+			       (const u64 __user *)(8 + (const char __user *)src),
 			       ret, "q", "", "=r", 8);
 		return ret;
 	default:
-		return copy_user_generic(dst, (__force void *)src, size);
+		return copy_user_generic(dst, (__force_kernel const void *)____m(src), size);
 	}
 }
 
 static __always_inline __must_check
-int __copy_to_user(void __user *dst, const void *src, unsigned size)
+unsigned long __copy_to_user(void __user *dst, const void *src, unsigned long size)
 {
-	int ret = 0;
+	size_t sz = __compiletime_object_size(src);
+	unsigned ret = 0;
 
 	might_fault();
+
+	if (size > INT_MAX)
+		return size;
+
+	check_object_size(src, size, true);
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	if (!access_ok_noprefault(VERIFY_WRITE, dst, size))
+		return size;
+#endif
+
+	if (unlikely(sz != (size_t)-1 && sz < size)) {
+		copy_to_user_overflow();
+		return size;
+	}
+
 	if (!__builtin_constant_p(size))
-		return copy_user_generic((__force void *)dst, src, size);
+		return copy_user_generic((__force_kernel void *)____m(dst), src, size);
 	switch (size) {
-	case 1:__put_user_asm(*(u8 *)src, (u8 __user *)dst,
+	case 1:__put_user_asm(*(const u8 *)src, (u8 __user *)dst,
 			      ret, "b", "b", "iq", 1);
 		return ret;
-	case 2:__put_user_asm(*(u16 *)src, (u16 __user *)dst,
+	case 2:__put_user_asm(*(const u16 *)src, (u16 __user *)dst,
 			      ret, "w", "w", "ir", 2);
 		return ret;
-	case 4:__put_user_asm(*(u32 *)src, (u32 __user *)dst,
+	case 4:__put_user_asm(*(const u32 *)src, (u32 __user *)dst,
 			      ret, "l", "k", "ir", 4);
 		return ret;
-	case 8:__put_user_asm(*(u64 *)src, (u64 __user *)dst,
+	case 8:__put_user_asm(*(const u64 *)src, (u64 __user *)dst,
 			      ret, "q", "", "er", 8);
 		return ret;
 	case 10:
-		__put_user_asm(*(u64 *)src, (u64 __user *)dst,
+		__put_user_asm(*(const u64 *)src, (u64 __user *)dst,
 			       ret, "q", "", "er", 10);
 		if (unlikely(ret))
 			return ret;
 		asm("":::"memory");
-		__put_user_asm(4[(u16 *)src], 4 + (u16 __user *)dst,
+		__put_user_asm(4[(const u16 *)src], 4 + (u16 __user *)dst,
 			       ret, "w", "w", "ir", 2);
 		return ret;
 	case 16:
-		__put_user_asm(*(u64 *)src, (u64 __user *)dst,
+		__put_user_asm(*(const u64 *)src, (u64 __user *)dst,
 			       ret, "q", "", "er", 16);
 		if (unlikely(ret))
 			return ret;
 		asm("":::"memory");
-		__put_user_asm(1[(u64 *)src], 1 + (u64 __user *)dst,
+		__put_user_asm(1[(const u64 *)src], 1 + (u64 __user *)dst,
 			       ret, "q", "", "er", 8);
 		return ret;
 	default:
-		return copy_user_generic((__force void *)dst, src, size);
+		return copy_user_generic((__force_kernel void *)____m(dst), src, size);
 	}
 }
 
 static __always_inline __must_check
-int __copy_in_user(void __user *dst, const void __user *src, unsigned size)
+unsigned long __copy_in_user(void __user *dst, const void __user *src, unsigned long size)
 {
-	int ret = 0;
+	unsigned ret = 0;
 
 	might_fault();
+
+	if (size > INT_MAX)
+		return size;
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	if (!access_ok_noprefault(VERIFY_READ, src, size))
+		return size;
+	if (!access_ok_noprefault(VERIFY_WRITE, dst, size))
+		return size;
+#endif
+
 	if (!__builtin_constant_p(size))
-		return copy_user_generic((__force void *)dst,
-					 (__force void *)src, size);
+		return copy_user_generic((__force_kernel void *)____m(dst),
+					 (__force_kernel const void *)____m(src), size);
 	switch (size) {
 	case 1: {
 		u8 tmp;
-		__get_user_asm(tmp, (u8 __user *)src,
+		__get_user_asm(tmp, (const u8 __user *)src,
 			       ret, "b", "b", "=q", 1);
 		if (likely(!ret))
 			__put_user_asm(tmp, (u8 __user *)dst,
@@ -176,7 +241,7 @@ int __copy_in_user(void __user *dst, con
 	}
 	case 2: {
 		u16 tmp;
-		__get_user_asm(tmp, (u16 __user *)src,
+		__get_user_asm(tmp, (const u16 __user *)src,
 			       ret, "w", "w", "=r", 2);
 		if (likely(!ret))
 			__put_user_asm(tmp, (u16 __user *)dst,
@@ -186,7 +251,7 @@ int __copy_in_user(void __user *dst, con
 
 	case 4: {
 		u32 tmp;
-		__get_user_asm(tmp, (u32 __user *)src,
+		__get_user_asm(tmp, (const u32 __user *)src,
 			       ret, "l", "k", "=r", 4);
 		if (likely(!ret))
 			__put_user_asm(tmp, (u32 __user *)dst,
@@ -195,7 +260,7 @@ int __copy_in_user(void __user *dst, con
 	}
 	case 8: {
 		u64 tmp;
-		__get_user_asm(tmp, (u64 __user *)src,
+		__get_user_asm(tmp, (const u64 __user *)src,
 			       ret, "q", "", "=r", 8);
 		if (likely(!ret))
 			__put_user_asm(tmp, (u64 __user *)dst,
@@ -203,8 +268,8 @@ int __copy_in_user(void __user *dst, con
 		return ret;
 	}
 	default:
-		return copy_user_generic((__force void *)dst,
-					 (__force void *)src, size);
+		return copy_user_generic((__force_kernel void *)____m(dst),
+					 (__force_kernel const void *)____m(src), size);
 	}
 }
 
@@ -218,36 +283,57 @@ __must_check long strlen_user(const char
 __must_check unsigned long clear_user(void __user *mem, unsigned long len);
 __must_check unsigned long __clear_user(void __user *mem, unsigned long len);
 
-static __must_check __always_inline int
-__copy_from_user_inatomic(void *dst, const void __user *src, unsigned size)
+static __must_check __always_inline unsigned long
+__copy_from_user_inatomic(void *dst, const void __user *src, unsigned long size)
 {
-	return copy_user_generic(dst, (__force const void *)src, size);
+	if (size > INT_MAX)
+		return size;
+
+	return copy_user_generic(dst, (__force_kernel const void *)____m(src), size);
 }
 
-static __must_check __always_inline int
-__copy_to_user_inatomic(void __user *dst, const void *src, unsigned size)
+static __must_check __always_inline unsigned long
+__copy_to_user_inatomic(void __user *dst, const void *src, unsigned long size)
 {
-	return copy_user_generic((__force void *)dst, src, size);
+	if (size > INT_MAX)
+		return size;
+
+	return copy_user_generic((__force_kernel void *)____m(dst), src, size);
 }
 
-extern long __copy_user_nocache(void *dst, const void __user *src,
-				unsigned size, int zerorest);
+extern unsigned long __copy_user_nocache(void *dst, const void __user *src,
+				unsigned long size, int zerorest);
 
-static inline int
-__copy_from_user_nocache(void *dst, const void __user *src, unsigned size)
+static inline unsigned long __copy_from_user_nocache(void *dst, const void __user *src, unsigned long size)
 {
 	might_sleep();
+
+	if (size > INT_MAX)
+		return size;
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	if (!access_ok_noprefault(VERIFY_READ, src, size))
+		return size;
+#endif
+
 	return __copy_user_nocache(dst, src, size, 1);
 }
 
-static inline int
-__copy_from_user_inatomic_nocache(void *dst, const void __user *src,
-				  unsigned size)
+static inline unsigned long __copy_from_user_inatomic_nocache(void *dst, const void __user *src,
+				  unsigned long size)
 {
+	if (size > INT_MAX)
+		return size;
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	if (!access_ok_noprefault(VERIFY_READ, src, size))
+		return size;
+#endif
+
 	return __copy_user_nocache(dst, src, size, 0);
 }
 
-unsigned long
-copy_user_handle_tail(char *to, char *from, unsigned len, unsigned zerorest);
+extern unsigned long
+copy_user_handle_tail(char __user *to, char __user *from, unsigned long len, unsigned zerorest) __size_overflow(3);
 
 #endif /* _ASM_X86_UACCESS_64_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/uaccess.h linux-3.2.71-pax/arch/x86/include/asm/uaccess.h
--- linux-3.2.71/arch/x86/include/asm/uaccess.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/uaccess.h	2015-04-30 02:58:02.112515451 +0200
@@ -7,6 +7,7 @@
 #include <linux/compiler.h>
 #include <linux/thread_info.h>
 #include <linux/string.h>
+#include <linux/sched.h>
 #include <asm/asm.h>
 #include <asm/page.h>
 
@@ -28,7 +29,12 @@
 
 #define get_ds()	(KERNEL_DS)
 #define get_fs()	(current_thread_info()->addr_limit)
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_MEMORY_UDEREF)
+void __set_fs(mm_segment_t x);
+void set_fs(mm_segment_t x);
+#else
 #define set_fs(x)	(current_thread_info()->addr_limit = (x))
+#endif
 
 #define segment_eq(a, b)	((a).seg == (b).seg)
 
@@ -52,7 +58,7 @@
 	__chk_user_ptr(addr);						\
 	asm("add %3,%1 ; sbb %0,%0 ; cmp %1,%4 ; sbb $0,%0"		\
 	    : "=&r" (flag), "=r" (roksum)				\
-	    : "1" (addr), "g" ((long)(size)),				\
+	    : "1" (addr), "rm" ((long)(size)),				\
 	      "rm" (current_thread_info()->addr_limit.seg));		\
 	flag;								\
 })
@@ -76,7 +82,35 @@
  * checks that the pointer is in the user space range - after calling
  * this function, memory access functions may still return -EFAULT.
  */
-#define access_ok(type, addr, size) (likely(__range_not_ok(addr, size) == 0))
+#define access_ok_noprefault(type, addr, size) (likely(__range_not_ok(addr, size) == 0))
+#define access_ok(type, addr, size)					\
+({									\
+	unsigned long __size = size;					\
+	unsigned long __addr = (unsigned long)addr;			\
+	bool __ret_ao = __range_not_ok(__addr, __size) == 0;		\
+	if (__ret_ao && __size) {					\
+		unsigned long __addr_ao = __addr & PAGE_MASK;		\
+		unsigned long __end_ao = __addr + __size - 1;		\
+		if (unlikely((__end_ao ^ __addr_ao) & PAGE_MASK)) {	\
+			while (__addr_ao <= __end_ao) {			\
+				char __c_ao;				\
+				__addr_ao += PAGE_SIZE;			\
+				if (__size > PAGE_SIZE)			\
+					cond_resched();			\
+				if (__get_user(__c_ao, (char __user *)__addr))	\
+					break;				\
+				if (type != VERIFY_WRITE) {		\
+					__addr = __addr_ao;		\
+					continue;			\
+				}					\
+				if (__put_user(__c_ao, (char __user *)__addr))	\
+					break;				\
+				__addr = __addr_ao;			\
+			}						\
+		}							\
+	}								\
+	__ret_ao;							\
+})
 
 /*
  * The exception table consists of pairs of addresses: the first is the
@@ -126,6 +160,15 @@ extern int __get_user_bad(void);
 /* Careful: we have to cast the result to the type of the pointer
  * for sign reasons */
 
+/*
+ * This is a type: either (un)signed int, if the argument fits into
+ * that type, or otherwise (un)signed long long.
+ */
+#define __inttype(x) \
+__typeof__(__builtin_choose_expr(sizeof(x) > sizeof(0U),		\
+	__builtin_choose_expr(__type_is_unsigned(__typeof__(x)), 0ULL, 0LL),\
+	__builtin_choose_expr(__type_is_unsigned(__typeof__(x)), 0U, 0)))
+
 /**
  * get_user: - Get a simple variable from user space.
  * @x:   Variable to store result.
@@ -154,7 +197,7 @@ extern int __get_user_bad(void);
 #define get_user(x, ptr)						\
 ({									\
 	int __ret_gu;							\
-	unsigned long __val_gu;						\
+	__inttype(*(ptr)) __val_gu;					\
 	__chk_user_ptr(ptr);						\
 	might_fault();							\
 	switch (sizeof(*(ptr))) {					\
@@ -182,12 +225,20 @@ extern int __get_user_bad(void);
 	asm volatile("call __put_user_" #size : "=a" (__ret_pu)	\
 		     : "0" ((typeof(*(ptr)))(x)), "c" (ptr) : "ebx")
 
-
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_MEMORY_UDEREF)
+#define __copyuser_seg "gs;"
+#define __COPYUSER_SET_ES "pushl %%gs; popl %%es\n"
+#define __COPYUSER_RESTORE_ES "pushl %%ss; popl %%es\n"
+#else
+#define __copyuser_seg
+#define __COPYUSER_SET_ES
+#define __COPYUSER_RESTORE_ES
+#endif
 
 #ifdef CONFIG_X86_32
 #define __put_user_asm_u64(x, addr, err, errret)			\
-	asm volatile("1:	movl %%eax,0(%2)\n"			\
-		     "2:	movl %%edx,4(%2)\n"			\
+	asm volatile("1:	"__copyuser_seg"movl %%eax,0(%2)\n"	\
+		     "2:	"__copyuser_seg"movl %%edx,4(%2)\n"	\
 		     "3:\n"						\
 		     ".section .fixup,\"ax\"\n"				\
 		     "4:	movl %3,%0\n"				\
@@ -199,8 +250,8 @@ extern int __get_user_bad(void);
 		     : "A" (x), "r" (addr), "i" (errret), "0" (err))
 
 #define __put_user_asm_ex_u64(x, addr)					\
-	asm volatile("1:	movl %%eax,0(%1)\n"			\
-		     "2:	movl %%edx,4(%1)\n"			\
+	asm volatile("1:	"__copyuser_seg"movl %%eax,0(%1)\n"	\
+		     "2:	"__copyuser_seg"movl %%edx,4(%1)\n"	\
 		     "3:\n"						\
 		     _ASM_EXTABLE(1b, 2b - 1b)				\
 		     _ASM_EXTABLE(2b, 3b - 2b)				\
@@ -252,7 +303,7 @@ extern void __put_user_8(void);
 	__typeof__(*(ptr)) __pu_val;				\
 	__chk_user_ptr(ptr);					\
 	might_fault();						\
-	__pu_val = x;						\
+	__pu_val = (x);						\
 	switch (sizeof(*(ptr))) {				\
 	case 1:							\
 		__put_user_x(1, __pu_val, ptr, __ret_pu);	\
@@ -373,7 +424,7 @@ do {									\
 } while (0)
 
 #define __get_user_asm(x, addr, err, itype, rtype, ltype, errret)	\
-	asm volatile("1:	mov"itype" %2,%"rtype"1\n"		\
+	asm volatile("1:	"__copyuser_seg"mov"itype" %2,%"rtype"1\n"\
 		     "2:\n"						\
 		     ".section .fixup,\"ax\"\n"				\
 		     "3:	mov %3,%0\n"				\
@@ -381,7 +432,7 @@ do {									\
 		     "	jmp 2b\n"					\
 		     ".previous\n"					\
 		     _ASM_EXTABLE(1b, 3b)				\
-		     : "=r" (err), ltype(x)				\
+		     : "=r" (err), ltype (x)				\
 		     : "m" (__m(addr)), "i" (errret), "0" (err))
 
 #define __get_user_size_ex(x, ptr, size)				\
@@ -406,7 +457,7 @@ do {									\
 } while (0)
 
 #define __get_user_asm_ex(x, addr, itype, rtype, ltype)			\
-	asm volatile("1:	mov"itype" %1,%"rtype"0\n"		\
+	asm volatile("1:	"__copyuser_seg"mov"itype" %1,%"rtype"0\n"\
 		     "2:\n"						\
 		     _ASM_EXTABLE(1b, 2b - 1b)				\
 		     : ltype(x) : "m" (__m(addr)))
@@ -423,13 +474,24 @@ do {									\
 	int __gu_err;							\
 	unsigned long __gu_val;						\
 	__get_user_size(__gu_val, (ptr), (size), __gu_err, -EFAULT);	\
-	(x) = (__force __typeof__(*(ptr)))__gu_val;			\
+	(x) = (__typeof__(*(ptr)))__gu_val;				\
 	__gu_err;							\
 })
 
 /* FIXME: this hack is definitely wrong -AK */
 struct __large_struct { unsigned long buf[100]; };
-#define __m(x) (*(struct __large_struct __user *)(x))
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+#define ____m(x)					\
+({							\
+	unsigned long ____x = (unsigned long)(x);	\
+	if (____x < pax_user_shadow_base)		\
+		____x += pax_user_shadow_base;		\
+	(typeof(x))____x;				\
+})
+#else
+#define ____m(x) (x)
+#endif
+#define __m(x) (*(struct __large_struct __user *)____m(x))
 
 /*
  * Tell gcc we read from memory instead of writing: this is because
@@ -437,7 +499,7 @@ struct __large_struct { unsigned long bu
  * aliasing issues.
  */
 #define __put_user_asm(x, addr, err, itype, rtype, ltype, errret)	\
-	asm volatile("1:	mov"itype" %"rtype"1,%2\n"		\
+	asm volatile("1:	"__copyuser_seg"mov"itype" %"rtype"1,%2\n"\
 		     "2:\n"						\
 		     ".section .fixup,\"ax\"\n"				\
 		     "3:	mov %3,%0\n"				\
@@ -445,10 +507,10 @@ struct __large_struct { unsigned long bu
 		     ".previous\n"					\
 		     _ASM_EXTABLE(1b, 3b)				\
 		     : "=r"(err)					\
-		     : ltype(x), "m" (__m(addr)), "i" (errret), "0" (err))
+		     : ltype (x), "m" (__m(addr)), "i" (errret), "0" (err))
 
 #define __put_user_asm_ex(x, addr, itype, rtype, ltype)			\
-	asm volatile("1:	mov"itype" %"rtype"0,%1\n"		\
+	asm volatile("1:	"__copyuser_seg"mov"itype" %"rtype"0,%1\n"\
 		     "2:\n"						\
 		     _ASM_EXTABLE(1b, 2b - 1b)				\
 		     : : ltype(x), "m" (__m(addr)))
@@ -487,8 +549,12 @@ struct __large_struct { unsigned long bu
  * On error, the variable @x is set to zero.
  */
 
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+#define __get_user(x, ptr)	get_user((x), (ptr))
+#else
 #define __get_user(x, ptr)						\
 	__get_user_nocheck((x), (ptr), sizeof(*(ptr)))
+#endif
 
 /**
  * __put_user: - Write a simple value into user space, with less checking.
@@ -510,8 +576,12 @@ struct __large_struct { unsigned long bu
  * Returns zero on success, or -EFAULT on error.
  */
 
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+#define __put_user(x, ptr)	put_user((x), (ptr))
+#else
 #define __put_user(x, ptr)						\
 	__put_user_nocheck((__typeof__(*(ptr)))(x), (ptr), sizeof(*(ptr)))
+#endif
 
 #define __get_user_unaligned __get_user
 #define __put_user_unaligned __put_user
@@ -529,7 +599,7 @@ struct __large_struct { unsigned long bu
 #define get_user_ex(x, ptr)	do {					\
 	unsigned long __gue_val;					\
 	__get_user_size_ex((__gue_val), (ptr), (sizeof(*(ptr))));	\
-	(x) = (__force __typeof__(*(ptr)))__gue_val;			\
+	(x) = (__typeof__(*(ptr)))__gue_val;				\
 } while (0)
 
 #ifdef CONFIG_X86_WP_WORKS_OK
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/vdso.h linux-3.2.71-pax/arch/x86/include/asm/vdso.h
--- linux-3.2.71/arch/x86/include/asm/vdso.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/vdso.h	2012-07-04 19:24:47.544063002 +0200
@@ -11,7 +11,7 @@ extern const char VDSO32_PRELINK[];
 #define VDSO32_SYMBOL(base, name)					\
 ({									\
 	extern const char VDSO32_##name[];				\
-	(void *)(VDSO32_##name - VDSO32_PRELINK + (unsigned long)(base)); \
+	(void __user *)(VDSO32_##name - VDSO32_PRELINK + (unsigned long)(base)); \
 })
 #endif
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/x86_init.h linux-3.2.71-pax/arch/x86/include/asm/x86_init.h
--- linux-3.2.71/arch/x86/include/asm/x86_init.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/x86_init.h	2013-03-28 03:36:52.456038764 +0100
@@ -139,7 +139,7 @@ struct x86_init_ops {
 	struct x86_init_timers		timers;
 	struct x86_init_iommu		iommu;
 	struct x86_init_pci		pci;
-};
+} __no_const;
 
 /**
  * struct x86_cpuinit_ops - platform specific cpu hotplug setups
@@ -147,7 +147,7 @@ struct x86_init_ops {
  */
 struct x86_cpuinit_ops {
 	void (*setup_percpu_clockev)(void);
-};
+} __no_const;
 
 /**
  * struct x86_platform_ops - platform specific runtime functions
@@ -169,7 +169,7 @@ struct x86_platform_ops {
 	void (*nmi_init)(void);
 	unsigned char (*get_nmi_reason)(void);
 	int (*i8042_detect)(void);
-};
+} __no_const;
 
 struct pci_dev;
 
@@ -177,7 +177,7 @@ struct x86_msi_ops {
 	int (*setup_msi_irqs)(struct pci_dev *dev, int nvec, int type);
 	void (*teardown_msi_irq)(unsigned int irq);
 	void (*teardown_msi_irqs)(struct pci_dev *dev);
-};
+} __no_const;
 
 extern struct x86_init_ops x86_init;
 extern struct x86_cpuinit_ops x86_cpuinit;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/xen/page.h linux-3.2.71-pax/arch/x86/include/asm/xen/page.h
--- linux-3.2.71/arch/x86/include/asm/xen/page.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/xen/page.h	2013-11-23 18:07:03.469937068 +0100
@@ -54,7 +54,7 @@ extern int m2p_remove_override(struct pa
 extern struct page *m2p_find_override(unsigned long mfn);
 extern unsigned long m2p_find_override_pfn(unsigned long mfn, unsigned long pfn);
 
-static inline unsigned long pfn_to_mfn(unsigned long pfn)
+static inline unsigned long __intentional_overflow(-1) pfn_to_mfn(unsigned long pfn)
 {
 	unsigned long mfn;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/include/asm/xsave.h linux-3.2.71-pax/arch/x86/include/asm/xsave.h
--- linux-3.2.71/arch/x86/include/asm/xsave.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/include/asm/xsave.h	2012-12-01 02:29:42.180012094 +0100
@@ -65,6 +65,8 @@ static inline int xsave_user(struct xsav
 {
 	int err;
 
+	buf = (struct xsave_struct __user *)____m(buf);
+
 	/*
 	 * Clear the xsave header first, so that reserved fields are
 	 * initialized to zero.
@@ -74,7 +76,9 @@ static inline int xsave_user(struct xsav
 	if (unlikely(err))
 		return -EFAULT;
 
-	__asm__ __volatile__("1: .byte " REX_PREFIX "0x0f,0xae,0x27\n"
+	__asm__ __volatile__("1:"
+			     __copyuser_seg
+			     ".byte " REX_PREFIX "0x0f,0xae,0x27\n"
 			     "2:\n"
 			     ".section .fixup,\"ax\"\n"
 			     "3:  movl $-1,%[err]\n"
@@ -96,11 +100,13 @@ static inline int xsave_user(struct xsav
 static inline int xrestore_user(struct xsave_struct __user *buf, u64 mask)
 {
 	int err;
-	struct xsave_struct *xstate = ((__force struct xsave_struct *)buf);
+	struct xsave_struct *xstate = ((__force_kernel struct xsave_struct *)____m(buf));
 	u32 lmask = mask;
 	u32 hmask = mask >> 32;
 
-	__asm__ __volatile__("1: .byte " REX_PREFIX "0x0f,0xae,0x2f\n"
+	__asm__ __volatile__("1:"
+			     __copyuser_seg
+			     ".byte " REX_PREFIX "0x0f,0xae,0x2f\n"
 			     "2:\n"
 			     ".section .fixup,\"ax\"\n"
 			     "3:  movl $-1,%[err]\n"
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/Kconfig linux-3.2.71-pax/arch/x86/Kconfig
--- linux-3.2.71/arch/x86/Kconfig	2015-08-07 11:37:20.371789888 +0200
+++ linux-3.2.71-pax/arch/x86/Kconfig	2015-08-07 11:37:42.991790553 +0200
@@ -237,7 +237,7 @@ config X86_HT
 
 config X86_32_LAZY_GS
 	def_bool y
-	depends on X86_32 && !CC_STACKPROTECTOR
+	depends on X86_32 && !CC_STACKPROTECTOR && !PAX_MEMORY_UDEREF
 
 config ARCH_HWEIGHT_CFLAGS
 	string
@@ -1132,7 +1132,7 @@ config PAGE_OFFSET
 	hex
 	default 0xB0000000 if VMSPLIT_3G_OPT
 	default 0x80000000 if VMSPLIT_2G
-	default 0x78000000 if VMSPLIT_2G_OPT
+	default 0x70000000 if VMSPLIT_2G_OPT
 	default 0x40000000 if VMSPLIT_1G
 	default 0xC0000000
 	depends on X86_32
@@ -1515,6 +1515,7 @@ config SECCOMP
 
 config CC_STACKPROTECTOR
 	bool "Enable -fstack-protector buffer overflow detection (EXPERIMENTAL)"
+	depends on X86_64 || !PAX_MEMORY_UDEREF
 	---help---
 	  This option turns on the -fstack-protector GCC feature. This
 	  feature puts, at the beginning of functions, a canary value on
@@ -1635,6 +1636,8 @@ config X86_NEED_RELOCS
 config PHYSICAL_ALIGN
 	hex "Alignment value to which kernel should be aligned" if X86_32
 	default "0x1000000"
+	range 0x200000 0x1000000 if PAX_KERNEXEC && X86_PAE
+	range 0x400000 0x1000000 if PAX_KERNEXEC && !X86_PAE
 	range 0x2000 0x1000000
 	---help---
 	  This value puts the alignment restrictions on physical address
@@ -1666,9 +1669,10 @@ config HOTPLUG_CPU
 	  Say N if you want to disable CPU hotplug.
 
 config COMPAT_VDSO
-	def_bool y
+	def_bool n
 	prompt "Compat VDSO support"
 	depends on X86_32 || IA32_EMULATION
+	depends on !PAX_PAGEEXEC && !PAX_SEGMEXEC && !PAX_KERNEXEC && !PAX_MEMORY_UDEREF
 	---help---
 	  Map the 32-bit VDSO to the predictable old-style address too.
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/Kconfig.cpu linux-3.2.71-pax/arch/x86/Kconfig.cpu
--- linux-3.2.71/arch/x86/Kconfig.cpu	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/Kconfig.cpu	2012-07-04 19:24:47.548063003 +0200
@@ -341,7 +341,7 @@ config X86_PPRO_FENCE
 
 config X86_F00F_BUG
 	def_bool y
-	depends on M586MMX || M586TSC || M586 || M486 || M386
+	depends on (M586MMX || M586TSC || M586 || M486 || M386) && !PAX_KERNEXEC
 
 config X86_INVD_BUG
 	def_bool y
@@ -365,7 +365,7 @@ config X86_POPAD_OK
 
 config X86_ALIGNMENT_16
 	def_bool y
-	depends on MWINCHIP3D || MWINCHIPC6 || MCYRIXIII || MELAN || MK6 || M586MMX || M586TSC || M586 || M486 || MVIAC3_2 || MGEODEGX1
+	depends on MWINCHIP3D || MWINCHIPC6 || MCYRIXIII || X86_ELAN || MK8 || MK7 || MK6 || MCORE2 || MPENTIUM4 || MPENTIUMIII || MPENTIUMII || M686 || M586MMX || M586TSC || M586 || M486 || MVIAC3_2 || MGEODEGX1
 
 config X86_INTEL_USERCOPY
 	def_bool y
@@ -411,7 +411,7 @@ config X86_CMPXCHG64
 # generates cmov.
 config X86_CMOV
 	def_bool y
-	depends on (MK8 || MK7 || MCORE2 || MPENTIUM4 || MPENTIUMM || MPENTIUMIII || MPENTIUMII || M686 || MVIAC3_2 || MVIAC7 || MCRUSOE || MEFFICEON || X86_64 || MATOM || MGEODE_LX)
+	depends on (MK8 || MK7 || MCORE2 || MPSC || MPENTIUM4 || MPENTIUMM || MPENTIUMIII || MPENTIUMII || M686 || MVIAC3_2 || MVIAC7 || MCRUSOE || MEFFICEON || X86_64 || MATOM || MGEODE_LX)
 
 config X86_MINIMUM_CPU_FAMILY
 	int
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/Kconfig.debug linux-3.2.71-pax/arch/x86/Kconfig.debug
--- linux-3.2.71/arch/x86/Kconfig.debug	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/Kconfig.debug	2012-07-21 10:46:40.572999078 +0200
@@ -81,7 +81,7 @@ config X86_PTDUMP
 config DEBUG_RODATA
 	bool "Write protect kernel read-only data structures"
 	default y
-	depends on DEBUG_KERNEL
+	depends on DEBUG_KERNEL && BROKEN
 	---help---
 	  Mark the kernel read-only data as write-protected in the pagetables,
 	  in order to catch accidental (and incorrect) writes to such const
@@ -99,7 +99,7 @@ config DEBUG_RODATA_TEST
 
 config DEBUG_SET_MODULE_RONX
 	bool "Set loadable kernel module data as NX and text as RO"
-	depends on MODULES
+	depends on MODULES && BROKEN
 	---help---
 	  This option helps catch unintended modifications to loadable
 	  kernel module's text and read-only data. It also prevents execution
@@ -272,7 +272,7 @@ config OPTIMIZE_INLINING
 
 config DEBUG_STRICT_USER_COPY_CHECKS
 	bool "Strict copy size checks"
-	depends on DEBUG_KERNEL && !TRACE_BRANCH_PROFILING
+	depends on DEBUG_KERNEL && !TRACE_BRANCH_PROFILING && BROKEN
 	---help---
 	  Enabling this option turns a certain set of sanity checks for user
 	  copy operations into compile time failures.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/acpi/boot.c linux-3.2.71-pax/arch/x86/kernel/acpi/boot.c
--- linux-3.2.71/arch/x86/kernel/acpi/boot.c	2012-07-27 22:08:37.690372798 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/acpi/boot.c	2013-03-28 01:35:23.240427951 +0100
@@ -1345,7 +1345,7 @@ static int __init dmi_ignore_irq0_timer_
  * If your system is blacklisted here, but you find that acpi=force
  * works for you, please contact linux-acpi@vger.kernel.org
  */
-static struct dmi_system_id __initdata acpi_dmi_table[] = {
+static const struct dmi_system_id __initconst acpi_dmi_table[] = {
 	/*
 	 * Boxes that need ACPI disabled
 	 */
@@ -1420,7 +1420,7 @@ static struct dmi_system_id __initdata a
 };
 
 /* second table for DMI checks that should run after early-quirks */
-static struct dmi_system_id __initdata acpi_dmi_table_late[] = {
+static const struct dmi_system_id __initconst acpi_dmi_table_late[] = {
 	/*
 	 * HP laptops which use a DSDT reporting as HP/SB400/10000,
 	 * which includes some code which overrides all temperature
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/acpi/realmode/Makefile linux-3.2.71-pax/arch/x86/kernel/acpi/realmode/Makefile
--- linux-3.2.71/arch/x86/kernel/acpi/realmode/Makefile	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/acpi/realmode/Makefile	2012-09-26 14:48:47.612342026 +0200
@@ -41,6 +41,9 @@ KBUILD_CFLAGS	:= $(LINUXINCLUDE) -g -Os
 		   $(call cc-option, -fno-stack-protector) \
 		   $(call cc-option, -mpreferred-stack-boundary=2)
 KBUILD_CFLAGS	+= $(call cc-option, -m32)
+ifdef CONSTIFY_PLUGIN
+KBUILD_CFLAGS	+= -fplugin-arg-constify_plugin-no-constify
+endif
 KBUILD_AFLAGS	:= $(KBUILD_CFLAGS) -D__ASSEMBLY__
 GCOV_PROFILE := n
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/acpi/sleep.c linux-3.2.71-pax/arch/x86/kernel/acpi/sleep.c
--- linux-3.2.71/arch/x86/kernel/acpi/sleep.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/acpi/sleep.c	2012-07-04 19:24:47.548063003 +0200
@@ -94,8 +94,12 @@ int acpi_suspend_lowlevel(void)
 	header->trampoline_segment = trampoline_address() >> 4;
 #ifdef CONFIG_SMP
 	stack_start = (unsigned long)temp_stack + sizeof(temp_stack);
+
+	pax_open_kernel();
 	early_gdt_descr.address =
 			(unsigned long)get_cpu_gdt_table(smp_processor_id());
+	pax_close_kernel();
+
 	initial_gs = per_cpu_offset(smp_processor_id());
 #endif
 	initial_code = (unsigned long)wakeup_long64;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/acpi/wakeup_32.S linux-3.2.71-pax/arch/x86/kernel/acpi/wakeup_32.S
--- linux-3.2.71/arch/x86/kernel/acpi/wakeup_32.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/acpi/wakeup_32.S	2012-07-04 19:24:47.552063005 +0200
@@ -30,13 +30,11 @@ wakeup_pmode_return:
 	# and restore the stack ... but you need gdt for this to work
 	movl	saved_context_esp, %esp
 
-	movl	%cs:saved_magic, %eax
-	cmpl	$0x12345678, %eax
+	cmpl	$0x12345678, saved_magic
 	jne	bogus_magic
 
 	# jump to place where we left off
-	movl	saved_eip, %eax
-	jmp	*%eax
+	jmp	*(saved_eip)
 
 bogus_magic:
 	jmp	bogus_magic
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/alternative.c linux-3.2.71-pax/arch/x86/kernel/alternative.c
--- linux-3.2.71/arch/x86/kernel/alternative.c	2012-10-10 11:02:19.571865892 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/alternative.c	2012-10-10 11:02:25.375866723 +0200
@@ -276,6 +276,13 @@ void __init_or_module apply_alternatives
 	 */
 	for (a = start; a < end; a++) {
 		instr = (u8 *)&a->instr_offset + a->instr_offset;
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+		instr += ____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR;
+		if (instr < (u8 *)_text || (u8 *)_einittext <= instr)
+			instr -= ____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR;
+#endif
+
 		replacement = (u8 *)&a->repl_offset + a->repl_offset;
 		BUG_ON(a->replacementlen > a->instrlen);
 		BUG_ON(a->instrlen > sizeof(insnbuf));
@@ -307,10 +314,16 @@ static void alternatives_smp_lock(const
 	for (poff = start; poff < end; poff++) {
 		u8 *ptr = (u8 *)poff + *poff;
 
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+		ptr += ____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR;
+		if (ptr < (u8 *)_text || (u8 *)_einittext <= ptr)
+			ptr -= ____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR;
+#endif
+
 		if (!*poff || ptr < text || ptr >= text_end)
 			continue;
 		/* turn DS segment override prefix into lock prefix */
-		if (*ptr == 0x3e)
+		if (*ktla_ktva(ptr) == 0x3e)
 			text_poke(ptr, ((unsigned char []){0xf0}), 1);
 	};
 	mutex_unlock(&text_mutex);
@@ -328,10 +341,16 @@ static void alternatives_smp_unlock(cons
 	for (poff = start; poff < end; poff++) {
 		u8 *ptr = (u8 *)poff + *poff;
 
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+		ptr += ____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR;
+		if (ptr < (u8 *)_text || (u8 *)_einittext <= ptr)
+			ptr -= ____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR;
+#endif
+
 		if (!*poff || ptr < text || ptr >= text_end)
 			continue;
 		/* turn lock prefix into DS segment override prefix */
-		if (*ptr == 0xf0)
+		if (*ktla_ktva(ptr) == 0xf0)
 			text_poke(ptr, ((unsigned char []){0x3E}), 1);
 	};
 	mutex_unlock(&text_mutex);
@@ -500,7 +519,7 @@ void __init_or_module apply_paravirt(str
 
 		BUG_ON(p->len > MAX_PATCH_LEN);
 		/* prep the buffer with the original instructions */
-		memcpy(insnbuf, p->instr, p->len);
+		memcpy(insnbuf, ktla_ktva(p->instr), p->len);
 		used = pv_init_ops.patch(p->instrtype, p->clobbers, insnbuf,
 					 (unsigned long)p->instr, p->len);
 
@@ -568,7 +587,7 @@ void __init alternative_instructions(voi
 	if (smp_alt_once)
 		free_init_pages("SMP alternatives",
 				(unsigned long)__smp_locks,
-				(unsigned long)__smp_locks_end);
+				PAGE_ALIGN((unsigned long)__smp_locks_end));
 
 	restart_nmi();
 }
@@ -585,13 +604,17 @@ void __init alternative_instructions(voi
  * instructions. And on the local CPU you need to be protected again NMI or MCE
  * handlers seeing an inconsistent instruction while you patch.
  */
-void *__init_or_module text_poke_early(void *addr, const void *opcode,
+void *__kprobes text_poke_early(void *addr, const void *opcode,
 					      size_t len)
 {
 	unsigned long flags;
 	local_irq_save(flags);
-	memcpy(addr, opcode, len);
+
+	pax_open_kernel();
+	memcpy(ktla_ktva(addr), opcode, len);
 	sync_core();
+	pax_close_kernel();
+
 	local_irq_restore(flags);
 	/* Could also do a CLFLUSH here to speed up CPU recovery; but
 	   that causes hangs on some VIA CPUs. */
@@ -613,36 +636,22 @@ void *__init_or_module text_poke_early(v
  */
 void *__kprobes text_poke(void *addr, const void *opcode, size_t len)
 {
-	unsigned long flags;
-	char *vaddr;
+	unsigned char *vaddr = ktla_ktva(addr);
 	struct page *pages[2];
-	int i;
+	size_t i;
 
 	if (!core_kernel_text((unsigned long)addr)) {
-		pages[0] = vmalloc_to_page(addr);
-		pages[1] = vmalloc_to_page(addr + PAGE_SIZE);
+		pages[0] = vmalloc_to_page(vaddr);
+		pages[1] = vmalloc_to_page(vaddr + PAGE_SIZE);
 	} else {
-		pages[0] = virt_to_page(addr);
+		pages[0] = virt_to_page(vaddr);
 		WARN_ON(!PageReserved(pages[0]));
-		pages[1] = virt_to_page(addr + PAGE_SIZE);
+		pages[1] = virt_to_page(vaddr + PAGE_SIZE);
 	}
 	BUG_ON(!pages[0]);
-	local_irq_save(flags);
-	set_fixmap(FIX_TEXT_POKE0, page_to_phys(pages[0]));
-	if (pages[1])
-		set_fixmap(FIX_TEXT_POKE1, page_to_phys(pages[1]));
-	vaddr = (char *)fix_to_virt(FIX_TEXT_POKE0);
-	memcpy(&vaddr[(unsigned long)addr & ~PAGE_MASK], opcode, len);
-	clear_fixmap(FIX_TEXT_POKE0);
-	if (pages[1])
-		clear_fixmap(FIX_TEXT_POKE1);
-	local_flush_tlb();
-	sync_core();
-	/* Could also do a CLFLUSH here to speed up CPU recovery; but
-	   that causes hangs on some VIA CPUs. */
+	text_poke_early(addr, opcode, len);
 	for (i = 0; i < len; i++)
-		BUG_ON(((char *)addr)[i] != ((char *)opcode)[i]);
-	local_irq_restore(flags);
+		BUG_ON((vaddr)[i] != ((const unsigned char *)opcode)[i]);
 	return addr;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/apic/apic.c linux-3.2.71-pax/arch/x86/kernel/apic/apic.c
--- linux-3.2.71/arch/x86/kernel/apic/apic.c	2014-12-14 21:13:44.978054661 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/apic/apic.c	2014-12-14 21:13:52.750069182 +0100
@@ -174,7 +174,7 @@ int first_system_vector = 0xfe;
 /*
  * Debug level, exported for io_apic.c
  */
-unsigned int apic_verbosity;
+int apic_verbosity;
 
 int pic_mode;
 
@@ -1859,7 +1859,7 @@ void smp_error_interrupt(struct pt_regs
 	apic_write(APIC_ESR, 0);
 	v1 = apic_read(APIC_ESR);
 	ack_APIC_irq();
-	atomic_inc(&irq_err_count);
+	atomic_inc_unchecked(&irq_err_count);
 
 	apic_printk(APIC_DEBUG, KERN_DEBUG "APIC error on CPU%d: %02x(%02x)",
 		    smp_processor_id(), v0 , v1);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/apic/apic_flat_64.c linux-3.2.71-pax/arch/x86/kernel/apic/apic_flat_64.c
--- linux-3.2.71/arch/x86/kernel/apic/apic_flat_64.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/apic/apic_flat_64.c	2013-02-17 16:32:46.228307443 +0100
@@ -171,7 +171,7 @@ static int flat_phys_pkg_id(int initial_
 	return initial_apic_id >> index_msb;
 }
 
-static struct apic apic_flat =  {
+static struct apic apic_flat __read_only =  {
 	.name				= "flat",
 	.probe				= NULL,
 	.acpi_madt_oem_check		= flat_acpi_madt_oem_check,
@@ -327,7 +327,7 @@ static int physflat_probe(void)
 	return 0;
 }
 
-static struct apic apic_physflat =  {
+static struct apic apic_physflat __read_only =  {
 
 	.name				= "physical flat",
 	.probe				= physflat_probe,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/apic/apic_noop.c linux-3.2.71-pax/arch/x86/kernel/apic/apic_noop.c
--- linux-3.2.71/arch/x86/kernel/apic/apic_noop.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/apic/apic_noop.c	2013-03-28 01:35:23.240427951 +0100
@@ -119,7 +119,7 @@ static void noop_apic_write(u32 reg, u32
 	WARN_ON_ONCE(cpu_has_apic && !disable_apic);
 }
 
-struct apic apic_noop = {
+struct apic apic_noop __read_only = {
 	.name				= "noop",
 	.probe				= noop_probe,
 	.acpi_madt_oem_check		= NULL,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/apic/bigsmp_32.c linux-3.2.71-pax/arch/x86/kernel/apic/bigsmp_32.c
--- linux-3.2.71/arch/x86/kernel/apic/bigsmp_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/apic/bigsmp_32.c	2013-02-17 16:28:47.616320183 +0100
@@ -193,7 +193,7 @@ static int probe_bigsmp(void)
 	return dmi_bigsmp;
 }
 
-static struct apic apic_bigsmp = {
+static struct apic apic_bigsmp __read_only = {
 
 	.name				= "bigsmp",
 	.probe				= probe_bigsmp,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/apic/es7000_32.c linux-3.2.71-pax/arch/x86/kernel/apic/es7000_32.c
--- linux-3.2.71/arch/x86/kernel/apic/es7000_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/apic/es7000_32.c	2013-03-28 01:35:23.104427959 +0100
@@ -619,8 +619,7 @@ static int es7000_mps_oem_check_cluster(
 	return ret && es7000_apic_is_cluster();
 }
 
-/* We've been warned by a false positive warning.Use __refdata to keep calm. */
-static struct apic __refdata apic_es7000_cluster = {
+static struct apic apic_es7000_cluster __read_only = {
 
 	.name				= "es7000",
 	.probe				= probe_es7000,
@@ -685,7 +684,7 @@ static struct apic __refdata apic_es7000
 	.x86_32_early_logical_apicid	= es7000_early_logical_apicid,
 };
 
-static struct apic __refdata apic_es7000 = {
+static struct apic apic_es7000 __read_only = {
 
 	.name				= "es7000",
 	.probe				= probe_es7000,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/apic/io_apic.c linux-3.2.71-pax/arch/x86/kernel/apic/io_apic.c
--- linux-3.2.71/arch/x86/kernel/apic/io_apic.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/apic/io_apic.c	2015-04-30 13:43:10.902969028 +0200
@@ -1096,7 +1096,7 @@ int IO_APIC_get_PCI_irq_vector(int bus,
 }
 EXPORT_SYMBOL(IO_APIC_get_PCI_irq_vector);
 
-void lock_vector_lock(void)
+void lock_vector_lock(void) __acquires(vector_lock)
 {
 	/* Used to the online set of cpus does not change
 	 * during assign_irq_vector.
@@ -1104,7 +1104,7 @@ void lock_vector_lock(void)
 	raw_spin_lock(&vector_lock);
 }
 
-void unlock_vector_lock(void)
+void unlock_vector_lock(void) __releases(vector_lock)
 {
 	raw_spin_unlock(&vector_lock);
 }
@@ -2510,7 +2510,7 @@ static void ack_apic_edge(struct irq_dat
 	ack_APIC_irq();
 }
 
-atomic_t irq_mis_count;
+atomic_unchecked_t irq_mis_count;
 
 static void ack_apic_level(struct irq_data *data)
 {
@@ -2576,7 +2576,7 @@ static void ack_apic_level(struct irq_da
 	 * at the cpu.
 	 */
 	if (!(v & (1 << (i & 0x1f)))) {
-		atomic_inc(&irq_mis_count);
+		atomic_inc_unchecked(&irq_mis_count);
 
 		eoi_ioapic_irq(irq, cfg);
 	}
@@ -2634,17 +2634,20 @@ static void ir_print_prefix(struct irq_d
 
 static void irq_remap_modify_chip_defaults(struct irq_chip *chip)
 {
-	chip->irq_print_chip = ir_print_prefix;
-	chip->irq_ack = ir_ack_apic_edge;
-	chip->irq_eoi = ir_ack_apic_level;
+	pax_open_kernel();
+	*(void **)&chip->irq_print_chip = ir_print_prefix;
+	*(void **)&chip->irq_ack = ir_ack_apic_edge;
+	*(void **)&chip->irq_eoi = ir_ack_apic_level;
 
 #ifdef CONFIG_SMP
-	chip->irq_set_affinity = ir_ioapic_set_affinity;
+	*(void **)&chip->irq_set_affinity = ir_ioapic_set_affinity;
 #endif
+
+	pax_close_kernel();
 }
 #endif /* CONFIG_IRQ_REMAP */
 
-static struct irq_chip ioapic_chip __read_mostly = {
+static struct irq_chip ioapic_chip = {
 	.name			= "IO-APIC",
 	.irq_startup		= startup_ioapic_irq,
 	.irq_mask		= mask_ioapic_irq,
@@ -2715,7 +2718,7 @@ static void ack_lapic_irq(struct irq_dat
 	ack_APIC_irq();
 }
 
-static struct irq_chip lapic_chip __read_mostly = {
+static struct irq_chip lapic_chip = {
 	.name		= "local-APIC",
 	.irq_mask	= mask_lapic_irq,
 	.irq_unmask	= unmask_lapic_irq,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/apic/numaq_32.c linux-3.2.71-pax/arch/x86/kernel/apic/numaq_32.c
--- linux-3.2.71/arch/x86/kernel/apic/numaq_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/apic/numaq_32.c	2013-02-17 16:28:47.520320188 +0100
@@ -472,8 +472,7 @@ static void numaq_setup_portio_remap(voi
 		(u_long) xquad_portio, (u_long) num_quads*XQUAD_PORTIO_QUAD);
 }
 
-/* Use __refdata to keep false positive warning calm.  */
-static struct apic __refdata apic_numaq = {
+static struct apic apic_numaq __read_only = {
 
 	.name				= "NUMAQ",
 	.probe				= probe_numaq,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/apic/probe_32.c linux-3.2.71-pax/arch/x86/kernel/apic/probe_32.c
--- linux-3.2.71/arch/x86/kernel/apic/probe_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/apic/probe_32.c	2013-02-17 16:28:47.616320183 +0100
@@ -87,7 +87,7 @@ static int probe_default(void)
 	return 1;
 }
 
-static struct apic apic_default = {
+static struct apic apic_default __read_only = {
 
 	.name				= "default",
 	.probe				= probe_default,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/apic/summit_32.c linux-3.2.71-pax/arch/x86/kernel/apic/summit_32.c
--- linux-3.2.71/arch/x86/kernel/apic/summit_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/apic/summit_32.c	2013-02-17 16:28:47.616320183 +0100
@@ -491,7 +491,7 @@ void setup_summit(void)
 }
 #endif
 
-static struct apic apic_summit = {
+static struct apic apic_summit __read_only = {
 
 	.name				= "summit",
 	.probe				= probe_summit,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/apic/x2apic_cluster.c linux-3.2.71-pax/arch/x86/kernel/apic/x2apic_cluster.c
--- linux-3.2.71/arch/x86/kernel/apic/x2apic_cluster.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/apic/x2apic_cluster.c	2013-02-20 01:19:12.082027525 +0100
@@ -182,7 +182,7 @@ update_clusterinfo(struct notifier_block
 	return notifier_from_errno(err);
 }
 
-static struct notifier_block __refdata x2apic_cpu_notifier = {
+static struct notifier_block x2apic_cpu_notifier = {
 	.notifier_call = update_clusterinfo,
 };
 
@@ -208,7 +208,7 @@ static int x2apic_cluster_probe(void)
 		return 0;
 }
 
-static struct apic apic_x2apic_cluster = {
+static struct apic apic_x2apic_cluster __read_only = {
 
 	.name				= "cluster x2apic",
 	.probe				= x2apic_cluster_probe,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/apic/x2apic_phys.c linux-3.2.71-pax/arch/x86/kernel/apic/x2apic_phys.c
--- linux-3.2.71/arch/x86/kernel/apic/x2apic_phys.c	2013-03-29 02:18:30.015676747 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/apic/x2apic_phys.c	2013-03-29 02:19:02.059675036 +0100
@@ -121,7 +121,7 @@ static int x2apic_phys_probe(void)
 	return apic == &apic_x2apic_phys;
 }
 
-static struct apic apic_x2apic_phys = {
+static struct apic apic_x2apic_phys __read_only = {
 
 	.name				= "physical x2apic",
 	.probe				= x2apic_phys_probe,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/apic/x2apic_uv_x.c linux-3.2.71-pax/arch/x86/kernel/apic/x2apic_uv_x.c
--- linux-3.2.71/arch/x86/kernel/apic/x2apic_uv_x.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/apic/x2apic_uv_x.c	2013-02-17 16:28:47.524320188 +0100
@@ -346,7 +346,7 @@ static int uv_probe(void)
 	return apic == &apic_x2apic_uv_x;
 }
 
-static struct apic __refdata apic_x2apic_uv_x = {
+static struct apic apic_x2apic_uv_x __read_only = {
 
 	.name				= "UV large system",
 	.probe				= uv_probe,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/apm_32.c linux-3.2.71-pax/arch/x86/kernel/apm_32.c
--- linux-3.2.71/arch/x86/kernel/apm_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/apm_32.c	2015-04-30 03:07:38.396532395 +0200
@@ -411,7 +411,7 @@ static DEFINE_MUTEX(apm_mutex);
  * This is for buggy BIOS's that refer to (real mode) segment 0x40
  * even though they are called in protected mode.
  */
-static struct desc_struct bad_bios_desc = GDT_ENTRY_INIT(0x4092,
+static const struct desc_struct bad_bios_desc = GDT_ENTRY_INIT(0x4093,
 			(unsigned long)__va(0x400UL), PAGE_SIZE - 0x400 - 1);
 
 static const char driver_version[] = "1.16ac";	/* no spaces */
@@ -589,7 +589,10 @@ static long __apm_bios_call(void *_call)
 	BUG_ON(cpu != 0);
 	gdt = get_cpu_gdt_table(cpu);
 	save_desc_40 = gdt[0x40 / 8];
+
+	pax_open_kernel();
 	gdt[0x40 / 8] = bad_bios_desc;
+	pax_close_kernel();
 
 	apm_irq_save(flags);
 	APM_DO_SAVE_SEGS;
@@ -598,7 +601,11 @@ static long __apm_bios_call(void *_call)
 			  &call->esi);
 	APM_DO_RESTORE_SEGS;
 	apm_irq_restore(flags);
+
+	pax_open_kernel();
 	gdt[0x40 / 8] = save_desc_40;
+	pax_close_kernel();
+
 	put_cpu();
 
 	return call->eax & 0xff;
@@ -665,7 +672,10 @@ static long __apm_bios_call_simple(void
 	BUG_ON(cpu != 0);
 	gdt = get_cpu_gdt_table(cpu);
 	save_desc_40 = gdt[0x40 / 8];
+
+	pax_open_kernel();
 	gdt[0x40 / 8] = bad_bios_desc;
+	pax_close_kernel();
 
 	apm_irq_save(flags);
 	APM_DO_SAVE_SEGS;
@@ -673,7 +683,11 @@ static long __apm_bios_call_simple(void
 					 &call->eax);
 	APM_DO_RESTORE_SEGS;
 	apm_irq_restore(flags);
+
+	pax_open_kernel();
 	gdt[0x40 / 8] = save_desc_40;
+	pax_close_kernel();
+
 	put_cpu();
 	return error;
 }
@@ -2037,7 +2051,7 @@ static int __init swab_apm_power_in_minu
 	return 0;
 }
 
-static struct dmi_system_id __initdata apm_dmi_table[] = {
+static const struct dmi_system_id __initconst apm_dmi_table[] = {
 	{
 		print_if_true,
 		KERN_WARNING "IBM T23 - BIOS 1.03b+ and controller firmware 1.02+ may be needed for Linux APM.",
@@ -2347,12 +2361,15 @@ static int __init apm_init(void)
 	 * code to that CPU.
 	 */
 	gdt = get_cpu_gdt_table(0);
+
+	pax_open_kernel();
 	set_desc_base(&gdt[APM_CS >> 3],
 		 (unsigned long)__va((unsigned long)apm_info.bios.cseg << 4));
 	set_desc_base(&gdt[APM_CS_16 >> 3],
 		 (unsigned long)__va((unsigned long)apm_info.bios.cseg_16 << 4));
 	set_desc_base(&gdt[APM_DS >> 3],
 		 (unsigned long)__va((unsigned long)apm_info.bios.dseg << 4));
+	pax_close_kernel();
 
 	proc_create("apm", 0, NULL, &apm_file_ops);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/asm-offsets_64.c linux-3.2.71-pax/arch/x86/kernel/asm-offsets_64.c
--- linux-3.2.71/arch/x86/kernel/asm-offsets_64.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/asm-offsets_64.c	2012-07-04 19:24:47.556063006 +0200
@@ -69,6 +69,7 @@ int main(void)
 	BLANK();
 #undef ENTRY
 
+	DEFINE(TSS_size, sizeof(struct tss_struct));
 	OFFSET(TSS_ist, tss_struct, x86_tss.ist);
 	BLANK();
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/asm-offsets.c linux-3.2.71-pax/arch/x86/kernel/asm-offsets.c
--- linux-3.2.71/arch/x86/kernel/asm-offsets.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/asm-offsets.c	2012-07-04 19:24:47.556063006 +0200
@@ -33,6 +33,8 @@ void common(void) {
 	OFFSET(TI_status, thread_info, status);
 	OFFSET(TI_addr_limit, thread_info, addr_limit);
 	OFFSET(TI_preempt_count, thread_info, preempt_count);
+	OFFSET(TI_lowest_stack, thread_info, lowest_stack);
+	DEFINE(TI_task_thread_sp0, offsetof(struct task_struct, thread.sp0) - offsetof(struct task_struct, tinfo));
 
 	BLANK();
 	OFFSET(crypto_tfm_ctx_offset, crypto_tfm, __crt_ctx);
@@ -53,8 +55,26 @@ void common(void) {
 	OFFSET(PV_CPU_irq_enable_sysexit, pv_cpu_ops, irq_enable_sysexit);
 	OFFSET(PV_CPU_read_cr0, pv_cpu_ops, read_cr0);
 	OFFSET(PV_MMU_read_cr2, pv_mmu_ops, read_cr2);
+
+#ifdef CONFIG_PAX_KERNEXEC
+	OFFSET(PV_CPU_write_cr0, pv_cpu_ops, write_cr0);
+#endif
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	OFFSET(PV_MMU_read_cr3, pv_mmu_ops, read_cr3);
+	OFFSET(PV_MMU_write_cr3, pv_mmu_ops, write_cr3);
+#ifdef CONFIG_X86_64
+	OFFSET(PV_MMU_set_pgd_batched, pv_mmu_ops, set_pgd_batched);
+#endif
 #endif
 
+#endif
+
+	BLANK();
+	DEFINE(PAGE_SIZE_asm, PAGE_SIZE);
+	DEFINE(PAGE_SHIFT_asm, PAGE_SHIFT);
+	DEFINE(THREAD_SIZE_asm, THREAD_SIZE);
+
 #ifdef CONFIG_XEN
 	BLANK();
 	OFFSET(XEN_vcpu_info_mask, vcpu_info, evtchn_upcall_mask);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/cpu/amd.c linux-3.2.71-pax/arch/x86/kernel/cpu/amd.c
--- linux-3.2.71/arch/x86/kernel/cpu/amd.c	2015-02-20 12:37:32.977178781 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/cpu/amd.c	2015-02-20 12:37:41.825178309 +0100
@@ -711,7 +711,7 @@ static unsigned int __cpuinit amd_size_c
 							unsigned int size)
 {
 	/* AMD errata T13 (order #21922) */
-	if ((c->x86 == 6)) {
+	if (c->x86 == 6) {
 		/* Duron Rev A0 */
 		if (c->x86_model == 3 && c->x86_mask == 0)
 			size = 64;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/cpu/common.c linux-3.2.71-pax/arch/x86/kernel/cpu/common.c
--- linux-3.2.71/arch/x86/kernel/cpu/common.c	2014-12-14 21:13:44.978054661 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/cpu/common.c	2015-04-03 01:48:49.944406343 +0200
@@ -84,60 +84,6 @@ static const struct cpu_dev __cpuinitcon
 
 static const struct cpu_dev *this_cpu __cpuinitdata = &default_cpu;
 
-DEFINE_PER_CPU_PAGE_ALIGNED(struct gdt_page, gdt_page) = { .gdt = {
-#ifdef CONFIG_X86_64
-	/*
-	 * We need valid kernel segments for data and code in long mode too
-	 * IRET will check the segment types  kkeil 2000/10/28
-	 * Also sysret mandates a special GDT layout
-	 *
-	 * TLS descriptors are currently at a different place compared to i386.
-	 * Hopefully nobody expects them at a fixed place (Wine?)
-	 */
-	[GDT_ENTRY_KERNEL32_CS]		= GDT_ENTRY_INIT(0xc09b, 0, 0xfffff),
-	[GDT_ENTRY_KERNEL_CS]		= GDT_ENTRY_INIT(0xa09b, 0, 0xfffff),
-	[GDT_ENTRY_KERNEL_DS]		= GDT_ENTRY_INIT(0xc093, 0, 0xfffff),
-	[GDT_ENTRY_DEFAULT_USER32_CS]	= GDT_ENTRY_INIT(0xc0fb, 0, 0xfffff),
-	[GDT_ENTRY_DEFAULT_USER_DS]	= GDT_ENTRY_INIT(0xc0f3, 0, 0xfffff),
-	[GDT_ENTRY_DEFAULT_USER_CS]	= GDT_ENTRY_INIT(0xa0fb, 0, 0xfffff),
-#else
-	[GDT_ENTRY_KERNEL_CS]		= GDT_ENTRY_INIT(0xc09a, 0, 0xfffff),
-	[GDT_ENTRY_KERNEL_DS]		= GDT_ENTRY_INIT(0xc092, 0, 0xfffff),
-	[GDT_ENTRY_DEFAULT_USER_CS]	= GDT_ENTRY_INIT(0xc0fa, 0, 0xfffff),
-	[GDT_ENTRY_DEFAULT_USER_DS]	= GDT_ENTRY_INIT(0xc0f2, 0, 0xfffff),
-	/*
-	 * Segments used for calling PnP BIOS have byte granularity.
-	 * They code segments and data segments have fixed 64k limits,
-	 * the transfer segment sizes are set at run time.
-	 */
-	/* 32-bit code */
-	[GDT_ENTRY_PNPBIOS_CS32]	= GDT_ENTRY_INIT(0x409a, 0, 0xffff),
-	/* 16-bit code */
-	[GDT_ENTRY_PNPBIOS_CS16]	= GDT_ENTRY_INIT(0x009a, 0, 0xffff),
-	/* 16-bit data */
-	[GDT_ENTRY_PNPBIOS_DS]		= GDT_ENTRY_INIT(0x0092, 0, 0xffff),
-	/* 16-bit data */
-	[GDT_ENTRY_PNPBIOS_TS1]		= GDT_ENTRY_INIT(0x0092, 0, 0),
-	/* 16-bit data */
-	[GDT_ENTRY_PNPBIOS_TS2]		= GDT_ENTRY_INIT(0x0092, 0, 0),
-	/*
-	 * The APM segments have byte granularity and their bases
-	 * are set at run time.  All have 64k limits.
-	 */
-	/* 32-bit code */
-	[GDT_ENTRY_APMBIOS_BASE]	= GDT_ENTRY_INIT(0x409a, 0, 0xffff),
-	/* 16-bit code */
-	[GDT_ENTRY_APMBIOS_BASE+1]	= GDT_ENTRY_INIT(0x009a, 0, 0xffff),
-	/* data */
-	[GDT_ENTRY_APMBIOS_BASE+2]	= GDT_ENTRY_INIT(0x4092, 0, 0xffff),
-
-	[GDT_ENTRY_ESPFIX_SS]		= GDT_ENTRY_INIT(0xc092, 0, 0xfffff),
-	[GDT_ENTRY_PERCPU]		= GDT_ENTRY_INIT(0xc092, 0, 0xfffff),
-	GDT_STACK_CANARY_INIT
-#endif
-} };
-EXPORT_PER_CPU_SYMBOL_GPL(gdt_page);
-
 static int __init x86_xsave_setup(char *s)
 {
 	if (strlen(s))
@@ -374,7 +320,7 @@ void switch_to_new_gdt(int cpu)
 {
 	struct desc_ptr gdt_descr;
 
-	gdt_descr.address = (long)get_cpu_gdt_table(cpu);
+	gdt_descr.address = (unsigned long)get_cpu_gdt_table(cpu);
 	gdt_descr.size = GDT_SIZE - 1;
 	load_gdt(&gdt_descr);
 	/* Reload the per-cpu base */
@@ -769,6 +715,16 @@ static void __cpuinit generic_identify(s
 
 	setup_smep(c);
 
+#ifdef CONFIG_X86_32
+#ifdef CONFIG_PAX_PAGEEXEC
+	if (!(__supported_pte_mask & _PAGE_NX))
+		clear_cpu_cap(c, X86_FEATURE_PSE);
+#endif
+#if defined(CONFIG_PAX_SEGMEXEC) || defined(CONFIG_PAX_KERNEXEC) || defined(CONFIG_PAX_MEMORY_UDEREF)
+	clear_cpu_cap(c, X86_FEATURE_SEP);
+#endif
+#endif
+
 	get_model_name(c); /* Default name */
 
 	detect_nopl(c);
@@ -1021,6 +977,9 @@ static __init int setup_disablecpuid(cha
 }
 __setup("clearcpuid=", setup_disablecpuid);
 
+DEFINE_PER_CPU(struct thread_info *, current_tinfo) = &init_task.tinfo;
+EXPORT_PER_CPU_SYMBOL(current_tinfo);
+
 #ifdef CONFIG_X86_64
 struct desc_ptr idt_descr = { NR_VECTORS * 16 - 1, (unsigned long) idt_table };
 
@@ -1036,7 +995,7 @@ DEFINE_PER_CPU(struct task_struct *, cur
 EXPORT_PER_CPU_SYMBOL(current_task);
 
 DEFINE_PER_CPU(unsigned long, kernel_stack) =
-	(unsigned long)&init_thread_union - KERNEL_STACK_OFFSET + THREAD_SIZE;
+	(unsigned long)&init_thread_union - 16 + THREAD_SIZE;
 EXPORT_PER_CPU_SYMBOL(kernel_stack);
 
 DEFINE_PER_CPU(char *, irq_stack_ptr) =
@@ -1101,7 +1060,7 @@ struct pt_regs * __cpuinit idle_regs(str
 {
 	memset(regs, 0, sizeof(struct pt_regs));
 	regs->fs = __KERNEL_PERCPU;
-	regs->gs = __KERNEL_STACK_CANARY;
+	savesegment(gs, regs->gs);
 
 	return regs;
 }
@@ -1156,7 +1115,7 @@ void __cpuinit cpu_init(void)
 	int i;
 
 	cpu = stack_smp_processor_id();
-	t = &per_cpu(init_tss, cpu);
+	t = init_tss + cpu;
 	oist = &per_cpu(orig_ist, cpu);
 
 #ifdef CONFIG_NUMA
@@ -1182,7 +1141,7 @@ void __cpuinit cpu_init(void)
 	switch_to_new_gdt(cpu);
 	loadsegment(fs, 0);
 
-	load_idt((const struct desc_ptr *)&idt_descr);
+	load_idt(&idt_descr);
 
 	memset(me->thread.tls_array, 0, GDT_ENTRY_TLS_ENTRIES * 8);
 	syscall_init();
@@ -1191,7 +1150,6 @@ void __cpuinit cpu_init(void)
 	wrmsrl(MSR_KERNEL_GS_BASE, 0);
 	barrier();
 
-	x86_configure_nx();
 	if (cpu != 0)
 		enable_x2apic();
 
@@ -1245,7 +1203,7 @@ void __cpuinit cpu_init(void)
 {
 	int cpu = smp_processor_id();
 	struct task_struct *curr = current;
-	struct tss_struct *t = &per_cpu(init_tss, cpu);
+	struct tss_struct *t = init_tss + cpu;
 	struct thread_struct *thread = &curr->thread;
 
 	if (cpumask_test_and_set_cpu(cpu, cpu_initialized_mask)) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/cpu/intel.c linux-3.2.71-pax/arch/x86/kernel/cpu/intel.c
--- linux-3.2.71/arch/x86/kernel/cpu/intel.c	2014-12-14 21:13:44.978054661 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/cpu/intel.c	2014-12-14 21:13:52.754069189 +0100
@@ -189,7 +189,7 @@ static void __cpuinit trap_init_f00f_bug
 	 * Update the IDT descriptor and reload the IDT so that
 	 * it uses the read-only mapped virtual address.
 	 */
-	idt_descr.address = fix_to_virt(FIX_F00F_IDT);
+	idt_descr.address = (struct desc_struct *)fix_to_virt(FIX_F00F_IDT);
 	load_idt(&idt_descr);
 }
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/cpu/intel_cacheinfo.c linux-3.2.71-pax/arch/x86/kernel/cpu/intel_cacheinfo.c
--- linux-3.2.71/arch/x86/kernel/cpu/intel_cacheinfo.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/cpu/intel_cacheinfo.c	2013-02-20 01:19:12.086027525 +0100
@@ -984,6 +984,22 @@ static struct attribute *default_attrs[]
 };
 
 #ifdef CONFIG_AMD_NB
+static struct attribute *default_attrs_amd_nb[] = {
+	&type.attr,
+	&level.attr,
+	&coherency_line_size.attr,
+	&physical_line_partition.attr,
+	&ways_of_associativity.attr,
+	&number_of_sets.attr,
+	&size.attr,
+	&shared_cpu_map.attr,
+	&shared_cpu_list.attr,
+	NULL,
+	NULL,
+	NULL,
+	NULL
+};
+
 static struct attribute ** __cpuinit amd_l3_attrs(void)
 {
 	static struct attribute **attrs;
@@ -994,18 +1010,7 @@ static struct attribute ** __cpuinit amd
 
 	n = sizeof (default_attrs) / sizeof (struct attribute *);
 
-	if (amd_nb_has_feature(AMD_NB_L3_INDEX_DISABLE))
-		n += 2;
-
-	if (amd_nb_has_feature(AMD_NB_L3_PARTITIONING))
-		n += 1;
-
-	attrs = kzalloc(n * sizeof (struct attribute *), GFP_KERNEL);
-	if (attrs == NULL)
-		return attrs = default_attrs;
-
-	for (n = 0; default_attrs[n]; n++)
-		attrs[n] = default_attrs[n];
+	attrs = default_attrs_amd_nb;
 
 	if (amd_nb_has_feature(AMD_NB_L3_INDEX_DISABLE)) {
 		attrs[n++] = &cache_disable_0.attr;
@@ -1056,6 +1061,13 @@ static struct kobj_type ktype_cache = {
 	.default_attrs	= default_attrs,
 };
 
+#ifdef CONFIG_AMD_NB
+static struct kobj_type ktype_cache_amd_nb = {
+	.sysfs_ops	= &sysfs_ops,
+	.default_attrs	= default_attrs_amd_nb,
+};
+#endif
+
 static struct kobj_type ktype_percpu_entry = {
 	.sysfs_ops	= &sysfs_ops,
 };
@@ -1121,20 +1133,26 @@ static int __cpuinit cache_add_dev(struc
 		return retval;
 	}
 
+#ifdef CONFIG_AMD_NB
+	amd_l3_attrs();
+#endif
+
 	for (i = 0; i < num_cache_leaves; i++) {
+		struct kobj_type *ktype;
+
 		this_object = INDEX_KOBJECT_PTR(cpu, i);
 		this_object->cpu = cpu;
 		this_object->index = i;
 
 		this_leaf = CPUID4_INFO_IDX(cpu, i);
 
-		ktype_cache.default_attrs = default_attrs;
+		ktype = &ktype_cache;
 #ifdef CONFIG_AMD_NB
 		if (this_leaf->base.nb)
-			ktype_cache.default_attrs = amd_l3_attrs();
+			ktype = &ktype_cache_amd_nb;
 #endif
 		retval = kobject_init_and_add(&(this_object->kobj),
-					      &ktype_cache,
+					      ktype,
 					      per_cpu(ici_cache_kobject, cpu),
 					      "index%1lu", i);
 		if (unlikely(retval)) {
@@ -1189,7 +1207,7 @@ static int __cpuinit cacheinfo_cpu_callb
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata cacheinfo_cpu_notifier = {
+static struct notifier_block cacheinfo_cpu_notifier = {
 	.notifier_call = cacheinfo_cpu_callback,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/cpu/Makefile linux-3.2.71-pax/arch/x86/kernel/cpu/Makefile
--- linux-3.2.71/arch/x86/kernel/cpu/Makefile	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/cpu/Makefile	2012-07-04 19:24:47.560063006 +0200
@@ -8,10 +8,6 @@ CFLAGS_REMOVE_common.o = -pg
 CFLAGS_REMOVE_perf_event.o = -pg
 endif
 
-# Make sure load_percpu_segment has no stackprotector
-nostackp := $(call cc-option, -fno-stack-protector)
-CFLAGS_common.o		:= $(nostackp)
-
 obj-y			:= intel_cacheinfo.o scattered.o topology.o
 obj-y			+= proc.o capflags.o powerflags.o common.o
 obj-y			+= vmware.o hypervisor.o sched.o mshyperv.o
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/cpu/mcheck/mce.c linux-3.2.71-pax/arch/x86/kernel/cpu/mcheck/mce.c
--- linux-3.2.71/arch/x86/kernel/cpu/mcheck/mce.c	2012-08-12 12:28:37.813230801 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/cpu/mcheck/mce.c	2013-06-21 19:46:49.506657585 +0200
@@ -42,6 +42,7 @@
 #include <asm/processor.h>
 #include <asm/mce.h>
 #include <asm/msr.h>
+#include <asm/local.h>
 
 #include "mce-internal.h"
 
@@ -200,7 +201,7 @@ static void print_mce(struct mce *m)
 			!(m->mcgstatus & MCG_STATUS_EIPV) ? " !INEXACT!" : "",
 				m->cs, m->ip);
 
-		if (m->cs == __KERNEL_CS)
+		if (m->cs == __KERNEL_CS || m->cs == __KERNEXEC_KERNEL_CS)
 			print_symbol("{%s}", m->ip);
 		pr_cont("\n");
 	}
@@ -233,10 +234,10 @@ static void print_mce(struct mce *m)
 
 #define PANIC_TIMEOUT 5 /* 5 seconds */
 
-static atomic_t mce_paniced;
+static atomic_unchecked_t mce_paniced;
 
 static int fake_panic;
-static atomic_t mce_fake_paniced;
+static atomic_unchecked_t mce_fake_paniced;
 
 /* Panic in progress. Enable interrupts and wait for final IPI */
 static void wait_for_panic(void)
@@ -260,7 +261,7 @@ static void mce_panic(char *msg, struct
 		/*
 		 * Make sure only one CPU runs in machine check panic
 		 */
-		if (atomic_inc_return(&mce_paniced) > 1)
+		if (atomic_inc_return_unchecked(&mce_paniced) > 1)
 			wait_for_panic();
 		barrier();
 
@@ -268,7 +269,7 @@ static void mce_panic(char *msg, struct
 		console_verbose();
 	} else {
 		/* Don't log too much for fake panic */
-		if (atomic_inc_return(&mce_fake_paniced) > 1)
+		if (atomic_inc_return_unchecked(&mce_fake_paniced) > 1)
 			return;
 	}
 	/* First print corrected ones that are still unlogged */
@@ -307,7 +308,7 @@ static void mce_panic(char *msg, struct
 	if (!fake_panic) {
 		if (panic_timeout == 0)
 			panic_timeout = mce_panic_timeout;
-		panic(msg);
+		panic("%s", msg);
 	} else
 		pr_emerg(HW_ERR "Fake kernel panic: %s\n", msg);
 }
@@ -616,7 +617,7 @@ static int mce_timed_out(u64 *t)
 	 * might have been modified by someone else.
 	 */
 	rmb();
-	if (atomic_read(&mce_paniced))
+	if (atomic_read_unchecked(&mce_paniced))
 		wait_for_panic();
 	if (!monarch_timeout)
 		goto out;
@@ -1404,7 +1405,7 @@ static void unexpected_machine_check(str
 }
 
 /* Call the installed machine check handler for this CPU setup. */
-void (*machine_check_vector)(struct pt_regs *, long error_code) =
+void (*machine_check_vector)(struct pt_regs *, long error_code) __read_only =
 						unexpected_machine_check;
 
 /*
@@ -1427,7 +1428,9 @@ void __cpuinit mcheck_cpu_init(struct cp
 		return;
 	}
 
+	pax_open_kernel();
 	machine_check_vector = do_machine_check;
+	pax_close_kernel();
 
 	__mcheck_cpu_init_generic();
 	__mcheck_cpu_init_vendor(c);
@@ -1441,7 +1444,7 @@ void __cpuinit mcheck_cpu_init(struct cp
  */
 
 static DEFINE_SPINLOCK(mce_chrdev_state_lock);
-static int mce_chrdev_open_count;	/* #times opened */
+static local_t mce_chrdev_open_count;	/* #times opened */
 static int mce_chrdev_open_exclu;	/* already open exclusive? */
 
 static int mce_chrdev_open(struct inode *inode, struct file *file)
@@ -1449,7 +1452,7 @@ static int mce_chrdev_open(struct inode
 	spin_lock(&mce_chrdev_state_lock);
 
 	if (mce_chrdev_open_exclu ||
-	    (mce_chrdev_open_count && (file->f_flags & O_EXCL))) {
+	    (local_read(&mce_chrdev_open_count) && (file->f_flags & O_EXCL))) {
 		spin_unlock(&mce_chrdev_state_lock);
 
 		return -EBUSY;
@@ -1457,7 +1460,7 @@ static int mce_chrdev_open(struct inode
 
 	if (file->f_flags & O_EXCL)
 		mce_chrdev_open_exclu = 1;
-	mce_chrdev_open_count++;
+	local_inc(&mce_chrdev_open_count);
 
 	spin_unlock(&mce_chrdev_state_lock);
 
@@ -1468,7 +1471,7 @@ static int mce_chrdev_release(struct ino
 {
 	spin_lock(&mce_chrdev_state_lock);
 
-	mce_chrdev_open_count--;
+	local_dec(&mce_chrdev_open_count);
 	mce_chrdev_open_exclu = 0;
 
 	spin_unlock(&mce_chrdev_state_lock);
@@ -2099,7 +2102,7 @@ mce_cpu_callback(struct notifier_block *
 	return NOTIFY_OK;
 }
 
-static struct notifier_block mce_cpu_notifier __cpuinitdata = {
+static struct notifier_block mce_cpu_notifier = {
 	.notifier_call = mce_cpu_callback,
 };
 
@@ -2109,7 +2112,7 @@ static __init void mce_init_banks(void)
 
 	for (i = 0; i < banks; i++) {
 		struct mce_bank *b = &mce_banks[i];
-		struct sysdev_attribute *a = &b->attr;
+		sysdev_attribute_no_const *a = &b->attr;
 
 		sysfs_attr_init(&a->attr);
 		a->attr.name	= b->attrname;
@@ -2177,7 +2180,7 @@ struct dentry *mce_get_debugfs_dir(void)
 static void mce_reset(void)
 {
 	cpu_missing = 0;
-	atomic_set(&mce_fake_paniced, 0);
+	atomic_set_unchecked(&mce_fake_paniced, 0);
 	atomic_set(&mce_executing, 0);
 	atomic_set(&mce_callin, 0);
 	atomic_set(&global_nwo, 0);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/cpu/mcheck/p5.c linux-3.2.71-pax/arch/x86/kernel/cpu/mcheck/p5.c
--- linux-3.2.71/arch/x86/kernel/cpu/mcheck/p5.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/cpu/mcheck/p5.c	2012-07-04 19:24:47.560063006 +0200
@@ -12,6 +12,7 @@
 #include <asm/system.h>
 #include <asm/mce.h>
 #include <asm/msr.h>
+#include <asm/pgtable.h>
 
 /* By default disabled */
 int mce_p5_enabled __read_mostly;
@@ -50,7 +51,9 @@ void intel_p5_mcheck_init(struct cpuinfo
 	if (!cpu_has(c, X86_FEATURE_MCE))
 		return;
 
+	pax_open_kernel();
 	machine_check_vector = pentium_machine_check;
+	pax_close_kernel();
 	/* Make sure the vector pointer is visible before we enable MCEs: */
 	wmb();
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/cpu/mcheck/therm_throt.c linux-3.2.71-pax/arch/x86/kernel/cpu/mcheck/therm_throt.c
--- linux-3.2.71/arch/x86/kernel/cpu/mcheck/therm_throt.c	2012-12-06 19:03:21.335215616 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/cpu/mcheck/therm_throt.c	2013-02-20 01:19:15.014027369 +0100
@@ -290,7 +290,7 @@ thermal_throttle_cpu_callback(struct not
 	return notifier_from_errno(err);
 }
 
-static struct notifier_block thermal_throttle_cpu_notifier __cpuinitdata =
+static struct notifier_block thermal_throttle_cpu_notifier =
 {
 	.notifier_call = thermal_throttle_cpu_callback,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/cpu/mcheck/winchip.c linux-3.2.71-pax/arch/x86/kernel/cpu/mcheck/winchip.c
--- linux-3.2.71/arch/x86/kernel/cpu/mcheck/winchip.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/cpu/mcheck/winchip.c	2012-07-04 19:24:47.560063006 +0200
@@ -11,6 +11,7 @@
 #include <asm/system.h>
 #include <asm/mce.h>
 #include <asm/msr.h>
+#include <asm/pgtable.h>
 
 /* Machine check handler for WinChip C6: */
 static void winchip_machine_check(struct pt_regs *regs, long error_code)
@@ -24,7 +25,9 @@ void winchip_mcheck_init(struct cpuinfo_
 {
 	u32 lo, hi;
 
+	pax_open_kernel();
 	machine_check_vector = winchip_machine_check;
+	pax_close_kernel();
 	/* Make sure the vector pointer is visible before we enable MCEs: */
 	wmb();
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/cpu/mtrr/main.c linux-3.2.71-pax/arch/x86/kernel/cpu/mtrr/main.c
--- linux-3.2.71/arch/x86/kernel/cpu/mtrr/main.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/cpu/mtrr/main.c	2012-07-04 19:24:47.564063006 +0200
@@ -62,7 +62,7 @@ static DEFINE_MUTEX(mtrr_mutex);
 u64 size_or_mask, size_and_mask;
 static bool mtrr_aps_delayed_init;
 
-static const struct mtrr_ops *mtrr_ops[X86_VENDOR_NUM];
+static const struct mtrr_ops *mtrr_ops[X86_VENDOR_NUM] __read_only;
 
 const struct mtrr_ops *mtrr_if;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/cpu/mtrr/mtrr.h linux-3.2.71-pax/arch/x86/kernel/cpu/mtrr/mtrr.h
--- linux-3.2.71/arch/x86/kernel/cpu/mtrr/mtrr.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/cpu/mtrr/mtrr.h	2012-07-04 19:24:47.564063006 +0200
@@ -25,7 +25,7 @@ struct mtrr_ops {
 	int	(*validate_add_page)(unsigned long base, unsigned long size,
 				     unsigned int type);
 	int	(*have_wrcomb)(void);
-};
+} __do_const;
 
 extern int generic_get_free_region(unsigned long base, unsigned long size,
 				   int replace_reg);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/cpu/perf_event.c linux-3.2.71-pax/arch/x86/kernel/cpu/perf_event.c
--- linux-3.2.71/arch/x86/kernel/cpu/perf_event.c	2014-04-02 03:15:40.767672598 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/cpu/perf_event.c	2014-04-02 03:15:49.155672150 +0200
@@ -1532,7 +1532,7 @@ perf_callchain_user(struct perf_callchai
 			break;
 
 		perf_callchain_store(entry, frame.return_address);
-		fp = frame.next_frame;
+		fp = (const void __force_user *)frame.next_frame;
 	}
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/cpuid.c linux-3.2.71-pax/arch/x86/kernel/cpuid.c
--- linux-3.2.71/arch/x86/kernel/cpuid.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/cpuid.c	2013-02-20 01:19:15.518027342 +0100
@@ -172,7 +172,7 @@ static int __cpuinit cpuid_class_cpu_cal
 	return notifier_from_errno(err);
 }
 
-static struct notifier_block __refdata cpuid_class_cpu_notifier =
+static struct notifier_block cpuid_class_cpu_notifier =
 {
 	.notifier_call = cpuid_class_cpu_callback,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/crash.c linux-3.2.71-pax/arch/x86/kernel/crash.c
--- linux-3.2.71/arch/x86/kernel/crash.c	2014-01-03 15:48:44.640070583 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/crash.c	2014-01-03 15:48:49.492070324 +0100
@@ -36,10 +36,8 @@ static void kdump_nmi_callback(int cpu,
 {
 #ifdef CONFIG_X86_32
 	struct pt_regs fixed_regs;
-#endif
 
-#ifdef CONFIG_X86_32
-	if (!user_mode_vm(regs)) {
+	if (!user_mode(regs)) {
 		crash_fixup_ss_esp(&fixed_regs, regs);
 		regs = &fixed_regs;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/crash_dump_64.c linux-3.2.71-pax/arch/x86/kernel/crash_dump_64.c
--- linux-3.2.71/arch/x86/kernel/crash_dump_64.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/crash_dump_64.c	2013-06-21 19:34:10.634698102 +0200
@@ -36,7 +36,7 @@ ssize_t copy_oldmem_page(unsigned long p
 		return -ENOMEM;
 
 	if (userbuf) {
-		if (copy_to_user(buf, vaddr + offset, csize)) {
+		if (copy_to_user((char __force_user *)buf, vaddr + offset, csize)) {
 			iounmap(vaddr);
 			return -EFAULT;
 		}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/doublefault_32.c linux-3.2.71-pax/arch/x86/kernel/doublefault_32.c
--- linux-3.2.71/arch/x86/kernel/doublefault_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/doublefault_32.c	2012-07-04 19:24:47.564063006 +0200
@@ -11,7 +11,7 @@
 
 #define DOUBLEFAULT_STACKSIZE (1024)
 static unsigned long doublefault_stack[DOUBLEFAULT_STACKSIZE];
-#define STACK_START (unsigned long)(doublefault_stack+DOUBLEFAULT_STACKSIZE)
+#define STACK_START (unsigned long)(doublefault_stack+DOUBLEFAULT_STACKSIZE-2)
 
 #define ptr_ok(x) ((x) > PAGE_OFFSET && (x) < PAGE_OFFSET + MAXMEM)
 
@@ -21,7 +21,7 @@ static void doublefault_fn(void)
 	unsigned long gdt, tss;
 
 	store_gdt(&gdt_desc);
-	gdt = gdt_desc.address;
+	gdt = (unsigned long)gdt_desc.address;
 
 	printk(KERN_EMERG "PANIC: double fault, gdt at %08lx [%d bytes]\n", gdt, gdt_desc.size);
 
@@ -58,10 +58,10 @@ struct tss_struct doublefault_tss __cach
 		/* 0x2 bit is always set */
 		.flags		= X86_EFLAGS_SF | 0x2,
 		.sp		= STACK_START,
-		.es		= __USER_DS,
+		.es		= __KERNEL_DS,
 		.cs		= __KERNEL_CS,
 		.ss		= __KERNEL_DS,
-		.ds		= __USER_DS,
+		.ds		= __KERNEL_DS,
 		.fs		= __KERNEL_PERCPU,
 
 		.__cr3		= __pa_nodebug(swapper_pg_dir),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/dumpstack_32.c linux-3.2.71-pax/arch/x86/kernel/dumpstack_32.c
--- linux-3.2.71/arch/x86/kernel/dumpstack_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/dumpstack_32.c	2012-12-01 02:29:42.184012135 +0100
@@ -38,15 +38,13 @@ void dump_trace(struct task_struct *task
 		bp = stack_frame(task, regs);
 
 	for (;;) {
-		struct thread_info *context;
+		void *stack_start = (void *)((unsigned long)stack & ~(THREAD_SIZE-1));
 
-		context = (struct thread_info *)
-			((unsigned long)stack & (~(THREAD_SIZE - 1)));
-		bp = ops->walk_stack(context, stack, bp, ops, data, NULL, &graph);
+		bp = ops->walk_stack(task, stack_start, stack, bp, ops, data, NULL, &graph);
 
-		stack = (unsigned long *)context->previous_esp;
-		if (!stack)
+		if (stack_start == task_stack_page(task))
 			break;
+		stack = *(unsigned long **)stack_start;
 		if (ops->stack(data, "IRQ") < 0)
 			break;
 		touch_nmi_watchdog();
@@ -96,21 +94,22 @@ void show_registers(struct pt_regs *regs
 	 * When in-kernel, we also print out the stack and code at the
 	 * time of the fault..
 	 */
-	if (!user_mode_vm(regs)) {
+	if (!user_mode(regs)) {
 		unsigned int code_prologue = code_bytes * 43 / 64;
 		unsigned int code_len = code_bytes;
 		unsigned char c;
 		u8 *ip;
+		unsigned long cs_base = get_desc_base(&get_cpu_gdt_table(0)[(0xffff & regs->cs) >> 3]);
 
 		printk(KERN_EMERG "Stack:\n");
 		show_stack_log_lvl(NULL, regs, &regs->sp, 0, KERN_EMERG);
 
 		printk(KERN_EMERG "Code: ");
 
-		ip = (u8 *)regs->ip - code_prologue;
+		ip = (u8 *)regs->ip - code_prologue + cs_base;
 		if (ip < (u8 *)PAGE_OFFSET || probe_kernel_address(ip, c)) {
 			/* try starting at IP */
-			ip = (u8 *)regs->ip;
+			ip = (u8 *)regs->ip + cs_base;
 			code_len = code_len - code_prologue + 1;
 		}
 		for (i = 0; i < code_len; i++, ip++) {
@@ -119,7 +118,7 @@ void show_registers(struct pt_regs *regs
 				printk(KERN_CONT " Bad EIP value.");
 				break;
 			}
-			if (ip == (u8 *)regs->ip)
+			if (ip == (u8 *)regs->ip + cs_base)
 				printk(KERN_CONT "<%02x> ", c);
 			else
 				printk(KERN_CONT "%02x ", c);
@@ -132,6 +131,7 @@ int is_valid_bugaddr(unsigned long ip)
 {
 	unsigned short ud2;
 
+	ip = ktla_ktva(ip);
 	if (ip < PAGE_OFFSET)
 		return 0;
 	if (probe_kernel_address((unsigned short *)ip, ud2))
@@ -139,3 +139,15 @@ int is_valid_bugaddr(unsigned long ip)
 
 	return ud2 == 0x0b0f;
 }
+
+#ifdef CONFIG_PAX_MEMORY_STACKLEAK
+void pax_check_alloca(unsigned long size)
+{
+	unsigned long sp = (unsigned long)&sp, stack_left;
+
+	/* all kernel stacks are of the same size */
+	stack_left = sp & (THREAD_SIZE - 1);
+	BUG_ON(stack_left < 256 || size >= stack_left - 256);
+}
+EXPORT_SYMBOL(pax_check_alloca);
+#endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/dumpstack_64.c linux-3.2.71-pax/arch/x86/kernel/dumpstack_64.c
--- linux-3.2.71/arch/x86/kernel/dumpstack_64.c	2014-12-14 21:13:44.978054661 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/dumpstack_64.c	2015-02-05 15:31:31.452192584 +0100
@@ -118,9 +118,9 @@ void dump_trace(struct task_struct *task
 	unsigned long *irq_stack_end =
 		(unsigned long *)per_cpu(irq_stack_ptr, cpu);
 	unsigned used = 0;
-	struct thread_info *tinfo;
 	int graph = 0;
 	unsigned long dummy;
+	void *stack_start;
 
 	if (!task)
 		task = current;
@@ -141,10 +141,10 @@ void dump_trace(struct task_struct *task
 	 * current stack address. If the stacks consist of nested
 	 * exceptions
 	 */
-	tinfo = task_thread_info(task);
 	for (;;) {
 		char *id;
 		unsigned long *estack_end;
+
 		estack_end = in_exception_stack(cpu, (unsigned long)stack,
 						&used, &id);
 
@@ -152,7 +152,7 @@ void dump_trace(struct task_struct *task
 			if (ops->stack(data, id) < 0)
 				break;
 
-			bp = ops->walk_stack(tinfo, stack, bp, ops,
+			bp = ops->walk_stack(task, estack_end - EXCEPTION_STKSZ, stack, bp, ops,
 					     data, estack_end, &graph);
 			ops->stack(data, "<EOE>");
 			/*
@@ -160,6 +160,8 @@ void dump_trace(struct task_struct *task
 			 * second-to-last pointer (index -2 to end) in the
 			 * exception stack:
 			 */
+			if ((u16)estack_end[-1] != __KERNEL_DS)
+				goto out;
 			stack = (unsigned long *) estack_end[-2];
 			continue;
 		}
@@ -171,7 +173,7 @@ void dump_trace(struct task_struct *task
 			if (in_irq_stack(stack, irq_stack, irq_stack_end)) {
 				if (ops->stack(data, "IRQ") < 0)
 					break;
-				bp = ops->walk_stack(tinfo, stack, bp,
+				bp = ops->walk_stack(task, irq_stack, stack, bp,
 					ops, data, irq_stack_end, &graph);
 				/*
 				 * We link to the next stack (which would be
@@ -190,7 +192,9 @@ void dump_trace(struct task_struct *task
 	/*
 	 * This handles the process stack:
 	 */
-	bp = ops->walk_stack(tinfo, stack, bp, ops, data, NULL, &graph);
+	stack_start = (void *)((unsigned long)stack & ~(THREAD_SIZE-1));
+	bp = ops->walk_stack(task, stack_start, stack, bp, ops, data, NULL, &graph);
+out:
 	put_cpu();
 }
 EXPORT_SYMBOL(dump_trace);
@@ -248,7 +252,7 @@ void show_registers(struct pt_regs *regs
 {
 	int i;
 	unsigned long sp;
-	const int cpu = smp_processor_id();
+	const int cpu = raw_smp_processor_id();
 	struct task_struct *cur = current;
 
 	sp = regs->sp;
@@ -299,8 +303,55 @@ int is_valid_bugaddr(unsigned long ip)
 {
 	unsigned short ud2;
 
-	if (__copy_from_user(&ud2, (const void __user *) ip, sizeof(ud2)))
+	if (probe_kernel_address((unsigned short *)ip, ud2))
 		return 0;
 
 	return ud2 == 0x0b0f;
 }
+
+#ifdef CONFIG_PAX_MEMORY_STACKLEAK
+void pax_check_alloca(unsigned long size)
+{
+	unsigned long sp = (unsigned long)&sp, stack_start, stack_end;
+	unsigned cpu, used;
+	char *id;
+
+	/* check the process stack first */
+	stack_start = (unsigned long)task_stack_page(current);
+	stack_end = stack_start + THREAD_SIZE;
+	if (likely(stack_start <= sp && sp < stack_end)) {
+		unsigned long stack_left = sp & (THREAD_SIZE - 1);
+		BUG_ON(stack_left < 256 || size >= stack_left - 256);
+		return;
+	}
+
+	cpu = get_cpu();
+
+	/* check the irq stacks */
+	stack_end = (unsigned long)per_cpu(irq_stack_ptr, cpu);
+	stack_start = stack_end - IRQ_STACK_SIZE;
+	if (stack_start <= sp && sp < stack_end) {
+		unsigned long stack_left = sp & (IRQ_STACK_SIZE - 1);
+		put_cpu();
+		BUG_ON(stack_left < 256 || size >= stack_left - 256);
+		return;
+	}
+
+	/* check the exception stacks */
+	used = 0;
+	stack_end = (unsigned long)in_exception_stack(cpu, sp, &used, &id);
+	stack_start = stack_end - EXCEPTION_STKSZ;
+	if (stack_end && stack_start <= sp && sp < stack_end) {
+		unsigned long stack_left = sp & (EXCEPTION_STKSZ - 1);
+		put_cpu();
+		BUG_ON(stack_left < 256 || size >= stack_left - 256);
+		return;
+	}
+
+	put_cpu();
+
+	/* unknown stack */
+	BUG();
+}
+EXPORT_SYMBOL(pax_check_alloca);
+#endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/dumpstack.c linux-3.2.71-pax/arch/x86/kernel/dumpstack.c
--- linux-3.2.71/arch/x86/kernel/dumpstack.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/dumpstack.c	2013-08-17 01:56:05.764231679 +0200
@@ -35,9 +35,8 @@ void printk_address(unsigned long addres
 static void
 print_ftrace_graph_addr(unsigned long addr, void *data,
 			const struct stacktrace_ops *ops,
-			struct thread_info *tinfo, int *graph)
+			struct task_struct *task, int *graph)
 {
-	struct task_struct *task = tinfo->task;
 	unsigned long ret_addr;
 	int index = task->curr_ret_stack;
 
@@ -58,7 +57,7 @@ print_ftrace_graph_addr(unsigned long ad
 static inline void
 print_ftrace_graph_addr(unsigned long addr, void *data,
 			const struct stacktrace_ops *ops,
-			struct thread_info *tinfo, int *graph)
+			struct task_struct *task, int *graph)
 { }
 #endif
 
@@ -69,10 +68,8 @@ print_ftrace_graph_addr(unsigned long ad
  * severe exception (double fault, nmi, stack fault, debug, mce) hardware stack
  */
 
-static inline int valid_stack_ptr(struct thread_info *tinfo,
-			void *p, unsigned int size, void *end)
+static inline int valid_stack_ptr(void *t, void *p, unsigned int size, void *end)
 {
-	void *t = tinfo;
 	if (end) {
 		if (p < end && p >= (end-THREAD_SIZE))
 			return 1;
@@ -83,14 +80,14 @@ static inline int valid_stack_ptr(struct
 }
 
 unsigned long
-print_context_stack(struct thread_info *tinfo,
+print_context_stack(struct task_struct *task, void *stack_start,
 		unsigned long *stack, unsigned long bp,
 		const struct stacktrace_ops *ops, void *data,
 		unsigned long *end, int *graph)
 {
 	struct stack_frame *frame = (struct stack_frame *)bp;
 
-	while (valid_stack_ptr(tinfo, stack, sizeof(*stack), end)) {
+	while (valid_stack_ptr(stack_start, stack, sizeof(*stack), end)) {
 		unsigned long addr;
 
 		addr = *stack;
@@ -102,7 +99,7 @@ print_context_stack(struct thread_info *
 			} else {
 				ops->address(data, addr, 0);
 			}
-			print_ftrace_graph_addr(addr, data, ops, tinfo, graph);
+			print_ftrace_graph_addr(addr, data, ops, task, graph);
 		}
 		stack++;
 	}
@@ -111,7 +108,7 @@ print_context_stack(struct thread_info *
 EXPORT_SYMBOL_GPL(print_context_stack);
 
 unsigned long
-print_context_stack_bp(struct thread_info *tinfo,
+print_context_stack_bp(struct task_struct *task, void *stack_start,
 		       unsigned long *stack, unsigned long bp,
 		       const struct stacktrace_ops *ops, void *data,
 		       unsigned long *end, int *graph)
@@ -119,7 +116,7 @@ print_context_stack_bp(struct thread_inf
 	struct stack_frame *frame = (struct stack_frame *)bp;
 	unsigned long *ret_addr = &frame->return_address;
 
-	while (valid_stack_ptr(tinfo, ret_addr, sizeof(*ret_addr), end)) {
+	while (valid_stack_ptr(stack_start, ret_addr, sizeof(*ret_addr), end)) {
 		unsigned long addr = *ret_addr;
 
 		if (!__kernel_text_address(addr))
@@ -128,7 +125,7 @@ print_context_stack_bp(struct thread_inf
 		ops->address(data, addr, 1);
 		frame = frame->next_frame;
 		ret_addr = &frame->return_address;
-		print_ftrace_graph_addr(addr, data, ops, tinfo, graph);
+		print_ftrace_graph_addr(addr, data, ops, task, graph);
 	}
 
 	return (unsigned long)frame;
@@ -147,7 +144,7 @@ static int print_trace_stack(void *data,
 static void print_trace_address(void *data, unsigned long addr, int reliable)
 {
 	touch_nmi_watchdog();
-	printk(data);
+	printk("%s", (char *)data);
 	printk_address(addr, reliable);
 }
 
@@ -186,7 +183,7 @@ void dump_stack(void)
 
 	bp = stack_frame(current, NULL);
 	printk("Pid: %d, comm: %.20s %s %s %.*s\n",
-		current->pid, current->comm, print_tainted(),
+		task_pid_nr(current), current->comm, print_tainted(),
 		init_utsname()->release,
 		(int)strcspn(init_utsname()->version, " "),
 		init_utsname()->version);
@@ -243,7 +240,7 @@ void __kprobes oops_end(unsigned long fl
 		panic("Fatal exception in interrupt");
 	if (panic_on_oops)
 		panic("Fatal exception");
-	do_exit(signr);
+	do_group_exit(signr);
 }
 
 int __kprobes __die(const char *str, struct pt_regs *regs, long err)
@@ -269,7 +266,7 @@ int __kprobes __die(const char *str, str
 
 	show_registers(regs);
 #ifdef CONFIG_X86_32
-	if (user_mode_vm(regs)) {
+	if (user_mode(regs)) {
 		sp = regs->sp;
 		ss = regs->ss & 0xffff;
 	} else {
@@ -297,7 +294,7 @@ void die(const char *str, struct pt_regs
 	unsigned long flags = oops_begin();
 	int sig = SIGSEGV;
 
-	if (!user_mode_vm(regs))
+	if (!user_mode(regs))
 		report_bug(regs->ip, regs);
 
 	if (__die(str, regs, err))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/e820.c linux-3.2.71-pax/arch/x86/kernel/e820.c
--- linux-3.2.71/arch/x86/kernel/e820.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/e820.c	2013-06-21 20:15:56.430564312 +0200
@@ -829,8 +829,8 @@ unsigned long __init e820_end_of_low_ram
 
 static void early_panic(char *msg)
 {
-	early_printk(msg);
-	panic(msg);
+	early_printk("%s", msg);
+	panic("%s", msg);
 }
 
 static int userdef __initdata;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/early_printk.c linux-3.2.71-pax/arch/x86/kernel/early_printk.c
--- linux-3.2.71/arch/x86/kernel/early_printk.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/early_printk.c	2012-07-04 19:24:47.568063004 +0200
@@ -7,6 +7,7 @@
 #include <linux/pci_regs.h>
 #include <linux/pci_ids.h>
 #include <linux/errno.h>
+#include <linux/sched.h>
 #include <asm/io.h>
 #include <asm/processor.h>
 #include <asm/fcntl.h>
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/entry_32.S linux-3.2.71-pax/arch/x86/kernel/entry_32.S
--- linux-3.2.71/arch/x86/kernel/entry_32.S	2014-09-14 14:10:58.062117231 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/entry_32.S	2015-02-05 15:43:41.740021440 +0100
@@ -180,13 +180,154 @@
 	/*CFI_REL_OFFSET gs, PT_GS*/
 .endm
 .macro SET_KERNEL_GS reg
+
+#ifdef CONFIG_CC_STACKPROTECTOR
 	movl $(__KERNEL_STACK_CANARY), \reg
+#elif defined(CONFIG_PAX_MEMORY_UDEREF)
+	movl $(__USER_DS), \reg
+#else
+	xorl \reg, \reg
+#endif
+
 	movl \reg, %gs
 .endm
 
 #endif	/* CONFIG_X86_32_LAZY_GS */
 
-.macro SAVE_ALL
+.macro pax_enter_kernel
+#ifdef CONFIG_PAX_KERNEXEC
+	call pax_enter_kernel
+#endif
+.endm
+
+.macro pax_exit_kernel
+#ifdef CONFIG_PAX_KERNEXEC
+	call pax_exit_kernel
+#endif
+.endm
+
+#ifdef CONFIG_PAX_KERNEXEC
+ENTRY(pax_enter_kernel)
+#ifdef CONFIG_PARAVIRT
+	pushl %eax
+	pushl %ecx
+	call PARA_INDIRECT(pv_cpu_ops+PV_CPU_read_cr0)
+	mov %eax, %esi
+#else
+	mov %cr0, %esi
+#endif
+	bts $16, %esi
+	jnc 1f
+	mov %cs, %esi
+	cmp $__KERNEL_CS, %esi
+	jz 3f
+	ljmp $__KERNEL_CS, $3f
+1:	ljmp $__KERNEXEC_KERNEL_CS, $2f
+2:
+#ifdef CONFIG_PARAVIRT
+	mov %esi, %eax
+	call PARA_INDIRECT(pv_cpu_ops+PV_CPU_write_cr0)
+#else
+	mov %esi, %cr0
+#endif
+3:
+#ifdef CONFIG_PARAVIRT
+	popl %ecx
+	popl %eax
+#endif
+	ret
+ENDPROC(pax_enter_kernel)
+
+ENTRY(pax_exit_kernel)
+#ifdef CONFIG_PARAVIRT
+	pushl %eax
+	pushl %ecx
+#endif
+	mov %cs, %esi
+	cmp $__KERNEXEC_KERNEL_CS, %esi
+	jnz 2f
+#ifdef CONFIG_PARAVIRT
+	call PARA_INDIRECT(pv_cpu_ops+PV_CPU_read_cr0);
+	mov %eax, %esi
+#else
+	mov %cr0, %esi
+#endif
+	btr $16, %esi
+	ljmp $__KERNEL_CS, $1f
+1:
+#ifdef CONFIG_PARAVIRT
+	mov %esi, %eax
+	call PARA_INDIRECT(pv_cpu_ops+PV_CPU_write_cr0);
+#else
+	mov %esi, %cr0
+#endif
+2:
+#ifdef CONFIG_PARAVIRT
+	popl %ecx
+	popl %eax
+#endif
+	ret
+ENDPROC(pax_exit_kernel)
+#endif
+
+.macro pax_erase_kstack
+#ifdef CONFIG_PAX_MEMORY_STACKLEAK
+	call pax_erase_kstack
+#endif
+.endm
+
+#ifdef CONFIG_PAX_MEMORY_STACKLEAK
+/*
+ * ebp: thread_info
+ */
+ENTRY(pax_erase_kstack)
+	pushl %edi
+	pushl %ecx
+	pushl %eax
+
+	mov TI_lowest_stack(%ebp), %edi
+	mov $0xB4DD00D5, %eax
+	std
+
+1:	mov %edi, %ecx
+	and $THREAD_SIZE_asm - 1, %ecx
+	shr $2, %ecx
+	repne scasl
+	jecxz 2f
+
+	cmp $2*16, %ecx
+	jc 2f
+
+	mov $2*16, %ecx
+	repe scasl
+	jecxz 2f
+	jne 1b
+
+2:	cld
+	or $2*4, %edi
+	mov %esp, %ecx
+	sub %edi, %ecx
+
+	cmp $THREAD_SIZE_asm, %ecx
+	jb 3f
+	ud2
+3:
+
+	shr $2, %ecx
+	rep stosl
+
+	mov TI_task_thread_sp0(%ebp), %edi
+	sub $128, %edi
+	mov %edi, TI_lowest_stack(%ebp)
+
+	popl %eax
+	popl %ecx
+	popl %edi
+	ret
+ENDPROC(pax_erase_kstack)
+#endif
+
+.macro __SAVE_ALL _DS
 	cld
 	PUSH_GS
 	pushl_cfi %fs
@@ -209,7 +350,7 @@
 	CFI_REL_OFFSET ecx, 0
 	pushl_cfi %ebx
 	CFI_REL_OFFSET ebx, 0
-	movl $(__USER_DS), %edx
+	movl $\_DS, %edx
 	movl %edx, %ds
 	movl %edx, %es
 	movl $(__KERNEL_PERCPU), %edx
@@ -217,6 +358,15 @@
 	SET_KERNEL_GS %edx
 .endm
 
+.macro SAVE_ALL
+#if defined(CONFIG_PAX_KERNEXEC) || defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC) || defined(CONFIG_PAX_MEMORY_UDEREF)
+	__SAVE_ALL __KERNEL_DS
+	pax_enter_kernel
+#else
+	__SAVE_ALL __USER_DS
+#endif
+.endm
+
 .macro RESTORE_INT_REGS
 	popl_cfi %ebx
 	CFI_RESTORE ebx
@@ -302,7 +452,7 @@ ENTRY(ret_from_fork)
 	popfl_cfi
 	jmp syscall_exit
 	CFI_ENDPROC
-END(ret_from_fork)
+ENDPROC(ret_from_fork)
 
 /*
  * Interrupt exit functions should be protected against kprobes
@@ -336,7 +486,15 @@ resume_userspace_sig:
 	andl $SEGMENT_RPL_MASK, %eax
 #endif
 	cmpl $USER_RPL, %eax
+
+#ifdef CONFIG_PAX_KERNEXEC
+	jae resume_userspace
+
+	pax_exit_kernel
+	jmp resume_kernel
+#else
 	jb resume_kernel		# not returning to v8086 or userspace
+#endif
 
 ENTRY(resume_userspace)
 	LOCKDEP_SYS_EXIT
@@ -348,8 +506,8 @@ ENTRY(resume_userspace)
 	andl $_TIF_WORK_MASK, %ecx	# is there any work to be done on
 					# int/exception return?
 	jne work_pending
-	jmp restore_all
-END(ret_from_exception)
+	jmp restore_all_pax
+ENDPROC(ret_from_exception)
 
 #ifdef CONFIG_PREEMPT
 ENTRY(resume_kernel)
@@ -364,7 +522,7 @@ need_resched:
 	jz restore_all
 	call preempt_schedule_irq
 	jmp need_resched
-END(resume_kernel)
+ENDPROC(resume_kernel)
 #endif
 	CFI_ENDPROC
 /*
@@ -398,23 +556,34 @@ sysenter_past_esp:
 	/*CFI_REL_OFFSET cs, 0*/
 	/*
 	 * Push current_thread_info()->sysenter_return to the stack.
-	 * A tiny bit of offset fixup is necessary - 4*4 means the 4 words
-	 * pushed above; +8 corresponds to copy_thread's esp0 setting.
 	 */
-	pushl_cfi ((TI_sysenter_return)-THREAD_SIZE+8+4*4)(%esp)
+	pushl_cfi $0
 	CFI_REL_OFFSET eip, 0
 
 	pushl_cfi %eax
 	SAVE_ALL
+	GET_THREAD_INFO(%ebp)
+	movl TI_sysenter_return(%ebp),%ebp
+	movl %ebp,PT_EIP(%esp)
 	ENABLE_INTERRUPTS(CLBR_NONE)
 
 /*
  * Load the potential sixth argument from user stack.
  * Careful about security.
  */
+	movl PT_OLDESP(%esp),%ebp
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	mov PT_OLDSS(%esp),%ds
+1:	movl %ds:(%ebp),%ebp
+	push %ss
+	pop %ds
+#else
 	cmpl $__PAGE_OFFSET-3,%ebp
 	jae syscall_fault
 1:	movl (%ebp),%ebp
+#endif
+
 	movl %ebp,PT_EBP(%esp)
 .section __ex_table,"a"
 	.align 4
@@ -423,6 +592,10 @@ sysenter_past_esp:
 
 	GET_THREAD_INFO(%ebp)
 
+#ifdef CONFIG_PAX_RANDKSTACK
+	pax_erase_kstack
+#endif
+
 	testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%ebp)
 	jnz sysenter_audit
 sysenter_do_call:
@@ -438,12 +611,24 @@ sysenter_after_call:
 	testl $_TIF_ALLWORK_MASK, %ecx
 	jne sysexit_audit
 sysenter_exit:
+
+#ifdef CONFIG_PAX_RANDKSTACK
+	pushl_cfi %eax
+	movl %esp, %eax
+	call pax_randomize_kstack
+	popl_cfi %eax
+#endif
+
+	pax_erase_kstack
+
 /* if something modifies registers it must also disable sysexit */
 	movl PT_EIP(%esp), %edx
 	movl PT_OLDESP(%esp), %ecx
 	xorl %ebp,%ebp
 	TRACE_IRQS_ON
 1:	mov  PT_FS(%esp), %fs
+2:	mov  PT_DS(%esp), %ds
+3:	mov  PT_ES(%esp), %es
 	PTGS_TO_GS
 	ENABLE_INTERRUPTS_SYSEXIT
 
@@ -460,6 +645,9 @@ sysenter_audit:
 	movl %eax,%edx			/* 2nd arg: syscall number */
 	movl $AUDIT_ARCH_I386,%eax	/* 1st arg: audit arch */
 	call audit_syscall_entry
+
+	pax_erase_kstack
+
 	pushl_cfi %ebx
 	movl PT_EAX(%esp),%eax		/* reload syscall number */
 	jmp sysenter_do_call
@@ -486,11 +674,17 @@ sysexit_audit:
 
 	CFI_ENDPROC
 .pushsection .fixup,"ax"
-2:	movl $0,PT_FS(%esp)
+4:	movl $0,PT_FS(%esp)
+	jmp 1b
+5:	movl $0,PT_DS(%esp)
+	jmp 1b
+6:	movl $0,PT_ES(%esp)
 	jmp 1b
 .section __ex_table,"a"
 	.align 4
-	.long 1b,2b
+	.long 1b,4b
+	.long 2b,5b
+	.long 3b,6b
 .popsection
 	PTGS_TO_GS_EX
 ENDPROC(ia32_sysenter_target)
@@ -505,6 +699,11 @@ ENTRY(system_call)
 	pushl_cfi %eax			# save orig_eax
 	SAVE_ALL
 	GET_THREAD_INFO(%ebp)
+
+#ifdef CONFIG_PAX_RANDKSTACK
+	pax_erase_kstack
+#endif
+
 					# system call tracing in operation / emulation
 	testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%ebp)
 	jnz syscall_trace_entry
@@ -524,6 +723,15 @@ syscall_exit:
 	testl $_TIF_ALLWORK_MASK, %ecx	# current->work
 	jne syscall_exit_work
 
+restore_all_pax:
+
+#ifdef CONFIG_PAX_RANDKSTACK
+	movl %esp, %eax
+	call pax_randomize_kstack
+#endif
+
+	pax_erase_kstack
+
 restore_all:
 	TRACE_IRQS_IRET
 restore_all_notrace:
@@ -581,14 +789,34 @@ ldt_ss:
  * compensating for the offset by changing to the ESPFIX segment with
  * a base address that matches for the difference.
  */
-#define GDT_ESPFIX_SS PER_CPU_VAR(gdt_page) + (GDT_ENTRY_ESPFIX_SS * 8)
+#define GDT_ESPFIX_SS (GDT_ENTRY_ESPFIX_SS * 8)(%ebx)
 	mov %esp, %edx			/* load kernel esp */
 	mov PT_OLDESP(%esp), %eax	/* load userspace esp */
 	mov %dx, %ax			/* eax: new kernel esp */
 	sub %eax, %edx			/* offset (low word is 0) */
+#ifdef CONFIG_SMP
+	movl PER_CPU_VAR(cpu_number), %ebx
+	shll $PAGE_SHIFT_asm, %ebx
+	addl $cpu_gdt_table, %ebx
+#else
+	movl $cpu_gdt_table, %ebx
+#endif
 	shr $16, %edx
-	mov %dl, GDT_ESPFIX_SS + 4 /* bits 16..23 */
-	mov %dh, GDT_ESPFIX_SS + 7 /* bits 24..31 */
+
+#ifdef CONFIG_PAX_KERNEXEC
+	mov %cr0, %esi
+	btr $16, %esi
+	mov %esi, %cr0
+#endif
+
+	mov %dl, 4 + GDT_ESPFIX_SS /* bits 16..23 */
+	mov %dh, 7 + GDT_ESPFIX_SS /* bits 24..31 */
+
+#ifdef CONFIG_PAX_KERNEXEC
+	bts $16, %esi
+	mov %esi, %cr0
+#endif
+
 	pushl_cfi $__ESPFIX_SS
 	pushl_cfi %eax			/* new kernel esp */
 	/* Disable interrupts, but do not irqtrace this section: we
@@ -618,34 +846,28 @@ work_resched:
 	movl TI_flags(%ebp), %ecx
 	andl $_TIF_WORK_MASK, %ecx	# is there any work to be done other
 					# than syscall tracing?
-	jz restore_all
+	jz restore_all_pax
 	testb $_TIF_NEED_RESCHED, %cl
 	jnz work_resched
 
 work_notifysig:				# deal with pending signals and
 					# notify-resume requests
+	movl %esp, %eax
 #ifdef CONFIG_VM86
 	testl $X86_EFLAGS_VM, PT_EFLAGS(%esp)
-	movl %esp, %eax
-	jne work_notifysig_v86		# returning to kernel-space or
+	jz 1f				# returning to kernel-space or
 					# vm86-space
-	xorl %edx, %edx
-	call do_notify_resume
-	jmp resume_userspace_sig
 
-	ALIGN
-work_notifysig_v86:
 	pushl_cfi %ecx			# save ti_flags for do_notify_resume
 	call save_v86_state		# %eax contains pt_regs pointer
 	popl_cfi %ecx
 	movl %eax, %esp
-#else
-	movl %esp, %eax
+1:
 #endif
 	xorl %edx, %edx
 	call do_notify_resume
 	jmp resume_userspace_sig
-END(work_pending)
+ENDPROC(work_pending)
 
 	# perform syscall exit tracing
 	ALIGN
@@ -653,11 +875,14 @@ syscall_trace_entry:
 	movl $-ENOSYS,PT_EAX(%esp)
 	movl %esp, %eax
 	call syscall_trace_enter
+
+	pax_erase_kstack
+
 	/* What it returned is what we'll actually use.  */
 	cmpl $(nr_syscalls), %eax
 	jnae syscall_call
 	jmp syscall_exit
-END(syscall_trace_entry)
+ENDPROC(syscall_trace_entry)
 
 	# perform syscall exit tracing
 	ALIGN
@@ -670,25 +895,29 @@ syscall_exit_work:
 	movl %esp, %eax
 	call syscall_trace_leave
 	jmp resume_userspace
-END(syscall_exit_work)
+ENDPROC(syscall_exit_work)
 	CFI_ENDPROC
 
 	RING0_INT_FRAME			# can't unwind into user space anyway
 syscall_fault:
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	push %ss
+	pop %ds
+#endif
 	GET_THREAD_INFO(%ebp)
 	movl $-EFAULT,PT_EAX(%esp)
 	jmp resume_userspace
-END(syscall_fault)
+ENDPROC(syscall_fault)
 
 syscall_badsys:
 	movl $-ENOSYS,%eax
 	jmp syscall_after_call
-END(syscall_badsys)
+ENDPROC(syscall_badsys)
 
 sysenter_badsys:
 	movl $-ENOSYS,%eax
 	jmp sysenter_after_call
-END(syscall_badsys)
+ENDPROC(sysenter_badsys)
 	CFI_ENDPROC
 /*
  * End of kprobes section
@@ -762,6 +991,36 @@ ptregs_clone:
 	CFI_ENDPROC
 ENDPROC(ptregs_clone)
 
+	ALIGN;
+ENTRY(kernel_execve)
+	CFI_STARTPROC
+	pushl_cfi %ebp
+	sub $PT_OLDSS+4,%esp
+	pushl_cfi %edi
+	pushl_cfi %ecx
+	pushl_cfi %eax
+	lea 3*4(%esp),%edi
+	mov $PT_OLDSS/4+1,%ecx
+	xorl %eax,%eax
+	rep stosl
+	popl_cfi %eax
+	popl_cfi %ecx
+	popl_cfi %edi
+	movl $X86_EFLAGS_IF,PT_EFLAGS(%esp)
+	pushl_cfi %esp
+	call sys_execve
+	add $4,%esp
+	CFI_ADJUST_CFA_OFFSET -4
+	GET_THREAD_INFO(%ebp)
+	test %eax,%eax
+	jz syscall_exit
+	add $PT_OLDSS+4,%esp
+	CFI_ADJUST_CFA_OFFSET -PT_OLDSS-4
+	popl_cfi %ebp
+	ret
+	CFI_ENDPROC
+ENDPROC(kernel_execve)
+
 .macro FIXUP_ESPFIX_STACK
 /*
  * Switch back for ESPFIX stack to the normal zerobased stack
@@ -772,8 +1031,15 @@ ENDPROC(ptregs_clone)
  */
 #ifdef CONFIG_X86_ESPFIX32
 	/* fixup the stack */
-	mov GDT_ESPFIX_SS + 4, %al /* bits 16..23 */
-	mov GDT_ESPFIX_SS + 7, %ah /* bits 24..31 */
+#ifdef CONFIG_SMP
+	movl PER_CPU_VAR(cpu_number), %ebx
+	shll $PAGE_SHIFT_asm, %ebx
+	addl $cpu_gdt_table, %ebx
+#else
+	movl $cpu_gdt_table, %ebx
+#endif
+	mov 4 + GDT_ESPFIX_SS, %al /* bits 16..23 */
+	mov 7 + GDT_ESPFIX_SS, %ah /* bits 24..31 */
 	shl $16, %eax
 	addl %esp, %eax			/* the adjusted stack pointer */
 	pushl_cfi $__KERNEL_DS
@@ -829,7 +1095,7 @@ vector=vector+1
   .endr
 2:	jmp common_interrupt
 .endr
-END(irq_entries_start)
+ENDPROC(irq_entries_start)
 
 .previous
 END(interrupt)
@@ -877,7 +1143,7 @@ ENTRY(coprocessor_error)
 	pushl_cfi $do_coprocessor_error
 	jmp error_code
 	CFI_ENDPROC
-END(coprocessor_error)
+ENDPROC(coprocessor_error)
 
 ENTRY(simd_coprocessor_error)
 	RING0_INT_FRAME
@@ -898,7 +1164,7 @@ ENTRY(simd_coprocessor_error)
 #endif
 	jmp error_code
 	CFI_ENDPROC
-END(simd_coprocessor_error)
+ENDPROC(simd_coprocessor_error)
 
 ENTRY(device_not_available)
 	RING0_INT_FRAME
@@ -906,7 +1172,7 @@ ENTRY(device_not_available)
 	pushl_cfi $do_device_not_available
 	jmp error_code
 	CFI_ENDPROC
-END(device_not_available)
+ENDPROC(device_not_available)
 
 #ifdef CONFIG_PARAVIRT
 ENTRY(native_iret)
@@ -915,12 +1181,12 @@ ENTRY(native_iret)
 	.align 4
 	.long native_iret, iret_exc
 .previous
-END(native_iret)
+ENDPROC(native_iret)
 
 ENTRY(native_irq_enable_sysexit)
 	sti
 	sysexit
-END(native_irq_enable_sysexit)
+ENDPROC(native_irq_enable_sysexit)
 #endif
 
 ENTRY(overflow)
@@ -929,7 +1195,7 @@ ENTRY(overflow)
 	pushl_cfi $do_overflow
 	jmp error_code
 	CFI_ENDPROC
-END(overflow)
+ENDPROC(overflow)
 
 ENTRY(bounds)
 	RING0_INT_FRAME
@@ -937,7 +1203,7 @@ ENTRY(bounds)
 	pushl_cfi $do_bounds
 	jmp error_code
 	CFI_ENDPROC
-END(bounds)
+ENDPROC(bounds)
 
 ENTRY(invalid_op)
 	RING0_INT_FRAME
@@ -945,7 +1211,7 @@ ENTRY(invalid_op)
 	pushl_cfi $do_invalid_op
 	jmp error_code
 	CFI_ENDPROC
-END(invalid_op)
+ENDPROC(invalid_op)
 
 ENTRY(coprocessor_segment_overrun)
 	RING0_INT_FRAME
@@ -953,35 +1219,35 @@ ENTRY(coprocessor_segment_overrun)
 	pushl_cfi $do_coprocessor_segment_overrun
 	jmp error_code
 	CFI_ENDPROC
-END(coprocessor_segment_overrun)
+ENDPROC(coprocessor_segment_overrun)
 
 ENTRY(invalid_TSS)
 	RING0_EC_FRAME
 	pushl_cfi $do_invalid_TSS
 	jmp error_code
 	CFI_ENDPROC
-END(invalid_TSS)
+ENDPROC(invalid_TSS)
 
 ENTRY(segment_not_present)
 	RING0_EC_FRAME
 	pushl_cfi $do_segment_not_present
 	jmp error_code
 	CFI_ENDPROC
-END(segment_not_present)
+ENDPROC(segment_not_present)
 
 ENTRY(stack_segment)
 	RING0_EC_FRAME
 	pushl_cfi $do_stack_segment
 	jmp error_code
 	CFI_ENDPROC
-END(stack_segment)
+ENDPROC(stack_segment)
 
 ENTRY(alignment_check)
 	RING0_EC_FRAME
 	pushl_cfi $do_alignment_check
 	jmp error_code
 	CFI_ENDPROC
-END(alignment_check)
+ENDPROC(alignment_check)
 
 ENTRY(divide_error)
 	RING0_INT_FRAME
@@ -989,7 +1255,7 @@ ENTRY(divide_error)
 	pushl_cfi $do_divide_error
 	jmp error_code
 	CFI_ENDPROC
-END(divide_error)
+ENDPROC(divide_error)
 
 #ifdef CONFIG_X86_MCE
 ENTRY(machine_check)
@@ -998,7 +1264,7 @@ ENTRY(machine_check)
 	pushl_cfi machine_check_vector
 	jmp error_code
 	CFI_ENDPROC
-END(machine_check)
+ENDPROC(machine_check)
 #endif
 
 ENTRY(spurious_interrupt_bug)
@@ -1007,7 +1273,7 @@ ENTRY(spurious_interrupt_bug)
 	pushl_cfi $do_spurious_interrupt_bug
 	jmp error_code
 	CFI_ENDPROC
-END(spurious_interrupt_bug)
+ENDPROC(spurious_interrupt_bug)
 /*
  * End of kprobes section
  */
@@ -1123,7 +1389,7 @@ BUILD_INTERRUPT3(xen_hvm_callback_vector
 
 ENTRY(mcount)
 	ret
-END(mcount)
+ENDPROC(mcount)
 
 ENTRY(ftrace_caller)
 	cmpl $0, function_trace_stop
@@ -1152,7 +1418,7 @@ ftrace_graph_call:
 .globl ftrace_stub
 ftrace_stub:
 	ret
-END(ftrace_caller)
+ENDPROC(ftrace_caller)
 
 #else /* ! CONFIG_DYNAMIC_FTRACE */
 
@@ -1188,7 +1454,7 @@ trace:
 	popl %ecx
 	popl %eax
 	jmp ftrace_stub
-END(mcount)
+ENDPROC(mcount)
 #endif /* CONFIG_DYNAMIC_FTRACE */
 #endif /* CONFIG_FUNCTION_TRACER */
 
@@ -1209,7 +1475,7 @@ ENTRY(ftrace_graph_caller)
 	popl %ecx
 	popl %eax
 	ret
-END(ftrace_graph_caller)
+ENDPROC(ftrace_graph_caller)
 
 .globl return_to_handler
 return_to_handler:
@@ -1223,7 +1489,6 @@ return_to_handler:
 	jmp *%ecx
 #endif
 
-.section .rodata,"a"
 #include "syscall_table_32.S"
 
 syscall_table_size=(.-sys_call_table)
@@ -1269,15 +1534,18 @@ error_code:
 	movl $-1, PT_ORIG_EAX(%esp)	# no syscall to restart
 	REG_TO_PTGS %ecx
 	SET_KERNEL_GS %ecx
-	movl $(__USER_DS), %ecx
+	movl $(__KERNEL_DS), %ecx
 	movl %ecx, %ds
 	movl %ecx, %es
+
+	pax_enter_kernel
+
 	TRACE_IRQS_OFF
 	movl %esp,%eax			# pt_regs pointer
 	call *%edi
 	jmp ret_from_exception
 	CFI_ENDPROC
-END(page_fault)
+ENDPROC(page_fault)
 
 /*
  * Debug traps and NMI can happen at the one SYSENTER instruction
@@ -1319,7 +1587,7 @@ debug_stack_correct:
 	call do_debug
 	jmp ret_from_exception
 	CFI_ENDPROC
-END(debug)
+ENDPROC(debug)
 
 /*
  * NMI is doubly nasty. It can happen _while_ we're handling
@@ -1358,6 +1626,9 @@ nmi_stack_correct:
 	xorl %edx,%edx		# zero error code
 	movl %esp,%eax		# pt_regs pointer
 	call do_nmi
+
+	pax_exit_kernel
+
 	jmp restore_all_notrace
 	CFI_ENDPROC
 
@@ -1395,13 +1666,16 @@ nmi_espfix_stack:
 	FIXUP_ESPFIX_STACK		# %eax == %esp
 	xorl %edx,%edx			# zero error code
 	call do_nmi
+
+	pax_exit_kernel
+
 	RESTORE_REGS
 	lss 12+4(%esp), %esp		# back to espfix stack
 	CFI_ADJUST_CFA_OFFSET -24
 	jmp irq_return
 #endif
 	CFI_ENDPROC
-END(nmi)
+ENDPROC(nmi)
 
 ENTRY(int3)
 	RING0_INT_FRAME
@@ -1413,14 +1687,14 @@ ENTRY(int3)
 	call do_int3
 	jmp ret_from_exception
 	CFI_ENDPROC
-END(int3)
+ENDPROC(int3)
 
 ENTRY(general_protection)
 	RING0_EC_FRAME
 	pushl_cfi $do_general_protection
 	jmp error_code
 	CFI_ENDPROC
-END(general_protection)
+ENDPROC(general_protection)
 
 #ifdef CONFIG_KVM_GUEST
 ENTRY(async_page_fault)
@@ -1428,7 +1702,7 @@ ENTRY(async_page_fault)
 	pushl_cfi $do_async_page_fault
 	jmp error_code
 	CFI_ENDPROC
-END(async_page_fault)
+ENDPROC(async_page_fault)
 #endif
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/entry_64.S linux-3.2.71-pax/arch/x86/kernel/entry_64.S
--- linux-3.2.71/arch/x86/kernel/entry_64.S	2015-05-10 09:22:36.671493009 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/entry_64.S	2015-05-10 09:24:00.651497570 +0200
@@ -56,6 +56,8 @@
 #include <asm/ftrace.h>
 #include <asm/percpu.h>
 #include <asm/pgtable_types.h>
+#include <asm/pgtable.h>
+#include <asm/alternative-asm.h>
 
 /* Avoid __ASSEMBLER__'ifying <linux/audit.h> just for this.  */
 #include <linux/elf-em.h>
@@ -69,8 +71,9 @@
 #ifdef CONFIG_FUNCTION_TRACER
 #ifdef CONFIG_DYNAMIC_FTRACE
 ENTRY(mcount)
+	pax_force_retaddr
 	retq
-END(mcount)
+ENDPROC(mcount)
 
 ENTRY(ftrace_caller)
 	cmpl $0, function_trace_stop
@@ -93,8 +96,9 @@ GLOBAL(ftrace_graph_call)
 #endif
 
 GLOBAL(ftrace_stub)
+	pax_force_retaddr
 	retq
-END(ftrace_caller)
+ENDPROC(ftrace_caller)
 
 #else /* ! CONFIG_DYNAMIC_FTRACE */
 ENTRY(mcount)
@@ -113,6 +117,7 @@ ENTRY(mcount)
 #endif
 
 GLOBAL(ftrace_stub)
+	pax_force_retaddr
 	retq
 
 trace:
@@ -122,12 +127,13 @@ trace:
 	movq 8(%rbp), %rsi
 	subq $MCOUNT_INSN_SIZE, %rdi
 
+	pax_force_fptr ftrace_trace_function
 	call   *ftrace_trace_function
 
 	MCOUNT_RESTORE_FRAME
 
 	jmp ftrace_stub
-END(mcount)
+ENDPROC(mcount)
 #endif /* CONFIG_DYNAMIC_FTRACE */
 #endif /* CONFIG_FUNCTION_TRACER */
 
@@ -147,8 +153,9 @@ ENTRY(ftrace_graph_caller)
 
 	MCOUNT_RESTORE_FRAME
 
+	pax_force_retaddr
 	retq
-END(ftrace_graph_caller)
+ENDPROC(ftrace_graph_caller)
 
 GLOBAL(return_to_handler)
 	subq  $24, %rsp
@@ -164,6 +171,7 @@ GLOBAL(return_to_handler)
 	movq 8(%rsp), %rdx
 	movq (%rsp), %rax
 	addq $24, %rsp
+	pax_force_fptr %rdi
 	jmp *%rdi
 #endif
 
@@ -179,6 +187,286 @@ ENTRY(native_usergs_sysret64)
 ENDPROC(native_usergs_sysret64)
 #endif /* CONFIG_PARAVIRT */
 
+	.macro ljmpq sel, off
+#if defined(CONFIG_MPSC) || defined(CONFIG_MCORE2) || defined (CONFIG_MATOM)
+	.byte 0x48; ljmp *1234f(%rip)
+	.pushsection .rodata
+	.align 16
+	1234: .quad \off; .word \sel
+	.popsection
+#else
+	pushq $\sel
+	pushq $\off
+	lretq
+#endif
+	.endm
+
+	.macro pax_enter_kernel
+	pax_set_fptr_mask
+#ifdef CONFIG_PAX_KERNEXEC
+	call pax_enter_kernel
+#endif
+	.endm
+
+	.macro pax_exit_kernel
+#ifdef CONFIG_PAX_KERNEXEC
+	call pax_exit_kernel
+#endif
+	.endm
+
+#ifdef CONFIG_PAX_KERNEXEC
+ENTRY(pax_enter_kernel)
+	pushq %rdi
+
+#ifdef CONFIG_PARAVIRT
+	PV_SAVE_REGS(CLBR_RDI)
+#endif
+
+	GET_CR0_INTO_RDI
+	bts $16,%rdi
+	jnc 3f
+	mov %cs,%edi
+	cmp $__KERNEL_CS,%edi
+	jnz 2f
+1:
+
+#ifdef CONFIG_PARAVIRT
+	PV_RESTORE_REGS(CLBR_RDI)
+#endif
+
+	popq %rdi
+	pax_force_retaddr
+	retq
+
+2:	ljmpq __KERNEL_CS,1b
+3:	ljmpq __KERNEXEC_KERNEL_CS,4f
+4:	SET_RDI_INTO_CR0
+	jmp 1b
+ENDPROC(pax_enter_kernel)
+
+ENTRY(pax_exit_kernel)
+	pushq %rdi
+
+#ifdef CONFIG_PARAVIRT
+	PV_SAVE_REGS(CLBR_RDI)
+#endif
+
+	mov %cs,%rdi
+	cmp $__KERNEXEC_KERNEL_CS,%edi
+	jz 2f
+	GET_CR0_INTO_RDI
+	bts $16,%rdi
+	jnc 4f
+1:
+
+#ifdef CONFIG_PARAVIRT
+	PV_RESTORE_REGS(CLBR_RDI);
+#endif
+
+	popq %rdi
+	pax_force_retaddr
+	retq
+
+2:	GET_CR0_INTO_RDI
+	btr $16,%rdi
+	jnc 4f
+	ljmpq __KERNEL_CS,3f
+3:	SET_RDI_INTO_CR0
+	jmp 1b
+4:	ud2
+	jmp 4b
+ENDPROC(pax_exit_kernel)
+#endif
+
+	.macro pax_enter_kernel_user
+	pax_set_fptr_mask
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	call pax_enter_kernel_user
+#endif
+	.endm
+
+	.macro pax_exit_kernel_user
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	call pax_exit_kernel_user
+#endif
+#ifdef CONFIG_PAX_RANDKSTACK
+	pushq %rax
+	pushq %r11
+	call pax_randomize_kstack
+	popq %r11
+	popq %rax
+#endif
+	.endm
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+ENTRY(pax_enter_kernel_user)
+	pushq %rdi
+	pushq %rbx
+
+#ifdef CONFIG_PARAVIRT
+	PV_SAVE_REGS(CLBR_RDI)
+#endif
+
+	GET_CR3_INTO_RDI
+	mov %rdi,%rbx
+	add $__START_KERNEL_map,%rbx
+	sub phys_base(%rip),%rbx
+
+#ifdef CONFIG_PARAVIRT
+	cmpl $0, pv_info+PARAVIRT_enabled
+	jz 1f
+	pushq %rdi
+	i = 0
+	.rept USER_PGD_PTRS
+	mov i*8(%rbx),%rsi
+	mov $0,%sil
+	lea i*8(%rbx),%rdi
+	call PARA_INDIRECT(pv_mmu_ops+PV_MMU_set_pgd_batched)
+	i = i + 1
+	.endr
+	popq %rdi
+	jmp 2f
+1:
+#endif
+
+	i = 0
+	.rept USER_PGD_PTRS
+	movb $0,i*8(%rbx)
+	i = i + 1
+	.endr
+
+#ifdef CONFIG_PARAVIRT
+2:
+#endif
+	SET_RDI_INTO_CR3
+
+#ifdef CONFIG_PAX_KERNEXEC
+	GET_CR0_INTO_RDI
+	bts $16,%rdi
+	SET_RDI_INTO_CR0
+#endif
+
+#ifdef CONFIG_PARAVIRT
+	PV_RESTORE_REGS(CLBR_RDI)
+#endif
+
+	popq %rbx
+	popq %rdi
+	pax_force_retaddr
+	retq
+ENDPROC(pax_enter_kernel_user)
+
+ENTRY(pax_exit_kernel_user)
+	pushq %rdi
+	pushq %rbx
+
+#ifdef CONFIG_PARAVIRT
+	PV_SAVE_REGS(CLBR_RDI)
+#endif
+
+#ifdef CONFIG_PAX_KERNEXEC
+	GET_CR0_INTO_RDI
+	btr $16,%rdi
+	jnc 3f
+	SET_RDI_INTO_CR0
+#endif
+
+	GET_CR3_INTO_RDI
+	mov %rdi,%rbx
+	add $__START_KERNEL_map,%rbx
+	sub phys_base(%rip),%rbx
+
+#ifdef CONFIG_PARAVIRT
+	cmpl $0, pv_info+PARAVIRT_enabled
+	jz 1f
+	i = 0
+	.rept USER_PGD_PTRS
+	mov i*8(%rbx),%rsi
+	mov $0x67,%sil
+	lea i*8(%rbx),%rdi
+	call PARA_INDIRECT(pv_mmu_ops+PV_MMU_set_pgd_batched)
+	i = i + 1
+	.endr
+	jmp 2f
+1:
+#endif
+
+	i = 0
+	.rept USER_PGD_PTRS
+	movb $0x67,i*8(%rbx)
+	i = i + 1
+	.endr
+
+#ifdef CONFIG_PARAVIRT
+2:	PV_RESTORE_REGS(CLBR_RDI)
+#endif
+
+	popq %rbx
+	popq %rdi
+	pax_force_retaddr
+	retq
+3:	ud2
+	jmp 3b
+ENDPROC(pax_exit_kernel_user)
+#endif
+
+.macro pax_erase_kstack
+#ifdef CONFIG_PAX_MEMORY_STACKLEAK
+	call pax_erase_kstack
+#endif
+.endm
+
+#ifdef CONFIG_PAX_MEMORY_STACKLEAK
+ENTRY(pax_erase_kstack)
+	pushq %rdi
+	pushq %rcx
+	pushq %rax
+	pushq %r11
+
+	GET_THREAD_INFO(%r11)
+	mov TI_lowest_stack(%r11), %rdi
+	mov $0xB4DD00D5BADBABE5, %rax
+	std
+
+1:	mov %edi, %ecx
+	and $THREAD_SIZE_asm - 1, %ecx
+	shr $3, %ecx
+	repne scasq
+	jecxz 2f
+
+	cmp $2*8, %ecx
+	jc 2f
+
+	mov $2*8, %ecx
+	repe scasq
+	jecxz 2f
+	jne 1b
+
+2:	cld
+	or $2*8, %rdi
+	mov %esp, %ecx
+	sub %edi, %ecx
+
+	cmp $THREAD_SIZE_asm, %rcx
+	jb 3f
+	ud2
+3:
+
+	shr $3, %ecx
+	rep stosq
+
+	mov TI_task_thread_sp0(%r11), %rdi
+	sub $256, %rdi
+	mov %rdi, TI_lowest_stack(%r11)
+
+	popq %r11
+	popq %rax
+	popq %rcx
+	popq %rdi
+	pax_force_retaddr
+	ret
+ENDPROC(pax_erase_kstack)
+#endif
 
 .macro TRACE_IRQS_IRETQ offset=ARGOFFSET
 #ifdef CONFIG_TRACE_IRQFLAGS
@@ -232,8 +520,8 @@ ENDPROC(native_usergs_sysret64)
 	.endm
 
 	.macro UNFAKE_STACK_FRAME
-	addq $8*6, %rsp
-	CFI_ADJUST_CFA_OFFSET	-(6*8)
+	addq $8*6 + ARG_SKIP, %rsp
+	CFI_ADJUST_CFA_OFFSET	-(6*8 + ARG_SKIP)
 	.endm
 
 /*
@@ -302,25 +590,26 @@ ENDPROC(native_usergs_sysret64)
 /* save partial stack frame */
 	.macro SAVE_ARGS_IRQ
 	cld
-	/* start from rbp in pt_regs and jump over */
-	movq_cfi rdi, RDI-RBP
-	movq_cfi rsi, RSI-RBP
-	movq_cfi rdx, RDX-RBP
-	movq_cfi rcx, RCX-RBP
-	movq_cfi rax, RAX-RBP
-	movq_cfi  r8,  R8-RBP
-	movq_cfi  r9,  R9-RBP
-	movq_cfi r10, R10-RBP
-	movq_cfi r11, R11-RBP
+	/* start from r15 in pt_regs and jump over */
+	movq_cfi rdi, RDI
+	movq_cfi rsi, RSI
+	movq_cfi rdx, RDX
+	movq_cfi rcx, RCX
+	movq_cfi rax, RAX
+	movq_cfi  r8,  R8
+	movq_cfi  r9,  R9
+	movq_cfi r10, R10
+	movq_cfi r11, R11
+	movq_cfi r12, R12
 
 	/* Save rbp so that we can unwind from get_irq_regs() */
-	movq_cfi rbp, 0
+	movq_cfi rbp, RBP
 
 	/* Save previous stack value */
 	movq %rsp, %rsi
 
-	leaq -RBP(%rsp),%rdi	/* arg1 for handler */
-	testl $3, CS(%rdi)
+	movq %rsp,%rdi	/* arg1 for handler */
+	testb $3, CS(%rsi)
 	je 1f
 	SWAPGS
 	/*
@@ -341,24 +630,39 @@ ENDPROC(native_usergs_sysret64)
 			0x06 /* DW_OP_deref */, \
 			0x08 /* DW_OP_const1u */, SS+8-RBP, \
 			0x22 /* DW_OP_plus */
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	testb $3, CS(%rdi)
+	jnz 1f
+	pax_enter_kernel
+	jmp 2f
+1:	pax_enter_kernel_user
+2:
+#else
+	pax_enter_kernel
+#endif
+
 	/* We entered an interrupt context - irqs are off: */
 	TRACE_IRQS_OFF
 	.endm
 
 ENTRY(save_rest)
-	PARTIAL_FRAME 1 REST_SKIP+8
-	movq 5*8+16(%rsp), %r11	/* save return address */
+	PARTIAL_FRAME 1 8
 	movq_cfi rbx, RBX+16
 	movq_cfi rbp, RBP+16
+
+#ifndef CONFIG_PAX_KERNEXEC_PLUGIN_METHOD_OR
 	movq_cfi r12, R12+16
+#endif
+
 	movq_cfi r13, R13+16
 	movq_cfi r14, R14+16
 	movq_cfi r15, R15+16
-	movq %r11, 8(%rsp)	/* return address */
 	FIXUP_TOP_OF_STACK %r11, 16
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
-END(save_rest)
+ENDPROC(save_rest)
 
 /* save complete stack frame */
 	.pushsection .kprobes.text, "ax"
@@ -387,10 +691,21 @@ ENTRY(save_paranoid)
 	js 1f	/* negative -> in kernel */
 	SWAPGS
 	xorl %ebx,%ebx
-1:	ret
+1:
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	testb $3, CS+8(%rsp)
+	jnz 1f
+	pax_enter_kernel
+	jmp 2f
+1:	pax_enter_kernel_user
+2:
+#else
+	pax_enter_kernel
+#endif
+	pax_force_retaddr
+	ret
 	CFI_ENDPROC
-END(save_paranoid)
-	.popsection
+ENDPROC(save_paranoid)
 
 /*
  * A newly forked process directly context switches into this address.
@@ -411,7 +726,7 @@ ENTRY(ret_from_fork)
 
 	RESTORE_REST
 
-	testl $3, CS-ARGOFFSET(%rsp)		# from kernel_thread?
+	testb $3, CS-ARGOFFSET(%rsp)		# from kernel_thread?
 	je   int_ret_from_sys_call
 
 	/*
@@ -424,7 +739,7 @@ ENTRY(ret_from_fork)
 	jmp  int_ret_from_sys_call
 
 	CFI_ENDPROC
-END(ret_from_fork)
+ENDPROC(ret_from_fork)
 
 /*
  * System call entry. Up to 6 arguments in registers are supported.
@@ -460,7 +775,7 @@ END(ret_from_fork)
 ENTRY(system_call)
 	CFI_STARTPROC	simple
 	CFI_SIGNAL_FRAME
-	CFI_DEF_CFA	rsp,KERNEL_STACK_OFFSET
+	CFI_DEF_CFA	rsp,0
 	CFI_REGISTER	rip,rcx
 	/*CFI_REGISTER	rflags,r11*/
 	SWAPGS_UNSAFE_STACK
@@ -473,12 +788,18 @@ ENTRY(system_call_after_swapgs)
 
 	movq	%rsp,PER_CPU_VAR(old_rsp)
 	movq	PER_CPU_VAR(kernel_stack),%rsp
+	SAVE_ARGS 8*6,0
+	pax_enter_kernel_user
+
+#ifdef CONFIG_PAX_RANDKSTACK
+	pax_erase_kstack
+#endif
+
 	/*
 	 * No need to follow this irqs off/on section - it's straight
 	 * and short:
 	 */
 	ENABLE_INTERRUPTS(CLBR_NONE)
-	SAVE_ARGS 8,0
 	movq  %rax,ORIG_RAX-ARGOFFSET(%rsp)
 	movq  %rcx,RIP-ARGOFFSET(%rsp)
 	CFI_REL_OFFSET rip,RIP-ARGOFFSET
@@ -507,6 +828,8 @@ sysret_check:
 	andl %edi,%edx
 	jnz  sysret_careful
 	CFI_REMEMBER_STATE
+	pax_exit_kernel_user
+	pax_erase_kstack
 	/*
 	 * sysretq will re-enable interrupts:
 	 */
@@ -565,6 +888,9 @@ auditsys:
 	movq %rax,%rsi			/* 2nd arg: syscall number */
 	movl $AUDIT_ARCH_X86_64,%edi	/* 1st arg: audit arch */
 	call audit_syscall_entry
+
+	pax_erase_kstack
+
 	LOAD_ARGS 0		/* reload call-clobbered registers */
 	jmp system_call_fastpath
 
@@ -595,12 +921,15 @@ tracesys:
 	FIXUP_TOP_OF_STACK %rdi
 	movq %rsp,%rdi
 	call syscall_trace_enter
+
+	pax_erase_kstack
+
 	/*
 	 * Reload arg registers from stack in case ptrace changed them.
 	 * We don't reload %rax because syscall_trace_enter() returned
 	 * the value it wants us to use in the table lookup.
 	 */
-	LOAD_ARGS ARGOFFSET, 1
+	LOAD_ARGS 1
 	RESTORE_REST
 	cmpq $__NR_syscall_max,%rax
 	ja   int_ret_from_sys_call	/* RAX(%rsp) set to -ENOSYS above */
@@ -616,7 +945,7 @@ tracesys:
 GLOBAL(int_ret_from_sys_call)
 	DISABLE_INTERRUPTS(CLBR_NONE)
 	TRACE_IRQS_OFF
-	testl $3,CS-ARGOFFSET(%rsp)
+	testb $3,CS-ARGOFFSET(%rsp)
 	je retint_restore_args
 	movl $_TIF_ALLWORK_MASK,%edi
 	/* edi:	mask to check */
@@ -627,7 +956,9 @@ GLOBAL(int_with_check)
 	andl %edi,%edx
 	jnz   int_careful
 	andl    $~TS_COMPAT,TI_status(%rcx)
-	jmp   retint_swapgs
+	pax_exit_kernel_user
+	pax_erase_kstack
+	jmp   retint_swapgs_pax
 
 	/* Either reschedule or signal or syscall exit tracking needed. */
 	/* First do a reschedule test. */
@@ -673,7 +1004,7 @@ int_restore_rest:
 	TRACE_IRQS_OFF
 	jmp int_with_check
 	CFI_ENDPROC
-END(system_call)
+ENDPROC(system_call)
 
 /*
  * Certain special system calls that need to save a complete full stack frame.
@@ -681,15 +1012,13 @@ END(system_call)
 	.macro PTREGSCALL label,func,arg
 ENTRY(\label)
 	PARTIAL_FRAME 1 8		/* offset 8: return address */
-	subq $REST_SKIP, %rsp
-	CFI_ADJUST_CFA_OFFSET REST_SKIP
 	call save_rest
 	DEFAULT_FRAME 0 8		/* offset 8: return address */
 	leaq 8(%rsp), \arg	/* pt_regs pointer */
 	call \func
 	jmp ptregscall_common
 	CFI_ENDPROC
-END(\label)
+ENDPROC(\label)
 	.endm
 
 	PTREGSCALL stub_clone, sys_clone, %r8
@@ -704,12 +1033,17 @@ ENTRY(ptregscall_common)
 	movq_cfi_restore R15+8, r15
 	movq_cfi_restore R14+8, r14
 	movq_cfi_restore R13+8, r13
+
+#ifndef CONFIG_PAX_KERNEXEC_PLUGIN_METHOD_OR
 	movq_cfi_restore R12+8, r12
+#endif
+
 	movq_cfi_restore RBP+8, rbp
 	movq_cfi_restore RBX+8, rbx
-	ret $REST_SKIP		/* pop extended registers */
+	pax_force_retaddr
+	ret
 	CFI_ENDPROC
-END(ptregscall_common)
+ENDPROC(ptregscall_common)
 
 ENTRY(stub_execve)
 	CFI_STARTPROC
@@ -724,7 +1058,7 @@ ENTRY(stub_execve)
 	RESTORE_REST
 	jmp int_ret_from_sys_call
 	CFI_ENDPROC
-END(stub_execve)
+ENDPROC(stub_execve)
 
 /*
  * sigreturn is special because it needs to restore all registers on return.
@@ -742,7 +1076,7 @@ ENTRY(stub_rt_sigreturn)
 	RESTORE_REST
 	jmp int_ret_from_sys_call
 	CFI_ENDPROC
-END(stub_rt_sigreturn)
+ENDPROC(stub_rt_sigreturn)
 
 /*
  * Build the entry stubs and pointer table with some assembler magic.
@@ -777,7 +1111,7 @@ vector=vector+1
 2:	jmp common_interrupt
 .endr
 	CFI_ENDPROC
-END(irq_entries_start)
+ENDPROC(irq_entries_start)
 
 .previous
 END(interrupt)
@@ -794,8 +1128,8 @@ END(interrupt)
 /* 0(%rsp): ~(interrupt number) */
 	.macro interrupt func
 	/* reserve pt_regs for scratch regs and rbp */
-	subq $ORIG_RAX-RBP, %rsp
-	CFI_ADJUST_CFA_OFFSET ORIG_RAX-RBP
+	subq $ORIG_RAX, %rsp
+	CFI_ADJUST_CFA_OFFSET ORIG_RAX
 	SAVE_ARGS_IRQ
 	call \func
 	.endm
@@ -822,13 +1156,13 @@ ret_from_intr:
 	/* Restore saved previous stack */
 	popq %rsi
 	CFI_DEF_CFA_REGISTER	rsi
-	leaq ARGOFFSET-RBP(%rsi), %rsp
+	movq %rsi, %rsp
 	CFI_DEF_CFA_REGISTER	rsp
-	CFI_ADJUST_CFA_OFFSET	RBP-ARGOFFSET
+	CFI_ADJUST_CFA_OFFSET	-ARGOFFSET
 
 exit_intr:
 	GET_THREAD_INFO(%rcx)
-	testl $3,CS-ARGOFFSET(%rsp)
+	testb $3,CS-ARGOFFSET(%rsp)
 	je retint_kernel
 
 	/* Interrupt came from user space */
@@ -850,12 +1184,16 @@ retint_swapgs:		/* return to user-space
 	 * The iretq could re-enable interrupts:
 	 */
 	DISABLE_INTERRUPTS(CLBR_ANY)
+	pax_exit_kernel_user
+retint_swapgs_pax:
 	TRACE_IRQS_IRETQ
 	SWAPGS
 	jmp restore_args
 
 retint_restore_args:	/* return to kernel space */
 	DISABLE_INTERRUPTS(CLBR_ANY)
+	pax_exit_kernel
+	pax_force_retaddr (RIP-ARGOFFSET)
 	/*
 	 * The iretq could re-enable interrupts:
 	 */
@@ -893,15 +1231,15 @@ native_irq_return_ldt:
 	SWAPGS
 	movq PER_CPU_VAR(espfix_waddr),%rdi
 	movq %rax,(0*8)(%rdi)	/* RAX */
-	movq (2*8)(%rsp),%rax	/* RIP */
+	movq (2*8 + RIP-RIP)(%rsp),%rax	/* RIP */
 	movq %rax,(1*8)(%rdi)
-	movq (3*8)(%rsp),%rax	/* CS */
+	movq (2*8 + CS-RIP)(%rsp),%rax	/* CS */
 	movq %rax,(2*8)(%rdi)
-	movq (4*8)(%rsp),%rax	/* RFLAGS */
+	movq (2*8 + EFLAGS-RIP)(%rsp),%rax	/* RFLAGS */
 	movq %rax,(3*8)(%rdi)
-	movq (6*8)(%rsp),%rax	/* SS */
+	movq (2*8 + SS-RIP)(%rsp),%rax	/* SS */
 	movq %rax,(5*8)(%rdi)
-	movq (5*8)(%rsp),%rax	/* RSP */
+	movq (2*8 + RSP-RIP)(%rsp),%rax	/* RSP */
 	movq %rax,(4*8)(%rdi)
 	andl $0xffff0000,%eax
 	popq_cfi %rdi
@@ -957,7 +1295,7 @@ ENTRY(retint_kernel)
 	jmp exit_intr
 #endif
 	CFI_ENDPROC
-END(common_interrupt)
+ENDPROC(common_interrupt)
 
 /*
  * End of kprobes section
@@ -974,7 +1312,7 @@ ENTRY(\sym)
 	interrupt \do_sym
 	jmp ret_from_intr
 	CFI_ENDPROC
-END(\sym)
+ENDPROC(\sym)
 .endm
 
 #ifdef CONFIG_SMP
@@ -1044,7 +1382,7 @@ ENTRY(\sym)
 	call \do_sym
 	jmp error_exit		/* %ebx: no swapgs flag */
 	CFI_ENDPROC
-END(\sym)
+ENDPROC(\sym)
 .endm
 
 .macro paranoidzeroentry sym do_sym
@@ -1061,10 +1399,10 @@ ENTRY(\sym)
 	call \do_sym
 	jmp paranoid_exit	/* %ebx: no swapgs flag */
 	CFI_ENDPROC
-END(\sym)
+ENDPROC(\sym)
 .endm
 
-#define INIT_TSS_IST(x) PER_CPU_VAR(init_tss) + (TSS_ist + ((x) - 1) * 8)
+#define INIT_TSS_IST(x) (TSS_ist + ((x) - 1) * 8)(%r13)
 .macro paranoidzeroentry_ist sym do_sym ist
 ENTRY(\sym)
 	INTR_FRAME
@@ -1076,12 +1414,18 @@ ENTRY(\sym)
 	TRACE_IRQS_OFF
 	movq %rsp,%rdi		/* pt_regs pointer */
 	xorl %esi,%esi		/* no error code */
+#ifdef CONFIG_SMP
+	imul $TSS_size, PER_CPU_VAR(cpu_number), %r13d
+	lea init_tss(%r13), %r13
+#else
+	lea init_tss(%rip), %r13
+#endif
 	subq $EXCEPTION_STKSZ, INIT_TSS_IST(\ist)
 	call \do_sym
 	addq $EXCEPTION_STKSZ, INIT_TSS_IST(\ist)
 	jmp paranoid_exit	/* %ebx: no swapgs flag */
 	CFI_ENDPROC
-END(\sym)
+ENDPROC(\sym)
 .endm
 
 .macro errorentry sym do_sym
@@ -1098,7 +1442,7 @@ ENTRY(\sym)
 	call \do_sym
 	jmp error_exit			/* %ebx: no swapgs flag */
 	CFI_ENDPROC
-END(\sym)
+ENDPROC(\sym)
 .endm
 
 	/* error code is on the stack already */
@@ -1117,7 +1461,7 @@ ENTRY(\sym)
 	call \do_sym
 	jmp paranoid_exit		/* %ebx: no swapgs flag */
 	CFI_ENDPROC
-END(\sym)
+ENDPROC(\sym)
 .endm
 
 zeroentry divide_error do_divide_error
@@ -1147,9 +1491,10 @@ gs_change:
 2:	mfence		/* workaround */
 	SWAPGS
 	popfq_cfi
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
-END(native_load_gs_index)
+ENDPROC(native_load_gs_index)
 
 	.section __ex_table,"a"
 	.align 8
@@ -1171,13 +1516,14 @@ ENTRY(kernel_thread_helper)
 	 * Here we are in the child and the registers are set as they were
 	 * at kernel_thread() invocation in the parent.
 	 */
+	pax_force_fptr %rsi
 	call *%rsi
 	# exit
 	mov %eax, %edi
 	call do_exit
 	ud2			# padding for call trace
 	CFI_ENDPROC
-END(kernel_thread_helper)
+ENDPROC(kernel_thread_helper)
 
 /*
  * execve(). This function needs to use IRET, not SYSRET, to set up all state properly.
@@ -1204,11 +1550,11 @@ ENTRY(kernel_execve)
 	RESTORE_REST
 	testq %rax,%rax
 	je int_ret_from_sys_call
-	RESTORE_ARGS
 	UNFAKE_STACK_FRAME
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
-END(kernel_execve)
+ENDPROC(kernel_execve)
 
 /* Call softirq on interrupt stack. Interrupts are off. */
 ENTRY(call_softirq)
@@ -1226,9 +1572,10 @@ ENTRY(call_softirq)
 	CFI_DEF_CFA_REGISTER	rsp
 	CFI_ADJUST_CFA_OFFSET   -8
 	decl PER_CPU_VAR(irq_count)
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
-END(call_softirq)
+ENDPROC(call_softirq)
 
 #ifdef CONFIG_XEN
 zeroentry xen_hypervisor_callback xen_do_hypervisor_callback
@@ -1266,7 +1613,7 @@ ENTRY(xen_do_hypervisor_callback)   # do
 	decl PER_CPU_VAR(irq_count)
 	jmp  error_exit
 	CFI_ENDPROC
-END(xen_do_hypervisor_callback)
+ENDPROC(xen_do_hypervisor_callback)
 
 /*
  * Hypervisor uses this for application faults while it executes.
@@ -1325,7 +1672,7 @@ ENTRY(xen_failsafe_callback)
 	SAVE_ALL
 	jmp error_exit
 	CFI_ENDPROC
-END(xen_failsafe_callback)
+ENDPROC(xen_failsafe_callback)
 
 apicinterrupt XEN_HVM_EVTCHN_CALLBACK \
 	xen_hvm_callback_vector xen_evtchn_do_upcall
@@ -1374,16 +1721,31 @@ ENTRY(paranoid_exit)
 	TRACE_IRQS_OFF
 	testl %ebx,%ebx				/* swapgs needed? */
 	jnz paranoid_restore
-	testl $3,CS(%rsp)
+	testb $3,CS(%rsp)
 	jnz   paranoid_userspace
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	pax_exit_kernel
+	TRACE_IRQS_IRETQ 0
+	SWAPGS_UNSAFE_STACK
+	RESTORE_ALL 8
+	pax_force_retaddr_bts
+	jmp irq_return
+#endif
 paranoid_swapgs:
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	pax_exit_kernel_user
+#else
+	pax_exit_kernel
+#endif
 	TRACE_IRQS_IRETQ 0
 	SWAPGS_UNSAFE_STACK
 	RESTORE_ALL 8
 	jmp irq_return
 paranoid_restore:
+	pax_exit_kernel
 	TRACE_IRQS_IRETQ 0
 	RESTORE_ALL 8
+	pax_force_retaddr_bts
 	jmp irq_return
 paranoid_userspace:
 	GET_THREAD_INFO(%rcx)
@@ -1412,7 +1774,7 @@ paranoid_schedule:
 	TRACE_IRQS_OFF
 	jmp paranoid_userspace
 	CFI_ENDPROC
-END(paranoid_exit)
+ENDPROC(paranoid_exit)
 
 /*
  * Exception entry point. This expects an error code/orig_rax on the stack.
@@ -1439,12 +1801,23 @@ ENTRY(error_entry)
 	movq_cfi r14, R14+8
 	movq_cfi r15, R15+8
 	xorl %ebx,%ebx
-	testl $3,CS+8(%rsp)
+	testb $3,CS+8(%rsp)
 	je error_kernelspace
 error_swapgs:
 	SWAPGS
 error_sti:
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	testb $3, CS+8(%rsp)
+	jnz 1f
+	pax_enter_kernel
+	jmp 2f
+1:	pax_enter_kernel_user
+2:
+#else
+	pax_enter_kernel
+#endif
 	TRACE_IRQS_OFF
+	pax_force_retaddr
 	ret
 
 /*
@@ -1478,7 +1851,7 @@ error_bad_iret:
 	decl %ebx	/* Return to usergs */
 	jmp error_sti
 	CFI_ENDPROC
-END(error_entry)
+ENDPROC(error_entry)
 
 
 /* ebx:	no swapgs flag (1: don't need swapgs, 0: need it) */
@@ -1498,7 +1871,7 @@ ENTRY(error_exit)
 	jnz retint_careful
 	jmp retint_swapgs
 	CFI_ENDPROC
-END(error_exit)
+ENDPROC(error_exit)
 
 
 	/* runs on exception stack */
@@ -1510,6 +1883,7 @@ ENTRY(nmi)
 	CFI_ADJUST_CFA_OFFSET ORIG_RAX-R15
 	call save_paranoid
 	DEFAULT_FRAME 0
+
 	/* paranoidentry do_nmi, 0; without TRACE_IRQS_OFF */
 	movq %rsp,%rdi
 	movq $-1,%rsi
@@ -1520,12 +1894,28 @@ ENTRY(nmi)
 	DISABLE_INTERRUPTS(CLBR_NONE)
 	testl %ebx,%ebx				/* swapgs needed? */
 	jnz nmi_restore
-	testl $3,CS(%rsp)
+	testb $3,CS(%rsp)
 	jnz nmi_userspace
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	pax_exit_kernel
+	SWAPGS_UNSAFE_STACK
+	RESTORE_ALL 8
+	pax_force_retaddr_bts
+	jmp irq_return
+#endif
 nmi_swapgs:
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	pax_exit_kernel_user
+#else
+	pax_exit_kernel
+#endif
 	SWAPGS_UNSAFE_STACK
+	RESTORE_ALL 8
+	jmp irq_return
 nmi_restore:
+	pax_exit_kernel
 	RESTORE_ALL 8
+	pax_force_retaddr_bts
 	jmp irq_return
 nmi_userspace:
 	GET_THREAD_INFO(%rcx)
@@ -1554,14 +1944,14 @@ nmi_schedule:
 	jmp paranoid_exit
 	CFI_ENDPROC
 #endif
-END(nmi)
+ENDPROC(nmi)
 
 ENTRY(ignore_sysret)
 	CFI_STARTPROC
 	mov $-ENOSYS,%eax
 	sysret
 	CFI_ENDPROC
-END(ignore_sysret)
+ENDPROC(ignore_sysret)
 
 /*
  * End of kprobes section
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/espfix_64.c linux-3.2.71-pax/arch/x86/kernel/espfix_64.c
--- linux-3.2.71/arch/x86/kernel/espfix_64.c	2014-09-14 14:10:58.070117237 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/espfix_64.c	2015-01-05 18:58:55.057414567 +0100
@@ -70,8 +70,7 @@ static DEFINE_MUTEX(espfix_init_mutex);
 #define ESPFIX_MAX_PAGES  DIV_ROUND_UP(CONFIG_NR_CPUS, ESPFIX_STACKS_PER_PAGE)
 static void *espfix_pages[ESPFIX_MAX_PAGES];
 
-static __page_aligned_bss pud_t espfix_pud_page[PTRS_PER_PUD]
-	__aligned(PAGE_SIZE);
+static __page_aligned_rodata pud_t espfix_pud_page[PTRS_PER_PUD];
 
 static unsigned int page_random, slot_random;
 
@@ -122,14 +121,16 @@ static void init_espfix_random(void)
 void __init init_espfix_bsp(void)
 {
 	pgd_t *pgd_p;
-	pteval_t ptemask;
-
-	ptemask = __supported_pte_mask;
+	unsigned long index = pgd_index(ESPFIX_BASE_ADDR);
 
 	/* Install the espfix pud into the kernel page directory */
-	pgd_p = &init_level4_pgt[pgd_index(ESPFIX_BASE_ADDR)];
+	pgd_p = &init_level4_pgt[index];
 	pgd_populate(&init_mm, pgd_p, (pud_t *)espfix_pud_page);
 
+#ifdef CONFIG_PAX_PER_CPU_PGD
+	clone_pgd_range(get_cpu_pgd(0) + index, swapper_pg_dir + index, 1);
+#endif
+
 	/* Randomize the locations */
 	init_espfix_random();
 
@@ -197,7 +198,7 @@ void init_espfix_ap(void)
 		set_pte(&pte_p[n*PTE_STRIDE], pte);
 
 	/* Job is done for this CPU and any CPU which shares this page */
-	ACCESS_ONCE(espfix_pages[page]) = stack_page;
+	ACCESS_ONCE_RW(espfix_pages[page]) = stack_page;
 
 unlock_done:
 	mutex_unlock(&espfix_init_mutex);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/ftrace.c linux-3.2.71-pax/arch/x86/kernel/ftrace.c
--- linux-3.2.71/arch/x86/kernel/ftrace.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/ftrace.c	2013-11-25 00:36:34.206512364 +0100
@@ -126,7 +126,7 @@ static void *mod_code_ip;		/* holds the
 static const void *mod_code_newcode;	/* holds the text to write to the IP */
 
 static unsigned nmi_wait_count;
-static atomic_t nmi_update_count = ATOMIC_INIT(0);
+static atomic_unchecked_t nmi_update_count = ATOMIC_INIT(0);
 
 int ftrace_arch_read_dyn_info(char *buf, int size)
 {
@@ -134,7 +134,7 @@ int ftrace_arch_read_dyn_info(char *buf,
 
 	r = snprintf(buf, size, "%u %u",
 		     nmi_wait_count,
-		     atomic_read(&nmi_update_count));
+		     atomic_read_unchecked(&nmi_update_count));
 	return r;
 }
 
@@ -178,7 +178,7 @@ void ftrace_nmi_enter(void)
 	if (atomic_inc_return(&nmi_running) & MOD_CODE_WRITE_FLAG) {
 		smp_rmb();
 		ftrace_mod_code();
-		atomic_inc(&nmi_update_count);
+		atomic_inc_unchecked(&nmi_update_count);
 	}
 	/* Must have previous changes seen before executions */
 	smp_mb();
@@ -271,6 +271,8 @@ ftrace_modify_code(unsigned long ip, uns
 {
 	unsigned char replaced[MCOUNT_INSN_SIZE];
 
+	ip = ktla_ktva(ip);
+
 	/*
 	 * Note: Due to modules and __init, code can
 	 *  disappear and change, we need to protect against faulting
@@ -327,7 +329,7 @@ int ftrace_update_ftrace_func(ftrace_fun
 	unsigned char old[MCOUNT_INSN_SIZE], *new;
 	int ret;
 
-	memcpy(old, &ftrace_call, MCOUNT_INSN_SIZE);
+	memcpy(old, ktla_ktva((void *)ftrace_call), MCOUNT_INSN_SIZE);
 	new = ftrace_call_replace(ip, (unsigned long)func);
 	ret = ftrace_modify_code(ip, old, new);
 
@@ -353,6 +355,8 @@ static int ftrace_mod_jmp(unsigned long
 {
 	unsigned char code[MCOUNT_INSN_SIZE];
 
+	ip = ktla_ktva(ip);
+
 	if (probe_kernel_read(code, (void *)ip, MCOUNT_INSN_SIZE))
 		return -EFAULT;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/head32.c linux-3.2.71-pax/arch/x86/kernel/head32.c
--- linux-3.2.71/arch/x86/kernel/head32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/head32.c	2013-02-17 16:28:47.528320188 +0100
@@ -19,6 +19,7 @@
 #include <asm/io_apic.h>
 #include <asm/bios_ebda.h>
 #include <asm/tlbflush.h>
+#include <asm/boot.h>
 
 static void __init i386_default_early_setup(void)
 {
@@ -33,7 +34,7 @@ void __init i386_start_kernel(void)
 {
 	memblock_init();
 
-	memblock_x86_reserve_range(__pa_symbol(&_text), __pa_symbol(&__bss_stop), "TEXT DATA BSS");
+	memblock_x86_reserve_range(LOAD_PHYSICAL_ADDR, __pa_symbol(&__bss_stop), "TEXT DATA BSS");
 
 #ifdef CONFIG_BLK_DEV_INITRD
 	/* Reserve INITRD */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/head_32.S linux-3.2.71-pax/arch/x86/kernel/head_32.S
--- linux-3.2.71/arch/x86/kernel/head_32.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/head_32.S	2014-08-04 01:38:45.182874275 +0200
@@ -25,6 +25,12 @@
 /* Physical address */
 #define pa(X) ((X) - __PAGE_OFFSET)
 
+#ifdef CONFIG_PAX_KERNEXEC
+#define ta(X) (X)
+#else
+#define ta(X) ((X) - __PAGE_OFFSET)
+#endif
+
 /*
  * References to members of the new_cpu_data structure.
  */
@@ -54,11 +60,7 @@
  * and small than max_low_pfn, otherwise will waste some page table entries
  */
 
-#if PTRS_PER_PMD > 1
-#define PAGE_TABLE_SIZE(pages) (((pages) / PTRS_PER_PMD) + PTRS_PER_PGD)
-#else
-#define PAGE_TABLE_SIZE(pages) ((pages) / PTRS_PER_PGD)
-#endif
+#define PAGE_TABLE_SIZE(pages) ((pages) / PTRS_PER_PTE)
 
 /* Number of possible pages in the lowmem region */
 LOWMEM_PAGES = (((1<<32) - __PAGE_OFFSET) >> PAGE_SHIFT)
@@ -77,6 +79,12 @@ INIT_MAP_SIZE = PAGE_TABLE_SIZE(KERNEL_P
 RESERVE_BRK(pagetables, INIT_MAP_SIZE)
 
 /*
+ * Real beginning of normal "text" segment
+ */
+ENTRY(stext)
+ENTRY(_stext)
+
+/*
  * 32-bit kernel entrypoint; only used by the boot CPU.  On entry,
  * %esi points to the real-mode code as a 32-bit pointer.
  * CS and DS must be 4 GB flat segments, but we don't depend on
@@ -84,6 +92,13 @@ RESERVE_BRK(pagetables, INIT_MAP_SIZE)
  * can.
  */
 __HEAD
+
+#ifdef CONFIG_PAX_KERNEXEC
+	jmp startup_32
+/* PaX: fill first page in .text with int3 to catch NULL derefs in kernel mode */
+.fill PAGE_SIZE-5,1,0xcc
+#endif
+
 ENTRY(startup_32)
 	movl pa(stack_start),%ecx
 	
@@ -105,6 +120,59 @@ ENTRY(startup_32)
 2:
 	leal -__PAGE_OFFSET(%ecx),%esp
 
+#ifdef CONFIG_SMP
+	movl $pa(cpu_gdt_table),%edi
+	movl $__per_cpu_load,%eax
+	movw %ax,GDT_ENTRY_PERCPU * 8 + 2(%edi)
+	rorl $16,%eax
+	movb %al,GDT_ENTRY_PERCPU * 8 + 4(%edi)
+	movb %ah,GDT_ENTRY_PERCPU * 8 + 7(%edi)
+	movl $__per_cpu_end - 1,%eax
+	subl $__per_cpu_start,%eax
+	movw %ax,GDT_ENTRY_PERCPU * 8 + 0(%edi)
+#endif
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	movl $NR_CPUS,%ecx
+	movl $pa(cpu_gdt_table),%edi
+1:
+	movl $((((__PAGE_OFFSET-1) & 0xf0000000) >> 12) | 0x00c09700),GDT_ENTRY_KERNEL_DS * 8 + 4(%edi)
+	movl $((((__PAGE_OFFSET-1) & 0xf0000000) >> 12) | 0x00c0fb00),GDT_ENTRY_DEFAULT_USER_CS * 8 + 4(%edi)
+	movl $((((__PAGE_OFFSET-1) & 0xf0000000) >> 12) | 0x00c0f300),GDT_ENTRY_DEFAULT_USER_DS * 8 + 4(%edi)
+	addl $PAGE_SIZE_asm,%edi
+	loop 1b
+#endif
+
+#ifdef CONFIG_PAX_KERNEXEC
+	movl $pa(boot_gdt),%edi
+	movl $__LOAD_PHYSICAL_ADDR,%eax
+	movw %ax,GDT_ENTRY_BOOT_CS * 8 + 2(%edi)
+	rorl $16,%eax
+	movb %al,GDT_ENTRY_BOOT_CS * 8 + 4(%edi)
+	movb %ah,GDT_ENTRY_BOOT_CS * 8 + 7(%edi)
+	rorl $16,%eax
+
+	ljmp $(__BOOT_CS),$1f
+1:
+
+	movl $NR_CPUS,%ecx
+	movl $pa(cpu_gdt_table),%edi
+	addl $__PAGE_OFFSET,%eax
+1:
+	movb $0xc0,GDT_ENTRY_KERNEL_CS * 8 + 6(%edi)
+	movb $0xc0,GDT_ENTRY_KERNEXEC_KERNEL_CS * 8 + 6(%edi)
+	movw %ax,GDT_ENTRY_KERNEL_CS * 8 + 2(%edi)
+	movw %ax,GDT_ENTRY_KERNEXEC_KERNEL_CS * 8 + 2(%edi)
+	rorl $16,%eax
+	movb %al,GDT_ENTRY_KERNEL_CS * 8 + 4(%edi)
+	movb %al,GDT_ENTRY_KERNEXEC_KERNEL_CS * 8 + 4(%edi)
+	movb %ah,GDT_ENTRY_KERNEL_CS * 8 + 7(%edi)
+	movb %ah,GDT_ENTRY_KERNEXEC_KERNEL_CS * 8 + 7(%edi)
+	rorl $16,%eax
+	addl $PAGE_SIZE_asm,%edi
+	loop 1b
+#endif
+
 /*
  * Clear BSS first so that there are no surprises...
  */
@@ -195,8 +263,11 @@ ENTRY(startup_32)
 	movl %eax, pa(max_pfn_mapped)
 
 	/* Do early initialization of the fixmap area */
-	movl $pa(initial_pg_fixmap)+PDE_IDENT_ATTR,%eax
-	movl %eax,pa(initial_pg_pmd+0x1000*KPMDS-8)
+#ifdef CONFIG_COMPAT_VDSO
+	movl $pa(initial_pg_fixmap)+PDE_IDENT_ATTR+_PAGE_USER,pa(initial_pg_pmd+0x1000*KPMDS-8)
+#else
+	movl $pa(initial_pg_fixmap)+PDE_IDENT_ATTR,pa(initial_pg_pmd+0x1000*KPMDS-8)
+#endif
 #else	/* Not PAE */
 
 page_pde_offset = (__PAGE_OFFSET >> 20);
@@ -226,8 +297,11 @@ page_pde_offset = (__PAGE_OFFSET >> 20);
 	movl %eax, pa(max_pfn_mapped)
 
 	/* Do early initialization of the fixmap area */
-	movl $pa(initial_pg_fixmap)+PDE_IDENT_ATTR,%eax
-	movl %eax,pa(initial_page_table+0xffc)
+#ifdef CONFIG_COMPAT_VDSO
+	movl $pa(initial_pg_fixmap)+PDE_IDENT_ATTR+_PAGE_USER,pa(initial_page_table+0xffc)
+#else
+	movl $pa(initial_pg_fixmap)+PDE_IDENT_ATTR,pa(initial_page_table+0xffc)
+#endif
 #endif
 
 #ifdef CONFIG_PARAVIRT
@@ -241,9 +315,7 @@ page_pde_offset = (__PAGE_OFFSET >> 20);
 	cmpl $num_subarch_entries, %eax
 	jae bad_subarch
 
-	movl pa(subarch_entries)(,%eax,4), %eax
-	subl $__PAGE_OFFSET, %eax
-	jmp *%eax
+	jmp *pa(subarch_entries)(,%eax,4)
 
 bad_subarch:
 WEAK(lguest_entry)
@@ -255,10 +327,10 @@ WEAK(xen_entry)
 	__INITDATA
 
 subarch_entries:
-	.long default_entry		/* normal x86/PC */
-	.long lguest_entry		/* lguest hypervisor */
-	.long xen_entry			/* Xen hypervisor */
-	.long default_entry		/* Moorestown MID */
+	.long ta(default_entry)		/* normal x86/PC */
+	.long ta(lguest_entry)		/* lguest hypervisor */
+	.long ta(xen_entry)		/* Xen hypervisor */
+	.long ta(default_entry)		/* Moorestown MID */
 num_subarch_entries = (. - subarch_entries) / 4
 .previous
 #else
@@ -312,6 +384,7 @@ default_entry:
 	orl %edx,%eax
 	movl %eax,%cr4
 
+#ifdef CONFIG_X86_PAE
 	testb $X86_CR4_PAE, %al		# check if PAE is enabled
 	jz 6f
 
@@ -340,6 +413,9 @@ default_entry:
 	/* Make changes effective */
 	wrmsr
 
+	btsl $_PAGE_BIT_NX-32,pa(__supported_pte_mask+4)
+#endif
+
 6:
 
 /*
@@ -443,7 +519,7 @@ is386:	movl $2,%ecx		# set MP
 1:	movl $(__KERNEL_DS),%eax	# reload all the segment registers
 	movl %eax,%ss			# after changing gdt.
 
-	movl $(__USER_DS),%eax		# DS/ES contains default USER segment
+#	movl $(__KERNEL_DS),%eax	# DS/ES contains default KERNEL segment
 	movl %eax,%ds
 	movl %eax,%es
 
@@ -457,15 +533,22 @@ is386:	movl $2,%ecx		# set MP
 	 */
 	cmpb $0,ready
 	jne 1f
-	movl $gdt_page,%eax
+	movl $cpu_gdt_table,%eax
 	movl $stack_canary,%ecx
+#ifdef CONFIG_SMP
+	addl $__per_cpu_load,%ecx
+#endif
 	movw %cx, 8 * GDT_ENTRY_STACK_CANARY + 2(%eax)
 	shrl $16, %ecx
 	movb %cl, 8 * GDT_ENTRY_STACK_CANARY + 4(%eax)
 	movb %ch, 8 * GDT_ENTRY_STACK_CANARY + 7(%eax)
 1:
-#endif
 	movl $(__KERNEL_STACK_CANARY),%eax
+#elif defined(CONFIG_PAX_MEMORY_UDEREF)
+	movl $(__USER_DS),%eax
+#else
+	xorl %eax,%eax
+#endif
 	movl %eax,%gs
 
 	xorl %eax,%eax			# Clear LDT
@@ -558,22 +641,22 @@ early_page_fault:
 	jmp early_fault
 
 early_fault:
-	cld
 #ifdef CONFIG_PRINTK
+	cmpl $1,%ss:early_recursion_flag
+	je hlt_loop
+	incl %ss:early_recursion_flag
+	cld
 	pusha
 	movl $(__KERNEL_DS),%eax
 	movl %eax,%ds
 	movl %eax,%es
-	cmpl $2,early_recursion_flag
-	je hlt_loop
-	incl early_recursion_flag
 	movl %cr2,%eax
 	pushl %eax
 	pushl %edx		/* trapno */
 	pushl $fault_msg
 	call printk
+;	call dump_stack
 #endif
-	call dump_stack
 hlt_loop:
 	hlt
 	jmp hlt_loop
@@ -581,8 +664,11 @@ hlt_loop:
 /* This is the default interrupt "handler" :-) */
 	ALIGN
 ignore_int:
-	cld
 #ifdef CONFIG_PRINTK
+	cmpl $2,%ss:early_recursion_flag
+	je hlt_loop
+	incl %ss:early_recursion_flag
+	cld
 	pushl %eax
 	pushl %ecx
 	pushl %edx
@@ -591,9 +677,6 @@ ignore_int:
 	movl $(__KERNEL_DS),%eax
 	movl %eax,%ds
 	movl %eax,%es
-	cmpl $2,early_recursion_flag
-	je hlt_loop
-	incl early_recursion_flag
 	pushl 16(%esp)
 	pushl 24(%esp)
 	pushl 32(%esp)
@@ -622,29 +705,43 @@ ENTRY(initial_code)
 /*
  * BSS section
  */
-__PAGE_ALIGNED_BSS
-	.align PAGE_SIZE
 #ifdef CONFIG_X86_PAE
+.section .initial_pg_pmd,"a",@progbits
 initial_pg_pmd:
 	.fill 1024*KPMDS,4,0
 #else
+.section .initial_page_table,"a",@progbits
 ENTRY(initial_page_table)
 	.fill 1024,4,0
 #endif
+.section .initial_pg_fixmap,"a",@progbits
 initial_pg_fixmap:
 	.fill 1024,4,0
+.section .empty_zero_page,"a",@progbits
 ENTRY(empty_zero_page)
 	.fill 4096,1,0
+.section .swapper_pg_dir,"a",@progbits
 ENTRY(swapper_pg_dir)
+#ifdef CONFIG_X86_PAE
+	.fill 4,8,0
+#else
 	.fill 1024,4,0
+#endif
+
+/*
+ * The IDT has to be page-aligned to simplify the Pentium
+ * F0 0F bug workaround.. We have a special link segment
+ * for this.
+ */
+.section .idt,"a",@progbits
+ENTRY(idt_table)
+	.fill 256,8,0
 
 /*
  * This starts the data section.
  */
 #ifdef CONFIG_X86_PAE
-__PAGE_ALIGNED_DATA
-	/* Page-aligned for the benefit of paravirt? */
-	.align PAGE_SIZE
+.section .initial_page_table,"a",@progbits
 ENTRY(initial_page_table)
 	.long	pa(initial_pg_pmd+PGD_IDENT_ATTR),0	/* low identity map */
 # if KPMDS == 3
@@ -663,18 +760,27 @@ ENTRY(initial_page_table)
 #  error "Kernel PMDs should be 1, 2 or 3"
 # endif
 	.align PAGE_SIZE		/* needs to be page-sized too */
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+ENTRY(cpu_pgd)
+	.rept NR_CPUS
+	.fill	4,8,0
+	.endr
+#endif
+
 #endif
 
 .data
 .balign 4
 ENTRY(stack_start)
-	.long init_thread_union+THREAD_SIZE
+	.long init_thread_union+THREAD_SIZE-8
+
+ready:	.byte 0
 
+.section .rodata,"a",@progbits
 early_recursion_flag:
 	.long 0
 
-ready:	.byte 0
-
 int_msg:
 	.asciz "Unknown interrupt or fault at: %p %p %p\n"
 
@@ -707,7 +813,7 @@ fault_msg:
 	.word 0				# 32 bit align gdt_desc.address
 boot_gdt_descr:
 	.word __BOOT_DS+7
-	.long boot_gdt - __PAGE_OFFSET
+	.long pa(boot_gdt)
 
 	.word 0				# 32-bit align idt_desc.address
 idt_descr:
@@ -718,7 +824,7 @@ idt_descr:
 	.word 0				# 32 bit align gdt_desc.address
 ENTRY(early_gdt_descr)
 	.word GDT_ENTRIES*8-1
-	.long gdt_page			/* Overwritten for secondary CPUs */
+	.long cpu_gdt_table		/* Overwritten for secondary CPUs */
 
 /*
  * The boot_gdt must mirror the equivalent in setup.S and is
@@ -727,5 +833,65 @@ ENTRY(early_gdt_descr)
 	.align L1_CACHE_BYTES
 ENTRY(boot_gdt)
 	.fill GDT_ENTRY_BOOT_CS,8,0
-	.quad 0x00cf9a000000ffff	/* kernel 4GB code at 0x00000000 */
-	.quad 0x00cf92000000ffff	/* kernel 4GB data at 0x00000000 */
+	.quad 0x00cf9b000000ffff	/* kernel 4GB code at 0x00000000 */
+	.quad 0x00cf93000000ffff	/* kernel 4GB data at 0x00000000 */
+
+	.align PAGE_SIZE_asm
+ENTRY(cpu_gdt_table)
+	.rept NR_CPUS
+	.quad 0x0000000000000000	/* NULL descriptor */
+	.quad 0x0000000000000000	/* 0x0b reserved */
+	.quad 0x0000000000000000	/* 0x13 reserved */
+	.quad 0x0000000000000000	/* 0x1b reserved */
+
+#ifdef CONFIG_PAX_KERNEXEC
+	.quad 0x00cf9b000000ffff	/* 0x20 alternate kernel 4GB code at 0x00000000 */
+#else
+	.quad 0x0000000000000000	/* 0x20 unused */
+#endif
+
+	.quad 0x0000000000000000	/* 0x28 unused */
+	.quad 0x0000000000000000	/* 0x33 TLS entry 1 */
+	.quad 0x0000000000000000	/* 0x3b TLS entry 2 */
+	.quad 0x0000000000000000	/* 0x43 TLS entry 3 */
+	.quad 0x0000000000000000	/* 0x4b reserved */
+	.quad 0x0000000000000000	/* 0x53 reserved */
+	.quad 0x0000000000000000	/* 0x5b reserved */
+
+	.quad 0x00cf9b000000ffff	/* 0x60 kernel 4GB code at 0x00000000 */
+	.quad 0x00cf93000000ffff	/* 0x68 kernel 4GB data at 0x00000000 */
+	.quad 0x00cffb000000ffff	/* 0x73 user 4GB code at 0x00000000 */
+	.quad 0x00cff3000000ffff	/* 0x7b user 4GB data at 0x00000000 */
+
+	.quad 0x0000000000000000	/* 0x80 TSS descriptor */
+	.quad 0x0000000000000000	/* 0x88 LDT descriptor */
+
+	/*
+	 * Segments used for calling PnP BIOS have byte granularity.
+	 * The code segments and data segments have fixed 64k limits,
+	 * the transfer segment sizes are set at run time.
+	 */
+	.quad 0x00409b000000ffff	/* 0x90 32-bit code */
+	.quad 0x00009b000000ffff	/* 0x98 16-bit code */
+	.quad 0x000093000000ffff	/* 0xa0 16-bit data */
+	.quad 0x0000930000000000	/* 0xa8 16-bit data */
+	.quad 0x0000930000000000	/* 0xb0 16-bit data */
+
+	/*
+	 * The APM segments have byte granularity and their bases
+	 * are set at run time.  All have 64k limits.
+	 */
+	.quad 0x00409b000000ffff	/* 0xb8 APM CS    code */
+	.quad 0x00009b000000ffff	/* 0xc0 APM CS 16 code (16 bit) */
+	.quad 0x004093000000ffff	/* 0xc8 APM DS    data */
+
+	.quad 0x00c093000000ffff	/* 0xd0 - ESPFIX SS */
+	.quad 0x0040930000000000	/* 0xd8 - PERCPU */
+	.quad 0x0040910000000017	/* 0xe0 - STACK_CANARY */
+	.quad 0x0000000000000000	/* 0xe8 - PCIBIOS_CS */
+	.quad 0x0000000000000000	/* 0xf0 - PCIBIOS_DS */
+	.quad 0x0000000000000000	/* 0xf8 - GDT entry 31: double-fault TSS */
+
+	/* Be sure this is zeroed to avoid false validations in Xen */
+	.fill PAGE_SIZE_asm - GDT_SIZE,1,0
+	.endr
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/head_64.S linux-3.2.71-pax/arch/x86/kernel/head_64.S
--- linux-3.2.71/arch/x86/kernel/head_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/head_64.S	2015-06-27 14:00:29.750527044 +0200
@@ -19,6 +19,8 @@
 #include <asm/cache.h>
 #include <asm/processor-flags.h>
 #include <asm/percpu.h>
+#include <asm/cpufeature.h>
+#include <asm/alternative-asm.h>
 
 #ifdef CONFIG_PARAVIRT
 #include <asm/asm-offsets.h>
@@ -38,6 +40,12 @@ L4_PAGE_OFFSET = pgd_index(__PAGE_OFFSET
 L3_PAGE_OFFSET = pud_index(__PAGE_OFFSET)
 L4_START_KERNEL = pgd_index(__START_KERNEL_map)
 L3_START_KERNEL = pud_index(__START_KERNEL_map)
+L4_VMALLOC_START = pgd_index(VMALLOC_START)
+L3_VMALLOC_START = pud_index(VMALLOC_START)
+L4_VMALLOC_END = pgd_index(VMALLOC_END)
+L3_VMALLOC_END = pud_index(VMALLOC_END)
+L4_VMEMMAP_START = pgd_index(VMEMMAP_START)
+L3_VMEMMAP_START = pud_index(VMEMMAP_START)
 
 	.text
 	__HEAD
@@ -85,35 +93,25 @@ startup_64:
 	 */
 	addq	%rbp, init_level4_pgt + 0(%rip)
 	addq	%rbp, init_level4_pgt + (L4_PAGE_OFFSET*8)(%rip)
+	addq	%rbp, init_level4_pgt + (L4_VMALLOC_START*8)(%rip)
+	addq	%rbp, init_level4_pgt + (L4_VMALLOC_END*8)(%rip)
+	addq	%rbp, init_level4_pgt + (L4_VMEMMAP_START*8)(%rip)
 	addq	%rbp, init_level4_pgt + (L4_START_KERNEL*8)(%rip)
 
 	addq	%rbp, level3_ident_pgt + 0(%rip)
+#ifndef CONFIG_XEN
+	addq	%rbp, level3_ident_pgt + 8(%rip)
+#endif
 
-	addq	%rbp, level3_kernel_pgt + (510*8)(%rip)
-	addq	%rbp, level3_kernel_pgt + (511*8)(%rip)
+	addq	%rbp, level3_vmemmap_pgt + (L3_VMEMMAP_START*8)(%rip)
 
-	addq	%rbp, level2_fixmap_pgt + (506*8)(%rip)
+	addq	%rbp, level3_kernel_pgt + (L3_START_KERNEL*8)(%rip)
+	addq	%rbp, level3_kernel_pgt + (L3_START_KERNEL*8+8)(%rip)
 
-	/* Add an Identity mapping if I am above 1G */
-	leaq	_text(%rip), %rdi
-	andq	$PMD_PAGE_MASK, %rdi
-
-	movq	%rdi, %rax
-	shrq	$PUD_SHIFT, %rax
-	andq	$(PTRS_PER_PUD - 1), %rax
-	jz	ident_complete
-
-	leaq	(level2_spare_pgt - __START_KERNEL_map + _KERNPG_TABLE)(%rbp), %rdx
-	leaq	level3_ident_pgt(%rip), %rbx
-	movq	%rdx, 0(%rbx, %rax, 8)
-
-	movq	%rdi, %rax
-	shrq	$PMD_SHIFT, %rax
-	andq	$(PTRS_PER_PMD - 1), %rax
-	leaq	__PAGE_KERNEL_IDENT_LARGE_EXEC(%rdi), %rdx
-	leaq	level2_spare_pgt(%rip), %rbx
-	movq	%rdx, 0(%rbx, %rax, 8)
-ident_complete:
+	addq	%rbp, level2_fixmap_pgt + (504*8)(%rip)
+	addq	%rbp, level2_fixmap_pgt + (505*8)(%rip)
+	addq	%rbp, level2_fixmap_pgt + (506*8)(%rip)
+	addq	%rbp, level2_fixmap_pgt + (507*8)(%rip)
 
 	/*
 	 * Fixup the kernel text+data virtual addresses. Note that
@@ -160,8 +158,8 @@ ENTRY(secondary_startup_64)
 	 * after the boot processor executes this code.
 	 */
 
-	/* Enable PAE mode and PGE */
-	movl	$(X86_CR4_PAE | X86_CR4_PGE), %eax
+	/* Enable PAE mode and PSE/PGE */
+	movl	$(X86_CR4_PSE | X86_CR4_PAE | X86_CR4_PGE), %eax
 	movq	%rax, %cr4
 
 	/* Setup early boot stage 4 level pagetables. */
@@ -183,9 +181,20 @@ ENTRY(secondary_startup_64)
 	movl	$MSR_EFER, %ecx
 	rdmsr
 	btsl	$_EFER_SCE, %eax	/* Enable System Call */
-	btl	$20,%edi		/* No Execute supported? */
+	btl	$(X86_FEATURE_NX & 31),%edi	/* No Execute supported? */
 	jnc     1f
 	btsl	$_EFER_NX, %eax
+#ifndef CONFIG_EFI
+	btsq	$_PAGE_BIT_NX, init_level4_pgt + 8*L4_PAGE_OFFSET(%rip)
+#endif
+	btsq	$_PAGE_BIT_NX, init_level4_pgt + 8*L4_VMALLOC_START(%rip)
+	btsq	$_PAGE_BIT_NX, init_level4_pgt + 8*L4_VMALLOC_END(%rip)
+	btsq	$_PAGE_BIT_NX, init_level4_pgt + 8*L4_VMEMMAP_START(%rip)
+	btsq	$_PAGE_BIT_NX, level2_fixmap_pgt + 8*504(%rip)
+	btsq	$_PAGE_BIT_NX, level2_fixmap_pgt + 8*505(%rip)
+	btsq	$_PAGE_BIT_NX, level2_fixmap_pgt + 8*506(%rip)
+	btsq	$_PAGE_BIT_NX, level2_fixmap_pgt + 8*507(%rip)
+	btsq	$_PAGE_BIT_NX, __supported_pte_mask(%rip)
 1:	wrmsr				/* Make changes effective */
 
 	/* Setup cr0 */
@@ -247,6 +256,7 @@ ENTRY(secondary_startup_64)
 	 * jump.  In addition we need to ensure %cs is set so we make this
 	 * a far return.
 	 */
+	pax_set_fptr_mask
 	movq	initial_code(%rip),%rax
 	pushq	$0		# fake return address to stop unwinder
 	pushq	$__KERNEL_CS	# set correct cs
@@ -262,14 +272,14 @@ ENTRY(secondary_startup_64)
 	.quad	INIT_PER_CPU_VAR(irq_stack_union)
 
 	ENTRY(stack_start)
-	.quad  init_thread_union+THREAD_SIZE-8
+	.quad  init_thread_union+THREAD_SIZE-16
 	.word  0
 	__FINITDATA
 
 bad_address:
 	jmp bad_address
 
-	.section ".init.text","ax"
+	__INIT
 #ifdef CONFIG_EARLY_PRINTK
 	.globl early_idt_handlers
 early_idt_handlers:
@@ -314,18 +324,23 @@ ENTRY(early_idt_handler)
 #endif /* EARLY_PRINTK */
 1:	hlt
 	jmp 1b
+	.previous
 
 #ifdef CONFIG_EARLY_PRINTK
+	__INITDATA
 early_recursion_flag:
 	.long 0
+	.previous
 
+	.section .rodata,"a",@progbits
 early_idt_msg:
 	.asciz "PANIC: early exception %02lx rip %lx:%lx error %lx cr2 %lx\n"
 early_idt_ripmsg:
 	.asciz "RIP %s\n"
-#endif /* CONFIG_EARLY_PRINTK */
 	.previous
+#endif /* CONFIG_EARLY_PRINTK */
 
+	.section .rodata,"a",@progbits
 #define NEXT_PAGE(name) \
 	.balign	PAGE_SIZE; \
 ENTRY(name)
@@ -338,7 +353,6 @@ ENTRY(name)
 	i = i + 1 ;					\
 	.endr
 
-	.data
 	/*
 	 * This default setting generates an ident mapping at address 0x100000
 	 * and a mapping for the kernel that precisely maps virtual address
@@ -349,13 +363,41 @@ NEXT_PAGE(init_level4_pgt)
 	.quad	level3_ident_pgt - __START_KERNEL_map + _KERNPG_TABLE
 	.org	init_level4_pgt + L4_PAGE_OFFSET*8, 0
 	.quad	level3_ident_pgt - __START_KERNEL_map + _KERNPG_TABLE
+	.org	init_level4_pgt + L4_VMALLOC_START*8, 0
+	.quad	level3_vmalloc_start_pgt - __START_KERNEL_map + _KERNPG_TABLE
+	.org	init_level4_pgt + L4_VMALLOC_END*8, 0
+	.quad	level3_vmalloc_end_pgt - __START_KERNEL_map + _KERNPG_TABLE
+	.org	init_level4_pgt + L4_VMEMMAP_START*8, 0
+	.quad	level3_vmemmap_pgt - __START_KERNEL_map + _KERNPG_TABLE
 	.org	init_level4_pgt + L4_START_KERNEL*8, 0
 	/* (2^48-(2*1024*1024*1024))/(2^39) = 511 */
 	.quad	level3_kernel_pgt - __START_KERNEL_map + _PAGE_TABLE
 
+#ifdef CONFIG_PAX_PER_CPU_PGD
+NEXT_PAGE(cpu_pgd)
+	.rept NR_CPUS
+	.fill	512,8,0
+	.endr
+#endif
+
 NEXT_PAGE(level3_ident_pgt)
 	.quad	level2_ident_pgt - __START_KERNEL_map + _KERNPG_TABLE
+#ifdef CONFIG_XEN
 	.fill	511,8,0
+#else
+	.quad	level2_ident_pgt + PAGE_SIZE - __START_KERNEL_map + _KERNPG_TABLE
+	.fill	510,8,0
+#endif
+
+NEXT_PAGE(level3_vmalloc_start_pgt)
+	.fill	512,8,0
+
+NEXT_PAGE(level3_vmalloc_end_pgt)
+	.fill	512,8,0
+
+NEXT_PAGE(level3_vmemmap_pgt)
+	.fill	L3_VMEMMAP_START,8,0
+	.quad	level2_vmemmap_pgt - __START_KERNEL_map + _KERNPG_TABLE
 
 NEXT_PAGE(level3_kernel_pgt)
 	.fill	L3_START_KERNEL,8,0
@@ -363,20 +405,29 @@ NEXT_PAGE(level3_kernel_pgt)
 	.quad	level2_kernel_pgt - __START_KERNEL_map + _KERNPG_TABLE
 	.quad	level2_fixmap_pgt - __START_KERNEL_map + _PAGE_TABLE
 
+NEXT_PAGE(level2_vmemmap_pgt)
+	.fill	512,8,0
+
 NEXT_PAGE(level2_fixmap_pgt)
-	.fill	506,8,0
-	.quad	level1_fixmap_pgt - __START_KERNEL_map + _PAGE_TABLE
-	/* 8MB reserved for vsyscalls + a 2MB hole = 4 + 1 entries */
-	.fill	5,8,0
+	.fill	504,8,0
+	.quad	level1_fixmap_pgt - __START_KERNEL_map + 0 * PAGE_SIZE + _PAGE_TABLE
+	.quad	level1_fixmap_pgt - __START_KERNEL_map + 1 * PAGE_SIZE + _PAGE_TABLE
+	.quad	level1_fixmap_pgt - __START_KERNEL_map + 2 * PAGE_SIZE + _PAGE_TABLE
+	.quad	level1_vsyscall_pgt - __START_KERNEL_map + _PAGE_TABLE
+	/* 6MB reserved for vsyscalls + a 2MB hole = 3 + 1 entries */
+	.fill	4,8,0
 
 NEXT_PAGE(level1_fixmap_pgt)
+	.fill	3*512,8,0
+
+NEXT_PAGE(level1_vsyscall_pgt)
 	.fill	512,8,0
 
-NEXT_PAGE(level2_ident_pgt)
-	/* Since I easily can, map the first 1G.
+	/* Since I easily can, map the first 2G.
 	 * Don't set NX because code runs from these pages.
 	 */
-	PMDS(0, __PAGE_KERNEL_IDENT_LARGE_EXEC, PTRS_PER_PMD)
+NEXT_PAGE(level2_ident_pgt)
+	PMDS(0, __PAGE_KERNEL_IDENT_LARGE_EXEC, 2*PTRS_PER_PMD)
 
 NEXT_PAGE(level2_kernel_pgt)
 	/*
@@ -389,35 +440,56 @@ NEXT_PAGE(level2_kernel_pgt)
 	 *  If you want to increase this then increase MODULES_VADDR
 	 *  too.)
 	 */
-	PMDS(0, __PAGE_KERNEL_LARGE_EXEC,
-		KERNEL_IMAGE_SIZE/PMD_SIZE)
-
-NEXT_PAGE(level2_spare_pgt)
-	.fill   512, 8, 0
+	PMDS(0, __PAGE_KERNEL_LARGE_EXEC, KERNEL_IMAGE_SIZE/PMD_SIZE)
 
 #undef PMDS
 #undef NEXT_PAGE
 
-	.data
+	.align PAGE_SIZE
+ENTRY(cpu_gdt_table)
+	.rept NR_CPUS
+	.quad	0x0000000000000000	/* NULL descriptor */
+	.quad	0x00cf9b000000ffff	/* __KERNEL32_CS */
+	.quad	0x00af9b000000ffff	/* __KERNEL_CS */
+	.quad	0x00cf93000000ffff	/* __KERNEL_DS */
+	.quad	0x00cffb000000ffff	/* __USER32_CS */
+	.quad	0x00cff3000000ffff	/* __USER_DS, __USER32_DS  */
+	.quad	0x00affb000000ffff	/* __USER_CS */
+
+#ifdef CONFIG_PAX_KERNEXEC
+	.quad	0x00af9b000000ffff	/* __KERNEXEC_KERNEL_CS */
+#else
+	.quad	0x0			/* unused */
+#endif
+
+	.quad	0,0			/* TSS */
+	.quad	0,0			/* LDT */
+	.quad	0,0,0			/* three TLS descriptors */
+	.quad	0x0000f40000000000	/* node/CPU stored in limit */
+	/* asm/segment.h:GDT_ENTRIES must match this */
+
+	/* zero the remaining page */
+	.fill PAGE_SIZE / 8 - GDT_ENTRIES,8,0
+	.endr
+
 	.align 16
 	.globl early_gdt_descr
 early_gdt_descr:
 	.word	GDT_ENTRIES*8-1
 early_gdt_descr_base:
-	.quad	INIT_PER_CPU_VAR(gdt_page)
+	.quad	cpu_gdt_table
 
 ENTRY(phys_base)
 	/* This must match the first entry in level2_kernel_pgt */
 	.quad   0x0000000000000000
 
 #include "../../x86/xen/xen-head.S"
-	
-	.section .bss, "aw", @nobits
+
+	.section .rodata,"a",@progbits
 	.align L1_CACHE_BYTES
 ENTRY(idt_table)
-	.skip IDT_ENTRIES * 16
+	.fill 512,8,0
 
-	__PAGE_ALIGNED_BSS
 	.align PAGE_SIZE
 ENTRY(empty_zero_page)
 	.skip PAGE_SIZE
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/i386_ksyms_32.c linux-3.2.71-pax/arch/x86/kernel/i386_ksyms_32.c
--- linux-3.2.71/arch/x86/kernel/i386_ksyms_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/i386_ksyms_32.c	2012-07-04 19:24:47.572063003 +0200
@@ -20,8 +20,12 @@ extern void cmpxchg8b_emu(void);
 EXPORT_SYMBOL(cmpxchg8b_emu);
 #endif
 
+EXPORT_SYMBOL_GPL(cpu_gdt_table);
+
 /* Networking helper routines. */
 EXPORT_SYMBOL(csum_partial_copy_generic);
+EXPORT_SYMBOL(csum_partial_copy_generic_to_user);
+EXPORT_SYMBOL(csum_partial_copy_generic_from_user);
 
 EXPORT_SYMBOL(__get_user_1);
 EXPORT_SYMBOL(__get_user_2);
@@ -36,3 +40,7 @@ EXPORT_SYMBOL(strstr);
 
 EXPORT_SYMBOL(csum_partial);
 EXPORT_SYMBOL(empty_zero_page);
+
+#ifdef CONFIG_PAX_KERNEXEC
+EXPORT_SYMBOL(__LOAD_PHYSICAL_ADDR);
+#endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/i8259.c linux-3.2.71-pax/arch/x86/kernel/i8259.c
--- linux-3.2.71/arch/x86/kernel/i8259.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/i8259.c	2013-04-30 00:31:29.787758251 +0200
@@ -111,7 +111,7 @@ static int i8259A_irq_pending(unsigned i
 static void make_8259A_irq(unsigned int irq)
 {
 	disable_irq_nosync(irq);
-	io_apic_irqs &= ~(1<<irq);
+	io_apic_irqs &= ~(1UL<<irq);
 	irq_set_chip_and_handler_name(irq, &i8259A_chip, handle_level_irq,
 				      i8259A_chip.name);
 	enable_irq(irq);
@@ -210,7 +210,7 @@ spurious_8259A_irq:
 			       "spurious 8259A interrupt: IRQ%d.\n", irq);
 			spurious_irq_mask |= irqmask;
 		}
-		atomic_inc(&irq_err_count);
+		atomic_inc_unchecked(&irq_err_count);
 		/*
 		 * Theoretically we do not have to handle this IRQ,
 		 * but in Linux this does not cause problems and is
@@ -334,14 +334,16 @@ static void init_8259A(int auto_eoi)
 	/* (slave's support for AEOI in flat mode is to be investigated) */
 	outb_pic(SLAVE_ICW4_DEFAULT, PIC_SLAVE_IMR);
 
+	pax_open_kernel();
 	if (auto_eoi)
 		/*
 		 * In AEOI mode we just have to mask the interrupt
 		 * when acking.
 		 */
-		i8259A_chip.irq_mask_ack = disable_8259A_irq;
+		*(void **)&i8259A_chip.irq_mask_ack = disable_8259A_irq;
 	else
-		i8259A_chip.irq_mask_ack = mask_and_ack_8259A;
+		*(void **)&i8259A_chip.irq_mask_ack = mask_and_ack_8259A;
+	pax_close_kernel();
 
 	udelay(100);		/* wait for 8259A to initialize */
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/init_task.c linux-3.2.71-pax/arch/x86/kernel/init_task.c
--- linux-3.2.71/arch/x86/kernel/init_task.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/init_task.c	2012-07-04 19:24:47.576063004 +0200
@@ -20,8 +20,7 @@ static struct sighand_struct init_sighan
  * way process stacks are handled. This is done by having a special
  * "init_task" linker map entry..
  */
-union thread_union init_thread_union __init_task_data =
-	{ INIT_THREAD_INFO(init_task) };
+union thread_union init_thread_union __init_task_data;
 
 /*
  * Initial task structure.
@@ -38,5 +37,5 @@ EXPORT_SYMBOL(init_task);
  * section. Since TSS's are completely CPU-local, we want them
  * on exact cacheline boundaries, to eliminate cacheline ping-pong.
  */
-DEFINE_PER_CPU_SHARED_ALIGNED(struct tss_struct, init_tss) = INIT_TSS;
-
+struct tss_struct init_tss[NR_CPUS] ____cacheline_internodealigned_in_smp = { [0 ... NR_CPUS-1] = INIT_TSS };
+EXPORT_SYMBOL(init_tss);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/io_delay.c linux-3.2.71-pax/arch/x86/kernel/io_delay.c
--- linux-3.2.71/arch/x86/kernel/io_delay.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/io_delay.c	2013-03-28 01:35:23.240427951 +0100
@@ -58,7 +58,7 @@ static int __init dmi_io_delay_0xed_port
  * Quirk table for systems that misbehave (lock up, etc.) if port
  * 0x80 is used:
  */
-static struct dmi_system_id __initdata io_delay_0xed_port_dmi_table[] = {
+static const struct dmi_system_id __initconst io_delay_0xed_port_dmi_table[] = {
 	{
 		.callback	= dmi_io_delay_0xed_port,
 		.ident		= "Compaq Presario V6000",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/ioport.c linux-3.2.71-pax/arch/x86/kernel/ioport.c
--- linux-3.2.71/arch/x86/kernel/ioport.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/ioport.c	2012-07-04 19:24:47.576063004 +0200
@@ -54,7 +54,7 @@ asmlinkage long sys_ioperm(unsigned long
 	 * because the ->io_bitmap_max value must match the bitmap
 	 * contents:
 	 */
-	tss = &per_cpu(init_tss, get_cpu());
+	tss = init_tss + get_cpu();
 
 	if (turn_on)
 		bitmap_clear(t->io_bitmap_ptr, from, num);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/irq_32.c linux-3.2.71-pax/arch/x86/kernel/irq_32.c
--- linux-3.2.71/arch/x86/kernel/irq_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/irq_32.c	2012-07-04 19:24:47.576063004 +0200
@@ -36,7 +36,7 @@ static int check_stack_overflow(void)
 	__asm__ __volatile__("andl %%esp,%0" :
 			     "=r" (sp) : "0" (THREAD_SIZE - 1));
 
-	return sp < (sizeof(struct thread_info) + STACK_WARN);
+	return sp < STACK_WARN;
 }
 
 static void print_stack_overflow(void)
@@ -54,8 +54,8 @@ static inline void print_stack_overflow(
  * per-CPU IRQ handling contexts (thread information and stack)
  */
 union irq_ctx {
-	struct thread_info      tinfo;
-	u32                     stack[THREAD_SIZE/sizeof(u32)];
+	unsigned long		previous_esp;
+	u32			stack[THREAD_SIZE/sizeof(u32)];
 } __attribute__((aligned(THREAD_SIZE)));
 
 static DEFINE_PER_CPU(union irq_ctx *, hardirq_ctx);
@@ -75,10 +75,9 @@ static void call_on_stack(void *func, vo
 static inline int
 execute_on_irq_stack(int overflow, struct irq_desc *desc, int irq)
 {
-	union irq_ctx *curctx, *irqctx;
+	union irq_ctx *irqctx;
 	u32 *isp, arg1, arg2;
 
-	curctx = (union irq_ctx *) current_thread_info();
 	irqctx = __this_cpu_read(hardirq_ctx);
 
 	/*
@@ -87,21 +86,16 @@ execute_on_irq_stack(int overflow, struc
 	 * handler) we can't do that and just have to keep using the
 	 * current stack (which is the irq stack already after all)
 	 */
-	if (unlikely(curctx == irqctx))
+	if (unlikely((void *)current_stack_pointer - (void *)irqctx < THREAD_SIZE))
 		return 0;
 
 	/* build the stack frame on the IRQ stack */
-	isp = (u32 *) ((char *)irqctx + sizeof(*irqctx));
-	irqctx->tinfo.task = curctx->tinfo.task;
-	irqctx->tinfo.previous_esp = current_stack_pointer;
+	isp = (u32 *) ((char *)irqctx + sizeof(*irqctx) - 8);
+	irqctx->previous_esp = current_stack_pointer;
 
-	/*
-	 * Copy the softirq bits in preempt_count so that the
-	 * softirq checks work in the hardirq context.
-	 */
-	irqctx->tinfo.preempt_count =
-		(irqctx->tinfo.preempt_count & ~SOFTIRQ_MASK) |
-		(curctx->tinfo.preempt_count & SOFTIRQ_MASK);
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	__set_fs(MAKE_MM_SEG(0));
+#endif
 
 	if (unlikely(overflow))
 		call_on_stack(print_stack_overflow, isp);
@@ -113,6 +107,11 @@ execute_on_irq_stack(int overflow, struc
 		     :  "0" (irq),   "1" (desc),  "2" (isp),
 			"D" (desc->handle_irq)
 		     : "memory", "cc", "ecx");
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	__set_fs(current_thread_info()->addr_limit);
+#endif
+
 	return 1;
 }
 
@@ -121,29 +120,11 @@ execute_on_irq_stack(int overflow, struc
  */
 void __cpuinit irq_ctx_init(int cpu)
 {
-	union irq_ctx *irqctx;
-
 	if (per_cpu(hardirq_ctx, cpu))
 		return;
 
-	irqctx = page_address(alloc_pages_node(cpu_to_node(cpu),
-					       THREAD_FLAGS,
-					       THREAD_ORDER));
-	memset(&irqctx->tinfo, 0, sizeof(struct thread_info));
-	irqctx->tinfo.cpu		= cpu;
-	irqctx->tinfo.preempt_count	= HARDIRQ_OFFSET;
-	irqctx->tinfo.addr_limit	= MAKE_MM_SEG(0);
-
-	per_cpu(hardirq_ctx, cpu) = irqctx;
-
-	irqctx = page_address(alloc_pages_node(cpu_to_node(cpu),
-					       THREAD_FLAGS,
-					       THREAD_ORDER));
-	memset(&irqctx->tinfo, 0, sizeof(struct thread_info));
-	irqctx->tinfo.cpu		= cpu;
-	irqctx->tinfo.addr_limit	= MAKE_MM_SEG(0);
-
-	per_cpu(softirq_ctx, cpu) = irqctx;
+	per_cpu(hardirq_ctx, cpu) = page_address(alloc_pages_node(cpu_to_node(cpu), THREAD_FLAGS, THREAD_ORDER));
+	per_cpu(softirq_ctx, cpu) = page_address(alloc_pages_node(cpu_to_node(cpu), THREAD_FLAGS, THREAD_ORDER));
 
 	printk(KERN_DEBUG "CPU %u irqstacks, hard=%p soft=%p\n",
 	       cpu, per_cpu(hardirq_ctx, cpu),  per_cpu(softirq_ctx, cpu));
@@ -152,7 +133,6 @@ void __cpuinit irq_ctx_init(int cpu)
 asmlinkage void do_softirq(void)
 {
 	unsigned long flags;
-	struct thread_info *curctx;
 	union irq_ctx *irqctx;
 	u32 *isp;
 
@@ -162,15 +142,22 @@ asmlinkage void do_softirq(void)
 	local_irq_save(flags);
 
 	if (local_softirq_pending()) {
-		curctx = current_thread_info();
 		irqctx = __this_cpu_read(softirq_ctx);
-		irqctx->tinfo.task = curctx->task;
-		irqctx->tinfo.previous_esp = current_stack_pointer;
+		irqctx->previous_esp = current_stack_pointer;
 
 		/* build the stack frame on the softirq stack */
-		isp = (u32 *) ((char *)irqctx + sizeof(*irqctx));
+		isp = (u32 *) ((char *)irqctx + sizeof(*irqctx) - 8);
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+		__set_fs(MAKE_MM_SEG(0));
+#endif
 
 		call_on_stack(__do_softirq, isp);
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+		__set_fs(current_thread_info()->addr_limit);
+#endif
+
 		/*
 		 * Shouldn't happen, we returned above if in_interrupt():
 		 */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/irq_64.c linux-3.2.71-pax/arch/x86/kernel/irq_64.c
--- linux-3.2.71/arch/x86/kernel/irq_64.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/irq_64.c	2012-07-04 19:24:47.576063004 +0200
@@ -38,7 +38,7 @@ static inline void stack_overflow_check(
 #ifdef CONFIG_DEBUG_STACKOVERFLOW
 	u64 curbase = (u64)task_stack_page(current);
 
-	if (user_mode_vm(regs))
+	if (user_mode(regs))
 		return;
 
 	WARN_ONCE(regs->sp >= curbase &&
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/irq.c linux-3.2.71-pax/arch/x86/kernel/irq.c
--- linux-3.2.71/arch/x86/kernel/irq.c	2014-04-02 03:15:40.787672597 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/irq.c	2014-04-02 03:15:49.155672150 +0200
@@ -18,7 +18,7 @@
 #include <asm/mce.h>
 #include <asm/hw_irq.h>
 
-atomic_t irq_err_count;
+atomic_unchecked_t irq_err_count;
 
 /* Function pointer for generic interrupt vector handling */
 void (*x86_platform_ipi_callback)(void) = NULL;
@@ -117,9 +117,9 @@ int arch_show_interrupts(struct seq_file
 		seq_printf(p, "%10u ", per_cpu(mce_poll_count, j));
 	seq_printf(p, "  Machine check polls\n");
 #endif
-	seq_printf(p, "%*s: %10u\n", prec, "ERR", atomic_read(&irq_err_count));
+	seq_printf(p, "%*s: %10u\n", prec, "ERR", atomic_read_unchecked(&irq_err_count));
 #if defined(CONFIG_X86_IO_APIC)
-	seq_printf(p, "%*s: %10u\n", prec, "MIS", atomic_read(&irq_mis_count));
+	seq_printf(p, "%*s: %10u\n", prec, "MIS", atomic_read_unchecked(&irq_mis_count));
 #endif
 	return 0;
 }
@@ -159,7 +159,7 @@ u64 arch_irq_stat_cpu(unsigned int cpu)
 
 u64 arch_irq_stat(void)
 {
-	u64 sum = atomic_read(&irq_err_count);
+	u64 sum = atomic_read_unchecked(&irq_err_count);
 	return sum;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/kgdb.c linux-3.2.71-pax/arch/x86/kernel/kgdb.c
--- linux-3.2.71/arch/x86/kernel/kgdb.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/kgdb.c	2012-12-14 19:33:31.789559245 +0100
@@ -126,11 +126,11 @@ char *dbg_get_reg(int regno, void *mem,
 #ifdef CONFIG_X86_32
 	switch (regno) {
 	case GDB_SS:
-		if (!user_mode_vm(regs))
+		if (!user_mode(regs))
 			*(unsigned long *)mem = __KERNEL_DS;
 		break;
 	case GDB_SP:
-		if (!user_mode_vm(regs))
+		if (!user_mode(regs))
 			*(unsigned long *)mem = kernel_stack_pointer(regs);
 		break;
 	case GDB_GS:
@@ -228,7 +228,10 @@ static void kgdb_correct_hw_break(void)
 		bp->attr.bp_addr = breakinfo[breakno].addr;
 		bp->attr.bp_len = breakinfo[breakno].len;
 		bp->attr.bp_type = breakinfo[breakno].type;
-		info->address = breakinfo[breakno].addr;
+		if (breakinfo[breakno].type == X86_BREAKPOINT_EXECUTE)
+			info->address = ktla_ktva(breakinfo[breakno].addr);
+		else
+			info->address = breakinfo[breakno].addr;
 		info->len = breakinfo[breakno].len;
 		info->type = breakinfo[breakno].type;
 		val = arch_install_hw_breakpoint(bp);
@@ -475,12 +478,12 @@ int kgdb_arch_handle_exception(int e_vec
 	case 'k':
 		/* clear the trace bit */
 		linux_regs->flags &= ~X86_EFLAGS_TF;
-		atomic_set(&kgdb_cpu_doing_single_step, -1);
+		atomic_set_unchecked(&kgdb_cpu_doing_single_step, -1);
 
 		/* set the trace bit if we're stepping */
 		if (remcomInBuffer[0] == 's') {
 			linux_regs->flags |= X86_EFLAGS_TF;
-			atomic_set(&kgdb_cpu_doing_single_step,
+			atomic_set_unchecked(&kgdb_cpu_doing_single_step,
 				   raw_smp_processor_id());
 		}
 
@@ -545,7 +548,7 @@ static int __kgdb_notify(struct die_args
 
 	switch (cmd) {
 	case DIE_DEBUG:
-		if (atomic_read(&kgdb_cpu_doing_single_step) != -1) {
+		if (atomic_read_unchecked(&kgdb_cpu_doing_single_step) != -1) {
 			if (user_mode(regs))
 				return single_step_cont(regs, args);
 			break;
@@ -748,11 +751,11 @@ int kgdb_arch_set_breakpoint(struct kgdb
 	char opc[BREAK_INSTR_SIZE];
 
 	bpt->type = BP_BREAKPOINT;
-	err = probe_kernel_read(bpt->saved_instr, (char *)bpt->bpt_addr,
+	err = probe_kernel_read(bpt->saved_instr, ktla_ktva((char *)bpt->bpt_addr),
 				BREAK_INSTR_SIZE);
 	if (err)
 		return err;
-	err = probe_kernel_write((char *)bpt->bpt_addr,
+	err = probe_kernel_write(ktla_ktva((char *)bpt->bpt_addr),
 				 arch_kgdb_ops.gdb_bpt_instr, BREAK_INSTR_SIZE);
 #ifdef CONFIG_DEBUG_RODATA
 	if (!err)
@@ -765,7 +768,7 @@ int kgdb_arch_set_breakpoint(struct kgdb
 		return -EBUSY;
 	text_poke((void *)bpt->bpt_addr, arch_kgdb_ops.gdb_bpt_instr,
 		  BREAK_INSTR_SIZE);
-	err = probe_kernel_read(opc, (char *)bpt->bpt_addr, BREAK_INSTR_SIZE);
+	err = probe_kernel_read(opc, ktla_ktva((char *)bpt->bpt_addr), BREAK_INSTR_SIZE);
 	if (err)
 		return err;
 	if (memcmp(opc, arch_kgdb_ops.gdb_bpt_instr, BREAK_INSTR_SIZE))
@@ -790,13 +793,13 @@ int kgdb_arch_remove_breakpoint(struct k
 	if (mutex_is_locked(&text_mutex))
 		goto knl_write;
 	text_poke((void *)bpt->bpt_addr, bpt->saved_instr, BREAK_INSTR_SIZE);
-	err = probe_kernel_read(opc, (char *)bpt->bpt_addr, BREAK_INSTR_SIZE);
+	err = probe_kernel_read(opc, ktla_ktva((char *)bpt->bpt_addr), BREAK_INSTR_SIZE);
 	if (err || memcmp(opc, bpt->saved_instr, BREAK_INSTR_SIZE))
 		goto knl_write;
 	return err;
 knl_write:
 #endif /* CONFIG_DEBUG_RODATA */
-	return probe_kernel_write((char *)bpt->bpt_addr,
+	return probe_kernel_write(ktla_ktva((char *)bpt->bpt_addr),
 				  (char *)bpt->saved_instr, BREAK_INSTR_SIZE);
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/kprobes.c linux-3.2.71-pax/arch/x86/kernel/kprobes.c
--- linux-3.2.71/arch/x86/kernel/kprobes.c	2015-02-20 12:37:32.981178781 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/kprobes.c	2015-02-20 12:37:41.829178309 +0100
@@ -117,9 +117,12 @@ static void __kprobes __synthesize_relat
 		s32 raddr;
 	} __attribute__((packed)) *insn;
 
-	insn = (struct __arch_relative_insn *)from;
+	insn = (struct __arch_relative_insn *)ktla_ktva(from);
+
+	pax_open_kernel();
 	insn->raddr = (s32)((long)(to) - ((long)(from) + 5));
 	insn->op = op;
+	pax_close_kernel();
 }
 
 /* Insert a jump instruction at address 'from', which jumps to address 'to'.*/
@@ -156,7 +159,7 @@ static int __kprobes can_boost(kprobe_op
 	kprobe_opcode_t opcode;
 	kprobe_opcode_t *orig_opcodes = opcodes;
 
-	if (search_exception_tables((unsigned long)opcodes))
+	if (search_exception_tables(ktva_ktla((unsigned long)opcodes)))
 		return 0;	/* Page fault may occur on this address. */
 
 retry:
@@ -228,7 +231,7 @@ static int recover_probed_instruction(kp
 	 *  for the first byte, we can recover the original instruction
 	 *  from it and kp->opcode.
 	 */
-	memcpy(buf, kp->addr, MAX_INSN_SIZE * sizeof(kprobe_opcode_t));
+	memcpy(buf, ktla_ktva(kp->addr), MAX_INSN_SIZE * sizeof(kprobe_opcode_t));
 	buf[0] = kp->opcode;
 	return 0;
 }
@@ -264,7 +267,7 @@ static int __kprobes can_probe(unsigned
 				 * recover it.
 				 */
 				return 0;
-			kernel_insn_init(&insn, buf);
+			kernel_insn_init(&insn, ktva_ktla(buf));
 		}
 		insn_get_length(&insn);
 		addr += insn.length;
@@ -313,11 +316,13 @@ static int __kprobes __copy_instruction(
 							 (unsigned long)src);
 			if (ret)
 				return 0;
-			kernel_insn_init(&insn, buf);
+			kernel_insn_init(&insn, ktva_ktla(buf));
 		}
 	}
 	insn_get_length(&insn);
+	pax_open_kernel();
 	memcpy(dest, insn.kaddr, insn.length);
+	pax_close_kernel();
 
 #ifdef CONFIG_X86_64
 	if (insn_rip_relative(&insn)) {
@@ -341,7 +346,9 @@ static int __kprobes __copy_instruction(
 			  (u8 *) dest;
 		BUG_ON((s64) (s32) newdisp != newdisp); /* Sanity check.  */
 		disp = (u8 *) dest + insn_offset_displacement(&insn);
+		pax_open_kernel();
 		*(s32 *) disp = (s32) newdisp;
+		pax_close_kernel();
 	}
 #endif
 	return insn.length;
@@ -355,12 +362,12 @@ static void __kprobes arch_copy_kprobe(s
 	 */
 	__copy_instruction(p->ainsn.insn, p->addr, 0);
 
-	if (can_boost(p->addr))
+	if (can_boost(ktla_ktva(p->addr)))
 		p->ainsn.boostable = 0;
 	else
 		p->ainsn.boostable = -1;
 
-	p->opcode = *p->addr;
+	p->opcode = *(ktla_ktva(p->addr));
 }
 
 int __kprobes arch_prepare_kprobe(struct kprobe *p)
@@ -477,7 +484,7 @@ static void __kprobes setup_singlestep(s
 		 * nor set current_kprobe, because it doesn't use single
 		 * stepping.
 		 */
-		regs->ip = (unsigned long)p->ainsn.insn;
+		regs->ip = ktva_ktla((unsigned long)p->ainsn.insn);
 		preempt_enable_no_resched();
 		return;
 	}
@@ -494,9 +501,9 @@ static void __kprobes setup_singlestep(s
 	regs->flags &= ~X86_EFLAGS_IF;
 	/* single step inline if the instruction is an int3 */
 	if (p->opcode == BREAKPOINT_INSTRUCTION)
-		regs->ip = (unsigned long)p->addr;
+		regs->ip = ktla_ktva((unsigned long)p->addr);
 	else
-		regs->ip = (unsigned long)p->ainsn.insn;
+		regs->ip = ktva_ktla((unsigned long)p->ainsn.insn);
 }
 
 /*
@@ -575,7 +582,7 @@ static int __kprobes kprobe_handler(stru
 				setup_singlestep(p, regs, kcb, 0);
 			return 1;
 		}
-	} else if (*addr != BREAKPOINT_INSTRUCTION) {
+	} else if (*(kprobe_opcode_t *)ktla_ktva((unsigned long)addr) != BREAKPOINT_INSTRUCTION) {
 		/*
 		 * The breakpoint instruction was removed right
 		 * after we hit it.  Another cpu has removed
@@ -683,6 +690,9 @@ static void __used __kprobes kretprobe_t
 			"	movq %rax, 152(%rsp)\n"
 			RESTORE_REGS_STRING
 			"	popfq\n"
+#ifdef KERNEXEC_PLUGIN
+			"	btsq $63,(%rsp)\n"
+#endif
 #else
 			"	pushf\n"
 			SAVE_REGS_STRING
@@ -820,7 +830,7 @@ static void __kprobes resume_execution(s
 		struct pt_regs *regs, struct kprobe_ctlblk *kcb)
 {
 	unsigned long *tos = stack_addr(regs);
-	unsigned long copy_ip = (unsigned long)p->ainsn.insn;
+	unsigned long copy_ip = ktva_ktla((unsigned long)p->ainsn.insn);
 	unsigned long orig_ip = (unsigned long)p->addr;
 	kprobe_opcode_t *insn = p->ainsn.insn;
 
@@ -1002,7 +1012,7 @@ int __kprobes kprobe_exceptions_notify(s
 	struct die_args *args = data;
 	int ret = NOTIFY_DONE;
 
-	if (args->regs && user_mode_vm(args->regs))
+	if (args->regs && user_mode(args->regs))
 		return ret;
 
 	switch (val) {
@@ -1130,6 +1140,7 @@ static void __kprobes synthesize_relcall
 static void __kprobes synthesize_set_arg1(kprobe_opcode_t *addr,
 					  unsigned long val)
 {
+	pax_open_kernel();
 #ifdef CONFIG_X86_64
 	*addr++ = 0x48;
 	*addr++ = 0xbf;
@@ -1137,6 +1148,7 @@ static void __kprobes synthesize_set_arg
 	*addr++ = 0xb8;
 #endif
 	*(unsigned long *)addr = val;
+	pax_close_kernel();
 }
 
 static void __used __kprobes kprobes_optinsn_template_holder(void)
@@ -1317,7 +1329,7 @@ static int __kprobes can_optimize(unsign
 			ret = recover_probed_instruction(buf, addr);
 			if (ret)
 				return 0;
-			kernel_insn_init(&insn, buf);
+			kernel_insn_init(&insn, ktva_ktla(buf));
 		}
 		insn_get_length(&insn);
 		/* Recover address */
@@ -1394,7 +1406,7 @@ int __kprobes arch_prepare_optimized_kpr
 	 * Verify if the address gap is in 2GB range, because this uses
 	 * a relative jump.
 	 */
-	rel = (long)op->optinsn.insn - (long)op->kp.addr + RELATIVEJUMP_SIZE;
+	rel = (long)op->optinsn.insn - ktla_ktva((long)op->kp.addr) + RELATIVEJUMP_SIZE;
 	if (abs(rel) > 0x7fffffff)
 		return -ERANGE;
 
@@ -1409,16 +1421,18 @@ int __kprobes arch_prepare_optimized_kpr
 	op->optinsn.size = ret;
 
 	/* Copy arch-dep-instance from template */
-	memcpy(buf, &optprobe_template_entry, TMPL_END_IDX);
+	pax_open_kernel();
+	memcpy(buf, ktla_ktva(&optprobe_template_entry), TMPL_END_IDX);
+	pax_close_kernel();
 
 	/* Set probe information */
 	synthesize_set_arg1(buf + TMPL_MOVE_IDX, (unsigned long)op);
 
 	/* Set probe function call */
-	synthesize_relcall(buf + TMPL_CALL_IDX, optimized_callback);
+	synthesize_relcall(ktva_ktla(buf) + TMPL_CALL_IDX, optimized_callback);
 
 	/* Set returning jmp instruction at the tail of out-of-line buffer */
-	synthesize_reljump(buf + TMPL_END_IDX + op->optinsn.size,
+	synthesize_reljump(ktva_ktla(buf) + TMPL_END_IDX + op->optinsn.size,
 			   (u8 *)op->kp.addr + op->optinsn.size);
 
 	flush_icache_range((unsigned long) buf,
@@ -1441,7 +1455,7 @@ static void __kprobes setup_optimize_kpr
 			((long)op->kp.addr + RELATIVEJUMP_SIZE));
 
 	/* Backup instructions which will be replaced by jump address */
-	memcpy(op->optinsn.copied_insn, op->kp.addr + INT3_SIZE,
+	memcpy(op->optinsn.copied_insn, ktla_ktva(op->kp.addr) + INT3_SIZE,
 	       RELATIVE_ADDR_SIZE);
 
 	insn_buf[0] = RELATIVEJUMP_OPCODE;
@@ -1540,7 +1554,7 @@ static int  __kprobes setup_detour_execu
 		/* This kprobe is really able to run optimized path. */
 		op = container_of(p, struct optimized_kprobe, kp);
 		/* Detour through copied instructions */
-		regs->ip = (unsigned long)op->optinsn.insn + TMPL_END_IDX;
+		regs->ip = ktva_ktla((unsigned long)op->optinsn.insn) + TMPL_END_IDX;
 		if (!reenter)
 			reset_current_kprobe();
 		preempt_enable_no_resched();
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/kvm.c linux-3.2.71-pax/arch/x86/kernel/kvm.c
--- linux-3.2.71/arch/x86/kernel/kvm.c	2015-01-01 15:15:23.768069606 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/kvm.c	2015-01-01 15:15:28.868069739 +0100
@@ -444,6 +444,7 @@ static void __init paravirt_ops_setup(vo
 		pv_mmu_ops.set_pud = kvm_set_pud;
 #if PAGETABLE_LEVELS == 4
 		pv_mmu_ops.set_pgd = kvm_set_pgd;
+		pv_mmu_ops.set_pgd_batched = kvm_set_pgd;
 #endif
 #endif
 		pv_mmu_ops.flush_tlb_user = kvm_flush_tlb;
@@ -586,7 +587,7 @@ static int __cpuinit kvm_cpu_notify(stru
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata kvm_cpu_notifier = {
+static struct notifier_block kvm_cpu_notifier = {
         .notifier_call  = kvm_cpu_notify,
 };
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/ldt.c linux-3.2.71-pax/arch/x86/kernel/ldt.c
--- linux-3.2.71/arch/x86/kernel/ldt.c	2014-09-14 14:10:58.074117240 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/ldt.c	2015-06-28 00:17:44.310444512 +0200
@@ -67,13 +67,13 @@ static int alloc_ldt(mm_context_t *pc, i
 	if (reload) {
 #ifdef CONFIG_SMP
 		preempt_disable();
-		load_LDT(pc);
+		load_LDT_nolock(pc);
 		if (!cpumask_equal(mm_cpumask(current->mm),
 				   cpumask_of(smp_processor_id())))
 			smp_call_function(flush_ldt, current->mm, 1);
 		preempt_enable();
 #else
-		load_LDT(pc);
+		load_LDT_nolock(pc);
 #endif
 	}
 	if (oldsize) {
@@ -95,7 +95,7 @@ static inline int copy_ldt(mm_context_t
 		return err;
 
 	for (i = 0; i < old->size; i++)
-		write_ldt_entry(new->ldt, i, old->ldt + i * LDT_ENTRY_SIZE);
+		write_ldt_entry(new->ldt, i, old->ldt + i);
 	return 0;
 }
 
@@ -116,6 +116,24 @@ int init_new_context(struct task_struct
 		retval = copy_ldt(&mm->context, &old_mm->context);
 		mutex_unlock(&old_mm->context.lock);
 	}
+
+	if (tsk == current) {
+		mm->context.vdso = 0;
+
+#ifdef CONFIG_X86_32
+#if defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC)
+		mm->context.user_cs_base = 0UL;
+		mm->context.user_cs_limit = ~0UL;
+
+#if defined(CONFIG_PAX_PAGEEXEC) && defined(CONFIG_SMP)
+		cpumask_clear(&mm->context.cpu_user_cs_mask);
+#endif
+
+#endif
+#endif
+
+	}
+
 	return retval;
 }
 
@@ -230,6 +248,13 @@ static int write_ldt(void __user *ptr, u
 		}
 	}
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if ((mm->pax_flags & MF_PAX_SEGMEXEC) && (ldt_info.contents & MODIFY_LDT_CONTENTS_CODE)) {
+		error = -EINVAL;
+		goto out_unlock;
+	}
+#endif
+
 	if (!IS_ENABLED(CONFIG_X86_16BIT) && !ldt_info.seg_32bit) {
 		error = -EINVAL;
 		goto out_unlock;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/machine_kexec_32.c linux-3.2.71-pax/arch/x86/kernel/machine_kexec_32.c
--- linux-3.2.71/arch/x86/kernel/machine_kexec_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/machine_kexec_32.c	2012-07-04 19:24:47.580063005 +0200
@@ -27,7 +27,7 @@
 #include <asm/cacheflush.h>
 #include <asm/debugreg.h>
 
-static void set_idt(void *newidt, __u16 limit)
+static void set_idt(struct desc_struct *newidt, __u16 limit)
 {
 	struct desc_ptr curidt;
 
@@ -39,7 +39,7 @@ static void set_idt(void *newidt, __u16
 }
 
 
-static void set_gdt(void *newgdt, __u16 limit)
+static void set_gdt(struct desc_struct *newgdt, __u16 limit)
 {
 	struct desc_ptr curgdt;
 
@@ -217,7 +217,7 @@ void machine_kexec(struct kimage *image)
 	}
 
 	control_page = page_address(image->control_code_page);
-	memcpy(control_page, relocate_kernel, KEXEC_CONTROL_CODE_MAX_SIZE);
+	memcpy(control_page, (void *)ktla_ktva((unsigned long)relocate_kernel), KEXEC_CONTROL_CODE_MAX_SIZE);
 
 	relocate_kernel_ptr = control_page;
 	page_list[PA_CONTROL_PAGE] = __pa(control_page);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/microcode_core.c linux-3.2.71-pax/arch/x86/kernel/microcode_core.c
--- linux-3.2.71/arch/x86/kernel/microcode_core.c	2012-08-03 01:53:45.914140680 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/microcode_core.c	2013-02-20 01:19:15.522027342 +0100
@@ -507,7 +507,7 @@ mc_cpu_callback(struct notifier_block *n
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __refdata mc_cpu_notifier = {
+static struct notifier_block mc_cpu_notifier = {
 	.notifier_call	= mc_cpu_callback,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/microcode_intel.c linux-3.2.71-pax/arch/x86/kernel/microcode_intel.c
--- linux-3.2.71/arch/x86/kernel/microcode_intel.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/microcode_intel.c	2012-07-04 19:24:47.584063005 +0200
@@ -436,13 +436,13 @@ static enum ucode_state request_microcod
 
 static int get_ucode_user(void *to, const void *from, size_t n)
 {
-	return copy_from_user(to, from, n);
+	return copy_from_user(to, (const void __force_user *)from, n);
 }
 
 static enum ucode_state
 request_microcode_user(int cpu, const void __user *buf, size_t size)
 {
-	return generic_load_microcode(cpu, (void *)buf, size, &get_ucode_user);
+	return generic_load_microcode(cpu, (__force_kernel void *)buf, size, &get_ucode_user);
 }
 
 static void microcode_fini_cpu(int cpu)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/module.c linux-3.2.71-pax/arch/x86/kernel/module.c
--- linux-3.2.71/arch/x86/kernel/module.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/module.c	2013-11-23 18:07:03.481937068 +0100
@@ -36,15 +36,62 @@
 #define DEBUGP(fmt...)
 #endif
 
-void *module_alloc(unsigned long size)
+static inline void *__module_alloc(unsigned long size, pgprot_t prot) __size_overflow(1);
+static inline void *__module_alloc(unsigned long size, pgprot_t prot)
 {
-	if (PAGE_ALIGN(size) > MODULES_LEN)
+	if (!size || PAGE_ALIGN(size) > MODULES_LEN)
 		return NULL;
 	return __vmalloc_node_range(size, 1, MODULES_VADDR, MODULES_END,
-				GFP_KERNEL | __GFP_HIGHMEM, PAGE_KERNEL_EXEC,
+				GFP_KERNEL | __GFP_HIGHMEM | __GFP_ZERO, prot,
 				-1, __builtin_return_address(0));
 }
 
+void *module_alloc(unsigned long size)
+{
+
+#ifdef CONFIG_PAX_KERNEXEC
+	return __module_alloc(size, PAGE_KERNEL);
+#else
+	return __module_alloc(size, PAGE_KERNEL_EXEC);
+#endif
+
+}
+
+#ifdef CONFIG_PAX_KERNEXEC
+#ifdef CONFIG_X86_32
+void *module_alloc_exec(unsigned long size) __size_overflow(1);
+void *module_alloc_exec(unsigned long size)
+{
+	struct vm_struct *area;
+
+	if (size == 0)
+		return NULL;
+
+	area = __get_vm_area(size, VM_ALLOC, (unsigned long)&MODULES_EXEC_VADDR, (unsigned long)&MODULES_EXEC_END);
+	return area ? area->addr : NULL;
+}
+EXPORT_SYMBOL(module_alloc_exec);
+
+void module_free_exec(struct module *mod, void *module_region)
+{
+	vunmap(module_region);
+}
+EXPORT_SYMBOL(module_free_exec);
+#else
+void module_free_exec(struct module *mod, void *module_region)
+{
+	module_free(mod, module_region);
+}
+EXPORT_SYMBOL(module_free_exec);
+
+void *module_alloc_exec(unsigned long size)
+{
+	return __module_alloc(size, PAGE_KERNEL_RX);
+}
+EXPORT_SYMBOL(module_alloc_exec);
+#endif
+#endif
+
 #ifdef CONFIG_X86_32
 int apply_relocate(Elf32_Shdr *sechdrs,
 		   const char *strtab,
@@ -55,14 +102,16 @@ int apply_relocate(Elf32_Shdr *sechdrs,
 	unsigned int i;
 	Elf32_Rel *rel = (void *)sechdrs[relsec].sh_addr;
 	Elf32_Sym *sym;
-	uint32_t *location;
+	uint32_t *plocation, location;
 
 	DEBUGP("Applying relocate section %u to %u\n", relsec,
 	       sechdrs[relsec].sh_info);
 	for (i = 0; i < sechdrs[relsec].sh_size / sizeof(*rel); i++) {
 		/* This is where to make the change */
-		location = (void *)sechdrs[sechdrs[relsec].sh_info].sh_addr
-			+ rel[i].r_offset;
+		plocation = (void *)sechdrs[sechdrs[relsec].sh_info].sh_addr + rel[i].r_offset;
+		location = (uint32_t)plocation;
+		if (sechdrs[sechdrs[relsec].sh_info].sh_flags & SHF_EXECINSTR)
+			plocation = ktla_ktva((void *)plocation);
 		/* This is the symbol it is referring to.  Note that all
 		   undefined symbols have been resolved.  */
 		sym = (Elf32_Sym *)sechdrs[symindex].sh_addr
@@ -71,11 +120,15 @@ int apply_relocate(Elf32_Shdr *sechdrs,
 		switch (ELF32_R_TYPE(rel[i].r_info)) {
 		case R_386_32:
 			/* We add the value into the location given */
-			*location += sym->st_value;
+			pax_open_kernel();
+			*plocation += sym->st_value;
+			pax_close_kernel();
 			break;
 		case R_386_PC32:
 			/* Add the value, subtract its postition */
-			*location += sym->st_value - (uint32_t)location;
+			pax_open_kernel();
+			*plocation += sym->st_value - location;
+			pax_close_kernel();
 			break;
 		default:
 			printk(KERN_ERR "module %s: Unknown relocation: %u\n",
@@ -120,21 +173,30 @@ int apply_relocate_add(Elf64_Shdr *sechd
 		case R_X86_64_NONE:
 			break;
 		case R_X86_64_64:
+			pax_open_kernel();
 			*(u64 *)loc = val;
+			pax_close_kernel();
 			break;
 		case R_X86_64_32:
+			pax_open_kernel();
 			*(u32 *)loc = val;
+			pax_close_kernel();
 			if (val != *(u32 *)loc)
 				goto overflow;
 			break;
 		case R_X86_64_32S:
+			pax_open_kernel();
 			*(s32 *)loc = val;
+			pax_close_kernel();
 			if ((s64)val != *(s32 *)loc)
 				goto overflow;
 			break;
 		case R_X86_64_PC32:
 			val -= (u64)loc;
+			pax_open_kernel();
 			*(u32 *)loc = val;
+			pax_close_kernel();
+
 #if 0
 			if ((s64)val != *(s32 *)loc)
 				goto overflow;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/msr.c linux-3.2.71-pax/arch/x86/kernel/msr.c
--- linux-3.2.71/arch/x86/kernel/msr.c	2013-02-09 01:12:40.720782284 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/msr.c	2013-02-20 01:19:15.530027341 +0100
@@ -235,7 +235,7 @@ static int __cpuinit msr_class_cpu_callb
 	return notifier_from_errno(err);
 }
 
-static struct notifier_block __refdata msr_class_cpu_notifier = {
+static struct notifier_block msr_class_cpu_notifier = {
 	.notifier_call = msr_class_cpu_callback,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/nmi.c linux-3.2.71-pax/arch/x86/kernel/nmi.c
--- linux-3.2.71/arch/x86/kernel/nmi.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/nmi.c	2013-03-28 01:50:13.392380424 +0100
@@ -126,9 +126,9 @@ static int __setup_nmi(unsigned int type
 	 * event confuses some handlers (kdump uses this flag)
 	 */
 	if (action->flags & NMI_FLAG_FIRST)
-		list_add_rcu(&action->list, &desc->head);
+		pax_list_add_rcu((struct list_head *)&action->list, &desc->head);
 	else
-		list_add_tail_rcu(&action->list, &desc->head);
+		pax_list_add_tail_rcu((struct list_head *)&action->list, &desc->head);
 	
 	spin_unlock_irqrestore(&desc->lock, flags);
 	return 0;
@@ -150,7 +150,7 @@ static struct nmiaction *__free_nmi(unsi
 		if (!strcmp(n->name, name)) {
 			WARN(in_nmi(),
 				"Trying to free NMI (%s) from NMI context!\n", n->name);
-			list_del_rcu(&n->list);
+			pax_list_del_rcu((struct list_head *)&n->list);
 			break;
 		}
 	}
@@ -408,6 +408,17 @@ static notrace __kprobes void default_do
 dotraplinkage notrace __kprobes void
 do_nmi(struct pt_regs *regs, long error_code)
 {
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+	if (!user_mode(regs)) {
+		unsigned long cs = regs->cs & 0xFFFF;
+		unsigned long ip = ktva_ktla(regs->ip);
+
+		if ((cs == __KERNEL_CS || cs == __KERNEXEC_KERNEL_CS) && ip <= (unsigned long)_etext)
+			regs->ip = ip;
+	}
+#endif
+
 	nmi_enter();
 
 	inc_irq_stat(__nmi_count);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/paravirt.c linux-3.2.71-pax/arch/x86/kernel/paravirt.c
--- linux-3.2.71/arch/x86/kernel/paravirt.c	2013-04-30 00:45:09.439714488 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/paravirt.c	2014-05-12 18:10:33.616604872 +0200
@@ -53,6 +53,9 @@ u64 _paravirt_ident_64(u64 x)
 {
 	return x;
 }
+#if defined(CONFIG_X86_32) && defined(CONFIG_X86_PAE)
+PV_CALLEE_SAVE_REGS_THUNK(_paravirt_ident_64);
+#endif
 
 void __init default_banner(void)
 {
@@ -144,16 +147,20 @@ unsigned paravirt_patch_default(u8 type,
 
 	if (opfunc == NULL)
 		/* If there's no function, patch it with a ud2a (BUG) */
-		ret = paravirt_patch_insns(insnbuf, len, ud2a, ud2a+sizeof(ud2a));
-	else if (opfunc == _paravirt_nop)
+		ret = paravirt_patch_insns(insnbuf, len, ktva_ktla(ud2a), ud2a+sizeof(ud2a));
+	else if (opfunc == (void *)_paravirt_nop)
 		/* If the operation is a nop, then nop the callsite */
 		ret = paravirt_patch_nop();
 
 	/* identity functions just return their single argument */
-	else if (opfunc == _paravirt_ident_32)
+	else if (opfunc == (void *)_paravirt_ident_32)
 		ret = paravirt_patch_ident_32(insnbuf, len);
-	else if (opfunc == _paravirt_ident_64)
+	else if (opfunc == (void *)_paravirt_ident_64)
+		ret = paravirt_patch_ident_64(insnbuf, len);
+#if defined(CONFIG_X86_32) && defined(CONFIG_X86_PAE)
+	else if (opfunc == (void *)__raw_callee_save__paravirt_ident_64)
 		ret = paravirt_patch_ident_64(insnbuf, len);
+#endif
 
 	else if (type == PARAVIRT_PATCH(pv_cpu_ops.iret) ||
 		 type == PARAVIRT_PATCH(pv_cpu_ops.irq_enable_sysexit) ||
@@ -178,7 +185,7 @@ unsigned paravirt_patch_insns(void *insn
 	if (insn_len > len || start == NULL)
 		insn_len = len;
 	else
-		memcpy(insnbuf, start, insn_len);
+		memcpy(insnbuf, ktla_ktva(start), insn_len);
 
 	return insn_len;
 }
@@ -302,7 +309,7 @@ enum paravirt_lazy_mode paravirt_get_laz
 	return percpu_read(paravirt_lazy_mode);
 }
 
-struct pv_info pv_info = {
+struct pv_info pv_info __read_only = {
 	.name = "bare hardware",
 	.paravirt_enabled = 0,
 	.kernel_rpl = 0,
@@ -313,16 +320,16 @@ struct pv_info pv_info = {
 #endif
 };
 
-struct pv_init_ops pv_init_ops = {
+struct pv_init_ops pv_init_ops __read_only = {
 	.patch = native_patch,
 };
 
-struct pv_time_ops pv_time_ops = {
+struct pv_time_ops pv_time_ops __read_only = {
 	.sched_clock = native_sched_clock,
 	.steal_clock = native_steal_clock,
 };
 
-struct pv_irq_ops pv_irq_ops = {
+struct pv_irq_ops pv_irq_ops __read_only = {
 	.save_fl = __PV_IS_CALLEE_SAVE(native_save_fl),
 	.restore_fl = __PV_IS_CALLEE_SAVE(native_restore_fl),
 	.irq_disable = __PV_IS_CALLEE_SAVE(native_irq_disable),
@@ -334,7 +341,7 @@ struct pv_irq_ops pv_irq_ops = {
 #endif
 };
 
-struct pv_cpu_ops pv_cpu_ops = {
+struct pv_cpu_ops pv_cpu_ops __read_only = {
 	.cpuid = native_cpuid,
 	.get_debugreg = native_get_debugreg,
 	.set_debugreg = native_set_debugreg,
@@ -395,21 +402,26 @@ struct pv_cpu_ops pv_cpu_ops = {
 	.end_context_switch = paravirt_nop,
 };
 
-struct pv_apic_ops pv_apic_ops = {
+struct pv_apic_ops pv_apic_ops __read_only= {
 #ifdef CONFIG_X86_LOCAL_APIC
 	.startup_ipi_hook = paravirt_nop,
 #endif
 };
 
-#if defined(CONFIG_X86_32) && !defined(CONFIG_X86_PAE)
+#ifdef CONFIG_X86_32
+#ifdef CONFIG_X86_PAE
+/* 64-bit pagetable entries */
+#define PTE_IDENT	PV_CALLEE_SAVE(_paravirt_ident_64)
+#else
 /* 32-bit pagetable entries */
 #define PTE_IDENT	__PV_IS_CALLEE_SAVE(_paravirt_ident_32)
+#endif
 #else
 /* 64-bit pagetable entries */
 #define PTE_IDENT	__PV_IS_CALLEE_SAVE(_paravirt_ident_64)
 #endif
 
-struct pv_mmu_ops pv_mmu_ops = {
+struct pv_mmu_ops pv_mmu_ops __read_only = {
 
 	.read_cr2 = native_read_cr2,
 	.write_cr2 = native_write_cr2,
@@ -459,6 +471,7 @@ struct pv_mmu_ops pv_mmu_ops = {
 	.make_pud = PTE_IDENT,
 
 	.set_pgd = native_set_pgd,
+	.set_pgd_batched = native_set_pgd_batched,
 #endif
 #endif /* PAGETABLE_LEVELS >= 3 */
 
@@ -479,6 +492,12 @@ struct pv_mmu_ops pv_mmu_ops = {
 	},
 
 	.set_fixmap = native_set_fixmap,
+
+#ifdef CONFIG_PAX_KERNEXEC
+	.pax_open_kernel = native_pax_open_kernel,
+	.pax_close_kernel = native_pax_close_kernel,
+#endif
+
 };
 
 EXPORT_SYMBOL_GPL(pv_time_ops);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/paravirt-spinlocks.c linux-3.2.71-pax/arch/x86/kernel/paravirt-spinlocks.c
--- linux-3.2.71/arch/x86/kernel/paravirt-spinlocks.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/paravirt-spinlocks.c	2012-07-04 19:24:47.584063005 +0200
@@ -13,7 +13,7 @@ default_spin_lock_flags(arch_spinlock_t
 	arch_spin_lock(lock);
 }
 
-struct pv_lock_ops pv_lock_ops = {
+struct pv_lock_ops pv_lock_ops __read_only = {
 #ifdef CONFIG_SMP
 	.spin_is_locked = __ticket_spin_is_locked,
 	.spin_is_contended = __ticket_spin_is_contended,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/pci-calgary_64.c linux-3.2.71-pax/arch/x86/kernel/pci-calgary_64.c
--- linux-3.2.71/arch/x86/kernel/pci-calgary_64.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/pci-calgary_64.c	2013-04-30 00:31:29.975758241 +0200
@@ -1341,7 +1341,7 @@ static void __init get_tce_space_from_ta
 			tce_space = be64_to_cpu(readq(target));
 			tce_space = tce_space & TAR_SW_BITS;
 
-			tce_space = tce_space & (~specified_table_size);
+			tce_space = tce_space & (~(unsigned long)specified_table_size);
 			info->tce_space = (u64 *)__va(tce_space);
 		}
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/pci-iommu_table.c linux-3.2.71-pax/arch/x86/kernel/pci-iommu_table.c
--- linux-3.2.71/arch/x86/kernel/pci-iommu_table.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/pci-iommu_table.c	2012-07-04 19:24:47.584063005 +0200
@@ -2,7 +2,7 @@
 #include <asm/iommu_table.h>
 #include <linux/string.h>
 #include <linux/kallsyms.h>
-
+#include <linux/sched.h>
 
 #define DEBUG 1
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/process_32.c linux-3.2.71-pax/arch/x86/kernel/process_32.c
--- linux-3.2.71/arch/x86/kernel/process_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/process_32.c	2015-02-05 15:44:58.396002601 +0100
@@ -67,6 +67,7 @@ asmlinkage void ret_from_fork(void) __as
 unsigned long thread_saved_pc(struct task_struct *tsk)
 {
 	return ((unsigned long *)tsk->thread.sp)[3];
+//XXX	return tsk->thread.eip;
 }
 
 #ifndef CONFIG_SMP
@@ -130,21 +131,20 @@ void __show_regs(struct pt_regs *regs, i
 	unsigned long sp;
 	unsigned short ss, gs;
 
-	if (user_mode_vm(regs)) {
+	if (user_mode(regs)) {
 		sp = regs->sp;
 		ss = regs->ss & 0xffff;
-		gs = get_user_gs(regs);
 	} else {
 		sp = kernel_stack_pointer(regs);
 		savesegment(ss, ss);
-		savesegment(gs, gs);
 	}
+	gs = get_user_gs(regs);
 
 	show_regs_common();
 
 	printk(KERN_DEFAULT "EIP: %04x:[<%08lx>] EFLAGS: %08lx CPU: %d\n",
 			(u16)regs->cs, regs->ip, regs->flags,
-			smp_processor_id());
+			raw_smp_processor_id());
 	print_symbol("EIP is at %s\n", regs->ip);
 
 	printk(KERN_DEFAULT "EAX: %08lx EBX: %08lx ECX: %08lx EDX: %08lx\n",
@@ -200,13 +200,14 @@ int copy_thread(unsigned long clone_flag
 	struct task_struct *tsk;
 	int err;
 
-	childregs = task_pt_regs(p);
+	childregs = task_stack_page(p) + THREAD_SIZE - sizeof(struct pt_regs) - 8;
 	*childregs = *regs;
 	childregs->ax = 0;
 	childregs->sp = sp;
 
 	p->thread.sp = (unsigned long) childregs;
 	p->thread.sp0 = (unsigned long) (childregs+1);
+	p->tinfo.lowest_stack = (unsigned long)task_stack_page(p) + 2 * sizeof(unsigned long);
 
 	p->thread.ip = (unsigned long) ret_from_fork;
 
@@ -296,7 +297,7 @@ __switch_to(struct task_struct *prev_p,
 	struct thread_struct *prev = &prev_p->thread,
 				 *next = &next_p->thread;
 	int cpu = smp_processor_id();
-	struct tss_struct *tss = &per_cpu(init_tss, cpu);
+	struct tss_struct *tss = init_tss + cpu;
 	fpu_switch_t fpu;
 
 	/* never put a printk in __switch_to... printk() calls wake_up*() indirectly */
@@ -320,6 +321,10 @@ __switch_to(struct task_struct *prev_p,
 	 */
 	lazy_save_gs(prev->gs);
 
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	__set_fs(task_thread_info(next_p)->addr_limit);
+#endif
+
 	/*
 	 * Load the per-thread Thread-Local Storage descriptor.
 	 */
@@ -350,6 +355,9 @@ __switch_to(struct task_struct *prev_p,
 	 */
 	arch_end_context_switch(next_p);
 
+	percpu_write(current_task, next_p);
+	percpu_write(current_tinfo, &next_p->tinfo);
+
 	/*
 	 * Restore %gs if needed (which is common)
 	 */
@@ -358,8 +366,6 @@ __switch_to(struct task_struct *prev_p,
 
 	switch_fpu_finish(next_p, fpu);
 
-	percpu_write(current_task, next_p);
-
 	return prev_p;
 }
 
@@ -389,4 +395,3 @@ unsigned long get_wchan(struct task_stru
 	} while (count++ < 16);
 	return 0;
 }
-
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/process_64.c linux-3.2.71-pax/arch/x86/kernel/process_64.c
--- linux-3.2.71/arch/x86/kernel/process_64.c	2015-02-20 12:37:32.981178781 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/process_64.c	2015-02-20 12:37:41.829178309 +0100
@@ -89,7 +89,7 @@ static void __exit_idle(void)
 void exit_idle(void)
 {
 	/* idle loop has pid 0 */
-	if (current->pid)
+	if (task_pid_nr(current))
 		return;
 	__exit_idle();
 }
@@ -264,8 +264,7 @@ int copy_thread(unsigned long clone_flag
 	struct pt_regs *childregs;
 	struct task_struct *me = current;
 
-	childregs = ((struct pt_regs *)
-			(THREAD_SIZE + task_stack_page(p))) - 1;
+	childregs = task_stack_page(p) + THREAD_SIZE - sizeof(struct pt_regs) - 16;
 	*childregs = *regs;
 
 	childregs->ax = 0;
@@ -277,6 +276,7 @@ int copy_thread(unsigned long clone_flag
 	p->thread.sp = (unsigned long) childregs;
 	p->thread.sp0 = (unsigned long) (childregs+1);
 	p->thread.usersp = me->thread.usersp;
+	p->tinfo.lowest_stack = (unsigned long)task_stack_page(p) + 2 * sizeof(unsigned long);
 
 	set_tsk_thread_flag(p, TIF_FORK);
 
@@ -379,7 +379,7 @@ __switch_to(struct task_struct *prev_p,
 	struct thread_struct *prev = &prev_p->thread;
 	struct thread_struct *next = &next_p->thread;
 	int cpu = smp_processor_id();
-	struct tss_struct *tss = &per_cpu(init_tss, cpu);
+	struct tss_struct *tss = init_tss + cpu;
 	unsigned fsindex, gsindex;
 	fpu_switch_t fpu;
 
@@ -506,10 +506,9 @@ __switch_to(struct task_struct *prev_p,
 	prev->usersp = percpu_read(old_rsp);
 	percpu_write(old_rsp, next->usersp);
 	percpu_write(current_task, next_p);
+	percpu_write(current_tinfo, &next_p->tinfo);
 
-	percpu_write(kernel_stack,
-		  (unsigned long)task_stack_page(next_p) +
-		  THREAD_SIZE - KERNEL_STACK_OFFSET);
+	percpu_write(kernel_stack, next->sp0);
 
 	/*
 	 * Now maybe reload the debug registers and handle I/O bitmaps
@@ -564,12 +563,11 @@ unsigned long get_wchan(struct task_stru
 	if (!p || p == current || p->state == TASK_RUNNING)
 		return 0;
 	stack = (unsigned long)task_stack_page(p);
-	if (p->thread.sp < stack || p->thread.sp >= stack+THREAD_SIZE)
+	if (p->thread.sp < stack || p->thread.sp > stack+THREAD_SIZE-16-sizeof(u64))
 		return 0;
 	fp = *(u64 *)(p->thread.sp);
 	do {
-		if (fp < (unsigned long)stack ||
-		    fp >= (unsigned long)stack+THREAD_SIZE)
+		if (fp < stack || fp > stack+THREAD_SIZE-16-sizeof(u64))
 			return 0;
 		ip = *(u64 *)(fp+8);
 		if (!in_sched_functions(ip))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/process.c linux-3.2.71-pax/arch/x86/kernel/process.c
--- linux-3.2.71/arch/x86/kernel/process.c	2012-11-18 02:43:53.017506762 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/process.c	2012-11-18 02:43:58.933510958 +0100
@@ -48,16 +48,33 @@ void free_thread_xstate(struct task_stru
 
 void free_thread_info(struct thread_info *ti)
 {
-	free_thread_xstate(ti->task);
 	free_pages((unsigned long)ti, THREAD_ORDER);
 }
 
+static struct kmem_cache *task_struct_cachep;
+
 void arch_task_cache_init(void)
 {
-        task_xstate_cachep =
-        	kmem_cache_create("task_xstate", xstate_size,
+	/* create a slab on which task_structs can be allocated */
+	task_struct_cachep =
+		kmem_cache_create("task_struct", sizeof(struct task_struct),
+			ARCH_MIN_TASKALIGN, SLAB_PANIC | SLAB_NOTRACK, NULL);
+
+	task_xstate_cachep =
+		kmem_cache_create("task_xstate", xstate_size,
 				  __alignof__(union thread_xstate),
-				  SLAB_PANIC | SLAB_NOTRACK, NULL);
+				  SLAB_PANIC | SLAB_NOTRACK | SLAB_USERCOPY, NULL);
+}
+
+struct task_struct *alloc_task_struct_node(int node)
+{
+	return kmem_cache_alloc_node(task_struct_cachep, GFP_KERNEL, node);
+}
+
+void free_task_struct(struct task_struct *task)
+{
+	free_thread_xstate(task);
+	kmem_cache_free(task_struct_cachep, task);
 }
 
 /*
@@ -70,7 +87,7 @@ void exit_thread(void)
 	unsigned long *bp = t->io_bitmap_ptr;
 
 	if (bp) {
-		struct tss_struct *tss = &per_cpu(init_tss, get_cpu());
+		struct tss_struct *tss = init_tss + get_cpu();
 
 		t->io_bitmap_ptr = NULL;
 		clear_thread_flag(TIF_IO_BITMAP);
@@ -106,7 +123,7 @@ void show_regs_common(void)
 
 	printk(KERN_CONT "\n");
 	printk(KERN_DEFAULT "Pid: %d, comm: %.20s %s %s %.*s",
-		current->pid, current->comm, print_tainted(),
+		task_pid_nr(current), current->comm, print_tainted(),
 		init_utsname()->release,
 		(int)strcspn(init_utsname()->version, " "),
 		init_utsname()->version);
@@ -120,6 +137,9 @@ void flush_thread(void)
 {
 	struct task_struct *tsk = current;
 
+#if defined(CONFIG_X86_32) && !defined(CONFIG_CC_STACKPROTECTOR) && !defined(CONFIG_PAX_MEMORY_UDEREF)
+	loadsegment(gs, 0);
+#endif
 	flush_ptrace_hw_breakpoint(tsk);
 	memset(tsk->thread.tls_array, 0, sizeof(tsk->thread.tls_array));
 	/*
@@ -282,10 +302,10 @@ int kernel_thread(int (*fn)(void *), voi
 	regs.di = (unsigned long) arg;
 
 #ifdef CONFIG_X86_32
-	regs.ds = __USER_DS;
-	regs.es = __USER_DS;
+	regs.ds = __KERNEL_DS;
+	regs.es = __KERNEL_DS;
 	regs.fs = __KERNEL_PERCPU;
-	regs.gs = __KERNEL_STACK_CANARY;
+	savesegment(gs, regs.gs);
 #else
 	regs.ss = __KERNEL_DS;
 #endif
@@ -387,7 +407,7 @@ bool set_pm_idle_to_default(void)
 
 	return ret;
 }
-void stop_this_cpu(void *dummy)
+__noreturn void stop_this_cpu(void *dummy)
 {
 	local_irq_disable();
 	/*
@@ -629,16 +649,37 @@ static int __init idle_setup(char *str)
 }
 early_param("idle", idle_setup);
 
-unsigned long arch_align_stack(unsigned long sp)
+#ifdef CONFIG_PAX_RANDKSTACK
+void pax_randomize_kstack(struct pt_regs *regs)
 {
-	if (!(current->personality & ADDR_NO_RANDOMIZE) && randomize_va_space)
-		sp -= get_random_int() % 8192;
-	return sp & ~0xf;
-}
+	struct thread_struct *thread = &current->thread;
+	unsigned long time;
 
-unsigned long arch_randomize_brk(struct mm_struct *mm)
-{
-	unsigned long range_end = mm->brk + 0x02000000;
-	return randomize_range(mm->brk, range_end, 0) ? : mm->brk;
-}
+	if (!randomize_va_space)
+		return;
+
+	if (v8086_mode(regs))
+		return;
 
+	rdtscl(time);
+
+	/* P4 seems to return a 0 LSB, ignore it */
+#ifdef CONFIG_MPENTIUM4
+	time &= 0x3EUL;
+	time <<= 2;
+#elif defined(CONFIG_X86_64)
+	time &= 0xFUL;
+	time <<= 4;
+#else
+	time &= 0x1FUL;
+	time <<= 3;
+#endif
+
+	thread->sp0 ^= time;
+	load_sp0(init_tss + smp_processor_id(), thread);
+
+#ifdef CONFIG_X86_64
+	percpu_write(kernel_stack, thread->sp0);
+#endif
+}
+#endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/ptrace.c linux-3.2.71-pax/arch/x86/kernel/ptrace.c
--- linux-3.2.71/arch/x86/kernel/ptrace.c	2012-12-06 19:03:21.335215616 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/ptrace.c	2013-02-17 16:28:47.536320187 +0100
@@ -181,14 +181,13 @@ unsigned long kernel_stack_pointer(struc
 {
 	unsigned long context = (unsigned long)regs & ~(THREAD_SIZE - 1);
 	unsigned long sp = (unsigned long)&regs->sp;
-	struct thread_info *tinfo;
 
-	if (context == (sp & ~(THREAD_SIZE - 1)))
+	if (context == ((sp + 8) & ~(THREAD_SIZE - 1)))
 		return sp;
 
-	tinfo = (struct thread_info *)context;
-	if (tinfo->previous_esp)
-		return tinfo->previous_esp;
+	sp = *(unsigned long *)context;
+	if (sp)
+		return sp;
 
 	return (unsigned long)regs;
 }
@@ -585,7 +584,7 @@ static void ptrace_triggered(struct perf
 static unsigned long ptrace_get_dr7(struct perf_event *bp[])
 {
 	int i;
-	int dr7 = 0;
+	unsigned long dr7 = 0;
 	struct arch_hw_breakpoint *info;
 
 	for (i = 0; i < HBP_NUM; i++) {
@@ -852,7 +851,7 @@ long arch_ptrace(struct task_struct *chi
 		 unsigned long addr, unsigned long data)
 {
 	int ret;
-	unsigned long __user *datap = (unsigned long __user *)data;
+	unsigned long __user *datap = (__force unsigned long __user *)data;
 
 	switch (request) {
 	/* read the word at location addr in the USER area. */
@@ -937,14 +936,14 @@ long arch_ptrace(struct task_struct *chi
 		if ((int) addr < 0)
 			return -EIO;
 		ret = do_get_thread_area(child, addr,
-					(struct user_desc __user *)data);
+					(__force struct user_desc __user *) data);
 		break;
 
 	case PTRACE_SET_THREAD_AREA:
 		if ((int) addr < 0)
 			return -EIO;
 		ret = do_set_thread_area(child, addr,
-					(struct user_desc __user *)data, 0);
+					(__force struct user_desc __user *) data, 0);
 		break;
 #endif
 
@@ -1229,7 +1228,7 @@ long compat_arch_ptrace(struct task_stru
 
 #ifdef CONFIG_X86_64
 
-static struct user_regset x86_64_regsets[] __read_mostly = {
+static user_regset_no_const x86_64_regsets[] __read_only = {
 	[REGSET_GENERAL] = {
 		.core_note_type = NT_PRSTATUS,
 		.n = sizeof(struct user_regs_struct) / sizeof(long),
@@ -1273,7 +1272,7 @@ static const struct user_regset_view use
 #endif	/* CONFIG_X86_64 */
 
 #if defined CONFIG_X86_32 || defined CONFIG_IA32_EMULATION
-static struct user_regset x86_32_regsets[] __read_mostly = {
+static user_regset_no_const x86_32_regsets[] __read_only = {
 	[REGSET_GENERAL] = {
 		.core_note_type = NT_PRSTATUS,
 		.n = sizeof(struct user_regs_struct32) / sizeof(u32),
@@ -1326,7 +1325,7 @@ static const struct user_regset_view use
  */
 u64 xstate_fx_sw_bytes[USER_XSTATE_FX_SW_WORDS];
 
-void update_regset_xstate_info(unsigned int size, u64 xstate_mask)
+void __init update_regset_xstate_info(unsigned int size, u64 xstate_mask)
 {
 #ifdef CONFIG_X86_64
 	x86_64_regsets[REGSET_XSTATE].n = size / sizeof(u64);
@@ -1361,7 +1360,7 @@ static void fill_sigtrap_info(struct tas
 	memset(info, 0, sizeof(*info));
 	info->si_signo = SIGTRAP;
 	info->si_code = si_code;
-	info->si_addr = user_mode_vm(regs) ? (void __user *)regs->ip : NULL;
+	info->si_addr = user_mode(regs) ? (__force void __user *)regs->ip : NULL;
 }
 
 void user_single_step_siginfo(struct task_struct *tsk,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/pvclock.c linux-3.2.71-pax/arch/x86/kernel/pvclock.c
--- linux-3.2.71/arch/x86/kernel/pvclock.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/pvclock.c	2012-07-04 19:24:47.588063004 +0200
@@ -81,11 +81,11 @@ unsigned long pvclock_tsc_khz(struct pvc
 	return pv_tsc_khz;
 }
 
-static atomic64_t last_value = ATOMIC64_INIT(0);
+static atomic64_unchecked_t last_value = ATOMIC64_INIT(0);
 
 void pvclock_resume(void)
 {
-	atomic64_set(&last_value, 0);
+	atomic64_set_unchecked(&last_value, 0);
 }
 
 cycle_t pvclock_clocksource_read(struct pvclock_vcpu_time_info *src)
@@ -121,11 +121,11 @@ cycle_t pvclock_clocksource_read(struct
 	 * updating at the same time, and one of them could be slightly behind,
 	 * making the assumption that last_value always go forward fail to hold.
 	 */
-	last = atomic64_read(&last_value);
+	last = atomic64_read_unchecked(&last_value);
 	do {
 		if (ret < last)
 			return last;
-		last = atomic64_cmpxchg(&last_value, last, ret);
+		last = atomic64_cmpxchg_unchecked(&last_value, last, ret);
 	} while (unlikely(last != ret));
 
 	return ret;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/reboot.c linux-3.2.71-pax/arch/x86/kernel/reboot.c
--- linux-3.2.71/arch/x86/kernel/reboot.c	2015-08-07 11:37:20.379789888 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/reboot.c	2015-08-07 11:37:42.991790553 +0200
@@ -35,7 +35,7 @@ void (*pm_power_off)(void);
 EXPORT_SYMBOL(pm_power_off);
 
 static const struct desc_ptr no_idt = {};
-static int reboot_mode;
+static unsigned short reboot_mode;
 enum reboot_type reboot_type = BOOT_ACPI;
 int reboot_force;
 
@@ -145,7 +145,7 @@ static int __init set_kbd_reboot(const s
 	return 0;
 }
 
-static struct dmi_system_id __initdata reboot_dmi_table[] = {
+static const struct dmi_system_id __initconst reboot_dmi_table[] = {
 	{	/* Handle problems with rebooting on Dell E520's */
 		.callback = set_bios_reboot,
 		.ident = "Dell E520",
@@ -308,13 +308,17 @@ core_initcall(reboot_init);
 extern const unsigned char machine_real_restart_asm[];
 extern const u64 machine_real_restart_gdt[3];
 
-void machine_real_restart(unsigned int type)
+__noreturn void machine_real_restart(unsigned int type)
 {
 	void *restart_va;
 	unsigned long restart_pa;
-	void (*restart_lowmem)(unsigned int);
+	void (* __noreturn restart_lowmem)(unsigned int);
 	u64 *lowmem_gdt;
 
+#if defined(CONFIG_X86_32) && (defined(CONFIG_PAX_KERNEXEC) || defined(CONFIG_PAX_MEMORY_UDEREF))
+	struct desc_struct *gdt;
+#endif
+
 	local_irq_disable();
 
 	/* Write zero to CMOS register number 0x0f, which the BIOS POST
@@ -340,14 +344,14 @@ void machine_real_restart(unsigned int t
 	   boot)".  This seems like a fairly standard thing that gets set by
 	   REBOOT.COM programs, and the previous reset routine did this
 	   too. */
-	*((unsigned short *)0x472) = reboot_mode;
+	*(unsigned short *)(__va(0x472)) = reboot_mode;
 
 	/* Patch the GDT in the low memory trampoline */
 	lowmem_gdt = TRAMPOLINE_SYM(machine_real_restart_gdt);
 
 	restart_va = TRAMPOLINE_SYM(machine_real_restart_asm);
 	restart_pa = virt_to_phys(restart_va);
-	restart_lowmem = (void (*)(unsigned int))restart_pa;
+	restart_lowmem = (void *)restart_pa;
 
 	/* GDT[0]: GDT self-pointer */
 	lowmem_gdt[0] =
@@ -358,7 +362,35 @@ void machine_real_restart(unsigned int t
 		GDT_ENTRY(0x009b, restart_pa, 0xffff);
 
 	/* Jump to the identity-mapped low memory code */
+
+#if defined(CONFIG_X86_32) && (defined(CONFIG_PAX_KERNEXEC) || defined(CONFIG_PAX_MEMORY_UDEREF))
+	gdt = get_cpu_gdt_table(smp_processor_id());
+	pax_open_kernel();
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	gdt[GDT_ENTRY_KERNEL_DS].type = 3;
+	gdt[GDT_ENTRY_KERNEL_DS].limit = 0xf;
+	loadsegment(ds, __KERNEL_DS);
+	loadsegment(es, __KERNEL_DS);
+	loadsegment(ss, __KERNEL_DS);
+#endif
+#ifdef CONFIG_PAX_KERNEXEC
+	gdt[GDT_ENTRY_KERNEL_CS].base0 = 0;
+	gdt[GDT_ENTRY_KERNEL_CS].base1 = 0;
+	gdt[GDT_ENTRY_KERNEL_CS].base2 = 0;
+	gdt[GDT_ENTRY_KERNEL_CS].limit0 = 0xffff;
+	gdt[GDT_ENTRY_KERNEL_CS].limit = 0xf;
+	gdt[GDT_ENTRY_KERNEL_CS].g = 1;
+#endif
+	pax_close_kernel();
+#endif
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+	asm volatile("push %0; push %1; lret\n" : : "i" (__KERNEL_CS), "rm" (restart_lowmem), "a" (type));
+	unreachable();
+#else
 	restart_lowmem(type);
+#endif
+
 }
 #ifdef CONFIG_APM_MODULE
 EXPORT_SYMBOL(machine_real_restart);
@@ -590,7 +622,7 @@ void __attribute__((weak)) mach_reboot_f
  * try to force a triple fault and then cycle between hitting the keyboard
  * controller and doing that
  */
-static void native_machine_emergency_restart(void)
+static void __noreturn native_machine_emergency_restart(void)
 {
 	int i;
 	int attempt = 0;
@@ -720,13 +752,13 @@ void native_machine_shutdown(void)
 #endif
 }
 
-static void __machine_emergency_restart(int emergency)
+static __noreturn void __machine_emergency_restart(int emergency)
 {
 	reboot_emergency = emergency;
 	machine_ops.emergency_restart();
 }
 
-static void native_machine_restart(char *__unused)
+static void __noreturn native_machine_restart(char *__unused)
 {
 	printk("machine restart\n");
 
@@ -735,7 +767,7 @@ static void native_machine_restart(char
 	__machine_emergency_restart(0);
 }
 
-static void native_machine_halt(void)
+static void __noreturn native_machine_halt(void)
 {
 	/* stop other cpus and apics */
 	machine_shutdown();
@@ -746,7 +778,7 @@ static void native_machine_halt(void)
 	stop_this_cpu(NULL);
 }
 
-static void native_machine_power_off(void)
+static void __noreturn native_machine_power_off(void)
 {
 	if (pm_power_off) {
 		if (!reboot_force)
@@ -755,9 +787,10 @@ static void native_machine_power_off(voi
 	}
 	/* a fallback in case there is no PM info available */
 	tboot_shutdown(TB_SHUTDOWN_HALT);
+	unreachable();
 }
 
-struct machine_ops machine_ops = {
+struct machine_ops machine_ops __read_only = {
 	.power_off = native_machine_power_off,
 	.shutdown = native_machine_shutdown,
 	.emergency_restart = native_machine_emergency_restart,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/reboot_fixups_32.c linux-3.2.71-pax/arch/x86/kernel/reboot_fixups_32.c
--- linux-3.2.71/arch/x86/kernel/reboot_fixups_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/reboot_fixups_32.c	2013-08-17 01:58:58.388236754 +0200
@@ -57,7 +57,7 @@ struct device_fixup {
 	unsigned int vendor;
 	unsigned int device;
 	void (*reboot_fixup)(struct pci_dev *);
-};
+} __do_const;
 
 /*
  * PCI ids solely used for fixups_table go here
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/setup.c linux-3.2.71-pax/arch/x86/kernel/setup.c
--- linux-3.2.71/arch/x86/kernel/setup.c	2013-02-09 01:12:40.720782284 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/setup.c	2013-02-09 01:13:27.784783668 +0100
@@ -447,7 +447,7 @@ static void __init parse_setup_data(void
 
 		switch (data->type) {
 		case SETUP_E820_EXT:
-			parse_e820_ext(data);
+			parse_e820_ext((struct setup_data __force_kernel *)data);
 			break;
 		case SETUP_DTB:
 			add_dtb(pa_data);
@@ -727,7 +727,7 @@ static void __init trim_bios_range(void)
 	 * area (640->1Mb) as ram even though it is not.
 	 * take them out.
 	 */
-	e820_remove_range(BIOS_BEGIN, BIOS_END - BIOS_BEGIN, E820_RAM, 1);
+	e820_remove_range(ISA_START_ADDRESS, ISA_END_ADDRESS - ISA_START_ADDRESS, E820_RAM, 1);
 
 	sanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);
 }
@@ -852,14 +852,14 @@ void __init setup_arch(char **cmdline_p)
 
 	if (!boot_params.hdr.root_flags)
 		root_mountflags &= ~MS_RDONLY;
-	init_mm.start_code = (unsigned long) _text;
-	init_mm.end_code = (unsigned long) _etext;
+	init_mm.start_code = ktla_ktva((unsigned long) _text);
+	init_mm.end_code = ktla_ktva((unsigned long) _etext);
 	init_mm.end_data = (unsigned long) _edata;
 	init_mm.brk = _brk_end;
 
-	code_resource.start = virt_to_phys(_text);
-	code_resource.end = virt_to_phys(_etext)-1;
-	data_resource.start = virt_to_phys(_etext);
+	code_resource.start = virt_to_phys(ktla_ktva(_text));
+	code_resource.end = virt_to_phys(ktla_ktva(_etext))-1;
+	data_resource.start = virt_to_phys(_sdata);
 	data_resource.end = virt_to_phys(_edata)-1;
 	bss_resource.start = virt_to_phys(&__bss_start);
 	bss_resource.end = virt_to_phys(&__bss_stop)-1;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/setup_percpu.c linux-3.2.71-pax/arch/x86/kernel/setup_percpu.c
--- linux-3.2.71/arch/x86/kernel/setup_percpu.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/setup_percpu.c	2013-03-28 04:04:21.511950717 +0100
@@ -21,19 +21,17 @@
 #include <asm/cpu.h>
 #include <asm/stackprotector.h>
 
-DEFINE_PER_CPU(int, cpu_number);
+#ifdef CONFIG_SMP
+DEFINE_PER_CPU(unsigned int, cpu_number);
 EXPORT_PER_CPU_SYMBOL(cpu_number);
+#endif
 
-#ifdef CONFIG_X86_64
 #define BOOT_PERCPU_OFFSET ((unsigned long)__per_cpu_load)
-#else
-#define BOOT_PERCPU_OFFSET 0
-#endif
 
 DEFINE_PER_CPU(unsigned long, this_cpu_off) = BOOT_PERCPU_OFFSET;
 EXPORT_PER_CPU_SYMBOL(this_cpu_off);
 
-unsigned long __per_cpu_offset[NR_CPUS] __read_mostly = {
+unsigned long __per_cpu_offset[NR_CPUS] __read_only = {
 	[0 ... NR_CPUS-1] = BOOT_PERCPU_OFFSET,
 };
 EXPORT_SYMBOL(__per_cpu_offset);
@@ -66,7 +64,7 @@ static bool __init pcpu_need_numa(void)
 {
 #ifdef CONFIG_NEED_MULTIPLE_NODES
 	pg_data_t *last = NULL;
-	unsigned int cpu;
+	int cpu;
 
 	for_each_possible_cpu(cpu) {
 		int node = early_cpu_to_node(cpu);
@@ -155,10 +153,10 @@ static inline void setup_percpu_segment(
 {
 #ifdef CONFIG_X86_32
 	struct desc_struct gdt;
+	unsigned long base = per_cpu_offset(cpu);
 
-	pack_descriptor(&gdt, per_cpu_offset(cpu), 0xFFFFF,
-			0x2 | DESCTYPE_S, 0x8);
-	gdt.s = 1;
+	pack_descriptor(&gdt, base, (VMALLOC_END - base - 1) >> PAGE_SHIFT,
+			0x83 | DESCTYPE_S, 0xC);
 	write_gdt_entry(get_cpu_gdt_table(cpu),
 			GDT_ENTRY_PERCPU, &gdt, DESCTYPE_S);
 #endif
@@ -219,6 +217,11 @@ void __init setup_per_cpu_areas(void)
 	/* alrighty, percpu areas up and running */
 	delta = (unsigned long)pcpu_base_addr - (unsigned long)__per_cpu_start;
 	for_each_possible_cpu(cpu) {
+#ifdef CONFIG_CC_STACKPROTECTOR
+#ifdef CONFIG_X86_32
+		unsigned long canary = per_cpu(stack_canary.canary, cpu);
+#endif
+#endif
 		per_cpu_offset(cpu) = delta + pcpu_unit_offsets[cpu];
 		per_cpu(this_cpu_off, cpu) = per_cpu_offset(cpu);
 		per_cpu(cpu_number, cpu) = cpu;
@@ -259,6 +262,12 @@ void __init setup_per_cpu_areas(void)
 		 */
 		set_cpu_numa_node(cpu, early_cpu_to_node(cpu));
 #endif
+#ifdef CONFIG_CC_STACKPROTECTOR
+#ifdef CONFIG_X86_32
+		if (!cpu)
+			per_cpu(stack_canary.canary, cpu) = canary;
+#endif
+#endif
 		/*
 		 * Up to this point, the boot CPU has been using .init.data
 		 * area.  Reload any changed state for the boot CPU.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/signal.c linux-3.2.71-pax/arch/x86/kernel/signal.c
--- linux-3.2.71/arch/x86/kernel/signal.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/signal.c	2012-07-04 19:24:47.592063004 +0200
@@ -198,7 +198,7 @@ static unsigned long align_sigframe(unsi
 	 * Align the stack pointer according to the i386 ABI,
 	 * i.e. so that on function entry ((sp + 4) & 15) == 0.
 	 */
-	sp = ((sp + 4) & -16ul) - 4;
+	sp = ((sp - 12) & -16ul) - 4;
 #else /* !CONFIG_X86_32 */
 	sp = round_down(sp, 16) - 8;
 #endif
@@ -249,11 +249,11 @@ get_sigframe(struct k_sigaction *ka, str
 	 * Return an always-bogus address instead so we will die with SIGSEGV.
 	 */
 	if (onsigstack && !likely(on_sig_stack(sp)))
-		return (void __user *)-1L;
+		return (__force void __user *)-1L;
 
 	/* save i387 state */
 	if (used_math() && save_i387_xstate(*fpstate) < 0)
-		return (void __user *)-1L;
+		return (__force void __user *)-1L;
 
 	return (void __user *)sp;
 }
@@ -308,9 +308,9 @@ __setup_frame(int sig, struct k_sigactio
 	}
 
 	if (current->mm->context.vdso)
-		restorer = VDSO32_SYMBOL(current->mm->context.vdso, sigreturn);
+		restorer = (__force void __user *)VDSO32_SYMBOL(current->mm->context.vdso, sigreturn);
 	else
-		restorer = &frame->retcode;
+		restorer = (void __user *)&frame->retcode;
 	if (ka->sa.sa_flags & SA_RESTORER)
 		restorer = ka->sa.sa_restorer;
 
@@ -324,7 +324,7 @@ __setup_frame(int sig, struct k_sigactio
 	 * reasons and because gdb uses it as a signature to notice
 	 * signal handler stack frames.
 	 */
-	err |= __put_user(*((u64 *)&retcode), (u64 *)frame->retcode);
+	err |= __put_user(*((u64 *)&retcode), (u64 __user *)frame->retcode);
 
 	if (err)
 		return -EFAULT;
@@ -378,7 +378,10 @@ static int __setup_rt_frame(int sig, str
 		err |= __copy_to_user(&frame->uc.uc_sigmask, set, sizeof(*set));
 
 		/* Set up to return from userspace.  */
-		restorer = VDSO32_SYMBOL(current->mm->context.vdso, rt_sigreturn);
+		if (current->mm->context.vdso)
+			restorer = (__force void __user *)VDSO32_SYMBOL(current->mm->context.vdso, rt_sigreturn);
+		else
+			restorer = (void __user *)&frame->retcode;
 		if (ka->sa.sa_flags & SA_RESTORER)
 			restorer = ka->sa.sa_restorer;
 		put_user_ex(restorer, &frame->pretcode);
@@ -390,7 +393,7 @@ static int __setup_rt_frame(int sig, str
 		 * reasons and because gdb uses it as a signature to notice
 		 * signal handler stack frames.
 		 */
-		put_user_ex(*((u64 *)&rt_retcode), (u64 *)frame->retcode);
+		put_user_ex(*((u64 *)&rt_retcode), (u64 __user *)frame->retcode);
 	} put_user_catch(err);
 
 	if (err)
@@ -769,7 +772,7 @@ static void do_signal(struct pt_regs *re
 	 * X86_32: vm86 regs switched out by assembly code before reaching
 	 * here, so testing against kernel CS suffices.
 	 */
-	if (!user_mode(regs))
+	if (!user_mode_novm(regs))
 		return;
 
 	signr = get_signal_to_deliver(&info, &ka, regs, NULL);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/smpboot.c linux-3.2.71-pax/arch/x86/kernel/smpboot.c
--- linux-3.2.71/arch/x86/kernel/smpboot.c	2014-11-05 23:20:29.977389704 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/smpboot.c	2014-11-05 23:20:50.417398778 +0100
@@ -252,11 +252,13 @@ notrace static void __cpuinit start_seco
 	preempt_disable();
 	smp_callin();
 
-#ifdef CONFIG_X86_32
 	/* switch away from the initial page table */
+#ifdef CONFIG_PAX_PER_CPU_PGD
+	load_cr3(get_cpu_pgd(smp_processor_id()));
+#else
 	load_cr3(swapper_pg_dir);
-	__flush_tlb_all();
 #endif
+	__flush_tlb_all();
 
 	/* otherwise gcc will move up smp_processor_id before the cpu_init */
 	barrier();
@@ -699,7 +701,7 @@ static int __cpuinit do_boot_cpu(int api
 	 */
 	if (c_idle.idle) {
 		c_idle.idle->thread.sp = (unsigned long) (((struct pt_regs *)
-			(THREAD_SIZE +  task_stack_page(c_idle.idle))) - 1);
+			(THREAD_SIZE - 16 + task_stack_page(c_idle.idle))) - 1);
 		init_idle(c_idle.idle, cpu);
 		goto do_rest;
 	}
@@ -716,17 +718,20 @@ static int __cpuinit do_boot_cpu(int api
 	set_idle_for_cpu(cpu, c_idle.idle);
 do_rest:
 	per_cpu(current_task, cpu) = c_idle.idle;
+	per_cpu(current_tinfo, cpu) = &c_idle.idle->tinfo;
 #ifdef CONFIG_X86_32
 	/* Stack for startup_32 can be just as for start_secondary onwards */
 	irq_ctx_init(cpu);
 #else
 	clear_tsk_thread_flag(c_idle.idle, TIF_FORK);
 	initial_gs = per_cpu_offset(cpu);
-	per_cpu(kernel_stack, cpu) =
-		(unsigned long)task_stack_page(c_idle.idle) -
-		KERNEL_STACK_OFFSET + THREAD_SIZE;
+	per_cpu(kernel_stack, cpu) = (unsigned long)task_stack_page(c_idle.idle) - 16 + THREAD_SIZE;
 #endif
+
+	pax_open_kernel();
 	early_gdt_descr.address = (unsigned long)get_cpu_gdt_table(cpu);
+	pax_close_kernel();
+
 	initial_code = (unsigned long)start_secondary;
 	stack_start  = c_idle.idle->thread.sp;
 
@@ -868,6 +873,12 @@ int __cpuinit native_cpu_up(unsigned int
 
 	per_cpu(cpu_state, cpu) = CPU_UP_PREPARE;
 
+#ifdef CONFIG_PAX_PER_CPU_PGD
+	clone_pgd_range(get_cpu_pgd(cpu) + KERNEL_PGD_BOUNDARY,
+			swapper_pg_dir + KERNEL_PGD_BOUNDARY,
+			KERNEL_PGD_PTRS);
+#endif
+
 	err = do_boot_cpu(apicid, cpu);
 	if (err) {
 		pr_debug("do_boot_cpu failed %d\n", err);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/smp.c linux-3.2.71-pax/arch/x86/kernel/smp.c
--- linux-3.2.71/arch/x86/kernel/smp.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/smp.c	2013-02-17 16:31:45.280310697 +0100
@@ -225,7 +225,7 @@ void smp_call_function_single_interrupt(
 	irq_exit();
 }
 
-struct smp_ops smp_ops = {
+struct smp_ops smp_ops __read_only = {
 	.smp_prepare_boot_cpu	= native_smp_prepare_boot_cpu,
 	.smp_prepare_cpus	= native_smp_prepare_cpus,
 	.smp_cpus_done		= native_smp_cpus_done,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/step.c linux-3.2.71-pax/arch/x86/kernel/step.c
--- linux-3.2.71/arch/x86/kernel/step.c	2013-02-20 12:30:42.036171944 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/step.c	2013-02-20 12:30:46.612171700 +0100
@@ -27,10 +27,10 @@ unsigned long convert_ip_to_linear(struc
 		struct desc_struct *desc;
 		unsigned long base;
 
-		seg &= ~7UL;
+		seg >>= 3;
 
 		mutex_lock(&child->mm->context.lock);
-		if (unlikely((seg >> 3) >= child->mm->context.size))
+		if (unlikely(seg >= child->mm->context.size))
 			addr = -1L; /* bogus selector, access would fault */
 		else {
 			desc = child->mm->context.ldt + seg;
@@ -42,7 +42,8 @@ unsigned long convert_ip_to_linear(struc
 			addr += base;
 		}
 		mutex_unlock(&child->mm->context.lock);
-	}
+	} else if (seg == __KERNEL_CS || seg == __KERNEXEC_KERNEL_CS)
+		addr = ktla_ktva(addr);
 
 	return addr;
 }
@@ -53,6 +54,9 @@ static int is_setting_trap_flag(struct t
 	unsigned char opcode[15];
 	unsigned long addr = convert_ip_to_linear(child, regs);
 
+	if (addr == -EINVAL)
+		return 0;
+
 	copied = access_process_vm(child, addr, opcode, sizeof(opcode), 0);
 	for (i = 0; i < copied; i++) {
 		switch (opcode[i]) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/syscall_table_32.S linux-3.2.71-pax/arch/x86/kernel/syscall_table_32.S
--- linux-3.2.71/arch/x86/kernel/syscall_table_32.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/syscall_table_32.S	2012-07-04 19:24:47.596063005 +0200
@@ -1,3 +1,4 @@
+.section .rodata,"a",@progbits
 ENTRY(sys_call_table)
 	.long sys_restart_syscall	/* 0 - old "setup()" system call, used for restarting */
 	.long sys_exit
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/sys_i386_32.c linux-3.2.71-pax/arch/x86/kernel/sys_i386_32.c
--- linux-3.2.71/arch/x86/kernel/sys_i386_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/sys_i386_32.c	2013-07-05 02:07:55.329217445 +0200
@@ -24,17 +24,226 @@
 
 #include <asm/syscalls.h>
 
-/*
- * Do a system call from kernel instead of calling sys_execve so we
- * end up with proper pt_regs.
- */
-int kernel_execve(const char *filename,
-		  const char *const argv[],
-		  const char *const envp[])
+int i386_mmap_check(unsigned long addr, unsigned long len, unsigned long flags)
 {
-	long __res;
-	asm volatile ("int $0x80"
-	: "=a" (__res)
-	: "0" (__NR_execve), "b" (filename), "c" (argv), "d" (envp) : "memory");
-	return __res;
+	unsigned long pax_task_size = TASK_SIZE;
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (current->mm->pax_flags & MF_PAX_SEGMEXEC)
+		pax_task_size = SEGMEXEC_TASK_SIZE;
+#endif
+
+	if (flags & MAP_FIXED)
+		if (len > pax_task_size || addr > pax_task_size - len)
+			return -EINVAL;
+
+	return 0;
+}
+
+unsigned long
+arch_get_unmapped_area(struct file *filp, unsigned long addr,
+		unsigned long len, unsigned long pgoff, unsigned long flags)
+{
+	struct mm_struct *mm = current->mm;
+	struct vm_area_struct *vma;
+	unsigned long start_addr, pax_task_size = TASK_SIZE;
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (mm->pax_flags & MF_PAX_SEGMEXEC)
+		pax_task_size = SEGMEXEC_TASK_SIZE;
+#endif
+
+	pax_task_size -= PAGE_SIZE;
+
+	if (len > pax_task_size)
+		return -ENOMEM;
+
+	if (flags & MAP_FIXED)
+		return addr;
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
+	if (addr) {
+		addr = PAGE_ALIGN(addr);
+		if (pax_task_size - len >= addr) {
+			vma = find_vma(mm, addr);
+			if (check_heap_stack_gap(vma, &addr, len))
+				return addr;
+		}
+	}
+	if (len > mm->cached_hole_size) {
+		start_addr = addr = mm->free_area_cache;
+	} else {
+		start_addr = addr = mm->mmap_base;
+		mm->cached_hole_size = 0;
+	}
+
+#ifdef CONFIG_PAX_PAGEEXEC
+	if (!(__supported_pte_mask & _PAGE_NX) && (mm->pax_flags & MF_PAX_PAGEEXEC) && (flags & MAP_EXECUTABLE) && start_addr >= mm->mmap_base) {
+		start_addr = 0x00110000UL;
+
+#ifdef CONFIG_PAX_RANDMMAP
+		if (mm->pax_flags & MF_PAX_RANDMMAP)
+			start_addr += mm->delta_mmap & 0x03FFF000UL;
+#endif
+
+		if (mm->start_brk <= start_addr && start_addr < mm->mmap_base)
+			start_addr = addr = mm->mmap_base;
+		else
+			addr = start_addr;
+	}
+#endif
+
+full_search:
+	for (vma = find_vma(mm, addr); ; vma = vma->vm_next) {
+		/* At this point:  (!vma || addr < vma->vm_end). */
+		if (pax_task_size - len < addr) {
+			/*
+			 * Start a new search - just in case we missed
+			 * some holes.
+			 */
+			if (start_addr != mm->mmap_base) {
+				start_addr = addr = mm->mmap_base;
+				mm->cached_hole_size = 0;
+				goto full_search;
+			}
+			return -ENOMEM;
+		}
+		if (check_heap_stack_gap(vma, &addr, len))
+			break;
+		if (addr + mm->cached_hole_size < vma->vm_start)
+			mm->cached_hole_size = vma->vm_start - addr;
+		addr = vma->vm_end;
+		if (mm->start_brk <= addr && addr < mm->mmap_base) {
+			start_addr = addr = mm->mmap_base;
+			mm->cached_hole_size = 0;
+			goto full_search;
+		}
+	}
+
+	/*
+	 * Remember the place where we stopped the search:
+	 */
+	mm->free_area_cache = addr + len;
+	return addr;
+}
+
+unsigned long
+arch_get_unmapped_area_topdown(struct file *filp, const unsigned long addr0,
+			  const unsigned long len, const unsigned long pgoff,
+			  const unsigned long flags)
+{
+	struct vm_area_struct *vma;
+	struct mm_struct *mm = current->mm;
+	unsigned long base = mm->mmap_base, addr = addr0, pax_task_size = TASK_SIZE;
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (mm->pax_flags & MF_PAX_SEGMEXEC)
+		pax_task_size = SEGMEXEC_TASK_SIZE;
+#endif
+
+	pax_task_size -= PAGE_SIZE;
+
+	/* requested length too big for entire address space */
+	if (len > pax_task_size)
+		return -ENOMEM;
+
+	if (flags & MAP_FIXED)
+		return addr;
+
+#ifdef CONFIG_PAX_PAGEEXEC
+	if (!(__supported_pte_mask & _PAGE_NX) && (mm->pax_flags & MF_PAX_PAGEEXEC) && (flags & MAP_EXECUTABLE))
+		goto bottomup;
+#endif
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
+	/* requesting a specific address */
+	if (addr) {
+		addr = PAGE_ALIGN(addr);
+		if (pax_task_size - len >= addr) {
+			vma = find_vma(mm, addr);
+			if (check_heap_stack_gap(vma, &addr, len))
+				return addr;
+		}
+	}
+
+	/* check if free_area_cache is useful for us */
+	if (len <= mm->cached_hole_size) {
+		mm->cached_hole_size = 0;
+		mm->free_area_cache = mm->mmap_base;
+	}
+
+	/* either no address requested or can't fit in requested address hole */
+	addr = mm->free_area_cache;
+
+	/* make sure it can fit in the remaining address space */
+	if (addr > len) {
+		addr -= len;
+		vma = find_vma(mm, addr);
+		if (check_heap_stack_gap(vma, &addr, len))
+			/* remember the address as a hint for next time */
+			return (mm->free_area_cache = addr);
+	}
+
+	if (mm->mmap_base < len)
+		goto bottomup;
+
+	addr = mm->mmap_base-len;
+
+	do {
+		/*
+		 * Lookup failure means no vma is above this address,
+		 * else if new region fits below vma->vm_start,
+		 * return with success:
+		 */
+		vma = find_vma(mm, addr);
+		if (check_heap_stack_gap(vma, &addr, len))
+			/* remember the address as a hint for next time */
+			return (mm->free_area_cache = addr);
+
+		/* remember the largest hole we saw so far */
+		if (addr + mm->cached_hole_size < vma->vm_start)
+			mm->cached_hole_size = vma->vm_start - addr;
+
+		/* try just below the current vma->vm_start */
+		addr = skip_heap_stack_gap(vma, len);
+	} while (!IS_ERR_VALUE(addr));
+
+bottomup:
+	/*
+	 * A failed mmap() very likely causes application failure,
+	 * so fall back to the bottom-up function here. This scenario
+	 * can happen with large stack limits and large mmap()
+	 * allocations.
+	 */
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (mm->pax_flags & MF_PAX_SEGMEXEC)
+		mm->mmap_base = SEGMEXEC_TASK_UNMAPPED_BASE;
+	else
+#endif
+
+	mm->mmap_base = TASK_UNMAPPED_BASE;
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (mm->pax_flags & MF_PAX_RANDMMAP)
+		mm->mmap_base += mm->delta_mmap;
+#endif
+
+	mm->free_area_cache = mm->mmap_base;
+	mm->cached_hole_size = ~0UL;
+	addr = arch_get_unmapped_area(filp, addr0, len, pgoff, flags);
+	/*
+	 * Restore the topdown base:
+	 */
+	mm->mmap_base = base;
+	mm->free_area_cache = base;
+	mm->cached_hole_size = ~0UL;
+
+	return addr;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/sys_x86_64.c linux-3.2.71-pax/arch/x86/kernel/sys_x86_64.c
--- linux-3.2.71/arch/x86/kernel/sys_x86_64.c	2013-09-10 17:24:55.293739129 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/sys_x86_64.c	2013-09-10 17:31:40.993717468 +0200
@@ -95,8 +95,8 @@ out:
 	return error;
 }
 
-static void find_start_end(unsigned long flags, unsigned long *begin,
-			   unsigned long *end)
+static void find_start_end(struct mm_struct *mm, unsigned long flags,
+			   unsigned long *begin, unsigned long *end)
 {
 	if (!test_thread_flag(TIF_IA32) && (flags & MAP_32BIT)) {
 		unsigned long new_begin;
@@ -115,7 +115,7 @@ static void find_start_end(unsigned long
 				*begin = new_begin;
 		}
 	} else {
-		*begin = current->mm->mmap_legacy_base;
+		*begin = mm->mmap_legacy_base;
 		*end = TASK_SIZE;
 	}
 }
@@ -132,16 +132,19 @@ arch_get_unmapped_area(struct file *filp
 	if (flags & MAP_FIXED)
 		return addr;
 
-	find_start_end(flags, &begin, &end);
+	find_start_end(mm, flags, &begin, &end);
 
 	if (len > end)
 		return -ENOMEM;
 
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	if (addr) {
 		addr = PAGE_ALIGN(addr);
 		vma = find_vma(mm, addr);
-		if (end - len >= addr &&
-		    (!vma || addr + len <= vma->vm_start))
+		if (end - len >= addr && check_heap_stack_gap(vma, &addr, len))
 			return addr;
 	}
 	if (((flags & MAP_32BIT) || test_thread_flag(TIF_IA32))
@@ -172,7 +175,7 @@ full_search:
 			}
 			return -ENOMEM;
 		}
-		if (!vma || addr + len <= vma->vm_start) {
+		if (check_heap_stack_gap(vma, &addr, len)) {
 			/*
 			 * Remember the place where we stopped the search:
 			 */
@@ -195,7 +198,7 @@ arch_get_unmapped_area_topdown(struct fi
 {
 	struct vm_area_struct *vma;
 	struct mm_struct *mm = current->mm;
-	unsigned long addr = addr0;
+	unsigned long base = mm->mmap_base, addr = addr0;
 
 	/* requested length too big for entire address space */
 	if (len > TASK_SIZE)
@@ -208,13 +211,18 @@ arch_get_unmapped_area_topdown(struct fi
 	if (!test_thread_flag(TIF_IA32) && (flags & MAP_32BIT))
 		goto bottomup;
 
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	/* requesting a specific address */
 	if (addr) {
 		addr = PAGE_ALIGN(addr);
-		vma = find_vma(mm, addr);
-		if (TASK_SIZE - len >= addr &&
-				(!vma || addr + len <= vma->vm_start))
-			return addr;
+		if (TASK_SIZE - len >= addr) {
+			vma = find_vma(mm, addr);
+			if (check_heap_stack_gap(vma, &addr, len))
+				return addr;
+		}
 	}
 
 	/* check if free_area_cache is useful for us */
@@ -232,7 +240,7 @@ arch_get_unmapped_area_topdown(struct fi
 						    ALIGN_TOPDOWN);
 
 		vma = find_vma(mm, tmp_addr);
-		if (!vma || tmp_addr + len <= vma->vm_start)
+		if (check_heap_stack_gap(vma, &tmp_addr, len))
 			/* remember the address as a hint for next time */
 			return mm->free_area_cache = tmp_addr;
 	}
@@ -251,7 +259,7 @@ arch_get_unmapped_area_topdown(struct fi
 		 * return with success:
 		 */
 		vma = find_vma(mm, addr);
-		if (!vma || addr+len <= vma->vm_start)
+		if (check_heap_stack_gap(vma, &addr, len))
 			/* remember the address as a hint for next time */
 			return mm->free_area_cache = addr;
 
@@ -260,8 +268,8 @@ arch_get_unmapped_area_topdown(struct fi
 			mm->cached_hole_size = vma->vm_start - addr;
 
 		/* try just below the current vma->vm_start */
-		addr = vma->vm_start-len;
-	} while (len < vma->vm_start);
+		addr = skip_heap_stack_gap(vma, len);
+	} while (!IS_ERR_VALUE(addr));
 
 bottomup:
 	/*
@@ -270,13 +278,21 @@ bottomup:
 	 * can happen with large stack limits and large mmap()
 	 * allocations.
 	 */
+	mm->mmap_base = TASK_UNMAPPED_BASE;
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (mm->pax_flags & MF_PAX_RANDMMAP)
+		mm->mmap_base += mm->delta_mmap;
+#endif
+
+	mm->free_area_cache = mm->mmap_base;
 	mm->cached_hole_size = ~0UL;
-	mm->free_area_cache = TASK_UNMAPPED_BASE;
 	addr = arch_get_unmapped_area(filp, addr0, len, pgoff, flags);
 	/*
 	 * Restore the topdown base:
 	 */
-	mm->free_area_cache = mm->mmap_base;
+	mm->mmap_base = base;
+	mm->free_area_cache = base;
 	mm->cached_hole_size = ~0UL;
 
 	return addr;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/tboot.c linux-3.2.71-pax/arch/x86/kernel/tboot.c
--- linux-3.2.71/arch/x86/kernel/tboot.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/tboot.c	2014-01-28 04:21:56.121073862 +0100
@@ -219,7 +219,7 @@ static int tboot_setup_sleep(void)
 
 void tboot_shutdown(u32 shutdown_type)
 {
-	void (*shutdown)(void);
+	void (* __noreturn shutdown)(void);
 
 	if (!tboot_enabled())
 		return;
@@ -241,7 +241,7 @@ void tboot_shutdown(u32 shutdown_type)
 
 	switch_to_tboot_pt();
 
-	shutdown = (void(*)(void))(unsigned long)tboot->shutdown_entry;
+	shutdown = (void *)(unsigned long)tboot->shutdown_entry;
 	shutdown();
 
 	/* should not reach here */
@@ -298,7 +298,7 @@ void tboot_sleep(u8 sleep_state, u32 pm1
 	tboot_shutdown(acpi_shutdown_map[sleep_state]);
 }
 
-static atomic_t ap_wfs_count;
+static atomic_unchecked_t ap_wfs_count;
 
 static int tboot_wait_for_aps(int num_aps)
 {
@@ -322,16 +322,16 @@ static int __cpuinit tboot_cpu_callback(
 {
 	switch (action) {
 	case CPU_DYING:
-		atomic_inc(&ap_wfs_count);
+		atomic_inc_unchecked(&ap_wfs_count);
 		if (num_online_cpus() == 1)
-			if (tboot_wait_for_aps(atomic_read(&ap_wfs_count)))
+			if (tboot_wait_for_aps(atomic_read_unchecked(&ap_wfs_count)))
 				return NOTIFY_BAD;
 		break;
 	}
 	return NOTIFY_OK;
 }
 
-static struct notifier_block tboot_cpu_notifier __cpuinitdata =
+static struct notifier_block tboot_cpu_notifier =
 {
 	.notifier_call = tboot_cpu_callback,
 };
@@ -343,7 +343,7 @@ static __init int tboot_late_init(void)
 
 	tboot_create_trampoline();
 
-	atomic_set(&ap_wfs_count, 0);
+	atomic_set_unchecked(&ap_wfs_count, 0);
 	register_hotcpu_notifier(&tboot_cpu_notifier);
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/time.c linux-3.2.71-pax/arch/x86/kernel/time.c
--- linux-3.2.71/arch/x86/kernel/time.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/time.c	2012-07-04 19:24:47.596063005 +0200
@@ -31,9 +31,9 @@ unsigned long profile_pc(struct pt_regs
 {
 	unsigned long pc = instruction_pointer(regs);
 
-	if (!user_mode_vm(regs) && in_lock_functions(pc)) {
+	if (!user_mode(regs) && in_lock_functions(pc)) {
 #ifdef CONFIG_FRAME_POINTER
-		return *(unsigned long *)(regs->bp + sizeof(long));
+		return ktla_ktva(*(unsigned long *)(regs->bp + sizeof(long)));
 #else
 		unsigned long *sp =
 			(unsigned long *)kernel_stack_pointer(regs);
@@ -42,11 +42,17 @@ unsigned long profile_pc(struct pt_regs
 		 * or above a saved flags. Eflags has bits 22-31 zero,
 		 * kernel addresses don't.
 		 */
+
+#ifdef CONFIG_PAX_KERNEXEC
+		return ktla_ktva(sp[0]);
+#else
 		if (sp[0] >> 22)
 			return sp[0];
 		if (sp[1] >> 22)
 			return sp[1];
 #endif
+
+#endif
 	}
 	return pc;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/tls.c linux-3.2.71-pax/arch/x86/kernel/tls.c
--- linux-3.2.71/arch/x86/kernel/tls.c	2015-02-20 12:37:32.981178781 +0100
+++ linux-3.2.71-pax/arch/x86/kernel/tls.c	2015-02-20 12:37:41.829178309 +0100
@@ -140,6 +140,11 @@ int do_set_thread_area(struct task_struc
 	if (idx < GDT_ENTRY_TLS_MIN || idx > GDT_ENTRY_TLS_MAX)
 		return -EINVAL;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if ((p->mm->pax_flags & MF_PAX_SEGMEXEC) && (info.contents & MODIFY_LDT_CONTENTS_CODE))
+		return -EINVAL;
+#endif
+
 	set_tls_desc(p, idx, &info, 1);
 
 	return 0;
@@ -261,7 +266,7 @@ int regset_tls_set(struct task_struct *t
 
 	if (kbuf)
 		info = kbuf;
-	else if (__copy_from_user(infobuf, ubuf, count))
+	else if (count > sizeof infobuf || __copy_from_user(infobuf, ubuf, count))
 		return -EFAULT;
 	else
 		info = infobuf;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/trampoline_32.S linux-3.2.71-pax/arch/x86/kernel/trampoline_32.S
--- linux-3.2.71/arch/x86/kernel/trampoline_32.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/trampoline_32.S	2012-07-04 19:24:47.600063005 +0200
@@ -32,6 +32,12 @@
 #include <asm/segment.h>
 #include <asm/page_types.h>
 
+#ifdef CONFIG_PAX_KERNEXEC
+#define ta(X) (X)
+#else
+#define ta(X) ((X) - __PAGE_OFFSET)
+#endif
+
 #ifdef CONFIG_SMP
 
 	.section ".x86_trampoline","a"
@@ -62,7 +68,7 @@ r_base = .
 	inc	%ax		# protected mode (PE) bit
 	lmsw	%ax		# into protected mode
 	# flush prefetch and jump to startup_32_smp in arch/i386/kernel/head.S
-	ljmpl	$__BOOT_CS, $(startup_32_smp-__PAGE_OFFSET)
+	ljmpl	$__BOOT_CS, $ta(startup_32_smp)
 
 	# These need to be in the same 64K segment as the above;
 	# hence we don't use the boot_gdt_descr defined in head.S
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/trampoline_64.S linux-3.2.71-pax/arch/x86/kernel/trampoline_64.S
--- linux-3.2.71/arch/x86/kernel/trampoline_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/trampoline_64.S	2012-07-04 19:24:47.600063005 +0200
@@ -90,7 +90,7 @@ startup_32:
 	movl	$__KERNEL_DS, %eax	# Initialize the %ds segment register
 	movl	%eax, %ds
 
-	movl	$X86_CR4_PAE, %eax
+	movl	$(X86_CR4_PSE | X86_CR4_PAE | X86_CR4_PGE), %eax
 	movl	%eax, %cr4		# Enable PAE mode
 
 					# Setup trampoline 4 level pagetables
@@ -138,7 +138,7 @@ tidt:
 	# so the kernel can live anywhere
 	.balign 4
 tgdt:
-	.short	tgdt_end - tgdt		# gdt limit
+	.short	tgdt_end - tgdt - 1	# gdt limit
 	.long	tgdt - r_base
 	.short 0
 	.quad	0x00cf9b000000ffff	# __KERNEL32_CS
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/traps.c linux-3.2.71-pax/arch/x86/kernel/traps.c
--- linux-3.2.71/arch/x86/kernel/traps.c	2015-05-10 09:22:36.679493009 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/traps.c	2015-05-10 09:45:39.623568120 +0200
@@ -70,12 +70,6 @@ asmlinkage int system_call(void);
 
 /* Do we ignore FPU interrupts ? */
 char ignore_fpu_irq;
-
-/*
- * The IDT has to be page-aligned to simplify the Pentium
- * F0 0F bug workaround.
- */
-gate_desc idt_table[NR_VECTORS] __page_aligned_data = { { { { 0, 0 } } }, };
 #endif
 
 DECLARE_BITMAP(used_vectors, NR_VECTORS);
@@ -108,13 +102,13 @@ static inline void preempt_conditional_c
 }
 
 static void __kprobes
-do_trap(int trapnr, int signr, char *str, struct pt_regs *regs,
+do_trap(int trapnr, int signr, const char *str, struct pt_regs *regs,
 	long error_code, siginfo_t *info)
 {
 	struct task_struct *tsk = current;
 
 #ifdef CONFIG_X86_32
-	if (regs->flags & X86_VM_MASK) {
+	if (v8086_mode(regs)) {
 		/*
 		 * traps 0, 1, 3, 4, and 5 should be forwarded to vm86.
 		 * On nmi (interrupt 2), do_trap should not be called.
@@ -125,7 +119,7 @@ do_trap(int trapnr, int signr, char *str
 	}
 #endif
 
-	if (!user_mode(regs))
+	if (!user_mode_novm(regs))
 		goto kernel_trap;
 
 #ifdef CONFIG_X86_32
@@ -148,7 +142,7 @@ trap_signal:
 	    printk_ratelimit()) {
 		printk(KERN_INFO
 		       "%s[%d] trap %s ip:%lx sp:%lx error:%lx",
-		       tsk->comm, tsk->pid, str,
+		       tsk->comm, task_pid_nr(tsk), str,
 		       regs->ip, regs->sp, error_code);
 		print_vma_addr(" in ", regs->ip);
 		printk("\n");
@@ -165,8 +159,20 @@ kernel_trap:
 	if (!fixup_exception(regs)) {
 		tsk->thread.error_code = error_code;
 		tsk->thread.trap_no = trapnr;
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+		if (trapnr == X86_TRAP_SS && ((regs->cs & 0xFFFF) == __KERNEL_CS || (regs->cs & 0xFFFF) == __KERNEXEC_KERNEL_CS))
+			str = "PAX: suspicious stack segment fault";
+#endif
+
 		die(str, regs, error_code);
 	}
+
+#ifdef CONFIG_PAX_REFCOUNT
+	if (trapnr == X86_TRAP_OF)
+		pax_report_refcount_overflow(regs);
+#endif
+
 	return;
 
 #ifdef CONFIG_X86_32
@@ -271,14 +277,30 @@ do_general_protection(struct pt_regs *re
 	conditional_sti(regs);
 
 #ifdef CONFIG_X86_32
-	if (regs->flags & X86_VM_MASK)
+	if (v8086_mode(regs))
 		goto gp_in_vm86;
 #endif
 
 	tsk = current;
-	if (!user_mode(regs))
+	if (!user_mode_novm(regs))
 		goto gp_in_kernel;
 
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_PAGEEXEC)
+	if (!(__supported_pte_mask & _PAGE_NX) && tsk->mm && (tsk->mm->pax_flags & MF_PAX_PAGEEXEC)) {
+		struct mm_struct *mm = tsk->mm;
+		unsigned long limit;
+
+		down_write(&mm->mmap_sem);
+		limit = mm->context.user_cs_limit;
+		if (limit < TASK_SIZE) {
+			track_exec_limit(mm, limit, TASK_SIZE, VM_EXEC);
+			up_write(&mm->mmap_sem);
+			return;
+		}
+		up_write(&mm->mmap_sem);
+	}
+#endif
+
 	tsk->thread.error_code = error_code;
 	tsk->thread.trap_no = X86_TRAP_GP;
 
@@ -311,6 +333,13 @@ gp_in_kernel:
 	if (notify_die(DIE_GPF, "general protection fault", regs, error_code,
 			X86_TRAP_GP, SIGSEGV) == NOTIFY_STOP)
 		return;
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+	if ((regs->cs & 0xFFFF) == __KERNEL_CS || (regs->cs & 0xFFFF) == __KERNEXEC_KERNEL_CS)
+		die("PAX: suspicious general protection fault", regs, error_code);
+	else
+#endif
+
 	die("general protection fault", regs, error_code);
 }
 
@@ -383,13 +412,16 @@ struct bad_iret_stack *fixup_bad_iret(st
 		container_of(task_pt_regs(current),
 			     struct bad_iret_stack, regs);
 
+	if ((current->thread.sp0 ^ (unsigned long)s) < THREAD_SIZE)
+		new_stack = s;
+
 	/* Copy the IRET target to the new stack. */
 	memmove(&new_stack->regs.ip, (void *)s->regs.sp, 5*8);
 
 	/* Copy the remainder of the stack from the current stack. */
 	memmove(new_stack, s, offsetof(struct bad_iret_stack, regs.ip));
 
-	BUG_ON(!user_mode_vm(&new_stack->regs));
+	BUG_ON(!user_mode(&new_stack->regs));
 	return new_stack;
 }
 #endif
@@ -435,7 +467,7 @@ dotraplinkage void __kprobes do_debug(st
 	 * then it's very likely the result of an icebp/int01 trap.
 	 * User wants a sigtrap for that.
 	 */
-	if (!dr6 && user_mode_vm(regs))
+	if (!dr6 && user_mode(regs))
 		user_icebp = 1;
 
 	/* Catch kmemcheck conditions first of all! */
@@ -460,7 +492,7 @@ dotraplinkage void __kprobes do_debug(st
 	/* It's safe to allow irq's after DR6 has been saved */
 	preempt_conditional_sti(regs);
 
-	if (regs->flags & X86_VM_MASK) {
+	if (v8086_mode(regs)) {
 		handle_vm86_trap((struct kernel_vm86_regs *) regs, error_code,
 					X86_TRAP_DB);
 		preempt_conditional_cli(regs);
@@ -474,7 +506,7 @@ dotraplinkage void __kprobes do_debug(st
 	 * We already checked v86 mode above, so we can check for kernel mode
 	 * by just checking the CPL of CS.
 	 */
-	if ((dr6 & DR_STEP) && !user_mode(regs)) {
+	if ((dr6 & DR_STEP) && !user_mode_novm(regs)) {
 		tsk->thread.debugreg6 &= ~DR_STEP;
 		set_tsk_thread_flag(tsk, TIF_SINGLESTEP);
 		regs->flags &= ~X86_EFLAGS_TF;
@@ -504,7 +536,7 @@ void math_error(struct pt_regs *regs, in
 		return;
 	conditional_sti(regs);
 
-	if (!user_mode_vm(regs))
+	if (!user_mode(regs))
 	{
 		if (!fixup_exception(regs)) {
 			task->thread.error_code = error_code;
@@ -617,8 +649,8 @@ asmlinkage void __attribute__((weak)) sm
 void __math_state_restore(struct task_struct *tsk)
 {
 	/* We need a safe address that is cheap to find and that is already
-	   in L1. We've just brought in "tsk->thread.has_fpu", so use that */
-#define safe_address (tsk->thread.has_fpu)
+	   in L1. */
+#define safe_address (init_tss[raw_smp_processor_id()].x86_tss.sp0)
 
 	/* AMD K7/K8 CPUs don't save/restore FDP/FIP/FOP unless an exception
 	   is pending.  Clear the x87 state here by setting it to fixed
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/vm86_32.c linux-3.2.71-pax/arch/x86/kernel/vm86_32.c
--- linux-3.2.71/arch/x86/kernel/vm86_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/vm86_32.c	2012-07-04 19:24:47.600063005 +0200
@@ -148,7 +148,7 @@ struct pt_regs *save_v86_state(struct ke
 		do_exit(SIGSEGV);
 	}
 
-	tss = &per_cpu(init_tss, get_cpu());
+	tss = init_tss + get_cpu();
 	current->thread.sp0 = current->thread.saved_sp0;
 	current->thread.sysenter_cs = __KERNEL_CS;
 	load_sp0(tss, &current->thread);
@@ -326,7 +326,7 @@ static void do_sys_vm86(struct kernel_vm
 	tsk->thread.saved_fs = info->regs32->fs;
 	tsk->thread.saved_gs = get_user_gs(info->regs32);
 
-	tss = &per_cpu(init_tss, get_cpu());
+	tss = init_tss + get_cpu();
 	tsk->thread.sp0 = (unsigned long) &info->VM86_TSS_ESP0;
 	if (cpu_has_sep)
 		tsk->thread.sysenter_cs = 0;
@@ -531,7 +531,7 @@ static void do_int(struct kernel_vm86_re
 		goto cannot_handle;
 	if (i == 0x21 && is_revectored(AH(regs), &KVM86->int21_revectored))
 		goto cannot_handle;
-	intr_ptr = (unsigned long __user *) (i << 2);
+	intr_ptr = (__force unsigned long __user *) (i << 2);
 	if (get_user(segoffs, intr_ptr))
 		goto cannot_handle;
 	if ((segoffs >> 16) == BIOSSEG)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/vmlinux.lds.S linux-3.2.71-pax/arch/x86/kernel/vmlinux.lds.S
--- linux-3.2.71/arch/x86/kernel/vmlinux.lds.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/vmlinux.lds.S	2015-02-20 12:12:48.729258029 +0100
@@ -26,6 +26,13 @@
 #include <asm/page_types.h>
 #include <asm/cache.h>
 #include <asm/boot.h>
+#include <asm/segment.h>
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+#define __KERNEL_TEXT_OFFSET	(LOAD_OFFSET + ____LOAD_PHYSICAL_ADDR)
+#else
+#define __KERNEL_TEXT_OFFSET	0
+#endif
 
 #undef i386     /* in case the preprocessor is a 32bit one */
 
@@ -69,30 +76,43 @@ jiffies_64 = jiffies;
 
 PHDRS {
 	text PT_LOAD FLAGS(5);          /* R_E */
+#ifdef CONFIG_X86_32
+	module PT_LOAD FLAGS(5);        /* R_E */
+#endif
+#ifdef CONFIG_XEN
+	rodata PT_LOAD FLAGS(5);        /* R_E */
+#else
+	rodata PT_LOAD FLAGS(4);        /* R__ */
+#endif
 	data PT_LOAD FLAGS(6);          /* RW_ */
-#ifdef CONFIG_X86_64
+	init.begin PT_LOAD FLAGS(6);    /* RW_ */
 #ifdef CONFIG_SMP
 	percpu PT_LOAD FLAGS(6);        /* RW_ */
 #endif
+	text.init PT_LOAD FLAGS(5);     /* R_E */
+	text.exit PT_LOAD FLAGS(5);     /* R_E */
 	init PT_LOAD FLAGS(7);          /* RWE */
-#endif
 	note PT_NOTE FLAGS(0);          /* ___ */
 }
 
 SECTIONS
 {
 #ifdef CONFIG_X86_32
-        . = LOAD_OFFSET + LOAD_PHYSICAL_ADDR;
-        phys_startup_32 = startup_32 - LOAD_OFFSET;
+	. = LOAD_OFFSET + ____LOAD_PHYSICAL_ADDR;
 #else
-        . = __START_KERNEL;
-        phys_startup_64 = startup_64 - LOAD_OFFSET;
+	. = __START_KERNEL;
 #endif
 
 	/* Text and read-only data */
-	.text :  AT(ADDR(.text) - LOAD_OFFSET) {
-		_text = .;
+	.text (. - __KERNEL_TEXT_OFFSET): AT(ADDR(.text) - LOAD_OFFSET + __KERNEL_TEXT_OFFSET) {
 		/* bootstrapping code */
+#ifdef CONFIG_X86_32
+		phys_startup_32 = startup_32 - LOAD_OFFSET + __KERNEL_TEXT_OFFSET;
+#else
+		phys_startup_64 = startup_64 - LOAD_OFFSET + __KERNEL_TEXT_OFFSET;
+#endif
+		__LOAD_PHYSICAL_ADDR = . - LOAD_OFFSET + __KERNEL_TEXT_OFFSET;
+		_text = .;
 		HEAD_TEXT
 #ifdef CONFIG_X86_32
 		. = ALIGN(PAGE_SIZE);
@@ -108,13 +128,48 @@ SECTIONS
 		IRQENTRY_TEXT
 		*(.fixup)
 		*(.gnu.warning)
-		/* End of text section */
-		_etext = .;
 	} :text = 0x9090
 
-	NOTES :text :note
+	. += __KERNEL_TEXT_OFFSET;
+
+#ifdef CONFIG_X86_32
+	. = ALIGN(PAGE_SIZE);
+	.module.text : AT(ADDR(.module.text) - LOAD_OFFSET) {
+
+#ifdef CONFIG_PAX_KERNEXEC
+		MODULES_EXEC_VADDR = .;
+		BYTE(0)
+		. += (CONFIG_PAX_KERNEXEC_MODULE_TEXT * 1024 * 1024);
+		. = ALIGN(HPAGE_SIZE) - 1;
+		MODULES_EXEC_END = .;
+#endif
+
+	} :module
+#endif
+
+	.text.end : AT(ADDR(.text.end) - LOAD_OFFSET) {
+		/* End of text section */
+		BYTE(0)
+		_etext = . - __KERNEL_TEXT_OFFSET;
+	}
+
+#ifdef CONFIG_X86_32
+	. = ALIGN(PAGE_SIZE);
+	.rodata.page_aligned : AT(ADDR(.rodata.page_aligned) - LOAD_OFFSET) {
+		*(.idt)
+		. = ALIGN(PAGE_SIZE);
+		*(.empty_zero_page)
+		*(.initial_pg_fixmap)
+		*(.initial_pg_pmd)
+		*(.initial_page_table)
+		*(.swapper_pg_dir)
+	} :rodata
+#endif
+
+	. = ALIGN(PAGE_SIZE);
+	NOTES :rodata :note
 
-	EXCEPTION_TABLE(16) :text = 0x9090
+	EXCEPTION_TABLE(16) :rodata
 
 #if defined(CONFIG_DEBUG_RODATA)
 	/* .text should occupy whole number of pages */
@@ -126,16 +181,20 @@ SECTIONS
 
 	/* Data */
 	.data : AT(ADDR(.data) - LOAD_OFFSET) {
+
+#ifdef CONFIG_PAX_KERNEXEC
+		. = ALIGN(HPAGE_SIZE);
+#else
+		. = ALIGN(PAGE_SIZE);
+#endif
+
 		/* Start of data section */
 		_sdata = .;
 
 		/* init_task */
 		INIT_TASK_DATA(THREAD_SIZE)
 
-#ifdef CONFIG_X86_32
-		/* 32 bit has nosave before _edata */
 		NOSAVE_DATA
-#endif
 
 		PAGE_ALIGNED_DATA(PAGE_SIZE)
 
@@ -176,12 +235,19 @@ SECTIONS
 #endif /* CONFIG_X86_64 */
 
 	/* Init code and data - will be freed after init */
-	. = ALIGN(PAGE_SIZE);
 	.init.begin : AT(ADDR(.init.begin) - LOAD_OFFSET) {
+		BYTE(0)
+
+#ifdef CONFIG_PAX_KERNEXEC
+		. = ALIGN(HPAGE_SIZE);
+#else
+		. = ALIGN(PAGE_SIZE);
+#endif
+
 		__init_begin = .; /* paired with __init_end */
-	}
+	} :init.begin
 
-#if defined(CONFIG_X86_64) && defined(CONFIG_SMP)
+#ifdef CONFIG_SMP
 	/*
 	 * percpu offsets are zero-based on SMP.  PERCPU_VADDR() changes the
 	 * output PHDR, so the next output section - .init.text - should
@@ -190,12 +256,27 @@ SECTIONS
 	PERCPU_VADDR(INTERNODE_CACHE_BYTES, 0, :percpu)
 #endif
 
-	INIT_TEXT_SECTION(PAGE_SIZE)
-#ifdef CONFIG_X86_64
-	:init
-#endif
+	. = ALIGN(PAGE_SIZE);
+	init_begin = .;
+	.init.text (. - __KERNEL_TEXT_OFFSET): AT(init_begin - LOAD_OFFSET) {
+		VMLINUX_SYMBOL(_sinittext) = .;
+		INIT_TEXT
+		. = ALIGN(PAGE_SIZE);
+	} :text.init
 
-	INIT_DATA_SECTION(16)
+	/*
+	 * .exit.text is discard at runtime, not link time, to deal with
+	 *  references from .altinstructions and .eh_frame
+	 */
+	.exit.text : AT(ADDR(.exit.text) - LOAD_OFFSET + __KERNEL_TEXT_OFFSET) {
+		EXIT_TEXT
+		VMLINUX_SYMBOL(_einittext) = .;
+		. = ALIGN(16);
+	} :text.exit
+	. = init_begin + SIZEOF(.init.text) + SIZEOF(.exit.text);
+
+	. = ALIGN(PAGE_SIZE);
+	INIT_DATA_SECTION(16) :init
 
 	/*
 	 * Code and data for a variety of lowlevel trampolines, to be
@@ -269,19 +350,12 @@ SECTIONS
 	}
 
 	. = ALIGN(8);
-	/*
-	 * .exit.text is discard at runtime, not link time, to deal with
-	 *  references from .altinstructions and .eh_frame
-	 */
-	.exit.text : AT(ADDR(.exit.text) - LOAD_OFFSET) {
-		EXIT_TEXT
-	}
 
 	.exit.data : AT(ADDR(.exit.data) - LOAD_OFFSET) {
 		EXIT_DATA
 	}
 
-#if !defined(CONFIG_X86_64) || !defined(CONFIG_SMP)
+#ifndef CONFIG_SMP
 	PERCPU_SECTION(INTERNODE_CACHE_BYTES)
 #endif
 
@@ -300,16 +374,10 @@ SECTIONS
 	.smp_locks : AT(ADDR(.smp_locks) - LOAD_OFFSET) {
 		__smp_locks = .;
 		*(.smp_locks)
-		. = ALIGN(PAGE_SIZE);
 		__smp_locks_end = .;
+		. = ALIGN(PAGE_SIZE);
 	}
 
-#ifdef CONFIG_X86_64
-	.data_nosave : AT(ADDR(.data_nosave) - LOAD_OFFSET) {
-		NOSAVE_DATA
-	}
-#endif
-
 	/* BSS */
 	. = ALIGN(PAGE_SIZE);
 	.bss : AT(ADDR(.bss) - LOAD_OFFSET) {
@@ -325,6 +393,7 @@ SECTIONS
 		__brk_base = .;
 		. += 64 * 1024;		/* 64k alignment slop space */
 		*(.brk_reservation)	/* areas brk users have reserved */
+		. = ALIGN(HPAGE_SIZE);
 		__brk_limit = .;
 	}
 
@@ -351,13 +420,12 @@ SECTIONS
  * for the boot processor.
  */
 #define INIT_PER_CPU(x) init_per_cpu__##x = x + __per_cpu_load
-INIT_PER_CPU(gdt_page);
 INIT_PER_CPU(irq_stack_union);
 
 /*
  * Build-time check on the image size:
  */
-. = ASSERT((_end - _text <= KERNEL_IMAGE_SIZE),
+. = ASSERT((_end - _text - __KERNEL_TEXT_OFFSET <= KERNEL_IMAGE_SIZE),
 	   "kernel image bigger than KERNEL_IMAGE_SIZE");
 
 #ifdef CONFIG_SMP
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/vsyscall_64.c linux-3.2.71-pax/arch/x86/kernel/vsyscall_64.c
--- linux-3.2.71/arch/x86/kernel/vsyscall_64.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/vsyscall_64.c	2012-07-04 19:24:47.604063004 +0200
@@ -57,15 +57,13 @@ DEFINE_VVAR(struct vsyscall_gtod_data, v
 	.lock = __SEQLOCK_UNLOCKED(__vsyscall_gtod_data.lock),
 };
 
-static enum { EMULATE, NATIVE, NONE } vsyscall_mode = NATIVE;
+static enum { EMULATE, NONE } vsyscall_mode = EMULATE;
 
 static int __init vsyscall_setup(char *str)
 {
 	if (str) {
 		if (!strcmp("emulate", str))
 			vsyscall_mode = EMULATE;
-		else if (!strcmp("native", str))
-			vsyscall_mode = NATIVE;
 		else if (!strcmp("none", str))
 			vsyscall_mode = NONE;
 		else
@@ -178,7 +176,7 @@ bool emulate_vsyscall(struct pt_regs *re
 
 	tsk = current;
 	if (seccomp_mode(&tsk->seccomp))
-		do_exit(SIGKILL);
+		do_group_exit(SIGKILL);
 
 	switch (vsyscall_nr) {
 	case 0:
@@ -220,8 +218,7 @@ bool emulate_vsyscall(struct pt_regs *re
 	return true;
 
 sigsegv:
-	force_sig(SIGSEGV, current);
-	return true;
+	do_group_exit(SIGKILL);
 }
 
 /*
@@ -274,10 +271,7 @@ void __init map_vsyscall(void)
 	extern char __vvar_page;
 	unsigned long physaddr_vvar_page = __pa_symbol(&__vvar_page);
 
-	__set_fixmap(VSYSCALL_FIRST_PAGE, physaddr_vsyscall,
-		     vsyscall_mode == NATIVE
-		     ? PAGE_KERNEL_VSYSCALL
-		     : PAGE_KERNEL_VVAR);
+	__set_fixmap(VSYSCALL_FIRST_PAGE, physaddr_vsyscall, PAGE_KERNEL_VVAR);
 	BUILD_BUG_ON((unsigned long)__fix_to_virt(VSYSCALL_FIRST_PAGE) !=
 		     (unsigned long)VSYSCALL_START);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/x8664_ksyms_64.c linux-3.2.71-pax/arch/x86/kernel/x8664_ksyms_64.c
--- linux-3.2.71/arch/x86/kernel/x8664_ksyms_64.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/x8664_ksyms_64.c	2012-07-04 19:24:47.604063004 +0200
@@ -29,8 +29,6 @@ EXPORT_SYMBOL(__put_user_8);
 EXPORT_SYMBOL(copy_user_generic_string);
 EXPORT_SYMBOL(copy_user_generic_unrolled);
 EXPORT_SYMBOL(__copy_user_nocache);
-EXPORT_SYMBOL(_copy_from_user);
-EXPORT_SYMBOL(_copy_to_user);
 
 EXPORT_SYMBOL(copy_page);
 EXPORT_SYMBOL(clear_page);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/x86_init.c linux-3.2.71-pax/arch/x86/kernel/x86_init.c
--- linux-3.2.71/arch/x86/kernel/x86_init.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/x86_init.c	2013-02-17 16:36:25.284295747 +0100
@@ -90,14 +90,14 @@ struct x86_init_ops x86_init __initdata
 	},
 };
 
-struct x86_cpuinit_ops x86_cpuinit __cpuinitdata = {
+struct x86_cpuinit_ops x86_cpuinit __cpuinitconst = {
 	.setup_percpu_clockev		= setup_secondary_APIC_clock,
 };
 
 static void default_nmi_init(void) { };
 static int default_i8042_detect(void) { return 1; };
 
-struct x86_platform_ops x86_platform = {
+struct x86_platform_ops x86_platform __read_only = {
 	.calibrate_tsc			= native_calibrate_tsc,
 	.wallclock_init			= wallclock_init_noop,
 	.get_wallclock			= mach_get_cmos_time,
@@ -110,7 +110,7 @@ struct x86_platform_ops x86_platform = {
 };
 
 EXPORT_SYMBOL_GPL(x86_platform);
-struct x86_msi_ops x86_msi = {
+struct x86_msi_ops x86_msi __read_only = {
 	.setup_msi_irqs = native_setup_msi_irqs,
 	.teardown_msi_irq = native_teardown_msi_irq,
 	.teardown_msi_irqs = default_teardown_msi_irqs,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kernel/xsave.c linux-3.2.71-pax/arch/x86/kernel/xsave.c
--- linux-3.2.71/arch/x86/kernel/xsave.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kernel/xsave.c	2014-01-28 04:55:33.312966160 +0100
@@ -130,7 +130,7 @@ int check_for_xstate(struct i387_fxsave_
 	    fx_sw_user->xstate_size > fx_sw_user->extended_size)
 		return -EINVAL;
 
-	err = __get_user(magic2, (__u32 *) (((void *)fpstate) +
+	err = __get_user(magic2, (__u32 __user *) (((void __user *)fpstate) +
 					    fx_sw_user->extended_size -
 					    FP_XSTATE_MAGIC2_SIZE));
 	if (err)
@@ -266,7 +266,7 @@ fx_only:
 	 * the other extended state.
 	 */
 	xrstor_state(init_xstate_buf, pcntxt_mask & ~XSTATE_FPSSE);
-	return fxrstor_checking((__force struct i387_fxsave_struct *)buf);
+	return fxrstor_checking((struct i387_fxsave_struct __user *)buf);
 }
 
 /*
@@ -295,8 +295,7 @@ int restore_i387_xstate(void __user *buf
 	if (use_xsave())
 		err = restore_user_xstate(buf);
 	else
-		err = fxrstor_checking((__force struct i387_fxsave_struct *)
-				       buf);
+		err = fxrstor_checking((struct i387_fxsave_struct __user *)buf);
 	if (unlikely(err)) {
 		/*
 		 * Encountered an error while doing the restore from the
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kvm/emulate.c linux-3.2.71-pax/arch/x86/kvm/emulate.c
--- linux-3.2.71/arch/x86/kvm/emulate.c	2015-05-10 09:22:36.687493010 +0200
+++ linux-3.2.71-pax/arch/x86/kvm/emulate.c	2015-05-10 09:23:08.939494761 +0200
@@ -249,6 +249,7 @@ struct gprefix {
 
 #define ____emulate_2op(ctxt, _op, _x, _y, _suffix, _dsttype)	\
 	do {								\
+		unsigned long _tmp;					\
 		__asm__ __volatile__ (					\
 			_PRE_EFLAGS("0", "4", "2")			\
 			_op _suffix " %"_x"3,%1; "			\
@@ -263,8 +264,6 @@ struct gprefix {
 /* Raw emulation: instruction has two explicit operands. */
 #define __emulate_2op_nobyte(ctxt,_op,_wx,_wy,_lx,_ly,_qx,_qy)		\
 	do {								\
-		unsigned long _tmp;					\
-									\
 		switch ((ctxt)->dst.bytes) {				\
 		case 2:							\
 			____emulate_2op(ctxt,_op,_wx,_wy,"w",u16);	\
@@ -280,7 +279,6 @@ struct gprefix {
 
 #define __emulate_2op(ctxt,_op,_bx,_by,_wx,_wy,_lx,_ly,_qx,_qy)		     \
 	do {								     \
-		unsigned long _tmp;					     \
 		switch ((ctxt)->dst.bytes) {				     \
 		case 1:							     \
 			____emulate_2op(ctxt,_op,_bx,_by,"b",u8);	     \
@@ -3013,7 +3011,7 @@ static int check_cr_write(struct x86_emu
 	int cr = ctxt->modrm_reg;
 	u64 efer = 0;
 
-	static u64 cr_reserved_bits[] = {
+	static const u64 cr_reserved_bits[] = {
 		0xffffffff00000000ULL,
 		0, 0, 0, /* CR3 checked later */
 		CR4_RESERVED_BITS,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kvm/lapic.c linux-3.2.71-pax/arch/x86/kvm/lapic.c
--- linux-3.2.71/arch/x86/kvm/lapic.c	2015-08-14 21:48:35.036707927 +0200
+++ linux-3.2.71-pax/arch/x86/kvm/lapic.c	2015-08-14 21:48:45.548707366 +0200
@@ -53,7 +53,7 @@
 #define APIC_BUS_CYCLE_NS 1
 
 /* #define apic_debug(fmt,arg...) printk(KERN_WARNING fmt,##arg) */
-#define apic_debug(fmt, arg...)
+#define apic_debug(fmt, arg...) do {} while (0)
 
 #define APIC_LVT_NUM			6
 /* 14 is the version for Xeon and Pentium 8.4.8*/
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kvm/mmu.c linux-3.2.71-pax/arch/x86/kvm/mmu.c
--- linux-3.2.71/arch/x86/kvm/mmu.c	2015-08-07 11:37:20.379789888 +0200
+++ linux-3.2.71-pax/arch/x86/kvm/mmu.c	2015-08-07 11:37:42.991790553 +0200
@@ -3558,7 +3558,7 @@ void kvm_mmu_pte_write(struct kvm_vcpu *
 
 	pgprintk("%s: gpa %llx bytes %d\n", __func__, gpa, bytes);
 
-	invlpg_counter = atomic_read(&vcpu->kvm->arch.invlpg_counter);
+	invlpg_counter = atomic_read_unchecked(&vcpu->kvm->arch.invlpg_counter);
 
 	/*
 	 * Assume that the pte write on a page table of the same type
@@ -3590,7 +3590,7 @@ void kvm_mmu_pte_write(struct kvm_vcpu *
 	}
 
 	spin_lock(&vcpu->kvm->mmu_lock);
-	if (atomic_read(&vcpu->kvm->arch.invlpg_counter) != invlpg_counter)
+	if (atomic_read_unchecked(&vcpu->kvm->arch.invlpg_counter) != invlpg_counter)
 		gentry = 0;
 	kvm_mmu_free_some_pages(vcpu);
 	++vcpu->kvm->stat.mmu_pte_write;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kvm/paging_tmpl.h linux-3.2.71-pax/arch/x86/kvm/paging_tmpl.h
--- linux-3.2.71/arch/x86/kvm/paging_tmpl.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/kvm/paging_tmpl.h	2012-07-04 19:24:47.608063004 +0200
@@ -197,7 +197,7 @@ retry_walk:
 		if (unlikely(kvm_is_error_hva(host_addr)))
 			goto error;
 
-		ptep_user = (pt_element_t __user *)((void *)host_addr + offset);
+		ptep_user = (pt_element_t __force_user *)((void *)host_addr + offset);
 		if (unlikely(__copy_from_user(&pte, ptep_user, sizeof(pte))))
 			goto error;
 
@@ -705,7 +705,7 @@ static void FNAME(invlpg)(struct kvm_vcp
 	if (need_flush)
 		kvm_flush_remote_tlbs(vcpu->kvm);
 
-	atomic_inc(&vcpu->kvm->arch.invlpg_counter);
+	atomic_inc_unchecked(&vcpu->kvm->arch.invlpg_counter);
 
 	spin_unlock(&vcpu->kvm->mmu_lock);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kvm/svm.c linux-3.2.71-pax/arch/x86/kvm/svm.c
--- linux-3.2.71/arch/x86/kvm/svm.c	2014-12-14 21:13:44.994054691 +0100
+++ linux-3.2.71-pax/arch/x86/kvm/svm.c	2014-12-14 21:13:52.758069196 +0100
@@ -3403,7 +3403,11 @@ static void reload_tss(struct kvm_vcpu *
 	int cpu = raw_smp_processor_id();
 
 	struct svm_cpu_data *sd = per_cpu(svm_data, cpu);
+
+	pax_open_kernel();
 	sd->tss_desc->type = 9; /* available 32/64-bit TSS */
+	pax_close_kernel();
+
 	load_TR_desc();
 }
 
@@ -3783,6 +3787,10 @@ static void svm_vcpu_run(struct kvm_vcpu
 #endif
 #endif
 
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_MEMORY_UDEREF)
+	__set_fs(current_thread_info()->addr_limit);
+#endif
+
 	reload_tss(vcpu);
 
 	local_irq_disable();
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kvm/vmx.c linux-3.2.71-pax/arch/x86/kvm/vmx.c
--- linux-3.2.71/arch/x86/kvm/vmx.c	2015-08-07 11:37:20.379789888 +0200
+++ linux-3.2.71-pax/arch/x86/kvm/vmx.c	2015-08-07 11:37:42.995790553 +0200
@@ -1100,12 +1100,12 @@ static void vmcs_write64(unsigned long f
 #endif
 }
 
-static void vmcs_clear_bits(unsigned long field, u32 mask)
+static void vmcs_clear_bits(unsigned long field, unsigned long mask)
 {
 	vmcs_writel(field, vmcs_readl(field) & ~mask);
 }
 
-static void vmcs_set_bits(unsigned long field, u32 mask)
+static void vmcs_set_bits(unsigned long field, unsigned long mask)
 {
 	vmcs_writel(field, vmcs_readl(field) | mask);
 }
@@ -1306,7 +1306,11 @@ static void reload_tss(void)
 	struct desc_struct *descs;
 
 	descs = (void *)gdt->address;
+
+	pax_open_kernel();
 	descs[GDT_ENTRY_TSS].type = 9; /* available TSS */
+	pax_close_kernel();
+
 	load_TR_desc();
 }
 
@@ -1505,6 +1509,10 @@ static void vmx_vcpu_load(struct kvm_vcp
 		vmcs_writel(HOST_TR_BASE, kvm_read_tr_base()); /* 22.2.4 */
 		vmcs_writel(HOST_GDTR_BASE, gdt->address);   /* 22.2.4 */
 
+#ifdef CONFIG_PAX_PER_CPU_PGD
+		vmcs_writel(HOST_CR3, read_cr3());  /* 22.2.3  FIXME: shadow tables */
+#endif
+
 		rdmsrl(MSR_IA32_SYSENTER_ESP, sysenter_esp);
 		vmcs_writel(HOST_IA32_SYSENTER_ESP, sysenter_esp); /* 22.2.3 */
 		vmx->loaded_vmcs->cpu = cpu;
@@ -2635,8 +2643,11 @@ static __init int hardware_setup(void)
 	if (!cpu_has_vmx_flexpriority())
 		flexpriority_enabled = 0;
 
-	if (!cpu_has_vmx_tpr_shadow())
-		kvm_x86_ops->update_cr8_intercept = NULL;
+	if (!cpu_has_vmx_tpr_shadow()) {
+		pax_open_kernel();
+		*(void **)&kvm_x86_ops->update_cr8_intercept = NULL;
+		pax_close_kernel();
+	}
 
 	if (enable_ept && !cpu_has_vmx_ept_2m_page())
 		kvm_disable_largepages();
@@ -3646,7 +3657,10 @@ static void vmx_set_constant_host_state(
 	unsigned long cr4;
 
 	vmcs_writel(HOST_CR0, read_cr0() | X86_CR0_TS);  /* 22.2.3 */
+
+#ifndef CONFIG_PAX_PER_CPU_PGD
 	vmcs_writel(HOST_CR3, read_cr3());  /* 22.2.3  FIXME: shadow tables */
+#endif
 
 	/* Save the most likely value for this task's CR4 in the VMCS. */
 	cr4 = read_cr4();
@@ -3663,7 +3677,7 @@ static void vmx_set_constant_host_state(
 	vmcs_writel(HOST_IDTR_BASE, dt.address);   /* 22.2.4 */
 
 	asm("mov $.Lkvm_vmx_return, %0" : "=r"(tmpl));
-	vmcs_writel(HOST_RIP, tmpl); /* 22.2.5 */
+	vmcs_writel(HOST_RIP, ktla_ktva(tmpl)); /* 22.2.5 */
 
 	rdmsr(MSR_IA32_SYSENTER_CS, low32, high32);
 	vmcs_write32(HOST_IA32_SYSENTER_CS, low32);
@@ -6214,6 +6228,12 @@ static void __noclone vmx_vcpu_run(struc
 		"jmp .Lkvm_vmx_return \n\t"
 		".Llaunched: " __ex(ASM_VMX_VMRESUME) "\n\t"
 		".Lkvm_vmx_return: "
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+		"ljmp %[cs],$.Lkvm_vmx_return2\n\t"
+		".Lkvm_vmx_return2: "
+#endif
+
 		/* Save guest registers, load host registers, keep flags */
 		"mov %0, %c[wordsize](%%"R"sp) \n\t"
 		"pop %0 \n\t"
@@ -6262,6 +6282,11 @@ static void __noclone vmx_vcpu_run(struc
 #endif
 		[cr2]"i"(offsetof(struct vcpu_vmx, vcpu.arch.cr2)),
 		[wordsize]"i"(sizeof(ulong))
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+		,[cs]"i"(__KERNEL_CS)
+#endif
+
 	      : "cc", "memory"
 		, R"ax", R"bx", R"di", R"si"
 #ifdef CONFIG_X86_64
@@ -6290,7 +6315,16 @@ static void __noclone vmx_vcpu_run(struc
 		}
 	}
 
-	asm("mov %0, %%ds; mov %0, %%es" : : "r"(__USER_DS));
+	asm("mov %0, %%ds; mov %0, %%es; mov %0, %%ss" : : "r"(__KERNEL_DS));
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+	loadsegment(fs, __KERNEL_PERCPU);
+#endif
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_MEMORY_UDEREF)
+	__set_fs(current_thread_info()->addr_limit);
+#endif
+
 	vmx->loaded_vmcs->launched = 1;
 
 	vmx->exit_reason = vmcs_read32(VM_EXIT_REASON);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/kvm/x86.c linux-3.2.71-pax/arch/x86/kvm/x86.c
--- linux-3.2.71/arch/x86/kvm/x86.c	2015-01-01 15:15:23.820069606 +0100
+++ linux-3.2.71-pax/arch/x86/kvm/x86.c	2015-01-01 15:15:28.980069743 +0100
@@ -1369,8 +1369,8 @@ static int xen_hvm_config(struct kvm_vcp
 {
 	struct kvm *kvm = vcpu->kvm;
 	int lm = is_long_mode(vcpu);
-	u8 *blob_addr = lm ? (u8 *)(long)kvm->arch.xen_hvm_config.blob_addr_64
-		: (u8 *)(long)kvm->arch.xen_hvm_config.blob_addr_32;
+	u8 __user *blob_addr = lm ? (u8 __user *)(long)kvm->arch.xen_hvm_config.blob_addr_64
+		: (u8 __user *)(long)kvm->arch.xen_hvm_config.blob_addr_32;
 	u8 blob_size = lm ? kvm->arch.xen_hvm_config.blob_size_64
 		: kvm->arch.xen_hvm_config.blob_size_32;
 	u32 page_num = data & ~PAGE_MASK;
@@ -2187,6 +2187,8 @@ long kvm_arch_dev_ioctl(struct file *fil
 		if (n < msr_list.nmsrs)
 			goto out;
 		r = -EFAULT;
+		if (num_msrs_to_save > ARRAY_SIZE(msrs_to_save))
+			goto out;
 		if (copy_to_user(user_msr_list->indices, &msrs_to_save,
 				 num_msrs_to_save * sizeof(u32)))
 			goto out;
@@ -2362,15 +2364,20 @@ static int kvm_vcpu_ioctl_set_cpuid2(str
 				     struct kvm_cpuid2 *cpuid,
 				     struct kvm_cpuid_entry2 __user *entries)
 {
-	int r;
+	int r, i;
 
 	r = -E2BIG;
 	if (cpuid->nent > KVM_MAX_CPUID_ENTRIES)
 		goto out;
 	r = -EFAULT;
-	if (copy_from_user(&vcpu->arch.cpuid_entries, entries,
-			   cpuid->nent * sizeof(struct kvm_cpuid_entry2)))
+	if (!access_ok(VERIFY_READ, entries, cpuid->nent * sizeof(struct kvm_cpuid_entry2)))
 		goto out;
+	for (i = 0; i < cpuid->nent; ++i) {
+		struct kvm_cpuid_entry2 cpuid_entry;
+		if (__copy_from_user(&cpuid_entry, entries + i, sizeof(cpuid_entry)))
+			goto out;
+		vcpu->arch.cpuid_entries[i] = cpuid_entry;
+	}
 	vcpu->arch.cpuid_nent = cpuid->nent;
 	kvm_apic_set_version(vcpu);
 	kvm_x86_ops->cpuid_update(vcpu);
@@ -2385,15 +2392,19 @@ static int kvm_vcpu_ioctl_get_cpuid2(str
 				     struct kvm_cpuid2 *cpuid,
 				     struct kvm_cpuid_entry2 __user *entries)
 {
-	int r;
+	int r, i;
 
 	r = -E2BIG;
 	if (cpuid->nent < vcpu->arch.cpuid_nent)
 		goto out;
 	r = -EFAULT;
-	if (copy_to_user(entries, &vcpu->arch.cpuid_entries,
-			 vcpu->arch.cpuid_nent * sizeof(struct kvm_cpuid_entry2)))
+	if (!access_ok(VERIFY_WRITE, entries, vcpu->arch.cpuid_nent * sizeof(struct kvm_cpuid_entry2)))
 		goto out;
+	for (i = 0; i < vcpu->arch.cpuid_nent; ++i) {
+		struct kvm_cpuid_entry2 cpuid_entry = vcpu->arch.cpuid_entries[i];
+		if (__copy_to_user(entries + i, &cpuid_entry, sizeof(cpuid_entry)))
+			goto out;
+	}
 	return 0;
 
 out:
@@ -2768,7 +2779,7 @@ static int kvm_vcpu_ioctl_set_lapic(stru
 static int kvm_vcpu_ioctl_interrupt(struct kvm_vcpu *vcpu,
 				    struct kvm_interrupt *irq)
 {
-	if (irq->irq < 0 || irq->irq >= 256)
+	if (irq->irq >= 256)
 		return -EINVAL;
 	if (irqchip_in_kernel(vcpu->kvm))
 		return -ENXIO;
@@ -5209,7 +5220,7 @@ static void kvm_set_mmio_spte_mask(void)
 	kvm_mmu_set_mmio_spte_mask(mask);
 }
 
-int kvm_arch_init(void *opaque)
+int kvm_arch_init(const void *opaque)
 {
 	int r;
 	struct kvm_x86_ops *ops = (struct kvm_x86_ops *)opaque;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lguest/boot.c linux-3.2.71-pax/arch/x86/lguest/boot.c
--- linux-3.2.71/arch/x86/lguest/boot.c	2013-04-30 00:45:09.443714487 +0200
+++ linux-3.2.71-pax/arch/x86/lguest/boot.c	2013-04-30 00:45:13.143714290 +0200
@@ -1195,9 +1195,10 @@ static __init int early_put_chars(u32 vt
  * Rebooting also tells the Host we're finished, but the RESTART flag tells the
  * Launcher to reboot us.
  */
-static void lguest_restart(char *reason)
+static __noreturn void lguest_restart(char *reason)
 {
 	hcall(LHCALL_SHUTDOWN, __pa(reason), LGUEST_SHUTDOWN_RESTART, 0, 0);
+	BUG();
 }
 
 /*G:050
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/atomic64_32.c linux-3.2.71-pax/arch/x86/lib/atomic64_32.c
--- linux-3.2.71/arch/x86/lib/atomic64_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/atomic64_32.c	2012-07-04 19:24:47.620063004 +0200
@@ -8,18 +8,30 @@
 
 long long atomic64_read_cx8(long long, const atomic64_t *v);
 EXPORT_SYMBOL(atomic64_read_cx8);
+long long atomic64_read_unchecked_cx8(long long, const atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_read_unchecked_cx8);
 long long atomic64_set_cx8(long long, const atomic64_t *v);
 EXPORT_SYMBOL(atomic64_set_cx8);
+long long atomic64_set_unchecked_cx8(long long, const atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_set_unchecked_cx8);
 long long atomic64_xchg_cx8(long long, unsigned high);
 EXPORT_SYMBOL(atomic64_xchg_cx8);
 long long atomic64_add_return_cx8(long long a, atomic64_t *v);
 EXPORT_SYMBOL(atomic64_add_return_cx8);
+long long atomic64_add_return_unchecked_cx8(long long a, atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_add_return_unchecked_cx8);
 long long atomic64_sub_return_cx8(long long a, atomic64_t *v);
 EXPORT_SYMBOL(atomic64_sub_return_cx8);
+long long atomic64_sub_return_unchecked_cx8(long long a, atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_sub_return_unchecked_cx8);
 long long atomic64_inc_return_cx8(long long a, atomic64_t *v);
 EXPORT_SYMBOL(atomic64_inc_return_cx8);
+long long atomic64_inc_return_unchecked_cx8(long long a, atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_inc_return_unchecked_cx8);
 long long atomic64_dec_return_cx8(long long a, atomic64_t *v);
 EXPORT_SYMBOL(atomic64_dec_return_cx8);
+long long atomic64_dec_return_unchecked_cx8(long long a, atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_dec_return_unchecked_cx8);
 long long atomic64_dec_if_positive_cx8(atomic64_t *v);
 EXPORT_SYMBOL(atomic64_dec_if_positive_cx8);
 int atomic64_inc_not_zero_cx8(atomic64_t *v);
@@ -30,26 +42,46 @@ EXPORT_SYMBOL(atomic64_add_unless_cx8);
 #ifndef CONFIG_X86_CMPXCHG64
 long long atomic64_read_386(long long, const atomic64_t *v);
 EXPORT_SYMBOL(atomic64_read_386);
+long long atomic64_read_unchecked_386(long long, const atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_read_unchecked_386);
 long long atomic64_set_386(long long, const atomic64_t *v);
 EXPORT_SYMBOL(atomic64_set_386);
+long long atomic64_set_unchecked_386(long long, const atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_set_unchecked_386);
 long long atomic64_xchg_386(long long, unsigned high);
 EXPORT_SYMBOL(atomic64_xchg_386);
 long long atomic64_add_return_386(long long a, atomic64_t *v);
 EXPORT_SYMBOL(atomic64_add_return_386);
+long long atomic64_add_return_unchecked_386(long long a, atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_add_return_unchecked_386);
 long long atomic64_sub_return_386(long long a, atomic64_t *v);
 EXPORT_SYMBOL(atomic64_sub_return_386);
+long long atomic64_sub_return_unchecked_386(long long a, atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_sub_return_unchecked_386);
 long long atomic64_inc_return_386(long long a, atomic64_t *v);
 EXPORT_SYMBOL(atomic64_inc_return_386);
+long long atomic64_inc_return_unchecked_386(long long a, atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_inc_return_unchecked_386);
 long long atomic64_dec_return_386(long long a, atomic64_t *v);
 EXPORT_SYMBOL(atomic64_dec_return_386);
+long long atomic64_dec_return_unchecked_386(long long a, atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_dec_return_unchecked_386);
 long long atomic64_add_386(long long a, atomic64_t *v);
 EXPORT_SYMBOL(atomic64_add_386);
+long long atomic64_add_unchecked_386(long long a, atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_add_unchecked_386);
 long long atomic64_sub_386(long long a, atomic64_t *v);
 EXPORT_SYMBOL(atomic64_sub_386);
+long long atomic64_sub_unchecked_386(long long a, atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_sub_unchecked_386);
 long long atomic64_inc_386(long long a, atomic64_t *v);
 EXPORT_SYMBOL(atomic64_inc_386);
+long long atomic64_inc_unchecked_386(long long a, atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_inc_unchecked_386);
 long long atomic64_dec_386(long long a, atomic64_t *v);
 EXPORT_SYMBOL(atomic64_dec_386);
+long long atomic64_dec_unchecked_386(long long a, atomic64_unchecked_t *v);
+EXPORT_SYMBOL(atomic64_dec_unchecked_386);
 long long atomic64_dec_if_positive_386(atomic64_t *v);
 EXPORT_SYMBOL(atomic64_dec_if_positive_386);
 int atomic64_inc_not_zero_386(atomic64_t *v);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/atomic64_386_32.S linux-3.2.71-pax/arch/x86/lib/atomic64_386_32.S
--- linux-3.2.71/arch/x86/lib/atomic64_386_32.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/atomic64_386_32.S	2012-07-04 19:24:47.620063004 +0200
@@ -48,6 +48,10 @@ BEGIN(read)
 	movl  (v), %eax
 	movl 4(v), %edx
 RET_ENDP
+BEGIN(read_unchecked)
+	movl  (v), %eax
+	movl 4(v), %edx
+RET_ENDP
 #undef v
 
 #define v %esi
@@ -55,6 +59,10 @@ BEGIN(set)
 	movl %ebx,  (v)
 	movl %ecx, 4(v)
 RET_ENDP
+BEGIN(set_unchecked)
+	movl %ebx,  (v)
+	movl %ecx, 4(v)
+RET_ENDP
 #undef v
 
 #define v  %esi
@@ -70,6 +78,20 @@ RET_ENDP
 BEGIN(add)
 	addl %eax,  (v)
 	adcl %edx, 4(v)
+
+#ifdef CONFIG_PAX_REFCOUNT
+	jno 0f
+	subl %eax,  (v)
+	sbbl %edx, 4(v)
+	int $4
+0:
+	_ASM_EXTABLE(0b, 0b)
+#endif
+
+RET_ENDP
+BEGIN(add_unchecked)
+	addl %eax,  (v)
+	adcl %edx, 4(v)
 RET_ENDP
 #undef v
 
@@ -77,6 +99,24 @@ RET_ENDP
 BEGIN(add_return)
 	addl  (v), %eax
 	adcl 4(v), %edx
+
+#ifdef CONFIG_PAX_REFCOUNT
+	into
+1234:
+	_ASM_EXTABLE(1234b, 2f)
+#endif
+
+	movl %eax,  (v)
+	movl %edx, 4(v)
+
+#ifdef CONFIG_PAX_REFCOUNT
+2:
+#endif
+
+RET_ENDP
+BEGIN(add_return_unchecked)
+	addl  (v), %eax
+	adcl 4(v), %edx
 	movl %eax,  (v)
 	movl %edx, 4(v)
 RET_ENDP
@@ -86,6 +126,20 @@ RET_ENDP
 BEGIN(sub)
 	subl %eax,  (v)
 	sbbl %edx, 4(v)
+
+#ifdef CONFIG_PAX_REFCOUNT
+	jno 0f
+	addl %eax,  (v)
+	adcl %edx, 4(v)
+	int $4
+0:
+	_ASM_EXTABLE(0b, 0b)
+#endif
+
+RET_ENDP
+BEGIN(sub_unchecked)
+	subl %eax,  (v)
+	sbbl %edx, 4(v)
 RET_ENDP
 #undef v
 
@@ -96,6 +150,27 @@ BEGIN(sub_return)
 	sbbl $0, %edx
 	addl  (v), %eax
 	adcl 4(v), %edx
+
+#ifdef CONFIG_PAX_REFCOUNT
+	into
+1234:
+	_ASM_EXTABLE(1234b, 2f)
+#endif
+
+	movl %eax,  (v)
+	movl %edx, 4(v)
+
+#ifdef CONFIG_PAX_REFCOUNT
+2:
+#endif
+
+RET_ENDP
+BEGIN(sub_return_unchecked)
+	negl %edx
+	negl %eax
+	sbbl $0, %edx
+	addl  (v), %eax
+	adcl 4(v), %edx
 	movl %eax,  (v)
 	movl %edx, 4(v)
 RET_ENDP
@@ -105,6 +180,20 @@ RET_ENDP
 BEGIN(inc)
 	addl $1,  (v)
 	adcl $0, 4(v)
+
+#ifdef CONFIG_PAX_REFCOUNT
+	jno 0f
+	subl $1,  (v)
+	sbbl $0, 4(v)
+	int $4
+0:
+	_ASM_EXTABLE(0b, 0b)
+#endif
+
+RET_ENDP
+BEGIN(inc_unchecked)
+	addl $1,  (v)
+	adcl $0, 4(v)
 RET_ENDP
 #undef v
 
@@ -114,6 +203,26 @@ BEGIN(inc_return)
 	movl 4(v), %edx
 	addl $1, %eax
 	adcl $0, %edx
+
+#ifdef CONFIG_PAX_REFCOUNT
+	into
+1234:
+	_ASM_EXTABLE(1234b, 2f)
+#endif
+
+	movl %eax,  (v)
+	movl %edx, 4(v)
+
+#ifdef CONFIG_PAX_REFCOUNT
+2:
+#endif
+
+RET_ENDP
+BEGIN(inc_return_unchecked)
+	movl  (v), %eax
+	movl 4(v), %edx
+	addl $1, %eax
+	adcl $0, %edx
 	movl %eax,  (v)
 	movl %edx, 4(v)
 RET_ENDP
@@ -123,6 +232,20 @@ RET_ENDP
 BEGIN(dec)
 	subl $1,  (v)
 	sbbl $0, 4(v)
+
+#ifdef CONFIG_PAX_REFCOUNT
+	jno 0f
+	addl $1,  (v)
+	adcl $0, 4(v)
+	int $4
+0:
+	_ASM_EXTABLE(0b, 0b)
+#endif
+
+RET_ENDP
+BEGIN(dec_unchecked)
+	subl $1,  (v)
+	sbbl $0, 4(v)
 RET_ENDP
 #undef v
 
@@ -132,6 +255,26 @@ BEGIN(dec_return)
 	movl 4(v), %edx
 	subl $1, %eax
 	sbbl $0, %edx
+
+#ifdef CONFIG_PAX_REFCOUNT
+	into
+1234:
+	_ASM_EXTABLE(1234b, 2f)
+#endif
+
+	movl %eax,  (v)
+	movl %edx, 4(v)
+
+#ifdef CONFIG_PAX_REFCOUNT
+2:
+#endif
+
+RET_ENDP
+BEGIN(dec_return_unchecked)
+	movl  (v), %eax
+	movl 4(v), %edx
+	subl $1, %eax
+	sbbl $0, %edx
 	movl %eax,  (v)
 	movl %edx, 4(v)
 RET_ENDP
@@ -143,6 +286,13 @@ BEGIN(add_unless)
 	adcl %edx, %edi
 	addl  (v), %eax
 	adcl 4(v), %edx
+
+#ifdef CONFIG_PAX_REFCOUNT
+	into
+1234:
+	_ASM_EXTABLE(1234b, 2f)
+#endif
+
 	cmpl %eax, %esi
 	je 3f
 1:
@@ -168,6 +318,13 @@ BEGIN(inc_not_zero)
 1:
 	addl $1, %eax
 	adcl $0, %edx
+
+#ifdef CONFIG_PAX_REFCOUNT
+	into
+1234:
+	_ASM_EXTABLE(1234b, 2f)
+#endif
+
 	movl %eax,  (v)
 	movl %edx, 4(v)
 	movl $1, %eax
@@ -186,6 +343,13 @@ BEGIN(dec_if_positive)
 	movl 4(v), %edx
 	subl $1, %eax
 	sbbl $0, %edx
+
+#ifdef CONFIG_PAX_REFCOUNT
+	into
+1234:
+	_ASM_EXTABLE(1234b, 1f)
+#endif
+
 	js 1f
 	movl %eax,  (v)
 	movl %edx, 4(v)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/atomic64_cx8_32.S linux-3.2.71-pax/arch/x86/lib/atomic64_cx8_32.S
--- linux-3.2.71/arch/x86/lib/atomic64_cx8_32.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/atomic64_cx8_32.S	2012-07-04 19:24:47.620063004 +0200
@@ -35,10 +35,20 @@ ENTRY(atomic64_read_cx8)
 	CFI_STARTPROC
 
 	read64 %ecx
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(atomic64_read_cx8)
 
+ENTRY(atomic64_read_unchecked_cx8)
+	CFI_STARTPROC
+
+	read64 %ecx
+	pax_force_retaddr
+	ret
+	CFI_ENDPROC
+ENDPROC(atomic64_read_unchecked_cx8)
+
 ENTRY(atomic64_set_cx8)
 	CFI_STARTPROC
 
@@ -48,10 +58,25 @@ ENTRY(atomic64_set_cx8)
 	cmpxchg8b (%esi)
 	jne 1b
 
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(atomic64_set_cx8)
 
+ENTRY(atomic64_set_unchecked_cx8)
+	CFI_STARTPROC
+
+1:
+/* we don't need LOCK_PREFIX since aligned 64-bit writes
+ * are atomic on 586 and newer */
+	cmpxchg8b (%esi)
+	jne 1b
+
+	pax_force_retaddr
+	ret
+	CFI_ENDPROC
+ENDPROC(atomic64_set_unchecked_cx8)
+
 ENTRY(atomic64_xchg_cx8)
 	CFI_STARTPROC
 
@@ -62,12 +87,13 @@ ENTRY(atomic64_xchg_cx8)
 	cmpxchg8b (%esi)
 	jne 1b
 
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(atomic64_xchg_cx8)
 
-.macro addsub_return func ins insc
-ENTRY(atomic64_\func\()_return_cx8)
+.macro addsub_return func ins insc unchecked=""
+ENTRY(atomic64_\func\()_return\unchecked\()_cx8)
 	CFI_STARTPROC
 	SAVE ebp
 	SAVE ebx
@@ -84,27 +110,44 @@ ENTRY(atomic64_\func\()_return_cx8)
 	movl %edx, %ecx
 	\ins\()l %esi, %ebx
 	\insc\()l %edi, %ecx
+
+.ifb \unchecked
+#ifdef CONFIG_PAX_REFCOUNT
+	into
+2:
+	_ASM_EXTABLE(2b, 3f)
+#endif
+.endif
+
 	LOCK_PREFIX
 	cmpxchg8b (%ebp)
 	jne 1b
-
-10:
 	movl %ebx, %eax
 	movl %ecx, %edx
+
+.ifb \unchecked
+#ifdef CONFIG_PAX_REFCOUNT
+3:
+#endif
+.endif
+
 	RESTORE edi
 	RESTORE esi
 	RESTORE ebx
 	RESTORE ebp
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
-ENDPROC(atomic64_\func\()_return_cx8)
+ENDPROC(atomic64_\func\()_return\unchecked\()_cx8)
 .endm
 
 addsub_return add add adc
 addsub_return sub sub sbb
+addsub_return add add adc _unchecked
+addsub_return sub sub sbb _unchecked
 
-.macro incdec_return func ins insc
-ENTRY(atomic64_\func\()_return_cx8)
+.macro incdec_return func ins insc unchecked=""
+ENTRY(atomic64_\func\()_return\unchecked\()_cx8)
 	CFI_STARTPROC
 	SAVE ebx
 
@@ -114,21 +157,39 @@ ENTRY(atomic64_\func\()_return_cx8)
 	movl %edx, %ecx
 	\ins\()l $1, %ebx
 	\insc\()l $0, %ecx
+
+.ifb \unchecked
+#ifdef CONFIG_PAX_REFCOUNT
+	into
+2:
+	_ASM_EXTABLE(2b, 3f)
+#endif
+.endif
+
 	LOCK_PREFIX
 	cmpxchg8b (%esi)
 	jne 1b
 
-10:
 	movl %ebx, %eax
 	movl %ecx, %edx
+
+.ifb \unchecked
+#ifdef CONFIG_PAX_REFCOUNT
+3:
+#endif
+.endif
+
 	RESTORE ebx
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
-ENDPROC(atomic64_\func\()_return_cx8)
+ENDPROC(atomic64_\func\()_return\unchecked\()_cx8)
 .endm
 
 incdec_return inc add adc
 incdec_return dec sub sbb
+incdec_return inc add adc _unchecked
+incdec_return dec sub sbb _unchecked
 
 ENTRY(atomic64_dec_if_positive_cx8)
 	CFI_STARTPROC
@@ -140,6 +201,13 @@ ENTRY(atomic64_dec_if_positive_cx8)
 	movl %edx, %ecx
 	subl $1, %ebx
 	sbb $0, %ecx
+
+#ifdef CONFIG_PAX_REFCOUNT
+	into
+1234:
+	_ASM_EXTABLE(1234b, 2f)
+#endif
+
 	js 2f
 	LOCK_PREFIX
 	cmpxchg8b (%esi)
@@ -149,6 +217,7 @@ ENTRY(atomic64_dec_if_positive_cx8)
 	movl %ebx, %eax
 	movl %ecx, %edx
 	RESTORE ebx
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(atomic64_dec_if_positive_cx8)
@@ -174,6 +243,13 @@ ENTRY(atomic64_add_unless_cx8)
 	movl %edx, %ecx
 	addl %esi, %ebx
 	adcl %edi, %ecx
+
+#ifdef CONFIG_PAX_REFCOUNT
+	into
+1234:
+	_ASM_EXTABLE(1234b, 3f)
+#endif
+
 	LOCK_PREFIX
 	cmpxchg8b (%ebp)
 	jne 1b
@@ -184,6 +260,7 @@ ENTRY(atomic64_add_unless_cx8)
 	CFI_ADJUST_CFA_OFFSET -8
 	RESTORE ebx
 	RESTORE ebp
+	pax_force_retaddr
 	ret
 4:
 	cmpl %edx, 4(%esp)
@@ -206,6 +283,13 @@ ENTRY(atomic64_inc_not_zero_cx8)
 	movl %edx, %ecx
 	addl $1, %ebx
 	adcl $0, %ecx
+
+#ifdef CONFIG_PAX_REFCOUNT
+	into
+1234:
+	_ASM_EXTABLE(1234b, 3f)
+#endif
+
 	LOCK_PREFIX
 	cmpxchg8b (%esi)
 	jne 1b
@@ -213,6 +297,7 @@ ENTRY(atomic64_inc_not_zero_cx8)
 	movl $1, %eax
 3:
 	RESTORE ebx
+	pax_force_retaddr
 	ret
 4:
 	testl %edx, %edx
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/checksum_32.S linux-3.2.71-pax/arch/x86/lib/checksum_32.S
--- linux-3.2.71/arch/x86/lib/checksum_32.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/checksum_32.S	2012-07-04 19:24:47.620063004 +0200
@@ -28,7 +28,8 @@
 #include <linux/linkage.h>
 #include <asm/dwarf2.h>
 #include <asm/errno.h>
-				
+#include <asm/segment.h>
+
 /*
  * computes a partial checksum, e.g. for TCP/UDP fragments
  */
@@ -296,9 +297,24 @@ unsigned int csum_partial_copy_generic (
 
 #define ARGBASE 16		
 #define FP		12
-		
-ENTRY(csum_partial_copy_generic)
+
+ENTRY(csum_partial_copy_generic_to_user)
 	CFI_STARTPROC
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	pushl_cfi %gs
+	popl_cfi %es
+	jmp csum_partial_copy_generic
+#endif
+
+ENTRY(csum_partial_copy_generic_from_user)
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	pushl_cfi %gs
+	popl_cfi %ds
+#endif
+
+ENTRY(csum_partial_copy_generic)
 	subl  $4,%esp	
 	CFI_ADJUST_CFA_OFFSET 4
 	pushl_cfi %edi
@@ -320,7 +336,7 @@ ENTRY(csum_partial_copy_generic)
 	jmp 4f
 SRC(1:	movw (%esi), %bx	)
 	addl $2, %esi
-DST(	movw %bx, (%edi)	)
+DST(	movw %bx, %es:(%edi)	)
 	addl $2, %edi
 	addw %bx, %ax	
 	adcl $0, %eax
@@ -332,30 +348,30 @@ DST(	movw %bx, (%edi)	)
 SRC(1:	movl (%esi), %ebx	)
 SRC(	movl 4(%esi), %edx	)
 	adcl %ebx, %eax
-DST(	movl %ebx, (%edi)	)
+DST(	movl %ebx, %es:(%edi)	)
 	adcl %edx, %eax
-DST(	movl %edx, 4(%edi)	)
+DST(	movl %edx, %es:4(%edi)	)
 
 SRC(	movl 8(%esi), %ebx	)
 SRC(	movl 12(%esi), %edx	)
 	adcl %ebx, %eax
-DST(	movl %ebx, 8(%edi)	)
+DST(	movl %ebx, %es:8(%edi)	)
 	adcl %edx, %eax
-DST(	movl %edx, 12(%edi)	)
+DST(	movl %edx, %es:12(%edi)	)
 
 SRC(	movl 16(%esi), %ebx 	)
 SRC(	movl 20(%esi), %edx	)
 	adcl %ebx, %eax
-DST(	movl %ebx, 16(%edi)	)
+DST(	movl %ebx, %es:16(%edi)	)
 	adcl %edx, %eax
-DST(	movl %edx, 20(%edi)	)
+DST(	movl %edx, %es:20(%edi)	)
 
 SRC(	movl 24(%esi), %ebx	)
 SRC(	movl 28(%esi), %edx	)
 	adcl %ebx, %eax
-DST(	movl %ebx, 24(%edi)	)
+DST(	movl %ebx, %es:24(%edi)	)
 	adcl %edx, %eax
-DST(	movl %edx, 28(%edi)	)
+DST(	movl %edx, %es:28(%edi)	)
 
 	lea 32(%esi), %esi
 	lea 32(%edi), %edi
@@ -369,7 +385,7 @@ DST(	movl %edx, 28(%edi)	)
 	shrl $2, %edx			# This clears CF
 SRC(3:	movl (%esi), %ebx	)
 	adcl %ebx, %eax
-DST(	movl %ebx, (%edi)	)
+DST(	movl %ebx, %es:(%edi)	)
 	lea 4(%esi), %esi
 	lea 4(%edi), %edi
 	dec %edx
@@ -381,12 +397,12 @@ DST(	movl %ebx, (%edi)	)
 	jb 5f
 SRC(	movw (%esi), %cx	)
 	leal 2(%esi), %esi
-DST(	movw %cx, (%edi)	)
+DST(	movw %cx, %es:(%edi)	)
 	leal 2(%edi), %edi
 	je 6f
 	shll $16,%ecx
 SRC(5:	movb (%esi), %cl	)
-DST(	movb %cl, (%edi)	)
+DST(	movb %cl, %es:(%edi)	)
 6:	addl %ecx, %eax
 	adcl $0, %eax
 7:
@@ -397,7 +413,7 @@ DST(	movb %cl, (%edi)	)
 
 6001:
 	movl ARGBASE+20(%esp), %ebx	# src_err_ptr
-	movl $-EFAULT, (%ebx)
+	movl $-EFAULT, %ss:(%ebx)
 
 	# zero the complete destination - computing the rest
 	# is too much work 
@@ -410,11 +426,15 @@ DST(	movb %cl, (%edi)	)
 
 6002:
 	movl ARGBASE+24(%esp), %ebx	# dst_err_ptr
-	movl $-EFAULT,(%ebx)
+	movl $-EFAULT,%ss:(%ebx)
 	jmp 5000b
 
 .previous
 
+	pushl_cfi %ss
+	popl_cfi %ds
+	pushl_cfi %ss
+	popl_cfi %es
 	popl_cfi %ebx
 	CFI_RESTORE ebx
 	popl_cfi %esi
@@ -424,26 +444,43 @@ DST(	movb %cl, (%edi)	)
 	popl_cfi %ecx			# equivalent to addl $4,%esp
 	ret	
 	CFI_ENDPROC
-ENDPROC(csum_partial_copy_generic)
+ENDPROC(csum_partial_copy_generic_to_user)
 
 #else
 
 /* Version for PentiumII/PPro */
 
 #define ROUND1(x) \
+	nop; nop; nop;				\
 	SRC(movl x(%esi), %ebx	)	;	\
 	addl %ebx, %eax			;	\
-	DST(movl %ebx, x(%edi)	)	; 
+	DST(movl %ebx, %es:x(%edi))	;
 
 #define ROUND(x) \
+	nop; nop; nop;				\
 	SRC(movl x(%esi), %ebx	)	;	\
 	adcl %ebx, %eax			;	\
-	DST(movl %ebx, x(%edi)	)	;
+	DST(movl %ebx, %es:x(%edi))	;
 
 #define ARGBASE 12
-		
-ENTRY(csum_partial_copy_generic)
+
+ENTRY(csum_partial_copy_generic_to_user)
 	CFI_STARTPROC
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	pushl_cfi %gs
+	popl_cfi %es
+	jmp csum_partial_copy_generic
+#endif
+
+ENTRY(csum_partial_copy_generic_from_user)
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	pushl_cfi %gs
+	popl_cfi %ds
+#endif
+
+ENTRY(csum_partial_copy_generic)
 	pushl_cfi %ebx
 	CFI_REL_OFFSET ebx, 0
 	pushl_cfi %edi
@@ -464,7 +501,7 @@ ENTRY(csum_partial_copy_generic)
 	subl %ebx, %edi  
 	lea  -1(%esi),%edx
 	andl $-32,%edx
-	lea 3f(%ebx,%ebx), %ebx
+	lea 3f(%ebx,%ebx,2), %ebx
 	testl %esi, %esi 
 	jmp *%ebx
 1:	addl $64,%esi
@@ -485,19 +522,19 @@ ENTRY(csum_partial_copy_generic)
 	jb 5f
 SRC(	movw (%esi), %dx         )
 	leal 2(%esi), %esi
-DST(	movw %dx, (%edi)         )
+DST(	movw %dx, %es:(%edi)     )
 	leal 2(%edi), %edi
 	je 6f
 	shll $16,%edx
 5:
 SRC(	movb (%esi), %dl         )
-DST(	movb %dl, (%edi)         )
+DST(	movb %dl, %es:(%edi)     )
 6:	addl %edx, %eax
 	adcl $0, %eax
 7:
 .section .fixup, "ax"
 6001:	movl	ARGBASE+20(%esp), %ebx	# src_err_ptr	
-	movl $-EFAULT, (%ebx)
+	movl $-EFAULT, %ss:(%ebx)
 	# zero the complete destination (computing the rest is too much work)
 	movl ARGBASE+8(%esp),%edi	# dst
 	movl ARGBASE+12(%esp),%ecx	# len
@@ -505,10 +542,17 @@ DST(	movb %dl, (%edi)         )
 	rep; stosb
 	jmp 7b
 6002:	movl ARGBASE+24(%esp), %ebx	# dst_err_ptr
-	movl $-EFAULT, (%ebx)
+	movl $-EFAULT, %ss:(%ebx)
 	jmp  7b			
 .previous				
 
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	pushl_cfi %ss
+	popl_cfi %ds
+	pushl_cfi %ss
+	popl_cfi %es
+#endif
+
 	popl_cfi %esi
 	CFI_RESTORE esi
 	popl_cfi %edi
@@ -517,7 +561,7 @@ DST(	movb %dl, (%edi)         )
 	CFI_RESTORE ebx
 	ret
 	CFI_ENDPROC
-ENDPROC(csum_partial_copy_generic)
+ENDPROC(csum_partial_copy_generic_to_user)
 				
 #undef ROUND
 #undef ROUND1		
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/clear_page_64.S linux-3.2.71-pax/arch/x86/lib/clear_page_64.S
--- linux-3.2.71/arch/x86/lib/clear_page_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/clear_page_64.S	2012-07-04 19:24:47.620063004 +0200
@@ -11,6 +11,7 @@ ENTRY(clear_page_c)
 	movl $4096/8,%ecx
 	xorl %eax,%eax
 	rep stosq
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(clear_page_c)
@@ -20,6 +21,7 @@ ENTRY(clear_page_c_e)
 	movl $4096,%ecx
 	xorl %eax,%eax
 	rep stosb
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(clear_page_c_e)
@@ -43,6 +45,7 @@ ENTRY(clear_page)
 	leaq	64(%rdi),%rdi
 	jnz	.Lloop
 	nop
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 .Lclear_page_end:
@@ -58,7 +61,7 @@ ENDPROC(clear_page)
 
 #include <asm/cpufeature.h>
 
-	.section .altinstr_replacement,"ax"
+	.section .altinstr_replacement,"a"
 1:	.byte 0xeb					/* jmp <disp8> */
 	.byte (clear_page_c - clear_page) - (2f - 1b)	/* offset */
 2:	.byte 0xeb					/* jmp <disp8> */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/cmpxchg16b_emu.S linux-3.2.71-pax/arch/x86/lib/cmpxchg16b_emu.S
--- linux-3.2.71/arch/x86/lib/cmpxchg16b_emu.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/cmpxchg16b_emu.S	2012-07-04 19:24:47.620063004 +0200
@@ -53,11 +53,13 @@ this_cpu_cmpxchg16b_emu:
 
 	popf
 	mov $1, %al
+	pax_force_retaddr
 	ret
 
  not_same:
 	popf
 	xor %al,%al
+	pax_force_retaddr
 	ret
 
 CFI_ENDPROC
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/copy_page_64.S linux-3.2.71-pax/arch/x86/lib/copy_page_64.S
--- linux-3.2.71/arch/x86/lib/copy_page_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/copy_page_64.S	2013-12-14 03:03:37.437664599 +0100
@@ -9,6 +9,7 @@ copy_page_c:
 	CFI_STARTPROC
 	movl $4096/8,%ecx
 	rep movsq
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(copy_page_c)
@@ -24,7 +25,7 @@ ENTRY(copy_page)
 	CFI_ADJUST_CFA_OFFSET 3*8
 	movq	%rbx,(%rsp)
 	CFI_REL_OFFSET rbx, 0
-	movq	%r12,1*8(%rsp)
+	movq	%r14,1*8(%rsp)
 	CFI_REL_OFFSET r12, 1*8
 	movq	%r13,2*8(%rsp)
 	CFI_REL_OFFSET r13, 2*8
@@ -41,7 +42,7 @@ ENTRY(copy_page)
 	movq     32 (%rsi), %r9
 	movq     40 (%rsi), %r10
 	movq     48 (%rsi), %r11
-	movq     56 (%rsi), %r12
+	movq     56 (%rsi), %r14
 
 	prefetcht0 5*64(%rsi)
 
@@ -52,7 +53,7 @@ ENTRY(copy_page)
 	movq     %r9,  32 (%rdi)
 	movq     %r10, 40 (%rdi)
 	movq     %r11, 48 (%rdi)
-	movq     %r12, 56 (%rdi)
+	movq     %r14, 56 (%rdi)
 
 	leaq    64 (%rsi), %rsi
 	leaq    64 (%rdi), %rdi
@@ -71,7 +72,7 @@ ENTRY(copy_page)
 	movq     32 (%rsi), %r9
 	movq     40 (%rsi), %r10
 	movq     48 (%rsi), %r11
-	movq     56 (%rsi), %r12
+	movq     56 (%rsi), %r14
 
 	movq     %rax,    (%rdi)
 	movq     %rbx,  8 (%rdi)
@@ -80,7 +81,7 @@ ENTRY(copy_page)
 	movq     %r9,  32 (%rdi)
 	movq     %r10, 40 (%rdi)
 	movq     %r11, 48 (%rdi)
-	movq     %r12, 56 (%rdi)
+	movq     %r14, 56 (%rdi)
 
 	leaq	64(%rdi),%rdi
 	leaq	64(%rsi),%rsi
@@ -89,12 +90,13 @@ ENTRY(copy_page)
 
 	movq	(%rsp),%rbx
 	CFI_RESTORE rbx
-	movq	1*8(%rsp),%r12
+	movq	1*8(%rsp),%r14
 	CFI_RESTORE r12
 	movq	2*8(%rsp),%r13
 	CFI_RESTORE r13
 	addq	$3*8,%rsp
 	CFI_ADJUST_CFA_OFFSET -3*8
+	pax_force_retaddr
 	ret
 .Lcopy_page_end:
 	CFI_ENDPROC
@@ -105,7 +107,7 @@ ENDPROC(copy_page)
 
 #include <asm/cpufeature.h>
 
-	.section .altinstr_replacement,"ax"
+	.section .altinstr_replacement,"a"
 1:	.byte 0xeb					/* jmp <disp8> */
 	.byte (copy_page_c - copy_page) - (2f - 1b)	/* offset */
 2:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/copy_user_64.S linux-3.2.71-pax/arch/x86/lib/copy_user_64.S
--- linux-3.2.71/arch/x86/lib/copy_user_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/copy_user_64.S	2013-12-10 22:41:21.287125545 +0100
@@ -16,6 +16,7 @@
 #include <asm/thread_info.h>
 #include <asm/cpufeature.h>
 #include <asm/alternative-asm.h>
+#include <asm/pgtable.h>
 
 /*
  * By placing feature2 after feature1 in altinstructions section, we logically
@@ -29,7 +30,7 @@
 	.byte 0xe9	/* 32bit jump */
 	.long \orig-1f	/* by default jump to orig */
 1:
-	.section .altinstr_replacement,"ax"
+	.section .altinstr_replacement,"a"
 2:	.byte 0xe9			/* near jump with 32bit immediate */
 	.long \alt1-1b /* offset */   /* or alternatively to alt1 */
 3:	.byte 0xe9			/* near jump with 32bit immediate */
@@ -71,47 +72,20 @@
 #endif
 	.endm
 
-/* Standard copy_to_user with segment limit checking */
-ENTRY(_copy_to_user)
-	CFI_STARTPROC
-	GET_THREAD_INFO(%rax)
-	movq %rdi,%rcx
-	addq %rdx,%rcx
-	jc bad_to_user
-	cmpq TI_addr_limit(%rax),%rcx
-	ja bad_to_user
-	ALTERNATIVE_JUMP X86_FEATURE_REP_GOOD,X86_FEATURE_ERMS,	\
-		copy_user_generic_unrolled,copy_user_generic_string,	\
-		copy_user_enhanced_fast_string
-	CFI_ENDPROC
-ENDPROC(_copy_to_user)
-
-/* Standard copy_from_user with segment limit checking */
-ENTRY(_copy_from_user)
-	CFI_STARTPROC
-	GET_THREAD_INFO(%rax)
-	movq %rsi,%rcx
-	addq %rdx,%rcx
-	jc bad_from_user
-	cmpq TI_addr_limit(%rax),%rcx
-	ja bad_from_user
-	ALTERNATIVE_JUMP X86_FEATURE_REP_GOOD,X86_FEATURE_ERMS,	\
-		copy_user_generic_unrolled,copy_user_generic_string,	\
-		copy_user_enhanced_fast_string
-	CFI_ENDPROC
-ENDPROC(_copy_from_user)
-
 	.section .fixup,"ax"
 	/* must zero dest */
 ENTRY(bad_from_user)
 bad_from_user:
 	CFI_STARTPROC
+	testl %edx,%edx
+	js bad_to_user
 	movl %edx,%ecx
 	xorl %eax,%eax
 	rep
 	stosb
 bad_to_user:
 	movl %edx,%eax
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(bad_from_user)
@@ -179,6 +153,7 @@ ENTRY(copy_user_generic_unrolled)
 	decl %ecx
 	jnz 21b
 23:	xor %eax,%eax
+	pax_force_retaddr
 	ret
 
 	.section .fixup,"ax"
@@ -251,6 +226,7 @@ ENTRY(copy_user_generic_string)
 3:	rep
 	movsb
 4:	xorl %eax,%eax
+	pax_force_retaddr
 	ret
 
 	.section .fixup,"ax"
@@ -287,6 +263,7 @@ ENTRY(copy_user_enhanced_fast_string)
 1:	rep
 	movsb
 2:	xorl %eax,%eax
+	pax_force_retaddr
 	ret
 
 	.section .fixup,"ax"
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/copy_user_nocache_64.S linux-3.2.71-pax/arch/x86/lib/copy_user_nocache_64.S
--- linux-3.2.71/arch/x86/lib/copy_user_nocache_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/copy_user_nocache_64.S	2013-12-10 22:41:21.287125545 +0100
@@ -8,12 +8,14 @@
 
 #include <linux/linkage.h>
 #include <asm/dwarf2.h>
+#include <asm/alternative-asm.h>
 
 #define FIX_ALIGNMENT 1
 
 #include <asm/current.h>
 #include <asm/asm-offsets.h>
 #include <asm/thread_info.h>
+#include <asm/pgtable.h>
 
 	.macro ALIGN_DESTINATION
 #ifdef FIX_ALIGNMENT
@@ -50,6 +52,15 @@
  */
 ENTRY(__copy_user_nocache)
 	CFI_STARTPROC
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	mov pax_user_shadow_base,%rcx
+	cmp %rcx,%rsi
+	jae 1f
+	add %rcx,%rsi
+1:
+#endif
+
 	cmpl $8,%edx
 	jb 20f		/* less then 8 bytes, go to byte copy loop */
 	ALIGN_DESTINATION
@@ -98,6 +109,7 @@ ENTRY(__copy_user_nocache)
 	jnz 21b
 23:	xorl %eax,%eax
 	sfence
+	pax_force_retaddr
 	ret
 
 	.section .fixup,"ax"
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/csum-copy_64.S linux-3.2.71-pax/arch/x86/lib/csum-copy_64.S
--- linux-3.2.71/arch/x86/lib/csum-copy_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/csum-copy_64.S	2013-12-10 22:41:21.291125545 +0100
@@ -8,6 +8,7 @@
 #include <linux/linkage.h>
 #include <asm/dwarf2.h>
 #include <asm/errno.h>
+#include <asm/alternative-asm.h>
 
 /*
  * Checksum copy with exception handling.
@@ -64,8 +65,8 @@ ENTRY(csum_partial_copy_generic)
 	CFI_ADJUST_CFA_OFFSET 7*8
 	movq  %rbx, 2*8(%rsp)
 	CFI_REL_OFFSET rbx, 2*8
-	movq  %r12, 3*8(%rsp)
-	CFI_REL_OFFSET r12, 3*8
+	movq  %r15, 3*8(%rsp)
+	CFI_REL_OFFSET r15, 3*8
 	movq  %r14, 4*8(%rsp)
 	CFI_REL_OFFSET r14, 4*8
 	movq  %r13, 5*8(%rsp)
@@ -80,16 +81,16 @@ ENTRY(csum_partial_copy_generic)
 	movl  %edx, %ecx
 
 	xorl  %r9d, %r9d
-	movq  %rcx, %r12
+	movq  %rcx, %r15
 
-	shrq  $6, %r12
+	shrq  $6, %r15
 	jz	.Lhandle_tail       /* < 64 */
 
 	clc
 
 	/* main loop. clear in 64 byte blocks */
 	/* r9: zero, r8: temp2, rbx: temp1, rax: sum, rcx: saved length */
-	/* r11:	temp3, rdx: temp4, r12 loopcnt */
+	/* r11:	temp3, rdx: temp4, r15 loopcnt */
 	/* r10:	temp5, rbp: temp6, r14 temp7, r13 temp8 */
 	.p2align 4
 .Lloop:
@@ -123,7 +124,7 @@ ENTRY(csum_partial_copy_generic)
 	adcq  %r14, %rax
 	adcq  %r13, %rax
 
-	decl %r12d
+	decl %r15d
 
 	dest
 	movq %rbx, (%rsi)
@@ -218,8 +219,8 @@ ENTRY(csum_partial_copy_generic)
 .Lende:
 	movq 2*8(%rsp), %rbx
 	CFI_RESTORE rbx
-	movq 3*8(%rsp), %r12
-	CFI_RESTORE r12
+	movq 3*8(%rsp), %r15
+	CFI_RESTORE r15
 	movq 4*8(%rsp), %r14
 	CFI_RESTORE r14
 	movq 5*8(%rsp), %r13
@@ -228,6 +229,7 @@ ENTRY(csum_partial_copy_generic)
 	CFI_RESTORE rbp
 	addq $7*8, %rsp
 	CFI_ADJUST_CFA_OFFSET -7*8
+	pax_force_retaddr
 	ret
 	CFI_RESTORE_STATE
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/csum-wrappers_64.c linux-3.2.71-pax/arch/x86/lib/csum-wrappers_64.c
--- linux-3.2.71/arch/x86/lib/csum-wrappers_64.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/csum-wrappers_64.c	2012-12-01 02:29:42.464012819 +0100
@@ -52,7 +52,7 @@ csum_partial_copy_from_user(const void _
 			len -= 2;
 		}
 	}
-	isum = csum_partial_copy_generic((__force const void *)src,
+	isum = csum_partial_copy_generic((const void __force_kernel *)____m(src),
 				dst, len, isum, errp, NULL);
 	if (unlikely(*errp))
 		goto out_err;
@@ -105,7 +105,7 @@ csum_partial_copy_to_user(const void *sr
 	}
 
 	*errp = 0;
-	return csum_partial_copy_generic(src, (void __force *)dst,
+	return csum_partial_copy_generic(src, (void __force_kernel *)____m(dst),
 					 len, isum, NULL, errp);
 }
 EXPORT_SYMBOL(csum_partial_copy_to_user);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/getuser.S linux-3.2.71-pax/arch/x86/lib/getuser.S
--- linux-3.2.71/arch/x86/lib/getuser.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/getuser.S	2013-05-13 13:25:07.967736083 +0200
@@ -33,15 +33,38 @@
 #include <asm/asm-offsets.h>
 #include <asm/thread_info.h>
 #include <asm/asm.h>
+#include <asm/segment.h>
+#include <asm/pgtable.h>
+#include <asm/alternative-asm.h>
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_MEMORY_UDEREF)
+#define __copyuser_seg gs;
+#else
+#define __copyuser_seg
+#endif
 
 	.text
 ENTRY(__get_user_1)
 	CFI_STARTPROC
+
+#if !defined(CONFIG_X86_32) || !defined(CONFIG_PAX_MEMORY_UDEREF)
 	GET_THREAD_INFO(%_ASM_DX)
 	cmp TI_addr_limit(%_ASM_DX),%_ASM_AX
 	jae bad_get_user
-1:	movzb (%_ASM_AX),%edx
+
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+	mov pax_user_shadow_base,%_ASM_DX
+	cmp %_ASM_DX,%_ASM_AX
+	jae 1234f
+	add %_ASM_DX,%_ASM_AX
+1234:
+#endif
+
+#endif
+
+1:	__copyuser_seg movzb (%_ASM_AX),%edx
 	xor %eax,%eax
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(__get_user_1)
@@ -49,12 +72,26 @@ ENDPROC(__get_user_1)
 ENTRY(__get_user_2)
 	CFI_STARTPROC
 	add $1,%_ASM_AX
+
+#if !defined(CONFIG_X86_32) || !defined(CONFIG_PAX_MEMORY_UDEREF)
 	jc bad_get_user
 	GET_THREAD_INFO(%_ASM_DX)
 	cmp TI_addr_limit(%_ASM_DX),%_ASM_AX
 	jae bad_get_user
-2:	movzwl -1(%_ASM_AX),%edx
+
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+	mov pax_user_shadow_base,%_ASM_DX
+	cmp %_ASM_DX,%_ASM_AX
+	jae 1234f
+	add %_ASM_DX,%_ASM_AX
+1234:
+#endif
+
+#endif
+
+2:	__copyuser_seg movzwl -1(%_ASM_AX),%edx
 	xor %eax,%eax
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(__get_user_2)
@@ -62,12 +99,26 @@ ENDPROC(__get_user_2)
 ENTRY(__get_user_4)
 	CFI_STARTPROC
 	add $3,%_ASM_AX
+
+#if !defined(CONFIG_X86_32) || !defined(CONFIG_PAX_MEMORY_UDEREF)
 	jc bad_get_user
 	GET_THREAD_INFO(%_ASM_DX)
 	cmp TI_addr_limit(%_ASM_DX),%_ASM_AX
 	jae bad_get_user
-3:	mov -3(%_ASM_AX),%edx
+
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+	mov pax_user_shadow_base,%_ASM_DX
+	cmp %_ASM_DX,%_ASM_AX
+	jae 1234f
+	add %_ASM_DX,%_ASM_AX
+1234:
+#endif
+
+#endif
+
+3:	__copyuser_seg mov -3(%_ASM_AX),%edx
 	xor %eax,%eax
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(__get_user_4)
@@ -80,8 +131,18 @@ ENTRY(__get_user_8)
 	GET_THREAD_INFO(%_ASM_DX)
 	cmp TI_addr_limit(%_ASM_DX),%_ASM_AX
 	jae	bad_get_user
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	mov pax_user_shadow_base,%_ASM_DX
+	cmp %_ASM_DX,%_ASM_AX
+	jae 1234f
+	add %_ASM_DX,%_ASM_AX
+1234:
+#endif
+
 4:	movq -7(%_ASM_AX),%_ASM_DX
 	xor %eax,%eax
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(__get_user_8)
@@ -91,6 +152,7 @@ bad_get_user:
 	CFI_STARTPROC
 	xor %edx,%edx
 	mov $(-EFAULT),%_ASM_AX
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 END(bad_get_user)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/insn.c linux-3.2.71-pax/arch/x86/lib/insn.c
--- linux-3.2.71/arch/x86/lib/insn.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/insn.c	2012-07-04 19:24:47.624063004 +0200
@@ -21,6 +21,11 @@
 #include <linux/string.h>
 #include <asm/inat.h>
 #include <asm/insn.h>
+#ifdef __KERNEL__
+#include <asm/pgtable_types.h>
+#else
+#define ktla_ktva(addr) addr
+#endif
 
 /* Verify next sizeof(t) bytes can be on the same instruction */
 #define validate_next(t, insn, n)	\
@@ -49,8 +54,8 @@
 void insn_init(struct insn *insn, const void *kaddr, int x86_64)
 {
 	memset(insn, 0, sizeof(*insn));
-	insn->kaddr = kaddr;
-	insn->next_byte = kaddr;
+	insn->kaddr = ktla_ktva(kaddr);
+	insn->next_byte = ktla_ktva(kaddr);
 	insn->x86_64 = x86_64 ? 1 : 0;
 	insn->opnd_bytes = 4;
 	if (x86_64)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/iomap_copy_64.S linux-3.2.71-pax/arch/x86/lib/iomap_copy_64.S
--- linux-3.2.71/arch/x86/lib/iomap_copy_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/iomap_copy_64.S	2012-07-04 19:24:47.628063005 +0200
@@ -17,6 +17,7 @@
 
 #include <linux/linkage.h>
 #include <asm/dwarf2.h>
+#include <asm/alternative-asm.h>
 
 /*
  * override generic version in lib/iomap_copy.c
@@ -25,6 +26,7 @@ ENTRY(__iowrite32_copy)
 	CFI_STARTPROC
 	movl %edx,%ecx
 	rep movsd
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(__iowrite32_copy)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/memcpy_64.S linux-3.2.71-pax/arch/x86/lib/memcpy_64.S
--- linux-3.2.71/arch/x86/lib/memcpy_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/memcpy_64.S	2013-12-10 22:41:21.291125545 +0100
@@ -34,6 +34,7 @@
 	rep movsq
 	movl %edx, %ecx
 	rep movsb
+	pax_force_retaddr
 	ret
 .Lmemcpy_e:
 	.previous
@@ -51,6 +52,7 @@
 
 	movl %edx, %ecx
 	rep movsb
+	pax_force_retaddr
 	ret
 .Lmemcpy_e_e:
 	.previous
@@ -141,6 +143,7 @@ ENTRY(memcpy)
 	movq %r9,	1*8(%rdi)
 	movq %r10,	-2*8(%rdi, %rdx)
 	movq %r11,	-1*8(%rdi, %rdx)
+	pax_force_retaddr
 	retq
 	.p2align 4
 .Lless_16bytes:
@@ -153,6 +156,7 @@ ENTRY(memcpy)
 	movq -1*8(%rsi, %rdx),	%r9
 	movq %r8,	0*8(%rdi)
 	movq %r9,	-1*8(%rdi, %rdx)
+	pax_force_retaddr
 	retq
 	.p2align 4
 .Lless_8bytes:
@@ -166,6 +170,7 @@ ENTRY(memcpy)
 	movl -4(%rsi, %rdx), %r8d
 	movl %ecx, (%rdi)
 	movl %r8d, -4(%rdi, %rdx)
+	pax_force_retaddr
 	retq
 	.p2align 4
 .Lless_3bytes:
@@ -183,6 +188,7 @@ ENTRY(memcpy)
 	jnz .Lloop_1
 
 .Lend:
+	pax_force_retaddr
 	retq
 	CFI_ENDPROC
 ENDPROC(memcpy)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/memmove_64.S linux-3.2.71-pax/arch/x86/lib/memmove_64.S
--- linux-3.2.71/arch/x86/lib/memmove_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/memmove_64.S	2013-12-10 22:41:21.291125545 +0100
@@ -202,6 +202,7 @@ ENTRY(memmove)
 	movb (%rsi), %r11b
 	movb %r11b, (%rdi)
 13:
+	pax_force_retaddr
 	retq
 	CFI_ENDPROC
 
@@ -210,6 +211,7 @@ ENTRY(memmove)
 	/* Forward moving data. */
 	movq %rdx, %rcx
 	rep movsb
+	pax_force_retaddr
 	retq
 .Lmemmove_end_forward_efs:
 	.previous
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/memset_64.S linux-3.2.71-pax/arch/x86/lib/memset_64.S
--- linux-3.2.71/arch/x86/lib/memset_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/memset_64.S	2013-12-10 22:44:40.731114897 +0100
@@ -31,6 +31,7 @@
 	movl %r8d,%ecx
 	rep stosb
 	movq %r9,%rax
+	pax_force_retaddr
 	ret
 .Lmemset_e:
 	.previous
@@ -53,6 +54,7 @@
 	movl %edx,%ecx
 	rep stosb
 	movq %r9,%rax
+	pax_force_retaddr
 	ret
 .Lmemset_e_e:
 	.previous
@@ -121,6 +123,7 @@ ENTRY(__memset)
 
 .Lende:
 	movq	%r10,%rax
+	pax_force_retaddr
 	ret
 
 	CFI_RESTORE_STATE
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/mmx_32.c linux-3.2.71-pax/arch/x86/lib/mmx_32.c
--- linux-3.2.71/arch/x86/lib/mmx_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/mmx_32.c	2012-07-04 19:24:47.628063005 +0200
@@ -29,6 +29,7 @@ void *_mmx_memcpy(void *to, const void *
 {
 	void *p;
 	int i;
+	unsigned long cr0;
 
 	if (unlikely(in_interrupt()))
 		return __memcpy(to, from, len);
@@ -39,44 +40,72 @@ void *_mmx_memcpy(void *to, const void *
 	kernel_fpu_begin();
 
 	__asm__ __volatile__ (
-		"1: prefetch (%0)\n"		/* This set is 28 bytes */
-		"   prefetch 64(%0)\n"
-		"   prefetch 128(%0)\n"
-		"   prefetch 192(%0)\n"
-		"   prefetch 256(%0)\n"
+		"1: prefetch (%1)\n"		/* This set is 28 bytes */
+		"   prefetch 64(%1)\n"
+		"   prefetch 128(%1)\n"
+		"   prefetch 192(%1)\n"
+		"   prefetch 256(%1)\n"
 		"2:  \n"
 		".section .fixup, \"ax\"\n"
-		"3: movw $0x1AEB, 1b\n"	/* jmp on 26 bytes */
+		"3:  \n"
+
+#ifdef CONFIG_PAX_KERNEXEC
+		"   movl %%cr0, %0\n"
+		"   movl %0, %%eax\n"
+		"   andl $0xFFFEFFFF, %%eax\n"
+		"   movl %%eax, %%cr0\n"
+#endif
+
+		"   movw $0x1AEB, 1b\n"	/* jmp on 26 bytes */
+
+#ifdef CONFIG_PAX_KERNEXEC
+		"   movl %0, %%cr0\n"
+#endif
+
 		"   jmp 2b\n"
 		".previous\n"
 			_ASM_EXTABLE(1b, 3b)
-			: : "r" (from));
+			: "=&r" (cr0) : "r" (from) : "ax");
 
 	for ( ; i > 5; i--) {
 		__asm__ __volatile__ (
-		"1:  prefetch 320(%0)\n"
-		"2:  movq (%0), %%mm0\n"
-		"  movq 8(%0), %%mm1\n"
-		"  movq 16(%0), %%mm2\n"
-		"  movq 24(%0), %%mm3\n"
-		"  movq %%mm0, (%1)\n"
-		"  movq %%mm1, 8(%1)\n"
-		"  movq %%mm2, 16(%1)\n"
-		"  movq %%mm3, 24(%1)\n"
-		"  movq 32(%0), %%mm0\n"
-		"  movq 40(%0), %%mm1\n"
-		"  movq 48(%0), %%mm2\n"
-		"  movq 56(%0), %%mm3\n"
-		"  movq %%mm0, 32(%1)\n"
-		"  movq %%mm1, 40(%1)\n"
-		"  movq %%mm2, 48(%1)\n"
-		"  movq %%mm3, 56(%1)\n"
+		"1:  prefetch 320(%1)\n"
+		"2:  movq (%1), %%mm0\n"
+		"  movq 8(%1), %%mm1\n"
+		"  movq 16(%1), %%mm2\n"
+		"  movq 24(%1), %%mm3\n"
+		"  movq %%mm0, (%2)\n"
+		"  movq %%mm1, 8(%2)\n"
+		"  movq %%mm2, 16(%2)\n"
+		"  movq %%mm3, 24(%2)\n"
+		"  movq 32(%1), %%mm0\n"
+		"  movq 40(%1), %%mm1\n"
+		"  movq 48(%1), %%mm2\n"
+		"  movq 56(%1), %%mm3\n"
+		"  movq %%mm0, 32(%2)\n"
+		"  movq %%mm1, 40(%2)\n"
+		"  movq %%mm2, 48(%2)\n"
+		"  movq %%mm3, 56(%2)\n"
 		".section .fixup, \"ax\"\n"
-		"3: movw $0x05EB, 1b\n"	/* jmp on 5 bytes */
+		"3:\n"
+
+#ifdef CONFIG_PAX_KERNEXEC
+		"   movl %%cr0, %0\n"
+		"   movl %0, %%eax\n"
+		"   andl $0xFFFEFFFF, %%eax\n"
+		"   movl %%eax, %%cr0\n"
+#endif
+
+		"   movw $0x05EB, 1b\n"	/* jmp on 5 bytes */
+
+#ifdef CONFIG_PAX_KERNEXEC
+		"   movl %0, %%cr0\n"
+#endif
+
 		"   jmp 2b\n"
 		".previous\n"
 			_ASM_EXTABLE(1b, 3b)
-			: : "r" (from), "r" (to) : "memory");
+			: "=&r" (cr0) : "r" (from), "r" (to) : "memory", "ax");
 
 		from += 64;
 		to += 64;
@@ -158,6 +187,7 @@ static void fast_clear_page(void *page)
 static void fast_copy_page(void *to, void *from)
 {
 	int i;
+	unsigned long cr0;
 
 	kernel_fpu_begin();
 
@@ -166,42 +196,70 @@ static void fast_copy_page(void *to, voi
 	 * but that is for later. -AV
 	 */
 	__asm__ __volatile__(
-		"1: prefetch (%0)\n"
-		"   prefetch 64(%0)\n"
-		"   prefetch 128(%0)\n"
-		"   prefetch 192(%0)\n"
-		"   prefetch 256(%0)\n"
+		"1: prefetch (%1)\n"
+		"   prefetch 64(%1)\n"
+		"   prefetch 128(%1)\n"
+		"   prefetch 192(%1)\n"
+		"   prefetch 256(%1)\n"
 		"2:  \n"
 		".section .fixup, \"ax\"\n"
-		"3: movw $0x1AEB, 1b\n"	/* jmp on 26 bytes */
+		"3:  \n"
+
+#ifdef CONFIG_PAX_KERNEXEC
+		"   movl %%cr0, %0\n"
+		"   movl %0, %%eax\n"
+		"   andl $0xFFFEFFFF, %%eax\n"
+		"   movl %%eax, %%cr0\n"
+#endif
+
+		"   movw $0x1AEB, 1b\n"	/* jmp on 26 bytes */
+
+#ifdef CONFIG_PAX_KERNEXEC
+		"   movl %0, %%cr0\n"
+#endif
+
 		"   jmp 2b\n"
 		".previous\n"
-			_ASM_EXTABLE(1b, 3b) : : "r" (from));
+			_ASM_EXTABLE(1b, 3b) : "=&r" (cr0) : "r" (from) : "ax");
 
 	for (i = 0; i < (4096-320)/64; i++) {
 		__asm__ __volatile__ (
-		"1: prefetch 320(%0)\n"
-		"2: movq (%0), %%mm0\n"
-		"   movntq %%mm0, (%1)\n"
-		"   movq 8(%0), %%mm1\n"
-		"   movntq %%mm1, 8(%1)\n"
-		"   movq 16(%0), %%mm2\n"
-		"   movntq %%mm2, 16(%1)\n"
-		"   movq 24(%0), %%mm3\n"
-		"   movntq %%mm3, 24(%1)\n"
-		"   movq 32(%0), %%mm4\n"
-		"   movntq %%mm4, 32(%1)\n"
-		"   movq 40(%0), %%mm5\n"
-		"   movntq %%mm5, 40(%1)\n"
-		"   movq 48(%0), %%mm6\n"
-		"   movntq %%mm6, 48(%1)\n"
-		"   movq 56(%0), %%mm7\n"
-		"   movntq %%mm7, 56(%1)\n"
+		"1: prefetch 320(%1)\n"
+		"2: movq (%1), %%mm0\n"
+		"   movntq %%mm0, (%2)\n"
+		"   movq 8(%1), %%mm1\n"
+		"   movntq %%mm1, 8(%2)\n"
+		"   movq 16(%1), %%mm2\n"
+		"   movntq %%mm2, 16(%2)\n"
+		"   movq 24(%1), %%mm3\n"
+		"   movntq %%mm3, 24(%2)\n"
+		"   movq 32(%1), %%mm4\n"
+		"   movntq %%mm4, 32(%2)\n"
+		"   movq 40(%1), %%mm5\n"
+		"   movntq %%mm5, 40(%2)\n"
+		"   movq 48(%1), %%mm6\n"
+		"   movntq %%mm6, 48(%2)\n"
+		"   movq 56(%1), %%mm7\n"
+		"   movntq %%mm7, 56(%2)\n"
 		".section .fixup, \"ax\"\n"
-		"3: movw $0x05EB, 1b\n"	/* jmp on 5 bytes */
+		"3:\n"
+
+#ifdef CONFIG_PAX_KERNEXEC
+		"   movl %%cr0, %0\n"
+		"   movl %0, %%eax\n"
+		"   andl $0xFFFEFFFF, %%eax\n"
+		"   movl %%eax, %%cr0\n"
+#endif
+
+		"   movw $0x05EB, 1b\n"	/* jmp on 5 bytes */
+
+#ifdef CONFIG_PAX_KERNEXEC
+		"   movl %0, %%cr0\n"
+#endif
+
 		"   jmp 2b\n"
 		".previous\n"
-		_ASM_EXTABLE(1b, 3b) : : "r" (from), "r" (to) : "memory");
+		_ASM_EXTABLE(1b, 3b) : "=&r" (cr0) : "r" (from), "r" (to) : "memory", "ax");
 
 		from += 64;
 		to += 64;
@@ -280,47 +338,76 @@ static void fast_clear_page(void *page)
 static void fast_copy_page(void *to, void *from)
 {
 	int i;
+	unsigned long cr0;
 
 	kernel_fpu_begin();
 
 	__asm__ __volatile__ (
-		"1: prefetch (%0)\n"
-		"   prefetch 64(%0)\n"
-		"   prefetch 128(%0)\n"
-		"   prefetch 192(%0)\n"
-		"   prefetch 256(%0)\n"
+		"1: prefetch (%1)\n"
+		"   prefetch 64(%1)\n"
+		"   prefetch 128(%1)\n"
+		"   prefetch 192(%1)\n"
+		"   prefetch 256(%1)\n"
 		"2:  \n"
 		".section .fixup, \"ax\"\n"
-		"3: movw $0x1AEB, 1b\n"	/* jmp on 26 bytes */
+		"3:  \n"
+
+#ifdef CONFIG_PAX_KERNEXEC
+		"   movl %%cr0, %0\n"
+		"   movl %0, %%eax\n"
+		"   andl $0xFFFEFFFF, %%eax\n"
+		"   movl %%eax, %%cr0\n"
+#endif
+
+		"   movw $0x1AEB, 1b\n"	/* jmp on 26 bytes */
+
+#ifdef CONFIG_PAX_KERNEXEC
+		"   movl %0, %%cr0\n"
+#endif
+
 		"   jmp 2b\n"
 		".previous\n"
-			_ASM_EXTABLE(1b, 3b) : : "r" (from));
+			_ASM_EXTABLE(1b, 3b) : "=&r" (cr0) : "r" (from) : "ax");
 
 	for (i = 0; i < 4096/64; i++) {
 		__asm__ __volatile__ (
-		"1: prefetch 320(%0)\n"
-		"2: movq (%0), %%mm0\n"
-		"   movq 8(%0), %%mm1\n"
-		"   movq 16(%0), %%mm2\n"
-		"   movq 24(%0), %%mm3\n"
-		"   movq %%mm0, (%1)\n"
-		"   movq %%mm1, 8(%1)\n"
-		"   movq %%mm2, 16(%1)\n"
-		"   movq %%mm3, 24(%1)\n"
-		"   movq 32(%0), %%mm0\n"
-		"   movq 40(%0), %%mm1\n"
-		"   movq 48(%0), %%mm2\n"
-		"   movq 56(%0), %%mm3\n"
-		"   movq %%mm0, 32(%1)\n"
-		"   movq %%mm1, 40(%1)\n"
-		"   movq %%mm2, 48(%1)\n"
-		"   movq %%mm3, 56(%1)\n"
+		"1: prefetch 320(%1)\n"
+		"2: movq (%1), %%mm0\n"
+		"   movq 8(%1), %%mm1\n"
+		"   movq 16(%1), %%mm2\n"
+		"   movq 24(%1), %%mm3\n"
+		"   movq %%mm0, (%2)\n"
+		"   movq %%mm1, 8(%2)\n"
+		"   movq %%mm2, 16(%2)\n"
+		"   movq %%mm3, 24(%2)\n"
+		"   movq 32(%1), %%mm0\n"
+		"   movq 40(%1), %%mm1\n"
+		"   movq 48(%1), %%mm2\n"
+		"   movq 56(%1), %%mm3\n"
+		"   movq %%mm0, 32(%2)\n"
+		"   movq %%mm1, 40(%2)\n"
+		"   movq %%mm2, 48(%2)\n"
+		"   movq %%mm3, 56(%2)\n"
 		".section .fixup, \"ax\"\n"
-		"3: movw $0x05EB, 1b\n"	/* jmp on 5 bytes */
+		"3:\n"
+
+#ifdef CONFIG_PAX_KERNEXEC
+		"   movl %%cr0, %0\n"
+		"   movl %0, %%eax\n"
+		"   andl $0xFFFEFFFF, %%eax\n"
+		"   movl %%eax, %%cr0\n"
+#endif
+
+		"   movw $0x05EB, 1b\n"	/* jmp on 5 bytes */
+
+#ifdef CONFIG_PAX_KERNEXEC
+		"   movl %0, %%cr0\n"
+#endif
+
 		"   jmp 2b\n"
 		".previous\n"
 			_ASM_EXTABLE(1b, 3b)
-			: : "r" (from), "r" (to) : "memory");
+			: "=&r" (cr0) : "r" (from), "r" (to) : "memory", "ax");
 
 		from += 64;
 		to += 64;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/msr-reg.S linux-3.2.71-pax/arch/x86/lib/msr-reg.S
--- linux-3.2.71/arch/x86/lib/msr-reg.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/msr-reg.S	2013-12-10 22:41:21.295125545 +0100
@@ -3,6 +3,7 @@
 #include <asm/dwarf2.h>
 #include <asm/asm.h>
 #include <asm/msr.h>
+#include <asm/alternative-asm.h>
 
 #ifdef CONFIG_X86_64
 /*
@@ -37,6 +38,7 @@ ENTRY(native_\op\()_safe_regs)
 	movl    %edi, 28(%r10)
 	popq_cfi %rbp
 	popq_cfi %rbx
+	pax_force_retaddr
 	ret
 3:
 	CFI_RESTORE_STATE
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/putuser.S linux-3.2.71-pax/arch/x86/lib/putuser.S
--- linux-3.2.71/arch/x86/lib/putuser.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/putuser.S	2013-05-13 13:26:15.647732470 +0200
@@ -15,7 +15,9 @@
 #include <asm/thread_info.h>
 #include <asm/errno.h>
 #include <asm/asm.h>
-
+#include <asm/segment.h>
+#include <asm/pgtable.h>
+#include <asm/alternative-asm.h>
 
 /*
  * __put_user_X
@@ -29,52 +31,119 @@
  * as they get called from within inline assembly.
  */
 
-#define ENTER	CFI_STARTPROC ; \
-		GET_THREAD_INFO(%_ASM_BX)
-#define EXIT	ret ; \
+#define ENTER	CFI_STARTPROC
+#define EXIT	pax_force_retaddr; ret ; \
 		CFI_ENDPROC
 
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+#define _DEST %_ASM_CX,%_ASM_BX
+#else
+#define _DEST %_ASM_CX
+#endif
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_MEMORY_UDEREF)
+#define __copyuser_seg gs;
+#else
+#define __copyuser_seg
+#endif
+
 .text
 ENTRY(__put_user_1)
 	ENTER
+
+#if !defined(CONFIG_X86_32) || !defined(CONFIG_PAX_MEMORY_UDEREF)
+	GET_THREAD_INFO(%_ASM_BX)
 	cmp TI_addr_limit(%_ASM_BX),%_ASM_CX
 	jae bad_put_user
-1:	movb %al,(%_ASM_CX)
+
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+	mov pax_user_shadow_base,%_ASM_BX
+	cmp %_ASM_BX,%_ASM_CX
+	jb 1234f
+	xor %ebx,%ebx
+1234:
+#endif
+
+#endif
+
+1:	__copyuser_seg movb %al,(_DEST)
 	xor %eax,%eax
 	EXIT
 ENDPROC(__put_user_1)
 
 ENTRY(__put_user_2)
 	ENTER
+
+#if !defined(CONFIG_X86_32) || !defined(CONFIG_PAX_MEMORY_UDEREF)
+	GET_THREAD_INFO(%_ASM_BX)
 	mov TI_addr_limit(%_ASM_BX),%_ASM_BX
 	sub $1,%_ASM_BX
 	cmp %_ASM_BX,%_ASM_CX
 	jae bad_put_user
-2:	movw %ax,(%_ASM_CX)
+
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+	mov pax_user_shadow_base,%_ASM_BX
+	cmp %_ASM_BX,%_ASM_CX
+	jb 1234f
+	xor %ebx,%ebx
+1234:
+#endif
+
+#endif
+
+2:	__copyuser_seg movw %ax,(_DEST)
 	xor %eax,%eax
 	EXIT
 ENDPROC(__put_user_2)
 
 ENTRY(__put_user_4)
 	ENTER
+
+#if !defined(CONFIG_X86_32) || !defined(CONFIG_PAX_MEMORY_UDEREF)
+	GET_THREAD_INFO(%_ASM_BX)
 	mov TI_addr_limit(%_ASM_BX),%_ASM_BX
 	sub $3,%_ASM_BX
 	cmp %_ASM_BX,%_ASM_CX
 	jae bad_put_user
-3:	movl %eax,(%_ASM_CX)
+
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+	mov pax_user_shadow_base,%_ASM_BX
+	cmp %_ASM_BX,%_ASM_CX
+	jb 1234f
+	xor %ebx,%ebx
+1234:
+#endif
+
+#endif
+
+3:	__copyuser_seg movl %eax,(_DEST)
 	xor %eax,%eax
 	EXIT
 ENDPROC(__put_user_4)
 
 ENTRY(__put_user_8)
 	ENTER
+
+#if !defined(CONFIG_X86_32) || !defined(CONFIG_PAX_MEMORY_UDEREF)
+	GET_THREAD_INFO(%_ASM_BX)
 	mov TI_addr_limit(%_ASM_BX),%_ASM_BX
 	sub $7,%_ASM_BX
 	cmp %_ASM_BX,%_ASM_CX
 	jae bad_put_user
-4:	mov %_ASM_AX,(%_ASM_CX)
+
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+	mov pax_user_shadow_base,%_ASM_BX
+	cmp %_ASM_BX,%_ASM_CX
+	jb 1234f
+	xor %ebx,%ebx
+1234:
+#endif
+
+#endif
+
+4:	__copyuser_seg mov %_ASM_AX,(_DEST)
 #ifdef CONFIG_X86_32
-5:	movl %edx,4(%_ASM_CX)
+5:	__copyuser_seg movl %edx,4(_DEST)
 #endif
 	xor %eax,%eax
 	EXIT
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/rwlock.S linux-3.2.71-pax/arch/x86/lib/rwlock.S
--- linux-3.2.71/arch/x86/lib/rwlock.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/rwlock.S	2012-07-04 19:24:47.632063005 +0200
@@ -16,13 +16,34 @@ ENTRY(__write_lock_failed)
 	FRAME
 0:	LOCK_PREFIX
 	WRITE_LOCK_ADD($RW_LOCK_BIAS) (%__lock_ptr)
+
+#ifdef CONFIG_PAX_REFCOUNT
+	jno 1234f
+	LOCK_PREFIX
+	WRITE_LOCK_SUB($RW_LOCK_BIAS) (%__lock_ptr)
+	int $4
+1234:
+	_ASM_EXTABLE(1234b, 1234b)
+#endif
+
 1:	rep; nop
 	cmpl	$WRITE_LOCK_CMP, (%__lock_ptr)
 	jne	1b
 	LOCK_PREFIX
 	WRITE_LOCK_SUB($RW_LOCK_BIAS) (%__lock_ptr)
+
+#ifdef CONFIG_PAX_REFCOUNT
+	jno 1234f
+	LOCK_PREFIX
+	WRITE_LOCK_ADD($RW_LOCK_BIAS) (%__lock_ptr)
+	int $4
+1234:
+	_ASM_EXTABLE(1234b, 1234b)
+#endif
+
 	jnz	0b
 	ENDFRAME
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 END(__write_lock_failed)
@@ -32,13 +53,34 @@ ENTRY(__read_lock_failed)
 	FRAME
 0:	LOCK_PREFIX
 	READ_LOCK_SIZE(inc) (%__lock_ptr)
+
+#ifdef CONFIG_PAX_REFCOUNT
+	jno 1234f
+	LOCK_PREFIX
+	READ_LOCK_SIZE(dec) (%__lock_ptr)
+	int $4
+1234:
+	_ASM_EXTABLE(1234b, 1234b)
+#endif
+
 1:	rep; nop
 	READ_LOCK_SIZE(cmp) $1, (%__lock_ptr)
 	js	1b
 	LOCK_PREFIX
 	READ_LOCK_SIZE(dec) (%__lock_ptr)
+
+#ifdef CONFIG_PAX_REFCOUNT
+	jno 1234f
+	LOCK_PREFIX
+	READ_LOCK_SIZE(inc) (%__lock_ptr)
+	int $4
+1234:
+	_ASM_EXTABLE(1234b, 1234b)
+#endif
+
 	js	0b
 	ENDFRAME
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 END(__read_lock_failed)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/rwsem.S linux-3.2.71-pax/arch/x86/lib/rwsem.S
--- linux-3.2.71/arch/x86/lib/rwsem.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/rwsem.S	2012-07-04 19:24:47.632063005 +0200
@@ -94,6 +94,7 @@ ENTRY(call_rwsem_down_read_failed)
 	__ASM_SIZE(pop,_cfi) %__ASM_REG(dx)
 	CFI_RESTORE __ASM_REG(dx)
 	restore_common_regs
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(call_rwsem_down_read_failed)
@@ -104,6 +105,7 @@ ENTRY(call_rwsem_down_write_failed)
 	movq %rax,%rdi
 	call rwsem_down_write_failed
 	restore_common_regs
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(call_rwsem_down_write_failed)
@@ -117,7 +119,8 @@ ENTRY(call_rwsem_wake)
 	movq %rax,%rdi
 	call rwsem_wake
 	restore_common_regs
-1:	ret
+1:	pax_force_retaddr
+	ret
 	CFI_ENDPROC
 ENDPROC(call_rwsem_wake)
 
@@ -131,6 +134,7 @@ ENTRY(call_rwsem_downgrade_wake)
 	__ASM_SIZE(pop,_cfi) %__ASM_REG(dx)
 	CFI_RESTORE __ASM_REG(dx)
 	restore_common_regs
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(call_rwsem_downgrade_wake)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/thunk_64.S linux-3.2.71-pax/arch/x86/lib/thunk_64.S
--- linux-3.2.71/arch/x86/lib/thunk_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/thunk_64.S	2014-01-27 22:40:30.878167615 +0100
@@ -8,6 +8,7 @@
 #include <linux/linkage.h>
 #include <asm/dwarf2.h>
 #include <asm/calling.h>
+#include <asm/alternative-asm.h>
 
 	/* rdi:	arg1 ... normal C conventions. rax is saved/restored. */
 	.macro THUNK name, func, put_ret_addr_in_rdi=0
@@ -15,11 +16,11 @@
 \name:
 	CFI_STARTPROC
 
-	/* this one pushes 9 elems, the next one would be %rIP */
-	SAVE_ARGS
+	/* this one pushes 15+1 elems, the next one would be %rIP */
+	SAVE_ARGS 8
 
 	.if \put_ret_addr_in_rdi
-	movq_cfi_restore 9*8, rdi
+	movq_cfi_restore RIP, rdi
 	.endif
 
 	call \func
@@ -38,8 +39,9 @@
 
 	/* SAVE_ARGS below is used only for the .cfi directives it contains. */
 	CFI_STARTPROC
-	SAVE_ARGS
+	SAVE_ARGS 8
 restore:
-	RESTORE_ARGS
+	RESTORE_ARGS 1,8
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/usercopy_32.c linux-3.2.71-pax/arch/x86/lib/usercopy_32.c
--- linux-3.2.71/arch/x86/lib/usercopy_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/lib/usercopy_32.c	2013-11-23 18:07:03.485937068 +0100
@@ -43,7 +43,7 @@ do {									   \
 	__asm__ __volatile__(						   \
 		"	testl %1,%1\n"					   \
 		"	jz 2f\n"					   \
-		"0:	lodsb\n"					   \
+		"0:	"__copyuser_seg"lodsb\n"			   \
 		"	stosb\n"					   \
 		"	testb %%al,%%al\n"				   \
 		"	jz 1f\n"					   \
@@ -128,10 +128,12 @@ do {									\
 	int __d0;							\
 	might_fault();							\
 	__asm__ __volatile__(						\
+		__COPYUSER_SET_ES					\
 		"0:	rep; stosl\n"					\
 		"	movl %2,%0\n"					\
 		"1:	rep; stosb\n"					\
 		"2:\n"							\
+		__COPYUSER_RESTORE_ES					\
 		".section .fixup,\"ax\"\n"				\
 		"3:	lea 0(%2,%0,4),%0\n"				\
 		"	jmp 2b\n"					\
@@ -200,6 +202,7 @@ long strnlen_user(const char __user *s,
 	might_fault();
 
 	__asm__ __volatile__(
+		__COPYUSER_SET_ES
 		"	testl %0, %0\n"
 		"	jz 3f\n"
 		"	andl %0,%%ecx\n"
@@ -208,6 +211,7 @@ long strnlen_user(const char __user *s,
 		"	subl %%ecx,%0\n"
 		"	addl %0,%%eax\n"
 		"1:\n"
+		__COPYUSER_RESTORE_ES
 		".section .fixup,\"ax\"\n"
 		"2:	xorl %%eax,%%eax\n"
 		"	jmp 1b\n"
@@ -227,7 +231,7 @@ EXPORT_SYMBOL(strnlen_user);
 
 #ifdef CONFIG_X86_INTEL_USERCOPY
 static unsigned long
-__copy_user_intel(void __user *to, const void *from, unsigned long size)
+__generic_copy_to_user_intel(void __user *to, const void *from, unsigned long size)
 {
 	int d0, d1;
 	__asm__ __volatile__(
@@ -239,36 +243,36 @@ __copy_user_intel(void __user *to, const
 		       "       .align 2,0x90\n"
 		       "3:     movl 0(%4), %%eax\n"
 		       "4:     movl 4(%4), %%edx\n"
-		       "5:     movl %%eax, 0(%3)\n"
-		       "6:     movl %%edx, 4(%3)\n"
+		       "5:     "__copyuser_seg" movl %%eax, 0(%3)\n"
+		       "6:     "__copyuser_seg" movl %%edx, 4(%3)\n"
 		       "7:     movl 8(%4), %%eax\n"
 		       "8:     movl 12(%4),%%edx\n"
-		       "9:     movl %%eax, 8(%3)\n"
-		       "10:    movl %%edx, 12(%3)\n"
+		       "9:     "__copyuser_seg" movl %%eax, 8(%3)\n"
+		       "10:    "__copyuser_seg" movl %%edx, 12(%3)\n"
 		       "11:    movl 16(%4), %%eax\n"
 		       "12:    movl 20(%4), %%edx\n"
-		       "13:    movl %%eax, 16(%3)\n"
-		       "14:    movl %%edx, 20(%3)\n"
+		       "13:    "__copyuser_seg" movl %%eax, 16(%3)\n"
+		       "14:    "__copyuser_seg" movl %%edx, 20(%3)\n"
 		       "15:    movl 24(%4), %%eax\n"
 		       "16:    movl 28(%4), %%edx\n"
-		       "17:    movl %%eax, 24(%3)\n"
-		       "18:    movl %%edx, 28(%3)\n"
+		       "17:    "__copyuser_seg" movl %%eax, 24(%3)\n"
+		       "18:    "__copyuser_seg" movl %%edx, 28(%3)\n"
 		       "19:    movl 32(%4), %%eax\n"
 		       "20:    movl 36(%4), %%edx\n"
-		       "21:    movl %%eax, 32(%3)\n"
-		       "22:    movl %%edx, 36(%3)\n"
+		       "21:    "__copyuser_seg" movl %%eax, 32(%3)\n"
+		       "22:    "__copyuser_seg" movl %%edx, 36(%3)\n"
 		       "23:    movl 40(%4), %%eax\n"
 		       "24:    movl 44(%4), %%edx\n"
-		       "25:    movl %%eax, 40(%3)\n"
-		       "26:    movl %%edx, 44(%3)\n"
+		       "25:    "__copyuser_seg" movl %%eax, 40(%3)\n"
+		       "26:    "__copyuser_seg" movl %%edx, 44(%3)\n"
 		       "27:    movl 48(%4), %%eax\n"
 		       "28:    movl 52(%4), %%edx\n"
-		       "29:    movl %%eax, 48(%3)\n"
-		       "30:    movl %%edx, 52(%3)\n"
+		       "29:    "__copyuser_seg" movl %%eax, 48(%3)\n"
+		       "30:    "__copyuser_seg" movl %%edx, 52(%3)\n"
 		       "31:    movl 56(%4), %%eax\n"
 		       "32:    movl 60(%4), %%edx\n"
-		       "33:    movl %%eax, 56(%3)\n"
-		       "34:    movl %%edx, 60(%3)\n"
+		       "33:    "__copyuser_seg" movl %%eax, 56(%3)\n"
+		       "34:    "__copyuser_seg" movl %%edx, 60(%3)\n"
 		       "       addl $-64, %0\n"
 		       "       addl $64, %4\n"
 		       "       addl $64, %3\n"
@@ -278,10 +282,119 @@ __copy_user_intel(void __user *to, const
 		       "       shrl  $2, %0\n"
 		       "       andl  $3, %%eax\n"
 		       "       cld\n"
+		       __COPYUSER_SET_ES
 		       "99:    rep; movsl\n"
 		       "36:    movl %%eax, %0\n"
 		       "37:    rep; movsb\n"
 		       "100:\n"
+		       __COPYUSER_RESTORE_ES
+		       ".section .fixup,\"ax\"\n"
+		       "101:   lea 0(%%eax,%0,4),%0\n"
+		       "       jmp 100b\n"
+		       ".previous\n"
+		       ".section __ex_table,\"a\"\n"
+		       "       .align 4\n"
+		       "       .long 1b,100b\n"
+		       "       .long 2b,100b\n"
+		       "       .long 3b,100b\n"
+		       "       .long 4b,100b\n"
+		       "       .long 5b,100b\n"
+		       "       .long 6b,100b\n"
+		       "       .long 7b,100b\n"
+		       "       .long 8b,100b\n"
+		       "       .long 9b,100b\n"
+		       "       .long 10b,100b\n"
+		       "       .long 11b,100b\n"
+		       "       .long 12b,100b\n"
+		       "       .long 13b,100b\n"
+		       "       .long 14b,100b\n"
+		       "       .long 15b,100b\n"
+		       "       .long 16b,100b\n"
+		       "       .long 17b,100b\n"
+		       "       .long 18b,100b\n"
+		       "       .long 19b,100b\n"
+		       "       .long 20b,100b\n"
+		       "       .long 21b,100b\n"
+		       "       .long 22b,100b\n"
+		       "       .long 23b,100b\n"
+		       "       .long 24b,100b\n"
+		       "       .long 25b,100b\n"
+		       "       .long 26b,100b\n"
+		       "       .long 27b,100b\n"
+		       "       .long 28b,100b\n"
+		       "       .long 29b,100b\n"
+		       "       .long 30b,100b\n"
+		       "       .long 31b,100b\n"
+		       "       .long 32b,100b\n"
+		       "       .long 33b,100b\n"
+		       "       .long 34b,100b\n"
+		       "       .long 35b,100b\n"
+		       "       .long 36b,100b\n"
+		       "       .long 37b,100b\n"
+		       "       .long 99b,101b\n"
+		       ".previous"
+		       : "=&c"(size), "=&D" (d0), "=&S" (d1)
+		       :  "1"(to), "2"(from), "0"(size)
+		       : "eax", "edx", "memory");
+	return size;
+}
+
+static unsigned long
+__generic_copy_from_user_intel(void *to, const void __user *from, unsigned long size)
+{
+	int d0, d1;
+	__asm__ __volatile__(
+		       "       .align 2,0x90\n"
+		       "1:     "__copyuser_seg" movl 32(%4), %%eax\n"
+		       "       cmpl $67, %0\n"
+		       "       jbe 3f\n"
+		       "2:     "__copyuser_seg" movl 64(%4), %%eax\n"
+		       "       .align 2,0x90\n"
+		       "3:     "__copyuser_seg" movl 0(%4), %%eax\n"
+		       "4:     "__copyuser_seg" movl 4(%4), %%edx\n"
+		       "5:     movl %%eax, 0(%3)\n"
+		       "6:     movl %%edx, 4(%3)\n"
+		       "7:     "__copyuser_seg" movl 8(%4), %%eax\n"
+		       "8:     "__copyuser_seg" movl 12(%4),%%edx\n"
+		       "9:     movl %%eax, 8(%3)\n"
+		       "10:    movl %%edx, 12(%3)\n"
+		       "11:    "__copyuser_seg" movl 16(%4), %%eax\n"
+		       "12:    "__copyuser_seg" movl 20(%4), %%edx\n"
+		       "13:    movl %%eax, 16(%3)\n"
+		       "14:    movl %%edx, 20(%3)\n"
+		       "15:    "__copyuser_seg" movl 24(%4), %%eax\n"
+		       "16:    "__copyuser_seg" movl 28(%4), %%edx\n"
+		       "17:    movl %%eax, 24(%3)\n"
+		       "18:    movl %%edx, 28(%3)\n"
+		       "19:    "__copyuser_seg" movl 32(%4), %%eax\n"
+		       "20:    "__copyuser_seg" movl 36(%4), %%edx\n"
+		       "21:    movl %%eax, 32(%3)\n"
+		       "22:    movl %%edx, 36(%3)\n"
+		       "23:    "__copyuser_seg" movl 40(%4), %%eax\n"
+		       "24:    "__copyuser_seg" movl 44(%4), %%edx\n"
+		       "25:    movl %%eax, 40(%3)\n"
+		       "26:    movl %%edx, 44(%3)\n"
+		       "27:    "__copyuser_seg" movl 48(%4), %%eax\n"
+		       "28:    "__copyuser_seg" movl 52(%4), %%edx\n"
+		       "29:    movl %%eax, 48(%3)\n"
+		       "30:    movl %%edx, 52(%3)\n"
+		       "31:    "__copyuser_seg" movl 56(%4), %%eax\n"
+		       "32:    "__copyuser_seg" movl 60(%4), %%edx\n"
+		       "33:    movl %%eax, 56(%3)\n"
+		       "34:    movl %%edx, 60(%3)\n"
+		       "       addl $-64, %0\n"
+		       "       addl $64, %4\n"
+		       "       addl $64, %3\n"
+		       "       cmpl $63, %0\n"
+		       "       ja  1b\n"
+		       "35:    movl  %0, %%eax\n"
+		       "       shrl  $2, %0\n"
+		       "       andl  $3, %%eax\n"
+		       "       cld\n"
+		       "99:    rep; "__copyuser_seg" movsl\n"
+		       "36:    movl %%eax, %0\n"
+		       "37:    rep; "__copyuser_seg" movsb\n"
+		       "100:\n"
 		       ".section .fixup,\"ax\"\n"
 		       "101:   lea 0(%%eax,%0,4),%0\n"
 		       "       jmp 100b\n"
@@ -339,41 +452,41 @@ __copy_user_zeroing_intel(void *to, cons
 	int d0, d1;
 	__asm__ __volatile__(
 		       "        .align 2,0x90\n"
-		       "0:      movl 32(%4), %%eax\n"
+		       "0:      "__copyuser_seg" movl 32(%4), %%eax\n"
 		       "        cmpl $67, %0\n"
 		       "        jbe 2f\n"
-		       "1:      movl 64(%4), %%eax\n"
+		       "1:      "__copyuser_seg" movl 64(%4), %%eax\n"
 		       "        .align 2,0x90\n"
-		       "2:      movl 0(%4), %%eax\n"
-		       "21:     movl 4(%4), %%edx\n"
+		       "2:      "__copyuser_seg" movl 0(%4), %%eax\n"
+		       "21:     "__copyuser_seg" movl 4(%4), %%edx\n"
 		       "        movl %%eax, 0(%3)\n"
 		       "        movl %%edx, 4(%3)\n"
-		       "3:      movl 8(%4), %%eax\n"
-		       "31:     movl 12(%4),%%edx\n"
+		       "3:      "__copyuser_seg" movl 8(%4), %%eax\n"
+		       "31:     "__copyuser_seg" movl 12(%4),%%edx\n"
 		       "        movl %%eax, 8(%3)\n"
 		       "        movl %%edx, 12(%3)\n"
-		       "4:      movl 16(%4), %%eax\n"
-		       "41:     movl 20(%4), %%edx\n"
+		       "4:      "__copyuser_seg" movl 16(%4), %%eax\n"
+		       "41:     "__copyuser_seg" movl 20(%4), %%edx\n"
 		       "        movl %%eax, 16(%3)\n"
 		       "        movl %%edx, 20(%3)\n"
-		       "10:     movl 24(%4), %%eax\n"
-		       "51:     movl 28(%4), %%edx\n"
+		       "10:     "__copyuser_seg" movl 24(%4), %%eax\n"
+		       "51:     "__copyuser_seg" movl 28(%4), %%edx\n"
 		       "        movl %%eax, 24(%3)\n"
 		       "        movl %%edx, 28(%3)\n"
-		       "11:     movl 32(%4), %%eax\n"
-		       "61:     movl 36(%4), %%edx\n"
+		       "11:     "__copyuser_seg" movl 32(%4), %%eax\n"
+		       "61:     "__copyuser_seg" movl 36(%4), %%edx\n"
 		       "        movl %%eax, 32(%3)\n"
 		       "        movl %%edx, 36(%3)\n"
-		       "12:     movl 40(%4), %%eax\n"
-		       "71:     movl 44(%4), %%edx\n"
+		       "12:     "__copyuser_seg" movl 40(%4), %%eax\n"
+		       "71:     "__copyuser_seg" movl 44(%4), %%edx\n"
 		       "        movl %%eax, 40(%3)\n"
 		       "        movl %%edx, 44(%3)\n"
-		       "13:     movl 48(%4), %%eax\n"
-		       "81:     movl 52(%4), %%edx\n"
+		       "13:     "__copyuser_seg" movl 48(%4), %%eax\n"
+		       "81:     "__copyuser_seg" movl 52(%4), %%edx\n"
 		       "        movl %%eax, 48(%3)\n"
 		       "        movl %%edx, 52(%3)\n"
-		       "14:     movl 56(%4), %%eax\n"
-		       "91:     movl 60(%4), %%edx\n"
+		       "14:     "__copyuser_seg" movl 56(%4), %%eax\n"
+		       "91:     "__copyuser_seg" movl 60(%4), %%edx\n"
 		       "        movl %%eax, 56(%3)\n"
 		       "        movl %%edx, 60(%3)\n"
 		       "        addl $-64, %0\n"
@@ -385,9 +498,9 @@ __copy_user_zeroing_intel(void *to, cons
 		       "        shrl  $2, %0\n"
 		       "        andl $3, %%eax\n"
 		       "        cld\n"
-		       "6:      rep; movsl\n"
+		       "6:      rep; "__copyuser_seg" movsl\n"
 		       "        movl %%eax,%0\n"
-		       "7:      rep; movsb\n"
+		       "7:      rep; "__copyuser_seg" movsb\n"
 		       "8:\n"
 		       ".section .fixup,\"ax\"\n"
 		       "9:      lea 0(%%eax,%0,4),%0\n"
@@ -440,41 +553,41 @@ static unsigned long __copy_user_zeroing
 
 	__asm__ __volatile__(
 	       "        .align 2,0x90\n"
-	       "0:      movl 32(%4), %%eax\n"
+	       "0:      "__copyuser_seg" movl 32(%4), %%eax\n"
 	       "        cmpl $67, %0\n"
 	       "        jbe 2f\n"
-	       "1:      movl 64(%4), %%eax\n"
+	       "1:      "__copyuser_seg" movl 64(%4), %%eax\n"
 	       "        .align 2,0x90\n"
-	       "2:      movl 0(%4), %%eax\n"
-	       "21:     movl 4(%4), %%edx\n"
+	       "2:      "__copyuser_seg" movl 0(%4), %%eax\n"
+	       "21:     "__copyuser_seg" movl 4(%4), %%edx\n"
 	       "        movnti %%eax, 0(%3)\n"
 	       "        movnti %%edx, 4(%3)\n"
-	       "3:      movl 8(%4), %%eax\n"
-	       "31:     movl 12(%4),%%edx\n"
+	       "3:      "__copyuser_seg" movl 8(%4), %%eax\n"
+	       "31:     "__copyuser_seg" movl 12(%4),%%edx\n"
 	       "        movnti %%eax, 8(%3)\n"
 	       "        movnti %%edx, 12(%3)\n"
-	       "4:      movl 16(%4), %%eax\n"
-	       "41:     movl 20(%4), %%edx\n"
+	       "4:      "__copyuser_seg" movl 16(%4), %%eax\n"
+	       "41:     "__copyuser_seg" movl 20(%4), %%edx\n"
 	       "        movnti %%eax, 16(%3)\n"
 	       "        movnti %%edx, 20(%3)\n"
-	       "10:     movl 24(%4), %%eax\n"
-	       "51:     movl 28(%4), %%edx\n"
+	       "10:     "__copyuser_seg" movl 24(%4), %%eax\n"
+	       "51:     "__copyuser_seg" movl 28(%4), %%edx\n"
 	       "        movnti %%eax, 24(%3)\n"
 	       "        movnti %%edx, 28(%3)\n"
-	       "11:     movl 32(%4), %%eax\n"
-	       "61:     movl 36(%4), %%edx\n"
+	       "11:     "__copyuser_seg" movl 32(%4), %%eax\n"
+	       "61:     "__copyuser_seg" movl 36(%4), %%edx\n"
 	       "        movnti %%eax, 32(%3)\n"
 	       "        movnti %%edx, 36(%3)\n"
-	       "12:     movl 40(%4), %%eax\n"
-	       "71:     movl 44(%4), %%edx\n"
+	       "12:     "__copyuser_seg" movl 40(%4), %%eax\n"
+	       "71:     "__copyuser_seg" movl 44(%4), %%edx\n"
 	       "        movnti %%eax, 40(%3)\n"
 	       "        movnti %%edx, 44(%3)\n"
-	       "13:     movl 48(%4), %%eax\n"
-	       "81:     movl 52(%4), %%edx\n"
+	       "13:     "__copyuser_seg" movl 48(%4), %%eax\n"
+	       "81:     "__copyuser_seg" movl 52(%4), %%edx\n"
 	       "        movnti %%eax, 48(%3)\n"
 	       "        movnti %%edx, 52(%3)\n"
-	       "14:     movl 56(%4), %%eax\n"
-	       "91:     movl 60(%4), %%edx\n"
+	       "14:     "__copyuser_seg" movl 56(%4), %%eax\n"
+	       "91:     "__copyuser_seg" movl 60(%4), %%edx\n"
 	       "        movnti %%eax, 56(%3)\n"
 	       "        movnti %%edx, 60(%3)\n"
 	       "        addl $-64, %0\n"
@@ -487,9 +600,9 @@ static unsigned long __copy_user_zeroing
 	       "        shrl  $2, %0\n"
 	       "        andl $3, %%eax\n"
 	       "        cld\n"
-	       "6:      rep; movsl\n"
+	       "6:      rep; "__copyuser_seg" movsl\n"
 	       "        movl %%eax,%0\n"
-	       "7:      rep; movsb\n"
+	       "7:      rep; "__copyuser_seg" movsb\n"
 	       "8:\n"
 	       ".section .fixup,\"ax\"\n"
 	       "9:      lea 0(%%eax,%0,4),%0\n"
@@ -537,41 +650,41 @@ static unsigned long __copy_user_intel_n
 
 	__asm__ __volatile__(
 	       "        .align 2,0x90\n"
-	       "0:      movl 32(%4), %%eax\n"
+	       "0:      "__copyuser_seg" movl 32(%4), %%eax\n"
 	       "        cmpl $67, %0\n"
 	       "        jbe 2f\n"
-	       "1:      movl 64(%4), %%eax\n"
+	       "1:      "__copyuser_seg" movl 64(%4), %%eax\n"
 	       "        .align 2,0x90\n"
-	       "2:      movl 0(%4), %%eax\n"
-	       "21:     movl 4(%4), %%edx\n"
+	       "2:      "__copyuser_seg" movl 0(%4), %%eax\n"
+	       "21:     "__copyuser_seg" movl 4(%4), %%edx\n"
 	       "        movnti %%eax, 0(%3)\n"
 	       "        movnti %%edx, 4(%3)\n"
-	       "3:      movl 8(%4), %%eax\n"
-	       "31:     movl 12(%4),%%edx\n"
+	       "3:      "__copyuser_seg" movl 8(%4), %%eax\n"
+	       "31:     "__copyuser_seg" movl 12(%4),%%edx\n"
 	       "        movnti %%eax, 8(%3)\n"
 	       "        movnti %%edx, 12(%3)\n"
-	       "4:      movl 16(%4), %%eax\n"
-	       "41:     movl 20(%4), %%edx\n"
+	       "4:      "__copyuser_seg" movl 16(%4), %%eax\n"
+	       "41:     "__copyuser_seg" movl 20(%4), %%edx\n"
 	       "        movnti %%eax, 16(%3)\n"
 	       "        movnti %%edx, 20(%3)\n"
-	       "10:     movl 24(%4), %%eax\n"
-	       "51:     movl 28(%4), %%edx\n"
+	       "10:     "__copyuser_seg" movl 24(%4), %%eax\n"
+	       "51:     "__copyuser_seg" movl 28(%4), %%edx\n"
 	       "        movnti %%eax, 24(%3)\n"
 	       "        movnti %%edx, 28(%3)\n"
-	       "11:     movl 32(%4), %%eax\n"
-	       "61:     movl 36(%4), %%edx\n"
+	       "11:     "__copyuser_seg" movl 32(%4), %%eax\n"
+	       "61:     "__copyuser_seg" movl 36(%4), %%edx\n"
 	       "        movnti %%eax, 32(%3)\n"
 	       "        movnti %%edx, 36(%3)\n"
-	       "12:     movl 40(%4), %%eax\n"
-	       "71:     movl 44(%4), %%edx\n"
+	       "12:     "__copyuser_seg" movl 40(%4), %%eax\n"
+	       "71:     "__copyuser_seg" movl 44(%4), %%edx\n"
 	       "        movnti %%eax, 40(%3)\n"
 	       "        movnti %%edx, 44(%3)\n"
-	       "13:     movl 48(%4), %%eax\n"
-	       "81:     movl 52(%4), %%edx\n"
+	       "13:     "__copyuser_seg" movl 48(%4), %%eax\n"
+	       "81:     "__copyuser_seg" movl 52(%4), %%edx\n"
 	       "        movnti %%eax, 48(%3)\n"
 	       "        movnti %%edx, 52(%3)\n"
-	       "14:     movl 56(%4), %%eax\n"
-	       "91:     movl 60(%4), %%edx\n"
+	       "14:     "__copyuser_seg" movl 56(%4), %%eax\n"
+	       "91:     "__copyuser_seg" movl 60(%4), %%edx\n"
 	       "        movnti %%eax, 56(%3)\n"
 	       "        movnti %%edx, 60(%3)\n"
 	       "        addl $-64, %0\n"
@@ -584,9 +697,9 @@ static unsigned long __copy_user_intel_n
 	       "        shrl  $2, %0\n"
 	       "        andl $3, %%eax\n"
 	       "        cld\n"
-	       "6:      rep; movsl\n"
+	       "6:      rep; "__copyuser_seg" movsl\n"
 	       "        movl %%eax,%0\n"
-	       "7:      rep; movsb\n"
+	       "7:      rep; "__copyuser_seg" movsb\n"
 	       "8:\n"
 	       ".section .fixup,\"ax\"\n"
 	       "9:      lea 0(%%eax,%0,4),%0\n"
@@ -629,32 +742,36 @@ static unsigned long __copy_user_intel_n
  */
 unsigned long __copy_user_zeroing_intel(void *to, const void __user *from,
 					unsigned long size);
-unsigned long __copy_user_intel(void __user *to, const void *from,
+unsigned long __generic_copy_to_user_intel(void __user *to, const void *from,
+					unsigned long size);
+unsigned long __generic_copy_from_user_intel(void *to, const void __user *from,
 					unsigned long size);
 unsigned long __copy_user_zeroing_intel_nocache(void *to,
 				const void __user *from, unsigned long size);
 #endif /* CONFIG_X86_INTEL_USERCOPY */
 
 /* Generic arbitrary sized copy.  */
-#define __copy_user(to, from, size)					\
+#define __copy_user(to, from, size, prefix, set, restore)		\
 do {									\
 	int __d0, __d1, __d2;						\
 	__asm__ __volatile__(						\
+		set							\
 		"	cmp  $7,%0\n"					\
 		"	jbe  1f\n"					\
 		"	movl %1,%0\n"					\
 		"	negl %0\n"					\
 		"	andl $7,%0\n"					\
 		"	subl %0,%3\n"					\
-		"4:	rep; movsb\n"					\
+		"4:	rep; "prefix"movsb\n"				\
 		"	movl %3,%0\n"					\
 		"	shrl $2,%0\n"					\
 		"	andl $3,%3\n"					\
 		"	.align 2,0x90\n"				\
-		"0:	rep; movsl\n"					\
+		"0:	rep; "prefix"movsl\n"				\
 		"	movl %3,%0\n"					\
-		"1:	rep; movsb\n"					\
+		"1:	rep; "prefix"movsb\n"				\
 		"2:\n"							\
+		restore							\
 		".section .fixup,\"ax\"\n"				\
 		"5:	addl %3,%0\n"					\
 		"	jmp 2b\n"					\
@@ -682,14 +799,14 @@ do {									\
 		"	negl %0\n"					\
 		"	andl $7,%0\n"					\
 		"	subl %0,%3\n"					\
-		"4:	rep; movsb\n"					\
+		"4:	rep; "__copyuser_seg"movsb\n"			\
 		"	movl %3,%0\n"					\
 		"	shrl $2,%0\n"					\
 		"	andl $3,%3\n"					\
 		"	.align 2,0x90\n"				\
-		"0:	rep; movsl\n"					\
+		"0:	rep; "__copyuser_seg"movsl\n"			\
 		"	movl %3,%0\n"					\
-		"1:	rep; movsb\n"					\
+		"1:	rep; "__copyuser_seg"movsb\n"			\
 		"2:\n"							\
 		".section .fixup,\"ax\"\n"				\
 		"5:	addl %3,%0\n"					\
@@ -775,9 +892,9 @@ survive:
 	}
 #endif
 	if (movsl_is_ok(to, from, n))
-		__copy_user(to, from, n);
+		__copy_user(to, from, n, "", __COPYUSER_SET_ES, __COPYUSER_RESTORE_ES);
 	else
-		n = __copy_user_intel(to, from, n);
+		n = __generic_copy_to_user_intel(to, from, n);
 	return n;
 }
 EXPORT_SYMBOL(__copy_to_user_ll);
@@ -797,10 +914,9 @@ unsigned long __copy_from_user_ll_nozero
 					 unsigned long n)
 {
 	if (movsl_is_ok(to, from, n))
-		__copy_user(to, from, n);
+		__copy_user(to, from, n, __copyuser_seg, "", "");
 	else
-		n = __copy_user_intel((void __user *)to,
-				      (const void *)from, n);
+		n = __generic_copy_from_user_intel(to, from, n);
 	return n;
 }
 EXPORT_SYMBOL(__copy_from_user_ll_nozero);
@@ -827,65 +943,49 @@ unsigned long __copy_from_user_ll_nocach
 	if (n > 64 && cpu_has_xmm2)
 		n = __copy_user_intel_nocache(to, from, n);
 	else
-		__copy_user(to, from, n);
+		__copy_user(to, from, n, __copyuser_seg, "", "");
 #else
-	__copy_user(to, from, n);
+	__copy_user(to, from, n, __copyuser_seg, "", "");
 #endif
 	return n;
 }
 EXPORT_SYMBOL(__copy_from_user_ll_nocache_nozero);
 
-/**
- * copy_to_user: - Copy a block of data into user space.
- * @to:   Destination address, in user space.
- * @from: Source address, in kernel space.
- * @n:    Number of bytes to copy.
- *
- * Context: User context only.  This function may sleep.
- *
- * Copy data from kernel space to user space.
- *
- * Returns number of bytes that could not be copied.
- * On success, this will be zero.
- */
-unsigned long
-copy_to_user(void __user *to, const void *from, unsigned long n)
+void copy_from_user_overflow(void)
 {
-	if (access_ok(VERIFY_WRITE, to, n))
-		n = __copy_to_user(to, from, n);
-	return n;
+	WARN(1, "Buffer overflow detected!\n");
 }
-EXPORT_SYMBOL(copy_to_user);
+EXPORT_SYMBOL(copy_from_user_overflow);
 
-/**
- * copy_from_user: - Copy a block of data from user space.
- * @to:   Destination address, in kernel space.
- * @from: Source address, in user space.
- * @n:    Number of bytes to copy.
- *
- * Context: User context only.  This function may sleep.
- *
- * Copy data from user space to kernel space.
- *
- * Returns number of bytes that could not be copied.
- * On success, this will be zero.
- *
- * If some data could not be copied, this function will pad the copied
- * data to the requested size using zero bytes.
- */
-unsigned long
-_copy_from_user(void *to, const void __user *from, unsigned long n)
+void copy_to_user_overflow(void)
 {
-	if (access_ok(VERIFY_READ, from, n))
-		n = __copy_from_user(to, from, n);
-	else
-		memset(to, 0, n);
-	return n;
+	WARN(1, "Buffer overflow detected!\n");
 }
-EXPORT_SYMBOL(_copy_from_user);
+EXPORT_SYMBOL(copy_to_user_overflow);
 
-void copy_from_user_overflow(void)
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+void __set_fs(mm_segment_t x)
 {
-	WARN(1, "Buffer overflow detected!\n");
+	switch (x.seg) {
+	case 0:
+		loadsegment(gs, 0);
+		break;
+	case TASK_SIZE_MAX:
+		loadsegment(gs, __USER_DS);
+		break;
+	case -1UL:
+		loadsegment(gs, __KERNEL_DS);
+		break;
+	default:
+		BUG();
+	}
 }
-EXPORT_SYMBOL(copy_from_user_overflow);
+EXPORT_SYMBOL(__set_fs);
+
+void set_fs(mm_segment_t x)
+{
+	current_thread_info()->addr_limit = x;
+	__set_fs(x);
+}
+EXPORT_SYMBOL(set_fs);
+#endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/lib/usercopy_64.c linux-3.2.71-pax/arch/x86/lib/usercopy_64.c
--- linux-3.2.71/arch/x86/lib/usercopy_64.c	2015-08-07 11:37:20.379789888 +0200
+++ linux-3.2.71-pax/arch/x86/lib/usercopy_64.c	2015-08-07 11:37:42.995790553 +0200
@@ -42,6 +42,12 @@ long
 __strncpy_from_user(char *dst, const char __user *src, long count)
 {
 	long res;
+
+#ifdef CONFIG_PAX_MEMORY_UDEREF
+	if ((unsigned long)src < pax_user_shadow_base)
+		src += pax_user_shadow_base;
+#endif
+
 	__do_strncpy_from_user(dst, src, count, res);
 	return res;
 }
@@ -87,7 +93,7 @@ unsigned long __clear_user(void __user *
 		_ASM_EXTABLE(0b,3b)
 		_ASM_EXTABLE(1b,2b)
 		: [size8] "=&c"(size), [dst] "=&D" (__d0)
-		: [size1] "r"(size & 7), "[size8]" (size / 8), "[dst]"(addr),
+		: [size1] "r"(size & 7), "[size8]" (size / 8), "[dst]"(____m(addr)),
 		  [zero] "r" (0UL), [eight] "r" (8UL));
 	return size;
 }
@@ -149,12 +155,11 @@ long strlen_user(const char __user *s)
 }
 EXPORT_SYMBOL(strlen_user);
 
-unsigned long copy_in_user(void __user *to, const void __user *from, unsigned len)
+unsigned long copy_in_user(void __user *to, const void __user *from, unsigned long len)
 {
-	if (access_ok(VERIFY_WRITE, to, len) && access_ok(VERIFY_READ, from, len)) { 
-		return copy_user_generic((__force void *)to, (__force void *)from, len);
-	} 
-	return len;		
+	if (access_ok(VERIFY_WRITE, to, len) && access_ok(VERIFY_READ, from, len))
+		return copy_user_generic((void __force_kernel *)____m(to), (void __force_kernel *)____m(from), len);
+	return len;
 }
 EXPORT_SYMBOL(copy_in_user);
 
@@ -164,7 +169,7 @@ EXPORT_SYMBOL(copy_in_user);
  * it is not necessary to optimize tail handling.
  */
 unsigned long
-copy_user_handle_tail(char *to, char *from, unsigned len, unsigned zerorest)
+copy_user_handle_tail(char __user *to, char __user *from, unsigned long len, unsigned zerorest)
 {
 	char c;
 	unsigned zero_len;
@@ -181,3 +186,15 @@ copy_user_handle_tail(char *to, char *fr
 			break;
 	return len;
 }
+
+void copy_from_user_overflow(void)
+{
+	WARN(1, "Buffer overflow detected!\n");
+}
+EXPORT_SYMBOL(copy_from_user_overflow);
+
+void copy_to_user_overflow(void)
+{
+	WARN(1, "Buffer overflow detected!\n");
+}
+EXPORT_SYMBOL(copy_to_user_overflow);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/Makefile linux-3.2.71-pax/arch/x86/Makefile
--- linux-3.2.71/arch/x86/Makefile	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/Makefile	2013-11-23 18:07:03.441937067 +0100
@@ -40,12 +40,12 @@ ifeq ($(CONFIG_X86_32),y)
         KBUILD_CFLAGS += $(cflags-y)
 
         # temporary until string.h is fixed
-        KBUILD_CFLAGS += -ffreestanding
 else
         BITS := 64
         UTS_MACHINE := x86_64
         CHECKFLAGS += -D__x86_64__ -m64
 
+        biarch := $(call cc-option,-m64)
         KBUILD_AFLAGS += -m64
         KBUILD_CFLAGS += -m64
 
@@ -72,6 +72,8 @@ else
         KBUILD_CFLAGS += -maccumulate-outgoing-args
 endif
 
+KBUILD_CFLAGS += -ffreestanding
+
 ifdef CONFIG_CC_STACKPROTECTOR
 	cc_has_sp := $(srctree)/scripts/gcc-x86_$(BITS)-has-stack-protector.sh
         ifeq ($(shell $(CONFIG_SHELL) $(cc_has_sp) $(CC) $(KBUILD_CPPFLAGS) $(biarch)),y)
@@ -199,3 +201,12 @@ define archhelp
   echo  '                  FDARGS="..."  arguments for the booted kernel'
   echo  '                  FDINITRD=file initrd for the booted kernel'
 endef
+
+define OLD_LD
+
+*** ${VERSION}.${PATCHLEVEL} PaX kernels no longer build correctly with old versions of binutils.
+*** Please upgrade your binutils to 2.18 or newer
+endef
+
+archprepare:
+	$(if $(LDFLAGS_BUILD_ID),,$(error $(OLD_LD)))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/extable.c linux-3.2.71-pax/arch/x86/mm/extable.c
--- linux-3.2.71/arch/x86/mm/extable.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/extable.c	2012-07-04 19:24:47.636063004 +0200
@@ -8,7 +8,7 @@ int fixup_exception(struct pt_regs *regs
 	const struct exception_table_entry *fixup;
 
 #ifdef CONFIG_PNPBIOS
-	if (unlikely(SEGMENT_IS_PNP_CODE(regs->cs))) {
+	if (unlikely(!v8086_mode(regs) && SEGMENT_IS_PNP_CODE(regs->cs))) {
 		extern u32 pnp_bios_fault_eip, pnp_bios_fault_esp;
 		extern u32 pnp_bios_is_utter_crap;
 		pnp_bios_is_utter_crap = 1;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/fault.c linux-3.2.71-pax/arch/x86/mm/fault.c
--- linux-3.2.71/arch/x86/mm/fault.c	2015-03-06 19:43:09.676464844 +0100
+++ linux-3.2.71-pax/arch/x86/mm/fault.c	2015-06-28 11:17:48.158538259 +0200
@@ -13,11 +13,18 @@
 #include <linux/perf_event.h>		/* perf_sw_event		*/
 #include <linux/hugetlb.h>		/* hstate_index_to_shift	*/
 #include <linux/prefetch.h>		/* prefetchw			*/
+#include <linux/unistd.h>
+#include <linux/compiler.h>
 
 #include <asm/traps.h>			/* dotraplinkage, ...		*/
 #include <asm/pgalloc.h>		/* pgd_*(), ...			*/
 #include <asm/kmemcheck.h>		/* kmemcheck_*(), ...		*/
 #include <asm/fixmap.h>			/* VSYSCALL_START		*/
+#include <asm/tlbflush.h>
+
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+#include <asm/stacktrace.h>
+#endif
 
 /*
  * Page fault error code bits:
@@ -55,7 +62,7 @@ static inline int __kprobes notify_page_
 	int ret = 0;
 
 	/* kprobe_running() needs smp_processor_id() */
-	if (kprobes_built_in() && !user_mode_vm(regs)) {
+	if (kprobes_built_in() && !user_mode(regs)) {
 		preempt_disable();
 		if (kprobe_running() && kprobe_fault_handler(regs, 14))
 			ret = 1;
@@ -116,7 +123,10 @@ check_prefetch_opcode(struct pt_regs *re
 		return !instr_lo || (instr_lo>>1) == 1;
 	case 0x00:
 		/* Prefetch instruction is 0x0F0D or 0x0F18 */
-		if (probe_kernel_address(instr, opcode))
+		if (user_mode(regs)) {
+			if (__copy_from_user_inatomic(&opcode, (unsigned char __force_user *)(instr), 1))
+				return 0;
+		} else if (probe_kernel_address(instr, opcode))
 			return 0;
 
 		*prefetch = (instr_lo == 0xF) &&
@@ -150,7 +160,10 @@ is_prefetch(struct pt_regs *regs, unsign
 	while (instr < max_instr) {
 		unsigned char opcode;
 
-		if (probe_kernel_address(instr, opcode))
+		if (user_mode(regs)) {
+			if (__copy_from_user_inatomic(&opcode, (unsigned char __force_user *)(instr), 1))
+				break;
+		} else if (probe_kernel_address(instr, opcode))
 			break;
 
 		instr++;
@@ -181,6 +194,34 @@ force_sig_info_fault(int si_signo, int s
 	force_sig_info(si_signo, &info, tsk);
 }
 
+#if defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC)
+static bool pax_is_fetch_fault(struct pt_regs *regs, unsigned long error_code, unsigned long address);
+#endif
+
+#ifdef CONFIG_PAX_EMUTRAMP
+static int pax_handle_fetch_fault(struct pt_regs *regs);
+#endif
+
+#ifdef CONFIG_PAX_PAGEEXEC
+static inline pmd_t * pax_get_pmd(struct mm_struct *mm, unsigned long address)
+{
+	pgd_t *pgd;
+	pud_t *pud;
+	pmd_t *pmd;
+
+	pgd = pgd_offset(mm, address);
+	if (!pgd_present(*pgd))
+		return NULL;
+	pud = pud_offset(pgd, address);
+	if (!pud_present(*pud))
+		return NULL;
+	pmd = pmd_offset(pud, address);
+	if (!pmd_present(*pmd))
+		return NULL;
+	return pmd;
+}
+#endif
+
 DEFINE_SPINLOCK(pgd_lock);
 LIST_HEAD(pgd_list);
 
@@ -231,10 +272,22 @@ void vmalloc_sync_all(void)
 	for (address = VMALLOC_START & PMD_MASK;
 	     address >= TASK_SIZE && address < FIXADDR_TOP;
 	     address += PMD_SIZE) {
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+		unsigned long cpu;
+#else
 		struct page *page;
+#endif
 
 		spin_lock(&pgd_lock);
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+		for (cpu = 0; cpu < nr_cpu_ids; ++cpu) {
+			pgd_t *pgd = get_cpu_pgd(cpu);
+			pmd_t *ret;
+#else
 		list_for_each_entry(page, &pgd_list, lru) {
+			pgd_t *pgd;
 			spinlock_t *pgt_lock;
 			pmd_t *ret;
 
@@ -242,8 +295,14 @@ void vmalloc_sync_all(void)
 			pgt_lock = &pgd_page_get_mm(page)->page_table_lock;
 
 			spin_lock(pgt_lock);
-			ret = vmalloc_sync_one(page_address(page), address);
+			pgd = page_address(page);
+#endif
+
+			ret = vmalloc_sync_one(pgd, address);
+
+#ifndef CONFIG_PAX_PER_CPU_PGD
 			spin_unlock(pgt_lock);
+#endif
 
 			if (!ret)
 				break;
@@ -277,6 +336,11 @@ static noinline __kprobes int vmalloc_fa
 	 * an interrupt in the middle of a task switch..
 	 */
 	pgd_paddr = read_cr3();
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+	BUG_ON(__pa(get_cpu_pgd(smp_processor_id())) != (pgd_paddr & PHYSICAL_PAGE_MASK));
+#endif
+
 	pmd_k = vmalloc_sync_one(__va(pgd_paddr), address);
 	if (!pmd_k)
 		return -1;
@@ -372,7 +436,14 @@ static noinline __kprobes int vmalloc_fa
 	 * happen within a race in page table update. In the later
 	 * case just flush:
 	 */
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+	BUG_ON(__pa(get_cpu_pgd(smp_processor_id())) != (read_cr3() & PHYSICAL_PAGE_MASK));
+	pgd = pgd_offset_cpu(smp_processor_id(), address);
+#else
 	pgd = pgd_offset(current->active_mm, address);
+#endif
+
 	pgd_ref = pgd_offset_k(address);
 	if (pgd_none(*pgd_ref))
 		return -1;
@@ -542,7 +613,7 @@ static int is_errata93(struct pt_regs *r
 static int is_errata100(struct pt_regs *regs, unsigned long address)
 {
 #ifdef CONFIG_X86_64
-	if ((regs->cs == __USER32_CS || (regs->cs & (1<<2))) && (address >> 32))
+	if ((regs->cs == __USER32_CS || (regs->cs & SEGMENT_LDT)) && (address >> 32))
 		return 1;
 #endif
 	return 0;
@@ -569,7 +640,7 @@ static int is_f00f_bug(struct pt_regs *r
 }
 
 static const char nx_warning[] = KERN_CRIT
-"kernel tried to execute NX-protected page - exploit attempt? (uid: %d)\n";
+"kernel tried to execute NX-protected page - exploit attempt? (uid: %d, task: %s, pid: %d)\n";
 
 static void
 show_fault_oops(struct pt_regs *regs, unsigned long error_code,
@@ -578,15 +649,21 @@ show_fault_oops(struct pt_regs *regs, un
 	if (!oops_may_print())
 		return;
 
-	if (error_code & PF_INSTR) {
+	if ((__supported_pte_mask & _PAGE_NX) && (error_code & PF_INSTR)) {
 		unsigned int level;
 
 		pte_t *pte = lookup_address(address, &level);
 
 		if (pte && pte_present(*pte) && !pte_exec(*pte))
-			printk(nx_warning, current_uid());
+			printk(nx_warning, current_uid(), current->comm, task_pid_nr(current));
 	}
 
+#ifdef CONFIG_PAX_KERNEXEC
+	if (init_mm.start_code <= address && address < init_mm.end_code)
+		printk(KERN_EMERG "PAX: %s:%d, uid/euid: %u/%u, attempted to modify kernel code\n",
+				 current->comm, task_pid_nr(current), current_uid(), current_euid());
+#endif
+
 	printk(KERN_ALERT "BUG: unable to handle kernel ");
 	if (address < PAGE_SIZE)
 		printk(KERN_CONT "NULL pointer dereference");
@@ -740,6 +817,22 @@ __bad_area_nosemaphore(struct pt_regs *r
 				return;
 		}
 #endif
+
+#if defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC)
+		if (pax_is_fetch_fault(regs, error_code, address)) {
+
+#ifdef CONFIG_PAX_EMUTRAMP
+			switch (pax_handle_fetch_fault(regs)) {
+			case 2:
+				return;
+			}
+#endif
+
+			pax_report_fault(regs, (void *)regs->ip, (void *)regs->sp);
+			do_group_exit(SIGKILL);
+		}
+#endif
+
 		/* Kernel addresses are always protection faults: */
 		if (address >= TASK_SIZE)
 			error_code |= PF_PROT;
@@ -839,7 +932,7 @@ do_sigbus(struct pt_regs *regs, unsigned
 	if (fault & (VM_FAULT_HWPOISON|VM_FAULT_HWPOISON_LARGE)) {
 		printk(KERN_ERR
 	"MCE: Killing %s:%d due to hardware memory corruption fault at %lx\n",
-			tsk->comm, tsk->pid, address);
+			tsk->comm, task_pid_nr(tsk), address);
 		code = BUS_MCEERR_AR;
 	}
 #endif
@@ -896,6 +989,99 @@ static int spurious_fault_check(unsigned
 	return 1;
 }
 
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_PAGEEXEC)
+static int pax_handle_pageexec_fault(struct pt_regs *regs, struct mm_struct *mm, unsigned long address, unsigned long error_code)
+{
+	pte_t *pte;
+	pmd_t *pmd;
+	spinlock_t *ptl;
+	unsigned char pte_mask;
+
+	if ((__supported_pte_mask & _PAGE_NX) || (error_code & (PF_PROT|PF_USER)) != (PF_PROT|PF_USER) || v8086_mode(regs) ||
+	    !(mm->pax_flags & MF_PAX_PAGEEXEC))
+		return 0;
+
+	/* PaX: it's our fault, let's handle it if we can */
+
+	/* PaX: take a look at read faults before acquiring any locks */
+	if (unlikely(!(error_code & PF_WRITE) && (regs->ip == address))) {
+		/* instruction fetch attempt from a protected page in user mode */
+		up_read(&mm->mmap_sem);
+
+#ifdef CONFIG_PAX_EMUTRAMP
+		switch (pax_handle_fetch_fault(regs)) {
+		case 2:
+			return 1;
+		}
+#endif
+
+		pax_report_fault(regs, (void *)regs->ip, (void *)regs->sp);
+		do_group_exit(SIGKILL);
+	}
+
+	pmd = pax_get_pmd(mm, address);
+	if (unlikely(!pmd))
+		return 0;
+
+	pte = pte_offset_map_lock(mm, pmd, address, &ptl);
+	if (unlikely(!(pte_val(*pte) & _PAGE_PRESENT) || pte_user(*pte))) {
+		pte_unmap_unlock(pte, ptl);
+		return 0;
+	}
+
+	if (unlikely((error_code & PF_WRITE) && !pte_write(*pte))) {
+		/* write attempt to a protected page in user mode */
+		pte_unmap_unlock(pte, ptl);
+		return 0;
+	}
+
+#ifdef CONFIG_SMP
+	if (likely(address > get_limit(regs->cs) && cpumask_test_cpu(smp_processor_id(), &mm->context.cpu_user_cs_mask)))
+#else
+	if (likely(address > get_limit(regs->cs)))
+#endif
+	{
+		set_pte(pte, pte_mkread(*pte));
+		__flush_tlb_one(address);
+		pte_unmap_unlock(pte, ptl);
+		up_read(&mm->mmap_sem);
+		return 1;
+	}
+
+	pte_mask = _PAGE_ACCESSED | _PAGE_USER | ((error_code & PF_WRITE) << (_PAGE_BIT_DIRTY-1));
+
+	/*
+	 * PaX: fill DTLB with user rights and retry
+	 */
+	__asm__ __volatile__ (
+		"orb %2,(%1)\n"
+#if defined(CONFIG_M586) || defined(CONFIG_M586TSC)
+/*
+ * PaX: let this uncommented 'invlpg' remind us on the behaviour of Intel's
+ * (and AMD's) TLBs. namely, they do not cache PTEs that would raise *any*
+ * page fault when examined during a TLB load attempt. this is true not only
+ * for PTEs holding a non-present entry but also present entries that will
+ * raise a page fault (such as those set up by PaX, or the copy-on-write
+ * mechanism). in effect it means that we do *not* need to flush the TLBs
+ * for our target pages since their PTEs are simply not in the TLBs at all.
+
+ * the best thing in omitting it is that we gain around 15-20% speed in the
+ * fast path of the page fault handler and can get rid of tracing since we
+ * can no longer flush unintended entries.
+ */
+		"invlpg (%0)\n"
+#endif
+		__copyuser_seg"testb $0,(%0)\n"
+		"xorb %3,(%1)\n"
+		:
+		: "r" (address), "r" (pte), "q" (pte_mask), "i" (_PAGE_USER)
+		: "memory", "cc");
+	pte_unmap_unlock(pte, ptl);
+	up_read(&mm->mmap_sem);
+	return 1;
+}
+#endif
+
 /*
  * Handle a spurious fault caused by a stale TLB entry.
  *
@@ -968,6 +1154,9 @@ int show_unhandled_signals = 1;
 static inline int
 access_error(unsigned long error_code, struct vm_area_struct *vma)
 {
+	if ((__supported_pte_mask & _PAGE_NX) && (error_code & PF_INSTR) && !(vma->vm_flags & VM_EXEC))
+		return 1;
+
 	if (error_code & PF_WRITE) {
 		/* write, present and write, not present: */
 		if (unlikely(!(vma->vm_flags & VM_WRITE)))
@@ -1001,19 +1190,33 @@ do_page_fault(struct pt_regs *regs, unsi
 {
 	struct vm_area_struct *vma;
 	struct task_struct *tsk;
-	unsigned long address;
 	struct mm_struct *mm;
 	int fault;
 	int write = error_code & PF_WRITE;
 	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE |
 					(write ? FAULT_FLAG_WRITE : 0);
 
+	/* Get the faulting address: */
+	unsigned long address = read_cr2();
+
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+	if (!user_mode(regs) && address < 2 * pax_user_shadow_base) {
+		if (!search_exception_tables(regs->ip)) {
+			bad_area_nosemaphore(regs, error_code, address);
+			return;
+		}
+		if (address < pax_user_shadow_base) {
+			printk(KERN_EMERG "PAX: please report this to pageexec@freemail.hu\n");
+			printk(KERN_EMERG "PAX: faulting IP: %pS\n", (void *)regs->ip);
+			show_trace_log_lvl(NULL, NULL, (void *)regs->sp, regs->bp, KERN_ERR);
+		} else
+			address -= pax_user_shadow_base;
+	}
+#endif
+
 	tsk = current;
 	mm = tsk->mm;
 
-	/* Get the faulting address: */
-	address = read_cr2();
-
 	/*
 	 * Detect and handle instructions that would cause a page fault for
 	 * both a tracked kernel page and a userspace page.
@@ -1073,7 +1276,7 @@ do_page_fault(struct pt_regs *regs, unsi
 	 * User-mode registers count as a user access even for any
 	 * potential system fault or CPU buglet:
 	 */
-	if (user_mode_vm(regs)) {
+	if (user_mode(regs)) {
 		local_irq_enable();
 		error_code |= PF_USER;
 	} else {
@@ -1128,6 +1331,11 @@ retry:
 		might_sleep();
 	}
 
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_PAGEEXEC)
+	if (pax_handle_pageexec_fault(regs, mm, address, error_code))
+		return;
+#endif
+
 	vma = find_vma(mm, address);
 	if (unlikely(!vma)) {
 		bad_area(regs, error_code, address);
@@ -1139,18 +1347,24 @@ retry:
 		bad_area(regs, error_code, address);
 		return;
 	}
-	if (error_code & PF_USER) {
-		/*
-		 * Accessing the stack below %sp is always a bug.
-		 * The large cushion allows instructions like enter
-		 * and pusha to work. ("enter $65535, $31" pushes
-		 * 32 pointers and then decrements %sp by 65535.)
-		 */
-		if (unlikely(address + 65536 + 32 * sizeof(unsigned long) < regs->sp)) {
-			bad_area(regs, error_code, address);
-			return;
-		}
+	/*
+	 * Accessing the stack below %sp is always a bug.
+	 * The large cushion allows instructions like enter
+	 * and pusha to work. ("enter $65535, $31" pushes
+	 * 32 pointers and then decrements %sp by 65535.)
+	 */
+	if (unlikely(address + 65536 + 32 * sizeof(unsigned long) < task_pt_regs(tsk)->sp)) {
+		bad_area(regs, error_code, address);
+		return;
 	}
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (unlikely((mm->pax_flags & MF_PAX_SEGMEXEC) && vma->vm_end - SEGMEXEC_TASK_SIZE - 1 < address - SEGMEXEC_TASK_SIZE - 1)) {
+		bad_area(regs, error_code, address);
+		return;
+	}
+#endif
+
 	if (unlikely(expand_stack(vma, address))) {
 		bad_area(regs, error_code, address);
 		return;
@@ -1205,3 +1419,292 @@ good_area:
 
 	up_read(&mm->mmap_sem);
 }
+
+#if defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC)
+static bool pax_is_fetch_fault(struct pt_regs *regs, unsigned long error_code, unsigned long address)
+{
+	struct mm_struct *mm = current->mm;
+	unsigned long ip = regs->ip;
+
+	if (v8086_mode(regs))
+		ip = ((regs->cs & 0xffff) << 4) + (ip & 0xffff);
+
+#ifdef CONFIG_PAX_PAGEEXEC
+	if (mm->pax_flags & MF_PAX_PAGEEXEC) {
+		if ((__supported_pte_mask & _PAGE_NX) && (error_code & PF_INSTR))
+			return true;
+		if (!(error_code & (PF_PROT | PF_WRITE)) && ip == address)
+			return true;
+		return false;
+	}
+#endif
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (mm->pax_flags & MF_PAX_SEGMEXEC) {
+		if (!(error_code & (PF_PROT | PF_WRITE)) && (ip + SEGMEXEC_TASK_SIZE == address))
+			return true;
+		return false;
+	}
+#endif
+
+	return false;
+}
+#endif
+
+#ifdef CONFIG_PAX_EMUTRAMP
+static int pax_handle_fetch_fault_32(struct pt_regs *regs)
+{
+	int err;
+
+	do { /* PaX: libffi trampoline emulation */
+		unsigned char mov, jmp;
+		unsigned int addr1, addr2;
+
+#ifdef CONFIG_X86_64
+		if ((regs->ip + 9) >> 32)
+			break;
+#endif
+
+		err = get_user(mov, (unsigned char __user *)regs->ip);
+		err |= get_user(addr1, (unsigned int __user *)(regs->ip + 1));
+		err |= get_user(jmp, (unsigned char __user *)(regs->ip + 5));
+		err |= get_user(addr2, (unsigned int __user *)(regs->ip + 6));
+
+		if (err)
+			break;
+
+		if (mov == 0xB8 && jmp == 0xE9) {
+			regs->ax = addr1;
+			regs->ip = (unsigned int)(regs->ip + addr2 + 10);
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: gcc trampoline emulation #1 */
+		unsigned char mov1, mov2;
+		unsigned short jmp;
+		unsigned int addr1, addr2;
+
+#ifdef CONFIG_X86_64
+		if ((regs->ip + 11) >> 32)
+			break;
+#endif
+
+		err = get_user(mov1, (unsigned char __user *)regs->ip);
+		err |= get_user(addr1, (unsigned int __user *)(regs->ip + 1));
+		err |= get_user(mov2, (unsigned char __user *)(regs->ip + 5));
+		err |= get_user(addr2, (unsigned int __user *)(regs->ip + 6));
+		err |= get_user(jmp, (unsigned short __user *)(regs->ip + 10));
+
+		if (err)
+			break;
+
+		if (mov1 == 0xB9 && mov2 == 0xB8 && jmp == 0xE0FF) {
+			regs->cx = addr1;
+			regs->ax = addr2;
+			regs->ip = addr2;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: gcc trampoline emulation #2 */
+		unsigned char mov, jmp;
+		unsigned int addr1, addr2;
+
+#ifdef CONFIG_X86_64
+		if ((regs->ip + 9) >> 32)
+			break;
+#endif
+
+		err = get_user(mov, (unsigned char __user *)regs->ip);
+		err |= get_user(addr1, (unsigned int __user *)(regs->ip + 1));
+		err |= get_user(jmp, (unsigned char __user *)(regs->ip + 5));
+		err |= get_user(addr2, (unsigned int __user *)(regs->ip + 6));
+
+		if (err)
+			break;
+
+		if (mov == 0xB9 && jmp == 0xE9) {
+			regs->cx = addr1;
+			regs->ip = (unsigned int)(regs->ip + addr2 + 10);
+			return 2;
+		}
+	} while (0);
+
+	return 1; /* PaX in action */
+}
+
+#ifdef CONFIG_X86_64
+static int pax_handle_fetch_fault_64(struct pt_regs *regs)
+{
+	int err;
+
+	do { /* PaX: libffi trampoline emulation */
+		unsigned short mov1, mov2, jmp1;
+		unsigned char stcclc, jmp2;
+		unsigned long addr1, addr2;
+
+		err = get_user(mov1, (unsigned short __user *)regs->ip);
+		err |= get_user(addr1, (unsigned long __user *)(regs->ip + 2));
+		err |= get_user(mov2, (unsigned short __user *)(regs->ip + 10));
+		err |= get_user(addr2, (unsigned long __user *)(regs->ip + 12));
+		err |= get_user(stcclc, (unsigned char __user *)(regs->ip + 20));
+		err |= get_user(jmp1, (unsigned short __user *)(regs->ip + 21));
+		err |= get_user(jmp2, (unsigned char __user *)(regs->ip + 23));
+
+		if (err)
+			break;
+
+		if (mov1 == 0xBB49 && mov2 == 0xBA49 && (stcclc == 0xF8 || stcclc == 0xF9) && jmp1 == 0xFF49 && jmp2 == 0xE3) {
+			regs->r11 = addr1;
+			regs->r10 = addr2;
+			if (stcclc == 0xF8)
+				regs->flags &= ~X86_EFLAGS_CF;
+			else
+				regs->flags |= X86_EFLAGS_CF;
+			regs->ip = addr1;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: gcc trampoline emulation #1 */
+		unsigned short mov1, mov2, jmp1;
+		unsigned char jmp2;
+		unsigned int addr1;
+		unsigned long addr2;
+
+		err = get_user(mov1, (unsigned short __user *)regs->ip);
+		err |= get_user(addr1, (unsigned int __user *)(regs->ip + 2));
+		err |= get_user(mov2, (unsigned short __user *)(regs->ip + 6));
+		err |= get_user(addr2, (unsigned long __user *)(regs->ip + 8));
+		err |= get_user(jmp1, (unsigned short __user *)(regs->ip + 16));
+		err |= get_user(jmp2, (unsigned char __user *)(regs->ip + 18));
+
+		if (err)
+			break;
+
+		if (mov1 == 0xBB41 && mov2 == 0xBA49 && jmp1 == 0xFF49 && jmp2 == 0xE3) {
+			regs->r11 = addr1;
+			regs->r10 = addr2;
+			regs->ip = addr1;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: gcc trampoline emulation #2 */
+		unsigned short mov1, mov2, jmp1;
+		unsigned char jmp2;
+		unsigned long addr1, addr2;
+
+		err = get_user(mov1, (unsigned short __user *)regs->ip);
+		err |= get_user(addr1, (unsigned long __user *)(regs->ip + 2));
+		err |= get_user(mov2, (unsigned short __user *)(regs->ip + 10));
+		err |= get_user(addr2, (unsigned long __user *)(regs->ip + 12));
+		err |= get_user(jmp1, (unsigned short __user *)(regs->ip + 20));
+		err |= get_user(jmp2, (unsigned char __user *)(regs->ip + 22));
+
+		if (err)
+			break;
+
+		if (mov1 == 0xBB49 && mov2 == 0xBA49 && jmp1 == 0xFF49 && jmp2 == 0xE3) {
+			regs->r11 = addr1;
+			regs->r10 = addr2;
+			regs->ip = addr1;
+			return 2;
+		}
+	} while (0);
+
+	return 1; /* PaX in action */
+}
+#endif
+
+/*
+ * PaX: decide what to do with offenders (regs->ip = fault address)
+ *
+ * returns 1 when task should be killed
+ *         2 when gcc trampoline was detected
+ */
+static int pax_handle_fetch_fault(struct pt_regs *regs)
+{
+	if (v8086_mode(regs))
+		return 1;
+
+	if (!(current->mm->pax_flags & MF_PAX_EMUTRAMP))
+		return 1;
+
+#ifdef CONFIG_X86_32
+	return pax_handle_fetch_fault_32(regs);
+#else
+	if (regs->cs == __USER32_CS || (regs->cs & SEGMENT_LDT))
+		return pax_handle_fetch_fault_32(regs);
+	else
+		return pax_handle_fetch_fault_64(regs);
+#endif
+}
+#endif
+
+#if defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC)
+void pax_report_insns(struct pt_regs *regs, void *pc, void *sp)
+{
+	long i;
+
+	printk(KERN_ERR "PAX: bytes at PC: ");
+	for (i = 0; i < 20; i++) {
+		unsigned char c;
+		if (get_user(c, (unsigned char __force_user *)pc+i))
+			printk(KERN_CONT "?? ");
+		else
+			printk(KERN_CONT "%02x ", c);
+	}
+	printk("\n");
+
+	printk(KERN_ERR "PAX: bytes at SP-%lu: ", (unsigned long)sizeof(long));
+	for (i = -1; i < 80 / (long)sizeof(long); i++) {
+		unsigned long c;
+		if (get_user(c, (unsigned long __force_user *)sp+i)) {
+#ifdef CONFIG_X86_32
+			printk(KERN_CONT "???????? ");
+#else
+			if ((regs->cs == __USER32_CS || (regs->cs & SEGMENT_LDT)))
+				printk(KERN_CONT "???????? ???????? ");
+			else
+				printk(KERN_CONT "???????????????? ");
+#endif
+		} else {
+#ifdef CONFIG_X86_64
+			if ((regs->cs == __USER32_CS || (regs->cs & SEGMENT_LDT))) {
+				printk(KERN_CONT "%08x ", (unsigned int)c);
+				printk(KERN_CONT "%08x ", (unsigned int)(c >> 32));
+			} else
+#endif
+				printk(KERN_CONT "%0*lx ", 2 * (int)sizeof(long), c);
+		}
+	}
+	printk("\n");
+}
+#endif
+
+/**
+ * probe_kernel_write(): safely attempt to write to a location
+ * @dst: address to write to
+ * @src: pointer to the data that shall be written
+ * @size: size of the data chunk
+ *
+ * Safely write to address @dst from the buffer at @src.  If a kernel fault
+ * happens, handle that and return -EFAULT.
+ */
+long notrace probe_kernel_write(void *dst, const void *src, size_t size)
+{
+	long ret;
+	mm_segment_t old_fs = get_fs();
+
+	set_fs(KERNEL_DS);
+	pagefault_disable();
+	pax_open_kernel();
+	ret = __copy_to_user_inatomic((void __force_user *)dst, src, size);
+	pax_close_kernel();
+	pagefault_enable();
+	set_fs(old_fs);
+
+	return ret ? -EFAULT : 0;
+}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/gup.c linux-3.2.71-pax/arch/x86/mm/gup.c
--- linux-3.2.71/arch/x86/mm/gup.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/gup.c	2014-03-23 21:07:50.740059889 +0100
@@ -255,7 +255,7 @@ int __get_user_pages_fast(unsigned long
 	addr = start;
 	len = (unsigned long) nr_pages << PAGE_SHIFT;
 	end = start + len;
-	if (unlikely(!access_ok(write ? VERIFY_WRITE : VERIFY_READ,
+	if (unlikely(!access_ok_noprefault(write ? VERIFY_WRITE : VERIFY_READ,
 					(void __user *)start, len)))
 		return 0;
 
@@ -331,6 +331,10 @@ int get_user_pages_fast(unsigned long st
 		goto slow_irqon;
 #endif
 
+	if (unlikely(!access_ok_noprefault(write ? VERIFY_WRITE : VERIFY_READ,
+					(void __user *)start, len)))
+		return 0;
+
 	/*
 	 * XXX: batch / limit 'nr', to avoid large irq off latency
 	 * needs some instrumenting to determine the common sizes used by
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/highmem_32.c linux-3.2.71-pax/arch/x86/mm/highmem_32.c
--- linux-3.2.71/arch/x86/mm/highmem_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/highmem_32.c	2012-07-04 19:24:47.636063004 +0200
@@ -44,7 +44,11 @@ void *kmap_atomic_prot(struct page *page
 	idx = type + KM_TYPE_NR*smp_processor_id();
 	vaddr = __fix_to_virt(FIX_KMAP_BEGIN + idx);
 	BUG_ON(!pte_none(*(kmap_pte-idx)));
+
+	pax_open_kernel();
 	set_pte(kmap_pte-idx, mk_pte(page, prot));
+	pax_close_kernel();
+
 	arch_flush_lazy_mmu_mode();
 
 	return (void *)vaddr;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/hugetlbpage.c linux-3.2.71-pax/arch/x86/mm/hugetlbpage.c
--- linux-3.2.71/arch/x86/mm/hugetlbpage.c	2012-09-12 12:17:18.739311267 +0200
+++ linux-3.2.71-pax/arch/x86/mm/hugetlbpage.c	2013-07-05 02:09:08.825213521 +0200
@@ -277,13 +277,20 @@ static unsigned long hugetlb_get_unmappe
 	struct hstate *h = hstate_file(file);
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct *vma;
-	unsigned long start_addr;
+	unsigned long start_addr, pax_task_size = TASK_SIZE;
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (mm->pax_flags & MF_PAX_SEGMEXEC)
+		pax_task_size = SEGMEXEC_TASK_SIZE;
+#endif
+
+	pax_task_size -= PAGE_SIZE;
 
 	if (len > mm->cached_hole_size) {
-	        start_addr = mm->free_area_cache;
+		start_addr = mm->free_area_cache;
 	} else {
-	        start_addr = TASK_UNMAPPED_BASE;
-	        mm->cached_hole_size = 0;
+		start_addr = mm->mmap_base;
+		mm->cached_hole_size = 0;
 	}
 
 full_search:
@@ -291,26 +298,27 @@ full_search:
 
 	for (vma = find_vma(mm, addr); ; vma = vma->vm_next) {
 		/* At this point:  (!vma || addr < vma->vm_end). */
-		if (TASK_SIZE - len < addr) {
+		if (pax_task_size - len < addr) {
 			/*
 			 * Start a new search - just in case we missed
 			 * some holes.
 			 */
-			if (start_addr != TASK_UNMAPPED_BASE) {
-				start_addr = TASK_UNMAPPED_BASE;
+			if (start_addr != mm->mmap_base) {
+				start_addr = mm->mmap_base;
 				mm->cached_hole_size = 0;
 				goto full_search;
 			}
 			return -ENOMEM;
 		}
-		if (!vma || addr + len <= vma->vm_start) {
-			mm->free_area_cache = addr + len;
-			return addr;
-		}
+		if (check_heap_stack_gap(vma, &addr, len))
+			break;
 		if (addr + mm->cached_hole_size < vma->vm_start)
 		        mm->cached_hole_size = vma->vm_start - addr;
 		addr = ALIGN(vma->vm_end, huge_page_size(h));
 	}
+
+	mm->free_area_cache = addr + len;
+	return addr;
 }
 
 static unsigned long hugetlb_get_unmapped_area_topdown(struct file *file,
@@ -319,10 +327,9 @@ static unsigned long hugetlb_get_unmappe
 {
 	struct hstate *h = hstate_file(file);
 	struct mm_struct *mm = current->mm;
-	struct vm_area_struct *vma, *prev_vma;
-	unsigned long base = mm->mmap_base, addr = addr0;
+	struct vm_area_struct *vma;
+	unsigned long base = mm->mmap_base, addr;
 	unsigned long largest_hole = mm->cached_hole_size;
-	int first_time = 1;
 
 	/* don't allow allocations above current base */
 	if (mm->free_area_cache > base)
@@ -332,64 +339,68 @@ static unsigned long hugetlb_get_unmappe
 	        largest_hole = 0;
 		mm->free_area_cache  = base;
 	}
-try_again:
+
 	/* make sure it can fit in the remaining address space */
 	if (mm->free_area_cache < len)
 		goto fail;
 
 	/* either no address requested or can't fit in requested address hole */
-	addr = (mm->free_area_cache - len) & huge_page_mask(h);
+	addr = (mm->free_area_cache - len);
 	do {
+		addr &= huge_page_mask(h);
 		/*
 		 * Lookup failure means no vma is above this address,
 		 * i.e. return with success:
 		 */
-		if (!(vma = find_vma_prev(mm, addr, &prev_vma)))
+		vma = find_vma(mm, addr);
+		if (!vma)
 			return addr;
 
 		/*
 		 * new region fits between prev_vma->vm_end and
 		 * vma->vm_start, use it:
 		 */
-		if (addr + len <= vma->vm_start &&
-		            (!prev_vma || (addr >= prev_vma->vm_end))) {
+		if (check_heap_stack_gap(vma, &addr, len)) {
 			/* remember the address as a hint for next time */
-		        mm->cached_hole_size = largest_hole;
-		        return (mm->free_area_cache = addr);
-		} else {
-			/* pull free_area_cache down to the first hole */
-		        if (mm->free_area_cache == vma->vm_end) {
-				mm->free_area_cache = vma->vm_start;
-				mm->cached_hole_size = largest_hole;
-			}
+			mm->cached_hole_size = largest_hole;
+			return (mm->free_area_cache = addr);
+		}
+		/* pull free_area_cache down to the first hole */
+		if (mm->free_area_cache == vma->vm_end) {
+			mm->free_area_cache = vma->vm_start;
+			mm->cached_hole_size = largest_hole;
 		}
 
 		/* remember the largest hole we saw so far */
 		if (addr + largest_hole < vma->vm_start)
-		        largest_hole = vma->vm_start - addr;
+			largest_hole = vma->vm_start - addr;
 
 		/* try just below the current vma->vm_start */
-		addr = (vma->vm_start - len) & huge_page_mask(h);
-	} while (len <= vma->vm_start);
+		addr = skip_heap_stack_gap(vma, len);
+	} while (!IS_ERR_VALUE(addr));
 
 fail:
 	/*
-	 * if hint left us with no space for the requested
-	 * mapping then try again:
-	 */
-	if (first_time) {
-		mm->free_area_cache = base;
-		largest_hole = 0;
-		first_time = 0;
-		goto try_again;
-	}
-	/*
 	 * A failed mmap() very likely causes application failure,
 	 * so fall back to the bottom-up function here. This scenario
 	 * can happen with large stack limits and large mmap()
 	 * allocations.
 	 */
-	mm->free_area_cache = TASK_UNMAPPED_BASE;
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (mm->pax_flags & MF_PAX_SEGMEXEC)
+		mm->mmap_base = SEGMEXEC_TASK_UNMAPPED_BASE;
+	else
+#endif
+
+	mm->mmap_base = TASK_UNMAPPED_BASE;
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (mm->pax_flags & MF_PAX_RANDMMAP)
+		mm->mmap_base += mm->delta_mmap;
+#endif
+
+	mm->free_area_cache = mm->mmap_base;
 	mm->cached_hole_size = ~0UL;
 	addr = hugetlb_get_unmapped_area_bottomup(file, addr0,
 			len, pgoff, flags);
@@ -397,6 +408,7 @@ fail:
 	/*
 	 * Restore the topdown base:
 	 */
+	mm->mmap_base = base;
 	mm->free_area_cache = base;
 	mm->cached_hole_size = ~0UL;
 
@@ -410,10 +422,19 @@ hugetlb_get_unmapped_area(struct file *f
 	struct hstate *h = hstate_file(file);
 	struct mm_struct *mm = current->mm;
 	struct vm_area_struct *vma;
+	unsigned long pax_task_size = TASK_SIZE;
 
 	if (len & ~huge_page_mask(h))
 		return -EINVAL;
-	if (len > TASK_SIZE)
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (mm->pax_flags & MF_PAX_SEGMEXEC)
+		pax_task_size = SEGMEXEC_TASK_SIZE;
+#endif
+
+	pax_task_size -= PAGE_SIZE;
+
+	if (len > pax_task_size)
 		return -ENOMEM;
 
 	if (flags & MAP_FIXED) {
@@ -422,11 +443,14 @@ hugetlb_get_unmapped_area(struct file *f
 		return addr;
 	}
 
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	if (addr) {
 		addr = ALIGN(addr, huge_page_size(h));
 		vma = find_vma(mm, addr);
-		if (TASK_SIZE - len >= addr &&
-		    (!vma || addr + len <= vma->vm_start))
+		if (pax_task_size - len >= addr && check_heap_stack_gap(vma, &addr, len))
 			return addr;
 	}
 	if (mm->get_unmapped_area == arch_get_unmapped_area)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/init_32.c linux-3.2.71-pax/arch/x86/mm/init_32.c
--- linux-3.2.71/arch/x86/mm/init_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/init_32.c	2013-07-04 21:46:56.774053490 +0200
@@ -74,36 +74,6 @@ static __init void *alloc_low_page(void)
 }
 
 /*
- * Creates a middle page table and puts a pointer to it in the
- * given global directory entry. This only returns the gd entry
- * in non-PAE compilation mode, since the middle layer is folded.
- */
-static pmd_t * __init one_md_table_init(pgd_t *pgd)
-{
-	pud_t *pud;
-	pmd_t *pmd_table;
-
-#ifdef CONFIG_X86_PAE
-	if (!(pgd_val(*pgd) & _PAGE_PRESENT)) {
-		if (after_bootmem)
-			pmd_table = (pmd_t *)alloc_bootmem_pages(PAGE_SIZE);
-		else
-			pmd_table = (pmd_t *)alloc_low_page();
-		paravirt_alloc_pmd(&init_mm, __pa(pmd_table) >> PAGE_SHIFT);
-		set_pgd(pgd, __pgd(__pa(pmd_table) | _PAGE_PRESENT));
-		pud = pud_offset(pgd, 0);
-		BUG_ON(pmd_table != pmd_offset(pud, 0));
-
-		return pmd_table;
-	}
-#endif
-	pud = pud_offset(pgd, 0);
-	pmd_table = pmd_offset(pud, 0);
-
-	return pmd_table;
-}
-
-/*
  * Create a page table and place a pointer to it in a middle page
  * directory entry:
  */
@@ -123,13 +93,28 @@ static pte_t * __init one_page_table_ini
 			page_table = (pte_t *)alloc_low_page();
 
 		paravirt_alloc_pte(&init_mm, __pa(page_table) >> PAGE_SHIFT);
+#if defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC)
+		set_pmd(pmd, __pmd(__pa(page_table) | _KERNPG_TABLE));
+#else
 		set_pmd(pmd, __pmd(__pa(page_table) | _PAGE_TABLE));
+#endif
 		BUG_ON(page_table != pte_offset_kernel(pmd, 0));
 	}
 
 	return pte_offset_kernel(pmd, 0);
 }
 
+static pmd_t * __init one_md_table_init(pgd_t *pgd)
+{
+	pud_t *pud;
+	pmd_t *pmd_table;
+
+	pud = pud_offset(pgd, 0);
+	pmd_table = pmd_offset(pud, 0);
+
+	return pmd_table;
+}
+
 pmd_t * __init populate_extra_pmd(unsigned long vaddr)
 {
 	int pgd_idx = pgd_index(vaddr);
@@ -203,6 +188,7 @@ page_table_range_init(unsigned long star
 	int pgd_idx, pmd_idx;
 	unsigned long vaddr;
 	pgd_t *pgd;
+	pud_t *pud;
 	pmd_t *pmd;
 	pte_t *pte = NULL;
 
@@ -212,8 +198,13 @@ page_table_range_init(unsigned long star
 	pgd = pgd_base + pgd_idx;
 
 	for ( ; (pgd_idx < PTRS_PER_PGD) && (vaddr != end); pgd++, pgd_idx++) {
-		pmd = one_md_table_init(pgd);
-		pmd = pmd + pmd_index(vaddr);
+		pud = pud_offset(pgd, vaddr);
+		pmd = pmd_offset(pud, vaddr);
+
+#ifdef CONFIG_X86_PAE
+		paravirt_alloc_pmd(&init_mm, __pa(pmd) >> PAGE_SHIFT);
+#endif
+
 		for (; (pmd_idx < PTRS_PER_PMD) && (vaddr != end);
 							pmd++, pmd_idx++) {
 			pte = page_table_kmap_check(one_page_table_init(pmd),
@@ -225,11 +216,20 @@ page_table_range_init(unsigned long star
 	}
 }
 
-static inline int is_kernel_text(unsigned long addr)
+static inline int is_kernel_text(unsigned long start, unsigned long end)
 {
-	if (addr >= (unsigned long)_text && addr <= (unsigned long)__init_end)
-		return 1;
-	return 0;
+	if ((start > ktla_ktva((unsigned long)_etext) ||
+	     end <= ktla_ktva((unsigned long)_stext)) &&
+	    (start > ktla_ktva((unsigned long)_einittext) ||
+	     end <= ktla_ktva((unsigned long)_sinittext)) &&
+
+#ifdef CONFIG_ACPI_SLEEP
+	    (start > (unsigned long)__va(acpi_wakeup_address) + 0x4000 || end <= (unsigned long)__va(acpi_wakeup_address)) &&
+#endif
+
+	    (start > (unsigned long)__va(0xfffff) || end <= (unsigned long)__va(0xc0000)))
+		return 0;
+	return 1;
 }
 
 /*
@@ -246,9 +246,10 @@ kernel_physical_mapping_init(unsigned lo
 	unsigned long last_map_addr = end;
 	unsigned long start_pfn, end_pfn;
 	pgd_t *pgd_base = swapper_pg_dir;
-	int pgd_idx, pmd_idx, pte_ofs;
+	unsigned int pgd_idx, pmd_idx, pte_ofs;
 	unsigned long pfn;
 	pgd_t *pgd;
+	pud_t *pud;
 	pmd_t *pmd;
 	pte_t *pte;
 	unsigned pages_2m, pages_4k;
@@ -281,8 +282,13 @@ repeat:
 	pfn = start_pfn;
 	pgd_idx = pgd_index((pfn<<PAGE_SHIFT) + PAGE_OFFSET);
 	pgd = pgd_base + pgd_idx;
-	for (; pgd_idx < PTRS_PER_PGD; pgd++, pgd_idx++) {
-		pmd = one_md_table_init(pgd);
+	for (; pgd_idx < PTRS_PER_PGD && pfn < max_low_pfn; pgd++, pgd_idx++) {
+		pud = pud_offset(pgd, 0);
+		pmd = pmd_offset(pud, 0);
+
+#ifdef CONFIG_X86_PAE
+		paravirt_alloc_pmd(&init_mm, __pa(pmd) >> PAGE_SHIFT);
+#endif
 
 		if (pfn >= end_pfn)
 			continue;
@@ -294,14 +300,13 @@ repeat:
 #endif
 		for (; pmd_idx < PTRS_PER_PMD && pfn < end_pfn;
 		     pmd++, pmd_idx++) {
-			unsigned int addr = pfn * PAGE_SIZE + PAGE_OFFSET;
+			unsigned long address = pfn * PAGE_SIZE + PAGE_OFFSET;
 
 			/*
 			 * Map with big pages if possible, otherwise
 			 * create normal page tables:
 			 */
 			if (use_pse) {
-				unsigned int addr2;
 				pgprot_t prot = PAGE_KERNEL_LARGE;
 				/*
 				 * first pass will use the same initial
@@ -311,11 +316,7 @@ repeat:
 					__pgprot(PTE_IDENT_ATTR |
 						 _PAGE_PSE);
 
-				addr2 = (pfn + PTRS_PER_PTE-1) * PAGE_SIZE +
-					PAGE_OFFSET + PAGE_SIZE-1;
-
-				if (is_kernel_text(addr) ||
-				    is_kernel_text(addr2))
+				if (is_kernel_text(address, address + PMD_SIZE))
 					prot = PAGE_KERNEL_LARGE_EXEC;
 
 				pages_2m++;
@@ -332,7 +333,7 @@ repeat:
 			pte_ofs = pte_index((pfn<<PAGE_SHIFT) + PAGE_OFFSET);
 			pte += pte_ofs;
 			for (; pte_ofs < PTRS_PER_PTE && pfn < end_pfn;
-			     pte++, pfn++, pte_ofs++, addr += PAGE_SIZE) {
+			     pte++, pfn++, pte_ofs++, address += PAGE_SIZE) {
 				pgprot_t prot = PAGE_KERNEL;
 				/*
 				 * first pass will use the same initial
@@ -340,7 +341,7 @@ repeat:
 				 */
 				pgprot_t init_prot = __pgprot(PTE_IDENT_ATTR);
 
-				if (is_kernel_text(addr))
+				if (is_kernel_text(address, address + PAGE_SIZE))
 					prot = PAGE_KERNEL_EXEC;
 
 				pages_4k++;
@@ -472,7 +473,7 @@ void __init native_pagetable_setup_start
 
 		pud = pud_offset(pgd, va);
 		pmd = pmd_offset(pud, va);
-		if (!pmd_present(*pmd))
+		if (!pmd_present(*pmd) || pmd_huge(*pmd))
 			break;
 
 		pte = pte_offset_kernel(pmd, va);
@@ -524,12 +525,10 @@ void __init early_ioremap_page_table_ran
 
 static void __init pagetable_init(void)
 {
-	pgd_t *pgd_base = swapper_pg_dir;
-
-	permanent_kmaps_init(pgd_base);
+	permanent_kmaps_init(swapper_pg_dir);
 }
 
-pteval_t __supported_pte_mask __read_mostly = ~(_PAGE_NX | _PAGE_GLOBAL | _PAGE_IOMAP);
+pteval_t __supported_pte_mask __read_only = ~(_PAGE_NX | _PAGE_GLOBAL | _PAGE_IOMAP);
 EXPORT_SYMBOL_GPL(__supported_pte_mask);
 
 /* user-defined highmem size */
@@ -774,7 +773,7 @@ void __init mem_init(void)
 	set_highmem_pages_init();
 
 	codesize =  (unsigned long) &_etext - (unsigned long) &_text;
-	datasize =  (unsigned long) &_edata - (unsigned long) &_etext;
+	datasize =  (unsigned long) &_edata - (unsigned long) &_sdata;
 	initsize =  (unsigned long) &__init_end - (unsigned long) &__init_begin;
 
 	printk(KERN_INFO "Memory: %luk/%luk available (%dk kernel code, "
@@ -815,10 +814,10 @@ void __init mem_init(void)
 		((unsigned long)&__init_end -
 		 (unsigned long)&__init_begin) >> 10,
 
-		(unsigned long)&_etext, (unsigned long)&_edata,
-		((unsigned long)&_edata - (unsigned long)&_etext) >> 10,
+		(unsigned long)&_sdata, (unsigned long)&_edata,
+		((unsigned long)&_edata - (unsigned long)&_sdata) >> 10,
 
-		(unsigned long)&_text, (unsigned long)&_etext,
+		ktla_ktva((unsigned long)&_text), ktla_ktva((unsigned long)&_etext),
 		((unsigned long)&_etext - (unsigned long)&_text) >> 10);
 
 	/*
@@ -896,6 +895,7 @@ void set_kernel_text_rw(void)
 	if (!kernel_set_to_readonly)
 		return;
 
+	start = ktla_ktva(start);
 	pr_debug("Set kernel text: %lx - %lx for read write\n",
 		 start, start+size);
 
@@ -910,6 +910,7 @@ void set_kernel_text_ro(void)
 	if (!kernel_set_to_readonly)
 		return;
 
+	start = ktla_ktva(start);
 	pr_debug("Set kernel text: %lx - %lx for read only\n",
 		 start, start+size);
 
@@ -938,6 +939,7 @@ void mark_rodata_ro(void)
 	unsigned long start = PFN_ALIGN(_text);
 	unsigned long size = PFN_ALIGN(_etext) - start;
 
+	start = ktla_ktva(start);
 	set_pages_ro(virt_to_page(start), size >> PAGE_SHIFT);
 	printk(KERN_INFO "Write protecting the kernel text: %luk\n",
 		size >> 10);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/init_64.c linux-3.2.71-pax/arch/x86/mm/init_64.c
--- linux-3.2.71/arch/x86/mm/init_64.c	2015-02-20 12:37:32.985178781 +0100
+++ linux-3.2.71-pax/arch/x86/mm/init_64.c	2015-06-29 17:35:55.334489262 +0200
@@ -75,7 +75,7 @@ early_param("gbpages", parse_direct_gbpa
  * around without checking the pgd every time.
  */
 
-pteval_t __supported_pte_mask __read_mostly = ~_PAGE_IOMAP;
+pteval_t __supported_pte_mask __read_only = ~(_PAGE_NX | _PAGE_IOMAP);
 EXPORT_SYMBOL_GPL(__supported_pte_mask);
 
 int force_personality32;
@@ -108,12 +108,22 @@ void sync_global_pgds(unsigned long star
 
 	for (address = start; address <= end; address += PGDIR_SIZE) {
 		const pgd_t *pgd_ref = pgd_offset_k(address);
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+		unsigned long cpu;
+#else
 		struct page *page;
+#endif
 
 		if (pgd_none(*pgd_ref))
 			continue;
 
 		spin_lock(&pgd_lock);
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+		for (cpu = 0; cpu < nr_cpu_ids; ++cpu) {
+			pgd_t *pgd = pgd_offset_cpu(cpu, address);
+#else
 		list_for_each_entry(page, &pgd_list, lru) {
 			pgd_t *pgd;
 			spinlock_t *pgt_lock;
@@ -122,6 +132,7 @@ void sync_global_pgds(unsigned long star
 			/* the pgt_lock only for Xen */
 			pgt_lock = &pgd_page_get_mm(page)->page_table_lock;
 			spin_lock(pgt_lock);
+#endif
 
 			if (pgd_none(*pgd))
 				set_pgd(pgd, *pgd_ref);
@@ -129,7 +140,10 @@ void sync_global_pgds(unsigned long star
 				BUG_ON(pgd_page_vaddr(*pgd)
 				       != pgd_page_vaddr(*pgd_ref));
 
+#ifndef CONFIG_PAX_PER_CPU_PGD
 			spin_unlock(pgt_lock);
+#endif
+
 		}
 		spin_unlock(&pgd_lock);
 	}
@@ -162,7 +176,7 @@ static pud_t *fill_pud(pgd_t *pgd, unsig
 {
 	if (pgd_none(*pgd)) {
 		pud_t *pud = (pud_t *)spp_getpage();
-		pgd_populate(&init_mm, pgd, pud);
+		pgd_populate_kernel(&init_mm, pgd, pud);
 		if (pud != pud_offset(pgd, 0))
 			printk(KERN_ERR "PAGETABLE BUG #00! %p <-> %p\n",
 			       pud, pud_offset(pgd, 0));
@@ -174,7 +188,7 @@ static pmd_t *fill_pmd(pud_t *pud, unsig
 {
 	if (pud_none(*pud)) {
 		pmd_t *pmd = (pmd_t *) spp_getpage();
-		pud_populate(&init_mm, pud, pmd);
+		pud_populate_kernel(&init_mm, pud, pmd);
 		if (pmd != pmd_offset(pud, 0))
 			printk(KERN_ERR "PAGETABLE BUG #01! %p <-> %p\n",
 			       pmd, pmd_offset(pud, 0));
@@ -203,7 +217,9 @@ void set_pte_vaddr_pud(pud_t *pud_page,
 	pmd = fill_pmd(pud, vaddr);
 	pte = fill_pte(pmd, vaddr);
 
+	pax_open_kernel();
 	set_pte(pte, new_pte);
+	pax_close_kernel();
 
 	/*
 	 * It's enough to flush this one mapping.
@@ -262,14 +278,12 @@ static void __init __init_extra_mapping(
 		pgd = pgd_offset_k((unsigned long)__va(phys));
 		if (pgd_none(*pgd)) {
 			pud = (pud_t *) spp_getpage();
-			set_pgd(pgd, __pgd(__pa(pud) | _KERNPG_TABLE |
-						_PAGE_USER));
+			set_pgd(pgd, __pgd(__pa(pud) | _PAGE_TABLE));
 		}
 		pud = pud_offset(pgd, (unsigned long)__va(phys));
 		if (pud_none(*pud)) {
 			pmd = (pmd_t *) spp_getpage();
-			set_pud(pud, __pud(__pa(pmd) | _KERNPG_TABLE |
-						_PAGE_USER));
+			set_pud(pud, __pud(__pa(pmd) | _PAGE_TABLE));
 		}
 		pmd = pmd_offset(pud, phys);
 		BUG_ON(!pmd_none(*pmd));
@@ -330,7 +344,7 @@ static __ref void *alloc_low_page(unsign
 	if (pfn >= pgt_buf_top)
 		panic("alloc_low_page: ran out of memory");
 
-	adr = early_memremap(pfn * PAGE_SIZE, PAGE_SIZE);
+	adr = (void __force_kernel *)early_memremap(pfn * PAGE_SIZE, PAGE_SIZE);
 	clear_page(adr);
 	*phys  = pfn * PAGE_SIZE;
 	return adr;
@@ -346,7 +360,7 @@ static __ref void *map_low_page(void *vi
 
 	phys = __pa(virt);
 	left = phys & (PAGE_SIZE - 1);
-	adr = early_memremap(phys & PAGE_MASK, PAGE_SIZE);
+	adr = (void __force_kernel *)early_memremap(phys & PAGE_MASK, PAGE_SIZE);
 	adr = (void *)(((unsigned long)adr) | left);
 
 	return adr;
@@ -413,7 +427,7 @@ phys_pmd_init(pmd_t *pmd_page, unsigned
 
 	int i = pmd_index(address);
 
-	for (; i < PTRS_PER_PMD; i++, address += PMD_SIZE) {
+	for (; i < PTRS_PER_PMD; i++, address = (address & PMD_MASK) + PMD_SIZE) {
 		unsigned long pte_phys;
 		pmd_t *pmd = pmd_page + pmd_index(address);
 		pte_t *pte;
@@ -546,7 +560,7 @@ phys_pud_init(pud_t *pud_page, unsigned
 		unmap_low_page(pmd);
 
 		spin_lock(&init_mm.page_table_lock);
-		pud_populate(&init_mm, pud, __va(pmd_phys));
+		pud_populate_kernel(&init_mm, pud, __va(pmd_phys));
 		spin_unlock(&init_mm.page_table_lock);
 	}
 	__flush_tlb_all();
@@ -592,7 +606,7 @@ kernel_physical_mapping_init(unsigned lo
 		unmap_low_page(pud);
 
 		spin_lock(&init_mm.page_table_lock);
-		pgd_populate(&init_mm, pgd, __va(pud_phys));
+		pgd_populate_kernel(&init_mm, pgd, __va(pud_phys));
 		spin_unlock(&init_mm.page_table_lock);
 		pgd_changed = true;
 	}
@@ -856,8 +870,8 @@ int kern_addr_valid(unsigned long addr)
 static struct vm_area_struct gate_vma = {
 	.vm_start	= VSYSCALL_START,
 	.vm_end		= VSYSCALL_START + (VSYSCALL_MAPPED_PAGES * PAGE_SIZE),
-	.vm_page_prot	= PAGE_READONLY_EXEC,
-	.vm_flags	= VM_READ | VM_EXEC
+	.vm_page_prot	= PAGE_READONLY,
+	.vm_flags	= VM_READ
 };
 
 struct vm_area_struct *get_gate_vma(struct mm_struct *mm)
@@ -891,7 +905,7 @@ int in_gate_area_no_mm(unsigned long add
 
 const char *arch_vma_name(struct vm_area_struct *vma)
 {
-	if (vma->vm_mm && vma->vm_start == (long)vma->vm_mm->context.vdso)
+	if (vma->vm_mm && vma->vm_start == vma->vm_mm->context.vdso)
 		return "[vdso]";
 	if (vma == &gate_vma)
 		return "[vsyscall]";
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/init.c linux-3.2.71-pax/arch/x86/mm/init.c
--- linux-3.2.71/arch/x86/mm/init.c	2013-05-14 13:33:40.524285678 +0200
+++ linux-3.2.71-pax/arch/x86/mm/init.c	2015-06-29 17:54:05.094486834 +0200
@@ -15,6 +15,7 @@
 #include <asm/tlbflush.h>
 #include <asm/tlb.h>
 #include <asm/proto.h>
+#include <asm/desc.h>
 
 unsigned long __initdata pgt_buf_start;
 unsigned long __meminitdata pgt_buf_end;
@@ -43,7 +44,7 @@ static void __init find_early_table_spac
 {
 	int i;
 	unsigned long puds = 0, pmds = 0, ptes = 0, tables;
-	unsigned long start = 0, good_end;
+	unsigned long start = 0x100000, good_end;
 	unsigned long pgd_extra = 0;
 	phys_addr_t base;
 
@@ -282,7 +283,14 @@ unsigned long __init_refok init_memory_m
 
 #ifdef CONFIG_X86_32
 	early_ioremap_page_table_range_init();
+#endif
 
+#ifdef CONFIG_PAX_PER_CPU_PGD
+	clone_pgd_range(get_cpu_pgd(0) + KERNEL_PGD_BOUNDARY,
+			swapper_pg_dir + KERNEL_PGD_BOUNDARY,
+			KERNEL_PGD_PTRS);
+	load_cr3(get_cpu_pgd(0));
+#elif defined(CONFIG_X86_32)
 	load_cr3(swapper_pg_dir);
 #endif
 
@@ -326,7 +334,13 @@ unsigned long __init_refok init_memory_m
  */
 int devmem_is_allowed(unsigned long pagenr)
 {
-	if (pagenr <= 256)
+	if (!pagenr)
+		return 1;
+#ifdef CONFIG_VM86
+	if (pagenr < (ISA_START_ADDRESS >> PAGE_SHIFT))
+		return 1;
+#endif
+	if ((ISA_START_ADDRESS >> PAGE_SHIFT) <= pagenr && pagenr < (ISA_END_ADDRESS >> PAGE_SHIFT))
 		return 1;
 	if (iomem_is_exclusive(pagenr << PAGE_SHIFT))
 		return 0;
@@ -386,6 +400,87 @@ void free_init_pages(char *what, unsigne
 
 void free_initmem(void)
 {
+
+#ifdef CONFIG_PAX_KERNEXEC
+#ifdef CONFIG_X86_32
+	/* PaX: limit KERNEL_CS to actual size */
+	unsigned long addr, limit;
+	struct desc_struct d;
+	int cpu;
+
+	limit = paravirt_enabled() ? ktva_ktla(0xffffffff) : (unsigned long)&_etext;
+	limit = (limit - 1UL) >> PAGE_SHIFT;
+
+	memset(__LOAD_PHYSICAL_ADDR + PAGE_OFFSET, POISON_FREE_INITMEM, PAGE_SIZE);
+	for (cpu = 0; cpu < nr_cpu_ids; cpu++) {
+		pack_descriptor(&d, get_desc_base(&get_cpu_gdt_table(cpu)[GDT_ENTRY_KERNEL_CS]), limit, 0x9B, 0xC);
+		write_gdt_entry(get_cpu_gdt_table(cpu), GDT_ENTRY_KERNEL_CS, &d, DESCTYPE_S);
+		write_gdt_entry(get_cpu_gdt_table(cpu), GDT_ENTRY_KERNEXEC_KERNEL_CS, &d, DESCTYPE_S);
+	}
+
+	/* PaX: make KERNEL_CS read-only */
+	addr = PFN_ALIGN(ktla_ktva((unsigned long)&_text));
+	if (!paravirt_enabled())
+		set_memory_ro(addr, (PFN_ALIGN(_sdata) - addr) >> PAGE_SHIFT);
+/*
+		for (addr = ktla_ktva((unsigned long)&_text); addr < (unsigned long)&_sdata; addr += PMD_SIZE) {
+			pgd = pgd_offset_k(addr);
+			pud = pud_offset(pgd, addr);
+			pmd = pmd_offset(pud, addr);
+			set_pmd(pmd, __pmd(pmd_val(*pmd) & ~_PAGE_RW));
+		}
+*/
+#ifdef CONFIG_X86_PAE
+	set_memory_nx(PFN_ALIGN(__init_begin), (PFN_ALIGN(__init_end) - PFN_ALIGN(__init_begin)) >> PAGE_SHIFT);
+/*
+	for (addr = (unsigned long)&__init_begin; addr < (unsigned long)&__init_end; addr += PMD_SIZE) {
+		pgd = pgd_offset_k(addr);
+		pud = pud_offset(pgd, addr);
+		pmd = pmd_offset(pud, addr);
+		set_pmd(pmd, __pmd(pmd_val(*pmd) | (_PAGE_NX & __supported_pte_mask)));
+	}
+*/
+#endif
+
+#ifdef CONFIG_MODULES
+	set_memory_4k((unsigned long)MODULES_EXEC_VADDR, (MODULES_EXEC_END - MODULES_EXEC_VADDR) >> PAGE_SHIFT);
+#endif
+
+#else
+	pgd_t *pgd;
+	pud_t *pud;
+	pmd_t *pmd;
+	unsigned long addr, end;
+
+	/* PaX: make kernel code/rodata read-only, rest non-executable */
+	for (addr = __START_KERNEL_map; addr < __START_KERNEL_map + KERNEL_IMAGE_SIZE; addr += PMD_SIZE) {
+		pgd = pgd_offset_k(addr);
+		pud = pud_offset(pgd, addr);
+		pmd = pmd_offset(pud, addr);
+		if (!pmd_present(*pmd))
+			continue;
+		if ((unsigned long)_text <= addr && addr < (unsigned long)_sdata)
+			set_pmd(pmd, __pmd(pmd_val(*pmd) & ~_PAGE_RW));
+		else
+			set_pmd(pmd, __pmd(pmd_val(*pmd) | (_PAGE_NX & __supported_pte_mask)));
+	}
+
+	addr = (unsigned long)__va(__pa(__START_KERNEL_map));
+	end = addr + KERNEL_IMAGE_SIZE;
+	for (; addr < end; addr += PMD_SIZE) {
+		pgd = pgd_offset_k(addr);
+		pud = pud_offset(pgd, addr);
+		pmd = pmd_offset(pud, addr);
+		if (!pmd_present(*pmd))
+			continue;
+		if ((unsigned long)__va(__pa(_text)) <= addr && addr < (unsigned long)__va(__pa(_sdata)))
+			set_pmd(pmd, __pmd(pmd_val(*pmd) & ~_PAGE_RW));
+	}
+#endif
+
+	flush_tlb_all();
+#endif
+
 	free_init_pages("unused kernel memory",
 			(unsigned long)(&__init_begin),
 			(unsigned long)(&__init_end));
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/iomap_32.c linux-3.2.71-pax/arch/x86/mm/iomap_32.c
--- linux-3.2.71/arch/x86/mm/iomap_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/iomap_32.c	2012-07-04 19:24:47.640063004 +0200
@@ -64,7 +64,11 @@ void *kmap_atomic_prot_pfn(unsigned long
 	type = kmap_atomic_idx_push();
 	idx = type + KM_TYPE_NR * smp_processor_id();
 	vaddr = __fix_to_virt(FIX_KMAP_BEGIN + idx);
+
+	pax_open_kernel();
 	set_pte(kmap_pte - idx, pfn_pte(pfn, prot));
+	pax_close_kernel();
+
 	arch_flush_lazy_mmu_mode();
 
 	return (void *)vaddr;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/ioremap.c linux-3.2.71-pax/arch/x86/mm/ioremap.c
--- linux-3.2.71/arch/x86/mm/ioremap.c	2014-08-06 23:17:20.693614204 +0200
+++ linux-3.2.71-pax/arch/x86/mm/ioremap.c	2015-02-20 12:14:03.521254035 +0100
@@ -56,8 +56,8 @@ static int __ioremap_check_ram(unsigned
 	unsigned long i;
 
 	for (i = 0; i < nr_pages; ++i)
-		if (pfn_valid(start_pfn + i) &&
-		    !PageReserved(pfn_to_page(start_pfn + i)))
+		if (pfn_valid(start_pfn + i) && (start_pfn + i >= 0x100 ||
+		    !PageReserved(pfn_to_page(start_pfn + i))))
 			return 1;
 
 	WARN_ONCE(1, "ioremap on RAM pfn 0x%lx\n", start_pfn);
@@ -268,7 +268,7 @@ EXPORT_SYMBOL(ioremap_prot);
  *
  * Caller must ensure there is only one unmapping for the same pointer.
  */
-void iounmap(volatile void __iomem *addr)
+void iounmap(const volatile void __iomem *addr)
 {
 	struct vm_struct *p, *o;
 
@@ -322,23 +322,22 @@ EXPORT_SYMBOL(iounmap);
  */
 void *xlate_dev_mem_ptr(unsigned long phys)
 {
-	void *addr;
-	unsigned long start = phys & PAGE_MASK;
-
 	/* If page is RAM, we can use __va. Otherwise ioremap and unmap. */
-	if (page_is_ram(start >> PAGE_SHIFT))
+	if (page_is_ram(phys >> PAGE_SHIFT))
+#ifdef CONFIG_HIGHMEM
+	if ((phys >> PAGE_SHIFT) < max_low_pfn)
+#endif
 		return __va(phys);
 
-	addr = (void __force *)ioremap_cache(start, PAGE_SIZE);
-	if (addr)
-		addr = (void *)((unsigned long)addr | (phys & ~PAGE_MASK));
-
-	return addr;
+	return (void __force *)ioremap_cache(phys, PAGE_SIZE);
 }
 
 void unxlate_dev_mem_ptr(unsigned long phys, void *addr)
 {
 	if (page_is_ram(phys >> PAGE_SHIFT))
+#ifdef CONFIG_HIGHMEM
+	if ((phys >> PAGE_SHIFT) < max_low_pfn)
+#endif
 		return;
 
 	iounmap((void __iomem *)((unsigned long)addr & PAGE_MASK));
@@ -356,7 +355,7 @@ static int __init early_ioremap_debug_se
 early_param("early_ioremap_debug", early_ioremap_debug_setup);
 
 static __initdata int after_paging_init;
-static pte_t bm_pte[PAGE_SIZE/sizeof(pte_t)] __page_aligned_bss;
+static pte_t bm_pte[PAGE_SIZE/sizeof(pte_t)] __read_only __aligned(PAGE_SIZE);
 
 static inline pmd_t * __init early_ioremap_pmd(unsigned long addr)
 {
@@ -393,8 +392,7 @@ void __init early_ioremap_init(void)
 		slot_virt[i] = __fix_to_virt(FIX_BTMAP_BEGIN - NR_FIX_BTMAPS*i);
 
 	pmd = early_ioremap_pmd(fix_to_virt(FIX_BTMAP_BEGIN));
-	memset(bm_pte, 0, sizeof(bm_pte));
-	pmd_populate_kernel(&init_mm, pmd, bm_pte);
+	pmd_populate_user(&init_mm, pmd, bm_pte);
 
 	/*
 	 * The boot-ioremap range spans multiple pmds, for which
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/kmemcheck/kmemcheck.c linux-3.2.71-pax/arch/x86/mm/kmemcheck/kmemcheck.c
--- linux-3.2.71/arch/x86/mm/kmemcheck/kmemcheck.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/kmemcheck/kmemcheck.c	2012-07-04 19:24:47.640063004 +0200
@@ -622,9 +622,9 @@ bool kmemcheck_fault(struct pt_regs *reg
 	 * memory (e.g. tracked pages)? For now, we need this to avoid
 	 * invoking kmemcheck for PnP BIOS calls.
 	 */
-	if (regs->flags & X86_VM_MASK)
+	if (v8086_mode(regs))
 		return false;
-	if (regs->cs != __KERNEL_CS)
+	if (regs->cs != __KERNEL_CS && regs->cs != __KERNEXEC_KERNEL_CS)
 		return false;
 
 	pte = kmemcheck_pte_lookup(address);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/mmap.c linux-3.2.71-pax/arch/x86/mm/mmap.c
--- linux-3.2.71/arch/x86/mm/mmap.c	2015-05-10 09:22:36.691493010 +0200
+++ linux-3.2.71-pax/arch/x86/mm/mmap.c	2015-05-10 09:23:08.939494761 +0200
@@ -52,7 +52,7 @@ static unsigned long stack_maxrandom_siz
  * Leave an at least ~128 MB hole with possible stack randomization.
  */
 #define MIN_GAP (128*1024*1024UL + stack_maxrandom_size())
-#define MAX_GAP (TASK_SIZE/6*5)
+#define MAX_GAP (pax_task_size/6*5)
 
 static int mmap_is_legacy(void)
 {
@@ -82,27 +82,40 @@ static unsigned long mmap_rnd(void)
 	return rnd << PAGE_SHIFT;
 }
 
-static unsigned long mmap_base(void)
+static unsigned long mmap_base(struct mm_struct *mm)
 {
 	unsigned long gap = rlimit(RLIMIT_STACK);
+	unsigned long pax_task_size = TASK_SIZE;
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (mm->pax_flags & MF_PAX_SEGMEXEC)
+		pax_task_size = SEGMEXEC_TASK_SIZE;
+#endif
 
 	if (gap < MIN_GAP)
 		gap = MIN_GAP;
 	else if (gap > MAX_GAP)
 		gap = MAX_GAP;
 
-	return PAGE_ALIGN(TASK_SIZE - gap - mmap_rnd());
+	return PAGE_ALIGN(pax_task_size - gap - mmap_rnd());
 }
 
 /*
  * Bottom-up (legacy) layout on X86_32 did not support randomization, X86_64
  * does, but not when emulating X86_32
  */
-static unsigned long mmap_legacy_base(void)
+static unsigned long mmap_legacy_base(struct mm_struct *mm)
 {
-	if (mmap_is_ia32())
+	if (mmap_is_ia32()) {
+
+#ifdef CONFIG_PAX_SEGMEXEC
+		if (mm->pax_flags & MF_PAX_SEGMEXEC)
+			return SEGMEXEC_TASK_UNMAPPED_BASE;
+		else
+#endif
+
 		return TASK_UNMAPPED_BASE;
-	else
+	} else
 		return TASK_UNMAPPED_BASE + mmap_rnd();
 }
 
@@ -112,8 +125,15 @@ static unsigned long mmap_legacy_base(vo
  */
 void arch_pick_mmap_layout(struct mm_struct *mm)
 {
-	mm->mmap_legacy_base = mmap_legacy_base();
-	mm->mmap_base = mmap_base();
+	mm->mmap_legacy_base = mmap_legacy_base(mm);
+	mm->mmap_base = mmap_base(mm);
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (mm->pax_flags & MF_PAX_RANDMMAP) {
+		mm->mmap_legacy_base += mm->delta_mmap;
+		mm->mmap_base -= mm->delta_mmap + mm->delta_stack;
+	}
+#endif
 
 	if (mmap_is_legacy()) {
 		mm->mmap_base = mm->mmap_legacy_base;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/mmio-mod.c linux-3.2.71-pax/arch/x86/mm/mmio-mod.c
--- linux-3.2.71/arch/x86/mm/mmio-mod.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/mmio-mod.c	2013-01-16 21:26:41.594837481 +0100
@@ -194,7 +194,7 @@ static void pre(struct kmmio_probe *p, s
 		break;
 	default:
 		{
-			unsigned char *ip = (unsigned char *)instptr;
+			unsigned char *ip = (unsigned char *)ktla_ktva(instptr);
 			my_trace->opcode = MMIO_UNKNOWN_OP;
 			my_trace->width = 0;
 			my_trace->value = (*ip) << 16 | *(ip + 1) << 8 |
@@ -234,7 +234,7 @@ static void post(struct kmmio_probe *p,
 static void ioremap_trace_core(resource_size_t offset, unsigned long size,
 							void __iomem *addr)
 {
-	static atomic_t next_id;
+	static atomic_unchecked_t next_id;
 	struct remap_trace *trace = kmalloc(sizeof(*trace), GFP_KERNEL);
 	/* These are page-unaligned. */
 	struct mmiotrace_map map = {
@@ -258,7 +258,7 @@ static void ioremap_trace_core(resource_
 			.private = trace
 		},
 		.phys = offset,
-		.id = atomic_inc_return(&next_id)
+		.id = atomic_inc_return_unchecked(&next_id)
 	};
 	map.map_id = trace->id;
 
@@ -290,7 +290,7 @@ void mmiotrace_ioremap(resource_size_t o
 	ioremap_trace_core(offset, size, addr);
 }
 
-static void iounmap_trace_core(volatile void __iomem *addr)
+static void iounmap_trace_core(const volatile void __iomem *addr)
 {
 	struct mmiotrace_map map = {
 		.phys = 0,
@@ -328,7 +328,7 @@ not_enabled:
 	}
 }
 
-void mmiotrace_iounmap(volatile void __iomem *addr)
+void mmiotrace_iounmap(const volatile void __iomem *addr)
 {
 	might_sleep();
 	if (is_enabled()) /* recheck and proper locking in *_core() */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/numa.c linux-3.2.71-pax/arch/x86/mm/numa.c
--- linux-3.2.71/arch/x86/mm/numa.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/numa.c	2013-03-28 04:04:53.503949009 +0100
@@ -494,7 +494,7 @@ static bool __init numa_meminfo_cover_me
 	return true;
 }
 
-static int __init numa_register_memblks(struct numa_meminfo *mi)
+static int __init __intentional_overflow(-1) numa_register_memblks(struct numa_meminfo *mi)
 {
 	unsigned long uninitialized_var(pfn_align);
 	int i, nid;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/pageattr.c linux-3.2.71-pax/arch/x86/mm/pageattr.c
--- linux-3.2.71/arch/x86/mm/pageattr.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/pageattr.c	2012-12-14 19:33:32.709556898 +0100
@@ -261,7 +261,7 @@ static inline pgprot_t static_protection
 	 */
 #ifdef CONFIG_PCI_BIOS
 	if (pcibios_enabled && within(pfn, BIOS_BEGIN >> PAGE_SHIFT, BIOS_END >> PAGE_SHIFT))
-		pgprot_val(forbidden) |= _PAGE_NX;
+		pgprot_val(forbidden) |= _PAGE_NX & __supported_pte_mask;
 #endif
 
 	/*
@@ -269,9 +269,10 @@ static inline pgprot_t static_protection
 	 * Does not cover __inittext since that is gone later on. On
 	 * 64bit we do not enforce !NX on the low mapping
 	 */
-	if (within(address, (unsigned long)_text, (unsigned long)_etext))
-		pgprot_val(forbidden) |= _PAGE_NX;
+	if (within(address, ktla_ktva((unsigned long)_text), ktla_ktva((unsigned long)_etext)))
+		pgprot_val(forbidden) |= _PAGE_NX & __supported_pte_mask;
 
+#ifdef CONFIG_DEBUG_RODATA
 	/*
 	 * The .rodata section needs to be read-only. Using the pfn
 	 * catches all aliases.
@@ -279,6 +280,7 @@ static inline pgprot_t static_protection
 	if (within(pfn, __pa((unsigned long)__start_rodata) >> PAGE_SHIFT,
 		   __pa((unsigned long)__end_rodata) >> PAGE_SHIFT))
 		pgprot_val(forbidden) |= _PAGE_RW;
+#endif
 
 #if defined(CONFIG_X86_64) && defined(CONFIG_DEBUG_RODATA)
 	/*
@@ -317,6 +319,13 @@ static inline pgprot_t static_protection
 	}
 #endif
 
+#ifdef CONFIG_PAX_KERNEXEC
+	if (within(pfn, __pa(ktla_ktva((unsigned long)&_text)), __pa((unsigned long)&_sdata))) {
+		pgprot_val(forbidden) |= _PAGE_RW;
+		pgprot_val(forbidden) |= _PAGE_NX & __supported_pte_mask;
+	}
+#endif
+
 	prot = __pgprot(pgprot_val(prot) & ~pgprot_val(forbidden));
 
 	return prot;
@@ -369,23 +378,37 @@ EXPORT_SYMBOL_GPL(lookup_address);
 static void __set_pmd_pte(pte_t *kpte, unsigned long address, pte_t pte)
 {
 	/* change init_mm */
+	pax_open_kernel();
 	set_pte_atomic(kpte, pte);
+
 #ifdef CONFIG_X86_32
 	if (!SHARED_KERNEL_PMD) {
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+		unsigned long cpu;
+#else
 		struct page *page;
+#endif
 
+#ifdef CONFIG_PAX_PER_CPU_PGD
+		for (cpu = 0; cpu < nr_cpu_ids; ++cpu) {
+			pgd_t *pgd = get_cpu_pgd(cpu);
+#else
 		list_for_each_entry(page, &pgd_list, lru) {
-			pgd_t *pgd;
+			pgd_t *pgd = (pgd_t *)page_address(page);
+#endif
+
 			pud_t *pud;
 			pmd_t *pmd;
 
-			pgd = (pgd_t *)page_address(page) + pgd_index(address);
+			pgd += pgd_index(address);
 			pud = pud_offset(pgd, address);
 			pmd = pmd_offset(pud, address);
 			set_pte_atomic((pte_t *)pmd, pte);
 		}
 	}
 #endif
+	pax_close_kernel();
 }
 
 static int
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/pageattr-test.c linux-3.2.71-pax/arch/x86/mm/pageattr-test.c
--- linux-3.2.71/arch/x86/mm/pageattr-test.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/pageattr-test.c	2012-07-04 19:24:47.644063005 +0200
@@ -36,7 +36,7 @@ enum {
 
 static int pte_testbit(pte_t pte)
 {
-	return pte_flags(pte) & _PAGE_UNUSED1;
+	return pte_flags(pte) & _PAGE_CPA_TEST;
 }
 
 struct split_state {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/pat.c linux-3.2.71-pax/arch/x86/mm/pat.c
--- linux-3.2.71/arch/x86/mm/pat.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/pat.c	2012-07-04 19:24:47.644063005 +0200
@@ -361,7 +361,7 @@ int free_memtype(u64 start, u64 end)
 
 	if (!entry) {
 		printk(KERN_INFO "%s:%d freeing invalid memtype %Lx-%Lx\n",
-			current->comm, current->pid, start, end);
+			current->comm, task_pid_nr(current), start, end);
 		return -EINVAL;
 	}
 
@@ -492,8 +492,8 @@ static inline int range_is_allowed(unsig
 	while (cursor < to) {
 		if (!devmem_is_allowed(pfn)) {
 			printk(KERN_INFO
-		"Program %s tried to access /dev/mem between %Lx->%Lx.\n",
-				current->comm, from, to);
+		"Program %s tried to access /dev/mem between %Lx->%Lx (%Lx).\n",
+				current->comm, from, to, cursor);
 			return 0;
 		}
 		cursor += PAGE_SIZE;
@@ -557,7 +557,7 @@ int kernel_map_sync_memtype(u64 base, un
 		printk(KERN_INFO
 			"%s:%d ioremap_change_attr failed %s "
 			"for %Lx-%Lx\n",
-			current->comm, current->pid,
+			current->comm, task_pid_nr(current),
 			cattr_name(flags),
 			base, (unsigned long long)(base + size));
 		return -EINVAL;
@@ -593,7 +593,7 @@ static int reserve_pfn_range(u64 paddr,
 		if (want_flags != flags) {
 			printk(KERN_WARNING
 			"%s:%d map pfn RAM range req %s for %Lx-%Lx, got %s\n",
-				current->comm, current->pid,
+				current->comm, task_pid_nr(current),
 				cattr_name(want_flags),
 				(unsigned long long)paddr,
 				(unsigned long long)(paddr + size),
@@ -615,7 +615,7 @@ static int reserve_pfn_range(u64 paddr,
 			free_memtype(paddr, paddr + size);
 			printk(KERN_ERR "%s:%d map pfn expected mapping type %s"
 				" for %Lx-%Lx, got %s\n",
-				current->comm, current->pid,
+				current->comm, task_pid_nr(current),
 				cattr_name(want_flags),
 				(unsigned long long)paddr,
 				(unsigned long long)(paddr + size),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/pat_rbtree.c linux-3.2.71-pax/arch/x86/mm/pat_rbtree.c
--- linux-3.2.71/arch/x86/mm/pat_rbtree.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/pat_rbtree.c	2013-07-09 03:06:51.039950343 +0200
@@ -165,7 +165,7 @@ success:
 
 failure:
 	printk(KERN_INFO "%s:%d conflicting memory types "
-		"%Lx-%Lx %s<->%s\n", current->comm, current->pid, start,
+		"%Lx-%Lx %s<->%s\n", current->comm, task_pid_nr(current), start,
 		end, cattr_name(found_type), cattr_name(match->type));
 	return -EBUSY;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/pf_in.c linux-3.2.71-pax/arch/x86/mm/pf_in.c
--- linux-3.2.71/arch/x86/mm/pf_in.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/pf_in.c	2012-07-04 19:24:47.648063005 +0200
@@ -148,7 +148,7 @@ enum reason_type get_ins_type(unsigned l
 	int i;
 	enum reason_type rv = OTHERS;
 
-	p = (unsigned char *)ins_addr;
+	p = (unsigned char *)ktla_ktva(ins_addr);
 	p += skip_prefix(p, &prf);
 	p += get_opcode(p, &opcode);
 
@@ -168,7 +168,7 @@ static unsigned int get_ins_reg_width(un
 	struct prefix_bits prf;
 	int i;
 
-	p = (unsigned char *)ins_addr;
+	p = (unsigned char *)ktla_ktva(ins_addr);
 	p += skip_prefix(p, &prf);
 	p += get_opcode(p, &opcode);
 
@@ -191,7 +191,7 @@ unsigned int get_ins_mem_width(unsigned
 	struct prefix_bits prf;
 	int i;
 
-	p = (unsigned char *)ins_addr;
+	p = (unsigned char *)ktla_ktva(ins_addr);
 	p += skip_prefix(p, &prf);
 	p += get_opcode(p, &opcode);
 
@@ -415,7 +415,7 @@ unsigned long get_ins_reg_val(unsigned l
 	struct prefix_bits prf;
 	int i;
 
-	p = (unsigned char *)ins_addr;
+	p = (unsigned char *)ktla_ktva(ins_addr);
 	p += skip_prefix(p, &prf);
 	p += get_opcode(p, &opcode);
 	for (i = 0; i < ARRAY_SIZE(reg_rop); i++)
@@ -470,7 +470,7 @@ unsigned long get_ins_imm_val(unsigned l
 	struct prefix_bits prf;
 	int i;
 
-	p = (unsigned char *)ins_addr;
+	p = (unsigned char *)ktla_ktva(ins_addr);
 	p += skip_prefix(p, &prf);
 	p += get_opcode(p, &opcode);
 	for (i = 0; i < ARRAY_SIZE(imm_wop); i++)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/pgtable_32.c linux-3.2.71-pax/arch/x86/mm/pgtable_32.c
--- linux-3.2.71/arch/x86/mm/pgtable_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/pgtable_32.c	2012-07-04 19:24:47.648063005 +0200
@@ -48,10 +48,13 @@ void set_pte_vaddr(unsigned long vaddr,
 		return;
 	}
 	pte = pte_offset_kernel(pmd, vaddr);
+
+	pax_open_kernel();
 	if (pte_val(pteval))
 		set_pte_at(&init_mm, vaddr, pte, pteval);
 	else
 		pte_clear(&init_mm, vaddr, pte);
+	pax_close_kernel();
 
 	/*
 	 * It's enough to flush this one mapping.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/pgtable.c linux-3.2.71-pax/arch/x86/mm/pgtable.c
--- linux-3.2.71/arch/x86/mm/pgtable.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/pgtable.c	2012-07-04 19:24:47.648063005 +0200
@@ -84,10 +84,64 @@ static inline void pgd_list_del(pgd_t *p
 	list_del(&page->lru);
 }
 
-#define UNSHARED_PTRS_PER_PGD				\
-	(SHARED_KERNEL_PMD ? KERNEL_PGD_BOUNDARY : PTRS_PER_PGD)
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+pgdval_t clone_pgd_mask __read_only = ~_PAGE_PRESENT;
 
+void __shadow_user_pgds(pgd_t *dst, const pgd_t *src)
+{
+	unsigned int count = USER_PGD_PTRS;
+
+	while (count--)
+		*dst++ = __pgd((pgd_val(*src++) | (_PAGE_NX & __supported_pte_mask)) & ~_PAGE_USER);
+}
+#endif
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+void __clone_user_pgds(pgd_t *dst, const pgd_t *src)
+{
+	unsigned int count = USER_PGD_PTRS;
+
+	while (count--) {
+		pgd_t pgd;
+
+#ifdef CONFIG_X86_64
+		pgd = __pgd(pgd_val(*src++) | _PAGE_USER);
+#else
+		pgd = *src++;
+#endif
 
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+		pgd = __pgd(pgd_val(pgd) & clone_pgd_mask);
+#endif
+
+		*dst++ = pgd;
+	}
+
+}
+#endif
+
+#ifdef CONFIG_X86_64
+#define pxd_t				pud_t
+#define pyd_t				pgd_t
+#define paravirt_release_pxd(pfn)	paravirt_release_pud(pfn)
+#define pxd_free(mm, pud)		pud_free((mm), (pud))
+#define pyd_populate(mm, pgd, pud)	pgd_populate((mm), (pgd), (pud))
+#define pyd_offset(mm, address)		pgd_offset((mm), (address))
+#define PYD_SIZE			PGDIR_SIZE
+#else
+#define pxd_t				pmd_t
+#define pyd_t				pud_t
+#define paravirt_release_pxd(pfn)	paravirt_release_pmd(pfn)
+#define pxd_free(mm, pud)		pmd_free((mm), (pud))
+#define pyd_populate(mm, pgd, pud)	pud_populate((mm), (pgd), (pud))
+#define pyd_offset(mm, address)		pud_offset((mm), (address))
+#define PYD_SIZE			PUD_SIZE
+#endif
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+static inline void pgd_ctor(struct mm_struct *mm, pgd_t *pgd) {}
+static inline void pgd_dtor(pgd_t *pgd) {}
+#else
 static void pgd_set_mm(pgd_t *pgd, struct mm_struct *mm)
 {
 	BUILD_BUG_ON(sizeof(virt_to_page(pgd)->index) < sizeof(mm));
@@ -128,6 +182,7 @@ static void pgd_dtor(pgd_t *pgd)
 	pgd_list_del(pgd);
 	spin_unlock(&pgd_lock);
 }
+#endif
 
 /*
  * List of all pgd's needed for non-PAE so it can invalidate entries
@@ -140,7 +195,7 @@ static void pgd_dtor(pgd_t *pgd)
  * -- wli
  */
 
-#ifdef CONFIG_X86_PAE
+#if defined(CONFIG_X86_32) && defined(CONFIG_X86_PAE)
 /*
  * In PAE mode, we need to do a cr3 reload (=tlb flush) when
  * updating the top-level pagetable entries to guarantee the
@@ -152,7 +207,7 @@ static void pgd_dtor(pgd_t *pgd)
  * not shared between pagetables (!SHARED_KERNEL_PMDS), we allocate
  * and initialize the kernel pmds here.
  */
-#define PREALLOCATED_PMDS	UNSHARED_PTRS_PER_PGD
+#define PREALLOCATED_PXDS	(SHARED_KERNEL_PMD ? KERNEL_PGD_BOUNDARY : PTRS_PER_PGD)
 
 void pud_populate(struct mm_struct *mm, pud_t *pudp, pmd_t *pmd)
 {
@@ -170,36 +225,38 @@ void pud_populate(struct mm_struct *mm,
 	 */
 	flush_tlb_mm(mm);
 }
+#elif defined(CONFIG_X86_64) && defined(CONFIG_PAX_PER_CPU_PGD)
+#define PREALLOCATED_PXDS	USER_PGD_PTRS
 #else  /* !CONFIG_X86_PAE */
 
 /* No need to prepopulate any pagetable entries in non-PAE modes. */
-#define PREALLOCATED_PMDS	0
+#define PREALLOCATED_PXDS	0
 
 #endif	/* CONFIG_X86_PAE */
 
-static void free_pmds(pmd_t *pmds[])
+static void free_pxds(pxd_t *pxds[])
 {
 	int i;
 
-	for(i = 0; i < PREALLOCATED_PMDS; i++)
-		if (pmds[i])
-			free_page((unsigned long)pmds[i]);
+	for(i = 0; i < PREALLOCATED_PXDS; i++)
+		if (pxds[i])
+			free_page((unsigned long)pxds[i]);
 }
 
-static int preallocate_pmds(pmd_t *pmds[])
+static int preallocate_pxds(pxd_t *pxds[])
 {
 	int i;
 	bool failed = false;
 
-	for(i = 0; i < PREALLOCATED_PMDS; i++) {
-		pmd_t *pmd = (pmd_t *)__get_free_page(PGALLOC_GFP);
-		if (pmd == NULL)
+	for(i = 0; i < PREALLOCATED_PXDS; i++) {
+		pxd_t *pxd = (pxd_t *)__get_free_page(PGALLOC_GFP);
+		if (pxd == NULL)
 			failed = true;
-		pmds[i] = pmd;
+		pxds[i] = pxd;
 	}
 
 	if (failed) {
-		free_pmds(pmds);
+		free_pxds(pxds);
 		return -ENOMEM;
 	}
 
@@ -212,51 +269,55 @@ static int preallocate_pmds(pmd_t *pmds[
  * preallocate which never got a corresponding vma will need to be
  * freed manually.
  */
-static void pgd_mop_up_pmds(struct mm_struct *mm, pgd_t *pgdp)
+static void pgd_mop_up_pxds(struct mm_struct *mm, pgd_t *pgdp)
 {
 	int i;
 
-	for(i = 0; i < PREALLOCATED_PMDS; i++) {
+	for(i = 0; i < PREALLOCATED_PXDS; i++) {
 		pgd_t pgd = pgdp[i];
 
 		if (pgd_val(pgd) != 0) {
-			pmd_t *pmd = (pmd_t *)pgd_page_vaddr(pgd);
+			pxd_t *pxd = (pxd_t *)pgd_page_vaddr(pgd);
 
-			pgdp[i] = native_make_pgd(0);
+			set_pgd(pgdp + i, native_make_pgd(0));
 
-			paravirt_release_pmd(pgd_val(pgd) >> PAGE_SHIFT);
-			pmd_free(mm, pmd);
+			paravirt_release_pxd(pgd_val(pgd) >> PAGE_SHIFT);
+			pxd_free(mm, pxd);
 		}
 	}
 }
 
-static void pgd_prepopulate_pmd(struct mm_struct *mm, pgd_t *pgd, pmd_t *pmds[])
+static void pgd_prepopulate_pxd(struct mm_struct *mm, pgd_t *pgd, pxd_t *pxds[])
 {
-	pud_t *pud;
+	pyd_t *pyd;
 	unsigned long addr;
 	int i;
 
-	if (PREALLOCATED_PMDS == 0) /* Work around gcc-3.4.x bug */
+	if (PREALLOCATED_PXDS == 0) /* Work around gcc-3.4.x bug */
 		return;
 
-	pud = pud_offset(pgd, 0);
-
- 	for (addr = i = 0; i < PREALLOCATED_PMDS;
-	     i++, pud++, addr += PUD_SIZE) {
-		pmd_t *pmd = pmds[i];
+#ifdef CONFIG_X86_64
+	pyd = pyd_offset(mm, 0L);
+#else
+	pyd = pyd_offset(pgd, 0L);
+#endif
+
+ 	for (addr = i = 0; i < PREALLOCATED_PXDS;
+	     i++, pyd++, addr += PYD_SIZE) {
+		pxd_t *pxd = pxds[i];
 
 		if (i >= KERNEL_PGD_BOUNDARY)
-			memcpy(pmd, (pmd_t *)pgd_page_vaddr(swapper_pg_dir[i]),
-			       sizeof(pmd_t) * PTRS_PER_PMD);
+			memcpy(pxd, (pxd_t *)pgd_page_vaddr(swapper_pg_dir[i]),
+			       sizeof(pxd_t) * PTRS_PER_PMD);
 
-		pud_populate(mm, pud, pmd);
+		pyd_populate(mm, pyd, pxd);
 	}
 }
 
 pgd_t *pgd_alloc(struct mm_struct *mm)
 {
 	pgd_t *pgd;
-	pmd_t *pmds[PREALLOCATED_PMDS];
+	pxd_t *pxds[PREALLOCATED_PXDS];
 
 	pgd = (pgd_t *)__get_free_page(PGALLOC_GFP);
 
@@ -265,11 +326,11 @@ pgd_t *pgd_alloc(struct mm_struct *mm)
 
 	mm->pgd = pgd;
 
-	if (preallocate_pmds(pmds) != 0)
+	if (preallocate_pxds(pxds) != 0)
 		goto out_free_pgd;
 
 	if (paravirt_pgd_alloc(mm) != 0)
-		goto out_free_pmds;
+		goto out_free_pxds;
 
 	/*
 	 * Make sure that pre-populating the pmds is atomic with
@@ -279,14 +340,14 @@ pgd_t *pgd_alloc(struct mm_struct *mm)
 	spin_lock(&pgd_lock);
 
 	pgd_ctor(mm, pgd);
-	pgd_prepopulate_pmd(mm, pgd, pmds);
+	pgd_prepopulate_pxd(mm, pgd, pxds);
 
 	spin_unlock(&pgd_lock);
 
 	return pgd;
 
-out_free_pmds:
-	free_pmds(pmds);
+out_free_pxds:
+	free_pxds(pxds);
 out_free_pgd:
 	free_page((unsigned long)pgd);
 out:
@@ -295,7 +356,7 @@ out:
 
 void pgd_free(struct mm_struct *mm, pgd_t *pgd)
 {
-	pgd_mop_up_pmds(mm, pgd);
+	pgd_mop_up_pxds(mm, pgd);
 	pgd_dtor(pgd);
 	paravirt_pgd_free(mm, pgd);
 	free_page((unsigned long)pgd);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/physaddr.c linux-3.2.71-pax/arch/x86/mm/physaddr.c
--- linux-3.2.71/arch/x86/mm/physaddr.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/physaddr.c	2013-03-28 04:05:16.295947792 +0100
@@ -8,7 +8,7 @@
 
 #ifdef CONFIG_X86_64
 
-unsigned long __phys_addr(unsigned long x)
+unsigned long __intentional_overflow(-1) __phys_addr(unsigned long x)
 {
 	if (x >= __START_KERNEL_map) {
 		x -= __START_KERNEL_map;
@@ -45,7 +45,7 @@ EXPORT_SYMBOL(__virt_addr_valid);
 #else
 
 #ifdef CONFIG_DEBUG_VIRTUAL
-unsigned long __phys_addr(unsigned long x)
+unsigned long __intentional_overflow(-1) __phys_addr(unsigned long x)
 {
 	/* VMALLOC_* aren't constants  */
 	VIRTUAL_BUG_ON(x < PAGE_OFFSET);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/setup_nx.c linux-3.2.71-pax/arch/x86/mm/setup_nx.c
--- linux-3.2.71/arch/x86/mm/setup_nx.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/setup_nx.c	2012-07-04 19:24:47.648063005 +0200
@@ -5,8 +5,10 @@
 #include <asm/pgtable.h>
 #include <asm/proto.h>
 
+#if defined(CONFIG_X86_64) || defined(CONFIG_X86_PAE)
 static int disable_nx __cpuinitdata;
 
+#ifndef CONFIG_PAX_PAGEEXEC
 /*
  * noexec = on|off
  *
@@ -28,12 +30,17 @@ static int __init noexec_setup(char *str
 	return 0;
 }
 early_param("noexec", noexec_setup);
+#endif
+
+#endif
 
 void __cpuinit x86_configure_nx(void)
 {
+#if defined(CONFIG_X86_64) || defined(CONFIG_X86_PAE)
 	if (cpu_has_nx && !disable_nx)
 		__supported_pte_mask |= _PAGE_NX;
 	else
+#endif
 		__supported_pte_mask &= ~_PAGE_NX;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/mm/tlb.c linux-3.2.71-pax/arch/x86/mm/tlb.c
--- linux-3.2.71/arch/x86/mm/tlb.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/mm/tlb.c	2012-07-04 19:24:47.648063005 +0200
@@ -65,7 +65,11 @@ void leave_mm(int cpu)
 		BUG();
 	cpumask_clear_cpu(cpu,
 			  mm_cpumask(percpu_read(cpu_tlbstate.active_mm)));
+
+#ifndef CONFIG_PAX_PER_CPU_PGD
 	load_cr3(swapper_pg_dir);
+#endif
+
 }
 EXPORT_SYMBOL_GPL(leave_mm);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/net/bpf_jit_comp.c linux-3.2.71-pax/arch/x86/net/bpf_jit_comp.c
--- linux-3.2.71/arch/x86/net/bpf_jit_comp.c	2015-08-07 11:37:20.379789888 +0200
+++ linux-3.2.71-pax/arch/x86/net/bpf_jit_comp.c	2015-08-07 11:37:42.995790553 +0200
@@ -117,6 +117,10 @@ static inline void bpf_flush_icache(void
 	set_fs(old_fs);
 }
 
+struct bpf_jit_work {
+	struct work_struct work;
+	void *image;
+};
 
 void bpf_jit_compile(struct sk_filter *fp)
 {
@@ -141,6 +145,10 @@ void bpf_jit_compile(struct sk_filter *f
 	if (addrs == NULL)
 		return;
 
+	fp->work = kmalloc(sizeof(*fp->work), GFP_KERNEL);
+	if (!fp->work)
+		goto out;
+
 	/* Before first pass, make a rough estimation of addrs[]
 	 * each bpf instruction is translated to less than 64 bytes
 	 */
@@ -482,7 +490,7 @@ void bpf_jit_compile(struct sk_filter *f
 common_load:			seen |= SEEN_DATAREF;
 				if ((int)K < 0) {
 					/* Abort the JIT because __load_pointer() is needed. */
-					goto out;
+					goto error;
 				}
 				t_offset = func - (image + addrs[i]);
 				EMIT1_off32(0xbe, K); /* mov imm32,%esi */
@@ -497,7 +505,7 @@ common_load:			seen |= SEEN_DATAREF;
 			case BPF_S_LDX_B_MSH:
 				if ((int)K < 0) {
 					/* Abort the JIT because __load_pointer() is needed. */
-					goto out;
+					goto error;
 				}
 				seen |= SEEN_DATAREF | SEEN_XREG;
 				t_offset = sk_load_byte_msh - (image + addrs[i]);
@@ -587,17 +595,18 @@ cond_branch:			f_offset = addrs[i + filt
 				break;
 			default:
 				/* hmm, too complex filter, give up with jit compiler */
-				goto out;
+				goto error;
 			}
 			ilen = prog - temp;
 			if (image) {
 				if (unlikely(proglen + ilen > oldproglen)) {
 					pr_err("bpb_jit_compile fatal error\n");
-					kfree(addrs);
-					module_free(NULL, image);
-					return;
+					module_free_exec(NULL, image);
+					goto error;
 				}
+				pax_open_kernel();
 				memcpy(image + proglen, temp, ilen);
+				pax_close_kernel();
 			}
 			proglen += ilen;
 			addrs[i] = proglen;
@@ -618,11 +627,9 @@ cond_branch:			f_offset = addrs[i + filt
 			break;
 		}
 		if (proglen == oldproglen) {
-			image = module_alloc(max_t(unsigned int,
-						   proglen,
-						   sizeof(struct work_struct)));
+			image = module_alloc_exec(proglen);
 			if (!image)
-				goto out;
+				goto error;
 		}
 		oldproglen = proglen;
 	}
@@ -638,7 +645,10 @@ cond_branch:			f_offset = addrs[i + filt
 		bpf_flush_icache(image, image + proglen);
 
 		fp->bpf_func = (void *)image;
-	}
+	} else
+error:
+		kfree(fp->work);
+
 out:
 	kfree(addrs);
 	return;
@@ -646,18 +656,20 @@ out:
 
 static void jit_free_defer(struct work_struct *arg)
 {
-	module_free(NULL, arg);
+	module_free_exec(NULL, ((struct bpf_jit_work *)arg)->image);
+	kfree(arg);
 }
 
 /* run from softirq, we must use a work_struct to call
- * module_free() from process context
+ * module_free_exec() from process context
  */
 void bpf_jit_free(struct sk_filter *fp)
 {
 	if (fp->bpf_func != sk_run_filter) {
-		struct work_struct *work = (struct work_struct *)fp->bpf_func;
+		struct work_struct *work = &fp->work->work;
 
 		INIT_WORK(work, jit_free_defer);
+		fp->work->image = fp->bpf_func;
 		schedule_work(work);
 	}
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/net/bpf_jit.S linux-3.2.71-pax/arch/x86/net/bpf_jit.S
--- linux-3.2.71/arch/x86/net/bpf_jit.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/net/bpf_jit.S	2012-07-04 19:24:47.648063005 +0200
@@ -9,6 +9,7 @@
  */
 #include <linux/linkage.h>
 #include <asm/dwarf2.h>
+#include <asm/alternative-asm.h>
 
 /*
  * Calling convention :
@@ -35,6 +36,7 @@ sk_load_word:
 	jle	bpf_slow_path_word
 	mov     (SKBDATA,%rsi),%eax
 	bswap   %eax  			/* ntohl() */
+	pax_force_retaddr
 	ret
 
 
@@ -53,6 +55,7 @@ sk_load_half:
 	jle	bpf_slow_path_half
 	movzwl	(SKBDATA,%rsi),%eax
 	rol	$8,%ax			# ntohs()
+	pax_force_retaddr
 	ret
 
 sk_load_byte_ind:
@@ -66,6 +69,7 @@ sk_load_byte:
 	cmp	%esi,%r9d   /* if (offset >= hlen) goto bpf_slow_path_byte */
 	jle	bpf_slow_path_byte
 	movzbl	(SKBDATA,%rsi),%eax
+	pax_force_retaddr
 	ret
 
 /**
@@ -82,6 +86,7 @@ ENTRY(sk_load_byte_msh)
 	movzbl	(SKBDATA,%rsi),%ebx
 	and	$15,%bl
 	shl	$2,%bl
+	pax_force_retaddr
 	ret
 	CFI_ENDPROC
 ENDPROC(sk_load_byte_msh)
@@ -91,6 +96,7 @@ bpf_error:
 	xor		%eax,%eax
 	mov		-8(%rbp),%rbx
 	leaveq
+	pax_force_retaddr
 	ret
 
 /* rsi contains offset and can be scratched */
@@ -113,6 +119,7 @@ bpf_slow_path_word:
 	js	bpf_error
 	mov	-12(%rbp),%eax
 	bswap	%eax
+	pax_force_retaddr
 	ret
 
 bpf_slow_path_half:
@@ -121,12 +128,14 @@ bpf_slow_path_half:
 	mov	-12(%rbp),%ax
 	rol	$8,%ax
 	movzwl	%ax,%eax
+	pax_force_retaddr
 	ret
 
 bpf_slow_path_byte:
 	bpf_slow_path_common(1)
 	js	bpf_error
 	movzbl	-12(%rbp),%eax
+	pax_force_retaddr
 	ret
 
 bpf_slow_path_byte_msh:
@@ -137,4 +146,5 @@ bpf_slow_path_byte_msh:
 	and	$15,%al
 	shl	$2,%al
 	xchg	%eax,%ebx
+	pax_force_retaddr
 	ret
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/oprofile/backtrace.c linux-3.2.71-pax/arch/x86/oprofile/backtrace.c
--- linux-3.2.71/arch/x86/oprofile/backtrace.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/oprofile/backtrace.c	2012-07-04 19:24:47.652063004 +0200
@@ -46,11 +46,11 @@ dump_user_backtrace_32(struct stack_fram
 	struct stack_frame_ia32 *fp;
 	unsigned long bytes;
 
-	bytes = copy_from_user_nmi(bufhead, head, sizeof(bufhead));
+	bytes = copy_from_user_nmi(bufhead, (const char __force_user *)head, sizeof(bufhead));
 	if (bytes != sizeof(bufhead))
 		return NULL;
 
-	fp = (struct stack_frame_ia32 *) compat_ptr(bufhead[0].next_frame);
+	fp = (struct stack_frame_ia32 __force_kernel *) compat_ptr(bufhead[0].next_frame);
 
 	oprofile_add_trace(bufhead[0].return_address);
 
@@ -92,7 +92,7 @@ static struct stack_frame *dump_user_bac
 	struct stack_frame bufhead[2];
 	unsigned long bytes;
 
-	bytes = copy_from_user_nmi(bufhead, head, sizeof(bufhead));
+	bytes = copy_from_user_nmi(bufhead, (const char __force_user *)head, sizeof(bufhead));
 	if (bytes != sizeof(bufhead))
 		return NULL;
 
@@ -111,7 +111,7 @@ x86_backtrace(struct pt_regs * const reg
 {
 	struct stack_frame *head = (struct stack_frame *)frame_pointer(regs);
 
-	if (!user_mode_vm(regs)) {
+	if (!user_mode(regs)) {
 		unsigned long stack = kernel_stack_pointer(regs);
 		if (depth)
 			dump_trace(NULL, regs, (unsigned long *)stack, 0,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/oprofile/nmi_int.c linux-3.2.71-pax/arch/x86/oprofile/nmi_int.c
--- linux-3.2.71/arch/x86/oprofile/nmi_int.c	2012-10-31 13:04:03.463702834 +0100
+++ linux-3.2.71-pax/arch/x86/oprofile/nmi_int.c	2013-03-28 01:35:23.244427951 +0100
@@ -23,6 +23,7 @@
 #include <asm/nmi.h>
 #include <asm/msr.h>
 #include <asm/apic.h>
+#include <asm/pgtable.h>
 
 #include "op_counter.h"
 #include "op_x86_model.h"
@@ -759,8 +760,11 @@ int __init op_nmi_init(struct oprofile_o
 	if (ret)
 		return ret;
 
-	if (!model->num_virt_counters)
-		model->num_virt_counters = model->num_counters;
+	if (!model->num_virt_counters) {
+		pax_open_kernel();
+		*(unsigned int *)&model->num_virt_counters = model->num_counters;
+		pax_close_kernel();
+	}
 
 	mux_init(ops);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/oprofile/op_model_amd.c linux-3.2.71-pax/arch/x86/oprofile/op_model_amd.c
--- linux-3.2.71/arch/x86/oprofile/op_model_amd.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/oprofile/op_model_amd.c	2013-03-28 01:35:23.244427951 +0100
@@ -519,9 +519,11 @@ static int op_amd_init(struct oprofile_o
 		num_counters = AMD64_NUM_COUNTERS;
 	}
 
-	op_amd_spec.num_counters = num_counters;
-	op_amd_spec.num_controls = num_counters;
-	op_amd_spec.num_virt_counters = max(num_counters, NUM_VIRT_COUNTERS);
+	pax_open_kernel();
+	*(unsigned int *)&op_amd_spec.num_counters = num_counters;
+	*(unsigned int *)&op_amd_spec.num_controls = num_counters;
+	*(unsigned int *)&op_amd_spec.num_virt_counters = max(num_counters, NUM_VIRT_COUNTERS);
+	pax_close_kernel();
 
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/oprofile/op_model_ppro.c linux-3.2.71-pax/arch/x86/oprofile/op_model_ppro.c
--- linux-3.2.71/arch/x86/oprofile/op_model_ppro.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/oprofile/op_model_ppro.c	2013-03-28 01:35:23.244427951 +0100
@@ -19,6 +19,7 @@
 #include <asm/msr.h>
 #include <asm/apic.h>
 #include <asm/nmi.h>
+#include <asm/pgtable.h>
 
 #include "op_x86_model.h"
 #include "op_counter.h"
@@ -221,8 +222,10 @@ static void arch_perfmon_setup_counters(
 
 	num_counters = min((int)eax.split.num_counters, OP_MAX_COUNTER);
 
-	op_arch_perfmon_spec.num_counters = num_counters;
-	op_arch_perfmon_spec.num_controls = num_counters;
+	pax_open_kernel();
+	*(unsigned int *)&op_arch_perfmon_spec.num_counters = num_counters;
+	*(unsigned int *)&op_arch_perfmon_spec.num_controls = num_counters;
+	pax_close_kernel();
 }
 
 static int arch_perfmon_init(struct oprofile_operations *ignore)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/oprofile/op_x86_model.h linux-3.2.71-pax/arch/x86/oprofile/op_x86_model.h
--- linux-3.2.71/arch/x86/oprofile/op_x86_model.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/oprofile/op_x86_model.h	2013-03-28 01:35:23.248427951 +0100
@@ -52,7 +52,7 @@ struct op_x86_model_spec {
 	void		(*switch_ctrl)(struct op_x86_model_spec const *model,
 				       struct op_msrs const * const msrs);
 #endif
-};
+} __do_const;
 
 struct op_counter_config;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/pci/amd_bus.c linux-3.2.71-pax/arch/x86/pci/amd_bus.c
--- linux-3.2.71/arch/x86/pci/amd_bus.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/pci/amd_bus.c	2013-02-20 01:19:15.530027341 +0100
@@ -355,7 +355,7 @@ static int __cpuinit amd_cpu_notify(stru
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata amd_cpu_notifier = {
+static struct notifier_block amd_cpu_notifier = {
 	.notifier_call	= amd_cpu_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/pci/irq.c linux-3.2.71-pax/arch/x86/pci/irq.c
--- linux-3.2.71/arch/x86/pci/irq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/pci/irq.c	2013-03-28 04:34:45.187853347 +0100
@@ -50,7 +50,7 @@ struct irq_router {
 struct irq_router_handler {
 	u16 vendor;
 	int (*probe)(struct irq_router *r, struct pci_dev *router, u16 device);
-};
+} __do_const;
 
 int (*pcibios_enable_irq)(struct pci_dev *dev) = pirq_enable_irq;
 void (*pcibios_disable_irq)(struct pci_dev *dev) = NULL;
@@ -794,7 +794,7 @@ static __init int pico_router_probe(stru
 	return 0;
 }
 
-static __initdata struct irq_router_handler pirq_routers[] = {
+static __initconst const struct irq_router_handler pirq_routers[] = {
 	{ PCI_VENDOR_ID_INTEL, intel_router_probe },
 	{ PCI_VENDOR_ID_AL, ali_router_probe },
 	{ PCI_VENDOR_ID_ITE, ite_router_probe },
@@ -821,7 +821,7 @@ static struct pci_dev *pirq_router_dev;
 static void __init pirq_find_router(struct irq_router *r)
 {
 	struct irq_routing_table *rt = pirq_table;
-	struct irq_router_handler *h;
+	const struct irq_router_handler *h;
 
 #ifdef CONFIG_PCI_BIOS
 	if (!rt->signature) {
@@ -1094,7 +1094,7 @@ static int __init fix_acer_tm360_irqrout
 	return 0;
 }
 
-static struct dmi_system_id __initdata pciirq_dmi_table[] = {
+static const struct dmi_system_id __initconst pciirq_dmi_table[] = {
 	{
 		.callback = fix_broken_hp_bios_irq9,
 		.ident = "HP Pavilion N5400 Series Laptop",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/pci/mrst.c linux-3.2.71-pax/arch/x86/pci/mrst.c
--- linux-3.2.71/arch/x86/pci/mrst.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/pci/mrst.c	2012-07-04 19:24:47.652063004 +0200
@@ -234,7 +234,9 @@ int __init pci_mrst_init(void)
 	printk(KERN_INFO "Moorestown platform detected, using MRST PCI ops\n");
 	pci_mmcfg_late_init();
 	pcibios_enable_irq = mrst_pci_irq_enable;
-	pci_root_ops = pci_mrst_ops;
+	pax_open_kernel();
+	memcpy((void *)&pci_root_ops, &pci_mrst_ops, sizeof(pci_mrst_ops));
+	pax_close_kernel();
 	/* Continue with standard init */
 	return 1;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/pci/pcbios.c linux-3.2.71-pax/arch/x86/pci/pcbios.c
--- linux-3.2.71/arch/x86/pci/pcbios.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/pci/pcbios.c	2012-07-04 19:24:47.652063004 +0200
@@ -79,50 +79,93 @@ union bios32 {
 static struct {
 	unsigned long address;
 	unsigned short segment;
-} bios32_indirect = { 0, __KERNEL_CS };
+} bios32_indirect __read_only = { 0, __PCIBIOS_CS };
 
 /*
  * Returns the entry point for the given service, NULL on error
  */
 
-static unsigned long bios32_service(unsigned long service)
+static unsigned long __devinit bios32_service(unsigned long service)
 {
 	unsigned char return_code;	/* %al */
 	unsigned long address;		/* %ebx */
 	unsigned long length;		/* %ecx */
 	unsigned long entry;		/* %edx */
 	unsigned long flags;
+	struct desc_struct d, *gdt;
 
 	local_irq_save(flags);
-	__asm__("lcall *(%%edi); cld"
+
+	gdt = get_cpu_gdt_table(smp_processor_id());
+
+	pack_descriptor(&d, 0UL, 0xFFFFFUL, 0x9B, 0xC);
+	write_gdt_entry(gdt, GDT_ENTRY_PCIBIOS_CS, &d, DESCTYPE_S);
+	pack_descriptor(&d, 0UL, 0xFFFFFUL, 0x93, 0xC);
+	write_gdt_entry(gdt, GDT_ENTRY_PCIBIOS_DS, &d, DESCTYPE_S);
+
+	__asm__("movw %w7, %%ds; lcall *(%%edi); push %%ss; pop %%ds; cld"
 		: "=a" (return_code),
 		  "=b" (address),
 		  "=c" (length),
 		  "=d" (entry)
 		: "0" (service),
 		  "1" (0),
-		  "D" (&bios32_indirect));
+		  "D" (&bios32_indirect),
+		  "r"(__PCIBIOS_DS)
+		: "memory");
+
+	pax_open_kernel();
+	gdt[GDT_ENTRY_PCIBIOS_CS].a = 0;
+	gdt[GDT_ENTRY_PCIBIOS_CS].b = 0;
+	gdt[GDT_ENTRY_PCIBIOS_DS].a = 0;
+	gdt[GDT_ENTRY_PCIBIOS_DS].b = 0;
+	pax_close_kernel();
+
 	local_irq_restore(flags);
 
 	switch (return_code) {
-		case 0:
-			return address + entry;
-		case 0x80:	/* Not present */
-			printk(KERN_WARNING "bios32_service(0x%lx): not present\n", service);
-			return 0;
-		default: /* Shouldn't happen */
-			printk(KERN_WARNING "bios32_service(0x%lx): returned 0x%x -- BIOS bug!\n",
-				service, return_code);
+	case 0: {
+		int cpu;
+		unsigned char flags;
+
+		printk(KERN_INFO "bios32_service: base:%08lx length:%08lx entry:%08lx\n", address, length, entry);
+		if (address >= 0xFFFF0 || length > 0x100000 - address || length <= entry) {
+			printk(KERN_WARNING "bios32_service: not valid\n");
 			return 0;
+		}
+		address = address + PAGE_OFFSET;
+		length += 16UL; /* some BIOSs underreport this... */
+		flags = 4;
+		if (length >= 64*1024*1024) {
+			length >>= PAGE_SHIFT;
+			flags |= 8;
+		}
+
+		for (cpu = 0; cpu < nr_cpu_ids; cpu++) {
+			gdt = get_cpu_gdt_table(cpu);
+			pack_descriptor(&d, address, length, 0x9b, flags);
+			write_gdt_entry(gdt, GDT_ENTRY_PCIBIOS_CS, &d, DESCTYPE_S);
+			pack_descriptor(&d, address, length, 0x93, flags);
+			write_gdt_entry(gdt, GDT_ENTRY_PCIBIOS_DS, &d, DESCTYPE_S);
+		}
+		return entry;
+	}
+	case 0x80:	/* Not present */
+		printk(KERN_WARNING "bios32_service(0x%lx): not present\n", service);
+		return 0;
+	default: /* Shouldn't happen */
+		printk(KERN_WARNING "bios32_service(0x%lx): returned 0x%x -- BIOS bug!\n",
+			service, return_code);
+		return 0;
 	}
 }
 
 static struct {
 	unsigned long address;
 	unsigned short segment;
-} pci_indirect = { 0, __KERNEL_CS };
+} pci_indirect __read_only = { 0, __PCIBIOS_CS };
 
-static int pci_bios_present;
+static int pci_bios_present __read_only;
 
 static int __devinit check_pcibios(void)
 {
@@ -131,11 +174,13 @@ static int __devinit check_pcibios(void)
 	unsigned long flags, pcibios_entry;
 
 	if ((pcibios_entry = bios32_service(PCI_SERVICE))) {
-		pci_indirect.address = pcibios_entry + PAGE_OFFSET;
+		pci_indirect.address = pcibios_entry;
 
 		local_irq_save(flags);
-		__asm__(
-			"lcall *(%%edi); cld\n\t"
+		__asm__("movw %w6, %%ds\n\t"
+			"lcall *%%ss:(%%edi); cld\n\t"
+			"push %%ss\n\t"
+			"pop %%ds\n\t"
 			"jc 1f\n\t"
 			"xor %%ah, %%ah\n"
 			"1:"
@@ -144,7 +189,8 @@ static int __devinit check_pcibios(void)
 			  "=b" (ebx),
 			  "=c" (ecx)
 			: "1" (PCIBIOS_PCI_BIOS_PRESENT),
-			  "D" (&pci_indirect)
+			  "D" (&pci_indirect),
+			  "r" (__PCIBIOS_DS)
 			: "memory");
 		local_irq_restore(flags);
 
@@ -189,7 +235,10 @@ static int pci_bios_read(unsigned int se
 
 	switch (len) {
 	case 1:
-		__asm__("lcall *(%%esi); cld\n\t"
+		__asm__("movw %w6, %%ds\n\t"
+			"lcall *%%ss:(%%esi); cld\n\t"
+			"push %%ss\n\t"
+			"pop %%ds\n\t"
 			"jc 1f\n\t"
 			"xor %%ah, %%ah\n"
 			"1:"
@@ -198,7 +247,8 @@ static int pci_bios_read(unsigned int se
 			: "1" (PCIBIOS_READ_CONFIG_BYTE),
 			  "b" (bx),
 			  "D" ((long)reg),
-			  "S" (&pci_indirect));
+			  "S" (&pci_indirect),
+			  "r" (__PCIBIOS_DS));
 		/*
 		 * Zero-extend the result beyond 8 bits, do not trust the
 		 * BIOS having done it:
@@ -206,7 +256,10 @@ static int pci_bios_read(unsigned int se
 		*value &= 0xff;
 		break;
 	case 2:
-		__asm__("lcall *(%%esi); cld\n\t"
+		__asm__("movw %w6, %%ds\n\t"
+			"lcall *%%ss:(%%esi); cld\n\t"
+			"push %%ss\n\t"
+			"pop %%ds\n\t"
 			"jc 1f\n\t"
 			"xor %%ah, %%ah\n"
 			"1:"
@@ -215,7 +268,8 @@ static int pci_bios_read(unsigned int se
 			: "1" (PCIBIOS_READ_CONFIG_WORD),
 			  "b" (bx),
 			  "D" ((long)reg),
-			  "S" (&pci_indirect));
+			  "S" (&pci_indirect),
+			  "r" (__PCIBIOS_DS));
 		/*
 		 * Zero-extend the result beyond 16 bits, do not trust the
 		 * BIOS having done it:
@@ -223,7 +277,10 @@ static int pci_bios_read(unsigned int se
 		*value &= 0xffff;
 		break;
 	case 4:
-		__asm__("lcall *(%%esi); cld\n\t"
+		__asm__("movw %w6, %%ds\n\t"
+			"lcall *%%ss:(%%esi); cld\n\t"
+			"push %%ss\n\t"
+			"pop %%ds\n\t"
 			"jc 1f\n\t"
 			"xor %%ah, %%ah\n"
 			"1:"
@@ -232,7 +289,8 @@ static int pci_bios_read(unsigned int se
 			: "1" (PCIBIOS_READ_CONFIG_DWORD),
 			  "b" (bx),
 			  "D" ((long)reg),
-			  "S" (&pci_indirect));
+			  "S" (&pci_indirect),
+			  "r" (__PCIBIOS_DS));
 		break;
 	}
 
@@ -256,7 +314,10 @@ static int pci_bios_write(unsigned int s
 
 	switch (len) {
 	case 1:
-		__asm__("lcall *(%%esi); cld\n\t"
+		__asm__("movw %w6, %%ds\n\t"
+			"lcall *%%ss:(%%esi); cld\n\t"
+			"push %%ss\n\t"
+			"pop %%ds\n\t"
 			"jc 1f\n\t"
 			"xor %%ah, %%ah\n"
 			"1:"
@@ -265,10 +326,14 @@ static int pci_bios_write(unsigned int s
 			  "c" (value),
 			  "b" (bx),
 			  "D" ((long)reg),
-			  "S" (&pci_indirect));
+			  "S" (&pci_indirect),
+			  "r" (__PCIBIOS_DS));
 		break;
 	case 2:
-		__asm__("lcall *(%%esi); cld\n\t"
+		__asm__("movw %w6, %%ds\n\t"
+			"lcall *%%ss:(%%esi); cld\n\t"
+			"push %%ss\n\t"
+			"pop %%ds\n\t"
 			"jc 1f\n\t"
 			"xor %%ah, %%ah\n"
 			"1:"
@@ -277,10 +342,14 @@ static int pci_bios_write(unsigned int s
 			  "c" (value),
 			  "b" (bx),
 			  "D" ((long)reg),
-			  "S" (&pci_indirect));
+			  "S" (&pci_indirect),
+			  "r" (__PCIBIOS_DS));
 		break;
 	case 4:
-		__asm__("lcall *(%%esi); cld\n\t"
+		__asm__("movw %w6, %%ds\n\t"
+			"lcall *%%ss:(%%esi); cld\n\t"
+			"push %%ss\n\t"
+			"pop %%ds\n\t"
 			"jc 1f\n\t"
 			"xor %%ah, %%ah\n"
 			"1:"
@@ -289,7 +358,8 @@ static int pci_bios_write(unsigned int s
 			  "c" (value),
 			  "b" (bx),
 			  "D" ((long)reg),
-			  "S" (&pci_indirect));
+			  "S" (&pci_indirect),
+			  "r" (__PCIBIOS_DS));
 		break;
 	}
 
@@ -394,10 +464,13 @@ struct irq_routing_table * pcibios_get_i
 
 	DBG("PCI: Fetching IRQ routing table... ");
 	__asm__("push %%es\n\t"
+		"movw %w8, %%ds\n\t"
 		"push %%ds\n\t"
 		"pop  %%es\n\t"
-		"lcall *(%%esi); cld\n\t"
+		"lcall *%%ss:(%%esi); cld\n\t"
 		"pop %%es\n\t"
+		"push %%ss\n\t"
+		"pop %%ds\n"
 		"jc 1f\n\t"
 		"xor %%ah, %%ah\n"
 		"1:"
@@ -408,7 +481,8 @@ struct irq_routing_table * pcibios_get_i
 		  "1" (0),
 		  "D" ((long) &opt),
 		  "S" (&pci_indirect),
-		  "m" (opt)
+		  "m" (opt),
+		  "r" (__PCIBIOS_DS)
 		: "memory");
 	DBG("OK  ret=%d, size=%d, map=%x\n", ret, opt.size, map);
 	if (ret & 0xff00)
@@ -432,7 +506,10 @@ int pcibios_set_irq_routing(struct pci_d
 {
 	int ret;
 
-	__asm__("lcall *(%%esi); cld\n\t"
+	__asm__("movw %w5, %%ds\n\t"
+		"lcall *%%ss:(%%esi); cld\n\t"
+		"push %%ss\n\t"
+		"pop %%ds\n"
 		"jc 1f\n\t"
 		"xor %%ah, %%ah\n"
 		"1:"
@@ -440,7 +517,8 @@ int pcibios_set_irq_routing(struct pci_d
 		: "0" (PCIBIOS_SET_PCI_HW_INT),
 		  "b" ((dev->bus->number << 8) | dev->devfn),
 		  "c" ((irq << 8) | (pin + 10)),
-		  "S" (&pci_indirect));
+		  "S" (&pci_indirect),
+		  "r" (__PCIBIOS_DS));
 	return !(ret & 0xff00);
 }
 EXPORT_SYMBOL(pcibios_set_irq_routing);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/platform/efi/efi_32.c linux-3.2.71-pax/arch/x86/platform/efi/efi_32.c
--- linux-3.2.71/arch/x86/platform/efi/efi_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/platform/efi/efi_32.c	2013-07-04 21:46:24.750055200 +0200
@@ -44,11 +44,22 @@ void efi_call_phys_prelog(void)
 {
 	struct desc_ptr gdt_descr;
 
+#ifdef CONFIG_PAX_KERNEXEC
+	struct desc_struct d;
+#endif
+
 	local_irq_save(efi_rt_eflags);
 
 	load_cr3(initial_page_table);
 	__flush_tlb_all();
 
+#ifdef CONFIG_PAX_KERNEXEC
+	pack_descriptor(&d, 0, 0xFFFFF, 0x9B, 0xC);
+	write_gdt_entry(get_cpu_gdt_table(0), GDT_ENTRY_KERNEXEC_EFI_CS, &d, DESCTYPE_S);
+	pack_descriptor(&d, 0, 0xFFFFF, 0x93, 0xC);
+	write_gdt_entry(get_cpu_gdt_table(0), GDT_ENTRY_KERNEXEC_EFI_DS, &d, DESCTYPE_S);
+#endif
+
 	gdt_descr.address = __pa(get_cpu_gdt_table(0));
 	gdt_descr.size = GDT_SIZE - 1;
 	load_gdt(&gdt_descr);
@@ -58,11 +69,24 @@ void efi_call_phys_epilog(void)
 {
 	struct desc_ptr gdt_descr;
 
+#ifdef CONFIG_PAX_KERNEXEC
+	struct desc_struct d;
+
+	memset(&d, 0, sizeof d);
+	write_gdt_entry(get_cpu_gdt_table(0), GDT_ENTRY_KERNEXEC_EFI_CS, &d, DESCTYPE_S);
+	write_gdt_entry(get_cpu_gdt_table(0), GDT_ENTRY_KERNEXEC_EFI_DS, &d, DESCTYPE_S);
+#endif
+
 	gdt_descr.address = (unsigned long)get_cpu_gdt_table(0);
 	gdt_descr.size = GDT_SIZE - 1;
 	load_gdt(&gdt_descr);
 
+#ifdef CONFIG_PAX_PER_CPU_PGD
+	load_cr3(get_cpu_pgd(smp_processor_id()));
+#else
 	load_cr3(swapper_pg_dir);
+#endif
+
 	__flush_tlb_all();
 
 	local_irq_restore(efi_rt_eflags);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/platform/efi/efi_64.c linux-3.2.71-pax/arch/x86/platform/efi/efi_64.c
--- linux-3.2.71/arch/x86/platform/efi/efi_64.c	2013-02-09 01:12:40.724782285 +0100
+++ linux-3.2.71-pax/arch/x86/platform/efi/efi_64.c	2013-07-04 21:44:54.842060001 +0200
@@ -75,6 +75,11 @@ void __init efi_call_phys_prelog(void)
 		vaddress = (unsigned long)__va(pgd * PGDIR_SIZE);
 		set_pgd(pgd_offset_k(pgd * PGDIR_SIZE), *pgd_offset_k(vaddress));
 	}
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+	load_cr3(swapper_pg_dir);
+#endif
+
 	__flush_tlb_all();
 }
 
@@ -88,6 +93,11 @@ void __init efi_call_phys_epilog(void)
 	for (pgd = 0; pgd < n_pgds; pgd++)
 		set_pgd(pgd_offset_k(pgd * PGDIR_SIZE), save_pgd[pgd]);
 	kfree(save_pgd);
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+	load_cr3(get_cpu_pgd(smp_processor_id()));
+#endif
+
 	__flush_tlb_all();
 	local_irq_restore(efi_flags);
 	early_code_mapping_set_exec(0);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/platform/efi/efi_stub_32.S linux-3.2.71-pax/arch/x86/platform/efi/efi_stub_32.S
--- linux-3.2.71/arch/x86/platform/efi/efi_stub_32.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/platform/efi/efi_stub_32.S	2012-08-06 13:22:50.335012030 +0200
@@ -6,7 +6,9 @@
  */
 
 #include <linux/linkage.h>
+#include <linux/init.h>
 #include <asm/page_types.h>
+#include <asm/segment.h>
 
 /*
  * efi_call_phys(void *, ...) is a function with variable parameters.
@@ -20,7 +22,7 @@
  * service functions will comply with gcc calling convention, too.
  */
 
-.text
+__INIT
 ENTRY(efi_call_phys)
 	/*
 	 * 0. The function can only be called in Linux kernel. So CS has been
@@ -36,10 +38,24 @@ ENTRY(efi_call_phys)
 	 * The mapping of lower virtual memory has been created in prelog and
 	 * epilog.
 	 */
-	movl	$1f, %edx
-	subl	$__PAGE_OFFSET, %edx
-	jmp	*%edx
+#ifdef CONFIG_PAX_KERNEXEC
+	movl	$(__KERNEXEC_EFI_DS), %edx
+	mov	%edx, %ds
+	mov	%edx, %es
+	mov	%edx, %ss
+	addl	$2f,(1f)
+	ljmp	*(1f)
+
+__INITDATA
+1:	.long __LOAD_PHYSICAL_ADDR, __KERNEXEC_EFI_CS
+.previous
+
+2:
+	subl	$2b,(1b)
+#else
+	jmp	1f-__PAGE_OFFSET
 1:
+#endif
 
 	/*
 	 * 2. Now on the top of stack is the return
@@ -47,14 +63,8 @@ ENTRY(efi_call_phys)
 	 * parameter 2, ..., param n. To make things easy, we save the return
 	 * address of efi_call_phys in a global variable.
 	 */
-	popl	%edx
-	movl	%edx, saved_return_addr
-	/* get the function pointer into ECX*/
-	popl	%ecx
-	movl	%ecx, efi_rt_function_ptr
-	movl	$2f, %edx
-	subl	$__PAGE_OFFSET, %edx
-	pushl	%edx
+	popl	(saved_return_addr)
+	popl	(efi_rt_function_ptr)
 
 	/*
 	 * 3. Clear PG bit in %CR0.
@@ -73,9 +83,8 @@ ENTRY(efi_call_phys)
 	/*
 	 * 5. Call the physical function.
 	 */
-	jmp	*%ecx
+	call	*(efi_rt_function_ptr-__PAGE_OFFSET)
 
-2:
 	/*
 	 * 6. After EFI runtime service returns, control will return to
 	 * following instruction. We'd better readjust stack pointer first.
@@ -88,35 +97,36 @@ ENTRY(efi_call_phys)
 	movl	%cr0, %edx
 	orl	$0x80000000, %edx
 	movl	%edx, %cr0
-	jmp	1f
-1:
+
 	/*
 	 * 8. Now restore the virtual mode from flat mode by
 	 * adding EIP with PAGE_OFFSET.
 	 */
-	movl	$1f, %edx
-	jmp	*%edx
+#ifdef CONFIG_PAX_KERNEXEC
+	movl	$(__KERNEL_DS), %edx
+	mov	%edx, %ds
+	mov	%edx, %es
+	mov	%edx, %ss
+	ljmp	$(__KERNEL_CS),$1f
+#else
+	jmp	1f+__PAGE_OFFSET
+#endif
 1:
 
 	/*
 	 * 9. Balance the stack. And because EAX contain the return value,
 	 * we'd better not clobber it.
 	 */
-	leal	efi_rt_function_ptr, %edx
-	movl	(%edx), %ecx
-	pushl	%ecx
+	pushl	(efi_rt_function_ptr)
 
 	/*
-	 * 10. Push the saved return address onto the stack and return.
+	 * 10. Return to the saved return address.
 	 */
-	leal	saved_return_addr, %edx
-	movl	(%edx), %ecx
-	pushl	%ecx
-	ret
+	jmpl	*(saved_return_addr)
 ENDPROC(efi_call_phys)
 .previous
 
-.data
+__INITDATA
 saved_return_addr:
 	.long 0
 efi_rt_function_ptr:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/platform/efi/efi_stub_64.S linux-3.2.71-pax/arch/x86/platform/efi/efi_stub_64.S
--- linux-3.2.71/arch/x86/platform/efi/efi_stub_64.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/platform/efi/efi_stub_64.S	2012-07-04 19:24:47.652063004 +0200
@@ -7,6 +7,7 @@
  */
 
 #include <linux/linkage.h>
+#include <asm/alternative-asm.h>
 
 #define SAVE_XMM			\
 	mov %rsp, %rax;			\
@@ -40,6 +41,7 @@ ENTRY(efi_call0)
 	call *%rdi
 	addq $32, %rsp
 	RESTORE_XMM
+	pax_force_retaddr 0, 1
 	ret
 ENDPROC(efi_call0)
 
@@ -50,6 +52,7 @@ ENTRY(efi_call1)
 	call *%rdi
 	addq $32, %rsp
 	RESTORE_XMM
+	pax_force_retaddr 0, 1
 	ret
 ENDPROC(efi_call1)
 
@@ -60,6 +63,7 @@ ENTRY(efi_call2)
 	call *%rdi
 	addq $32, %rsp
 	RESTORE_XMM
+	pax_force_retaddr 0, 1
 	ret
 ENDPROC(efi_call2)
 
@@ -71,6 +75,7 @@ ENTRY(efi_call3)
 	call *%rdi
 	addq $32, %rsp
 	RESTORE_XMM
+	pax_force_retaddr 0, 1
 	ret
 ENDPROC(efi_call3)
 
@@ -83,6 +88,7 @@ ENTRY(efi_call4)
 	call *%rdi
 	addq $32, %rsp
 	RESTORE_XMM
+	pax_force_retaddr 0, 1
 	ret
 ENDPROC(efi_call4)
 
@@ -96,6 +102,7 @@ ENTRY(efi_call5)
 	call *%rdi
 	addq $48, %rsp
 	RESTORE_XMM
+	pax_force_retaddr 0, 1
 	ret
 ENDPROC(efi_call5)
 
@@ -112,5 +119,6 @@ ENTRY(efi_call6)
 	call *%rdi
 	addq $48, %rsp
 	RESTORE_XMM
+	pax_force_retaddr 0, 1
 	ret
 ENDPROC(efi_call6)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/platform/mrst/mrst.c linux-3.2.71-pax/arch/x86/platform/mrst/mrst.c
--- linux-3.2.71/arch/x86/platform/mrst/mrst.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/platform/mrst/mrst.c	2013-02-17 16:28:47.544320187 +0100
@@ -76,18 +76,20 @@ struct sfi_rtc_table_entry sfi_mrtc_arra
 EXPORT_SYMBOL_GPL(sfi_mrtc_array);
 int sfi_mrtc_num;
 
-static void mrst_power_off(void)
+static __noreturn void mrst_power_off(void)
 {
 	if (__mrst_cpu_chip == MRST_CPU_CHIP_LINCROFT)
 		intel_scu_ipc_simple_command(IPCMSG_COLD_RESET, 1);
+	BUG();
 }
 
-static void mrst_reboot(void)
+static __noreturn void mrst_reboot(void)
 {
 	if (__mrst_cpu_chip == MRST_CPU_CHIP_LINCROFT)
 		intel_scu_ipc_simple_command(IPCMSG_COLD_RESET, 0);
 	else
 		intel_scu_ipc_simple_command(IPCMSG_COLD_BOOT, 0);
+	BUG();
 }
 
 /* parse all the mtimer info to a static mtimer array */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/platform/olpc/olpc_dt.c linux-3.2.71-pax/arch/x86/platform/olpc/olpc_dt.c
--- linux-3.2.71/arch/x86/platform/olpc/olpc_dt.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/platform/olpc/olpc_dt.c	2013-01-16 21:27:00.926837034 +0100
@@ -156,7 +156,7 @@ void * __init prom_early_alloc(unsigned
 	return res;
 }
 
-static struct of_pdt_ops prom_olpc_ops __initdata = {
+static struct of_pdt_ops prom_olpc_ops __initconst = {
 	.nextprop = olpc_dt_nextprop,
 	.getproplen = olpc_dt_getproplen,
 	.getproperty = olpc_dt_getproperty,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/power/cpu.c linux-3.2.71-pax/arch/x86/power/cpu.c
--- linux-3.2.71/arch/x86/power/cpu.c	2013-03-29 02:18:43.367676034 +0100
+++ linux-3.2.71-pax/arch/x86/power/cpu.c	2013-03-29 02:22:27.803664051 +0100
@@ -132,7 +132,7 @@ static void do_fpu_end(void)
 static void fix_processor_context(void)
 {
 	int cpu = smp_processor_id();
-	struct tss_struct *t = &per_cpu(init_tss, cpu);
+	struct tss_struct *t = init_tss + cpu;
 
 	set_tss_desc(cpu, t);	/*
 				 * This just modifies memory; should not be
@@ -142,8 +142,6 @@ static void fix_processor_context(void)
 				 */
 
 #ifdef CONFIG_X86_64
-	get_cpu_gdt_table(cpu)[GDT_ENTRY_TSS].type = 9;
-
 	syscall_init();				/* This sets MSR_*STAR and related */
 #endif
 	load_TR_desc();				/* This does ltr */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/tools/relocs.c linux-3.2.71-pax/arch/x86/tools/relocs.c
--- linux-3.2.71/arch/x86/tools/relocs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/tools/relocs.c	2012-07-31 00:31:09.016074659 +0200
@@ -11,10 +11,13 @@
 #include <endian.h>
 #include <regex.h>
 
+#include "../../../include/generated/autoconf.h"
+
 static void die(char *fmt, ...);
 
 #define ARRAY_SIZE(x) (sizeof(x) / sizeof((x)[0]))
 static Elf32_Ehdr ehdr;
+static Elf32_Phdr *phdr;
 static unsigned long reloc_count, reloc_idx;
 static unsigned long *relocs;
 static unsigned long reloc16_count, reloc16_idx;
@@ -322,9 +325,39 @@ static void read_ehdr(FILE *fp)
 	}
 }
 
+static void read_phdrs(FILE *fp)
+{
+	unsigned int i;
+
+	phdr = calloc(ehdr.e_phnum, sizeof(Elf32_Phdr));
+	if (!phdr) {
+		die("Unable to allocate %d program headers\n",
+		    ehdr.e_phnum);
+	}
+	if (fseek(fp, ehdr.e_phoff, SEEK_SET) < 0) {
+		die("Seek to %d failed: %s\n",
+			ehdr.e_phoff, strerror(errno));
+	}
+	if (fread(phdr, sizeof(*phdr), ehdr.e_phnum, fp) != ehdr.e_phnum) {
+		die("Cannot read ELF program headers: %s\n",
+			strerror(errno));
+	}
+	for(i = 0; i < ehdr.e_phnum; i++) {
+		phdr[i].p_type      = elf32_to_cpu(phdr[i].p_type);
+		phdr[i].p_offset    = elf32_to_cpu(phdr[i].p_offset);
+		phdr[i].p_vaddr     = elf32_to_cpu(phdr[i].p_vaddr);
+		phdr[i].p_paddr     = elf32_to_cpu(phdr[i].p_paddr);
+		phdr[i].p_filesz    = elf32_to_cpu(phdr[i].p_filesz);
+		phdr[i].p_memsz     = elf32_to_cpu(phdr[i].p_memsz);
+		phdr[i].p_flags     = elf32_to_cpu(phdr[i].p_flags);
+		phdr[i].p_align     = elf32_to_cpu(phdr[i].p_align);
+	}
+
+}
+
 static void read_shdrs(FILE *fp)
 {
-	int i;
+	unsigned int i;
 	Elf32_Shdr shdr;
 
 	secs = calloc(ehdr.e_shnum, sizeof(struct section));
@@ -359,7 +392,7 @@ static void read_shdrs(FILE *fp)
 
 static void read_strtabs(FILE *fp)
 {
-	int i;
+	unsigned int i;
 	for (i = 0; i < ehdr.e_shnum; i++) {
 		struct section *sec = &secs[i];
 		if (sec->shdr.sh_type != SHT_STRTAB) {
@@ -384,7 +417,7 @@ static void read_strtabs(FILE *fp)
 
 static void read_symtabs(FILE *fp)
 {
-	int i,j;
+	unsigned int i,j;
 	for (i = 0; i < ehdr.e_shnum; i++) {
 		struct section *sec = &secs[i];
 		if (sec->shdr.sh_type != SHT_SYMTAB) {
@@ -417,7 +450,9 @@ static void read_symtabs(FILE *fp)
 
 static void read_relocs(FILE *fp)
 {
-	int i,j;
+	unsigned int i,j;
+	uint32_t base;
+
 	for (i = 0; i < ehdr.e_shnum; i++) {
 		struct section *sec = &secs[i];
 		if (sec->shdr.sh_type != SHT_REL) {
@@ -437,9 +472,22 @@ static void read_relocs(FILE *fp)
 			die("Cannot read symbol table: %s\n",
 				strerror(errno));
 		}
+		base = 0;
+
+#ifdef CONFIG_X86_32
+		for (j = 0; j < ehdr.e_phnum; j++) {
+			if (phdr[j].p_type != PT_LOAD )
+				continue;
+			if (secs[sec->shdr.sh_info].shdr.sh_offset < phdr[j].p_offset || secs[sec->shdr.sh_info].shdr.sh_offset >= phdr[j].p_offset + phdr[j].p_filesz)
+				continue;
+			base = CONFIG_PAGE_OFFSET + phdr[j].p_paddr - phdr[j].p_vaddr;
+			break;
+		}
+#endif
+
 		for (j = 0; j < sec->shdr.sh_size/sizeof(Elf32_Rel); j++) {
 			Elf32_Rel *rel = &sec->reltab[j];
-			rel->r_offset = elf32_to_cpu(rel->r_offset);
+			rel->r_offset = elf32_to_cpu(rel->r_offset) + base;
 			rel->r_info   = elf32_to_cpu(rel->r_info);
 		}
 	}
@@ -448,13 +496,13 @@ static void read_relocs(FILE *fp)
 
 static void print_absolute_symbols(void)
 {
-	int i;
+	unsigned int i;
 	printf("Absolute symbols\n");
 	printf(" Num:    Value Size  Type       Bind        Visibility  Name\n");
 	for (i = 0; i < ehdr.e_shnum; i++) {
 		struct section *sec = &secs[i];
 		char *sym_strtab;
-		int j;
+		unsigned int j;
 
 		if (sec->shdr.sh_type != SHT_SYMTAB) {
 			continue;
@@ -481,14 +529,14 @@ static void print_absolute_symbols(void)
 
 static void print_absolute_relocs(void)
 {
-	int i, printed = 0;
+	unsigned int i, printed = 0;
 
 	for (i = 0; i < ehdr.e_shnum; i++) {
 		struct section *sec = &secs[i];
 		struct section *sec_applies, *sec_symtab;
 		char *sym_strtab;
 		Elf32_Sym *sh_symtab;
-		int j;
+		unsigned int j;
 		if (sec->shdr.sh_type != SHT_REL) {
 			continue;
 		}
@@ -550,13 +598,13 @@ static void print_absolute_relocs(void)
 static void walk_relocs(void (*visit)(Elf32_Rel *rel, Elf32_Sym *sym),
 			int use_real_mode)
 {
-	int i;
+	unsigned int i;
 	/* Walk through the relocations */
 	for (i = 0; i < ehdr.e_shnum; i++) {
 		char *sym_strtab;
 		Elf32_Sym *sh_symtab;
 		struct section *sec_applies, *sec_symtab;
-		int j;
+		unsigned int j;
 		struct section *sec = &secs[i];
 
 		if (sec->shdr.sh_type != SHT_REL) {
@@ -580,6 +628,22 @@ static void walk_relocs(void (*visit)(El
 			sym = &sh_symtab[ELF32_R_SYM(rel->r_info)];
 			r_type = ELF32_R_TYPE(rel->r_info);
 
+			/* Don't relocate actual per-cpu variables, they are absolute indices, not addresses */
+			if (!strcmp(sec_name(sym->st_shndx), ".data..percpu") && strcmp(sym_name(sym_strtab, sym), "__per_cpu_load"))
+				continue;
+
+#if defined(CONFIG_PAX_KERNEXEC) && defined(CONFIG_X86_32)
+			/* Don't relocate actual code, they are relocated implicitly by the base address of KERNEL_CS */
+			if (!strcmp(sec_name(sym->st_shndx), ".text.end") && !strcmp(sym_name(sym_strtab, sym), "_etext"))
+				continue;
+			if (!strcmp(sec_name(sym->st_shndx), ".init.text"))
+				continue;
+			if (!strcmp(sec_name(sym->st_shndx), ".exit.text"))
+				continue;
+			if (!strcmp(sec_name(sym->st_shndx), ".text") && strcmp(sym_name(sym_strtab, sym), "__LOAD_PHYSICAL_ADDR"))
+				continue;
+#endif
+
 			shn_abs = sym->st_shndx == SHN_ABS;
 
 			switch (r_type) {
@@ -676,7 +740,7 @@ static int write32(unsigned int v, FILE
 
 static void emit_relocs(int as_text, int use_real_mode)
 {
-	int i;
+	unsigned int i;
 	/* Count how many relocations I have and allocate space for them. */
 	reloc_count = 0;
 	walk_relocs(count_reloc, use_real_mode);
@@ -803,6 +867,7 @@ int main(int argc, char **argv)
 			fname, strerror(errno));
 	}
 	read_ehdr(fp);
+	read_phdrs(fp);
 	read_shdrs(fp);
 	read_strtabs(fp);
 	read_symtabs(fp);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/um/tls_32.c linux-3.2.71-pax/arch/x86/um/tls_32.c
--- linux-3.2.71/arch/x86/um/tls_32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/um/tls_32.c	2013-07-09 03:06:22.339951875 +0200
@@ -259,7 +259,7 @@ out:
 	if (unlikely(task == current &&
 		     !t->arch.tls_array[idx - GDT_ENTRY_TLS_MIN].flushed)) {
 		printk(KERN_ERR "get_tls_entry: task with pid %d got here "
-				"without flushed TLS.", current->pid);
+				"without flushed TLS.", task_pid_nr(current));
 	}
 
 	return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/vdso/Makefile linux-3.2.71-pax/arch/x86/vdso/Makefile
--- linux-3.2.71/arch/x86/vdso/Makefile	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/vdso/Makefile	2012-07-04 19:24:47.656063004 +0200
@@ -137,7 +137,7 @@ quiet_cmd_vdso = VDSO    $@
 		       -Wl,-T,$(filter %.lds,$^) $(filter %.o,$^) && \
 		 sh $(srctree)/$(src)/checkundef.sh '$(NM)' '$@'
 
-VDSO_LDFLAGS = -fPIC -shared $(call cc-ldoption, -Wl$(comma)--hash-style=sysv)
+VDSO_LDFLAGS = -fPIC -shared -Wl,--no-undefined $(call cc-ldoption, -Wl$(comma)--hash-style=sysv)
 GCOV_PROFILE := n
 
 #
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/vdso/vdso32-setup.c linux-3.2.71-pax/arch/x86/vdso/vdso32-setup.c
--- linux-3.2.71/arch/x86/vdso/vdso32-setup.c	2014-09-14 14:10:58.146117294 +0200
+++ linux-3.2.71-pax/arch/x86/vdso/vdso32-setup.c	2014-09-14 14:11:25.922138325 +0200
@@ -25,6 +25,7 @@
 #include <asm/tlbflush.h>
 #include <asm/vdso.h>
 #include <asm/proto.h>
+#include <asm/mman.h>
 
 enum {
 	VDSO_DISABLED = 0,
@@ -226,7 +227,7 @@ static inline void map_compat_vdso(int m
 void enable_sep_cpu(void)
 {
 	int cpu = get_cpu();
-	struct tss_struct *tss = &per_cpu(init_tss, cpu);
+	struct tss_struct *tss = init_tss + cpu;
 
 	if (!boot_cpu_has(X86_FEATURE_SEP)) {
 		put_cpu();
@@ -249,7 +250,7 @@ static int __init gate_vma_init(void)
 	gate_vma.vm_start = FIXADDR_USER_START;
 	gate_vma.vm_end = FIXADDR_USER_END;
 	gate_vma.vm_flags = VM_READ | VM_MAYREAD | VM_EXEC | VM_MAYEXEC;
-	gate_vma.vm_page_prot = __P101;
+	gate_vma.vm_page_prot = vm_get_page_prot(gate_vma.vm_flags);
 	/*
 	 * Make sure the vDSO gets into every core dump.
 	 * Dumping its contents makes post-mortem fully interpretable later
@@ -331,14 +332,14 @@ int arch_setup_additional_pages(struct l
 	if (compat)
 		addr = VDSO_HIGH_BASE;
 	else {
-		addr = get_unmapped_area(NULL, 0, PAGE_SIZE, 0, 0);
+		addr = get_unmapped_area(NULL, 0, PAGE_SIZE, 0, MAP_EXECUTABLE);
 		if (IS_ERR_VALUE(addr)) {
 			ret = addr;
 			goto up_fail;
 		}
 	}
 
-	current->mm->context.vdso = (void *)addr;
+	current->mm->context.vdso = addr;
 
 	if (compat_uses_vma || !compat) {
 		/*
@@ -361,11 +362,11 @@ int arch_setup_additional_pages(struct l
 	}
 
 	current_thread_info()->sysenter_return =
-		VDSO32_SYMBOL(addr, SYSENTER_RETURN);
+		(__force void __user *)VDSO32_SYMBOL(addr, SYSENTER_RETURN);
 
   up_fail:
 	if (ret)
-		current->mm->context.vdso = NULL;
+		current->mm->context.vdso = 0;
 
 	up_write(&mm->mmap_sem);
 
@@ -412,8 +413,14 @@ __initcall(ia32_binfmt_init);
 
 const char *arch_vma_name(struct vm_area_struct *vma)
 {
-	if (vma->vm_mm && vma->vm_start == (long)vma->vm_mm->context.vdso)
+	if (vma->vm_mm && vma->vm_start == vma->vm_mm->context.vdso)
 		return "[vdso]";
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (vma->vm_mm && vma->vm_mirror && vma->vm_mirror->vm_start == vma->vm_mm->context.vdso)
+		return "[vdso]";
+#endif
+
 	return NULL;
 }
 
@@ -423,7 +430,7 @@ struct vm_area_struct *get_gate_vma(stru
 	 * Check to see if the corresponding task was created in compat vdso
 	 * mode.
 	 */
-	if (mm && mm->context.vdso == (void *)VDSO_HIGH_BASE)
+	if (mm && mm->context.vdso == VDSO_HIGH_BASE)
 		return &gate_vma;
 	return NULL;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/vdso/vma.c linux-3.2.71-pax/arch/x86/vdso/vma.c
--- linux-3.2.71/arch/x86/vdso/vma.c	2015-02-20 12:37:32.985178781 +0100
+++ linux-3.2.71-pax/arch/x86/vdso/vma.c	2015-02-20 12:47:47.613145965 +0100
@@ -16,8 +16,6 @@
 #include <asm/vdso.h>
 #include <asm/page.h>
 
-unsigned int __read_mostly vdso_enabled = 1;
-
 extern char vdso_start[], vdso_end[];
 extern unsigned short vdso_sync_cpuid;
 
@@ -119,13 +117,15 @@ static unsigned long vdso_addr(unsigned
 int arch_setup_additional_pages(struct linux_binprm *bprm, int uses_interp)
 {
 	struct mm_struct *mm = current->mm;
-	unsigned long addr;
+	unsigned long addr = 0;
 	int ret;
 
-	if (!vdso_enabled)
-		return 0;
-
 	down_write(&mm->mmap_sem);
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	addr = vdso_addr(mm->start_stack, vdso_size);
 	addr = get_unmapped_area(NULL, addr, vdso_size, 0, 0);
 	if (IS_ERR_VALUE(addr)) {
@@ -133,26 +133,18 @@ int arch_setup_additional_pages(struct l
 		goto up_fail;
 	}
 
-	current->mm->context.vdso = (void *)addr;
+	mm->context.vdso = addr;
 
 	ret = install_special_mapping(mm, addr, vdso_size,
 				      VM_READ|VM_EXEC|
 				      VM_MAYREAD|VM_MAYWRITE|VM_MAYEXEC|
 				      VM_ALWAYSDUMP,
 				      vdso_pages);
-	if (ret) {
-		current->mm->context.vdso = NULL;
-		goto up_fail;
-	}
+
+	if (ret)
+		mm->context.vdso = 0;
 
 up_fail:
 	up_write(&mm->mmap_sem);
 	return ret;
 }
-
-static __init int vdso_setup(char *s)
-{
-	vdso_enabled = simple_strtoul(s, NULL, 0);
-	return 0;
-}
-__setup("vdso=", vdso_setup);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/xen/enlighten.c linux-3.2.71-pax/arch/x86/xen/enlighten.c
--- linux-3.2.71/arch/x86/xen/enlighten.c	2015-08-14 21:48:35.036707927 +0200
+++ linux-3.2.71-pax/arch/x86/xen/enlighten.c	2015-08-14 21:48:45.548707366 +0200
@@ -86,8 +86,6 @@ EXPORT_SYMBOL_GPL(xen_start_info);
 
 struct shared_info xen_dummy_shared_info;
 
-void *xen_initial_gdt;
-
 RESERVE_BRK(shared_info_page_brk, PAGE_SIZE);
 __read_mostly int xen_have_vector_callback;
 EXPORT_SYMBOL_GPL(xen_have_vector_callback);
@@ -422,8 +420,7 @@ static void xen_load_gdt(const struct de
 {
 	unsigned long va = dtr->address;
 	unsigned int size = dtr->size + 1;
-	unsigned pages = (size + PAGE_SIZE - 1) / PAGE_SIZE;
-	unsigned long frames[pages];
+	unsigned long frames[65536 / PAGE_SIZE];
 	int f;
 
 	/*
@@ -471,8 +468,7 @@ static void __init xen_load_gdt_boot(con
 {
 	unsigned long va = dtr->address;
 	unsigned int size = dtr->size + 1;
-	unsigned pages = (size + PAGE_SIZE - 1) / PAGE_SIZE;
-	unsigned long frames[pages];
+	unsigned long frames[(GDT_SIZE + PAGE_SIZE - 1) / PAGE_SIZE];
 	int f;
 
 	/*
@@ -480,7 +476,7 @@ static void __init xen_load_gdt_boot(con
 	 * 8-byte entries, or 16 4k pages..
 	 */
 
-	BUG_ON(size > 65536);
+	BUG_ON(size > GDT_SIZE);
 	BUG_ON(va & ~PAGE_MASK);
 
 	for (f = 0; va < dtr->address + size; va += PAGE_SIZE, f++) {
@@ -1112,30 +1108,30 @@ static const struct pv_apic_ops xen_apic
 #endif
 };
 
-static void xen_reboot(int reason)
+static __noreturn void xen_reboot(int reason)
 {
 	struct sched_shutdown r = { .reason = reason };
 
-	if (HYPERVISOR_sched_op(SCHEDOP_shutdown, &r))
-		BUG();
+	HYPERVISOR_sched_op(SCHEDOP_shutdown, &r);
+	BUG();
 }
 
-static void xen_restart(char *msg)
+static __noreturn void xen_restart(char *msg)
 {
 	xen_reboot(SHUTDOWN_reboot);
 }
 
-static void xen_emergency_restart(void)
+static __noreturn void xen_emergency_restart(void)
 {
 	xen_reboot(SHUTDOWN_reboot);
 }
 
-static void xen_machine_halt(void)
+static __noreturn void xen_machine_halt(void)
 {
 	xen_reboot(SHUTDOWN_poweroff);
 }
 
-static void xen_machine_power_off(void)
+static void __noreturn xen_machine_power_off(void)
 {
 	if (pm_power_off)
 		pm_power_off();
@@ -1184,6 +1180,9 @@ static void __init xen_setup_stackprotec
 	pv_cpu_ops.load_gdt = xen_load_gdt_boot;
 
 	setup_stack_canary_segment(0);
+#ifdef CONFIG_X86_64
+	load_percpu_segment(0);
+#endif
 	switch_to_new_gdt(0);
 
 	pv_cpu_ops.write_gdt_entry = xen_write_gdt_entry;
@@ -1236,7 +1235,17 @@ asmlinkage void __init xen_start_kernel(
 	__userpte_alloc_gfp &= ~__GFP_HIGHMEM;
 
 	/* Work out if we support NX */
-	x86_configure_nx();
+#if defined(CONFIG_X86_64) || defined(CONFIG_X86_PAE)
+	if ((cpuid_eax(0x80000000) & 0xffff0000) == 0x80000000 &&
+	    (cpuid_edx(0x80000001) & (1U << (X86_FEATURE_NX & 31)))) {
+		unsigned l, h;
+
+		__supported_pte_mask |= _PAGE_NX;
+		rdmsr(MSR_EFER, l, h);
+		l |= EFER_NX;
+		wrmsr(MSR_EFER, l, h);
+	}
+#endif
 
 	xen_setup_features();
 
@@ -1267,13 +1276,6 @@ asmlinkage void __init xen_start_kernel(
 
 	machine_ops = xen_machine_ops;
 
-	/*
-	 * The only reliable way to retain the initial address of the
-	 * percpu gdt_page is to remember it here, so we can go and
-	 * mark it RW later, when the initial percpu area is freed.
-	 */
-	xen_initial_gdt = &per_cpu(gdt_page, 0);
-
 	xen_smp_init();
 
 #ifdef CONFIG_ACPI_NUMA
@@ -1458,7 +1460,7 @@ static int __cpuinit xen_hvm_cpu_notify(
 	return NOTIFY_OK;
 }
 
-static struct notifier_block xen_hvm_cpu_notifier __cpuinitdata = {
+static struct notifier_block xen_hvm_cpu_notifier = {
 	.notifier_call	= xen_hvm_cpu_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/xen/mmu.c linux-3.2.71-pax/arch/x86/xen/mmu.c
--- linux-3.2.71/arch/x86/xen/mmu.c	2013-04-30 00:45:09.475714486 +0200
+++ linux-3.2.71-pax/arch/x86/xen/mmu.c	2013-11-23 18:07:03.493937069 +0100
@@ -365,7 +365,7 @@ static pteval_t pte_mfn_to_pfn(pteval_t
 	return val;
 }
 
-static pteval_t pte_pfn_to_mfn(pteval_t val)
+static pteval_t __intentional_overflow(-1) pte_pfn_to_mfn(pteval_t val)
 {
 	if (val & _PAGE_PRESENT) {
 		unsigned long pfn = (val & PTE_PFN_MASK) >> PAGE_SHIFT;
@@ -1757,6 +1757,9 @@ pgd_t * __init xen_setup_kernel_pagetabl
 	convert_pfn_mfn(init_level4_pgt);
 	convert_pfn_mfn(level3_ident_pgt);
 	convert_pfn_mfn(level3_kernel_pgt);
+	convert_pfn_mfn(level3_vmalloc_start_pgt);
+	convert_pfn_mfn(level3_vmalloc_end_pgt);
+	convert_pfn_mfn(level3_vmemmap_pgt);
 
 	l3 = m2v(pgd[pgd_index(__START_KERNEL_map)].pgd);
 	l2 = m2v(l3[pud_index(__START_KERNEL_map)].pud);
@@ -1775,7 +1778,11 @@ pgd_t * __init xen_setup_kernel_pagetabl
 	set_page_prot(init_level4_pgt, PAGE_KERNEL_RO);
 	set_page_prot(level3_ident_pgt, PAGE_KERNEL_RO);
 	set_page_prot(level3_kernel_pgt, PAGE_KERNEL_RO);
+	set_page_prot(level3_vmalloc_start_pgt, PAGE_KERNEL_RO);
+	set_page_prot(level3_vmalloc_end_pgt, PAGE_KERNEL_RO);
+	set_page_prot(level3_vmemmap_pgt, PAGE_KERNEL_RO);
 	set_page_prot(level3_user_vsyscall, PAGE_KERNEL_RO);
+	set_page_prot(level2_vmemmap_pgt, PAGE_KERNEL_RO);
 	set_page_prot(level2_kernel_pgt, PAGE_KERNEL_RO);
 	set_page_prot(level2_fixmap_pgt, PAGE_KERNEL_RO);
 
@@ -1986,6 +1993,7 @@ static void __init xen_post_allocator_in
 	pv_mmu_ops.set_pud = xen_set_pud;
 #if PAGETABLE_LEVELS == 4
 	pv_mmu_ops.set_pgd = xen_set_pgd;
+	pv_mmu_ops.set_pgd_batched = xen_set_pgd;
 #endif
 
 	/* This will work as long as patching hasn't happened yet
@@ -2067,6 +2075,7 @@ static const struct pv_mmu_ops xen_mmu_o
 	.pud_val = PV_CALLEE_SAVE(xen_pud_val),
 	.make_pud = PV_CALLEE_SAVE(xen_make_pud),
 	.set_pgd = xen_set_pgd_hyper,
+	.set_pgd_batched = xen_set_pgd_hyper,
 
 	.alloc_pud = xen_alloc_pmd_init,
 	.release_pud = xen_release_pmd_init,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/xen/smp.c linux-3.2.71-pax/arch/x86/xen/smp.c
--- linux-3.2.71/arch/x86/xen/smp.c	2013-05-14 13:33:40.524285678 +0200
+++ linux-3.2.71-pax/arch/x86/xen/smp.c	2013-08-17 01:55:05.452229905 +0200
@@ -209,11 +209,6 @@ static void __init xen_smp_prepare_boot_
 {
 	BUG_ON(smp_processor_id() != 0);
 	native_smp_prepare_boot_cpu();
-
-	/* We've switched to the "real" per-cpu gdt, so make sure the
-	   old memory can be recycled */
-	make_lowmem_page_readwrite(xen_initial_gdt);
-
 	xen_filter_cpu_maps();
 	xen_setup_vcpu_info_placement();
 }
@@ -290,12 +285,12 @@ cpu_initialize_context(unsigned int cpu,
 	gdt = get_cpu_gdt_table(cpu);
 
 	ctxt->flags = VGCF_IN_KERNEL;
-	ctxt->user_regs.ds = __USER_DS;
-	ctxt->user_regs.es = __USER_DS;
+	ctxt->user_regs.ds = __KERNEL_DS;
+	ctxt->user_regs.es = __KERNEL_DS;
 	ctxt->user_regs.ss = __KERNEL_DS;
 #ifdef CONFIG_X86_32
 	ctxt->user_regs.fs = __KERNEL_PERCPU;
-	ctxt->user_regs.gs = __KERNEL_STACK_CANARY;
+	savesegment(gs, ctxt->user_regs.gs);
 #else
 	ctxt->gs_base_kernel = per_cpu_offset(cpu);
 #endif
@@ -346,13 +341,12 @@ static int __cpuinit xen_cpu_up(unsigned
 	int rc;
 
 	per_cpu(current_task, cpu) = idle;
+	per_cpu(current_tinfo, cpu) = &idle->tinfo;
 #ifdef CONFIG_X86_32
 	irq_ctx_init(cpu);
 #else
 	clear_tsk_thread_flag(idle, TIF_FORK);
-	per_cpu(kernel_stack, cpu) =
-		(unsigned long)task_stack_page(idle) -
-		KERNEL_STACK_OFFSET + THREAD_SIZE;
+	per_cpu(kernel_stack, cpu) = (unsigned long)task_stack_page(idle) - 16 + THREAD_SIZE;
 #endif
 	xen_setup_runstate_info(cpu);
 	xen_setup_timer(cpu);
@@ -536,7 +530,7 @@ static const struct smp_ops xen_smp_ops
 
 void __init xen_smp_init(void)
 {
-	smp_ops = xen_smp_ops;
+	memcpy((void *)&smp_ops, &xen_smp_ops, sizeof smp_ops);
 	xen_fill_possible_map();
 	xen_init_spinlocks();
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/xen/xen-asm_32.S linux-3.2.71-pax/arch/x86/xen/xen-asm_32.S
--- linux-3.2.71/arch/x86/xen/xen-asm_32.S	2013-02-20 12:30:42.036171944 +0100
+++ linux-3.2.71-pax/arch/x86/xen/xen-asm_32.S	2013-02-20 12:34:37.124159392 +0100
@@ -83,14 +83,14 @@ ENTRY(xen_iret)
 	ESP_OFFSET=4	# bytes pushed onto stack
 
 	/*
-	 * Store vcpu_info pointer for easy access.  Do it this way to
-	 * avoid having to reload %fs
+	 * Store vcpu_info pointer for easy access.
 	 */
 #ifdef CONFIG_SMP
-	GET_THREAD_INFO(%eax)
-	movl %ss:TI_cpu(%eax), %eax
-	movl %ss:__per_cpu_offset(,%eax,4), %eax
-	mov %ss:xen_vcpu(%eax), %eax
+	push %fs
+	mov $(__KERNEL_PERCPU), %eax
+	mov %eax, %fs
+	mov PER_CPU_VAR(xen_vcpu), %eax
+	pop %fs
 #else
 	movl %ss:xen_vcpu, %eax
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/xen/xen-head.S linux-3.2.71-pax/arch/x86/xen/xen-head.S
--- linux-3.2.71/arch/x86/xen/xen-head.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/xen/xen-head.S	2012-07-04 19:24:47.660063005 +0200
@@ -19,6 +19,17 @@ ENTRY(startup_xen)
 #ifdef CONFIG_X86_32
 	mov %esi,xen_start_info
 	mov $init_thread_union+THREAD_SIZE,%esp
+#ifdef CONFIG_SMP
+	movl $cpu_gdt_table,%edi
+	movl $__per_cpu_load,%eax
+	movw %ax,__KERNEL_PERCPU + 2(%edi)
+	rorl $16,%eax
+	movb %al,__KERNEL_PERCPU + 4(%edi)
+	movb %ah,__KERNEL_PERCPU + 7(%edi)
+	movl $__per_cpu_end - 1,%eax
+	subl $__per_cpu_start,%eax
+	movw %ax,__KERNEL_PERCPU + 0(%edi)
+#endif
 #else
 	mov %rsi,xen_start_info
 	mov $init_thread_union+THREAD_SIZE,%rsp
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/arch/x86/xen/xen-ops.h linux-3.2.71-pax/arch/x86/xen/xen-ops.h
--- linux-3.2.71/arch/x86/xen/xen-ops.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/arch/x86/xen/xen-ops.h	2012-07-04 19:24:47.664063005 +0200
@@ -10,8 +10,6 @@
 extern const char xen_hypervisor_callback[];
 extern const char xen_failsafe_callback[];
 
-extern void *xen_initial_gdt;
-
 struct trap_info;
 void xen_copy_trap_info(struct trap_info *traps);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/block/blk-iopoll.c linux-3.2.71-pax/block/blk-iopoll.c
--- linux-3.2.71/block/blk-iopoll.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/block/blk-iopoll.c	2013-09-27 19:55:59.940207777 +0200
@@ -77,7 +77,7 @@ void blk_iopoll_complete(struct blk_iopo
 }
 EXPORT_SYMBOL(blk_iopoll_complete);
 
-static void blk_iopoll_softirq(struct softirq_action *h)
+static __latent_entropy void blk_iopoll_softirq(void)
 {
 	struct list_head *list = &__get_cpu_var(blk_cpu_iopoll);
 	int rearm = 0, budget = blk_iopoll_budget;
@@ -209,7 +209,7 @@ static int __cpuinit blk_iopoll_cpu_noti
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata blk_iopoll_cpu_notifier = {
+static struct notifier_block blk_iopoll_cpu_notifier = {
 	.notifier_call	= blk_iopoll_cpu_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/block/blk-map.c linux-3.2.71-pax/block/blk-map.c
--- linux-3.2.71/block/blk-map.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/block/blk-map.c	2012-07-04 19:24:47.664063005 +0200
@@ -302,7 +302,7 @@ int blk_rq_map_kern(struct request_queue
 	if (!len || !kbuf)
 		return -EINVAL;
 
-	do_copy = !blk_rq_aligned(q, addr, len) || object_is_on_stack(kbuf);
+	do_copy = !blk_rq_aligned(q, addr, len) || object_starts_on_stack(kbuf);
 	if (do_copy)
 		bio = bio_copy_kern(q, kbuf, len, gfp_mask, reading);
 	else
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/block/blk-softirq.c linux-3.2.71-pax/block/blk-softirq.c
--- linux-3.2.71/block/blk-softirq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/block/blk-softirq.c	2013-09-27 19:55:53.260208133 +0200
@@ -17,7 +17,7 @@ static DEFINE_PER_CPU(struct list_head,
  * Softirq action handler - move entries to local list and loop over them
  * while passing them to the queue registered handler.
  */
-static void blk_done_softirq(struct softirq_action *h)
+static __latent_entropy void blk_done_softirq(void)
 {
 	struct list_head *cpu_list, local_list;
 
@@ -97,7 +97,7 @@ static int __cpuinit blk_cpu_notify(stru
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata blk_cpu_notifier = {
+static struct notifier_block blk_cpu_notifier = {
 	.notifier_call	= blk_cpu_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/block/bsg.c linux-3.2.71-pax/block/bsg.c
--- linux-3.2.71/block/bsg.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/block/bsg.c	2012-07-04 19:24:47.664063005 +0200
@@ -176,16 +176,24 @@ static int blk_fill_sgv4_hdr_rq(struct r
 				struct sg_io_v4 *hdr, struct bsg_device *bd,
 				fmode_t has_write_perm)
 {
+	unsigned char tmpcmd[sizeof(rq->__cmd)];
+	unsigned char *cmdptr;
+
 	if (hdr->request_len > BLK_MAX_CDB) {
 		rq->cmd = kzalloc(hdr->request_len, GFP_KERNEL);
 		if (!rq->cmd)
 			return -ENOMEM;
-	}
+		cmdptr = rq->cmd;
+	} else
+		cmdptr = tmpcmd;
 
-	if (copy_from_user(rq->cmd, (void __user *)(unsigned long)hdr->request,
+	if (copy_from_user(cmdptr, (void __user *)(unsigned long)hdr->request,
 			   hdr->request_len))
 		return -EFAULT;
 
+	if (cmdptr != rq->cmd)
+		memcpy(rq->cmd, cmdptr, hdr->request_len);
+
 	if (hdr->subprotocol == BSG_SUB_PROTOCOL_SCSI_CMD) {
 		if (blk_verify_command(rq->cmd, has_write_perm))
 			return -EPERM;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/block/compat_ioctl.c linux-3.2.71-pax/block/compat_ioctl.c
--- linux-3.2.71/block/compat_ioctl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/block/compat_ioctl.c	2014-01-28 04:21:56.121073862 +0100
@@ -155,7 +155,7 @@ static int compat_cdrom_generic_command(
 	cgc = compat_alloc_user_space(sizeof(*cgc));
 	cgc32 = compat_ptr(arg);
 
-	if (copy_in_user(&cgc->cmd, &cgc32->cmd, sizeof(cgc->cmd)) ||
+	if (copy_in_user(cgc->cmd, cgc32->cmd, sizeof(cgc->cmd)) ||
 	    get_user(data, &cgc32->buffer) ||
 	    put_user(compat_ptr(data), &cgc->buffer) ||
 	    copy_in_user(&cgc->buflen, &cgc32->buflen,
@@ -340,7 +340,7 @@ static int compat_fd_ioctl(struct block_
 		err |= __get_user(f->spec1, &uf->spec1);
 		err |= __get_user(f->fmt_gap, &uf->fmt_gap);
 		err |= __get_user(name, &uf->name);
-		f->name = compat_ptr(name);
+		f->name = (void __force_kernel *)compat_ptr(name);
 		if (err) {
 			err = -EFAULT;
 			goto out;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/block/genhd.c linux-3.2.71-pax/block/genhd.c
--- linux-3.2.71/block/genhd.c	2015-02-20 12:37:32.993178781 +0100
+++ linux-3.2.71-pax/block/genhd.c	2015-02-20 12:37:41.833178309 +0100
@@ -472,21 +472,24 @@ static char *bdevt_str(dev_t devt, char
 
 /*
  * Register device numbers dev..(dev+range-1)
- * range must be nonzero
+ * Noop if @range is zero.
  * The hash chain is sorted on range, so that subranges can override.
  */
 void blk_register_region(dev_t devt, unsigned long range, struct module *module,
 			 struct kobject *(*probe)(dev_t, int *, void *),
 			 int (*lock)(dev_t, void *), void *data)
 {
-	kobj_map(bdev_map, devt, range, module, probe, lock, data);
+	if (range)
+		kobj_map(bdev_map, devt, range, module, probe, lock, data);
 }
 
 EXPORT_SYMBOL(blk_register_region);
 
+/* undo blk_register_region(), noop if @range is zero */
 void blk_unregister_region(dev_t devt, unsigned long range)
 {
-	kobj_unmap(bdev_map, devt, range);
+	if (range)
+		kobj_unmap(bdev_map, devt, range);
 }
 
 EXPORT_SYMBOL(blk_unregister_region);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/block/scsi_ioctl.c linux-3.2.71-pax/block/scsi_ioctl.c
--- linux-3.2.71/block/scsi_ioctl.c	2014-12-14 21:13:45.018054736 +0100
+++ linux-3.2.71-pax/block/scsi_ioctl.c	2014-12-14 21:13:52.766069210 +0100
@@ -66,7 +66,7 @@ static int scsi_get_bus(struct request_q
 	return put_user(0, p);
 }
 
-static int sg_get_timeout(struct request_queue *q)
+static int __intentional_overflow(-1) sg_get_timeout(struct request_queue *q)
 {
 	return jiffies_to_clock_t(q->sg_timeout);
 }
@@ -223,8 +223,20 @@ EXPORT_SYMBOL(blk_verify_command);
 static int blk_fill_sghdr_rq(struct request_queue *q, struct request *rq,
 			     struct sg_io_hdr *hdr, fmode_t mode)
 {
-	if (copy_from_user(rq->cmd, hdr->cmdp, hdr->cmd_len))
+	unsigned char tmpcmd[sizeof(rq->__cmd)];
+	unsigned char *cmdptr;
+
+	if (rq->cmd != rq->__cmd)
+		cmdptr = rq->cmd;
+	else
+		cmdptr = tmpcmd;
+
+	if (copy_from_user(cmdptr, hdr->cmdp, hdr->cmd_len))
 		return -EFAULT;
+
+	if (cmdptr != rq->cmd)
+		memcpy(rq->cmd, cmdptr, hdr->cmd_len);
+
 	if (blk_verify_command(rq->cmd, mode & FMODE_WRITE))
 		return -EPERM;
 
@@ -433,6 +445,8 @@ int sg_scsi_ioctl(struct request_queue *
 	int err;
 	unsigned int in_len, out_len, bytes, opcode, cmdlen;
 	char *buffer = NULL, sense[SCSI_SENSE_BUFFERSIZE];
+	unsigned char tmpcmd[sizeof(rq->__cmd)];
+	unsigned char *cmdptr;
 
 	if (!sic)
 		return -EINVAL;
@@ -466,9 +480,18 @@ int sg_scsi_ioctl(struct request_queue *
 	 */
 	err = -EFAULT;
 	rq->cmd_len = cmdlen;
-	if (copy_from_user(rq->cmd, sic->data, cmdlen))
+
+	if (rq->cmd != rq->__cmd)
+		cmdptr = rq->cmd;
+	else
+		cmdptr = tmpcmd;
+
+	if (copy_from_user(cmdptr, sic->data, cmdlen))
 		goto error;
 
+	if (rq->cmd != cmdptr)
+		memcpy(rq->cmd, cmdptr, cmdlen);
+
 	if (in_len && copy_from_user(buffer, sic->data + cmdlen, in_len))
 		goto error;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/crypto/cryptd.c linux-3.2.71-pax/crypto/cryptd.c
--- linux-3.2.71/crypto/cryptd.c	2015-02-20 12:37:32.997178780 +0100
+++ linux-3.2.71-pax/crypto/cryptd.c	2015-02-20 12:37:41.841178308 +0100
@@ -63,7 +63,7 @@ struct cryptd_blkcipher_ctx {
 
 struct cryptd_blkcipher_request_ctx {
 	crypto_completion_t complete;
-};
+} __no_const;
 
 struct cryptd_hash_ctx {
 	struct crypto_shash *child;
@@ -80,7 +80,7 @@ struct cryptd_aead_ctx {
 
 struct cryptd_aead_request_ctx {
 	crypto_completion_t complete;
-};
+} __no_const;
 
 static void cryptd_queue_worker(struct work_struct *work);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/crypto/pcrypt.c linux-3.2.71-pax/crypto/pcrypt.c
--- linux-3.2.71/crypto/pcrypt.c	2015-02-20 12:37:33.013178779 +0100
+++ linux-3.2.71-pax/crypto/pcrypt.c	2015-02-20 12:37:41.849178308 +0100
@@ -440,7 +440,7 @@ static int pcrypt_sysfs_add(struct padat
 	int ret;
 
 	pinst->kobj.kset = pcrypt_kset;
-	ret = kobject_add(&pinst->kobj, NULL, name);
+	ret = kobject_add(&pinst->kobj, NULL, "%s", name);
 	if (!ret)
 		kobject_uevent(&pinst->kobj, KOBJ_ADD);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/crypto/zlib.c linux-3.2.71-pax/crypto/zlib.c
--- linux-3.2.71/crypto/zlib.c	2015-02-20 12:37:33.017178779 +0100
+++ linux-3.2.71-pax/crypto/zlib.c	2015-04-30 02:44:19.412491262 +0200
@@ -95,10 +95,10 @@ static int zlib_compress_setup(struct cr
 	zlib_comp_exit(ctx);
 
 	window_bits = tb[ZLIB_COMP_WINDOWBITS]
-					? nla_get_u32(tb[ZLIB_COMP_WINDOWBITS])
+					? nla_get_s32(tb[ZLIB_COMP_WINDOWBITS])
 					: MAX_WBITS;
 	mem_level = tb[ZLIB_COMP_MEMLEVEL]
-					? nla_get_u32(tb[ZLIB_COMP_MEMLEVEL])
+					? nla_get_s32(tb[ZLIB_COMP_MEMLEVEL])
 					: DEF_MEM_LEVEL;
 
 	workspacesize = zlib_deflate_workspacesize(window_bits, mem_level);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/Documentation/dontdiff linux-3.2.71-pax/Documentation/dontdiff
--- linux-3.2.71/Documentation/dontdiff	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/Documentation/dontdiff	2013-06-21 20:15:56.158564327 +0200
@@ -2,9 +2,11 @@
 *.aux
 *.bin
 *.bz2
+*.c.[012]*.*
 *.cis
 *.cpio
 *.csp
+*.dbg
 *.dsp
 *.dvi
 *.elf
@@ -14,6 +16,7 @@
 *.gcov
 *.gen.S
 *.gif
+*.gmo
 *.grep
 *.grp
 *.gz
@@ -48,14 +51,17 @@
 *.tab.h
 *.tex
 *.ver
+*.vim
 *.xml
 *.xz
 *_MODULES
+*_reg_safe.h
 *_vga16.c
 *~
 \#*#
 *.9
-.*
+.[^g]*
+.gen*
 .*.d
 .mm
 53c700_d.h
@@ -70,9 +76,11 @@ Kerntypes
 Module.markers
 Module.symvers
 PENDING
+PERF*
 SCCS
 System.map*
 TAGS
+TRACEEVENT-CFLAGS
 aconf
 af_names.h
 aic7*reg.h*
@@ -81,6 +89,7 @@ aic7*seq.h*
 aicasm
 aicdb.h*
 altivec*.c
+ashldi3.S
 asm-offsets.h
 asm_offsets.h
 autoconf.h*
@@ -93,19 +102,24 @@ bounds.h
 bsetup
 btfixupprep
 build
+builtin-policy.h
 bvmlinux
 bzImage*
 capability_names.h
 capflags.c
 classlist.h*
+clut_vga16.c
+common-cmds.h
 comp*.log
 compile.h*
 conf
 config
 config-*
 config_data.h*
+config.c
 config.mak
 config.mak.autogen
+config.tmp
 conmakehash
 consolemap_deftbl.c*
 cpustr.h
@@ -116,9 +130,11 @@ devlist.h*
 dnotify_test
 docproc
 dslm
+dtc-lexer.lex.c
 elf2ecoff
 elfconfig.h*
 evergreen_reg_safe.h
+exception_policy.conf
 fixdep
 flask.h
 fore200e_mkfirm
@@ -126,12 +142,15 @@ fore200e_pca_fw.c*
 gconf
 gconf.glade.h
 gen-devlist
+gen-kdb_cmds.c
 gen_crc32table
 gen_init_cpio
 generated
 genheaders
 genksyms
 *_gray256.c
+hash
+hid-example
 hpet_example
 hugepage-mmap
 hugepage-shm
@@ -146,7 +165,7 @@ int32.c
 int4.c
 int8.c
 kallsyms
-kconfig
+kern_constants.h
 keywords.c
 ksym.c*
 ksym.h*
@@ -154,7 +173,7 @@ kxgettext
 lkc_defs.h
 lex.c
 lex.*.c
-linux
+lib1funcs.S
 logo_*.c
 logo_*_clut224.c
 logo_*_mono.c
@@ -166,14 +185,15 @@ machtypes.h
 map
 map_hugetlb
 maui_boot.h
-media
 mconf
+mdp
 miboot*
 mk_elfconfig
 mkboot
 mkbugboot
 mkcpustr
 mkdep
+mkpiggy
 mkprep
 mkregtable
 mktables
@@ -209,6 +229,7 @@ r300_reg_safe.h
 r420_reg_safe.h
 r600_reg_safe.h
 recordmcount
+regdb.c
 relocs
 rlim_names.h
 rn50_reg_safe.h
@@ -218,7 +239,10 @@ series
 setup
 setup.bin
 setup.elf
+signing_key*
+size_overflow_hash.h
 sImage
+slabinfo
 sm_tbl*
 split-include
 syscalltab.h
@@ -229,6 +253,7 @@ tftpboot.img
 timeconst.h
 times.h*
 trix_boot.h
+user_constants.h
 utsrelease.h*
 vdso-syms.lds
 vdso.lds
@@ -246,7 +271,9 @@ vmlinux
 vmlinux-*
 vmlinux.aout
 vmlinux.bin.all
+vmlinux.bin.bz2
 vmlinux.lds
+vmlinux.relocs
 vmlinuz
 voffset.h
 vsyscall.lds
@@ -254,9 +281,12 @@ vsyscall_32.lds
 wanxlfw.inc
 uImage
 unifdef
+utsrelease.h
 wakeup.bin
 wakeup.elf
 wakeup.lds
+x509*
 zImage*
 zconf.hash.c
+zconf.lex.c
 zoffset.h
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/Documentation/kernel-parameters.txt linux-3.2.71-pax/Documentation/kernel-parameters.txt
--- linux-3.2.71/Documentation/kernel-parameters.txt	2015-02-20 12:37:32.797178791 +0100
+++ linux-3.2.71-pax/Documentation/kernel-parameters.txt	2015-02-20 12:37:41.805178310 +0100
@@ -1963,6 +1963,27 @@ bytes respectively. Such letter suffixes
 			the specified number of seconds.  This is to be used if
 			your oopses keep scrolling off the screen.
 
+	pax_nouderef	[X86] disables UDEREF.  Most likely needed under certain
+			virtualization environments that don't cope well with the
+			expand down segment used by UDEREF on X86-32 or the frequent
+			page table updates on X86-64.
+
+	pax_sanitize_slab=
+			Format: { 0 | 1 | off | fast | full }
+			Options '0' and '1' are only provided for backward
+			compatibility, 'off' or 'fast' should be used instead.
+			0|off : disable slab object sanitization
+			1|fast: enable slab object sanitization excluding
+				whitelisted slabs (default)
+			full  : sanitize all slabs, even the whitelisted ones
+
+	pax_softmode=	0/1 to disable/enable PaX softmode on boot already.
+
+	pax_extra_latent_entropy
+			Enable a very simple form of latent entropy extraction
+			from the first 4GB of memory as the bootmem allocator
+			passes the memory pages to the buddy allocator.
+
 	pcbit=		[HW,ISDN]
 
 	pcd.		[PARIDE]
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/apei/apei-internal.h linux-3.2.71-pax/drivers/acpi/apei/apei-internal.h
--- linux-3.2.71/drivers/acpi/apei/apei-internal.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/acpi/apei/apei-internal.h	2013-03-28 01:35:23.248427951 +0100
@@ -18,7 +18,7 @@ typedef int (*apei_exec_ins_func_t)(stru
 struct apei_exec_ins_type {
 	u32 flags;
 	apei_exec_ins_func_t run;
-};
+} __do_const;
 
 struct apei_exec_context {
 	u32 ip;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/apei/cper.c linux-3.2.71-pax/drivers/acpi/apei/cper.c
--- linux-3.2.71/drivers/acpi/apei/cper.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/acpi/apei/cper.c	2012-07-04 19:24:47.672063004 +0200
@@ -38,12 +38,12 @@
  */
 u64 cper_next_record_id(void)
 {
-	static atomic64_t seq;
+	static atomic64_unchecked_t seq;
 
-	if (!atomic64_read(&seq))
-		atomic64_set(&seq, ((u64)get_seconds()) << 32);
+	if (!atomic64_read_unchecked(&seq))
+		atomic64_set_unchecked(&seq, ((u64)get_seconds()) << 32);
 
-	return atomic64_inc_return(&seq);
+	return atomic64_inc_return_unchecked(&seq);
 }
 EXPORT_SYMBOL_GPL(cper_next_record_id);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/blacklist.c linux-3.2.71-pax/drivers/acpi/blacklist.c
--- linux-3.2.71/drivers/acpi/blacklist.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/acpi/blacklist.c	2013-03-28 04:34:45.191853346 +0100
@@ -52,7 +52,7 @@ struct acpi_blacklist_item {
 	u32 is_critical_error;
 };
 
-static struct dmi_system_id acpi_osi_dmi_table[] __initdata;
+static const struct dmi_system_id acpi_osi_dmi_table[] __initconst;
 
 /*
  * POLICY: If *anything* doesn't work, put it on the blacklist.
@@ -193,7 +193,7 @@ static int __init dmi_disable_osi_win7(c
 	return 0;
 }
 
-static struct dmi_system_id acpi_osi_dmi_table[] __initdata = {
+static const struct dmi_system_id acpi_osi_dmi_table[] __initconst = {
 	{
 	.callback = dmi_disable_osi_vista,
 	.ident = "Fujitsu Siemens",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/bus.c linux-3.2.71-pax/drivers/acpi/bus.c
--- linux-3.2.71/drivers/acpi/bus.c	2014-07-12 17:42:33.748954216 +0200
+++ linux-3.2.71-pax/drivers/acpi/bus.c	2015-04-30 03:07:38.400532395 +0200
@@ -72,7 +72,7 @@ static int set_copy_dsdt(const struct dm
 }
 #endif
 
-static struct dmi_system_id dsdt_dmi_table[] __initdata = {
+static const struct dmi_system_id dsdt_dmi_table[] __initconst = {
 	/*
 	 * Invoke DSDT corruption work-around on all Toshiba Satellite.
 	 * https://bugzilla.kernel.org/show_bug.cgi?id=14679
@@ -88,7 +88,7 @@ static struct dmi_system_id dsdt_dmi_tab
 	{}
 };
 #else
-static struct dmi_system_id dsdt_dmi_table[] __initdata = {
+static const struct dmi_system_id dsdt_dmi_table[] __initconst = {
 	{}
 };
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/ec.c linux-3.2.71-pax/drivers/acpi/ec.c
--- linux-3.2.71/drivers/acpi/ec.c	2015-02-20 12:37:33.017178779 +0100
+++ linux-3.2.71-pax/drivers/acpi/ec.c	2015-04-30 03:09:22.244535448 +0200
@@ -1018,7 +1018,7 @@ static int ec_clear_on_resume(const stru
 	return 0;
 }
 
-static struct dmi_system_id __initdata ec_dmi_table[] = {
+static const struct dmi_system_id __initconst ec_dmi_table[] = {
 	{
 	ec_skip_dsdt_scan, "Compal JFL92", {
 	DMI_MATCH(DMI_BIOS_VENDOR, "COMPAL"),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/ec_sys.c linux-3.2.71-pax/drivers/acpi/ec_sys.c
--- linux-3.2.71/drivers/acpi/ec_sys.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/acpi/ec_sys.c	2012-07-04 19:24:47.672063004 +0200
@@ -12,6 +12,7 @@
 #include <linux/acpi.h>
 #include <linux/debugfs.h>
 #include <linux/module.h>
+#include <linux/uaccess.h>
 #include "internal.h"
 
 MODULE_AUTHOR("Thomas Renninger <trenn@suse.de>");
@@ -40,7 +41,7 @@ static ssize_t acpi_ec_read_io(struct fi
 	 * struct acpi_ec *ec = ((struct seq_file *)f->private_data)->private;
 	 */
 	unsigned int size = EC_SPACE_SIZE;
-	u8 *data = (u8 *) buf;
+	u8 data;
 	loff_t init_off = *off;
 	int err = 0;
 
@@ -53,9 +54,11 @@ static ssize_t acpi_ec_read_io(struct fi
 		size = count;
 
 	while (size) {
-		err = ec_read(*off, &data[*off - init_off]);
+		err = ec_read(*off, &data);
 		if (err)
 			return err;
+		if (put_user(data, &buf[*off - init_off]))
+			return -EFAULT;
 		*off += 1;
 		size--;
 	}
@@ -71,7 +74,6 @@ static ssize_t acpi_ec_write_io(struct f
 
 	unsigned int size = count;
 	loff_t init_off = *off;
-	u8 *data = (u8 *) buf;
 	int err = 0;
 
 	if (*off >= EC_SPACE_SIZE)
@@ -82,7 +84,9 @@ static ssize_t acpi_ec_write_io(struct f
 	}
 
 	while (size) {
-		u8 byte_write = data[*off - init_off];
+		u8 byte_write;
+		if (get_user(byte_write, &buf[*off - init_off]))
+			return -EFAULT;
 		err = ec_write(*off, byte_write);
 		if (err)
 			return err;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/pci_slot.c linux-3.2.71-pax/drivers/acpi/pci_slot.c
--- linux-3.2.71/drivers/acpi/pci_slot.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/acpi/pci_slot.c	2015-04-30 03:07:38.400532395 +0200
@@ -336,7 +336,7 @@ static int do_sta_before_sun(const struc
 	return 0;
 }
 
-static struct dmi_system_id acpi_pci_slot_dmi_table[] __initdata = {
+static const struct dmi_system_id acpi_pci_slot_dmi_table[] __initconst = {
 	/*
 	 * Fujitsu Primequest machines will return 1023 to indicate an
 	 * error if the _SUN method is evaluated on SxFy objects that
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/proc.c linux-3.2.71-pax/drivers/acpi/proc.c
--- linux-3.2.71/drivers/acpi/proc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/acpi/proc.c	2013-02-09 00:44:33.724732684 +0100
@@ -345,16 +345,13 @@ acpi_system_write_wakeup_device(struct f
 	struct list_head *node, *next;
 	char strbuf[5];
 	char str[5] = "";
-	unsigned int len = count;
 
-	if (len > 4)
-		len = 4;
-	if (len < 0)
-		return -EFAULT;
+	if (count > 4)
+		count = 4;
 
-	if (copy_from_user(strbuf, buffer, len))
+	if (copy_from_user(strbuf, buffer, count))
 		return -EFAULT;
-	strbuf[len] = '\0';
+	strbuf[count] = '\0';
 	sscanf(strbuf, "%s", str);
 
 	mutex_lock(&acpi_device_lock);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/processor_core.c linux-3.2.71-pax/drivers/acpi/processor_core.c
--- linux-3.2.71/drivers/acpi/processor_core.c	2012-07-27 22:08:37.306372788 +0200
+++ linux-3.2.71-pax/drivers/acpi/processor_core.c	2015-04-30 03:08:26.404533806 +0200
@@ -28,7 +28,7 @@ static int __init set_no_mwait(const str
 	return 0;
 }
 
-static struct dmi_system_id __initdata processor_idle_dmi_table[] = {
+static const struct dmi_system_id __initconst processor_idle_dmi_table[] = {
 	{
 	set_no_mwait, "Extensa 5220", {
 	DMI_MATCH(DMI_BIOS_VENDOR, "Phoenix Technologies LTD"),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/processor_driver.c linux-3.2.71-pax/drivers/acpi/processor_driver.c
--- linux-3.2.71/drivers/acpi/processor_driver.c	2013-01-03 19:05:12.816036805 +0100
+++ linux-3.2.71-pax/drivers/acpi/processor_driver.c	2013-01-03 19:05:22.044037076 +0100
@@ -474,7 +474,7 @@ static int __cpuinit acpi_processor_add(
 		return 0;
 #endif
 
-	BUG_ON((pr->id >= nr_cpu_ids) || (pr->id < 0));
+	BUG_ON(pr->id >= nr_cpu_ids);
 
 	/*
 	 * Buggy BIOS check
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/processor_idle.c linux-3.2.71-pax/drivers/acpi/processor_idle.c
--- linux-3.2.71/drivers/acpi/processor_idle.c	2014-11-05 23:20:29.985389708 +0100
+++ linux-3.2.71-pax/drivers/acpi/processor_idle.c	2014-11-05 23:20:50.477398804 +0100
@@ -1036,7 +1036,7 @@ static int acpi_processor_setup_cpuidle_
 {
 	int i, count = CPUIDLE_DRIVER_STATE_START;
 	struct acpi_processor_cx *cx;
-	struct cpuidle_state *state;
+	cpuidle_state_no_const *state;
 	struct cpuidle_driver *drv = &acpi_idle_driver;
 
 	if (!pr->flags.power_setup_done)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/sleep.c linux-3.2.71-pax/drivers/acpi/sleep.c
--- linux-3.2.71/drivers/acpi/sleep.c	2013-03-29 02:18:30.067676744 +0100
+++ linux-3.2.71-pax/drivers/acpi/sleep.c	2015-04-30 03:08:55.432534660 +0200
@@ -120,7 +120,7 @@ static int __init init_nvs_nosave(const
 	return 0;
 }
 
-static struct dmi_system_id __initdata acpisleep_dmi_table[] = {
+static const struct dmi_system_id __initconst acpisleep_dmi_table[] = {
 	{
 	.callback = init_old_suspend_ordering,
 	.ident = "Abit KN9 (nForce4 variant)",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/sysfs.c linux-3.2.71-pax/drivers/acpi/sysfs.c
--- linux-3.2.71/drivers/acpi/sysfs.c	2012-07-27 22:08:37.694372798 +0200
+++ linux-3.2.71-pax/drivers/acpi/sysfs.c	2013-03-28 01:35:23.252427951 +0100
@@ -420,11 +420,11 @@ static u32 num_counters;
 static struct attribute **all_attrs;
 static u32 acpi_gpe_count;
 
-static struct attribute_group interrupt_stats_attr_group = {
+static attribute_group_no_const interrupt_stats_attr_group = {
 	.name = "interrupts",
 };
 
-static struct kobj_attribute *counter_attrs;
+static kobj_attribute_no_const *counter_attrs;
 
 static void delete_gpe_attr_array(void)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/thermal.c linux-3.2.71-pax/drivers/acpi/thermal.c
--- linux-3.2.71/drivers/acpi/thermal.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/acpi/thermal.c	2015-04-30 03:07:38.400532395 +0200
@@ -1110,7 +1110,7 @@ static int thermal_psv(const struct dmi_
 	return 0;
 }
 
-static struct dmi_system_id thermal_dmi_table[] __initdata = {
+static const struct dmi_system_id thermal_dmi_table[] __initconst = {
 	/*
 	 * Award BIOS on this AOpen makes thermal control almost worthless.
 	 * http://bugzilla.kernel.org/show_bug.cgi?id=8842
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/acpi/video.c linux-3.2.71-pax/drivers/acpi/video.c
--- linux-3.2.71/drivers/acpi/video.c	2015-05-10 09:22:36.759493013 +0200
+++ linux-3.2.71-pax/drivers/acpi/video.c	2015-05-10 09:23:08.939494761 +0200
@@ -395,7 +395,7 @@ static int video_ignore_initial_backligh
 	return 0;
 }
 
-static struct dmi_system_id video_dmi_table[] __initdata = {
+static const struct dmi_system_id video_dmi_table[] __initconst = {
 	/*
 	 * Broken _BQC workaround http://bugzilla.kernel.org/show_bug.cgi?id=13121
 	 */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ata/libahci.c linux-3.2.71-pax/drivers/ata/libahci.c
--- linux-3.2.71/drivers/ata/libahci.c	2015-08-07 11:37:20.423789889 +0200
+++ linux-3.2.71-pax/drivers/ata/libahci.c	2015-08-07 11:37:42.999790553 +0200
@@ -1212,7 +1212,7 @@ int ahci_kick_engine(struct ata_port *ap
 }
 EXPORT_SYMBOL_GPL(ahci_kick_engine);
 
-static int ahci_exec_polled_cmd(struct ata_port *ap, int pmp,
+static int __intentional_overflow(-1) ahci_exec_polled_cmd(struct ata_port *ap, int pmp,
 				struct ata_taskfile *tf, int is_cmd, u16 flags,
 				unsigned long timeout_msec)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ata/libata-core.c linux-3.2.71-pax/drivers/ata/libata-core.c
--- linux-3.2.71/drivers/ata/libata-core.c	2015-08-14 21:48:35.068707926 +0200
+++ linux-3.2.71-pax/drivers/ata/libata-core.c	2015-08-14 21:48:45.548707366 +0200
@@ -4795,7 +4795,7 @@ void ata_qc_free(struct ata_queued_cmd *
 	struct ata_port *ap;
 	unsigned int tag;
 
-	WARN_ON_ONCE(qc == NULL); /* ata_qc_from_tag _might_ return NULL */
+	BUG_ON(qc == NULL); /* ata_qc_from_tag _might_ return NULL */
 	ap = qc->ap;
 
 	qc->flags = 0;
@@ -4811,7 +4811,7 @@ void __ata_qc_complete(struct ata_queued
 	struct ata_port *ap;
 	struct ata_link *link;
 
-	WARN_ON_ONCE(qc == NULL); /* ata_qc_from_tag _might_ return NULL */
+	BUG_ON(qc == NULL); /* ata_qc_from_tag _might_ return NULL */
 	WARN_ON_ONCE(!(qc->flags & ATA_QCFLAG_ACTIVE));
 	ap = qc->ap;
 	link = qc->dev->link;
@@ -5816,6 +5816,7 @@ static void ata_finalize_port_ops(struct
 		return;
 
 	spin_lock(&lock);
+	pax_open_kernel();
 
 	for (cur = ops->inherits; cur; cur = cur->inherits) {
 		void **inherit = (void **)cur;
@@ -5829,8 +5830,9 @@ static void ata_finalize_port_ops(struct
 		if (IS_ERR(*pp))
 			*pp = NULL;
 
-	ops->inherits = NULL;
+	*(struct ata_port_operations **)&ops->inherits = NULL;
 
+	pax_close_kernel();
 	spin_unlock(&lock);
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ata/pata_arasan_cf.c linux-3.2.71-pax/drivers/ata/pata_arasan_cf.c
--- linux-3.2.71/drivers/ata/pata_arasan_cf.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ata/pata_arasan_cf.c	2012-07-04 19:24:47.676063005 +0200
@@ -862,7 +862,9 @@ static int __devinit arasan_cf_probe(str
 	/* Handle platform specific quirks */
 	if (pdata->quirk) {
 		if (pdata->quirk & CF_BROKEN_PIO) {
-			ap->ops->set_piomode = NULL;
+			pax_open_kernel();
+			*(void **)&ap->ops->set_piomode = NULL;
+			pax_close_kernel();
 			ap->pio_mask = 0;
 		}
 		if (pdata->quirk & CF_BROKEN_MWDMA)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/adummy.c linux-3.2.71-pax/drivers/atm/adummy.c
--- linux-3.2.71/drivers/atm/adummy.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/atm/adummy.c	2012-07-04 19:24:47.676063005 +0200
@@ -114,7 +114,7 @@ adummy_send(struct atm_vcc *vcc, struct
 		vcc->pop(vcc, skb);
 	else
 		dev_kfree_skb_any(skb);
-	atomic_inc(&vcc->stats->tx);
+	atomic_inc_unchecked(&vcc->stats->tx);
 
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/ambassador.c linux-3.2.71-pax/drivers/atm/ambassador.c
--- linux-3.2.71/drivers/atm/ambassador.c	2014-06-10 10:59:38.750436245 +0200
+++ linux-3.2.71-pax/drivers/atm/ambassador.c	2014-06-10 10:59:44.134435957 +0200
@@ -454,7 +454,7 @@ static void tx_complete (amb_dev * dev,
   PRINTD (DBG_FLOW|DBG_TX, "tx_complete %p %p", dev, tx);
   
   // VC layer stats
-  atomic_inc(&ATM_SKB(skb)->vcc->stats->tx);
+  atomic_inc_unchecked(&ATM_SKB(skb)->vcc->stats->tx);
   
   // free the descriptor
   kfree (tx_descr);
@@ -495,7 +495,7 @@ static void rx_complete (amb_dev * dev,
 	  dump_skb ("<<<", vc, skb);
 	  
 	  // VC layer stats
-	  atomic_inc(&atm_vcc->stats->rx);
+	  atomic_inc_unchecked(&atm_vcc->stats->rx);
 	  __net_timestamp(skb);
 	  // end of our responsibility
 	  atm_vcc->push (atm_vcc, skb);
@@ -510,7 +510,7 @@ static void rx_complete (amb_dev * dev,
       } else {
       	PRINTK (KERN_INFO, "dropped over-size frame");
 	// should we count this?
-	atomic_inc(&atm_vcc->stats->rx_drop);
+	atomic_inc_unchecked(&atm_vcc->stats->rx_drop);
       }
       
     } else {
@@ -1338,7 +1338,7 @@ static int amb_send (struct atm_vcc * at
   }
   
   if (check_area (skb->data, skb->len)) {
-    atomic_inc(&atm_vcc->stats->tx_err);
+    atomic_inc_unchecked(&atm_vcc->stats->tx_err);
     return -ENOMEM; // ?
   }
   
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/atmtcp.c linux-3.2.71-pax/drivers/atm/atmtcp.c
--- linux-3.2.71/drivers/atm/atmtcp.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/atm/atmtcp.c	2012-07-04 19:24:47.676063005 +0200
@@ -207,7 +207,7 @@ static int atmtcp_v_send(struct atm_vcc
 		if (vcc->pop) vcc->pop(vcc,skb);
 		else dev_kfree_skb(skb);
 		if (dev_data) return 0;
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		return -ENOLINK;
 	}
 	size = skb->len+sizeof(struct atmtcp_hdr);
@@ -215,7 +215,7 @@ static int atmtcp_v_send(struct atm_vcc
 	if (!new_skb) {
 		if (vcc->pop) vcc->pop(vcc,skb);
 		else dev_kfree_skb(skb);
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		return -ENOBUFS;
 	}
 	hdr = (void *) skb_put(new_skb,sizeof(struct atmtcp_hdr));
@@ -226,8 +226,8 @@ static int atmtcp_v_send(struct atm_vcc
 	if (vcc->pop) vcc->pop(vcc,skb);
 	else dev_kfree_skb(skb);
 	out_vcc->push(out_vcc,new_skb);
-	atomic_inc(&vcc->stats->tx);
-	atomic_inc(&out_vcc->stats->rx);
+	atomic_inc_unchecked(&vcc->stats->tx);
+	atomic_inc_unchecked(&out_vcc->stats->rx);
 	return 0;
 }
 
@@ -301,7 +301,7 @@ static int atmtcp_c_send(struct atm_vcc
 	out_vcc = find_vcc(dev, ntohs(hdr->vpi), ntohs(hdr->vci));
 	read_unlock(&vcc_sklist_lock);
 	if (!out_vcc) {
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		goto done;
 	}
 	skb_pull(skb,sizeof(struct atmtcp_hdr));
@@ -313,8 +313,8 @@ static int atmtcp_c_send(struct atm_vcc
 	__net_timestamp(new_skb);
 	skb_copy_from_linear_data(skb, skb_put(new_skb, skb->len), skb->len);
 	out_vcc->push(out_vcc,new_skb);
-	atomic_inc(&vcc->stats->tx);
-	atomic_inc(&out_vcc->stats->rx);
+	atomic_inc_unchecked(&vcc->stats->tx);
+	atomic_inc_unchecked(&out_vcc->stats->rx);
 done:
 	if (vcc->pop) vcc->pop(vcc,skb);
 	else dev_kfree_skb(skb);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/eni.c linux-3.2.71-pax/drivers/atm/eni.c
--- linux-3.2.71/drivers/atm/eni.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/atm/eni.c	2012-07-04 19:24:47.680063005 +0200
@@ -526,7 +526,7 @@ static int rx_aal0(struct atm_vcc *vcc)
 		DPRINTK(DEV_LABEL "(itf %d): trashing empty cell\n",
 		    vcc->dev->number);
 		length = 0;
-		atomic_inc(&vcc->stats->rx_err);
+		atomic_inc_unchecked(&vcc->stats->rx_err);
 	}
 	else {
 		length = ATM_CELL_SIZE-1; /* no HEC */
@@ -581,7 +581,7 @@ static int rx_aal5(struct atm_vcc *vcc)
 			    size);
 		}
 		eff = length = 0;
-		atomic_inc(&vcc->stats->rx_err);
+		atomic_inc_unchecked(&vcc->stats->rx_err);
 	}
 	else {
 		size = (descr & MID_RED_COUNT)*(ATM_CELL_PAYLOAD >> 2);
@@ -598,7 +598,7 @@ static int rx_aal5(struct atm_vcc *vcc)
 			    "(VCI=%d,length=%ld,size=%ld (descr 0x%lx))\n",
 			    vcc->dev->number,vcc->vci,length,size << 2,descr);
 			length = eff = 0;
-			atomic_inc(&vcc->stats->rx_err);
+			atomic_inc_unchecked(&vcc->stats->rx_err);
 		}
 	}
 	skb = eff ? atm_alloc_charge(vcc,eff << 2,GFP_ATOMIC) : NULL;
@@ -771,7 +771,7 @@ rx_dequeued++;
 			vcc->push(vcc,skb);
 			pushed++;
 		}
-		atomic_inc(&vcc->stats->rx);
+		atomic_inc_unchecked(&vcc->stats->rx);
 	}
 	wake_up(&eni_dev->rx_wait);
 }
@@ -1229,7 +1229,7 @@ static void dequeue_tx(struct atm_dev *d
 		    PCI_DMA_TODEVICE);
 		if (vcc->pop) vcc->pop(vcc,skb);
 		else dev_kfree_skb_irq(skb);
-		atomic_inc(&vcc->stats->tx);
+		atomic_inc_unchecked(&vcc->stats->tx);
 		wake_up(&eni_dev->tx_wait);
 dma_complete++;
 	}
@@ -1569,7 +1569,7 @@ tx_complete++;
 /*--------------------------------- entries ---------------------------------*/
 
 
-static const char *media_name[] __devinitdata = {
+static const char *media_name[] __devinitconst = {
     "MMF", "SMF", "MMF", "03?", /*  0- 3 */
     "UTP", "05?", "06?", "07?", /*  4- 7 */
     "TAXI","09?", "10?", "11?", /*  8-11 */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/firestream.c linux-3.2.71-pax/drivers/atm/firestream.c
--- linux-3.2.71/drivers/atm/firestream.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/atm/firestream.c	2012-07-04 19:24:47.680063005 +0200
@@ -750,7 +750,7 @@ static void process_txdone_queue (struct
 				}
 			}
 
-			atomic_inc(&ATM_SKB(skb)->vcc->stats->tx);
+			atomic_inc_unchecked(&ATM_SKB(skb)->vcc->stats->tx);
 
 			fs_dprintk (FS_DEBUG_TXMEM, "i");
 			fs_dprintk (FS_DEBUG_ALLOC, "Free t-skb: %p\n", skb);
@@ -817,7 +817,7 @@ static void process_incoming (struct fs_
 #endif
 				skb_put (skb, qe->p1 & 0xffff); 
 				ATM_SKB(skb)->vcc = atm_vcc;
-				atomic_inc(&atm_vcc->stats->rx);
+				atomic_inc_unchecked(&atm_vcc->stats->rx);
 				__net_timestamp(skb);
 				fs_dprintk (FS_DEBUG_ALLOC, "Free rec-skb: %p (pushed)\n", skb);
 				atm_vcc->push (atm_vcc, skb);
@@ -838,12 +838,12 @@ static void process_incoming (struct fs_
 				kfree (pe);
 			}
 			if (atm_vcc)
-				atomic_inc(&atm_vcc->stats->rx_drop);
+				atomic_inc_unchecked(&atm_vcc->stats->rx_drop);
 			break;
 		case 0x1f: /*  Reassembly abort: no buffers. */
 			/* Silently increment error counter. */
 			if (atm_vcc)
-				atomic_inc(&atm_vcc->stats->rx_drop);
+				atomic_inc_unchecked(&atm_vcc->stats->rx_drop);
 			break;
 		default: /* Hmm. Haven't written the code to handle the others yet... -- REW */
 			printk (KERN_WARNING "Don't know what to do with RX status %x: %s.\n", 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/fore200e.c linux-3.2.71-pax/drivers/atm/fore200e.c
--- linux-3.2.71/drivers/atm/fore200e.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/atm/fore200e.c	2012-07-04 19:24:47.680063005 +0200
@@ -933,9 +933,9 @@ fore200e_tx_irq(struct fore200e* fore200
 #endif
 		/* check error condition */
 		if (*entry->status & STATUS_ERROR)
-		    atomic_inc(&vcc->stats->tx_err);
+		    atomic_inc_unchecked(&vcc->stats->tx_err);
 		else
-		    atomic_inc(&vcc->stats->tx);
+		    atomic_inc_unchecked(&vcc->stats->tx);
 	    }
 	}
 
@@ -1084,7 +1084,7 @@ fore200e_push_rpd(struct fore200e* fore2
     if (skb == NULL) {
 	DPRINTK(2, "unable to alloc new skb, rx PDU length = %d\n", pdu_len);
 
-	atomic_inc(&vcc->stats->rx_drop);
+	atomic_inc_unchecked(&vcc->stats->rx_drop);
 	return -ENOMEM;
     } 
 
@@ -1127,14 +1127,14 @@ fore200e_push_rpd(struct fore200e* fore2
 
 	dev_kfree_skb_any(skb);
 
-	atomic_inc(&vcc->stats->rx_drop);
+	atomic_inc_unchecked(&vcc->stats->rx_drop);
 	return -ENOMEM;
     }
 
     ASSERT(atomic_read(&sk_atm(vcc)->sk_wmem_alloc) >= 0);
 
     vcc->push(vcc, skb);
-    atomic_inc(&vcc->stats->rx);
+    atomic_inc_unchecked(&vcc->stats->rx);
 
     ASSERT(atomic_read(&sk_atm(vcc)->sk_wmem_alloc) >= 0);
 
@@ -1212,7 +1212,7 @@ fore200e_rx_irq(struct fore200e* fore200
 		DPRINTK(2, "damaged PDU on %d.%d.%d\n",
 			fore200e->atm_dev->number,
 			entry->rpd->atm_header.vpi, entry->rpd->atm_header.vci);
-		atomic_inc(&vcc->stats->rx_err);
+		atomic_inc_unchecked(&vcc->stats->rx_err);
 	    }
 	}
 
@@ -1657,7 +1657,7 @@ fore200e_send(struct atm_vcc *vcc, struc
 		goto retry_here;
 	    }
 
-	    atomic_inc(&vcc->stats->tx_err);
+	    atomic_inc_unchecked(&vcc->stats->tx_err);
 
 	    fore200e->tx_sat++;
 	    DPRINTK(2, "tx queue of device %s is saturated, PDU dropped - heartbeat is %08x\n",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/he.c linux-3.2.71-pax/drivers/atm/he.c
--- linux-3.2.71/drivers/atm/he.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/atm/he.c	2012-07-04 19:24:47.684063004 +0200
@@ -1709,7 +1709,7 @@ he_service_rbrq(struct he_dev *he_dev, i
 
 		if (RBRQ_HBUF_ERR(he_dev->rbrq_head)) {
 			hprintk("HBUF_ERR!  (cid 0x%x)\n", cid);
-				atomic_inc(&vcc->stats->rx_drop);
+				atomic_inc_unchecked(&vcc->stats->rx_drop);
 			goto return_host_buffers;
 		}
 
@@ -1736,7 +1736,7 @@ he_service_rbrq(struct he_dev *he_dev, i
 				RBRQ_LEN_ERR(he_dev->rbrq_head)
 							? "LEN_ERR" : "",
 							vcc->vpi, vcc->vci);
-			atomic_inc(&vcc->stats->rx_err);
+			atomic_inc_unchecked(&vcc->stats->rx_err);
 			goto return_host_buffers;
 		}
 
@@ -1788,7 +1788,7 @@ he_service_rbrq(struct he_dev *he_dev, i
 		vcc->push(vcc, skb);
 		spin_lock(&he_dev->global_lock);
 
-		atomic_inc(&vcc->stats->rx);
+		atomic_inc_unchecked(&vcc->stats->rx);
 
 return_host_buffers:
 		++pdus_assembled;
@@ -2114,7 +2114,7 @@ __enqueue_tpd(struct he_dev *he_dev, str
 					tpd->vcc->pop(tpd->vcc, tpd->skb);
 				else
 					dev_kfree_skb_any(tpd->skb);
-				atomic_inc(&tpd->vcc->stats->tx_err);
+				atomic_inc_unchecked(&tpd->vcc->stats->tx_err);
 			}
 			pci_pool_free(he_dev->tpd_pool, tpd, TPD_ADDR(tpd->status));
 			return;
@@ -2526,7 +2526,7 @@ he_send(struct atm_vcc *vcc, struct sk_b
 			vcc->pop(vcc, skb);
 		else
 			dev_kfree_skb_any(skb);
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		return -EINVAL;
 	}
 
@@ -2537,7 +2537,7 @@ he_send(struct atm_vcc *vcc, struct sk_b
 			vcc->pop(vcc, skb);
 		else
 			dev_kfree_skb_any(skb);
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		return -EINVAL;
 	}
 #endif
@@ -2549,7 +2549,7 @@ he_send(struct atm_vcc *vcc, struct sk_b
 			vcc->pop(vcc, skb);
 		else
 			dev_kfree_skb_any(skb);
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		spin_unlock_irqrestore(&he_dev->global_lock, flags);
 		return -ENOMEM;
 	}
@@ -2591,7 +2591,7 @@ he_send(struct atm_vcc *vcc, struct sk_b
 					vcc->pop(vcc, skb);
 				else
 					dev_kfree_skb_any(skb);
-				atomic_inc(&vcc->stats->tx_err);
+				atomic_inc_unchecked(&vcc->stats->tx_err);
 				spin_unlock_irqrestore(&he_dev->global_lock, flags);
 				return -ENOMEM;
 			}
@@ -2622,7 +2622,7 @@ he_send(struct atm_vcc *vcc, struct sk_b
 	__enqueue_tpd(he_dev, tpd, cid);
 	spin_unlock_irqrestore(&he_dev->global_lock, flags);
 
-	atomic_inc(&vcc->stats->tx);
+	atomic_inc_unchecked(&vcc->stats->tx);
 
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/horizon.c linux-3.2.71-pax/drivers/atm/horizon.c
--- linux-3.2.71/drivers/atm/horizon.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/atm/horizon.c	2012-07-04 19:24:47.684063004 +0200
@@ -1035,7 +1035,7 @@ static void rx_schedule (hrz_dev * dev,
 	{
 	  struct atm_vcc * vcc = ATM_SKB(skb)->vcc;
 	  // VC layer stats
-	  atomic_inc(&vcc->stats->rx);
+	  atomic_inc_unchecked(&vcc->stats->rx);
 	  __net_timestamp(skb);
 	  // end of our responsibility
 	  vcc->push (vcc, skb);
@@ -1187,7 +1187,7 @@ static void tx_schedule (hrz_dev * const
 	dev->tx_iovec = NULL;
 	
 	// VC layer stats
-	atomic_inc(&ATM_SKB(skb)->vcc->stats->tx);
+	atomic_inc_unchecked(&ATM_SKB(skb)->vcc->stats->tx);
 	
 	// free the skb
 	hrz_kfree_skb (skb);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/idt77252.c linux-3.2.71-pax/drivers/atm/idt77252.c
--- linux-3.2.71/drivers/atm/idt77252.c	2014-06-10 10:59:38.750436245 +0200
+++ linux-3.2.71-pax/drivers/atm/idt77252.c	2014-06-10 10:59:44.138435957 +0200
@@ -812,7 +812,7 @@ drain_scq(struct idt77252_dev *card, str
 		else
 			dev_kfree_skb(skb);
 
-		atomic_inc(&vcc->stats->tx);
+		atomic_inc_unchecked(&vcc->stats->tx);
 	}
 
 	atomic_dec(&scq->used);
@@ -1075,13 +1075,13 @@ dequeue_rx(struct idt77252_dev *card, st
 			if ((sb = dev_alloc_skb(64)) == NULL) {
 				printk("%s: Can't allocate buffers for aal0.\n",
 				       card->name);
-				atomic_add(i, &vcc->stats->rx_drop);
+				atomic_add_unchecked(i, &vcc->stats->rx_drop);
 				break;
 			}
 			if (!atm_charge(vcc, sb->truesize)) {
 				RXPRINTK("%s: atm_charge() dropped aal0 packets.\n",
 					 card->name);
-				atomic_add(i - 1, &vcc->stats->rx_drop);
+				atomic_add_unchecked(i - 1, &vcc->stats->rx_drop);
 				dev_kfree_skb(sb);
 				break;
 			}
@@ -1098,7 +1098,7 @@ dequeue_rx(struct idt77252_dev *card, st
 			ATM_SKB(sb)->vcc = vcc;
 			__net_timestamp(sb);
 			vcc->push(vcc, sb);
-			atomic_inc(&vcc->stats->rx);
+			atomic_inc_unchecked(&vcc->stats->rx);
 
 			cell += ATM_CELL_PAYLOAD;
 		}
@@ -1135,13 +1135,13 @@ dequeue_rx(struct idt77252_dev *card, st
 			         "(CDC: %08x)\n",
 			         card->name, len, rpp->len, readl(SAR_REG_CDC));
 			recycle_rx_pool_skb(card, rpp);
-			atomic_inc(&vcc->stats->rx_err);
+			atomic_inc_unchecked(&vcc->stats->rx_err);
 			return;
 		}
 		if (stat & SAR_RSQE_CRC) {
 			RXPRINTK("%s: AAL5 CRC error.\n", card->name);
 			recycle_rx_pool_skb(card, rpp);
-			atomic_inc(&vcc->stats->rx_err);
+			atomic_inc_unchecked(&vcc->stats->rx_err);
 			return;
 		}
 		if (skb_queue_len(&rpp->queue) > 1) {
@@ -1152,7 +1152,7 @@ dequeue_rx(struct idt77252_dev *card, st
 				RXPRINTK("%s: Can't alloc RX skb.\n",
 					 card->name);
 				recycle_rx_pool_skb(card, rpp);
-				atomic_inc(&vcc->stats->rx_err);
+				atomic_inc_unchecked(&vcc->stats->rx_err);
 				return;
 			}
 			if (!atm_charge(vcc, skb->truesize)) {
@@ -1171,7 +1171,7 @@ dequeue_rx(struct idt77252_dev *card, st
 			__net_timestamp(skb);
 
 			vcc->push(vcc, skb);
-			atomic_inc(&vcc->stats->rx);
+			atomic_inc_unchecked(&vcc->stats->rx);
 
 			return;
 		}
@@ -1193,7 +1193,7 @@ dequeue_rx(struct idt77252_dev *card, st
 		__net_timestamp(skb);
 
 		vcc->push(vcc, skb);
-		atomic_inc(&vcc->stats->rx);
+		atomic_inc_unchecked(&vcc->stats->rx);
 
 		if (skb->truesize > SAR_FB_SIZE_3)
 			add_rx_skb(card, 3, SAR_FB_SIZE_3, 1);
@@ -1304,14 +1304,14 @@ idt77252_rx_raw(struct idt77252_dev *car
 		if (vcc->qos.aal != ATM_AAL0) {
 			RPRINTK("%s: raw cell for non AAL0 vc %u.%u\n",
 				card->name, vpi, vci);
-			atomic_inc(&vcc->stats->rx_drop);
+			atomic_inc_unchecked(&vcc->stats->rx_drop);
 			goto drop;
 		}
 	
 		if ((sb = dev_alloc_skb(64)) == NULL) {
 			printk("%s: Can't allocate buffers for AAL0.\n",
 			       card->name);
-			atomic_inc(&vcc->stats->rx_err);
+			atomic_inc_unchecked(&vcc->stats->rx_err);
 			goto drop;
 		}
 
@@ -1330,7 +1330,7 @@ idt77252_rx_raw(struct idt77252_dev *car
 		ATM_SKB(sb)->vcc = vcc;
 		__net_timestamp(sb);
 		vcc->push(vcc, sb);
-		atomic_inc(&vcc->stats->rx);
+		atomic_inc_unchecked(&vcc->stats->rx);
 
 drop:
 		skb_pull(queue, 64);
@@ -1955,13 +1955,13 @@ idt77252_send_skb(struct atm_vcc *vcc, s
 
 	if (vc == NULL) {
 		printk("%s: NULL connection in send().\n", card->name);
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		dev_kfree_skb(skb);
 		return -EINVAL;
 	}
 	if (!test_bit(VCF_TX, &vc->flags)) {
 		printk("%s: Trying to transmit on a non-tx VC.\n", card->name);
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		dev_kfree_skb(skb);
 		return -EINVAL;
 	}
@@ -1973,14 +1973,14 @@ idt77252_send_skb(struct atm_vcc *vcc, s
 		break;
 	default:
 		printk("%s: Unsupported AAL: %d\n", card->name, vcc->qos.aal);
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		dev_kfree_skb(skb);
 		return -EINVAL;
 	}
 
 	if (skb_shinfo(skb)->nr_frags != 0) {
 		printk("%s: No scatter-gather yet.\n", card->name);
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		dev_kfree_skb(skb);
 		return -EINVAL;
 	}
@@ -1988,7 +1988,7 @@ idt77252_send_skb(struct atm_vcc *vcc, s
 
 	err = queue_skb(card, vc, skb, oam);
 	if (err) {
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		dev_kfree_skb(skb);
 		return err;
 	}
@@ -2011,7 +2011,7 @@ idt77252_send_oam(struct atm_vcc *vcc, v
 	skb = dev_alloc_skb(64);
 	if (!skb) {
 		printk("%s: Out of memory in send_oam().\n", card->name);
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		return -ENOMEM;
 	}
 	atomic_add(skb->truesize, &sk_atm(vcc)->sk_wmem_alloc);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/iphase.c linux-3.2.71-pax/drivers/atm/iphase.c
--- linux-3.2.71/drivers/atm/iphase.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/atm/iphase.c	2012-07-04 19:24:47.688063004 +0200
@@ -1146,7 +1146,7 @@ static int rx_pkt(struct atm_dev *dev)
 	status = (u_short) (buf_desc_ptr->desc_mode);  
 	if (status & (RX_CER | RX_PTE | RX_OFL))  
 	{  
-                atomic_inc(&vcc->stats->rx_err);
+                atomic_inc_unchecked(&vcc->stats->rx_err);
 		IF_ERR(printk("IA: bad packet, dropping it");)  
                 if (status & RX_CER) { 
                     IF_ERR(printk(" cause: packet CRC error\n");)
@@ -1169,7 +1169,7 @@ static int rx_pkt(struct atm_dev *dev)
 	len = dma_addr - buf_addr;  
         if (len > iadev->rx_buf_sz) {
            printk("Over %d bytes sdu received, dropped!!!\n", iadev->rx_buf_sz);
-           atomic_inc(&vcc->stats->rx_err);
+           atomic_inc_unchecked(&vcc->stats->rx_err);
 	   goto out_free_desc;
         }
 		  
@@ -1319,7 +1319,7 @@ static void rx_dle_intr(struct atm_dev *
           ia_vcc = INPH_IA_VCC(vcc);
           if (ia_vcc == NULL)
           {
-             atomic_inc(&vcc->stats->rx_err);
+             atomic_inc_unchecked(&vcc->stats->rx_err);
              dev_kfree_skb_any(skb);
              atm_return(vcc, atm_guess_pdu2truesize(len));
              goto INCR_DLE;
@@ -1331,7 +1331,7 @@ static void rx_dle_intr(struct atm_dev *
           if ((length > iadev->rx_buf_sz) || (length > 
                               (skb->len - sizeof(struct cpcs_trailer))))
           {
-             atomic_inc(&vcc->stats->rx_err);
+             atomic_inc_unchecked(&vcc->stats->rx_err);
              IF_ERR(printk("rx_dle_intr: Bad  AAL5 trailer %d (skb len %d)", 
                                                             length, skb->len);)
              dev_kfree_skb_any(skb);
@@ -1347,7 +1347,7 @@ static void rx_dle_intr(struct atm_dev *
 
 	  IF_RX(printk("rx_dle_intr: skb push");)  
 	  vcc->push(vcc,skb);  
-	  atomic_inc(&vcc->stats->rx);
+	  atomic_inc_unchecked(&vcc->stats->rx);
           iadev->rx_pkt_cnt++;
       }  
 INCR_DLE:
@@ -2827,15 +2827,15 @@ static int ia_ioctl(struct atm_dev *dev,
          {
              struct k_sonet_stats *stats;
              stats = &PRIV(_ia_dev[board])->sonet_stats;
-             printk("section_bip: %d\n", atomic_read(&stats->section_bip));
-             printk("line_bip   : %d\n", atomic_read(&stats->line_bip));
-             printk("path_bip   : %d\n", atomic_read(&stats->path_bip));
-             printk("line_febe  : %d\n", atomic_read(&stats->line_febe));
-             printk("path_febe  : %d\n", atomic_read(&stats->path_febe));
-             printk("corr_hcs   : %d\n", atomic_read(&stats->corr_hcs));
-             printk("uncorr_hcs : %d\n", atomic_read(&stats->uncorr_hcs));
-             printk("tx_cells   : %d\n", atomic_read(&stats->tx_cells));
-             printk("rx_cells   : %d\n", atomic_read(&stats->rx_cells));
+             printk("section_bip: %d\n", atomic_read_unchecked(&stats->section_bip));
+             printk("line_bip   : %d\n", atomic_read_unchecked(&stats->line_bip));
+             printk("path_bip   : %d\n", atomic_read_unchecked(&stats->path_bip));
+             printk("line_febe  : %d\n", atomic_read_unchecked(&stats->line_febe));
+             printk("path_febe  : %d\n", atomic_read_unchecked(&stats->path_febe));
+             printk("corr_hcs   : %d\n", atomic_read_unchecked(&stats->corr_hcs));
+             printk("uncorr_hcs : %d\n", atomic_read_unchecked(&stats->uncorr_hcs));
+             printk("tx_cells   : %d\n", atomic_read_unchecked(&stats->tx_cells));
+             printk("rx_cells   : %d\n", atomic_read_unchecked(&stats->rx_cells));
          }
             ia_cmds.status = 0;
             break;
@@ -2940,7 +2940,7 @@ static int ia_pkt_tx (struct atm_vcc *vc
 	if ((desc == 0) || (desc > iadev->num_tx_desc))  
 	{  
 		IF_ERR(printk(DEV_LABEL "invalid desc for send: %d\n", desc);) 
-                atomic_inc(&vcc->stats->tx);
+                atomic_inc_unchecked(&vcc->stats->tx);
 		if (vcc->pop)   
 		    vcc->pop(vcc, skb);   
 		else  
@@ -3045,14 +3045,14 @@ static int ia_pkt_tx (struct atm_vcc *vc
         ATM_DESC(skb) = vcc->vci;
         skb_queue_tail(&iadev->tx_dma_q, skb);
 
-        atomic_inc(&vcc->stats->tx);
+        atomic_inc_unchecked(&vcc->stats->tx);
         iadev->tx_pkt_cnt++;
 	/* Increment transaction counter */  
 	writel(2, iadev->dma+IPHASE5575_TX_COUNTER);  
         
 #if 0        
         /* add flow control logic */ 
-        if (atomic_read(&vcc->stats->tx) % 20 == 0) {
+        if (atomic_read_unchecked(&vcc->stats->tx) % 20 == 0) {
           if (iavcc->vc_desc_cnt > 10) {
              vcc->tx_quota =  vcc->tx_quota * 3 / 4;
             printk("Tx1:  vcc->tx_quota = %d \n", (u32)vcc->tx_quota );
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/lanai.c linux-3.2.71-pax/drivers/atm/lanai.c
--- linux-3.2.71/drivers/atm/lanai.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/atm/lanai.c	2012-07-04 19:24:47.688063004 +0200
@@ -1303,7 +1303,7 @@ static void lanai_send_one_aal5(struct l
 	vcc_tx_add_aal5_trailer(lvcc, skb->len, 0, 0);
 	lanai_endtx(lanai, lvcc);
 	lanai_free_skb(lvcc->tx.atmvcc, skb);
-	atomic_inc(&lvcc->tx.atmvcc->stats->tx);
+	atomic_inc_unchecked(&lvcc->tx.atmvcc->stats->tx);
 }
 
 /* Try to fill the buffer - don't call unless there is backlog */
@@ -1426,7 +1426,7 @@ static void vcc_rx_aal5(struct lanai_vcc
 	ATM_SKB(skb)->vcc = lvcc->rx.atmvcc;
 	__net_timestamp(skb);
 	lvcc->rx.atmvcc->push(lvcc->rx.atmvcc, skb);
-	atomic_inc(&lvcc->rx.atmvcc->stats->rx);
+	atomic_inc_unchecked(&lvcc->rx.atmvcc->stats->rx);
     out:
 	lvcc->rx.buf.ptr = end;
 	cardvcc_write(lvcc, endptr, vcc_rxreadptr);
@@ -1667,7 +1667,7 @@ static int handle_service(struct lanai_d
 		DPRINTK("(itf %d) got RX service entry 0x%X for non-AAL5 "
 		    "vcc %d\n", lanai->number, (unsigned int) s, vci);
 		lanai->stats.service_rxnotaal5++;
-		atomic_inc(&lvcc->rx.atmvcc->stats->rx_err);
+		atomic_inc_unchecked(&lvcc->rx.atmvcc->stats->rx_err);
 		return 0;
 	}
 	if (likely(!(s & (SERVICE_TRASH | SERVICE_STREAM | SERVICE_CRCERR)))) {
@@ -1679,7 +1679,7 @@ static int handle_service(struct lanai_d
 		int bytes;
 		read_unlock(&vcc_sklist_lock);
 		DPRINTK("got trashed rx pdu on vci %d\n", vci);
-		atomic_inc(&lvcc->rx.atmvcc->stats->rx_err);
+		atomic_inc_unchecked(&lvcc->rx.atmvcc->stats->rx_err);
 		lvcc->stats.x.aal5.service_trash++;
 		bytes = (SERVICE_GET_END(s) * 16) -
 		    (((unsigned long) lvcc->rx.buf.ptr) -
@@ -1691,7 +1691,7 @@ static int handle_service(struct lanai_d
 	}
 	if (s & SERVICE_STREAM) {
 		read_unlock(&vcc_sklist_lock);
-		atomic_inc(&lvcc->rx.atmvcc->stats->rx_err);
+		atomic_inc_unchecked(&lvcc->rx.atmvcc->stats->rx_err);
 		lvcc->stats.x.aal5.service_stream++;
 		printk(KERN_ERR DEV_LABEL "(itf %d): Got AAL5 stream "
 		    "PDU on VCI %d!\n", lanai->number, vci);
@@ -1699,7 +1699,7 @@ static int handle_service(struct lanai_d
 		return 0;
 	}
 	DPRINTK("got rx crc error on vci %d\n", vci);
-	atomic_inc(&lvcc->rx.atmvcc->stats->rx_err);
+	atomic_inc_unchecked(&lvcc->rx.atmvcc->stats->rx_err);
 	lvcc->stats.x.aal5.service_rxcrc++;
 	lvcc->rx.buf.ptr = &lvcc->rx.buf.start[SERVICE_GET_END(s) * 4];
 	cardvcc_write(lvcc, SERVICE_GET_END(s), vcc_rxreadptr);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/nicstar.c linux-3.2.71-pax/drivers/atm/nicstar.c
--- linux-3.2.71/drivers/atm/nicstar.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/atm/nicstar.c	2012-07-04 19:24:47.688063004 +0200
@@ -1654,7 +1654,7 @@ static int ns_send(struct atm_vcc *vcc,
 	if ((vc = (vc_map *) vcc->dev_data) == NULL) {
 		printk("nicstar%d: vcc->dev_data == NULL on ns_send().\n",
 		       card->index);
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		dev_kfree_skb_any(skb);
 		return -EINVAL;
 	}
@@ -1662,7 +1662,7 @@ static int ns_send(struct atm_vcc *vcc,
 	if (!vc->tx) {
 		printk("nicstar%d: Trying to transmit on a non-tx VC.\n",
 		       card->index);
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		dev_kfree_skb_any(skb);
 		return -EINVAL;
 	}
@@ -1670,14 +1670,14 @@ static int ns_send(struct atm_vcc *vcc,
 	if (vcc->qos.aal != ATM_AAL5 && vcc->qos.aal != ATM_AAL0) {
 		printk("nicstar%d: Only AAL0 and AAL5 are supported.\n",
 		       card->index);
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		dev_kfree_skb_any(skb);
 		return -EINVAL;
 	}
 
 	if (skb_shinfo(skb)->nr_frags != 0) {
 		printk("nicstar%d: No scatter-gather yet.\n", card->index);
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		dev_kfree_skb_any(skb);
 		return -EINVAL;
 	}
@@ -1725,11 +1725,11 @@ static int ns_send(struct atm_vcc *vcc,
 	}
 
 	if (push_scqe(card, vc, scq, &scqe, skb) != 0) {
-		atomic_inc(&vcc->stats->tx_err);
+		atomic_inc_unchecked(&vcc->stats->tx_err);
 		dev_kfree_skb_any(skb);
 		return -EIO;
 	}
-	atomic_inc(&vcc->stats->tx);
+	atomic_inc_unchecked(&vcc->stats->tx);
 
 	return 0;
 }
@@ -2046,14 +2046,14 @@ static void dequeue_rx(ns_dev * card, ns
 				printk
 				    ("nicstar%d: Can't allocate buffers for aal0.\n",
 				     card->index);
-				atomic_add(i, &vcc->stats->rx_drop);
+				atomic_add_unchecked(i, &vcc->stats->rx_drop);
 				break;
 			}
 			if (!atm_charge(vcc, sb->truesize)) {
 				RXPRINTK
 				    ("nicstar%d: atm_charge() dropped aal0 packets.\n",
 				     card->index);
-				atomic_add(i - 1, &vcc->stats->rx_drop);	/* already increased by 1 */
+				atomic_add_unchecked(i - 1, &vcc->stats->rx_drop);	/* already increased by 1 */
 				dev_kfree_skb_any(sb);
 				break;
 			}
@@ -2068,7 +2068,7 @@ static void dequeue_rx(ns_dev * card, ns
 			ATM_SKB(sb)->vcc = vcc;
 			__net_timestamp(sb);
 			vcc->push(vcc, sb);
-			atomic_inc(&vcc->stats->rx);
+			atomic_inc_unchecked(&vcc->stats->rx);
 			cell += ATM_CELL_PAYLOAD;
 		}
 
@@ -2085,7 +2085,7 @@ static void dequeue_rx(ns_dev * card, ns
 			if (iovb == NULL) {
 				printk("nicstar%d: Out of iovec buffers.\n",
 				       card->index);
-				atomic_inc(&vcc->stats->rx_drop);
+				atomic_inc_unchecked(&vcc->stats->rx_drop);
 				recycle_rx_buf(card, skb);
 				return;
 			}
@@ -2109,7 +2109,7 @@ static void dequeue_rx(ns_dev * card, ns
 		   small or large buffer itself. */
 	} else if (NS_PRV_IOVCNT(iovb) >= NS_MAX_IOVECS) {
 		printk("nicstar%d: received too big AAL5 SDU.\n", card->index);
-		atomic_inc(&vcc->stats->rx_err);
+		atomic_inc_unchecked(&vcc->stats->rx_err);
 		recycle_iovec_rx_bufs(card, (struct iovec *)iovb->data,
 				      NS_MAX_IOVECS);
 		NS_PRV_IOVCNT(iovb) = 0;
@@ -2129,7 +2129,7 @@ static void dequeue_rx(ns_dev * card, ns
 			    ("nicstar%d: Expected a small buffer, and this is not one.\n",
 			     card->index);
 			which_list(card, skb);
-			atomic_inc(&vcc->stats->rx_err);
+			atomic_inc_unchecked(&vcc->stats->rx_err);
 			recycle_rx_buf(card, skb);
 			vc->rx_iov = NULL;
 			recycle_iov_buf(card, iovb);
@@ -2142,7 +2142,7 @@ static void dequeue_rx(ns_dev * card, ns
 			    ("nicstar%d: Expected a large buffer, and this is not one.\n",
 			     card->index);
 			which_list(card, skb);
-			atomic_inc(&vcc->stats->rx_err);
+			atomic_inc_unchecked(&vcc->stats->rx_err);
 			recycle_iovec_rx_bufs(card, (struct iovec *)iovb->data,
 					      NS_PRV_IOVCNT(iovb));
 			vc->rx_iov = NULL;
@@ -2165,7 +2165,7 @@ static void dequeue_rx(ns_dev * card, ns
 				printk(" - PDU size mismatch.\n");
 			else
 				printk(".\n");
-			atomic_inc(&vcc->stats->rx_err);
+			atomic_inc_unchecked(&vcc->stats->rx_err);
 			recycle_iovec_rx_bufs(card, (struct iovec *)iovb->data,
 					      NS_PRV_IOVCNT(iovb));
 			vc->rx_iov = NULL;
@@ -2179,7 +2179,7 @@ static void dequeue_rx(ns_dev * card, ns
 			/* skb points to a small buffer */
 			if (!atm_charge(vcc, skb->truesize)) {
 				push_rxbufs(card, skb);
-				atomic_inc(&vcc->stats->rx_drop);
+				atomic_inc_unchecked(&vcc->stats->rx_drop);
 			} else {
 				skb_put(skb, len);
 				dequeue_sm_buf(card, skb);
@@ -2189,7 +2189,7 @@ static void dequeue_rx(ns_dev * card, ns
 				ATM_SKB(skb)->vcc = vcc;
 				__net_timestamp(skb);
 				vcc->push(vcc, skb);
-				atomic_inc(&vcc->stats->rx);
+				atomic_inc_unchecked(&vcc->stats->rx);
 			}
 		} else if (NS_PRV_IOVCNT(iovb) == 2) {	/* One small plus one large buffer */
 			struct sk_buff *sb;
@@ -2200,7 +2200,7 @@ static void dequeue_rx(ns_dev * card, ns
 			if (len <= NS_SMBUFSIZE) {
 				if (!atm_charge(vcc, sb->truesize)) {
 					push_rxbufs(card, sb);
-					atomic_inc(&vcc->stats->rx_drop);
+					atomic_inc_unchecked(&vcc->stats->rx_drop);
 				} else {
 					skb_put(sb, len);
 					dequeue_sm_buf(card, sb);
@@ -2210,7 +2210,7 @@ static void dequeue_rx(ns_dev * card, ns
 					ATM_SKB(sb)->vcc = vcc;
 					__net_timestamp(sb);
 					vcc->push(vcc, sb);
-					atomic_inc(&vcc->stats->rx);
+					atomic_inc_unchecked(&vcc->stats->rx);
 				}
 
 				push_rxbufs(card, skb);
@@ -2219,7 +2219,7 @@ static void dequeue_rx(ns_dev * card, ns
 
 				if (!atm_charge(vcc, skb->truesize)) {
 					push_rxbufs(card, skb);
-					atomic_inc(&vcc->stats->rx_drop);
+					atomic_inc_unchecked(&vcc->stats->rx_drop);
 				} else {
 					dequeue_lg_buf(card, skb);
 #ifdef NS_USE_DESTRUCTORS
@@ -2232,7 +2232,7 @@ static void dequeue_rx(ns_dev * card, ns
 					ATM_SKB(skb)->vcc = vcc;
 					__net_timestamp(skb);
 					vcc->push(vcc, skb);
-					atomic_inc(&vcc->stats->rx);
+					atomic_inc_unchecked(&vcc->stats->rx);
 				}
 
 				push_rxbufs(card, sb);
@@ -2253,7 +2253,7 @@ static void dequeue_rx(ns_dev * card, ns
 					printk
 					    ("nicstar%d: Out of huge buffers.\n",
 					     card->index);
-					atomic_inc(&vcc->stats->rx_drop);
+					atomic_inc_unchecked(&vcc->stats->rx_drop);
 					recycle_iovec_rx_bufs(card,
 							      (struct iovec *)
 							      iovb->data,
@@ -2304,7 +2304,7 @@ static void dequeue_rx(ns_dev * card, ns
 					card->hbpool.count++;
 				} else
 					dev_kfree_skb_any(hb);
-				atomic_inc(&vcc->stats->rx_drop);
+				atomic_inc_unchecked(&vcc->stats->rx_drop);
 			} else {
 				/* Copy the small buffer to the huge buffer */
 				sb = (struct sk_buff *)iov->iov_base;
@@ -2341,7 +2341,7 @@ static void dequeue_rx(ns_dev * card, ns
 #endif /* NS_USE_DESTRUCTORS */
 				__net_timestamp(hb);
 				vcc->push(vcc, hb);
-				atomic_inc(&vcc->stats->rx);
+				atomic_inc_unchecked(&vcc->stats->rx);
 			}
 		}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/solos-pci.c linux-3.2.71-pax/drivers/atm/solos-pci.c
--- linux-3.2.71/drivers/atm/solos-pci.c	2013-01-03 19:05:12.904036808 +0100
+++ linux-3.2.71-pax/drivers/atm/solos-pci.c	2013-01-03 19:05:22.048037077 +0100
@@ -714,7 +714,7 @@ void solos_bh(unsigned long card_arg)
 				}
 				atm_charge(vcc, skb->truesize);
 				vcc->push(vcc, skb);
-				atomic_inc(&vcc->stats->rx);
+				atomic_inc_unchecked(&vcc->stats->rx);
 				break;
 
 			case PKT_STATUS:
@@ -1010,7 +1010,7 @@ static uint32_t fpga_tx(struct solos_car
 			vcc = SKB_CB(oldskb)->vcc;
 
 			if (vcc) {
-				atomic_inc(&vcc->stats->tx);
+				atomic_inc_unchecked(&vcc->stats->tx);
 				solos_pop(vcc, oldskb);
 			} else
 				dev_kfree_skb_irq(oldskb);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/suni.c linux-3.2.71-pax/drivers/atm/suni.c
--- linux-3.2.71/drivers/atm/suni.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/atm/suni.c	2012-07-04 19:24:47.692063005 +0200
@@ -50,8 +50,8 @@ static DEFINE_SPINLOCK(sunis_lock);
 
 
 #define ADD_LIMITED(s,v) \
-    atomic_add((v),&stats->s); \
-    if (atomic_read(&stats->s) < 0) atomic_set(&stats->s,INT_MAX);
+    atomic_add_unchecked((v),&stats->s); \
+    if (atomic_read_unchecked(&stats->s) < 0) atomic_set_unchecked(&stats->s,INT_MAX);
 
 
 static void suni_hz(unsigned long from_timer)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/uPD98402.c linux-3.2.71-pax/drivers/atm/uPD98402.c
--- linux-3.2.71/drivers/atm/uPD98402.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/atm/uPD98402.c	2012-07-04 19:24:47.692063005 +0200
@@ -42,7 +42,7 @@ static int fetch_stats(struct atm_dev *d
 	struct sonet_stats tmp;
  	int error = 0;
 
-	atomic_add(GET(HECCT),&PRIV(dev)->sonet_stats.uncorr_hcs);
+	atomic_add_unchecked(GET(HECCT),&PRIV(dev)->sonet_stats.uncorr_hcs);
 	sonet_copy_stats(&PRIV(dev)->sonet_stats,&tmp);
 	if (arg) error = copy_to_user(arg,&tmp,sizeof(tmp));
 	if (zero && !error) {
@@ -161,9 +161,9 @@ static int uPD98402_ioctl(struct atm_dev
 
 
 #define ADD_LIMITED(s,v) \
-    { atomic_add(GET(v),&PRIV(dev)->sonet_stats.s); \
-    if (atomic_read(&PRIV(dev)->sonet_stats.s) < 0) \
-	atomic_set(&PRIV(dev)->sonet_stats.s,INT_MAX); }
+    { atomic_add_unchecked(GET(v),&PRIV(dev)->sonet_stats.s); \
+    if (atomic_read_unchecked(&PRIV(dev)->sonet_stats.s) < 0) \
+	atomic_set_unchecked(&PRIV(dev)->sonet_stats.s,INT_MAX); }
 
 
 static void stat_event(struct atm_dev *dev)
@@ -194,7 +194,7 @@ static void uPD98402_int(struct atm_dev
 		if (reason & uPD98402_INT_PFM) stat_event(dev);
 		if (reason & uPD98402_INT_PCO) {
 			(void) GET(PCOCR); /* clear interrupt cause */
-			atomic_add(GET(HECCT),
+			atomic_add_unchecked(GET(HECCT),
 			    &PRIV(dev)->sonet_stats.uncorr_hcs);
 		}
 		if ((reason & uPD98402_INT_RFO) && 
@@ -222,9 +222,9 @@ static int uPD98402_start(struct atm_dev
 	PUT(~(uPD98402_INT_PFM | uPD98402_INT_ALM | uPD98402_INT_RFO |
 	  uPD98402_INT_LOS),PIMR); /* enable them */
 	(void) fetch_stats(dev,NULL,1); /* clear kernel counters */
-	atomic_set(&PRIV(dev)->sonet_stats.corr_hcs,-1);
-	atomic_set(&PRIV(dev)->sonet_stats.tx_cells,-1);
-	atomic_set(&PRIV(dev)->sonet_stats.rx_cells,-1);
+	atomic_set_unchecked(&PRIV(dev)->sonet_stats.corr_hcs,-1);
+	atomic_set_unchecked(&PRIV(dev)->sonet_stats.tx_cells,-1);
+	atomic_set_unchecked(&PRIV(dev)->sonet_stats.rx_cells,-1);
 	return 0;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/atm/zatm.c linux-3.2.71-pax/drivers/atm/zatm.c
--- linux-3.2.71/drivers/atm/zatm.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/atm/zatm.c	2012-07-04 19:24:47.692063005 +0200
@@ -460,7 +460,7 @@ printk("dummy: 0x%08lx, 0x%08lx\n",dummy
 		}
 		if (!size) {
 			dev_kfree_skb_irq(skb);
-			if (vcc) atomic_inc(&vcc->stats->rx_err);
+			if (vcc) atomic_inc_unchecked(&vcc->stats->rx_err);
 			continue;
 		}
 		if (!atm_charge(vcc,skb->truesize)) {
@@ -470,7 +470,7 @@ printk("dummy: 0x%08lx, 0x%08lx\n",dummy
 		skb->len = size;
 		ATM_SKB(skb)->vcc = vcc;
 		vcc->push(vcc,skb);
-		atomic_inc(&vcc->stats->rx);
+		atomic_inc_unchecked(&vcc->stats->rx);
 	}
 	zout(pos & 0xffff,MTA(mbx));
 #if 0 /* probably a stupid idea */
@@ -734,7 +734,7 @@ if (*ZATM_PRV_DSC(skb) != (uPD98401_TXPD
 			skb_queue_head(&zatm_vcc->backlog,skb);
 			break;
 		}
-	atomic_inc(&vcc->stats->tx);
+	atomic_inc_unchecked(&vcc->stats->tx);
 	wake_up(&zatm_vcc->tx_wait);
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/base/attribute_container.c linux-3.2.71-pax/drivers/base/attribute_container.c
--- linux-3.2.71/drivers/base/attribute_container.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/base/attribute_container.c	2013-06-21 20:15:56.434564312 +0200
@@ -167,7 +167,7 @@ attribute_container_add_device(struct de
 		ic->classdev.parent = get_device(dev);
 		ic->classdev.class = cont->class;
 		cont->class->dev_release = attribute_container_release;
-		dev_set_name(&ic->classdev, dev_name(dev));
+		dev_set_name(&ic->classdev, "%s", dev_name(dev));
 		if (fn)
 			fn(cont, dev, &ic->classdev);
 		else
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/base/devtmpfs.c linux-3.2.71-pax/drivers/base/devtmpfs.c
--- linux-3.2.71/drivers/base/devtmpfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/base/devtmpfs.c	2013-06-21 19:34:10.290698121 +0200
@@ -368,7 +368,7 @@ int devtmpfs_mount(const char *mntdir)
 	if (!thread)
 		return 0;
 
-	err = sys_mount("devtmpfs", (char *)mntdir, "devtmpfs", MS_SILENT, NULL);
+	err = sys_mount((char __force_user *)"devtmpfs", (char __force_user *)mntdir, (char __force_user *)"devtmpfs", MS_SILENT, NULL);
 	if (err)
 		printk(KERN_INFO "devtmpfs: error mounting %i\n", err);
 	else
@@ -393,11 +393,11 @@ static int devtmpfsd(void *p)
 	*err = sys_unshare(CLONE_NEWNS);
 	if (*err)
 		goto out;
-	*err = sys_mount("devtmpfs", "/", "devtmpfs", MS_SILENT, options);
+	*err = sys_mount((char __force_user *)"devtmpfs", (char __force_user *)"/", (char __force_user *)"devtmpfs", MS_SILENT, (char __force_user *)options);
 	if (*err)
 		goto out;
-	sys_chdir("/.."); /* will traverse into overmounted root */
-	sys_chroot(".");
+	sys_chdir((char __force_user *)"/.."); /* will traverse into overmounted root */
+	sys_chroot((char __force_user *)".");
 	complete(&setup_done);
 	while (1) {
 		spin_lock(&req_lock);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/base/node.c linux-3.2.71-pax/drivers/base/node.c
--- linux-3.2.71/drivers/base/node.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/base/node.c	2013-03-28 03:20:23.408091571 +0100
@@ -598,7 +598,7 @@ static ssize_t print_nodes_state(enum no
 struct node_attr {
 	struct sysdev_class_attribute attr;
 	enum node_states state;
-};
+} __do_const;
 
 static ssize_t show_node_state(struct sysdev_class *class,
 			       struct sysdev_class_attribute *attr, char *buf)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/base/power/sysfs.c linux-3.2.71-pax/drivers/base/power/sysfs.c
--- linux-3.2.71/drivers/base/power/sysfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/base/power/sysfs.c	2013-06-21 20:15:56.434564312 +0200
@@ -184,7 +184,7 @@ static ssize_t rtpm_status_show(struct d
 			return -EIO;
 		}
 	}
-	return sprintf(buf, p);
+	return sprintf(buf, "%s", p);
 }
 
 static DEVICE_ATTR(runtime_status, 0444, rtpm_status_show, NULL);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/base/power/wakeup.c linux-3.2.71-pax/drivers/base/power/wakeup.c
--- linux-3.2.71/drivers/base/power/wakeup.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/base/power/wakeup.c	2012-07-04 19:24:47.692063005 +0200
@@ -30,14 +30,14 @@ bool events_check_enabled;
  * They need to be modified together atomically, so it's better to use one
  * atomic variable to hold them both.
  */
-static atomic_t combined_event_count = ATOMIC_INIT(0);
+static atomic_unchecked_t combined_event_count = ATOMIC_INIT(0);
 
 #define IN_PROGRESS_BITS	(sizeof(int) * 4)
 #define MAX_IN_PROGRESS		((1 << IN_PROGRESS_BITS) - 1)
 
 static void split_counters(unsigned int *cnt, unsigned int *inpr)
 {
-	unsigned int comb = atomic_read(&combined_event_count);
+	unsigned int comb = atomic_read_unchecked(&combined_event_count);
 
 	*cnt = (comb >> IN_PROGRESS_BITS);
 	*inpr = comb & MAX_IN_PROGRESS;
@@ -353,7 +353,7 @@ static void wakeup_source_activate(struc
 	ws->last_time = ktime_get();
 
 	/* Increment the counter of events in progress. */
-	atomic_inc(&combined_event_count);
+	atomic_inc_unchecked(&combined_event_count);
 }
 
 /**
@@ -443,7 +443,7 @@ static void wakeup_source_deactivate(str
 	 * Increment the counter of registered wakeup events and decrement the
 	 * couter of wakeup events in progress simultaneously.
 	 */
-	atomic_add(MAX_IN_PROGRESS, &combined_event_count);
+	atomic_add_unchecked(MAX_IN_PROGRESS, &combined_event_count);
 }
 
 /**
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/base/syscore.c linux-3.2.71-pax/drivers/base/syscore.c
--- linux-3.2.71/drivers/base/syscore.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/base/syscore.c	2013-03-28 01:35:23.252427951 +0100
@@ -21,7 +21,7 @@ static DEFINE_MUTEX(syscore_ops_lock);
 void register_syscore_ops(struct syscore_ops *ops)
 {
 	mutex_lock(&syscore_ops_lock);
-	list_add_tail(&ops->node, &syscore_ops_list);
+	pax_list_add_tail((struct list_head *)&ops->node, &syscore_ops_list);
 	mutex_unlock(&syscore_ops_lock);
 }
 EXPORT_SYMBOL_GPL(register_syscore_ops);
@@ -33,7 +33,7 @@ EXPORT_SYMBOL_GPL(register_syscore_ops);
 void unregister_syscore_ops(struct syscore_ops *ops)
 {
 	mutex_lock(&syscore_ops_lock);
-	list_del(&ops->node);
+	pax_list_del((struct list_head *)&ops->node);
 	mutex_unlock(&syscore_ops_lock);
 }
 EXPORT_SYMBOL_GPL(unregister_syscore_ops);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/block/cciss.c linux-3.2.71-pax/drivers/block/cciss.c
--- linux-3.2.71/drivers/block/cciss.c	2013-10-27 17:59:56.812642408 +0100
+++ linux-3.2.71-pax/drivers/block/cciss.c	2013-10-27 18:00:09.448641734 +0100
@@ -3008,7 +3008,7 @@ static void start_io(ctlr_info_t *h)
 	while (!list_empty(&h->reqQ)) {
 		c = list_entry(h->reqQ.next, CommandList_struct, list);
 		/* can't do anything if fifo is full */
-		if ((h->access.fifo_full(h))) {
+		if ((h->access->fifo_full(h))) {
 			dev_warn(&h->pdev->dev, "fifo full\n");
 			break;
 		}
@@ -3018,7 +3018,7 @@ static void start_io(ctlr_info_t *h)
 		h->Qdepth--;
 
 		/* Tell the controller execute command */
-		h->access.submit_command(h, c);
+		h->access->submit_command(h, c);
 
 		/* Put job onto the completed Q */
 		addQ(&h->cmpQ, c);
@@ -3444,17 +3444,17 @@ startio:
 
 static inline unsigned long get_next_completion(ctlr_info_t *h)
 {
-	return h->access.command_completed(h);
+	return h->access->command_completed(h);
 }
 
 static inline int interrupt_pending(ctlr_info_t *h)
 {
-	return h->access.intr_pending(h);
+	return h->access->intr_pending(h);
 }
 
 static inline long interrupt_not_for_us(ctlr_info_t *h)
 {
-	return ((h->access.intr_pending(h) == 0) ||
+	return ((h->access->intr_pending(h) == 0) ||
 		(h->interrupts_enabled == 0));
 }
 
@@ -3487,7 +3487,7 @@ static inline u32 next_command(ctlr_info
 	u32 a;
 
 	if (unlikely(!(h->transMethod & CFGTBL_Trans_Performant)))
-		return h->access.command_completed(h);
+		return h->access->command_completed(h);
 
 	if ((*(h->reply_pool_head) & 1) == (h->reply_pool_wraparound)) {
 		a = *(h->reply_pool_head); /* Next cmd in ring buffer */
@@ -4045,7 +4045,7 @@ static void __devinit cciss_put_controll
 		trans_support & CFGTBL_Trans_use_short_tags);
 
 	/* Change the access methods to the performant access methods */
-	h->access = SA5_performant_access;
+	h->access = &SA5_performant_access;
 	h->transMethod = CFGTBL_Trans_Performant;
 
 	return;
@@ -4317,7 +4317,7 @@ static int __devinit cciss_pci_init(ctlr
 	if (prod_index < 0)
 		return -ENODEV;
 	h->product_name = products[prod_index].product_name;
-	h->access = *(products[prod_index].access);
+	h->access = products[prod_index].access;
 
 	if (cciss_board_disabled(h)) {
 		dev_warn(&h->pdev->dev, "controller appears to be disabled\n");
@@ -5042,7 +5042,7 @@ reinit_after_soft_reset:
 	}
 
 	/* make sure the board interrupts are off */
-	h->access.set_intr_mask(h, CCISS_INTR_OFF);
+	h->access->set_intr_mask(h, CCISS_INTR_OFF);
 	rc = cciss_request_irq(h, do_cciss_msix_intr, do_cciss_intx);
 	if (rc)
 		goto clean2;
@@ -5094,7 +5094,7 @@ reinit_after_soft_reset:
 		 * fake ones to scoop up any residual completions.
 		 */
 		spin_lock_irqsave(&h->lock, flags);
-		h->access.set_intr_mask(h, CCISS_INTR_OFF);
+		h->access->set_intr_mask(h, CCISS_INTR_OFF);
 		spin_unlock_irqrestore(&h->lock, flags);
 		free_irq(h->intr[h->intr_mode], h);
 		rc = cciss_request_irq(h, cciss_msix_discard_completions,
@@ -5114,9 +5114,9 @@ reinit_after_soft_reset:
 		dev_info(&h->pdev->dev, "Board READY.\n");
 		dev_info(&h->pdev->dev,
 			"Waiting for stale completions to drain.\n");
-		h->access.set_intr_mask(h, CCISS_INTR_ON);
+		h->access->set_intr_mask(h, CCISS_INTR_ON);
 		msleep(10000);
-		h->access.set_intr_mask(h, CCISS_INTR_OFF);
+		h->access->set_intr_mask(h, CCISS_INTR_OFF);
 
 		rc = controller_reset_failed(h->cfgtable);
 		if (rc)
@@ -5139,7 +5139,7 @@ reinit_after_soft_reset:
 	cciss_scsi_setup(h);
 
 	/* Turn the interrupts on so we can service requests */
-	h->access.set_intr_mask(h, CCISS_INTR_ON);
+	h->access->set_intr_mask(h, CCISS_INTR_ON);
 
 	/* Get the firmware version */
 	inq_buff = kzalloc(sizeof(InquiryData_struct), GFP_KERNEL);
@@ -5212,7 +5212,7 @@ static void cciss_shutdown(struct pci_de
 	kfree(flush_buf);
 	if (return_code != IO_OK)
 		dev_warn(&h->pdev->dev, "Error flushing cache\n");
-	h->access.set_intr_mask(h, CCISS_INTR_OFF);
+	h->access->set_intr_mask(h, CCISS_INTR_OFF);
 	free_irq(h->intr[h->intr_mode], h);
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/block/cciss.h linux-3.2.71-pax/drivers/block/cciss.h
--- linux-3.2.71/drivers/block/cciss.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/block/cciss.h	2012-07-04 19:24:47.696063005 +0200
@@ -101,7 +101,7 @@ struct ctlr_info
 	/* information about each logical volume */
 	drive_info_struct *drv[CISS_MAX_LUN];
 
-	struct access_method access;
+	struct access_method *access;
 
 	/* queue and queue Info */ 
 	struct list_head reqQ;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/block/cpqarray.c linux-3.2.71-pax/drivers/block/cpqarray.c
--- linux-3.2.71/drivers/block/cpqarray.c	2013-10-27 17:59:56.820642408 +0100
+++ linux-3.2.71-pax/drivers/block/cpqarray.c	2013-10-27 18:00:09.448641734 +0100
@@ -404,7 +404,7 @@ static int __devinit cpqarray_register_c
 	if (register_blkdev(COMPAQ_SMART2_MAJOR+i, hba[i]->devname)) {
 		goto Enomem4;
 	}
-	hba[i]->access.set_intr_mask(hba[i], 0);
+	hba[i]->access->set_intr_mask(hba[i], 0);
 	if (request_irq(hba[i]->intr, do_ida_intr,
 		IRQF_DISABLED|IRQF_SHARED, hba[i]->devname, hba[i]))
 	{
@@ -459,7 +459,7 @@ static int __devinit cpqarray_register_c
 	add_timer(&hba[i]->timer);
 
 	/* Enable IRQ now that spinlock and rate limit timer are set up */
-	hba[i]->access.set_intr_mask(hba[i], FIFO_NOT_EMPTY);
+	hba[i]->access->set_intr_mask(hba[i], FIFO_NOT_EMPTY);
 
 	for(j=0; j<NWD; j++) {
 		struct gendisk *disk = ida_gendisk[i][j];
@@ -694,7 +694,7 @@ DBGINFO(
 	for(i=0; i<NR_PRODUCTS; i++) {
 		if (board_id == products[i].board_id) {
 			c->product_name = products[i].product_name;
-			c->access = *(products[i].access);
+			c->access = products[i].access;
 			break;
 		}
 	}
@@ -792,7 +792,7 @@ static int __devinit cpqarray_eisa_detec
 		hba[ctlr]->intr = intr;
 		sprintf(hba[ctlr]->devname, "ida%d", nr_ctlr);
 		hba[ctlr]->product_name = products[j].product_name;
-		hba[ctlr]->access = *(products[j].access);
+		hba[ctlr]->access = products[j].access;
 		hba[ctlr]->ctlr = ctlr;
 		hba[ctlr]->board_id = board_id;
 		hba[ctlr]->pci_dev = NULL; /* not PCI */
@@ -980,7 +980,7 @@ static void start_io(ctlr_info_t *h)
 
 	while((c = h->reqQ) != NULL) {
 		/* Can't do anything if we're busy */
-		if (h->access.fifo_full(h) == 0)
+		if (h->access->fifo_full(h) == 0)
 			return;
 
 		/* Get the first entry from the request Q */
@@ -988,7 +988,7 @@ static void start_io(ctlr_info_t *h)
 		h->Qdepth--;
 	
 		/* Tell the controller to do our bidding */
-		h->access.submit_command(h, c);
+		h->access->submit_command(h, c);
 
 		/* Get onto the completion Q */
 		addQ(&h->cmpQ, c);
@@ -1050,7 +1050,7 @@ static irqreturn_t do_ida_intr(int irq,
 	unsigned long flags;
 	__u32 a,a1;
 
-	istat = h->access.intr_pending(h);
+	istat = h->access->intr_pending(h);
 	/* Is this interrupt for us? */
 	if (istat == 0)
 		return IRQ_NONE;
@@ -1061,7 +1061,7 @@ static irqreturn_t do_ida_intr(int irq,
 	 */
 	spin_lock_irqsave(IDA_LOCK(h->ctlr), flags);
 	if (istat & FIFO_NOT_EMPTY) {
-		while((a = h->access.command_completed(h))) {
+		while((a = h->access->command_completed(h))) {
 			a1 = a; a &= ~3;
 			if ((c = h->cmpQ) == NULL)
 			{  
@@ -1450,11 +1450,11 @@ static int sendcmd(
 	/*
 	 * Disable interrupt
 	 */
-	info_p->access.set_intr_mask(info_p, 0);
+	info_p->access->set_intr_mask(info_p, 0);
 	/* Make sure there is room in the command FIFO */
 	/* Actually it should be completely empty at this time. */
 	for (i = 200000; i > 0; i--) {
-		temp = info_p->access.fifo_full(info_p);
+		temp = info_p->access->fifo_full(info_p);
 		if (temp != 0) {
 			break;
 		}
@@ -1467,7 +1467,7 @@ DBG(
 	/*
 	 * Send the cmd
 	 */
-	info_p->access.submit_command(info_p, c);
+	info_p->access->submit_command(info_p, c);
 	complete = pollcomplete(ctlr);
 	
 	pci_unmap_single(info_p->pci_dev, (dma_addr_t) c->req.sg[0].addr, 
@@ -1550,9 +1550,9 @@ static int revalidate_allvol(ctlr_info_t
 	 * we check the new geometry.  Then turn interrupts back on when
 	 * we're done.
 	 */
-	host->access.set_intr_mask(host, 0);
+	host->access->set_intr_mask(host, 0);
 	getgeometry(ctlr);
-	host->access.set_intr_mask(host, FIFO_NOT_EMPTY);
+	host->access->set_intr_mask(host, FIFO_NOT_EMPTY);
 
 	for(i=0; i<NWD; i++) {
 		struct gendisk *disk = ida_gendisk[ctlr][i];
@@ -1592,7 +1592,7 @@ static int pollcomplete(int ctlr)
 	/* Wait (up to 2 seconds) for a command to complete */
 
 	for (i = 200000; i > 0; i--) {
-		done = hba[ctlr]->access.command_completed(hba[ctlr]);
+		done = hba[ctlr]->access->command_completed(hba[ctlr]);
 		if (done == 0) {
 			udelay(10);	/* a short fixed delay */
 		} else
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/block/cpqarray.h linux-3.2.71-pax/drivers/block/cpqarray.h
--- linux-3.2.71/drivers/block/cpqarray.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/block/cpqarray.h	2012-07-04 19:24:47.696063005 +0200
@@ -99,7 +99,7 @@ struct ctlr_info {
 	drv_info_t	drv[NWD];
 	struct proc_dir_entry *proc;
 
-	struct access_method access;
+	struct access_method *access;
 
 	cmdlist_t *reqQ;
 	cmdlist_t *cmpQ;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/block/drbd/drbd_bitmap.c linux-3.2.71-pax/drivers/block/drbd/drbd_bitmap.c
--- linux-3.2.71/drivers/block/drbd/drbd_bitmap.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/block/drbd/drbd_bitmap.c	2014-09-28 19:38:57.184304993 +0200
@@ -992,7 +992,7 @@ static void bm_page_io_async(struct bm_a
 		submit_bio(rw, bio);
 		/* this should not count as user activity and cause the
 		 * resync to throttle -- see drbd_rs_should_slow_down(). */
-		atomic_add(len >> 9, &mdev->rs_sect_ev);
+		atomic_add_unchecked(len >> 9, &mdev->rs_sect_ev);
 	}
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/block/drbd/drbd_int.h linux-3.2.71-pax/drivers/block/drbd/drbd_int.h
--- linux-3.2.71/drivers/block/drbd/drbd_int.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/block/drbd/drbd_int.h	2014-09-28 19:37:48.988286686 +0200
@@ -736,7 +736,7 @@ struct drbd_request;
 struct drbd_epoch {
 	struct list_head list;
 	unsigned int barrier_nr;
-	atomic_t epoch_size; /* increased on every request added. */
+	atomic_unchecked_t epoch_size; /* increased on every request added. */
 	atomic_t active;     /* increased on every req. added, and dec on every finished. */
 	unsigned long flags;
 };
@@ -1108,7 +1108,7 @@ struct drbd_conf {
 	void *int_dig_in;
 	void *int_dig_vv;
 	wait_queue_head_t seq_wait;
-	atomic_t packet_seq;
+	atomic_unchecked_t packet_seq;
 	unsigned int peer_seq;
 	spinlock_t peer_seq_lock;
 	unsigned int minor;
@@ -1118,8 +1118,8 @@ struct drbd_conf {
 	u64 ed_uuid; /* UUID of the exposed data */
 	struct mutex state_mutex;
 	char congestion_reason;  /* Why we where congested... */
-	atomic_t rs_sect_in; /* for incoming resync data rate, SyncTarget */
-	atomic_t rs_sect_ev; /* for submitted resync data rate, both */
+	atomic_unchecked_t rs_sect_in; /* for incoming resync data rate, SyncTarget */
+	atomic_unchecked_t rs_sect_ev; /* for submitted resync data rate, both */
 	int rs_last_sect_ev; /* counter to compare with */
 	int rs_last_events;  /* counter of read or write "events" (unit sectors)
 			      * on the lower level device when we last looked. */
@@ -1617,30 +1617,30 @@ static inline int drbd_setsockopt(struct
 
 static inline void drbd_tcp_cork(struct socket *sock)
 {
-	int __user val = 1;
+	int val = 1;
 	(void) drbd_setsockopt(sock, SOL_TCP, TCP_CORK,
-			(char __user *)&val, sizeof(val));
+			(char __force_user *)&val, sizeof(val));
 }
 
 static inline void drbd_tcp_uncork(struct socket *sock)
 {
-	int __user val = 0;
+	int val = 0;
 	(void) drbd_setsockopt(sock, SOL_TCP, TCP_CORK,
-			(char __user *)&val, sizeof(val));
+			(char __force_user *)&val, sizeof(val));
 }
 
 static inline void drbd_tcp_nodelay(struct socket *sock)
 {
-	int __user val = 1;
+	int val = 1;
 	(void) drbd_setsockopt(sock, SOL_TCP, TCP_NODELAY,
-			(char __user *)&val, sizeof(val));
+			(char __force_user *)&val, sizeof(val));
 }
 
 static inline void drbd_tcp_quickack(struct socket *sock)
 {
-	int __user val = 2;
+	int val = 2;
 	(void) drbd_setsockopt(sock, SOL_TCP, TCP_QUICKACK,
-			(char __user *)&val, sizeof(val));
+			(char __force_user *)&val, sizeof(val));
 }
 
 void drbd_bump_write_ordering(struct drbd_conf *mdev, enum write_ordering_e wo);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/block/drbd/drbd_main.c linux-3.2.71-pax/drivers/block/drbd/drbd_main.c
--- linux-3.2.71/drivers/block/drbd/drbd_main.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/block/drbd/drbd_main.c	2014-09-28 19:37:59.756289563 +0200
@@ -2397,7 +2397,7 @@ static int _drbd_send_ack(struct drbd_co
 	p.sector   = sector;
 	p.block_id = block_id;
 	p.blksize  = blksize;
-	p.seq_num  = cpu_to_be32(atomic_add_return(1, &mdev->packet_seq));
+	p.seq_num  = cpu_to_be32(atomic_add_return_unchecked(1, &mdev->packet_seq));
 
 	if (!mdev->meta.socket || mdev->state.conn < C_CONNECTED)
 		return false;
@@ -2696,7 +2696,7 @@ int drbd_send_dblock(struct drbd_conf *m
 	p.sector   = cpu_to_be64(req->sector);
 	p.block_id = (unsigned long)req;
 	p.seq_num  = cpu_to_be32(req->seq_num =
-				 atomic_add_return(1, &mdev->packet_seq));
+				 atomic_add_return_unchecked(1, &mdev->packet_seq));
 
 	dp_flags = bio_flags_to_wire(mdev, req->master_bio->bi_rw);
 
@@ -2981,11 +2981,11 @@ void drbd_init_set_defaults(struct drbd_
 	atomic_set(&mdev->unacked_cnt, 0);
 	atomic_set(&mdev->local_cnt, 0);
 	atomic_set(&mdev->net_cnt, 0);
-	atomic_set(&mdev->packet_seq, 0);
+	atomic_set_unchecked(&mdev->packet_seq, 0);
 	atomic_set(&mdev->pp_in_use, 0);
 	atomic_set(&mdev->pp_in_use_by_net, 0);
-	atomic_set(&mdev->rs_sect_in, 0);
-	atomic_set(&mdev->rs_sect_ev, 0);
+	atomic_set_unchecked(&mdev->rs_sect_in, 0);
+	atomic_set_unchecked(&mdev->rs_sect_ev, 0);
 	atomic_set(&mdev->ap_in_flight, 0);
 
 	mutex_init(&mdev->md_io_mutex);
@@ -3063,8 +3063,8 @@ void drbd_mdev_cleanup(struct drbd_conf
 				mdev->receiver.t_state);
 
 	/* no need to lock it, I'm the only thread alive */
-	if (atomic_read(&mdev->current_epoch->epoch_size) !=  0)
-		dev_err(DEV, "epoch_size:%d\n", atomic_read(&mdev->current_epoch->epoch_size));
+	if (atomic_read_unchecked(&mdev->current_epoch->epoch_size) !=  0)
+		dev_err(DEV, "epoch_size:%d\n", atomic_read_unchecked(&mdev->current_epoch->epoch_size));
 	mdev->al_writ_cnt  =
 	mdev->bm_writ_cnt  =
 	mdev->read_cnt     =
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/block/drbd/drbd_nl.c linux-3.2.71-pax/drivers/block/drbd/drbd_nl.c
--- linux-3.2.71/drivers/block/drbd/drbd_nl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/block/drbd/drbd_nl.c	2012-07-04 19:24:47.700063004 +0200
@@ -2359,7 +2359,7 @@ static void drbd_connector_callback(stru
 	module_put(THIS_MODULE);
 }
 
-static atomic_t drbd_nl_seq = ATOMIC_INIT(2); /* two. */
+static atomic_unchecked_t drbd_nl_seq = ATOMIC_INIT(2); /* two. */
 
 static unsigned short *
 __tl_add_blob(unsigned short *tl, enum drbd_tags tag, const void *data,
@@ -2430,7 +2430,7 @@ void drbd_bcast_state(struct drbd_conf *
 	cn_reply->id.idx = CN_IDX_DRBD;
 	cn_reply->id.val = CN_VAL_DRBD;
 
-	cn_reply->seq = atomic_add_return(1, &drbd_nl_seq);
+	cn_reply->seq = atomic_add_return_unchecked(1, &drbd_nl_seq);
 	cn_reply->ack = 0; /* not used here. */
 	cn_reply->len = sizeof(struct drbd_nl_cfg_reply) +
 		(int)((char *)tl - (char *)reply->tag_list);
@@ -2462,7 +2462,7 @@ void drbd_bcast_ev_helper(struct drbd_co
 	cn_reply->id.idx = CN_IDX_DRBD;
 	cn_reply->id.val = CN_VAL_DRBD;
 
-	cn_reply->seq = atomic_add_return(1, &drbd_nl_seq);
+	cn_reply->seq = atomic_add_return_unchecked(1, &drbd_nl_seq);
 	cn_reply->ack = 0; /* not used here. */
 	cn_reply->len = sizeof(struct drbd_nl_cfg_reply) +
 		(int)((char *)tl - (char *)reply->tag_list);
@@ -2540,7 +2540,7 @@ void drbd_bcast_ee(struct drbd_conf *mde
 	cn_reply->id.idx = CN_IDX_DRBD;
 	cn_reply->id.val = CN_VAL_DRBD;
 
-	cn_reply->seq = atomic_add_return(1,&drbd_nl_seq);
+	cn_reply->seq = atomic_add_return_unchecked(1,&drbd_nl_seq);
 	cn_reply->ack = 0; // not used here.
 	cn_reply->len = sizeof(struct drbd_nl_cfg_reply) +
 		(int)((char*)tl - (char*)reply->tag_list);
@@ -2579,7 +2579,7 @@ void drbd_bcast_sync_progress(struct drb
 	cn_reply->id.idx = CN_IDX_DRBD;
 	cn_reply->id.val = CN_VAL_DRBD;
 
-	cn_reply->seq = atomic_add_return(1, &drbd_nl_seq);
+	cn_reply->seq = atomic_add_return_unchecked(1, &drbd_nl_seq);
 	cn_reply->ack = 0; /* not used here. */
 	cn_reply->len = sizeof(struct drbd_nl_cfg_reply) +
 		(int)((char *)tl - (char *)reply->tag_list);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/block/drbd/drbd_receiver.c linux-3.2.71-pax/drivers/block/drbd/drbd_receiver.c
--- linux-3.2.71/drivers/block/drbd/drbd_receiver.c	2013-06-09 18:04:43.201591760 +0200
+++ linux-3.2.71-pax/drivers/block/drbd/drbd_receiver.c	2014-09-28 19:38:26.572297698 +0200
@@ -894,7 +894,7 @@ retry:
 	sock->sk->sk_sndtimeo = mdev->net_conf->timeout*HZ/10;
 	sock->sk->sk_rcvtimeo = MAX_SCHEDULE_TIMEOUT;
 
-	atomic_set(&mdev->packet_seq, 0);
+	atomic_set_unchecked(&mdev->packet_seq, 0);
 	mdev->peer_seq = 0;
 
 	drbd_thread_start(&mdev->asender);
@@ -985,7 +985,7 @@ static enum finish_epoch drbd_may_finish
 	do {
 		next_epoch = NULL;
 
-		epoch_size = atomic_read(&epoch->epoch_size);
+		epoch_size = atomic_read_unchecked(&epoch->epoch_size);
 
 		switch (ev & ~EV_CLEANUP) {
 		case EV_PUT:
@@ -1020,7 +1020,7 @@ static enum finish_epoch drbd_may_finish
 					rv = FE_DESTROYED;
 			} else {
 				epoch->flags = 0;
-				atomic_set(&epoch->epoch_size, 0);
+				atomic_set_unchecked(&epoch->epoch_size, 0);
 				/* atomic_set(&epoch->active, 0); is already zero */
 				if (rv == FE_STILL_LIVE)
 					rv = FE_RECYCLED;
@@ -1191,14 +1191,14 @@ static int receive_Barrier(struct drbd_c
 		drbd_wait_ee_list_empty(mdev, &mdev->active_ee);
 		drbd_flush(mdev);
 
-		if (atomic_read(&mdev->current_epoch->epoch_size)) {
+		if (atomic_read_unchecked(&mdev->current_epoch->epoch_size)) {
 			epoch = kmalloc(sizeof(struct drbd_epoch), GFP_NOIO);
 			if (epoch)
 				break;
 		}
 
 		epoch = mdev->current_epoch;
-		wait_event(mdev->ee_wait, atomic_read(&epoch->epoch_size) == 0);
+		wait_event(mdev->ee_wait, atomic_read_unchecked(&epoch->epoch_size) == 0);
 
 		D_ASSERT(atomic_read(&epoch->active) == 0);
 		D_ASSERT(epoch->flags == 0);
@@ -1210,11 +1210,11 @@ static int receive_Barrier(struct drbd_c
 	}
 
 	epoch->flags = 0;
-	atomic_set(&epoch->epoch_size, 0);
+	atomic_set_unchecked(&epoch->epoch_size, 0);
 	atomic_set(&epoch->active, 0);
 
 	spin_lock(&mdev->epoch_lock);
-	if (atomic_read(&mdev->current_epoch->epoch_size)) {
+	if (atomic_read_unchecked(&mdev->current_epoch->epoch_size)) {
 		list_add(&epoch->list, &mdev->current_epoch->list);
 		mdev->current_epoch = epoch;
 		mdev->epochs++;
@@ -1449,7 +1449,7 @@ static int recv_resync_read(struct drbd_
 	list_add(&e->w.list, &mdev->sync_ee);
 	spin_unlock_irq(&mdev->req_lock);
 
-	atomic_add(data_size >> 9, &mdev->rs_sect_ev);
+	atomic_add_unchecked(data_size >> 9, &mdev->rs_sect_ev);
 	if (drbd_submit_ee(mdev, e, WRITE, DRBD_FAULT_RS_WR) == 0)
 		return true;
 
@@ -1519,7 +1519,7 @@ static int receive_RSDataReply(struct dr
 		drbd_send_ack_dp(mdev, P_NEG_ACK, p, data_size);
 	}
 
-	atomic_add(data_size >> 9, &mdev->rs_sect_in);
+	atomic_add_unchecked(data_size >> 9, &mdev->rs_sect_in);
 
 	return ok;
 }
@@ -1663,7 +1663,7 @@ static int receive_Data(struct drbd_conf
 		spin_unlock(&mdev->peer_seq_lock);
 
 		drbd_send_ack_dp(mdev, P_NEG_ACK, p, data_size);
-		atomic_inc(&mdev->current_epoch->epoch_size);
+		atomic_inc_unchecked(&mdev->current_epoch->epoch_size);
 		return drbd_drain_block(mdev, data_size);
 	}
 
@@ -1689,7 +1689,7 @@ static int receive_Data(struct drbd_conf
 
 	spin_lock(&mdev->epoch_lock);
 	e->epoch = mdev->current_epoch;
-	atomic_inc(&e->epoch->epoch_size);
+	atomic_inc_unchecked(&e->epoch->epoch_size);
 	atomic_inc(&e->epoch->active);
 	spin_unlock(&mdev->epoch_lock);
 
@@ -1906,7 +1906,7 @@ int drbd_rs_should_slow_down(struct drbd
 
 	curr_events = (int)part_stat_read(&disk->part0, sectors[0]) +
 		      (int)part_stat_read(&disk->part0, sectors[1]) -
-			atomic_read(&mdev->rs_sect_ev);
+			atomic_read_unchecked(&mdev->rs_sect_ev);
 
 	if (!mdev->rs_last_events || curr_events - mdev->rs_last_events > 64) {
 		unsigned long rs_left;
@@ -2034,7 +2034,7 @@ static int receive_DataRequest(struct dr
 			mdev->bm_resync_fo = BM_SECT_TO_BIT(sector);
 		} else if (cmd == P_OV_REPLY) {
 			/* track progress, we may need to throttle */
-			atomic_add(size >> 9, &mdev->rs_sect_in);
+			atomic_add_unchecked(size >> 9, &mdev->rs_sect_in);
 			e->w.cb = w_e_end_ov_reply;
 			dec_rs_pending(mdev);
 			/* drbd_rs_begin_io done when we sent this request,
@@ -2098,7 +2098,7 @@ static int receive_DataRequest(struct dr
 		goto out_free_e;
 
 submit_for_resync:
-	atomic_add(size >> 9, &mdev->rs_sect_ev);
+	atomic_add_unchecked(size >> 9, &mdev->rs_sect_ev);
 
 submit:
 	inc_unacked(mdev);
@@ -3637,7 +3637,7 @@ struct data_cmd {
 	int expect_payload;
 	size_t pkt_size;
 	drbd_cmd_handler_f function;
-};
+} __do_const;
 
 static struct data_cmd drbd_cmd_handler[] = {
 	[P_DATA]	    = { 1, sizeof(struct p_data), receive_Data },
@@ -3884,7 +3884,7 @@ static void drbd_disconnect(struct drbd_
 	D_ASSERT(list_empty(&mdev->done_ee));
 
 	/* ok, no more ee's on the fly, it is safe to reset the epoch_size */
-	atomic_set(&mdev->current_epoch->epoch_size, 0);
+	atomic_set_unchecked(&mdev->current_epoch->epoch_size, 0);
 	D_ASSERT(list_empty(&mdev->current_epoch->list));
 }
 
@@ -4240,7 +4240,7 @@ static int got_IsInSync(struct drbd_conf
 		put_ldev(mdev);
 	}
 	dec_rs_pending(mdev);
-	atomic_add(blksize >> 9, &mdev->rs_sect_in);
+	atomic_add_unchecked(blksize >> 9, &mdev->rs_sect_in);
 
 	return true;
 }
@@ -4492,7 +4492,7 @@ static int got_skip(struct drbd_conf *md
 struct asender_cmd {
 	size_t pkt_size;
 	int (*process)(struct drbd_conf *mdev, struct p_header80 *h);
-};
+} __do_const;
 
 static struct asender_cmd *get_asender_cmd(int cmd)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/block/drbd/drbd_worker.c linux-3.2.71-pax/drivers/block/drbd/drbd_worker.c
--- linux-3.2.71/drivers/block/drbd/drbd_worker.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/block/drbd/drbd_worker.c	2014-09-28 19:38:46.352300706 +0200
@@ -368,7 +368,7 @@ static int read_for_csum(struct drbd_con
 	list_add(&e->w.list, &mdev->read_ee);
 	spin_unlock_irq(&mdev->req_lock);
 
-	atomic_add(size >> 9, &mdev->rs_sect_ev);
+	atomic_add_unchecked(size >> 9, &mdev->rs_sect_ev);
 	if (drbd_submit_ee(mdev, e, READ, DRBD_FAULT_RS_RD) == 0)
 		return 0;
 
@@ -448,7 +448,7 @@ static int drbd_rs_controller(struct drb
 	int curr_corr;
 	int max_sect;
 
-	sect_in = atomic_xchg(&mdev->rs_sect_in, 0); /* Number of sectors that came in */
+	sect_in = atomic_xchg_unchecked(&mdev->rs_sect_in, 0); /* Number of sectors that came in */
 	mdev->rs_in_flight -= sect_in;
 
 	spin_lock(&mdev->peer_seq_lock); /* get an atomic view on mdev->rs_plan_s */
@@ -1455,8 +1455,8 @@ int drbd_alter_sa(struct drbd_conf *mdev
 
 void drbd_rs_controller_reset(struct drbd_conf *mdev)
 {
-	atomic_set(&mdev->rs_sect_in, 0);
-	atomic_set(&mdev->rs_sect_ev, 0);
+	atomic_set_unchecked(&mdev->rs_sect_in, 0);
+	atomic_set_unchecked(&mdev->rs_sect_ev, 0);
 	mdev->rs_in_flight = 0;
 	mdev->rs_planed = 0;
 	spin_lock(&mdev->peer_seq_lock);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/block/loop.c linux-3.2.71-pax/drivers/block/loop.c
--- linux-3.2.71/drivers/block/loop.c	2014-01-03 15:48:44.700070580 +0100
+++ linux-3.2.71-pax/drivers/block/loop.c	2014-01-03 15:48:49.516070323 +0100
@@ -227,7 +227,7 @@ static int __do_lo_send_write(struct fil
 	mm_segment_t old_fs = get_fs();
 
 	set_fs(get_ds());
-	bw = file->f_op->write(file, buf, len, &pos);
+	bw = file->f_op->write(file, (const char __force_user *)buf, len, &pos);
 	set_fs(old_fs);
 	if (likely(bw == len))
 		return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/block/pktcdvd.c linux-3.2.71-pax/drivers/block/pktcdvd.c
--- linux-3.2.71/drivers/block/pktcdvd.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/block/pktcdvd.c	2013-04-30 00:31:29.983758240 +0200
@@ -83,7 +83,7 @@
 
 #define MAX_SPEED 0xffff
 
-#define ZONE(sector, pd) (((sector) + (pd)->offset) & ~((pd)->settings.size - 1))
+#define ZONE(sector, pd) (((sector) + (pd)->offset) & ~((pd)->settings.size - 1UL))
 
 static DEFINE_MUTEX(pktcdvd_mutex);
 static struct pktcdvd_device *pkt_devs[MAX_WRITERS];
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/bluetooth/btwilink.c linux-3.2.71-pax/drivers/bluetooth/btwilink.c
--- linux-3.2.71/drivers/bluetooth/btwilink.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/bluetooth/btwilink.c	2013-11-12 01:26:18.081407001 +0100
@@ -301,7 +301,7 @@ static void ti_st_destruct(struct hci_de
 
 static int bt_ti_probe(struct platform_device *pdev)
 {
-	static struct ti_st *hst;
+	struct ti_st *hst;
 	struct hci_dev *hdev;
 	int err;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/cdrom/cdrom.c linux-3.2.71-pax/drivers/cdrom/cdrom.c
--- linux-3.2.71/drivers/cdrom/cdrom.c	2013-07-27 11:12:22.295992805 +0200
+++ linux-3.2.71-pax/drivers/cdrom/cdrom.c	2013-07-27 11:12:26.575992576 +0200
@@ -419,7 +419,6 @@ int register_cdrom(struct cdrom_device_i
 	ENSURE(reset, CDC_RESET);
 	ENSURE(generic_packet, CDC_GENERIC_PACKET);
 	cdi->mc_flags = 0;
-	cdo->n_minors = 0;
         cdi->options = CDO_USE_FFLAGS;
 	
 	if (autoclose==1 && CDROM_CAN(CDC_CLOSE_TRAY))
@@ -439,8 +438,11 @@ int register_cdrom(struct cdrom_device_i
 	else
 		cdi->cdda_method = CDDA_OLD;
 
-	if (!cdo->generic_packet)
-		cdo->generic_packet = cdrom_dummy_generic_packet;
+	if (!cdo->generic_packet) {
+		pax_open_kernel();
+		*(void **)&cdo->generic_packet = cdrom_dummy_generic_packet;
+		pax_close_kernel();
+	}
 
 	cdinfo(CD_REG_UNREG, "drive \"/dev/%s\" registered\n", cdi->name);
 	mutex_lock(&cdrom_mutex);
@@ -461,7 +463,6 @@ void unregister_cdrom(struct cdrom_devic
 	if (cdi->exit)
 		cdi->exit(cdi);
 
-	cdi->ops->n_minors--;
 	cdinfo(CD_REG_UNREG, "drive \"/dev/%s\" unregistered\n", cdi->name);
 }
 
@@ -3432,7 +3433,7 @@ static int cdrom_print_info(const char *
 	struct cdrom_device_info *cdi;
 	int ret;
 
-	ret = scnprintf(info + *pos, max_size - *pos, header);
+	ret = scnprintf(info + *pos, max_size - *pos, "%s", header);
 	if (!ret)
 		return 1;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/cdrom/gdrom.c linux-3.2.71-pax/drivers/cdrom/gdrom.c
--- linux-3.2.71/drivers/cdrom/gdrom.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/cdrom/gdrom.c	2013-01-16 21:27:01.694837016 +0100
@@ -491,7 +491,6 @@ static struct cdrom_device_ops gdrom_ops
 	.audio_ioctl		= gdrom_audio_ioctl,
 	.capability		= CDC_MULTI_SESSION | CDC_MEDIA_CHANGED |
 				  CDC_RESET | CDC_DRIVE_STATUS | CDC_CD_R,
-	.n_minors		= 1,
 };
 
 static int gdrom_bdops_open(struct block_device *bdev, fmode_t mode)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/agp/compat_ioctl.c linux-3.2.71-pax/drivers/char/agp/compat_ioctl.c
--- linux-3.2.71/drivers/char/agp/compat_ioctl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/char/agp/compat_ioctl.c	2013-06-21 19:34:10.634698102 +0200
@@ -108,7 +108,7 @@ static int compat_agpioc_reserve_wrap(st
 			return -ENOMEM;
 		}
 
-		if (copy_from_user(usegment, (void __user *) ureserve.seg_list,
+		if (copy_from_user(usegment, (void __force_user *) ureserve.seg_list,
 				   sizeof(*usegment) * ureserve.seg_count)) {
 			kfree(usegment);
 			kfree(ksegment);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/agp/frontend.c linux-3.2.71-pax/drivers/char/agp/frontend.c
--- linux-3.2.71/drivers/char/agp/frontend.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/char/agp/frontend.c	2013-06-21 19:34:10.290698121 +0200
@@ -817,7 +817,7 @@ static int agpioc_reserve_wrap(struct ag
 	if (copy_from_user(&reserve, arg, sizeof(struct agp_region)))
 		return -EFAULT;
 
-	if ((unsigned) reserve.seg_count >= ~0U/sizeof(struct agp_segment))
+	if ((unsigned) reserve.seg_count >= ~0U/sizeof(struct agp_segment_priv))
 		return -EFAULT;
 
 	client = agp_find_client_by_pid(reserve.pid);
@@ -847,7 +847,7 @@ static int agpioc_reserve_wrap(struct ag
 		if (segment == NULL)
 			return -ENOMEM;
 
-		if (copy_from_user(segment, (void __user *) reserve.seg_list,
+		if (copy_from_user(segment, (void __force_user *) reserve.seg_list,
 				   sizeof(struct agp_segment) * reserve.seg_count)) {
 			kfree(segment);
 			return -EFAULT;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/hpet.c linux-3.2.71-pax/drivers/char/hpet.c
--- linux-3.2.71/drivers/char/hpet.c	2013-05-14 13:33:40.536285677 +0200
+++ linux-3.2.71-pax/drivers/char/hpet.c	2013-05-14 13:33:46.524285357 +0200
@@ -560,7 +560,7 @@ static inline unsigned long hpet_time_di
 }
 
 static int
-hpet_ioctl_common(struct hpet_dev *devp, int cmd, unsigned long arg,
+hpet_ioctl_common(struct hpet_dev *devp, unsigned int cmd, unsigned long arg,
 		  struct hpet_info *info)
 {
 	struct hpet_timer __iomem *timer;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/hw_random/intel-rng.c linux-3.2.71-pax/drivers/char/hw_random/intel-rng.c
--- linux-3.2.71/drivers/char/hw_random/intel-rng.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/char/hw_random/intel-rng.c	2013-06-21 20:15:56.434564312 +0200
@@ -314,7 +314,7 @@ PFX "RNG, try using the 'no_fwh_detect'
 
 		if (no_fwh_detect)
 			return -ENODEV;
-		printk(warning);
+		printk("%s", warning);
 		return -EBUSY;
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/i8k.c linux-3.2.71-pax/drivers/char/i8k.c
--- linux-3.2.71/drivers/char/i8k.c	2014-01-03 15:48:44.712070579 +0100
+++ linux-3.2.71-pax/drivers/char/i8k.c	2015-04-30 03:12:29.440540952 +0200
@@ -607,7 +607,7 @@ static void __exit i8k_exit_hwmon(void)
 	hwmon_device_unregister(i8k_hwmon_dev);
 }
 
-static struct dmi_system_id __initdata i8k_dmi_table[] = {
+static const struct dmi_system_id __initconst i8k_dmi_table[] = {
 	{
 		.ident = "Dell Inspiron",
 		.matches = {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/ipmi/ipmi_msghandler.c linux-3.2.71-pax/drivers/char/ipmi/ipmi_msghandler.c
--- linux-3.2.71/drivers/char/ipmi/ipmi_msghandler.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/char/ipmi/ipmi_msghandler.c	2012-07-04 19:24:47.708063005 +0200
@@ -415,7 +415,7 @@ struct ipmi_smi {
 	struct proc_dir_entry *proc_dir;
 	char                  proc_dir_name[10];
 
-	atomic_t stats[IPMI_NUM_STATS];
+	atomic_unchecked_t stats[IPMI_NUM_STATS];
 
 	/*
 	 * run_to_completion duplicate of smb_info, smi_info
@@ -448,9 +448,9 @@ static DEFINE_MUTEX(smi_watchers_mutex);
 
 
 #define ipmi_inc_stat(intf, stat) \
-	atomic_inc(&(intf)->stats[IPMI_STAT_ ## stat])
+	atomic_inc_unchecked(&(intf)->stats[IPMI_STAT_ ## stat])
 #define ipmi_get_stat(intf, stat) \
-	((unsigned int) atomic_read(&(intf)->stats[IPMI_STAT_ ## stat]))
+	((unsigned int) atomic_read_unchecked(&(intf)->stats[IPMI_STAT_ ## stat]))
 
 static int is_lan_addr(struct ipmi_addr *addr)
 {
@@ -2868,7 +2868,7 @@ int ipmi_register_smi(struct ipmi_smi_ha
 	INIT_LIST_HEAD(&intf->cmd_rcvrs);
 	init_waitqueue_head(&intf->waitq);
 	for (i = 0; i < IPMI_NUM_STATS; i++)
-		atomic_set(&intf->stats[i], 0);
+		atomic_set_unchecked(&intf->stats[i], 0);
 
 	intf->proc_dir = NULL;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/ipmi/ipmi_si_intf.c linux-3.2.71-pax/drivers/char/ipmi/ipmi_si_intf.c
--- linux-3.2.71/drivers/char/ipmi/ipmi_si_intf.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/char/ipmi/ipmi_si_intf.c	2012-07-04 19:24:47.708063005 +0200
@@ -277,7 +277,7 @@ struct smi_info {
 	unsigned char slave_addr;
 
 	/* Counters and things for the proc filesystem. */
-	atomic_t stats[SI_NUM_STATS];
+	atomic_unchecked_t stats[SI_NUM_STATS];
 
 	struct task_struct *thread;
 
@@ -286,9 +286,9 @@ struct smi_info {
 };
 
 #define smi_inc_stat(smi, stat) \
-	atomic_inc(&(smi)->stats[SI_STAT_ ## stat])
+	atomic_inc_unchecked(&(smi)->stats[SI_STAT_ ## stat])
 #define smi_get_stat(smi, stat) \
-	((unsigned int) atomic_read(&(smi)->stats[SI_STAT_ ## stat]))
+	((unsigned int) atomic_read_unchecked(&(smi)->stats[SI_STAT_ ## stat]))
 
 #define SI_MAX_PARMS 4
 
@@ -3230,7 +3230,7 @@ static int try_smi_init(struct smi_info
 	atomic_set(&new_smi->req_events, 0);
 	new_smi->run_to_completion = 0;
 	for (i = 0; i < SI_NUM_STATS; i++)
-		atomic_set(&new_smi->stats[i], 0);
+		atomic_set_unchecked(&new_smi->stats[i], 0);
 
 	new_smi->interrupt_disabled = 1;
 	atomic_set(&new_smi->stop_operation, 0);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/mbcs.c linux-3.2.71-pax/drivers/char/mbcs.c
--- linux-3.2.71/drivers/char/mbcs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/char/mbcs.c	2012-07-04 19:24:47.708063005 +0200
@@ -800,7 +800,7 @@ static int mbcs_remove(struct cx_dev *de
 	return 0;
 }
 
-static const struct cx_device_id __devinitdata mbcs_id_table[] = {
+static const struct cx_device_id __devinitconst mbcs_id_table[] = {
 	{
 	 .part_num = MBCS_PART_NUM,
 	 .mfg_num = MBCS_MFG_NUM,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/mem.c linux-3.2.71-pax/drivers/char/mem.c
--- linux-3.2.71/drivers/char/mem.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/char/mem.c	2015-02-20 12:17:09.473244107 +0100
@@ -117,7 +117,8 @@ static ssize_t read_mem(struct file *fil
 #endif
 
 	while (count > 0) {
-		unsigned long remaining;
+		unsigned long remaining = 0;
+		char *temp;
 
 		sz = size_inside_page(p, count);
 
@@ -133,7 +134,24 @@ static ssize_t read_mem(struct file *fil
 		if (!ptr)
 			return -EFAULT;
 
-		remaining = copy_to_user(buf, ptr, sz);
+#ifdef CONFIG_PAX_USERCOPY
+		temp = kmalloc(sz, GFP_KERNEL|GFP_USERCOPY);
+		if (!temp) {
+			unxlate_dev_mem_ptr(p, ptr);
+			return -ENOMEM;
+		}
+		remaining = probe_kernel_read(temp, ptr, sz);
+#else
+		temp = ptr;
+#endif
+
+		if (!remaining)
+			remaining = copy_to_user(buf, temp, sz);
+
+#ifdef CONFIG_PAX_USERCOPY
+		kfree(temp);
+#endif
+
 		unxlate_dev_mem_ptr(p, ptr);
 		if (remaining)
 			return -EFAULT;
@@ -376,7 +394,7 @@ static ssize_t read_oldmem(struct file *
 		else
 			csize = count;
 
-		rc = copy_oldmem_page(pfn, buf, csize, offset, 1);
+		rc = copy_oldmem_page(pfn, (char __force_kernel *)buf, csize, offset, 1);
 		if (rc < 0)
 			return rc;
 		buf += csize;
@@ -396,9 +414,8 @@ static ssize_t read_kmem(struct file *fi
 			 size_t count, loff_t *ppos)
 {
 	unsigned long p = *ppos;
-	ssize_t low_count, read, sz;
+	ssize_t low_count, read, sz, err = 0;
 	char * kbuf; /* k-addr because vread() takes vmlist_lock rwlock */
-	int err = 0;
 
 	read = 0;
 	if (p < (unsigned long) high_memory) {
@@ -420,6 +437,8 @@ static ssize_t read_kmem(struct file *fi
 		}
 #endif
 		while (low_count > 0) {
+			char *temp;
+
 			sz = size_inside_page(p, low_count);
 
 			/*
@@ -429,7 +448,23 @@ static ssize_t read_kmem(struct file *fi
 			 */
 			kbuf = xlate_dev_kmem_ptr((char *)p);
 
-			if (copy_to_user(buf, kbuf, sz))
+#ifdef CONFIG_PAX_USERCOPY
+			temp = kmalloc(sz, GFP_KERNEL|GFP_USERCOPY);
+			if (!temp)
+				return -ENOMEM;
+			err = probe_kernel_read(temp, kbuf, sz);
+#else
+			temp = kbuf;
+#endif
+
+			if (!err)
+				err = copy_to_user(buf, temp, sz);
+
+#ifdef CONFIG_PAX_USERCOPY
+			kfree(temp);
+#endif
+
+			if (err)
 				return -EFAULT;
 			buf += sz;
 			p += sz;
@@ -931,7 +966,7 @@ static int __init chr_dev_init(void)
 		if (!devlist[minor].name)
 			continue;
 		device_create(mem_class, NULL, MKDEV(MEM_MAJOR, minor),
-			      NULL, devlist[minor].name);
+			      NULL, "%s", devlist[minor].name);
 	}
 
 	return tty_init();
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/nvram.c linux-3.2.71-pax/drivers/char/nvram.c
--- linux-3.2.71/drivers/char/nvram.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/char/nvram.c	2012-07-04 19:24:47.712063005 +0200
@@ -248,7 +248,7 @@ static ssize_t nvram_read(struct file *f
 
 	spin_unlock_irq(&rtc_lock);
 
-	if (copy_to_user(buf, contents, tmp - contents))
+	if (tmp - contents > sizeof(contents) || copy_to_user(buf, contents, tmp - contents))
 		return -EFAULT;
 
 	*ppos = i;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/random.c linux-3.2.71-pax/drivers/char/random.c
--- linux-3.2.71/drivers/char/random.c	2014-12-14 21:13:45.050054795 +0100
+++ linux-3.2.71-pax/drivers/char/random.c	2014-12-14 21:13:52.770069218 +0100
@@ -437,9 +437,9 @@ struct entropy_store {
 	__u8 last_data[EXTRACT_SIZE];
 };
 
-static __u32 input_pool_data[INPUT_POOL_WORDS];
-static __u32 blocking_pool_data[OUTPUT_POOL_WORDS];
-static __u32 nonblocking_pool_data[OUTPUT_POOL_WORDS];
+static __u32 input_pool_data[INPUT_POOL_WORDS] __latent_entropy;
+static __u32 blocking_pool_data[OUTPUT_POOL_WORDS] __latent_entropy;
+static __u32 nonblocking_pool_data[OUTPUT_POOL_WORDS] __latent_entropy;
 
 static struct entropy_store input_pool = {
 	.poolinfo = &poolinfo_table[0],
@@ -524,8 +524,8 @@ static void __mix_pool_bytes(struct entr
 		input_rotate += i ? 7 : 14;
 	}
 
-	ACCESS_ONCE(r->input_rotate) = input_rotate;
-	ACCESS_ONCE(r->add_ptr) = i;
+	ACCESS_ONCE_RW(r->input_rotate) = input_rotate;
+	ACCESS_ONCE_RW(r->add_ptr) = i;
 	smp_wmb();
 
 	if (out)
@@ -1036,7 +1036,7 @@ static ssize_t extract_entropy_user(stru
 
 		extract_buf(r, tmp);
 		i = min_t(int, nbytes, EXTRACT_SIZE);
-		if (copy_to_user(buf, tmp, i)) {
+		if (i > sizeof(tmp) || copy_to_user(buf, tmp, i)) {
 			ret = -EFAULT;
 			break;
 		}
@@ -1387,7 +1387,7 @@ EXPORT_SYMBOL(generate_random_uuid);
 #include <linux/sysctl.h>
 
 static int min_read_thresh = 8, min_write_thresh;
-static int max_read_thresh = INPUT_POOL_WORDS * 32;
+static int max_read_thresh = OUTPUT_POOL_WORDS * 32;
 static int max_write_thresh = INPUT_POOL_WORDS * 32;
 static char sysctl_bootid[16];
 
@@ -1403,7 +1403,7 @@ static char sysctl_bootid[16];
 static int proc_do_uuid(ctl_table *table, int write,
 			void __user *buffer, size_t *lenp, loff_t *ppos)
 {
-	ctl_table fake_table;
+	ctl_table_no_const fake_table;
 	unsigned char buf[64], tmp_uuid[16], *uuid;
 
 	uuid = table->data;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/sonypi.c linux-3.2.71-pax/drivers/char/sonypi.c
--- linux-3.2.71/drivers/char/sonypi.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/char/sonypi.c	2015-04-30 03:07:38.396532395 +0200
@@ -55,6 +55,7 @@
 #include <asm/uaccess.h>
 #include <asm/io.h>
 #include <asm/system.h>
+#include <asm/local.h>
 
 #include <linux/sonypi.h>
 
@@ -491,7 +492,7 @@ static struct sonypi_device {
 	spinlock_t fifo_lock;
 	wait_queue_head_t fifo_proc_list;
 	struct fasync_struct *fifo_async;
-	int open_count;
+	local_t open_count;
 	int model;
 	struct input_dev *input_jog_dev;
 	struct input_dev *input_key_dev;
@@ -898,7 +899,7 @@ static int sonypi_misc_fasync(int fd, st
 static int sonypi_misc_release(struct inode *inode, struct file *file)
 {
 	mutex_lock(&sonypi_device.lock);
-	sonypi_device.open_count--;
+	local_dec(&sonypi_device.open_count);
 	mutex_unlock(&sonypi_device.lock);
 	return 0;
 }
@@ -907,9 +908,9 @@ static int sonypi_misc_open(struct inode
 {
 	mutex_lock(&sonypi_device.lock);
 	/* Flush input queue on first open */
-	if (!sonypi_device.open_count)
+	if (!local_read(&sonypi_device.open_count))
 		kfifo_reset(&sonypi_device.fifo);
-	sonypi_device.open_count++;
+	local_inc(&sonypi_device.open_count);
 	mutex_unlock(&sonypi_device.lock);
 
 	return 0;
@@ -1497,7 +1498,7 @@ static struct platform_driver sonypi_dri
 
 static struct platform_device *sonypi_platform_device;
 
-static struct dmi_system_id __initdata sonypi_dmi_table[] = {
+static const struct dmi_system_id __initconst sonypi_dmi_table[] = {
 	{
 		.ident = "Sony Vaio",
 		.matches = {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/tpm/tpm_bios.c linux-3.2.71-pax/drivers/char/tpm/tpm_bios.c
--- linux-3.2.71/drivers/char/tpm/tpm_bios.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/char/tpm/tpm_bios.c	2012-07-04 19:24:47.712063005 +0200
@@ -173,7 +173,7 @@ static void *tpm_bios_measurements_start
 	event = addr;
 
 	if ((event->event_type == 0 && event->event_size == 0) ||
-	    ((addr + sizeof(struct tcpa_event) + event->event_size) >= limit))
+	    (event->event_size >= limit - addr - sizeof(struct tcpa_event)))
 		return NULL;
 
 	return addr;
@@ -198,7 +198,7 @@ static void *tpm_bios_measurements_next(
 		return NULL;
 
 	if ((event->event_type == 0 && event->event_size == 0) ||
-	    ((v + sizeof(struct tcpa_event) + event->event_size) >= limit))
+	    (event->event_size >= limit - v - sizeof(struct tcpa_event)))
 		return NULL;
 
 	(*pos)++;
@@ -291,7 +291,8 @@ static int tpm_binary_bios_measurements_
 	int i;
 
 	for (i = 0; i < sizeof(struct tcpa_event) + event->event_size; i++)
-		seq_putc(m, data[i]);
+		if (!seq_putc(m, data[i]))
+			return -EFAULT;
 
 	return 0;
 }
@@ -410,8 +411,13 @@ static int read_log(struct tpm_bios_log
 	log->bios_event_log_end = log->bios_event_log + len;
 
 	virt = acpi_os_map_memory(start, len);
+	if (!virt) {
+		kfree(log->bios_event_log);
+		log->bios_event_log = NULL;
+		return -EFAULT;
+	}
 
-	memcpy(log->bios_event_log, virt, len);
+	memcpy(log->bios_event_log, (const char __force_kernel *)virt, len);
 
 	acpi_os_unmap_memory(virt, len);
 	return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/tpm/tpm.c linux-3.2.71-pax/drivers/char/tpm/tpm.c
--- linux-3.2.71/drivers/char/tpm/tpm.c	2015-05-10 09:22:36.859493019 +0200
+++ linux-3.2.71-pax/drivers/char/tpm/tpm.c	2015-05-10 09:23:08.979494763 +0200
@@ -414,7 +414,7 @@ static ssize_t tpm_transmit(struct tpm_c
 		    chip->vendor.req_complete_val)
 			goto out_recv;
 
-		if ((status == chip->vendor.req_canceled)) {
+		if (status == chip->vendor.req_canceled) {
 			dev_err(chip->dev, "Operation Canceled\n");
 			rc = -ECANCELED;
 			goto out;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/char/virtio_console.c linux-3.2.71-pax/drivers/char/virtio_console.c
--- linux-3.2.71/drivers/char/virtio_console.c	2015-05-10 09:22:36.859493019 +0200
+++ linux-3.2.71-pax/drivers/char/virtio_console.c	2015-05-10 09:23:08.995494764 +0200
@@ -571,7 +571,7 @@ static ssize_t fill_readbuf(struct port
 	if (to_user) {
 		ssize_t ret;
 
-		ret = copy_to_user(out_buf, buf->buf + buf->offset, out_count);
+		ret = copy_to_user((char __force_user *)out_buf, buf->buf + buf->offset, out_count);
 		if (ret)
 			return -EFAULT;
 	} else {
@@ -674,7 +674,7 @@ static ssize_t port_fops_read(struct fil
 	if (!port_has_data(port) && !port->host_connected)
 		return 0;
 
-	return fill_readbuf(port, ubuf, count, true);
+	return fill_readbuf(port, (char __force_kernel *)ubuf, count, true);
 }
 
 static ssize_t port_fops_write(struct file *filp, const char __user *ubuf,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/cpufreq/acpi-cpufreq.c linux-3.2.71-pax/drivers/cpufreq/acpi-cpufreq.c
--- linux-3.2.71/drivers/cpufreq/acpi-cpufreq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/cpufreq/acpi-cpufreq.c	2013-03-28 01:35:23.256427950 +0100
@@ -533,8 +533,11 @@ static int acpi_cpufreq_cpu_init(struct
 	data->acpi_data = per_cpu_ptr(acpi_perf_data, cpu);
 	per_cpu(acfreq_data, cpu) = data;
 
-	if (cpu_has(c, X86_FEATURE_CONSTANT_TSC))
-		acpi_cpufreq_driver.flags |= CPUFREQ_CONST_LOOPS;
+	if (cpu_has(c, X86_FEATURE_CONSTANT_TSC)) {
+		pax_open_kernel();
+		*(u8 *)&acpi_cpufreq_driver.flags |= CPUFREQ_CONST_LOOPS;
+		pax_close_kernel();
+	}
 
 	result = acpi_processor_register_performance(data->acpi_data, cpu);
 	if (result)
@@ -644,7 +647,9 @@ static int acpi_cpufreq_cpu_init(struct
 		policy->cur = acpi_cpufreq_guess_freq(data, policy->cpu);
 		break;
 	case ACPI_ADR_SPACE_FIXED_HARDWARE:
-		acpi_cpufreq_driver.get = get_cur_freq_on_cpu;
+		pax_open_kernel();
+		*(void **)&acpi_cpufreq_driver.get = get_cur_freq_on_cpu;
+		pax_close_kernel();
 		policy->cur = get_cur_freq_on_cpu(cpu);
 		break;
 	default:
@@ -655,8 +660,11 @@ static int acpi_cpufreq_cpu_init(struct
 	acpi_processor_notify_smm(THIS_MODULE);
 
 	/* Check for APERF/MPERF support in hardware */
-	if (boot_cpu_has(X86_FEATURE_APERFMPERF))
-		acpi_cpufreq_driver.getavg = cpufreq_get_measured_perf;
+	if (boot_cpu_has(X86_FEATURE_APERFMPERF)) {
+		pax_open_kernel();
+		*(void **)&acpi_cpufreq_driver.getavg = cpufreq_get_measured_perf;
+		pax_close_kernel();
+	}
 
 	pr_debug("CPU%u - ACPI performance management activated.\n", cpu);
 	for (i = 0; i < perf->state_count; i++)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/cpufreq/cpufreq.c linux-3.2.71-pax/drivers/cpufreq/cpufreq.c
--- linux-3.2.71/drivers/cpufreq/cpufreq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/cpufreq/cpufreq.c	2013-03-28 01:35:23.120427958 +0100
@@ -1790,7 +1790,7 @@ static int __cpuinit cpufreq_cpu_callbac
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __refdata cpufreq_cpu_notifier = {
+static struct notifier_block cpufreq_cpu_notifier = {
     .notifier_call = cpufreq_cpu_callback,
 };
 
@@ -1819,8 +1819,11 @@ int cpufreq_register_driver(struct cpufr
 
 	pr_debug("trying to register driver %s\n", driver_data->name);
 
-	if (driver_data->setpolicy)
-		driver_data->flags |= CPUFREQ_CONST_LOOPS;
+	if (driver_data->setpolicy) {
+		pax_open_kernel();
+		*(u8 *)&driver_data->flags |= CPUFREQ_CONST_LOOPS;
+		pax_close_kernel();
+	}
 
 	spin_lock_irqsave(&cpufreq_driver_lock, flags);
 	if (cpufreq_driver) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/cpufreq/cpufreq_stats.c linux-3.2.71-pax/drivers/cpufreq/cpufreq_stats.c
--- linux-3.2.71/drivers/cpufreq/cpufreq_stats.c	2013-03-29 02:18:38.683676284 +0100
+++ linux-3.2.71-pax/drivers/cpufreq/cpufreq_stats.c	2013-03-29 02:20:31.323670270 +0100
@@ -342,7 +342,7 @@ static int __cpuinit cpufreq_stat_cpu_ca
 }
 
 /* priority=1 so this will get called before cpufreq_remove_dev */
-static struct notifier_block cpufreq_stat_cpu_notifier __refdata = {
+static struct notifier_block cpufreq_stat_cpu_notifier = {
 	.notifier_call = cpufreq_stat_cpu_callback,
 	.priority = 1,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/cpufreq/p4-clockmod.c linux-3.2.71-pax/drivers/cpufreq/p4-clockmod.c
--- linux-3.2.71/drivers/cpufreq/p4-clockmod.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/cpufreq/p4-clockmod.c	2013-03-28 01:35:23.256427950 +0100
@@ -166,10 +166,14 @@ static unsigned int cpufreq_p4_get_frequ
 		case 0x0F: /* Core Duo */
 		case 0x16: /* Celeron Core */
 		case 0x1C: /* Atom */
-			p4clockmod_driver.flags |= CPUFREQ_CONST_LOOPS;
+			pax_open_kernel();
+			*(u8 *)&p4clockmod_driver.flags |= CPUFREQ_CONST_LOOPS;
+			pax_close_kernel();
 			return speedstep_get_frequency(SPEEDSTEP_CPU_PCORE);
 		case 0x0D: /* Pentium M (Dothan) */
-			p4clockmod_driver.flags |= CPUFREQ_CONST_LOOPS;
+			pax_open_kernel();
+			*(u8 *)&p4clockmod_driver.flags |= CPUFREQ_CONST_LOOPS;
+			pax_close_kernel();
 			/* fall through */
 		case 0x09: /* Pentium M (Banias) */
 			return speedstep_get_frequency(SPEEDSTEP_CPU_PM);
@@ -181,7 +185,9 @@ static unsigned int cpufreq_p4_get_frequ
 
 	/* on P-4s, the TSC runs with constant frequency independent whether
 	 * throttling is active or not. */
-	p4clockmod_driver.flags |= CPUFREQ_CONST_LOOPS;
+	pax_open_kernel();
+	*(u8 *)&p4clockmod_driver.flags |= CPUFREQ_CONST_LOOPS;
+	pax_close_kernel();
 
 	if (speedstep_detect_processor() == SPEEDSTEP_CPU_P4M) {
 		printk(KERN_WARNING PFX "Warning: Pentium 4-M detected. "
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/cpufreq/powernow-k8.c linux-3.2.71-pax/drivers/cpufreq/powernow-k8.c
--- linux-3.2.71/drivers/cpufreq/powernow-k8.c	2012-10-31 13:04:03.627702855 +0100
+++ linux-3.2.71-pax/drivers/cpufreq/powernow-k8.c	2013-03-28 13:58:01.990048859 +0100
@@ -1341,8 +1341,11 @@ static int __cpuinit powernowk8_cpu_init
 	}
 
 	/* Check for APERF/MPERF support in hardware */
-	if (cpu_has(c, X86_FEATURE_APERFMPERF))
-		cpufreq_amd64_driver.getavg = cpufreq_get_measured_perf;
+	if (cpu_has(c, X86_FEATURE_APERFMPERF)) {
+		pax_open_kernel();
+		*(void **)&cpufreq_amd64_driver.getavg = cpufreq_get_measured_perf;
+		pax_close_kernel();
+	}
 
 	cpufreq_frequency_table_get_attr(data->powernow_table, pol->cpu);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/cpufreq/speedstep-centrino.c linux-3.2.71-pax/drivers/cpufreq/speedstep-centrino.c
--- linux-3.2.71/drivers/cpufreq/speedstep-centrino.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/cpufreq/speedstep-centrino.c	2013-03-28 01:35:23.256427950 +0100
@@ -352,8 +352,11 @@ static int centrino_cpu_init(struct cpuf
 	    !cpu_has(cpu, X86_FEATURE_EST))
 		return -ENODEV;
 
-	if (cpu_has(cpu, X86_FEATURE_CONSTANT_TSC))
-		centrino_driver.flags |= CPUFREQ_CONST_LOOPS;
+	if (cpu_has(cpu, X86_FEATURE_CONSTANT_TSC)) {
+		pax_open_kernel();
+		*(u8 *)&centrino_driver.flags |= CPUFREQ_CONST_LOOPS;
+		pax_close_kernel();
+	}
 
 	if (policy->cpu != 0)
 		return -ENODEV;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/cpuidle/cpuidle.c linux-3.2.71-pax/drivers/cpuidle/cpuidle.c
--- linux-3.2.71/drivers/cpuidle/cpuidle.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/cpuidle/cpuidle.c	2013-03-28 01:35:23.260427950 +0100
@@ -188,7 +188,7 @@ static int poll_idle(struct cpuidle_devi
 
 static void poll_idle_init(struct cpuidle_driver *drv)
 {
-	struct cpuidle_state *state = &drv->states[0];
+	cpuidle_state_no_const *state = &drv->states[0];
 
 	snprintf(state->name, CPUIDLE_NAME_LEN, "POLL");
 	snprintf(state->desc, CPUIDLE_DESC_LEN, "CPUIDLE CORE POLL IDLE");
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/cpuidle/governor.c linux-3.2.71-pax/drivers/cpuidle/governor.c
--- linux-3.2.71/drivers/cpuidle/governor.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/cpuidle/governor.c	2013-03-28 01:35:23.260427950 +0100
@@ -87,7 +87,7 @@ int cpuidle_register_governor(struct cpu
 	mutex_lock(&cpuidle_lock);
 	if (__cpuidle_find_governor(gov->name) == NULL) {
 		ret = 0;
-		list_add_tail(&gov->governor_list, &cpuidle_governors);
+		pax_list_add_tail((struct list_head *)&gov->governor_list, &cpuidle_governors);
 		if (!cpuidle_curr_governor ||
 		    cpuidle_curr_governor->rating < gov->rating)
 			cpuidle_switch_governor(gov);
@@ -135,7 +135,7 @@ void cpuidle_unregister_governor(struct
 		new_gov = cpuidle_replace_governor(gov->rating);
 		cpuidle_switch_governor(new_gov);
 	}
-	list_del(&gov->governor_list);
+	pax_list_del((struct list_head *)&gov->governor_list);
 	mutex_unlock(&cpuidle_lock);
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/cpuidle/sysfs.c linux-3.2.71-pax/drivers/cpuidle/sysfs.c
--- linux-3.2.71/drivers/cpuidle/sysfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/cpuidle/sysfs.c	2013-03-28 04:26:18.455880402 +0100
@@ -131,7 +131,7 @@ static struct attribute *cpuclass_switch
 	NULL
 };
 
-static struct attribute_group cpuclass_attr_group = {
+static attribute_group_no_const cpuclass_attr_group = {
 	.attrs = cpuclass_default_attrs,
 	.name = "cpuidle",
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/crypto/hifn_795x.c linux-3.2.71-pax/drivers/crypto/hifn_795x.c
--- linux-3.2.71/drivers/crypto/hifn_795x.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/crypto/hifn_795x.c	2013-09-01 19:52:53.411867298 +0200
@@ -51,7 +51,7 @@ module_param_string(hifn_pll_ref, hifn_p
 MODULE_PARM_DESC(hifn_pll_ref,
 		 "PLL reference clock (pci[freq] or ext[freq], default ext)");
 
-static atomic_t hifn_dev_number;
+static atomic_unchecked_t hifn_dev_number;
 
 #define ACRYPTO_OP_DECRYPT	0
 #define ACRYPTO_OP_ENCRYPT	1
@@ -2576,7 +2576,7 @@ static int __devinit hifn_probe(struct p
 		goto err_out_disable_pci_device;
 
 	snprintf(name, sizeof(name), "hifn%d",
-			atomic_inc_return(&hifn_dev_number)-1);
+			atomic_inc_return_unchecked(&hifn_dev_number)-1);
 
 	err = pci_request_regions(pdev, name);
 	if (err)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/devfreq/devfreq.c linux-3.2.71-pax/drivers/devfreq/devfreq.c
--- linux-3.2.71/drivers/devfreq/devfreq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/devfreq/devfreq.c	2013-06-21 19:50:19.074646395 +0200
@@ -372,7 +372,7 @@ struct devfreq *devfreq_add_device(struc
 			      = msecs_to_jiffies(devfreq->profile->polling_ms);
 	devfreq->nb.notifier_call = devfreq_notifier_call;
 
-	dev_set_name(&devfreq->dev, dev_name(dev));
+	dev_set_name(&devfreq->dev, "%s", dev_name(dev));
 	err = device_register(&devfreq->dev);
 	if (err) {
 		put_device(&devfreq->dev);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/dma/dmatest.c linux-3.2.71-pax/drivers/dma/dmatest.c
--- linux-3.2.71/drivers/dma/dmatest.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/dma/dmatest.c	2012-07-04 19:24:47.716063004 +0200
@@ -591,7 +591,7 @@ static int dmatest_add_channel(struct dm
 	}
 	if (dma_has_cap(DMA_PQ, dma_dev->cap_mask)) {
 		cnt = dmatest_add_threads(dtc, DMA_PQ);
-		thread_count += cnt > 0 ?: 0;
+		thread_count += cnt > 0 ? cnt : 0;
 	}
 
 	pr_info("dmatest: Started %u threads using %s\n",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/dma/shdma.c linux-3.2.71-pax/drivers/dma/shdma.c
--- linux-3.2.71/drivers/dma/shdma.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/dma/shdma.c	2013-02-20 01:22:42.778016276 +0100
@@ -1054,7 +1054,7 @@ static int sh_dmae_nmi_handler(struct no
 	return ret;
 }
 
-static struct notifier_block sh_dmae_nmi_notifier __read_mostly = {
+static struct notifier_block sh_dmae_nmi_notifier = {
 	.notifier_call	= sh_dmae_nmi_handler,
 
 	/* Run before NMI debug handler and KGDB */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/amd64_edac.c linux-3.2.71-pax/drivers/edac/amd64_edac.c
--- linux-3.2.71/drivers/edac/amd64_edac.c	2012-10-31 13:04:03.651702855 +0100
+++ linux-3.2.71-pax/drivers/edac/amd64_edac.c	2012-10-31 13:04:10.919703313 +0100
@@ -2682,7 +2682,7 @@ static void __devexit amd64_remove_one_i
  * PCI core identifies what devices are on a system during boot, and then
  * inquiry this table to see if this driver is for a given device found.
  */
-static const struct pci_device_id amd64_pci_table[] __devinitdata = {
+static const struct pci_device_id amd64_pci_table[] __devinitconst = {
 	{
 		.vendor		= PCI_VENDOR_ID_AMD,
 		.device		= PCI_DEVICE_ID_AMD_K8_NB_MEMCTL,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/amd76x_edac.c linux-3.2.71-pax/drivers/edac/amd76x_edac.c
--- linux-3.2.71/drivers/edac/amd76x_edac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/amd76x_edac.c	2012-07-04 19:24:47.716063004 +0200
@@ -321,7 +321,7 @@ static void __devexit amd76x_remove_one(
 	edac_mc_free(mci);
 }
 
-static const struct pci_device_id amd76x_pci_tbl[] __devinitdata = {
+static const struct pci_device_id amd76x_pci_tbl[] __devinitconst = {
 	{
 	 PCI_VEND_DEV(AMD, FE_GATE_700C), PCI_ANY_ID, PCI_ANY_ID, 0, 0,
 	 AMD762},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/e752x_edac.c linux-3.2.71-pax/drivers/edac/e752x_edac.c
--- linux-3.2.71/drivers/edac/e752x_edac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/e752x_edac.c	2012-07-04 19:24:47.724063005 +0200
@@ -1380,7 +1380,7 @@ static void __devexit e752x_remove_one(s
 	edac_mc_free(mci);
 }
 
-static const struct pci_device_id e752x_pci_tbl[] __devinitdata = {
+static const struct pci_device_id e752x_pci_tbl[] __devinitconst = {
 	{
 	 PCI_VEND_DEV(INTEL, 7520_0), PCI_ANY_ID, PCI_ANY_ID, 0, 0,
 	 E7520},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/e7xxx_edac.c linux-3.2.71-pax/drivers/edac/e7xxx_edac.c
--- linux-3.2.71/drivers/edac/e7xxx_edac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/e7xxx_edac.c	2012-07-04 19:24:47.724063005 +0200
@@ -525,7 +525,7 @@ static void __devexit e7xxx_remove_one(s
 	edac_mc_free(mci);
 }
 
-static const struct pci_device_id e7xxx_pci_tbl[] __devinitdata = {
+static const struct pci_device_id e7xxx_pci_tbl[] __devinitconst = {
 	{
 	 PCI_VEND_DEV(INTEL, 7205_0), PCI_ANY_ID, PCI_ANY_ID, 0, 0,
 	 E7205},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/edac_device.c linux-3.2.71-pax/drivers/edac/edac_device.c
--- linux-3.2.71/drivers/edac/edac_device.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/edac_device.c	2013-09-01 19:57:33.055852367 +0200
@@ -483,9 +483,9 @@ void edac_device_reset_delay_period(stru
  */
 int edac_device_alloc_index(void)
 {
-	static atomic_t device_indexes = ATOMIC_INIT(0);
+	static atomic_unchecked_t device_indexes = ATOMIC_INIT(0);
 
-	return atomic_inc_return(&device_indexes) - 1;
+	return atomic_inc_return_unchecked(&device_indexes) - 1;
 }
 EXPORT_SYMBOL_GPL(edac_device_alloc_index);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/edac_pci.c linux-3.2.71-pax/drivers/edac/edac_pci.c
--- linux-3.2.71/drivers/edac/edac_pci.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/edac_pci.c	2013-09-01 19:57:57.711851051 +0200
@@ -30,7 +30,7 @@
 
 static DEFINE_MUTEX(edac_pci_ctls_mutex);
 static LIST_HEAD(edac_pci_list);
-static atomic_t pci_indexes = ATOMIC_INIT(0);
+static atomic_unchecked_t pci_indexes = ATOMIC_INIT(0);
 
 /*
  * edac_pci_alloc_ctl_info
@@ -316,7 +316,7 @@ EXPORT_SYMBOL_GPL(edac_pci_reset_delay_p
  */
 int edac_pci_alloc_index(void)
 {
-	return atomic_inc_return(&pci_indexes) - 1;
+	return atomic_inc_return_unchecked(&pci_indexes) - 1;
 }
 EXPORT_SYMBOL_GPL(edac_pci_alloc_index);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/edac_pci_sysfs.c linux-3.2.71-pax/drivers/edac/edac_pci_sysfs.c
--- linux-3.2.71/drivers/edac/edac_pci_sysfs.c	2013-02-09 01:12:40.728782285 +0100
+++ linux-3.2.71-pax/drivers/edac/edac_pci_sysfs.c	2013-03-28 01:35:23.124427957 +0100
@@ -26,8 +26,8 @@ static int edac_pci_log_pe = 1;		/* log
 static int edac_pci_log_npe = 1;	/* log PCI non-parity error errors */
 static int edac_pci_poll_msec = 1000;	/* one second workq period */
 
-static atomic_t pci_parity_count = ATOMIC_INIT(0);
-static atomic_t pci_nonparity_count = ATOMIC_INIT(0);
+static atomic_unchecked_t pci_parity_count = ATOMIC_INIT(0);
+static atomic_unchecked_t pci_nonparity_count = ATOMIC_INIT(0);
 
 static struct kobject *edac_pci_top_main_kobj;
 static atomic_t edac_pci_sysfs_refcount = ATOMIC_INIT(0);
@@ -236,7 +236,7 @@ struct edac_pci_dev_attribute {
 	void *value;
 	 ssize_t(*show) (void *, char *);
 	 ssize_t(*store) (void *, const char *, size_t);
-};
+} __do_const;
 
 /* Set of show/store abstract level functions for PCI Parity object */
 static ssize_t edac_pci_dev_show(struct kobject *kobj, struct attribute *attr,
@@ -582,7 +582,7 @@ static void edac_pci_dev_parity_test(str
 			edac_printk(KERN_CRIT, EDAC_PCI,
 				"Signaled System Error on %s\n",
 				pci_name(dev));
-			atomic_inc(&pci_nonparity_count);
+			atomic_inc_unchecked(&pci_nonparity_count);
 		}
 
 		if (status & (PCI_STATUS_PARITY)) {
@@ -590,7 +590,7 @@ static void edac_pci_dev_parity_test(str
 				"Master Data Parity Error on %s\n",
 				pci_name(dev));
 
-			atomic_inc(&pci_parity_count);
+			atomic_inc_unchecked(&pci_parity_count);
 		}
 
 		if (status & (PCI_STATUS_DETECTED_PARITY)) {
@@ -598,7 +598,7 @@ static void edac_pci_dev_parity_test(str
 				"Detected Parity Error on %s\n",
 				pci_name(dev));
 
-			atomic_inc(&pci_parity_count);
+			atomic_inc_unchecked(&pci_parity_count);
 		}
 	}
 
@@ -619,7 +619,7 @@ static void edac_pci_dev_parity_test(str
 				edac_printk(KERN_CRIT, EDAC_PCI, "Bridge "
 					"Signaled System Error on %s\n",
 					pci_name(dev));
-				atomic_inc(&pci_nonparity_count);
+				atomic_inc_unchecked(&pci_nonparity_count);
 			}
 
 			if (status & (PCI_STATUS_PARITY)) {
@@ -627,7 +627,7 @@ static void edac_pci_dev_parity_test(str
 					"Master Data Parity Error on "
 					"%s\n", pci_name(dev));
 
-				atomic_inc(&pci_parity_count);
+				atomic_inc_unchecked(&pci_parity_count);
 			}
 
 			if (status & (PCI_STATUS_DETECTED_PARITY)) {
@@ -635,7 +635,7 @@ static void edac_pci_dev_parity_test(str
 					"Detected Parity Error on %s\n",
 					pci_name(dev));
 
-				atomic_inc(&pci_parity_count);
+				atomic_inc_unchecked(&pci_parity_count);
 			}
 		}
 	}
@@ -677,7 +677,7 @@ void edac_pci_do_parity_check(void)
 	if (!check_pci_errors)
 		return;
 
-	before_count = atomic_read(&pci_parity_count);
+	before_count = atomic_read_unchecked(&pci_parity_count);
 
 	/* scan all PCI devices looking for a Parity Error on devices and
 	 * bridges.
@@ -689,7 +689,7 @@ void edac_pci_do_parity_check(void)
 	/* Only if operator has selected panic on PCI Error */
 	if (edac_pci_get_panic_on_pe()) {
 		/* If the count is different 'after' from 'before' */
-		if (before_count != atomic_read(&pci_parity_count))
+		if (before_count != atomic_read_unchecked(&pci_parity_count))
 			panic("EDAC: PCI Parity Error");
 	}
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/i3000_edac.c linux-3.2.71-pax/drivers/edac/i3000_edac.c
--- linux-3.2.71/drivers/edac/i3000_edac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/i3000_edac.c	2012-07-04 19:24:47.728063005 +0200
@@ -470,7 +470,7 @@ static void __devexit i3000_remove_one(s
 	edac_mc_free(mci);
 }
 
-static const struct pci_device_id i3000_pci_tbl[] __devinitdata = {
+static const struct pci_device_id i3000_pci_tbl[] __devinitconst = {
 	{
 	 PCI_VEND_DEV(INTEL, 3000_HB), PCI_ANY_ID, PCI_ANY_ID, 0, 0,
 	 I3000},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/i3200_edac.c linux-3.2.71-pax/drivers/edac/i3200_edac.c
--- linux-3.2.71/drivers/edac/i3200_edac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/i3200_edac.c	2012-07-04 19:24:47.728063005 +0200
@@ -456,7 +456,7 @@ static void __devexit i3200_remove_one(s
 	edac_mc_free(mci);
 }
 
-static const struct pci_device_id i3200_pci_tbl[] __devinitdata = {
+static const struct pci_device_id i3200_pci_tbl[] __devinitconst = {
 	{
 		PCI_VEND_DEV(INTEL, 3200_HB), PCI_ANY_ID, PCI_ANY_ID, 0, 0,
 		I3200},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/i5000_edac.c linux-3.2.71-pax/drivers/edac/i5000_edac.c
--- linux-3.2.71/drivers/edac/i5000_edac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/i5000_edac.c	2012-07-04 19:24:47.732063004 +0200
@@ -1516,7 +1516,7 @@ static void __devexit i5000_remove_one(s
  *
  *	The "E500P" device is the first device supported.
  */
-static const struct pci_device_id i5000_pci_tbl[] __devinitdata = {
+static const struct pci_device_id i5000_pci_tbl[] __devinitconst = {
 	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_I5000_DEV16),
 	 .driver_data = I5000P},
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/i5100_edac.c linux-3.2.71-pax/drivers/edac/i5100_edac.c
--- linux-3.2.71/drivers/edac/i5100_edac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/i5100_edac.c	2012-07-04 19:24:47.732063004 +0200
@@ -1051,7 +1051,7 @@ static void __devexit i5100_remove_one(s
 	edac_mc_free(mci);
 }
 
-static const struct pci_device_id i5100_pci_tbl[] __devinitdata = {
+static const struct pci_device_id i5100_pci_tbl[] __devinitconst = {
 	/* Device 16, Function 0, Channel 0 Memory Map, Error Flag/Mask, ... */
 	{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_5100_16) },
 	{ 0, }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/i5400_edac.c linux-3.2.71-pax/drivers/edac/i5400_edac.c
--- linux-3.2.71/drivers/edac/i5400_edac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/i5400_edac.c	2012-07-04 19:24:47.732063004 +0200
@@ -1383,7 +1383,7 @@ static void __devexit i5400_remove_one(s
  *
  *	The "E500P" device is the first device supported.
  */
-static const struct pci_device_id i5400_pci_tbl[] __devinitdata = {
+static const struct pci_device_id i5400_pci_tbl[] __devinitconst = {
 	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_5400_ERR)},
 	{0,}			/* 0 terminated list. */
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/i7300_edac.c linux-3.2.71-pax/drivers/edac/i7300_edac.c
--- linux-3.2.71/drivers/edac/i7300_edac.c	2014-04-02 03:15:41.283672570 +0200
+++ linux-3.2.71-pax/drivers/edac/i7300_edac.c	2014-04-02 03:15:49.203672148 +0200
@@ -1194,7 +1194,7 @@ static void __devexit i7300_remove_one(s
  *
  * Has only 8086:360c PCI ID
  */
-static const struct pci_device_id i7300_pci_tbl[] __devinitdata = {
+static const struct pci_device_id i7300_pci_tbl[] __devinitconst = {
 	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_I7300_MCH_ERR)},
 	{0,}			/* 0 terminated list. */
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/i7core_edac.c linux-3.2.71-pax/drivers/edac/i7core_edac.c
--- linux-3.2.71/drivers/edac/i7core_edac.c	2014-04-02 03:15:41.295672570 +0200
+++ linux-3.2.71-pax/drivers/edac/i7core_edac.c	2014-04-02 03:15:49.203672148 +0200
@@ -391,7 +391,7 @@ static const struct pci_id_table pci_dev
 /*
  *	pci_device_id	table for which devices we are looking for
  */
-static const struct pci_device_id i7core_pci_tbl[] __devinitdata = {
+static const struct pci_device_id i7core_pci_tbl[] __devinitconst = {
 	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_X58_HUB_MGMT)},
 	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_LYNNFIELD_QPI_LINK0)},
 	{0,}			/* 0 terminated list. */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/i82443bxgx_edac.c linux-3.2.71-pax/drivers/edac/i82443bxgx_edac.c
--- linux-3.2.71/drivers/edac/i82443bxgx_edac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/i82443bxgx_edac.c	2012-07-04 19:24:47.736063004 +0200
@@ -380,7 +380,7 @@ static void __devexit i82443bxgx_edacmc_
 
 EXPORT_SYMBOL_GPL(i82443bxgx_edacmc_remove_one);
 
-static const struct pci_device_id i82443bxgx_pci_tbl[] __devinitdata = {
+static const struct pci_device_id i82443bxgx_pci_tbl[] __devinitconst = {
 	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_82443BX_0)},
 	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_82443BX_2)},
 	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_82443GX_0)},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/i82860_edac.c linux-3.2.71-pax/drivers/edac/i82860_edac.c
--- linux-3.2.71/drivers/edac/i82860_edac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/i82860_edac.c	2012-07-04 19:24:47.736063004 +0200
@@ -270,7 +270,7 @@ static void __devexit i82860_remove_one(
 	edac_mc_free(mci);
 }
 
-static const struct pci_device_id i82860_pci_tbl[] __devinitdata = {
+static const struct pci_device_id i82860_pci_tbl[] __devinitconst = {
 	{
 	 PCI_VEND_DEV(INTEL, 82860_0), PCI_ANY_ID, PCI_ANY_ID, 0, 0,
 	 I82860},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/i82875p_edac.c linux-3.2.71-pax/drivers/edac/i82875p_edac.c
--- linux-3.2.71/drivers/edac/i82875p_edac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/i82875p_edac.c	2012-07-04 19:24:47.736063004 +0200
@@ -511,7 +511,7 @@ static void __devexit i82875p_remove_one
 	edac_mc_free(mci);
 }
 
-static const struct pci_device_id i82875p_pci_tbl[] __devinitdata = {
+static const struct pci_device_id i82875p_pci_tbl[] __devinitconst = {
 	{
 	 PCI_VEND_DEV(INTEL, 82875_0), PCI_ANY_ID, PCI_ANY_ID, 0, 0,
 	 I82875P},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/i82975x_edac.c linux-3.2.71-pax/drivers/edac/i82975x_edac.c
--- linux-3.2.71/drivers/edac/i82975x_edac.c	2013-01-03 19:05:13.012036811 +0100
+++ linux-3.2.71-pax/drivers/edac/i82975x_edac.c	2013-01-03 19:05:22.052037077 +0100
@@ -601,7 +601,7 @@ static void __devexit i82975x_remove_one
 	edac_mc_free(mci);
 }
 
-static const struct pci_device_id i82975x_pci_tbl[] __devinitdata = {
+static const struct pci_device_id i82975x_pci_tbl[] __devinitconst = {
 	{
 		PCI_VEND_DEV(INTEL, 82975_0), PCI_ANY_ID, PCI_ANY_ID, 0, 0,
 		I82975X
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/mce_amd.h linux-3.2.71-pax/drivers/edac/mce_amd.h
--- linux-3.2.71/drivers/edac/mce_amd.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/mce_amd.h	2012-07-04 19:24:47.736063004 +0200
@@ -83,7 +83,7 @@ struct amd_decoder_ops {
 	bool (*dc_mce)(u16, u8);
 	bool (*ic_mce)(u16, u8);
 	bool (*nb_mce)(u16, u8);
-};
+} __no_const;
 
 void amd_report_gart_errors(bool);
 void amd_register_ecc_decoder(void (*f)(int, struct mce *));
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/r82600_edac.c linux-3.2.71-pax/drivers/edac/r82600_edac.c
--- linux-3.2.71/drivers/edac/r82600_edac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/r82600_edac.c	2012-07-04 19:24:47.736063004 +0200
@@ -373,7 +373,7 @@ static void __devexit r82600_remove_one(
 	edac_mc_free(mci);
 }
 
-static const struct pci_device_id r82600_pci_tbl[] __devinitdata = {
+static const struct pci_device_id r82600_pci_tbl[] __devinitconst = {
 	{
 	 PCI_DEVICE(PCI_VENDOR_ID_RADISYS, R82600_BRIDGE_ID)
 	 },
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/sb_edac.c linux-3.2.71-pax/drivers/edac/sb_edac.c
--- linux-3.2.71/drivers/edac/sb_edac.c	2015-08-07 11:37:20.435789890 +0200
+++ linux-3.2.71-pax/drivers/edac/sb_edac.c	2015-08-07 11:37:42.999790553 +0200
@@ -368,7 +368,7 @@ static const struct pci_id_table pci_dev
 /*
  *	pci_device_id	table for which devices we are looking for
  */
-static const struct pci_device_id sbridge_pci_tbl[] __devinitdata = {
+static const struct pci_device_id sbridge_pci_tbl[] __devinitconst = {
 	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_TA)},
 	{0,}			/* 0 terminated list. */
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/edac/x38_edac.c linux-3.2.71-pax/drivers/edac/x38_edac.c
--- linux-3.2.71/drivers/edac/x38_edac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/edac/x38_edac.c	2012-07-04 19:24:48.344063008 +0200
@@ -440,7 +440,7 @@ static void __devexit x38_remove_one(str
 	edac_mc_free(mci);
 }
 
-static const struct pci_device_id x38_pci_tbl[] __devinitdata = {
+static const struct pci_device_id x38_pci_tbl[] __devinitconst = {
 	{
 	 PCI_VEND_DEV(INTEL, X38_HB), PCI_ANY_ID, PCI_ANY_ID, 0, 0,
 	 X38},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/firewire/core-card.c linux-3.2.71-pax/drivers/firewire/core-card.c
--- linux-3.2.71/drivers/firewire/core-card.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/firewire/core-card.c	2013-09-01 19:43:49.227896353 +0200
@@ -512,9 +512,9 @@ void fw_card_initialize(struct fw_card *
 			const struct fw_card_driver *driver,
 			struct device *device)
 {
-	static atomic_t index = ATOMIC_INIT(-1);
+	static atomic_unchecked_t index = ATOMIC_INIT(-1);
 
-	card->index = atomic_inc_return(&index);
+	card->index = atomic_inc_return_unchecked(&index);
 	card->driver = driver;
 	card->device = device;
 	card->current_tlabel = 0;
@@ -657,7 +657,7 @@ void fw_card_release(struct kref *kref)
 
 void fw_core_remove_card(struct fw_card *card)
 {
-	struct fw_card_driver dummy_driver = dummy_driver_template;
+	fw_card_driver_no_const dummy_driver = dummy_driver_template;
 
 	card->driver->update_phy_reg(card, 4,
 				     PHY_LINK_ACTIVE | PHY_CONTENDER, 0);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/firewire/core-cdev.c linux-3.2.71-pax/drivers/firewire/core-cdev.c
--- linux-3.2.71/drivers/firewire/core-cdev.c	2014-12-14 21:13:45.050054795 +0100
+++ linux-3.2.71-pax/drivers/firewire/core-cdev.c	2014-12-14 21:13:52.774069225 +0100
@@ -1331,8 +1331,7 @@ static int init_iso_resource(struct clie
 	int ret;
 
 	if ((request->channels == 0 && request->bandwidth == 0) ||
-	    request->bandwidth > BANDWIDTH_AVAILABLE_INITIAL ||
-	    request->bandwidth < 0)
+	    request->bandwidth > BANDWIDTH_AVAILABLE_INITIAL)
 		return -EINVAL;
 
 	r  = kmalloc(sizeof(*r), GFP_KERNEL);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/firewire/core-device.c linux-3.2.71-pax/drivers/firewire/core-device.c
--- linux-3.2.71/drivers/firewire/core-device.c	2013-03-29 02:18:30.083676744 +0100
+++ linux-3.2.71-pax/drivers/firewire/core-device.c	2013-03-29 02:19:02.075675035 +0100
@@ -232,7 +232,7 @@ EXPORT_SYMBOL(fw_device_enable_phys_dma)
 struct config_rom_attribute {
 	struct device_attribute attr;
 	u32 key;
-};
+} __do_const;
 
 static ssize_t show_immediate(struct device *dev,
 			      struct device_attribute *dattr, char *buf)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/firewire/core.h linux-3.2.71-pax/drivers/firewire/core.h
--- linux-3.2.71/drivers/firewire/core.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/firewire/core.h	2012-07-04 19:24:48.352063006 +0200
@@ -101,6 +101,7 @@ struct fw_card_driver {
 
 	int (*stop_iso)(struct fw_iso_context *ctx);
 };
+typedef struct fw_card_driver __no_const fw_card_driver_no_const;
 
 void fw_card_initialize(struct fw_card *card,
 		const struct fw_card_driver *driver, struct device *device);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/firewire/core-transaction.c linux-3.2.71-pax/drivers/firewire/core-transaction.c
--- linux-3.2.71/drivers/firewire/core-transaction.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/firewire/core-transaction.c	2012-07-04 19:24:48.356063006 +0200
@@ -37,6 +37,7 @@
 #include <linux/timer.h>
 #include <linux/types.h>
 #include <linux/workqueue.h>
+#include <linux/sched.h>
 
 #include <asm/byteorder.h>
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/firmware/dmi-id.c linux-3.2.71-pax/drivers/firmware/dmi-id.c
--- linux-3.2.71/drivers/firmware/dmi-id.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/firmware/dmi-id.c	2013-03-28 01:35:23.264427950 +0100
@@ -16,7 +16,7 @@
 struct dmi_device_attribute{
 	struct device_attribute dev_attr;
 	int field;
-};
+} __do_const;
 #define to_dmi_dev_attr(_dev_attr) \
 	container_of(_dev_attr, struct dmi_device_attribute, dev_attr)
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/firmware/dmi_scan.c linux-3.2.71-pax/drivers/firmware/dmi_scan.c
--- linux-3.2.71/drivers/firmware/dmi_scan.c	2015-08-07 11:37:20.435789890 +0200
+++ linux-3.2.71-pax/drivers/firmware/dmi_scan.c	2015-08-07 11:37:42.999790553 +0200
@@ -488,11 +488,6 @@ void __init dmi_scan_machine(void)
 		}
 	}
 	else {
-		/*
-		 * no iounmap() for that ioremap(); it would be a no-op, but
-		 * it's so early in setup that sucker gets confused into doing
-		 * what it shouldn't if we actually call it.
-		 */
 		p = dmi_ioremap(0xF0000, 0x10000);
 		if (p == NULL)
 			goto error;
@@ -770,7 +765,7 @@ int dmi_walk(void (*decode)(const struct
 	if (buf == NULL)
 		return -1;
 
-	dmi_table(buf, dmi_len, dmi_num, decode, private_data);
+	dmi_table((char __force_kernel *)buf, dmi_len, dmi_num, decode, private_data);
 
 	iounmap(buf);
 	return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/firmware/efivars.c linux-3.2.71-pax/drivers/firmware/efivars.c
--- linux-3.2.71/drivers/firmware/efivars.c	2013-06-09 18:04:43.241591758 +0200
+++ linux-3.2.71-pax/drivers/firmware/efivars.c	2013-06-09 18:04:48.869591458 +0200
@@ -1221,7 +1221,7 @@ efivar_create_sysfs_entry(struct efivars
 static int
 create_efivars_bin_attributes(struct efivars *efivars)
 {
-	struct bin_attribute *attr;
+	bin_attribute_no_const *attr;
 	int error;
 
 	/* new_var */
@@ -1413,7 +1413,7 @@ out:
 }
 EXPORT_SYMBOL_GPL(register_efivars);
 
-static struct efivar_operations ops;
+static efivar_operations_no_const ops __read_only;
 
 /*
  * For now we register the efi subsystem with the firmware subsystem
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/firmware/google/gsmi.c linux-3.2.71-pax/drivers/firmware/google/gsmi.c
--- linux-3.2.71/drivers/firmware/google/gsmi.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/firmware/google/gsmi.c	2015-04-30 03:07:38.400532395 +0200
@@ -718,7 +718,7 @@ static u32 __init hash_oem_table_id(char
 	return local_hash_64(input, 32);
 }
 
-static struct dmi_system_id gsmi_dmi_table[] __initdata = {
+static const struct dmi_system_id gsmi_dmi_table[] __initconst = {
 	{
 		.ident = "Google Board",
 		.matches = {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/firmware/google/memconsole.c linux-3.2.71-pax/drivers/firmware/google/memconsole.c
--- linux-3.2.71/drivers/firmware/google/memconsole.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/firmware/google/memconsole.c	2015-04-30 03:07:38.396532395 +0200
@@ -126,7 +126,7 @@ static bool found_memconsole(void)
 	return false;
 }
 
-static struct dmi_system_id memconsole_dmi_table[] __initdata = {
+static const struct dmi_system_id memconsole_dmi_table[] __initconst = {
 	{
 		.ident = "Google Board",
 		.matches = {
@@ -147,7 +147,9 @@ static int __init memconsole_init(void)
 	if (!found_memconsole())
 		return -ENODEV;
 
-	memconsole_bin_attr.size = memconsole_length;
+	pax_open_kernel();
+	*(size_t *)&memconsole_bin_attr.size = memconsole_length;
+	pax_close_kernel();
 
 	ret = sysfs_create_bin_file(firmware_kobj, &memconsole_bin_attr);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpio/gpio-vr41xx.c linux-3.2.71-pax/drivers/gpio/gpio-vr41xx.c
--- linux-3.2.71/drivers/gpio/gpio-vr41xx.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpio/gpio-vr41xx.c	2012-07-04 19:24:48.356063006 +0200
@@ -204,7 +204,7 @@ static int giu_get_irq(unsigned int irq)
 	printk(KERN_ERR "spurious GIU interrupt: %04x(%04x),%04x(%04x)\n",
 	       maskl, pendl, maskh, pendh);
 
-	atomic_inc(&irq_err_count);
+	atomic_inc_unchecked(&irq_err_count);
 
 	return -EINVAL;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/drm_crtc.c linux-3.2.71-pax/drivers/gpu/drm/drm_crtc.c
--- linux-3.2.71/drivers/gpu/drm/drm_crtc.c	2015-08-14 21:48:35.112707923 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/drm_crtc.c	2015-08-14 21:48:45.584707364 +0200
@@ -1379,7 +1379,7 @@ int drm_mode_getconnector(struct drm_dev
 	 */
 	if ((out_resp->count_modes >= mode_count) && mode_count) {
 		copied = 0;
-		mode_ptr = (struct drm_mode_modeinfo *)(unsigned long)out_resp->modes_ptr;
+		mode_ptr = (struct drm_mode_modeinfo __user *)(unsigned long)out_resp->modes_ptr;
 		list_for_each_entry(mode, &connector->modes, head) {
 			drm_crtc_convert_to_umode(&u_mode, mode);
 			if (copy_to_user(mode_ptr + copied,
@@ -1394,8 +1394,8 @@ int drm_mode_getconnector(struct drm_dev
 
 	if ((out_resp->count_props >= props_count) && props_count) {
 		copied = 0;
-		prop_ptr = (uint32_t *)(unsigned long)(out_resp->props_ptr);
-		prop_values = (uint64_t *)(unsigned long)(out_resp->prop_values_ptr);
+		prop_ptr = (uint32_t __user *)(unsigned long)(out_resp->props_ptr);
+		prop_values = (uint64_t __user *)(unsigned long)(out_resp->prop_values_ptr);
 		for (i = 0; i < DRM_CONNECTOR_MAX_PROPERTY; i++) {
 			if (connector->property_ids[i] != 0) {
 				if (put_user(connector->property_ids[i],
@@ -1417,7 +1417,7 @@ int drm_mode_getconnector(struct drm_dev
 
 	if ((out_resp->count_encoders >= encoders_count) && encoders_count) {
 		copied = 0;
-		encoder_ptr = (uint32_t *)(unsigned long)(out_resp->encoders_ptr);
+		encoder_ptr = (uint32_t __user *)(unsigned long)(out_resp->encoders_ptr);
 		for (i = 0; i < DRM_CONNECTOR_MAX_ENCODER; i++) {
 			if (connector->encoder_ids[i] != 0) {
 				if (put_user(connector->encoder_ids[i],
@@ -1583,7 +1583,7 @@ int drm_mode_setcrtc(struct drm_device *
 		}
 
 		for (i = 0; i < crtc_req->count_connectors; i++) {
-			set_connectors_ptr = (uint32_t *)(unsigned long)crtc_req->set_connectors_ptr;
+			set_connectors_ptr = (uint32_t __user *)(unsigned long)crtc_req->set_connectors_ptr;
 			if (get_user(out_id, &set_connectors_ptr[i])) {
 				ret = -EFAULT;
 				goto out;
@@ -1863,7 +1863,7 @@ int drm_mode_dirtyfb_ioctl(struct drm_de
 	fb = obj_to_fb(obj);
 
 	num_clips = r->num_clips;
-	clips_ptr = (struct drm_clip_rect *)(unsigned long)r->clips_ptr;
+	clips_ptr = (struct drm_clip_rect __user *)(unsigned long)r->clips_ptr;
 
 	if (!num_clips != !clips_ptr) {
 		ret = -EINVAL;
@@ -2289,7 +2289,7 @@ int drm_mode_getproperty_ioctl(struct dr
 	out_resp->flags = property->flags;
 
 	if ((out_resp->count_values >= value_count) && value_count) {
-		values_ptr = (uint64_t *)(unsigned long)out_resp->values_ptr;
+		values_ptr = (uint64_t __user *)(unsigned long)out_resp->values_ptr;
 		for (i = 0; i < value_count; i++) {
 			if (copy_to_user(values_ptr + i, &property->values[i], sizeof(uint64_t))) {
 				ret = -EFAULT;
@@ -2302,7 +2302,7 @@ int drm_mode_getproperty_ioctl(struct dr
 	if (property->flags & DRM_MODE_PROP_ENUM) {
 		if ((out_resp->count_enum_blobs >= enum_count) && enum_count) {
 			copied = 0;
-			enum_ptr = (struct drm_mode_property_enum *)(unsigned long)out_resp->enum_blob_ptr;
+			enum_ptr = (struct drm_mode_property_enum __user *)(unsigned long)out_resp->enum_blob_ptr;
 			list_for_each_entry(prop_enum, &property->enum_blob_list, head) {
 
 				if (copy_to_user(&enum_ptr[copied].value, &prop_enum->value, sizeof(uint64_t))) {
@@ -2310,7 +2310,7 @@ int drm_mode_getproperty_ioctl(struct dr
 					goto done;
 				}
 
-				if (copy_to_user(&enum_ptr[copied].name,
+				if (copy_to_user(enum_ptr[copied].name,
 						 &prop_enum->name, DRM_PROP_NAME_LEN)) {
 					ret = -EFAULT;
 					goto done;
@@ -2325,7 +2325,7 @@ int drm_mode_getproperty_ioctl(struct dr
 		if ((out_resp->count_enum_blobs >= blob_count) && blob_count) {
 			copied = 0;
 			blob_id_ptr = (uint32_t *)(unsigned long)out_resp->enum_blob_ptr;
-			blob_length_ptr = (uint32_t *)(unsigned long)out_resp->values_ptr;
+			blob_length_ptr = (uint32_t __user *)(unsigned long)out_resp->values_ptr;
 
 			list_for_each_entry(prop_blob, &property->enum_blob_list, head) {
 				if (put_user(prop_blob->base.id, blob_id_ptr + copied)) {
@@ -2386,7 +2386,7 @@ int drm_mode_getblob_ioctl(struct drm_de
 	struct drm_mode_get_blob *out_resp = data;
 	struct drm_property_blob *blob;
 	int ret = 0;
-	void *blob_ptr;
+	void __user *blob_ptr;
 
 	if (!drm_core_check_feature(dev, DRIVER_MODESET))
 		return -EINVAL;
@@ -2400,7 +2400,7 @@ int drm_mode_getblob_ioctl(struct drm_de
 	blob = obj_to_blob(obj);
 
 	if (out_resp->length == blob->length) {
-		blob_ptr = (void *)(unsigned long)out_resp->data;
+		blob_ptr = (void __user *)(unsigned long)out_resp->data;
 		if (copy_to_user(blob_ptr, blob->data, blob->length)){
 			ret = -EFAULT;
 			goto done;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/drm_crtc_helper.c linux-3.2.71-pax/drivers/gpu/drm/drm_crtc_helper.c
--- linux-3.2.71/drivers/gpu/drm/drm_crtc_helper.c	2013-01-03 19:05:13.048036812 +0100
+++ linux-3.2.71-pax/drivers/gpu/drm/drm_crtc_helper.c	2013-01-03 19:05:22.052037077 +0100
@@ -279,7 +279,7 @@ static bool drm_encoder_crtc_ok(struct d
 	struct drm_crtc *tmp;
 	int crtc_mask = 1;
 
-	WARN(!crtc, "checking null crtc?\n");
+	BUG_ON(!crtc);
 
 	dev = crtc->dev;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/drm_drv.c linux-3.2.71-pax/drivers/gpu/drm/drm_drv.c
--- linux-3.2.71/drivers/gpu/drm/drm_drv.c	2014-07-12 17:42:33.760954216 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/drm_drv.c	2014-07-12 17:42:44.728954191 +0200
@@ -308,7 +308,7 @@ module_exit(drm_core_exit);
 /**
  * Copy and IOCTL return string to user space
  */
-static int drm_copy_field(char *buf, size_t *buf_len, const char *value)
+static int drm_copy_field(char __user *buf, size_t *buf_len, const char *value)
 {
 	int len;
 
@@ -378,7 +378,7 @@ long drm_ioctl(struct file *filp,
 	struct drm_file *file_priv = filp->private_data;
 	struct drm_device *dev;
 	struct drm_ioctl_desc *ioctl;
-	drm_ioctl_t *func;
+	drm_ioctl_no_const_t func;
 	unsigned int nr = DRM_IOCTL_NR(cmd);
 	int retcode = -EINVAL;
 	char stack_kdata[128];
@@ -387,7 +387,7 @@ long drm_ioctl(struct file *filp,
 
 	dev = file_priv->minor->dev;
 	atomic_inc(&dev->ioctl_count);
-	atomic_inc(&dev->counts[_DRM_STAT_IOCTLS]);
+	atomic_inc_unchecked(&dev->counts[_DRM_STAT_IOCTLS]);
 	++file_priv->ioctl_count;
 
 	DRM_DEBUG("pid=%d, cmd=0x%02x, nr=0x%02x, dev 0x%lx, auth=%d\n",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/drm_encoder_slave.c linux-3.2.71-pax/drivers/gpu/drm/drm_encoder_slave.c
--- linux-3.2.71/drivers/gpu/drm/drm_encoder_slave.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/drm_encoder_slave.c	2013-06-21 20:15:56.434564312 +0200
@@ -54,16 +54,12 @@ int drm_i2c_encoder_init(struct drm_devi
 			 struct i2c_adapter *adap,
 			 const struct i2c_board_info *info)
 {
-	char modalias[sizeof(I2C_MODULE_PREFIX)
-		      + I2C_NAME_SIZE];
 	struct module *module = NULL;
 	struct i2c_client *client;
 	struct drm_i2c_encoder_driver *encoder_drv;
 	int err = 0;
 
-	snprintf(modalias, sizeof(modalias),
-		 "%s%s", I2C_MODULE_PREFIX, info->type);
-	request_module(modalias);
+	request_module("%s%s", I2C_MODULE_PREFIX, info->type);
 
 	client = i2c_new_device(adap, info);
 	if (!client) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/drm_fops.c linux-3.2.71-pax/drivers/gpu/drm/drm_fops.c
--- linux-3.2.71/drivers/gpu/drm/drm_fops.c	2012-11-18 02:43:53.021507035 +0100
+++ linux-3.2.71-pax/drivers/gpu/drm/drm_fops.c	2012-11-18 02:46:03.469507426 +0100
@@ -71,7 +71,7 @@ static int drm_setup(struct drm_device *
 	}
 
 	for (i = 0; i < ARRAY_SIZE(dev->counts); i++)
-		atomic_set(&dev->counts[i], 0);
+		atomic_set_unchecked(&dev->counts[i], 0);
 
 	dev->sigdata.lock = NULL;
 
@@ -135,11 +135,11 @@ int drm_open(struct inode *inode, struct
 
 	retcode = drm_open_helper(inode, filp, dev);
 	if (!retcode) {
-		atomic_inc(&dev->counts[_DRM_STAT_OPENS]);
-		if (!dev->open_count++) {
+		atomic_inc_unchecked(&dev->counts[_DRM_STAT_OPENS]);
+		if (local_inc_return(&dev->open_count) == 1) {
 			retcode = drm_setup(dev);
 			if (retcode)
-				dev->open_count--;
+				local_dec(&dev->open_count);
 		}
 	}
 	if (!retcode) {
@@ -476,7 +476,7 @@ int drm_release(struct inode *inode, str
 
 	mutex_lock(&drm_global_mutex);
 
-	DRM_DEBUG("open_count = %d\n", dev->open_count);
+	DRM_DEBUG("open_count = %d\n", local_read(&dev->open_count));
 
 	if (dev->driver->preclose)
 		dev->driver->preclose(dev, file_priv);
@@ -488,7 +488,7 @@ int drm_release(struct inode *inode, str
 	DRM_DEBUG("pid = %d, device = 0x%lx, open_count = %d\n",
 		  task_pid_nr(current),
 		  (long)old_encode_dev(file_priv->minor->device),
-		  dev->open_count);
+		  local_read(&dev->open_count));
 
 	/* Release any auth tokens that might point to this file_priv,
 	   (do that under the drm_global_mutex) */
@@ -574,8 +574,8 @@ int drm_release(struct inode *inode, str
 	 * End inline drm_release
 	 */
 
-	atomic_inc(&dev->counts[_DRM_STAT_CLOSES]);
-	if (!--dev->open_count) {
+	atomic_inc_unchecked(&dev->counts[_DRM_STAT_CLOSES]);
+	if (local_dec_and_test(&dev->open_count)) {
 		if (atomic_read(&dev->ioctl_count)) {
 			DRM_ERROR("Device busy: %d\n",
 				  atomic_read(&dev->ioctl_count));
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/drm_global.c linux-3.2.71-pax/drivers/gpu/drm/drm_global.c
--- linux-3.2.71/drivers/gpu/drm/drm_global.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/drm_global.c	2012-07-04 19:24:48.360063007 +0200
@@ -36,7 +36,7 @@
 struct drm_global_item {
 	struct mutex mutex;
 	void *object;
-	int refcount;
+	atomic_t refcount;
 };
 
 static struct drm_global_item glob[DRM_GLOBAL_NUM];
@@ -49,7 +49,7 @@ void drm_global_init(void)
 		struct drm_global_item *item = &glob[i];
 		mutex_init(&item->mutex);
 		item->object = NULL;
-		item->refcount = 0;
+		atomic_set(&item->refcount, 0);
 	}
 }
 
@@ -59,7 +59,7 @@ void drm_global_release(void)
 	for (i = 0; i < DRM_GLOBAL_NUM; ++i) {
 		struct drm_global_item *item = &glob[i];
 		BUG_ON(item->object != NULL);
-		BUG_ON(item->refcount != 0);
+		BUG_ON(atomic_read(&item->refcount) != 0);
 	}
 }
 
@@ -70,7 +70,7 @@ int drm_global_item_ref(struct drm_globa
 	void *object;
 
 	mutex_lock(&item->mutex);
-	if (item->refcount == 0) {
+	if (atomic_read(&item->refcount) == 0) {
 		item->object = kzalloc(ref->size, GFP_KERNEL);
 		if (unlikely(item->object == NULL)) {
 			ret = -ENOMEM;
@@ -83,7 +83,7 @@ int drm_global_item_ref(struct drm_globa
 			goto out_err;
 
 	}
-	++item->refcount;
+	atomic_inc(&item->refcount);
 	ref->object = item->object;
 	object = item->object;
 	mutex_unlock(&item->mutex);
@@ -100,9 +100,9 @@ void drm_global_item_unref(struct drm_gl
 	struct drm_global_item *item = &glob[ref->global_type];
 
 	mutex_lock(&item->mutex);
-	BUG_ON(item->refcount == 0);
+	BUG_ON(atomic_read(&item->refcount) == 0);
 	BUG_ON(ref->object != item->object);
-	if (--item->refcount == 0) {
+	if (atomic_dec_and_test(&item->refcount)) {
 		ref->release(ref);
 		item->object = NULL;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/drm_info.c linux-3.2.71-pax/drivers/gpu/drm/drm_info.c
--- linux-3.2.71/drivers/gpu/drm/drm_info.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/drm_info.c	2012-07-04 19:24:48.360063007 +0200
@@ -75,10 +75,14 @@ int drm_vm_info(struct seq_file *m, void
 	struct drm_local_map *map;
 	struct drm_map_list *r_list;
 
-	/* Hardcoded from _DRM_FRAME_BUFFER,
-	   _DRM_REGISTERS, _DRM_SHM, _DRM_AGP, and
-	   _DRM_SCATTER_GATHER and _DRM_CONSISTENT */
-	const char *types[] = { "FB", "REG", "SHM", "AGP", "SG", "PCI" };
+	static const char * const types[] = {
+		[_DRM_FRAME_BUFFER] = "FB",
+		[_DRM_REGISTERS] = "REG",
+		[_DRM_SHM] = "SHM",
+		[_DRM_AGP] = "AGP",
+		[_DRM_SCATTER_GATHER] = "SG",
+		[_DRM_CONSISTENT] = "PCI",
+		[_DRM_GEM] = "GEM" };
 	const char *type;
 	int i;
 
@@ -89,7 +93,7 @@ int drm_vm_info(struct seq_file *m, void
 		map = r_list->map;
 		if (!map)
 			continue;
-		if (map->type < 0 || map->type > 5)
+		if (map->type >= ARRAY_SIZE(types))
 			type = "??";
 		else
 			type = types[map->type];
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/drm_ioc32.c linux-3.2.71-pax/drivers/gpu/drm/drm_ioc32.c
--- linux-3.2.71/drivers/gpu/drm/drm_ioc32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/drm_ioc32.c	2013-03-28 01:35:23.124427957 +0100
@@ -456,7 +456,7 @@ static int compat_drm_infobufs(struct fi
 	request = compat_alloc_user_space(nbytes);
 	if (!access_ok(VERIFY_WRITE, request, nbytes))
 		return -EFAULT;
-	list = (struct drm_buf_desc *) (request + 1);
+	list = (struct drm_buf_desc __user *) (request + 1);
 
 	if (__put_user(count, &request->count)
 	    || __put_user(list, &request->list))
@@ -517,7 +517,7 @@ static int compat_drm_mapbufs(struct fil
 	request = compat_alloc_user_space(nbytes);
 	if (!access_ok(VERIFY_WRITE, request, nbytes))
 		return -EFAULT;
-	list = (struct drm_buf_pub *) (request + 1);
+	list = (struct drm_buf_pub __user *) (request + 1);
 
 	if (__put_user(count, &request->count)
 	    || __put_user(list, &request->list))
@@ -1015,7 +1015,7 @@ static int compat_drm_wait_vblank(struct
 	return 0;
 }
 
-drm_ioctl_compat_t *drm_compat_ioctls[] = {
+drm_ioctl_compat_t drm_compat_ioctls[] = {
 	[DRM_IOCTL_NR(DRM_IOCTL_VERSION32)] = compat_drm_version,
 	[DRM_IOCTL_NR(DRM_IOCTL_GET_UNIQUE32)] = compat_drm_getunique,
 	[DRM_IOCTL_NR(DRM_IOCTL_GET_MAP32)] = compat_drm_getmap,
@@ -1061,7 +1061,6 @@ drm_ioctl_compat_t *drm_compat_ioctls[]
 long drm_compat_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 {
 	unsigned int nr = DRM_IOCTL_NR(cmd);
-	drm_ioctl_compat_t *fn;
 	int ret;
 
 	/* Assume that ioctls without an explicit compat routine will just
@@ -1071,10 +1070,8 @@ long drm_compat_ioctl(struct file *filp,
 	if (nr >= ARRAY_SIZE(drm_compat_ioctls))
 		return drm_ioctl(filp, cmd, arg);
 
-	fn = drm_compat_ioctls[nr];
-
-	if (fn != NULL)
-		ret = (*fn) (filp, cmd, arg);
+	if (drm_compat_ioctls[nr] != NULL)
+		ret = (*drm_compat_ioctls[nr]) (filp, cmd, arg);
 	else
 		ret = drm_ioctl(filp, cmd, arg);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/drm_ioctl.c linux-3.2.71-pax/drivers/gpu/drm/drm_ioctl.c
--- linux-3.2.71/drivers/gpu/drm/drm_ioctl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/drm_ioctl.c	2012-07-04 19:24:48.364063007 +0200
@@ -256,7 +256,7 @@ int drm_getstats(struct drm_device *dev,
 			stats->data[i].value =
 			    (file_priv->master->lock.hw_lock ? file_priv->master->lock.hw_lock->lock : 0);
 		else
-			stats->data[i].value = atomic_read(&dev->counts[i]);
+			stats->data[i].value = atomic_read_unchecked(&dev->counts[i]);
 		stats->data[i].type = dev->types[i];
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/drm_lock.c linux-3.2.71-pax/drivers/gpu/drm/drm_lock.c
--- linux-3.2.71/drivers/gpu/drm/drm_lock.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/drm_lock.c	2012-07-04 19:24:48.364063007 +0200
@@ -89,7 +89,7 @@ int drm_lock(struct drm_device *dev, voi
 		if (drm_lock_take(&master->lock, lock->context)) {
 			master->lock.file_priv = file_priv;
 			master->lock.lock_time = jiffies;
-			atomic_inc(&dev->counts[_DRM_STAT_LOCKS]);
+			atomic_inc_unchecked(&dev->counts[_DRM_STAT_LOCKS]);
 			break;	/* Got lock */
 		}
 
@@ -160,7 +160,7 @@ int drm_unlock(struct drm_device *dev, v
 		return -EINVAL;
 	}
 
-	atomic_inc(&dev->counts[_DRM_STAT_UNLOCKS]);
+	atomic_inc_unchecked(&dev->counts[_DRM_STAT_UNLOCKS]);
 
 	if (drm_lock_free(&master->lock, lock->context)) {
 		/* FIXME: Should really bail out here. */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/drm_sysfs.c linux-3.2.71-pax/drivers/gpu/drm/drm_sysfs.c
--- linux-3.2.71/drivers/gpu/drm/drm_sysfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/drm_sysfs.c	2013-06-21 20:15:56.434564312 +0200
@@ -495,7 +495,7 @@ EXPORT_SYMBOL(drm_sysfs_hotplug_event);
 int drm_sysfs_device_add(struct drm_minor *minor)
 {
 	int err;
-	char *minor_str;
+	const char *minor_str;
 
 	minor->kdev.parent = minor->dev->dev;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/i810/i810_dma.c linux-3.2.71-pax/drivers/gpu/drm/i810/i810_dma.c
--- linux-3.2.71/drivers/gpu/drm/i810/i810_dma.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/i810/i810_dma.c	2012-07-04 19:24:48.364063007 +0200
@@ -950,8 +950,8 @@ static int i810_dma_vertex(struct drm_de
 				 dma->buflist[vertex->idx],
 				 vertex->discard, vertex->used);
 
-	atomic_add(vertex->used, &dev->counts[_DRM_STAT_SECONDARY]);
-	atomic_inc(&dev->counts[_DRM_STAT_DMA]);
+	atomic_add_unchecked(vertex->used, &dev->counts[_DRM_STAT_SECONDARY]);
+	atomic_inc_unchecked(&dev->counts[_DRM_STAT_DMA]);
 	sarea_priv->last_enqueue = dev_priv->counter - 1;
 	sarea_priv->last_dispatch = (int)hw_status[5];
 
@@ -1111,8 +1111,8 @@ static int i810_dma_mc(struct drm_device
 	i810_dma_dispatch_mc(dev, dma->buflist[mc->idx], mc->used,
 			     mc->last_render);
 
-	atomic_add(mc->used, &dev->counts[_DRM_STAT_SECONDARY]);
-	atomic_inc(&dev->counts[_DRM_STAT_DMA]);
+	atomic_add_unchecked(mc->used, &dev->counts[_DRM_STAT_SECONDARY]);
+	atomic_inc_unchecked(&dev->counts[_DRM_STAT_DMA]);
 	sarea_priv->last_enqueue = dev_priv->counter - 1;
 	sarea_priv->last_dispatch = (int)hw_status[5];
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/i810/i810_drv.h linux-3.2.71-pax/drivers/gpu/drm/i810/i810_drv.h
--- linux-3.2.71/drivers/gpu/drm/i810/i810_drv.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/i810/i810_drv.h	2012-07-04 19:24:48.364063007 +0200
@@ -108,8 +108,8 @@ typedef struct drm_i810_private {
 	int page_flipping;
 
 	wait_queue_head_t irq_queue;
-	atomic_t irq_received;
-	atomic_t irq_emitted;
+	atomic_unchecked_t irq_received;
+	atomic_unchecked_t irq_emitted;
 
 	int front_offset;
 } drm_i810_private_t;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/i915/i915_debugfs.c linux-3.2.71-pax/drivers/gpu/drm/i915/i915_debugfs.c
--- linux-3.2.71/drivers/gpu/drm/i915/i915_debugfs.c	2013-03-29 02:18:43.379676034 +0100
+++ linux-3.2.71-pax/drivers/gpu/drm/i915/i915_debugfs.c	2013-03-29 02:22:27.807664051 +0100
@@ -500,7 +500,7 @@ static int i915_interrupt_info(struct se
 			   I915_READ(GTIMR));
 	}
 	seq_printf(m, "Interrupts received: %d\n",
-		   atomic_read(&dev_priv->irq_received));
+		   atomic_read_unchecked(&dev_priv->irq_received));
 	for (i = 0; i < I915_NUM_RINGS; i++) {
 		if (IS_GEN6(dev) || IS_GEN7(dev)) {
 			seq_printf(m, "Graphics Interrupt mask (%s):	%08x\n",
@@ -1234,7 +1234,7 @@ static int i915_opregion(struct seq_file
 		return ret;
 
 	if (opregion->header)
-		seq_write(m, opregion->header, OPREGION_SIZE);
+		seq_write(m, (const void __force_kernel *)opregion->header, OPREGION_SIZE);
 
 	mutex_unlock(&dev->struct_mutex);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/i915/i915_dma.c linux-3.2.71-pax/drivers/gpu/drm/i915/i915_dma.c
--- linux-3.2.71/drivers/gpu/drm/i915/i915_dma.c	2013-06-09 18:04:43.241591758 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/i915/i915_dma.c	2013-06-09 18:04:48.869591458 +0200
@@ -1172,7 +1172,7 @@ static bool i915_switcheroo_can_switch(s
 	bool can_switch;
 
 	spin_lock(&dev->count_lock);
-	can_switch = (dev->open_count == 0);
+	can_switch = (local_read(&dev->open_count) == 0);
 	spin_unlock(&dev->count_lock);
 	return can_switch;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/i915/i915_drv.h linux-3.2.71-pax/drivers/gpu/drm/i915/i915_drv.h
--- linux-3.2.71/drivers/gpu/drm/i915/i915_drv.h	2013-09-10 17:24:55.357739125 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/i915/i915_drv.h	2013-09-10 17:24:59.013738930 +0200
@@ -321,7 +321,7 @@ typedef struct drm_i915_private {
 	int current_page;
 	int page_flipping;
 
-	atomic_t irq_received;
+	atomic_unchecked_t irq_received;
 
 	/* protects the irq masks */
 	spinlock_t irq_lock;
@@ -898,7 +898,7 @@ struct drm_i915_gem_object {
 	 * will be page flipped away on the next vblank.  When it
 	 * reaches 0, dev_priv->pending_flip_queue will be woken up.
 	 */
-	atomic_t pending_flip;
+	atomic_unchecked_t pending_flip;
 };
 
 #define to_intel_bo(x) container_of(x, struct drm_i915_gem_object, base)
@@ -1275,7 +1275,7 @@ extern int intel_setup_gmbus(struct drm_
 extern void intel_teardown_gmbus(struct drm_device *dev);
 extern void intel_gmbus_set_speed(struct i2c_adapter *adapter, int speed);
 extern void intel_gmbus_force_bit(struct i2c_adapter *adapter, bool force_bit);
-extern inline bool intel_gmbus_is_forced_bit(struct i2c_adapter *adapter)
+static inline bool intel_gmbus_is_forced_bit(struct i2c_adapter *adapter)
 {
 	return container_of(adapter, struct intel_gmbus, adapter)->force_bit;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/i915/i915_gem_execbuffer.c linux-3.2.71-pax/drivers/gpu/drm/i915/i915_gem_execbuffer.c
--- linux-3.2.71/drivers/gpu/drm/i915/i915_gem_execbuffer.c	2014-07-12 17:42:33.764954216 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/i915/i915_gem_execbuffer.c	2014-07-12 17:42:44.728954191 +0200
@@ -189,7 +189,7 @@ i915_gem_object_set_to_gpu_domain(struct
 		i915_gem_clflush_object(obj);
 
 	if (obj->base.pending_write_domain)
-		cd->flips |= atomic_read(&obj->pending_flip);
+		cd->flips |= atomic_read_unchecked(&obj->pending_flip);
 
 	/* The actual obj->write_domain will be updated with
 	 * pending_write_domain after we emit the accumulated flush for all
@@ -904,9 +904,9 @@ i915_gem_check_execbuffer(struct drm_i91
 
 static int
 validate_exec_list(struct drm_i915_gem_exec_object2 *exec,
-		   int count)
+		   unsigned int count)
 {
-	int i;
+	unsigned int i;
 	int relocs_total = 0;
 	int relocs_max = INT_MAX / sizeof(struct drm_i915_gem_relocation_entry);
 
@@ -1373,7 +1373,7 @@ i915_gem_execbuffer2(struct drm_device *
 		return -ENOMEM;
 	}
 	ret = copy_from_user(exec2_list,
-			     (struct drm_i915_relocation_entry __user *)
+			     (struct drm_i915_gem_exec_object2 __user *)
 			     (uintptr_t) args->buffers_ptr,
 			     sizeof(*exec2_list) * args->buffer_count);
 	if (ret != 0) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/i915/i915_ioc32.c linux-3.2.71-pax/drivers/gpu/drm/i915/i915_ioc32.c
--- linux-3.2.71/drivers/gpu/drm/i915/i915_ioc32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/i915/i915_ioc32.c	2015-05-05 00:58:05.344159398 +0200
@@ -62,7 +62,7 @@ static int compat_i915_batchbuffer(struc
 	    || __put_user(batchbuffer32.DR4, &batchbuffer->DR4)
 	    || __put_user(batchbuffer32.num_cliprects,
 			  &batchbuffer->num_cliprects)
-	    || __put_user((int __user *)(unsigned long)batchbuffer32.cliprects,
+	    || __put_user((struct drm_clip_rect __user *)(unsigned long)batchbuffer32.cliprects,
 			  &batchbuffer->cliprects))
 		return -EFAULT;
 
@@ -91,13 +91,13 @@ static int compat_i915_cmdbuffer(struct
 
 	cmdbuffer = compat_alloc_user_space(sizeof(*cmdbuffer));
 	if (!access_ok(VERIFY_WRITE, cmdbuffer, sizeof(*cmdbuffer))
-	    || __put_user((int __user *)(unsigned long)cmdbuffer32.buf,
+	    || __put_user((char __user *)(unsigned long)cmdbuffer32.buf,
 			  &cmdbuffer->buf)
 	    || __put_user(cmdbuffer32.sz, &cmdbuffer->sz)
 	    || __put_user(cmdbuffer32.DR1, &cmdbuffer->DR1)
 	    || __put_user(cmdbuffer32.DR4, &cmdbuffer->DR4)
 	    || __put_user(cmdbuffer32.num_cliprects, &cmdbuffer->num_cliprects)
-	    || __put_user((int __user *)(unsigned long)cmdbuffer32.cliprects,
+	    || __put_user((struct drm_clip_rect __user *)(unsigned long)cmdbuffer32.cliprects,
 			  &cmdbuffer->cliprects))
 		return -EFAULT;
 
@@ -181,7 +181,7 @@ static int compat_i915_alloc(struct file
 			 (unsigned long)request);
 }
 
-drm_ioctl_compat_t *i915_compat_ioctls[] = {
+drm_ioctl_compat_t i915_compat_ioctls[] = {
 	[DRM_I915_BATCHBUFFER] = compat_i915_batchbuffer,
 	[DRM_I915_CMDBUFFER] = compat_i915_cmdbuffer,
 	[DRM_I915_GETPARAM] = compat_i915_getparam,
@@ -201,17 +201,13 @@ drm_ioctl_compat_t *i915_compat_ioctls[]
 long i915_compat_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 {
 	unsigned int nr = DRM_IOCTL_NR(cmd);
-	drm_ioctl_compat_t *fn = NULL;
 	int ret;
 
 	if (nr < DRM_COMMAND_BASE)
 		return drm_compat_ioctl(filp, cmd, arg);
 
-	if (nr < DRM_COMMAND_BASE + DRM_ARRAY_SIZE(i915_compat_ioctls))
-		fn = i915_compat_ioctls[nr - DRM_COMMAND_BASE];
-
-	if (fn != NULL)
-		ret = (*fn) (filp, cmd, arg);
+	if (nr < DRM_COMMAND_BASE + DRM_ARRAY_SIZE(i915_compat_ioctls) && i915_compat_ioctls[nr - DRM_COMMAND_BASE])
+		ret = (*i915_compat_ioctls[nr - DRM_COMMAND_BASE]) (filp, cmd, arg);
 	else
 		ret = drm_ioctl(filp, cmd, arg);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/i915/i915_irq.c linux-3.2.71-pax/drivers/gpu/drm/i915/i915_irq.c
--- linux-3.2.71/drivers/gpu/drm/i915/i915_irq.c	2013-01-03 19:05:13.080036813 +0100
+++ linux-3.2.71-pax/drivers/gpu/drm/i915/i915_irq.c	2013-01-03 19:05:22.056037077 +0100
@@ -496,7 +496,7 @@ static irqreturn_t ivybridge_irq_handler
 	u32 de_iir, gt_iir, de_ier, pch_iir, pm_iir;
 	struct drm_i915_master_private *master_priv;
 
-	atomic_inc(&dev_priv->irq_received);
+	atomic_inc_unchecked(&dev_priv->irq_received);
 
 	/* disable master interrupt before clearing iir  */
 	de_ier = I915_READ(DEIER);
@@ -579,7 +579,7 @@ static irqreturn_t ironlake_irq_handler(
 	struct drm_i915_master_private *master_priv;
 	u32 bsd_usr_interrupt = GT_BSD_USER_INTERRUPT;
 
-	atomic_inc(&dev_priv->irq_received);
+	atomic_inc_unchecked(&dev_priv->irq_received);
 
 	if (IS_GEN6(dev))
 		bsd_usr_interrupt = GT_GEN6_BSD_USER_INTERRUPT;
@@ -1229,7 +1229,7 @@ static irqreturn_t i915_driver_irq_handl
 	int ret = IRQ_NONE, pipe;
 	bool blc_event = false;
 
-	atomic_inc(&dev_priv->irq_received);
+	atomic_inc_unchecked(&dev_priv->irq_received);
 
 	iir = I915_READ(IIR);
 
@@ -1748,7 +1748,7 @@ static void ironlake_irq_preinstall(stru
 {
 	drm_i915_private_t *dev_priv = (drm_i915_private_t *) dev->dev_private;
 
-	atomic_set(&dev_priv->irq_received, 0);
+	atomic_set_unchecked(&dev_priv->irq_received, 0);
 
 	INIT_WORK(&dev_priv->hotplug_work, i915_hotplug_work_func);
 	INIT_WORK(&dev_priv->error_work, i915_error_work_func);
@@ -1936,7 +1936,7 @@ static void i915_driver_irq_preinstall(s
 	drm_i915_private_t *dev_priv = (drm_i915_private_t *) dev->dev_private;
 	int pipe;
 
-	atomic_set(&dev_priv->irq_received, 0);
+	atomic_set_unchecked(&dev_priv->irq_received, 0);
 
 	INIT_WORK(&dev_priv->hotplug_work, i915_hotplug_work_func);
 	INIT_WORK(&dev_priv->error_work, i915_error_work_func);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/i915/intel_display.c linux-3.2.71-pax/drivers/gpu/drm/i915/intel_display.c
--- linux-3.2.71/drivers/gpu/drm/i915/intel_display.c	2014-04-30 18:53:45.376223431 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/i915/intel_display.c	2014-04-30 18:53:50.416223420 +0200
@@ -2215,7 +2215,7 @@ intel_finish_fb(struct drm_framebuffer *
 
 	wait_event(dev_priv->pending_flip_queue,
 		   atomic_read(&dev_priv->mm.wedged) ||
-		   atomic_read(&obj->pending_flip) == 0);
+		   atomic_read_unchecked(&obj->pending_flip) == 0);
 
 	/* Big Hammer, we also need to ensure that any pending
 	 * MI_WAIT_FOR_EVENT inside a user batch buffer on the
@@ -6991,8 +6991,7 @@ static void do_intel_finish_page_flip(st
 
 	obj = work->old_fb_obj;
 
-	atomic_clear_mask(1 << intel_crtc->plane,
-			  &obj->pending_flip.counter);
+	atomic_clear_mask_unchecked(1 << intel_crtc->plane, &obj->pending_flip);
 
 	wake_up(&dev_priv->pending_flip_queue);
 	schedule_work(&work->work);
@@ -7201,7 +7200,13 @@ static int intel_gen6_queue_flip(struct
 	OUT_RING(fb->pitch | obj->tiling_mode);
 	OUT_RING(obj->gtt_offset);
 
-	pf = I915_READ(PF_CTL(intel_crtc->pipe)) & PF_ENABLE;
+	/* Contrary to the suggestions in the documentation,
+	 * "Enable Panel Fitter" does not seem to be required when page
+	 * flipping with a non-native mode, and worse causes a normal
+	 * modeset to fail.
+	 * pf = I915_READ(PF_CTL(intel_crtc->pipe)) & PF_ENABLE;
+	 */
+	pf = 0;
 	pipesrc = I915_READ(PIPESRC(intel_crtc->pipe)) & 0x0fff0fff;
 	OUT_RING(pf | pipesrc);
 
@@ -7347,7 +7352,7 @@ static int intel_crtc_page_flip(struct d
 	/* Block clients from rendering to the new back buffer until
 	 * the flip occurs and the object is no longer visible.
 	 */
-	atomic_add(1 << intel_crtc->plane, &work->old_fb_obj->pending_flip);
+	atomic_add_unchecked(1 << intel_crtc->plane, &work->old_fb_obj->pending_flip);
 
 	ret = dev_priv->display.queue_flip(dev, crtc, fb, obj);
 	if (ret)
@@ -7361,7 +7366,7 @@ static int intel_crtc_page_flip(struct d
 	return 0;
 
 cleanup_pending:
-	atomic_sub(1 << intel_crtc->plane, &work->old_fb_obj->pending_flip);
+	atomic_sub_unchecked(1 << intel_crtc->plane, &work->old_fb_obj->pending_flip);
 	crtc->fb = old_fb;
 	drm_gem_object_unreference(&work->old_fb_obj->base);
 	drm_gem_object_unreference(&obj->base);
@@ -7496,11 +7501,15 @@ static void intel_crtc_init(struct drm_d
 	if (HAS_PCH_SPLIT(dev)) {
 		if (pipe == 2 && IS_IVYBRIDGE(dev))
 			intel_crtc->no_pll = true;
-		intel_helper_funcs.prepare = ironlake_crtc_prepare;
-		intel_helper_funcs.commit = ironlake_crtc_commit;
+		pax_open_kernel();
+		*(void **)&intel_helper_funcs.prepare = ironlake_crtc_prepare;
+		*(void **)&intel_helper_funcs.commit = ironlake_crtc_commit;
+		pax_close_kernel();
 	} else {
-		intel_helper_funcs.prepare = i9xx_crtc_prepare;
-		intel_helper_funcs.commit = i9xx_crtc_commit;
+		pax_open_kernel();
+		*(void **)&intel_helper_funcs.prepare = i9xx_crtc_prepare;
+		*(void **)&intel_helper_funcs.commit = i9xx_crtc_commit;
+		pax_close_kernel();
 	}
 
 	drm_crtc_helper_add(&intel_crtc->base, &intel_helper_funcs);
@@ -8876,7 +8885,7 @@ struct intel_quirk {
 	int subsystem_vendor;
 	int subsystem_device;
 	void (*hook)(struct drm_device *dev);
-};
+} __do_const;
 
 /* For systems that don't have a meaningful PCI subdevice/subvendor ID */
 struct intel_dmi_quirk {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/mga/mga_drv.h linux-3.2.71-pax/drivers/gpu/drm/mga/mga_drv.h
--- linux-3.2.71/drivers/gpu/drm/mga/mga_drv.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/mga/mga_drv.h	2012-07-04 19:24:48.376063007 +0200
@@ -120,9 +120,9 @@ typedef struct drm_mga_private {
 	u32 clear_cmd;
 	u32 maccess;
 
-	atomic_t vbl_received;          /**< Number of vblanks received. */
+	atomic_unchecked_t vbl_received;          /**< Number of vblanks received. */
 	wait_queue_head_t fence_queue;
-	atomic_t last_fence_retired;
+	atomic_unchecked_t last_fence_retired;
 	u32 next_fence_to_post;
 
 	unsigned int fb_cpp;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/mga/mga_ioc32.c linux-3.2.71-pax/drivers/gpu/drm/mga/mga_ioc32.c
--- linux-3.2.71/drivers/gpu/drm/mga/mga_ioc32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/mga/mga_ioc32.c	2015-05-05 00:58:05.344159398 +0200
@@ -190,7 +190,7 @@ static int compat_mga_dma_bootstrap(stru
 	return 0;
 }
 
-drm_ioctl_compat_t *mga_compat_ioctls[] = {
+drm_ioctl_compat_t mga_compat_ioctls[] = {
 	[DRM_MGA_INIT] = compat_mga_init,
 	[DRM_MGA_GETPARAM] = compat_mga_getparam,
 	[DRM_MGA_DMA_BOOTSTRAP] = compat_mga_dma_bootstrap,
@@ -208,17 +208,13 @@ drm_ioctl_compat_t *mga_compat_ioctls[]
 long mga_compat_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 {
 	unsigned int nr = DRM_IOCTL_NR(cmd);
-	drm_ioctl_compat_t *fn = NULL;
 	int ret;
 
 	if (nr < DRM_COMMAND_BASE)
 		return drm_compat_ioctl(filp, cmd, arg);
 
-	if (nr < DRM_COMMAND_BASE + DRM_ARRAY_SIZE(mga_compat_ioctls))
-		fn = mga_compat_ioctls[nr - DRM_COMMAND_BASE];
-
-	if (fn != NULL)
-		ret = (*fn) (filp, cmd, arg);
+	if (nr < DRM_COMMAND_BASE + DRM_ARRAY_SIZE(mga_compat_ioctls) && mga_compat_ioctls[nr - DRM_COMMAND_BASE])
+		ret = (*mga_compat_ioctls[nr - DRM_COMMAND_BASE]) (filp, cmd, arg);
 	else
 		ret = drm_ioctl(filp, cmd, arg);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/mga/mga_irq.c linux-3.2.71-pax/drivers/gpu/drm/mga/mga_irq.c
--- linux-3.2.71/drivers/gpu/drm/mga/mga_irq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/mga/mga_irq.c	2012-07-04 19:24:48.376063007 +0200
@@ -44,7 +44,7 @@ u32 mga_get_vblank_counter(struct drm_de
 	if (crtc != 0)
 		return 0;
 
-	return atomic_read(&dev_priv->vbl_received);
+	return atomic_read_unchecked(&dev_priv->vbl_received);
 }
 
 
@@ -60,7 +60,7 @@ irqreturn_t mga_driver_irq_handler(DRM_I
 	/* VBLANK interrupt */
 	if (status & MGA_VLINEPEN) {
 		MGA_WRITE(MGA_ICLEAR, MGA_VLINEICLR);
-		atomic_inc(&dev_priv->vbl_received);
+		atomic_inc_unchecked(&dev_priv->vbl_received);
 		drm_handle_vblank(dev, 0);
 		handled = 1;
 	}
@@ -79,7 +79,7 @@ irqreturn_t mga_driver_irq_handler(DRM_I
 		if ((prim_start & ~0x03) != (prim_end & ~0x03))
 			MGA_WRITE(MGA_PRIMEND, prim_end);
 
-		atomic_inc(&dev_priv->last_fence_retired);
+		atomic_inc_unchecked(&dev_priv->last_fence_retired);
 		DRM_WAKEUP(&dev_priv->fence_queue);
 		handled = 1;
 	}
@@ -130,7 +130,7 @@ int mga_driver_fence_wait(struct drm_dev
 	 * using fences.
 	 */
 	DRM_WAIT_ON(ret, dev_priv->fence_queue, 3 * DRM_HZ,
-		    (((cur_fence = atomic_read(&dev_priv->last_fence_retired))
+		    (((cur_fence = atomic_read_unchecked(&dev_priv->last_fence_retired))
 		      - *sequence) <= (1 << 23)));
 
 	*sequence = cur_fence;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/nouveau/nouveau_bios.c linux-3.2.71-pax/drivers/gpu/drm/nouveau/nouveau_bios.c
--- linux-3.2.71/drivers/gpu/drm/nouveau/nouveau_bios.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/nouveau/nouveau_bios.c	2014-01-16 03:23:24.818140526 +0100
@@ -5474,7 +5474,7 @@ parse_bit_U_tbl_entry(struct drm_device
 struct bit_table {
 	const char id;
 	int (* const parse_fn)(struct drm_device *, struct nvbios *, struct bit_entry *);
-};
+} __no_const;
 
 #define BIT_TABLE(id, funcid) ((struct bit_table){ id, parse_bit_##funcid##_tbl_entry })
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/nouveau/nouveau_drv.h linux-3.2.71-pax/drivers/gpu/drm/nouveau/nouveau_drv.h
--- linux-3.2.71/drivers/gpu/drm/nouveau/nouveau_drv.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/nouveau/nouveau_drv.h	2013-03-28 04:29:23.135870542 +0100
@@ -238,7 +238,7 @@ struct nouveau_channel {
 		struct list_head pending;
 		uint32_t sequence;
 		uint32_t sequence_ack;
-		atomic_t last_sequence_irq;
+		atomic_unchecked_t last_sequence_irq;
 		struct nouveau_vma vma;
 	} fence;
 
@@ -319,7 +319,7 @@ struct nouveau_exec_engine {
 			   u32 handle, u16 class);
 	void (*set_tile_region)(struct drm_device *dev, int i);
 	void (*tlb_flush)(struct drm_device *, int engine);
-};
+} __no_const;
 
 struct nouveau_instmem_engine {
 	void	*priv;
@@ -341,13 +341,13 @@ struct nouveau_instmem_engine {
 struct nouveau_mc_engine {
 	int  (*init)(struct drm_device *dev);
 	void (*takedown)(struct drm_device *dev);
-};
+} __no_const;
 
 struct nouveau_timer_engine {
 	int      (*init)(struct drm_device *dev);
 	void     (*takedown)(struct drm_device *dev);
 	uint64_t (*read)(struct drm_device *dev);
-};
+} __no_const;
 
 struct nouveau_fb_engine {
 	int num_tiles;
@@ -706,7 +706,7 @@ struct drm_nouveau_private {
 		struct drm_global_reference mem_global_ref;
 		struct ttm_bo_global_ref bo_global_ref;
 		struct ttm_bo_device bdev;
-		atomic_t validate_sequence;
+		atomic_unchecked_t validate_sequence;
 	} ttm;
 
 	struct {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/nouveau/nouveau_fence.c linux-3.2.71-pax/drivers/gpu/drm/nouveau/nouveau_fence.c
--- linux-3.2.71/drivers/gpu/drm/nouveau/nouveau_fence.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/nouveau/nouveau_fence.c	2012-07-04 19:24:48.384063007 +0200
@@ -85,7 +85,7 @@ nouveau_fence_update(struct nouveau_chan
 		if (USE_REFCNT(dev))
 			sequence = nvchan_rd32(chan, 0x48);
 		else
-			sequence = atomic_read(&chan->fence.last_sequence_irq);
+			sequence = atomic_read_unchecked(&chan->fence.last_sequence_irq);
 
 		if (chan->fence.sequence_ack == sequence)
 			goto out;
@@ -539,7 +539,7 @@ nouveau_fence_channel_init(struct nouvea
 			return ret;
 	}
 
-	atomic_set(&chan->fence.last_sequence_irq, 0);
+	atomic_set_unchecked(&chan->fence.last_sequence_irq, 0);
 	return 0;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/nouveau/nouveau_gem.c linux-3.2.71-pax/drivers/gpu/drm/nouveau/nouveau_gem.c
--- linux-3.2.71/drivers/gpu/drm/nouveau/nouveau_gem.c	2014-01-03 15:48:44.724070579 +0100
+++ linux-3.2.71-pax/drivers/gpu/drm/nouveau/nouveau_gem.c	2014-01-03 15:48:49.524070322 +0100
@@ -315,7 +315,7 @@ validate_init(struct nouveau_channel *ch
 	int trycnt = 0;
 	int ret, i;
 
-	sequence = atomic_add_return(1, &dev_priv->ttm.validate_sequence);
+	sequence = atomic_add_return_unchecked(1, &dev_priv->ttm.validate_sequence);
 retry:
 	if (++trycnt > 100000) {
 		NV_ERROR(dev, "%s failed and gave up.\n", __func__);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/nouveau/nouveau_ioc32.c linux-3.2.71-pax/drivers/gpu/drm/nouveau/nouveau_ioc32.c
--- linux-3.2.71/drivers/gpu/drm/nouveau/nouveau_ioc32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/nouveau/nouveau_ioc32.c	2013-03-28 01:35:23.268427950 +0100
@@ -51,7 +51,7 @@ long nouveau_compat_ioctl(struct file *f
 			 unsigned long arg)
 {
 	unsigned int nr = DRM_IOCTL_NR(cmd);
-	drm_ioctl_compat_t *fn = NULL;
+	drm_ioctl_compat_t fn = NULL;
 	int ret;
 
 	if (nr < DRM_COMMAND_BASE)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/nouveau/nouveau_state.c linux-3.2.71-pax/drivers/gpu/drm/nouveau/nouveau_state.c
--- linux-3.2.71/drivers/gpu/drm/nouveau/nouveau_state.c	2012-11-18 02:43:53.025507450 +0100
+++ linux-3.2.71-pax/drivers/gpu/drm/nouveau/nouveau_state.c	2012-11-18 02:43:58.945511176 +0100
@@ -544,7 +544,7 @@ static bool nouveau_switcheroo_can_switc
 	bool can_switch;
 
 	spin_lock(&dev->count_lock);
-	can_switch = (dev->open_count == 0);
+	can_switch = (local_read(&dev->open_count) == 0);
 	spin_unlock(&dev->count_lock);
 	return can_switch;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/nouveau/nv04_graph.c linux-3.2.71-pax/drivers/gpu/drm/nouveau/nv04_graph.c
--- linux-3.2.71/drivers/gpu/drm/nouveau/nv04_graph.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/nouveau/nv04_graph.c	2012-07-04 19:24:48.392063007 +0200
@@ -554,7 +554,7 @@ static int
 nv04_graph_mthd_set_ref(struct nouveau_channel *chan,
 			u32 class, u32 mthd, u32 data)
 {
-	atomic_set(&chan->fence.last_sequence_irq, data);
+	atomic_set_unchecked(&chan->fence.last_sequence_irq, data);
 	return 0;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/r128/r128_cce.c linux-3.2.71-pax/drivers/gpu/drm/r128/r128_cce.c
--- linux-3.2.71/drivers/gpu/drm/r128/r128_cce.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/r128/r128_cce.c	2012-07-04 19:24:48.392063007 +0200
@@ -378,7 +378,7 @@ static int r128_do_init_cce(struct drm_d
 
 	/* GH: Simple idle check.
 	 */
-	atomic_set(&dev_priv->idle_count, 0);
+	atomic_set_unchecked(&dev_priv->idle_count, 0);
 
 	/* We don't support anything other than bus-mastering ring mode,
 	 * but the ring can be in either AGP or PCI space for the ring
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/r128/r128_drv.h linux-3.2.71-pax/drivers/gpu/drm/r128/r128_drv.h
--- linux-3.2.71/drivers/gpu/drm/r128/r128_drv.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/r128/r128_drv.h	2012-07-04 19:24:48.392063007 +0200
@@ -90,14 +90,14 @@ typedef struct drm_r128_private {
 	int is_pci;
 	unsigned long cce_buffers_offset;
 
-	atomic_t idle_count;
+	atomic_unchecked_t idle_count;
 
 	int page_flipping;
 	int current_page;
 	u32 crtc_offset;
 	u32 crtc_offset_cntl;
 
-	atomic_t vbl_received;
+	atomic_unchecked_t vbl_received;
 
 	u32 color_fmt;
 	unsigned int front_offset;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/r128/r128_ioc32.c linux-3.2.71-pax/drivers/gpu/drm/r128/r128_ioc32.c
--- linux-3.2.71/drivers/gpu/drm/r128/r128_ioc32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/r128/r128_ioc32.c	2015-05-05 00:58:05.344159398 +0200
@@ -178,7 +178,7 @@ static int compat_r128_getparam(struct f
 	return drm_ioctl(file, DRM_IOCTL_R128_GETPARAM, (unsigned long)getparam);
 }
 
-drm_ioctl_compat_t *r128_compat_ioctls[] = {
+drm_ioctl_compat_t r128_compat_ioctls[] = {
 	[DRM_R128_INIT] = compat_r128_init,
 	[DRM_R128_DEPTH] = compat_r128_depth,
 	[DRM_R128_STIPPLE] = compat_r128_stipple,
@@ -197,17 +197,13 @@ drm_ioctl_compat_t *r128_compat_ioctls[]
 long r128_compat_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 {
 	unsigned int nr = DRM_IOCTL_NR(cmd);
-	drm_ioctl_compat_t *fn = NULL;
 	int ret;
 
 	if (nr < DRM_COMMAND_BASE)
 		return drm_compat_ioctl(filp, cmd, arg);
 
-	if (nr < DRM_COMMAND_BASE + DRM_ARRAY_SIZE(r128_compat_ioctls))
-		fn = r128_compat_ioctls[nr - DRM_COMMAND_BASE];
-
-	if (fn != NULL)
-		ret = (*fn) (filp, cmd, arg);
+	if (nr < DRM_COMMAND_BASE + DRM_ARRAY_SIZE(r128_compat_ioctls) && r128_compat_ioctls[nr - DRM_COMMAND_BASE])
+		ret = (*r128_compat_ioctls[nr - DRM_COMMAND_BASE]) (filp, cmd, arg);
 	else
 		ret = drm_ioctl(filp, cmd, arg);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/r128/r128_irq.c linux-3.2.71-pax/drivers/gpu/drm/r128/r128_irq.c
--- linux-3.2.71/drivers/gpu/drm/r128/r128_irq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/r128/r128_irq.c	2012-07-04 19:24:48.392063007 +0200
@@ -42,7 +42,7 @@ u32 r128_get_vblank_counter(struct drm_d
 	if (crtc != 0)
 		return 0;
 
-	return atomic_read(&dev_priv->vbl_received);
+	return atomic_read_unchecked(&dev_priv->vbl_received);
 }
 
 irqreturn_t r128_driver_irq_handler(DRM_IRQ_ARGS)
@@ -56,7 +56,7 @@ irqreturn_t r128_driver_irq_handler(DRM_
 	/* VBLANK interrupt */
 	if (status & R128_CRTC_VBLANK_INT) {
 		R128_WRITE(R128_GEN_INT_STATUS, R128_CRTC_VBLANK_INT_AK);
-		atomic_inc(&dev_priv->vbl_received);
+		atomic_inc_unchecked(&dev_priv->vbl_received);
 		drm_handle_vblank(dev, 0);
 		return IRQ_HANDLED;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/r128/r128_state.c linux-3.2.71-pax/drivers/gpu/drm/r128/r128_state.c
--- linux-3.2.71/drivers/gpu/drm/r128/r128_state.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/r128/r128_state.c	2012-07-04 19:24:48.396063007 +0200
@@ -321,10 +321,10 @@ static void r128_clear_box(drm_r128_priv
 
 static void r128_cce_performance_boxes(drm_r128_private_t *dev_priv)
 {
-	if (atomic_read(&dev_priv->idle_count) == 0)
+	if (atomic_read_unchecked(&dev_priv->idle_count) == 0)
 		r128_clear_box(dev_priv, 64, 4, 8, 8, 0, 255, 0);
 	else
-		atomic_set(&dev_priv->idle_count, 0);
+		atomic_set_unchecked(&dev_priv->idle_count, 0);
 }
 
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/evergreen.c linux-3.2.71-pax/drivers/gpu/drm/radeon/evergreen.c
--- linux-3.2.71/drivers/gpu/drm/radeon/evergreen.c	2015-05-10 09:22:37.003493027 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/evergreen.c	2015-05-10 09:23:09.003494765 +0200
@@ -3098,7 +3098,9 @@ static int evergreen_startup(struct rade
 	r = evergreen_blit_init(rdev);
 	if (r) {
 		r600_blit_fini(rdev);
-		rdev->asic->copy = NULL;
+		pax_open_kernel();
+		*(void **)&rdev->asic->copy = NULL;
+		pax_close_kernel();
 		dev_warn(rdev->dev, "failed blitter (%d) falling back to memcpy\n", r);
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/mkregtable.c linux-3.2.71-pax/drivers/gpu/drm/radeon/mkregtable.c
--- linux-3.2.71/drivers/gpu/drm/radeon/mkregtable.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/mkregtable.c	2012-07-04 19:24:48.396063007 +0200
@@ -637,14 +637,14 @@ static int parser_auth(struct table *t,
 	regex_t mask_rex;
 	regmatch_t match[4];
 	char buf[1024];
-	size_t end;
+	long end;
 	int len;
 	int done = 0;
 	int r;
 	unsigned o;
 	struct offset *offset;
 	char last_reg_s[10];
-	int last_reg;
+	unsigned long last_reg;
 
 	if (regcomp
 	    (&mask_rex, "(0x[0-9a-fA-F]*) *([_a-zA-Z0-9]*)", REG_EXTENDED)) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/ni.c linux-3.2.71-pax/drivers/gpu/drm/radeon/ni.c
--- linux-3.2.71/drivers/gpu/drm/radeon/ni.c	2013-09-10 17:24:55.369739125 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/ni.c	2013-09-10 17:24:59.029738929 +0200
@@ -1380,7 +1380,9 @@ static int cayman_startup(struct radeon_
 	r = evergreen_blit_init(rdev);
 	if (r) {
 		r600_blit_fini(rdev);
-		rdev->asic->copy = NULL;
+		pax_open_kernel();
+		*(void **)&rdev->asic->copy = NULL;
+		pax_close_kernel();
 		dev_warn(rdev->dev, "failed blitter (%d) falling back to memcpy\n", r);
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/r100.c linux-3.2.71-pax/drivers/gpu/drm/radeon/r100.c
--- linux-3.2.71/drivers/gpu/drm/radeon/r100.c	2015-05-10 09:22:37.003493027 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/r100.c	2015-05-10 09:23:09.003494765 +0200
@@ -592,8 +592,10 @@ int r100_pci_gart_init(struct radeon_dev
 	if (r)
 		return r;
 	rdev->gart.table_size = rdev->gart.num_gpu_pages * 4;
-	rdev->asic->gart_tlb_flush = &r100_pci_gart_tlb_flush;
-	rdev->asic->gart_set_page = &r100_pci_gart_set_page;
+	pax_open_kernel();
+	*(void **)&rdev->asic->gart_tlb_flush = &r100_pci_gart_tlb_flush;
+	*(void **)&rdev->asic->gart_set_page = &r100_pci_gart_set_page;
+	pax_close_kernel();
 	return radeon_gart_table_ram_alloc(rdev);
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/r300.c linux-3.2.71-pax/drivers/gpu/drm/radeon/r300.c
--- linux-3.2.71/drivers/gpu/drm/radeon/r300.c	2013-06-21 21:22:07.650352280 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/r300.c	2013-06-21 21:21:57.302352832 +0200
@@ -105,8 +105,10 @@ int rv370_pcie_gart_init(struct radeon_d
 	if (r)
 		DRM_ERROR("Failed to register debugfs file for PCIE gart !\n");
 	rdev->gart.table_size = rdev->gart.num_gpu_pages * 4;
-	rdev->asic->gart_tlb_flush = &rv370_pcie_gart_tlb_flush;
-	rdev->asic->gart_set_page = &rv370_pcie_gart_set_page;
+	pax_open_kernel();
+	*(void **)&rdev->asic->gart_tlb_flush = &rv370_pcie_gart_tlb_flush;
+	*(void **)&rdev->asic->gart_set_page = &rv370_pcie_gart_set_page;
+	pax_close_kernel();
 	return radeon_gart_table_vram_alloc(rdev);
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/r600.c linux-3.2.71-pax/drivers/gpu/drm/radeon/r600.c
--- linux-3.2.71/drivers/gpu/drm/radeon/r600.c	2015-05-10 09:22:37.007493027 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/r600.c	2015-05-10 09:23:09.007494765 +0200
@@ -2442,7 +2442,9 @@ int r600_startup(struct radeon_device *r
 	r = r600_blit_init(rdev);
 	if (r) {
 		r600_blit_fini(rdev);
-		rdev->asic->copy = NULL;
+		pax_open_kernel();
+		*(void **)&rdev->asic->copy = NULL;
+		pax_close_kernel();
 		dev_warn(rdev->dev, "failed blitter (%d) falling back to memcpy\n", r);
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/radeon_asic.c linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_asic.c
--- linux-3.2.71/drivers/gpu/drm/radeon/radeon_asic.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_asic.c	2013-01-17 00:15:32.706603364 +0100
@@ -114,13 +114,17 @@ void radeon_agp_disable(struct radeon_de
 			rdev->family == CHIP_R423) {
 		DRM_INFO("Forcing AGP to PCIE mode\n");
 		rdev->flags |= RADEON_IS_PCIE;
-		rdev->asic->gart_tlb_flush = &rv370_pcie_gart_tlb_flush;
-		rdev->asic->gart_set_page = &rv370_pcie_gart_set_page;
+		pax_open_kernel();
+		*(void **)&rdev->asic->gart_tlb_flush = &rv370_pcie_gart_tlb_flush;
+		*(void **)&rdev->asic->gart_set_page = &rv370_pcie_gart_set_page;
+		pax_close_kernel();
 	} else {
 		DRM_INFO("Forcing AGP to PCI mode\n");
 		rdev->flags |= RADEON_IS_PCI;
-		rdev->asic->gart_tlb_flush = &r100_pci_gart_tlb_flush;
-		rdev->asic->gart_set_page = &r100_pci_gart_set_page;
+		pax_open_kernel();
+		*(void **)&rdev->asic->gart_tlb_flush = &r100_pci_gart_tlb_flush;
+		*(void **)&rdev->asic->gart_set_page = &r100_pci_gart_set_page;
+		pax_close_kernel();
 	}
 	rdev->mc.gtt_size = radeon_gart_size * 1024 * 1024;
 }
@@ -974,10 +978,12 @@ int radeon_asic_init(struct radeon_devic
 		rdev->asic = &r420_asic;
 		/* handle macs */
 		if (rdev->bios == NULL) {
-			rdev->asic->get_engine_clock = &radeon_legacy_get_engine_clock;
-			rdev->asic->set_engine_clock = &radeon_legacy_set_engine_clock;
-			rdev->asic->get_memory_clock = &radeon_legacy_get_memory_clock;
-			rdev->asic->set_memory_clock = NULL;
+			pax_open_kernel();
+			*(void **)&rdev->asic->get_engine_clock = &radeon_legacy_get_engine_clock;
+			*(void **)&rdev->asic->set_engine_clock = &radeon_legacy_set_engine_clock;
+			*(void **)&rdev->asic->get_memory_clock = &radeon_legacy_get_memory_clock;
+			*(void **)&rdev->asic->set_memory_clock = NULL;
+			pax_close_kernel();
 		}
 		break;
 	case CHIP_RS400:
@@ -1057,8 +1063,10 @@ int radeon_asic_init(struct radeon_devic
 	}
 
 	if (rdev->flags & RADEON_IS_IGP) {
-		rdev->asic->get_memory_clock = NULL;
-		rdev->asic->set_memory_clock = NULL;
+		pax_open_kernel();
+		*(void **)&rdev->asic->get_memory_clock = NULL;
+		*(void **)&rdev->asic->set_memory_clock = NULL;
+		pax_close_kernel();
 	}
 
 	return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/radeon_device.c linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_device.c
--- linux-3.2.71/drivers/gpu/drm/radeon/radeon_device.c	2013-10-27 17:59:57.020642397 +0100
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_device.c	2013-10-27 18:00:09.468641733 +0100
@@ -687,7 +687,7 @@ static bool radeon_switcheroo_can_switch
 	bool can_switch;
 
 	spin_lock(&dev->count_lock);
-	can_switch = (dev->open_count == 0);
+	can_switch = (local_read(&dev->open_count) == 0);
 	spin_unlock(&dev->count_lock);
 	return can_switch;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/radeon_drv.h linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_drv.h
--- linux-3.2.71/drivers/gpu/drm/radeon/radeon_drv.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_drv.h	2012-07-04 19:24:48.396063007 +0200
@@ -255,7 +255,7 @@ typedef struct drm_radeon_private {
 
 	/* SW interrupt */
 	wait_queue_head_t swi_queue;
-	atomic_t swi_emitted;
+	atomic_unchecked_t swi_emitted;
 	int vblank_crtc;
 	uint32_t irq_enable_reg;
 	uint32_t r500_disp_irq_reg;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/radeon_fence.c linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_fence.c
--- linux-3.2.71/drivers/gpu/drm/radeon/radeon_fence.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_fence.c	2012-07-04 19:24:48.400063007 +0200
@@ -78,7 +78,7 @@ int radeon_fence_emit(struct radeon_devi
 		write_unlock_irqrestore(&rdev->fence_drv.lock, irq_flags);
 		return 0;
 	}
-	fence->seq = atomic_add_return(1, &rdev->fence_drv.seq);
+	fence->seq = atomic_add_return_unchecked(1, &rdev->fence_drv.seq);
 	if (!rdev->cp.ready)
 		/* FIXME: cp is not running assume everythings is done right
 		 * away
@@ -373,7 +373,7 @@ int radeon_fence_driver_init(struct rade
 		return r;
 	}
 	radeon_fence_write(rdev, 0);
-	atomic_set(&rdev->fence_drv.seq, 0);
+	atomic_set_unchecked(&rdev->fence_drv.seq, 0);
 	INIT_LIST_HEAD(&rdev->fence_drv.created);
 	INIT_LIST_HEAD(&rdev->fence_drv.emited);
 	INIT_LIST_HEAD(&rdev->fence_drv.signaled);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/radeon.h linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon.h
--- linux-3.2.71/drivers/gpu/drm/radeon/radeon.h	2012-09-12 12:17:18.775311267 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon.h	2013-01-16 21:42:45.922815197 +0100
@@ -177,7 +177,7 @@ extern int sumo_get_temp(struct radeon_d
  */
 struct radeon_fence_driver {
 	uint32_t			scratch_reg;
-	atomic_t			seq;
+	atomic_unchecked_t		seq;
 	uint32_t			last_seq;
 	unsigned long			last_jiffies;
 	unsigned long			last_timeout;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/radeon_ioc32.c linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_ioc32.c
--- linux-3.2.71/drivers/gpu/drm/radeon/radeon_ioc32.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_ioc32.c	2015-05-05 00:58:05.344159398 +0200
@@ -359,7 +359,7 @@ static int compat_radeon_cp_setparam(str
 	request = compat_alloc_user_space(sizeof(*request));
 	if (!access_ok(VERIFY_WRITE, request, sizeof(*request))
 	    || __put_user(req32.param, &request->param)
-	    || __put_user((void __user *)(unsigned long)req32.value,
+	    || __put_user((unsigned long)req32.value,
 			  &request->value))
 		return -EFAULT;
 
@@ -369,7 +369,7 @@ static int compat_radeon_cp_setparam(str
 #define compat_radeon_cp_setparam NULL
 #endif /* X86_64 || IA64 */
 
-drm_ioctl_compat_t *radeon_compat_ioctls[] = {
+drm_ioctl_compat_t radeon_compat_ioctls[] = {
 	[DRM_RADEON_CP_INIT] = compat_radeon_cp_init,
 	[DRM_RADEON_CLEAR] = compat_radeon_cp_clear,
 	[DRM_RADEON_STIPPLE] = compat_radeon_cp_stipple,
@@ -394,17 +394,13 @@ drm_ioctl_compat_t *radeon_compat_ioctls
 long radeon_compat_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 {
 	unsigned int nr = DRM_IOCTL_NR(cmd);
-	drm_ioctl_compat_t *fn = NULL;
 	int ret;
 
 	if (nr < DRM_COMMAND_BASE)
 		return drm_compat_ioctl(filp, cmd, arg);
 
-	if (nr < DRM_COMMAND_BASE + DRM_ARRAY_SIZE(radeon_compat_ioctls))
-		fn = radeon_compat_ioctls[nr - DRM_COMMAND_BASE];
-
-	if (fn != NULL)
-		ret = (*fn) (filp, cmd, arg);
+	if (nr < DRM_COMMAND_BASE + DRM_ARRAY_SIZE(radeon_compat_ioctls) && radeon_compat_ioctls[nr - DRM_COMMAND_BASE])
+		ret = (*radeon_compat_ioctls[nr - DRM_COMMAND_BASE]) (filp, cmd, arg);
 	else
 		ret = drm_ioctl(filp, cmd, arg);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/radeon_irq.c linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_irq.c
--- linux-3.2.71/drivers/gpu/drm/radeon/radeon_irq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_irq.c	2012-07-04 19:24:48.400063007 +0200
@@ -225,8 +225,8 @@ static int radeon_emit_irq(struct drm_de
 	unsigned int ret;
 	RING_LOCALS;
 
-	atomic_inc(&dev_priv->swi_emitted);
-	ret = atomic_read(&dev_priv->swi_emitted);
+	atomic_inc_unchecked(&dev_priv->swi_emitted);
+	ret = atomic_read_unchecked(&dev_priv->swi_emitted);
 
 	BEGIN_RING(4);
 	OUT_RING_REG(RADEON_LAST_SWI_REG, ret);
@@ -352,7 +352,7 @@ int radeon_driver_irq_postinstall(struct
 	drm_radeon_private_t *dev_priv =
 	    (drm_radeon_private_t *) dev->dev_private;
 
-	atomic_set(&dev_priv->swi_emitted, 0);
+	atomic_set_unchecked(&dev_priv->swi_emitted, 0);
 	DRM_INIT_WAITQUEUE(&dev_priv->swi_queue);
 
 	dev->max_vblank_count = 0x001fffff;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/radeon_ring.c linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_ring.c
--- linux-3.2.71/drivers/gpu/drm/radeon/radeon_ring.c	2013-02-20 12:30:42.040171944 +0100
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_ring.c	2013-03-28 14:38:36.013918901 +0100
@@ -487,16 +487,20 @@ int radeon_debugfs_ib_init(struct radeon
 	unsigned i;
 	int r;
 
-	radeon_debugfs_ib_bogus_info_list[0].data = rdev;
+	pax_open_kernel();
+	*(void **)&radeon_debugfs_ib_bogus_info_list[0].data = rdev;
+	pax_close_kernel();
 	r = radeon_debugfs_add_files(rdev, radeon_debugfs_ib_bogus_info_list, 1);
 	if (r)
 		return r;
 	for (i = 0; i < RADEON_IB_POOL_SIZE; i++) {
 		sprintf(radeon_debugfs_ib_names[i], "radeon_ib_%04u", i);
-		radeon_debugfs_ib_list[i].name = radeon_debugfs_ib_names[i];
-		radeon_debugfs_ib_list[i].show = &radeon_debugfs_ib_info;
-		radeon_debugfs_ib_list[i].driver_features = 0;
-		radeon_debugfs_ib_list[i].data = &rdev->ib_pool.ibs[i];
+		pax_open_kernel();
+		*(void **)&radeon_debugfs_ib_list[i].name = radeon_debugfs_ib_names[i];
+		*(void **)&radeon_debugfs_ib_list[i].show = &radeon_debugfs_ib_info;
+		*(u32 *)&radeon_debugfs_ib_list[i].driver_features = 0;
+		*(void **)&radeon_debugfs_ib_list[i].data = &rdev->ib_pool.ibs[i];
+		pax_close_kernel();
 	}
 	return radeon_debugfs_add_files(rdev, radeon_debugfs_ib_list,
 					RADEON_IB_POOL_SIZE);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/radeon_state.c linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_state.c
--- linux-3.2.71/drivers/gpu/drm/radeon/radeon_state.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_state.c	2012-07-04 19:24:48.404063007 +0200
@@ -2168,7 +2168,7 @@ static int radeon_cp_clear(struct drm_de
 	if (sarea_priv->nbox > RADEON_NR_SAREA_CLIPRECTS)
 		sarea_priv->nbox = RADEON_NR_SAREA_CLIPRECTS;
 
-	if (DRM_COPY_FROM_USER(&depth_boxes, clear->depth_boxes,
+	if (sarea_priv->nbox > RADEON_NR_SAREA_CLIPRECTS || DRM_COPY_FROM_USER(&depth_boxes, clear->depth_boxes,
 			       sarea_priv->nbox * sizeof(depth_boxes[0])))
 		return -EFAULT;
 
@@ -3031,7 +3031,7 @@ static int radeon_cp_getparam(struct drm
 {
 	drm_radeon_private_t *dev_priv = dev->dev_private;
 	drm_radeon_getparam_t *param = data;
-	int value;
+	int value = 0;
 
 	DRM_DEBUG("pid=%d\n", DRM_CURRENTPID);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/radeon_ttm.c linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_ttm.c
--- linux-3.2.71/drivers/gpu/drm/radeon/radeon_ttm.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/radeon_ttm.c	2013-07-09 03:09:46.559940971 +0200
@@ -631,7 +631,7 @@ void radeon_ttm_set_active_vram_size(str
 	man->size = size >> PAGE_SHIFT;
 }
 
-static struct vm_operations_struct radeon_ttm_vm_ops;
+static vm_operations_struct_no_const radeon_ttm_vm_ops __read_only;
 static const struct vm_operations_struct *ttm_vm_ops = NULL;
 
 static int radeon_ttm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
@@ -672,8 +672,10 @@ int radeon_mmap(struct file *filp, struc
 	}
 	if (unlikely(ttm_vm_ops == NULL)) {
 		ttm_vm_ops = vma->vm_ops;
+		pax_open_kernel();
 		radeon_ttm_vm_ops = *ttm_vm_ops;
 		radeon_ttm_vm_ops.fault = &radeon_ttm_fault;
+		pax_close_kernel();
 	}
 	vma->vm_ops = &radeon_ttm_vm_ops;
 	return 0;
@@ -820,30 +822,25 @@ static int radeon_mm_dump_table(struct s
 static int radeon_ttm_debugfs_init(struct radeon_device *rdev)
 {
 #if defined(CONFIG_DEBUG_FS)
-	static struct drm_info_list radeon_mem_types_list[RADEON_DEBUGFS_MEM_TYPES+1];
-	static char radeon_mem_types_names[RADEON_DEBUGFS_MEM_TYPES+1][32];
-	unsigned i;
-
-	for (i = 0; i < RADEON_DEBUGFS_MEM_TYPES; i++) {
-		if (i == 0)
-			sprintf(radeon_mem_types_names[i], "radeon_vram_mm");
-		else
-			sprintf(radeon_mem_types_names[i], "radeon_gtt_mm");
-		radeon_mem_types_list[i].name = radeon_mem_types_names[i];
-		radeon_mem_types_list[i].show = &radeon_mm_dump_table;
-		radeon_mem_types_list[i].driver_features = 0;
-		if (i == 0)
-			radeon_mem_types_list[i].data = rdev->mman.bdev.man[TTM_PL_VRAM].priv;
-		else
-			radeon_mem_types_list[i].data = rdev->mman.bdev.man[TTM_PL_TT].priv;
-
-	}
-	/* Add ttm page pool to debugfs */
-	sprintf(radeon_mem_types_names[i], "ttm_page_pool");
-	radeon_mem_types_list[i].name = radeon_mem_types_names[i];
-	radeon_mem_types_list[i].show = &ttm_page_alloc_debugfs;
-	radeon_mem_types_list[i].driver_features = 0;
-	radeon_mem_types_list[i].data = NULL;
+	static struct drm_info_list radeon_mem_types_list[RADEON_DEBUGFS_MEM_TYPES+1] = {
+		{
+			.name = "radeon_vram_mm",
+			.show = &radeon_mm_dump_table,
+		},
+		{
+			.name = "radeon_gtt_mm",
+			.show = &radeon_mm_dump_table,
+		},
+		{
+			.name = "ttm_page_pool",
+			.show = &ttm_page_alloc_debugfs,
+		},
+	};
+
+	pax_open_kernel();
+	*(void **)&radeon_mem_types_list[0].data = rdev->mman.bdev.man[TTM_PL_VRAM].priv;
+	*(void **)&radeon_mem_types_list[1].data = rdev->mman.bdev.man[TTM_PL_TT].priv;
+	pax_close_kernel();
 	return radeon_debugfs_add_files(rdev, radeon_mem_types_list, RADEON_DEBUGFS_MEM_TYPES+1);
 
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/rs690.c linux-3.2.71-pax/drivers/gpu/drm/radeon/rs690.c
--- linux-3.2.71/drivers/gpu/drm/radeon/rs690.c	2014-02-16 00:01:51.612847721 +0100
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/rs690.c	2014-02-16 00:01:57.708847395 +0100
@@ -314,9 +314,11 @@ void rs690_crtc_bandwidth_compute(struct
 		if (rdev->pm.max_bandwidth.full > rdev->pm.sideport_bandwidth.full &&
 			rdev->pm.sideport_bandwidth.full)
 			rdev->pm.max_bandwidth = rdev->pm.sideport_bandwidth;
-		read_delay_latency.full = dfixed_const(370 * 800 * 1000);
+		read_delay_latency.full = dfixed_const(800 * 1000);
 		read_delay_latency.full = dfixed_div(read_delay_latency,
 			rdev->pm.igp_sideport_mclk);
+		a.full = dfixed_const(370);
+		read_delay_latency.full = dfixed_mul(read_delay_latency, a);
 	} else {
 		if (rdev->pm.max_bandwidth.full > rdev->pm.k8_bandwidth.full &&
 			rdev->pm.k8_bandwidth.full)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/radeon/rv770.c linux-3.2.71-pax/drivers/gpu/drm/radeon/rv770.c
--- linux-3.2.71/drivers/gpu/drm/radeon/rv770.c	2013-09-10 17:24:55.373739125 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/radeon/rv770.c	2013-09-10 17:24:59.033738929 +0200
@@ -1083,7 +1083,9 @@ static int rv770_startup(struct radeon_d
 	r = r600_blit_init(rdev);
 	if (r) {
 		r600_blit_fini(rdev);
-		rdev->asic->copy = NULL;
+		pax_open_kernel();
+		*(void **)&rdev->asic->copy = NULL;
+		pax_close_kernel();
 		dev_warn(rdev->dev, "failed blitter (%d) falling back to memcpy\n", r);
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/ttm/ttm_memory.c linux-3.2.71-pax/drivers/gpu/drm/ttm/ttm_memory.c
--- linux-3.2.71/drivers/gpu/drm/ttm/ttm_memory.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/ttm/ttm_memory.c	2013-06-21 20:15:56.434564312 +0200
@@ -263,7 +263,7 @@ static int ttm_mem_init_kernel_zone(stru
 	zone->glob = glob;
 	glob->zone_kernel = zone;
 	ret = kobject_init_and_add(
-		&zone->kobj, &ttm_mem_zone_kobj_type, &glob->kobj, zone->name);
+		&zone->kobj, &ttm_mem_zone_kobj_type, &glob->kobj, "%s", zone->name);
 	if (unlikely(ret != 0)) {
 		kobject_put(&zone->kobj);
 		return ret;
@@ -346,7 +346,7 @@ static int ttm_mem_init_dma32_zone(struc
 	zone->glob = glob;
 	glob->zone_dma32 = zone;
 	ret = kobject_init_and_add(
-		&zone->kobj, &ttm_mem_zone_kobj_type, &glob->kobj, zone->name);
+		&zone->kobj, &ttm_mem_zone_kobj_type, &glob->kobj, "%s", zone->name);
 	if (unlikely(ret != 0)) {
 		kobject_put(&zone->kobj);
 		return ret;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/ttm/ttm_page_alloc.c linux-3.2.71-pax/drivers/gpu/drm/ttm/ttm_page_alloc.c
--- linux-3.2.71/drivers/gpu/drm/ttm/ttm_page_alloc.c	2014-09-14 14:10:58.542117594 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/ttm/ttm_page_alloc.c	2015-01-05 18:41:27.888452157 +0100
@@ -51,7 +51,7 @@
 
 #define NUM_PAGES_TO_ALLOC		(PAGE_SIZE/sizeof(struct page *))
 #define SMALL_ALLOCATION		16
-#define FREE_ALL_PAGES			(~0U)
+#define FREE_ALL_PAGES			(~0UL)
 /* times are in msecs */
 #define PAGE_FREE_INTERVAL		1000
 
@@ -301,13 +301,12 @@ static void ttm_pool_update_free_locked(
  * @pool: to free the pages from
  * @free_all: If set to true will free all pages in pool
  **/
-static int ttm_page_pool_free(struct ttm_page_pool *pool, unsigned nr_free)
+static unsigned long ttm_page_pool_free(struct ttm_page_pool *pool, unsigned long nr_free)
 {
 	unsigned long irq_flags;
 	struct page *p;
 	struct page **pages_to_free;
-	unsigned freed_pages = 0,
-		 npages_to_free = nr_free;
+	unsigned long freed_pages = 0, npages_to_free = nr_free;
 
 	if (NUM_PAGES_TO_ALLOC < nr_free)
 		npages_to_free = NUM_PAGES_TO_ALLOC;
@@ -369,7 +368,8 @@ restart:
 		__list_del(&p->lru, &pool->list);
 
 		ttm_pool_update_free_locked(pool, freed_pages);
-		nr_free -= freed_pages;
+		if (likely(nr_free != FREE_ALL_PAGES))
+			nr_free -= freed_pages;
 	}
 
 	spin_unlock_irqrestore(&pool->lock, irq_flags);
@@ -403,7 +403,7 @@ static int ttm_pool_mm_shrink(struct shr
 	unsigned i;
 	unsigned pool_offset;
 	struct ttm_page_pool *pool;
-	int shrink_pages = sc->nr_to_scan;
+	unsigned long shrink_pages = sc->nr_to_scan;
 
 	if (shrink_pages == 0)
 		goto out;
@@ -412,7 +412,7 @@ static int ttm_pool_mm_shrink(struct shr
 	pool_offset = ++start_pool % NUM_POOLS;
 	/* select start pool in round robin fashion */
 	for (i = 0; i < NUM_POOLS; ++i) {
-		unsigned nr_free = shrink_pages;
+		unsigned long nr_free = shrink_pages;
 		if (shrink_pages == 0)
 			break;
 		pool = &_manager->pools[(i + pool_offset)%NUM_POOLS];
@@ -744,7 +744,7 @@ int ttm_get_pages(struct list_head *page
 }
 
 /* Put all pages in pages list to correct pool to wait for reuse */
-void ttm_put_pages(struct list_head *pages, unsigned page_count, int flags,
+void ttm_put_pages(struct list_head *pages, unsigned long page_count, int flags,
 		   enum ttm_caching_state cstate, dma_addr_t *dma_address)
 {
 	unsigned long irq_flags;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/via/via_drv.h linux-3.2.71-pax/drivers/gpu/drm/via/via_drv.h
--- linux-3.2.71/drivers/gpu/drm/via/via_drv.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/via/via_drv.h	2012-07-04 19:24:48.404063007 +0200
@@ -51,7 +51,7 @@ typedef struct drm_via_ring_buffer {
 typedef uint32_t maskarray_t[5];
 
 typedef struct drm_via_irq {
-	atomic_t irq_received;
+	atomic_unchecked_t irq_received;
 	uint32_t pending_mask;
 	uint32_t enable_mask;
 	wait_queue_head_t irq_queue;
@@ -75,7 +75,7 @@ typedef struct drm_via_private {
 	struct timeval last_vblank;
 	int last_vblank_valid;
 	unsigned usec_per_vblank;
-	atomic_t vbl_received;
+	atomic_unchecked_t vbl_received;
 	drm_via_state_t hc_state;
 	char pci_buf[VIA_PCI_BUF_SIZE];
 	const uint32_t *fire_offsets[VIA_FIRE_BUF_SIZE];
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/via/via_irq.c linux-3.2.71-pax/drivers/gpu/drm/via/via_irq.c
--- linux-3.2.71/drivers/gpu/drm/via/via_irq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/via/via_irq.c	2012-07-04 19:24:48.408063007 +0200
@@ -102,7 +102,7 @@ u32 via_get_vblank_counter(struct drm_de
 	if (crtc != 0)
 		return 0;
 
-	return atomic_read(&dev_priv->vbl_received);
+	return atomic_read_unchecked(&dev_priv->vbl_received);
 }
 
 irqreturn_t via_driver_irq_handler(DRM_IRQ_ARGS)
@@ -117,8 +117,8 @@ irqreturn_t via_driver_irq_handler(DRM_I
 
 	status = VIA_READ(VIA_REG_INTERRUPT);
 	if (status & VIA_IRQ_VBLANK_PENDING) {
-		atomic_inc(&dev_priv->vbl_received);
-		if (!(atomic_read(&dev_priv->vbl_received) & 0x0F)) {
+		atomic_inc_unchecked(&dev_priv->vbl_received);
+		if (!(atomic_read_unchecked(&dev_priv->vbl_received) & 0x0F)) {
 			do_gettimeofday(&cur_vblank);
 			if (dev_priv->last_vblank_valid) {
 				dev_priv->usec_per_vblank =
@@ -128,7 +128,7 @@ irqreturn_t via_driver_irq_handler(DRM_I
 			dev_priv->last_vblank = cur_vblank;
 			dev_priv->last_vblank_valid = 1;
 		}
-		if (!(atomic_read(&dev_priv->vbl_received) & 0xFF)) {
+		if (!(atomic_read_unchecked(&dev_priv->vbl_received) & 0xFF)) {
 			DRM_DEBUG("US per vblank is: %u\n",
 				  dev_priv->usec_per_vblank);
 		}
@@ -138,7 +138,7 @@ irqreturn_t via_driver_irq_handler(DRM_I
 
 	for (i = 0; i < dev_priv->num_irqs; ++i) {
 		if (status & cur_irq->pending_mask) {
-			atomic_inc(&cur_irq->irq_received);
+			atomic_inc_unchecked(&cur_irq->irq_received);
 			DRM_WAKEUP(&cur_irq->irq_queue);
 			handled = 1;
 			if (dev_priv->irq_map[drm_via_irq_dma0_td] == i)
@@ -243,11 +243,11 @@ via_driver_irq_wait(struct drm_device *d
 		DRM_WAIT_ON(ret, cur_irq->irq_queue, 3 * DRM_HZ,
 			    ((VIA_READ(masks[irq][2]) & masks[irq][3]) ==
 			     masks[irq][4]));
-		cur_irq_sequence = atomic_read(&cur_irq->irq_received);
+		cur_irq_sequence = atomic_read_unchecked(&cur_irq->irq_received);
 	} else {
 		DRM_WAIT_ON(ret, cur_irq->irq_queue, 3 * DRM_HZ,
 			    (((cur_irq_sequence =
-			       atomic_read(&cur_irq->irq_received)) -
+			       atomic_read_unchecked(&cur_irq->irq_received)) -
 			      *sequence) <= (1 << 23)));
 	}
 	*sequence = cur_irq_sequence;
@@ -285,7 +285,7 @@ void via_driver_irq_preinstall(struct dr
 		}
 
 		for (i = 0; i < dev_priv->num_irqs; ++i) {
-			atomic_set(&cur_irq->irq_received, 0);
+			atomic_set_unchecked(&cur_irq->irq_received, 0);
 			cur_irq->enable_mask = dev_priv->irq_masks[i][0];
 			cur_irq->pending_mask = dev_priv->irq_masks[i][1];
 			DRM_INIT_WAITQUEUE(&cur_irq->irq_queue);
@@ -367,7 +367,7 @@ int via_wait_irq(struct drm_device *dev,
 	switch (irqwait->request.type & ~VIA_IRQ_FLAGS_MASK) {
 	case VIA_IRQ_RELATIVE:
 		irqwait->request.sequence +=
-			atomic_read(&cur_irq->irq_received);
+			atomic_read_unchecked(&cur_irq->irq_received);
 		irqwait->request.type &= ~_DRM_VBLANK_RELATIVE;
 	case VIA_IRQ_ABSOLUTE:
 		break;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/vmwgfx/vmwgfx_drv.h linux-3.2.71-pax/drivers/gpu/drm/vmwgfx/vmwgfx_drv.h
--- linux-3.2.71/drivers/gpu/drm/vmwgfx/vmwgfx_drv.h	2012-09-20 01:42:17.194672774 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/vmwgfx/vmwgfx_drv.h	2012-09-20 01:42:29.894672813 +0200
@@ -260,7 +260,7 @@ struct vmw_private {
 	 * Fencing and IRQs.
 	 */
 
-	atomic_t marker_seq;
+	atomic_unchecked_t marker_seq;
 	wait_queue_head_t fence_queue;
 	wait_queue_head_t fifo_queue;
 	int fence_queue_waiters; /* Protected by hw_mutex */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c linux-3.2.71-pax/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c
--- linux-3.2.71/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c	2014-11-05 23:20:30.001389714 +0100
+++ linux-3.2.71-pax/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c	2014-11-05 23:20:50.481398806 +0100
@@ -137,7 +137,7 @@ int vmw_fifo_init(struct vmw_private *de
 		 (unsigned int) min,
 		 (unsigned int) fifo->capabilities);
 
-	atomic_set(&dev_priv->marker_seq, dev_priv->last_read_seqno);
+	atomic_set_unchecked(&dev_priv->marker_seq, dev_priv->last_read_seqno);
 	iowrite32(dev_priv->last_read_seqno, fifo_mem + SVGA_FIFO_FENCE);
 	vmw_marker_queue_init(&fifo->marker_queue);
 	return vmw_fifo_send_fence(dev_priv, &dummy);
@@ -356,7 +356,7 @@ void *vmw_fifo_reserve(struct vmw_privat
 				if (reserveable)
 					iowrite32(bytes, fifo_mem +
 						  SVGA_FIFO_RESERVED);
-				return fifo_mem + (next_cmd >> 2);
+				return (__le32 __force_kernel *)fifo_mem + (next_cmd >> 2);
 			} else {
 				need_bounce = true;
 			}
@@ -476,7 +476,7 @@ int vmw_fifo_send_fence(struct vmw_priva
 
 	fm = vmw_fifo_reserve(dev_priv, bytes);
 	if (unlikely(fm == NULL)) {
-		*seqno = atomic_read(&dev_priv->marker_seq);
+		*seqno = atomic_read_unchecked(&dev_priv->marker_seq);
 		ret = -ENOMEM;
 		(void)vmw_fallback_wait(dev_priv, false, true, *seqno,
 					false, 3*HZ);
@@ -484,7 +484,7 @@ int vmw_fifo_send_fence(struct vmw_priva
 	}
 
 	do {
-		*seqno = atomic_add_return(1, &dev_priv->marker_seq);
+		*seqno = atomic_add_return_unchecked(1, &dev_priv->marker_seq);
 	} while (*seqno == 0);
 
 	if (!(fifo_state->capabilities & SVGA_FIFO_CAP_FENCE)) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/vmwgfx/vmwgfx_ioctl.c linux-3.2.71-pax/drivers/gpu/drm/vmwgfx/vmwgfx_ioctl.c
--- linux-3.2.71/drivers/gpu/drm/vmwgfx/vmwgfx_ioctl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/vmwgfx/vmwgfx_ioctl.c	2013-06-21 19:34:10.638698102 +0200
@@ -135,7 +135,7 @@ int vmw_present_ioctl(struct drm_device
 	int ret;
 
 	num_clips = arg->num_clips;
-	clips_ptr = (struct drm_vmw_rect *)(unsigned long)arg->clips_ptr;
+	clips_ptr = (struct drm_vmw_rect __user *)(unsigned long)arg->clips_ptr;
 
 	if (unlikely(num_clips == 0))
 		return 0;
@@ -221,7 +221,7 @@ int vmw_present_readback_ioctl(struct dr
 	int ret;
 
 	num_clips = arg->num_clips;
-	clips_ptr = (struct drm_vmw_rect *)(unsigned long)arg->clips_ptr;
+	clips_ptr = (struct drm_vmw_rect __user *)(unsigned long)arg->clips_ptr;
 
 	if (unlikely(num_clips == 0))
 		return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/vmwgfx/vmwgfx_irq.c linux-3.2.71-pax/drivers/gpu/drm/vmwgfx/vmwgfx_irq.c
--- linux-3.2.71/drivers/gpu/drm/vmwgfx/vmwgfx_irq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/vmwgfx/vmwgfx_irq.c	2012-07-04 19:24:48.408063007 +0200
@@ -107,7 +107,7 @@ bool vmw_seqno_passed(struct vmw_private
 	 * emitted. Then the fence is stale and signaled.
 	 */
 
-	ret = ((atomic_read(&dev_priv->marker_seq) - seqno)
+	ret = ((atomic_read_unchecked(&dev_priv->marker_seq) - seqno)
 	       > VMW_FENCE_WRAP);
 
 	return ret;
@@ -138,7 +138,7 @@ int vmw_fallback_wait(struct vmw_private
 
 	if (fifo_idle)
 		down_read(&fifo_state->rwsem);
-	signal_seq = atomic_read(&dev_priv->marker_seq);
+	signal_seq = atomic_read_unchecked(&dev_priv->marker_seq);
 	ret = 0;
 
 	for (;;) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/gpu/drm/vmwgfx/vmwgfx_marker.c linux-3.2.71-pax/drivers/gpu/drm/vmwgfx/vmwgfx_marker.c
--- linux-3.2.71/drivers/gpu/drm/vmwgfx/vmwgfx_marker.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/gpu/drm/vmwgfx/vmwgfx_marker.c	2012-07-04 19:24:48.408063007 +0200
@@ -151,7 +151,7 @@ int vmw_wait_lag(struct vmw_private *dev
 	while (!vmw_lag_lt(queue, us)) {
 		spin_lock(&queue->lock);
 		if (list_empty(&queue->head))
-			seqno = atomic_read(&dev_priv->marker_seq);
+			seqno = atomic_read_unchecked(&dev_priv->marker_seq);
 		else {
 			marker = list_first_entry(&queue->head,
 						 struct vmw_marker, head);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hid/hid-core.c linux-3.2.71-pax/drivers/hid/hid-core.c
--- linux-3.2.71/drivers/hid/hid-core.c	2014-07-12 17:42:33.768954216 +0200
+++ linux-3.2.71-pax/drivers/hid/hid-core.c	2014-07-12 17:42:44.732954191 +0200
@@ -2112,7 +2112,7 @@ static bool hid_ignore(struct hid_device
 
 int hid_add_device(struct hid_device *hdev)
 {
-	static atomic_t id = ATOMIC_INIT(0);
+	static atomic_unchecked_t id = ATOMIC_INIT(0);
 	int ret;
 
 	if (WARN_ON(hdev->status & HID_STAT_ADDED))
@@ -2127,7 +2127,7 @@ int hid_add_device(struct hid_device *hd
 	/* XXX hack, any other cleaner solution after the driver core
 	 * is converted to allow more than 20 bytes as the device name? */
 	dev_set_name(&hdev->dev, "%04X:%04X:%04X.%04X", hdev->bus,
-		     hdev->vendor, hdev->product, atomic_inc_return(&id));
+		     hdev->vendor, hdev->product, atomic_inc_return_unchecked(&id));
 
 	hid_debug_register(hdev, dev_name(&hdev->dev));
 	ret = device_add(&hdev->dev);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hid/usbhid/hiddev.c linux-3.2.71-pax/drivers/hid/usbhid/hiddev.c
--- linux-3.2.71/drivers/hid/usbhid/hiddev.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/hid/usbhid/hiddev.c	2012-07-04 19:24:48.412063007 +0200
@@ -624,7 +624,7 @@ static long hiddev_ioctl(struct file *fi
 		break;
 
 	case HIDIOCAPPLICATION:
-		if (arg < 0 || arg >= hid->maxapplication)
+		if (arg >= hid->maxapplication)
 			break;
 
 		for (i = 0; i < hid->maxcollection; i++)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hv/channel.c linux-3.2.71-pax/drivers/hv/channel.c
--- linux-3.2.71/drivers/hv/channel.c	2015-08-07 11:37:20.435789890 +0200
+++ linux-3.2.71-pax/drivers/hv/channel.c	2015-08-07 11:37:43.003790553 +0200
@@ -406,8 +406,8 @@ int vmbus_establish_gpadl(struct vmbus_c
 	unsigned long flags;
 	int ret = 0;
 
-	next_gpadl_handle = atomic_read(&vmbus_connection.next_gpadl_handle);
-	atomic_inc(&vmbus_connection.next_gpadl_handle);
+	next_gpadl_handle = atomic_read_unchecked(&vmbus_connection.next_gpadl_handle);
+	atomic_inc_unchecked(&vmbus_connection.next_gpadl_handle);
 
 	ret = create_gpadl_header(kbuffer, size, &msginfo, &msgcount);
 	if (ret)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hv/hv.c linux-3.2.71-pax/drivers/hv/hv.c
--- linux-3.2.71/drivers/hv/hv.c	2014-12-14 21:13:45.062054818 +0100
+++ linux-3.2.71-pax/drivers/hv/hv.c	2014-12-14 21:13:52.774069225 +0100
@@ -132,7 +132,7 @@ static u64 do_hypercall(u64 control, voi
 	u64 output_address = (output) ? virt_to_phys(output) : 0;
 	u32 output_address_hi = output_address >> 32;
 	u32 output_address_lo = output_address & 0xFFFFFFFF;
-	void *hypercall_page = hv_context.hypercall_page;
+	void *hypercall_page = ktva_ktla(hv_context.hypercall_page);
 
 	__asm__ __volatile__ ("call *%8" : "=d"(hv_status_hi),
 			      "=a"(hv_status_lo) : "d" (control_hi),
@@ -178,7 +178,7 @@ int hv_init(void)
 	/* See if the hypercall page is already set */
 	rdmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);
 
-	virtaddr = __vmalloc(PAGE_SIZE, GFP_KERNEL, PAGE_KERNEL_EXEC);
+	virtaddr = __vmalloc(PAGE_SIZE, GFP_KERNEL, PAGE_KERNEL_RX);
 
 	if (!virtaddr)
 		goto cleanup;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hv/hyperv_vmbus.h linux-3.2.71-pax/drivers/hv/hyperv_vmbus.h
--- linux-3.2.71/drivers/hv/hyperv_vmbus.h	2014-12-14 21:13:45.062054818 +0100
+++ linux-3.2.71-pax/drivers/hv/hyperv_vmbus.h	2014-12-14 21:13:52.774069225 +0100
@@ -560,7 +560,7 @@ enum vmbus_connect_state {
 struct vmbus_connection {
 	enum vmbus_connect_state conn_state;
 
-	atomic_t next_gpadl_handle;
+	atomic_unchecked_t next_gpadl_handle;
 
 	/*
 	 * Represents channel interrupts. Each bit position represents a
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hv/vmbus_drv.c linux-3.2.71-pax/drivers/hv/vmbus_drv.c
--- linux-3.2.71/drivers/hv/vmbus_drv.c	2015-03-06 19:43:09.680464844 +0100
+++ linux-3.2.71-pax/drivers/hv/vmbus_drv.c	2015-03-06 19:43:13.324464649 +0100
@@ -663,10 +663,10 @@ int vmbus_device_register(struct hv_devi
 {
 	int ret = 0;
 
-	static atomic_t device_num = ATOMIC_INIT(0);
+	static atomic_unchecked_t device_num = ATOMIC_INIT(0);
 
 	dev_set_name(&child_device_obj->device, "vmbus_0_%d",
-		     atomic_inc_return(&device_num));
+		     atomic_inc_return_unchecked(&device_num));
 
 	child_device_obj->device.bus = &hv_bus;
 	child_device_obj->device.parent = &hv_acpi_dev->dev;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hwmon/acpi_power_meter.c linux-3.2.71-pax/drivers/hwmon/acpi_power_meter.c
--- linux-3.2.71/drivers/hwmon/acpi_power_meter.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/hwmon/acpi_power_meter.c	2015-04-30 03:07:38.396532395 +0200
@@ -124,7 +124,7 @@ struct rw_sensor_template {
 		       struct device_attribute *devattr,
 		       const char *buf, size_t count);
 	int index;
-};
+} __do_const;
 
 /* Averaging interval */
 static int update_avg_interval(struct acpi_power_meter_resource *resource)
@@ -316,8 +316,6 @@ static ssize_t set_trip(struct device *d
 		return res;
 
 	temp /= 1000;
-	if (temp < 0)
-		return -EINVAL;
 
 	mutex_lock(&resource->lock);
 	resource->trip[attr->index - 7] = temp;
@@ -622,7 +620,7 @@ static int register_ro_attrs(struct acpi
 			     struct ro_sensor_template *ro)
 {
 	struct device *dev = &resource->acpi_dev->dev;
-	struct sensor_device_attribute *sensors =
+	sensor_device_attribute_no_const *sensors =
 		&resource->sensors[resource->num_sensors];
 	int res = 0;
 
@@ -650,7 +648,7 @@ static int register_rw_attrs(struct acpi
 			     struct rw_sensor_template *rw)
 {
 	struct device *dev = &resource->acpi_dev->dev;
-	struct sensor_device_attribute *sensors =
+	sensor_device_attribute_no_const *sensors =
 		&resource->sensors[resource->num_sensors];
 	int res = 0;
 
@@ -981,7 +979,7 @@ static int __init enable_cap_knobs(const
 	return 0;
 }
 
-static struct dmi_system_id __initdata pm_dmi_table[] = {
+static const struct dmi_system_id __initconst pm_dmi_table[] = {
 	{
 		enable_cap_knobs, "IBM Active Energy Manager",
 		{
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hwmon/applesmc.c linux-3.2.71-pax/drivers/hwmon/applesmc.c
--- linux-3.2.71/drivers/hwmon/applesmc.c	2013-11-29 01:58:28.606491617 +0100
+++ linux-3.2.71-pax/drivers/hwmon/applesmc.c	2013-11-29 01:58:37.658491883 +0100
@@ -1082,7 +1082,7 @@ static int applesmc_create_nodes(struct
 {
 	struct applesmc_node_group *grp;
 	struct applesmc_dev_attr *node;
-	struct attribute *attr;
+	attribute_no_const *attr;
 	int ret, i;
 
 	for (grp = groups; grp->format; grp++) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hwmon/asus_atk0110.c linux-3.2.71-pax/drivers/hwmon/asus_atk0110.c
--- linux-3.2.71/drivers/hwmon/asus_atk0110.c	2012-09-20 01:42:17.202672773 +0200
+++ linux-3.2.71-pax/drivers/hwmon/asus_atk0110.c	2013-03-28 01:35:23.272427950 +0100
@@ -149,10 +149,10 @@ MODULE_DEVICE_TABLE(acpi, atk_ids);
 struct atk_sensor_data {
 	struct list_head list;
 	struct atk_data *data;
-	struct device_attribute label_attr;
-	struct device_attribute input_attr;
-	struct device_attribute limit1_attr;
-	struct device_attribute limit2_attr;
+	device_attribute_no_const label_attr;
+	device_attribute_no_const input_attr;
+	device_attribute_no_const limit1_attr;
+	device_attribute_no_const limit2_attr;
 	char label_attr_name[ATTR_NAME_SIZE];
 	char input_attr_name[ATTR_NAME_SIZE];
 	char limit1_attr_name[ATTR_NAME_SIZE];
@@ -271,7 +271,7 @@ static ssize_t atk_name_show(struct devi
 static struct device_attribute atk_name_attr =
 		__ATTR(name, 0444, atk_name_show, NULL);
 
-static void atk_init_attribute(struct device_attribute *attr, char *name,
+static void atk_init_attribute(device_attribute_no_const *attr, char *name,
 		sysfs_show_func show)
 {
 	sysfs_attr_init(&attr->attr);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hwmon/coretemp.c linux-3.2.71-pax/drivers/hwmon/coretemp.c
--- linux-3.2.71/drivers/hwmon/coretemp.c	2014-02-16 00:01:51.616847721 +0100
+++ linux-3.2.71-pax/drivers/hwmon/coretemp.c	2014-02-16 00:01:57.708847395 +0100
@@ -787,7 +787,7 @@ static int __cpuinit coretemp_cpu_callba
 	return NOTIFY_OK;
 }
 
-static struct notifier_block coretemp_cpu_notifier __refdata = {
+static struct notifier_block coretemp_cpu_notifier = {
 	.notifier_call = coretemp_cpu_callback,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hwmon/ibmaem.c linux-3.2.71-pax/drivers/hwmon/ibmaem.c
--- linux-3.2.71/drivers/hwmon/ibmaem.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/hwmon/ibmaem.c	2013-03-28 01:35:23.276427949 +0100
@@ -924,7 +924,7 @@ static int aem_register_sensors(struct a
 				struct aem_rw_sensor_template *rw)
 {
 	struct device *dev = &data->pdev->dev;
-	struct sensor_device_attribute *sensors = data->sensors;
+	sensor_device_attribute_no_const *sensors = data->sensors;
 	int err;
 
 	/* Set up read-only sensors */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hwmon/pmbus/pmbus_core.c linux-3.2.71-pax/drivers/hwmon/pmbus/pmbus_core.c
--- linux-3.2.71/drivers/hwmon/pmbus/pmbus_core.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/hwmon/pmbus/pmbus_core.c	2013-03-28 01:35:23.276427949 +0100
@@ -809,7 +809,7 @@ static ssize_t pmbus_show_label(struct d
 
 #define PMBUS_ADD_ATTR(data, _name, _idx, _mode, _type, _show, _set)	\
 do {									\
-	struct sensor_device_attribute *a				\
+	sensor_device_attribute_no_const *a				\
 	    = &data->_type##s[data->num_##_type##s].attribute;		\
 	BUG_ON(data->num_attributes >= data->max_attributes);		\
 	sysfs_attr_init(&a->dev_attr.attr);				\
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hwmon/sht15.c linux-3.2.71-pax/drivers/hwmon/sht15.c
--- linux-3.2.71/drivers/hwmon/sht15.c	2013-03-29 02:18:38.691676284 +0100
+++ linux-3.2.71-pax/drivers/hwmon/sht15.c	2013-03-29 02:20:31.331670270 +0100
@@ -166,7 +166,7 @@ struct sht15_data {
 	int				supply_uV;
 	bool				supply_uV_valid;
 	struct work_struct		update_supply_work;
-	atomic_t			interrupt_handled;
+	atomic_unchecked_t		interrupt_handled;
 };
 
 /**
@@ -509,13 +509,13 @@ static int sht15_measurement(struct sht1
 		return ret;
 
 	gpio_direction_input(data->pdata->gpio_data);
-	atomic_set(&data->interrupt_handled, 0);
+	atomic_set_unchecked(&data->interrupt_handled, 0);
 
 	enable_irq(gpio_to_irq(data->pdata->gpio_data));
 	if (gpio_get_value(data->pdata->gpio_data) == 0) {
 		disable_irq_nosync(gpio_to_irq(data->pdata->gpio_data));
 		/* Only relevant if the interrupt hasn't occurred. */
-		if (!atomic_read(&data->interrupt_handled))
+		if (!atomic_read_unchecked(&data->interrupt_handled))
 			schedule_work(&data->read_work);
 	}
 	ret = wait_event_timeout(data->wait_queue,
@@ -782,7 +782,7 @@ static irqreturn_t sht15_interrupt_fired
 
 	/* First disable the interrupt */
 	disable_irq_nosync(irq);
-	atomic_inc(&data->interrupt_handled);
+	atomic_inc_unchecked(&data->interrupt_handled);
 	/* Then schedule a reading work struct */
 	if (data->state != SHT15_READING_NOTHING)
 		schedule_work(&data->read_work);
@@ -804,11 +804,11 @@ static void sht15_bh_read_data(struct wo
 		 * If not, then start the interrupt again - care here as could
 		 * have gone low in meantime so verify it hasn't!
 		 */
-		atomic_set(&data->interrupt_handled, 0);
+		atomic_set_unchecked(&data->interrupt_handled, 0);
 		enable_irq(gpio_to_irq(data->pdata->gpio_data));
 		/* If still not occurred or another handler has been scheduled */
 		if (gpio_get_value(data->pdata->gpio_data)
-		    || atomic_read(&data->interrupt_handled))
+		    || atomic_read_unchecked(&data->interrupt_handled))
 			return;
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/hwmon/via-cputemp.c linux-3.2.71-pax/drivers/hwmon/via-cputemp.c
--- linux-3.2.71/drivers/hwmon/via-cputemp.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/hwmon/via-cputemp.c	2013-02-20 01:19:15.894027322 +0100
@@ -304,7 +304,7 @@ static int __cpuinit via_cputemp_cpu_cal
 	return NOTIFY_OK;
 }
 
-static struct notifier_block via_cputemp_cpu_notifier __refdata = {
+static struct notifier_block via_cputemp_cpu_notifier = {
 	.notifier_call = via_cputemp_cpu_callback,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/i2c/busses/i2c-amd756-s4882.c linux-3.2.71-pax/drivers/i2c/busses/i2c-amd756-s4882.c
--- linux-3.2.71/drivers/i2c/busses/i2c-amd756-s4882.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/i2c/busses/i2c-amd756-s4882.c	2012-07-04 19:24:48.416063007 +0200
@@ -43,7 +43,7 @@
 extern struct i2c_adapter amd756_smbus;
 
 static struct i2c_adapter *s4882_adapter;
-static struct i2c_algorithm *s4882_algo;
+static i2c_algorithm_no_const *s4882_algo;
 
 /* Wrapper access functions for multiplexed SMBus */
 static DEFINE_MUTEX(amd756_lock);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/i2c/busses/i2c-diolan-u2c.c linux-3.2.71-pax/drivers/i2c/busses/i2c-diolan-u2c.c
--- linux-3.2.71/drivers/i2c/busses/i2c-diolan-u2c.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/i2c/busses/i2c-diolan-u2c.c	2013-11-23 18:07:03.549937070 +0100
@@ -99,7 +99,7 @@ MODULE_PARM_DESC(frequency, "I2C clock f
 /* usb layer */
 
 /* Send command to device, and get response. */
-static int diolan_usb_transfer(struct i2c_diolan_u2c *dev)
+static int __intentional_overflow(-1) diolan_usb_transfer(struct i2c_diolan_u2c *dev)
 {
 	int ret = 0;
 	int actual;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/i2c/busses/i2c-nforce2-s4985.c linux-3.2.71-pax/drivers/i2c/busses/i2c-nforce2-s4985.c
--- linux-3.2.71/drivers/i2c/busses/i2c-nforce2-s4985.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/i2c/busses/i2c-nforce2-s4985.c	2012-07-04 19:24:48.416063007 +0200
@@ -41,7 +41,7 @@
 extern struct i2c_adapter *nforce2_smbus;
 
 static struct i2c_adapter *s4985_adapter;
-static struct i2c_algorithm *s4985_algo;
+static i2c_algorithm_no_const *s4985_algo;
 
 /* Wrapper access functions for multiplexed SMBus */
 static DEFINE_MUTEX(nforce2_lock);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/i2c/i2c-dev.c linux-3.2.71-pax/drivers/i2c/i2c-dev.c
--- linux-3.2.71/drivers/i2c/i2c-dev.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/i2c/i2c-dev.c	2013-06-21 19:11:21.694771193 +0200
@@ -276,7 +276,7 @@ static noinline int i2cdev_ioctl_rdrw(st
 			res = -EINVAL;
 			break;
 		}
-		data_ptrs[i] = (u8 __user *)rdwr_pa[i].buf;
+		data_ptrs[i] = (u8 __force_user *)rdwr_pa[i].buf;
 		rdwr_pa[i].buf = memdup_user(data_ptrs[i], rdwr_pa[i].len);
 		if (IS_ERR(rdwr_pa[i].buf)) {
 			res = PTR_ERR(rdwr_pa[i].buf);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/aec62xx.c linux-3.2.71-pax/drivers/ide/aec62xx.c
--- linux-3.2.71/drivers/ide/aec62xx.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/aec62xx.c	2012-07-04 19:24:48.420063007 +0200
@@ -181,7 +181,7 @@ static const struct ide_port_ops atp86x_
 	.cable_detect		= atp86x_cable_detect,
 };
 
-static const struct ide_port_info aec62xx_chipsets[] __devinitdata = {
+static const struct ide_port_info aec62xx_chipsets[] __devinitconst = {
 	{	/* 0: AEC6210 */
 		.name		= DRV_NAME,
 		.init_chipset	= init_chipset_aec62xx,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/alim15x3.c linux-3.2.71-pax/drivers/ide/alim15x3.c
--- linux-3.2.71/drivers/ide/alim15x3.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/alim15x3.c	2012-07-04 19:24:48.420063007 +0200
@@ -512,7 +512,7 @@ static const struct ide_dma_ops ali_dma_
 	.dma_sff_read_status	= ide_dma_sff_read_status,
 };
 
-static const struct ide_port_info ali15x3_chipset __devinitdata = {
+static const struct ide_port_info ali15x3_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.init_chipset	= init_chipset_ali15x3,
 	.init_hwif	= init_hwif_ali15x3,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/amd74xx.c linux-3.2.71-pax/drivers/ide/amd74xx.c
--- linux-3.2.71/drivers/ide/amd74xx.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/amd74xx.c	2012-07-04 19:24:48.420063007 +0200
@@ -223,7 +223,7 @@ static const struct ide_port_ops amd_por
 		.udma_mask	= udma,					\
 	}
 
-static const struct ide_port_info amd74xx_chipsets[] __devinitdata = {
+static const struct ide_port_info amd74xx_chipsets[] __devinitconst = {
 	/* 0: AMD7401 */	DECLARE_AMD_DEV(0x00, ATA_UDMA2),
 	/* 1: AMD7409 */	DECLARE_AMD_DEV(ATA_SWDMA2, ATA_UDMA4),
 	/* 2: AMD7411/7441 */	DECLARE_AMD_DEV(ATA_SWDMA2, ATA_UDMA5),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/atiixp.c linux-3.2.71-pax/drivers/ide/atiixp.c
--- linux-3.2.71/drivers/ide/atiixp.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/atiixp.c	2012-07-04 19:24:48.420063007 +0200
@@ -139,7 +139,7 @@ static const struct ide_port_ops atiixp_
 	.cable_detect		= atiixp_cable_detect,
 };
 
-static const struct ide_port_info atiixp_pci_info[] __devinitdata = {
+static const struct ide_port_info atiixp_pci_info[] __devinitconst = {
 	{	/* 0: IXP200/300/400/700 */
 		.name		= DRV_NAME,
 		.enablebits	= {{0x48,0x01,0x00}, {0x48,0x08,0x00}},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/cmd64x.c linux-3.2.71-pax/drivers/ide/cmd64x.c
--- linux-3.2.71/drivers/ide/cmd64x.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/cmd64x.c	2012-07-04 19:24:48.420063007 +0200
@@ -327,7 +327,7 @@ static const struct ide_dma_ops cmd646_r
 	.dma_sff_read_status	= ide_dma_sff_read_status,
 };
 
-static const struct ide_port_info cmd64x_chipsets[] __devinitdata = {
+static const struct ide_port_info cmd64x_chipsets[] __devinitconst = {
 	{	/* 0: CMD643 */
 		.name		= DRV_NAME,
 		.init_chipset	= init_chipset_cmd64x,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/cs5520.c linux-3.2.71-pax/drivers/ide/cs5520.c
--- linux-3.2.71/drivers/ide/cs5520.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/cs5520.c	2012-07-04 19:24:48.420063007 +0200
@@ -94,7 +94,7 @@ static const struct ide_port_ops cs5520_
 	.set_dma_mode		= cs5520_set_dma_mode,
 };
 
-static const struct ide_port_info cyrix_chipset __devinitdata = {
+static const struct ide_port_info cyrix_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.enablebits	= { { 0x60, 0x01, 0x01 }, { 0x60, 0x02, 0x02 } },
 	.port_ops	= &cs5520_port_ops,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/cs5530.c linux-3.2.71-pax/drivers/ide/cs5530.c
--- linux-3.2.71/drivers/ide/cs5530.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/cs5530.c	2012-07-04 19:24:48.420063007 +0200
@@ -245,7 +245,7 @@ static const struct ide_port_ops cs5530_
 	.udma_filter		= cs5530_udma_filter,
 };
 
-static const struct ide_port_info cs5530_chipset __devinitdata = {
+static const struct ide_port_info cs5530_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.init_chipset	= init_chipset_cs5530,
 	.init_hwif	= init_hwif_cs5530,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/cs5535.c linux-3.2.71-pax/drivers/ide/cs5535.c
--- linux-3.2.71/drivers/ide/cs5535.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/cs5535.c	2012-07-04 19:24:48.424063007 +0200
@@ -170,7 +170,7 @@ static const struct ide_port_ops cs5535_
 	.cable_detect		= cs5535_cable_detect,
 };
 
-static const struct ide_port_info cs5535_chipset __devinitdata = {
+static const struct ide_port_info cs5535_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.port_ops	= &cs5535_port_ops,
 	.host_flags	= IDE_HFLAG_SINGLE | IDE_HFLAG_POST_SET_MODE,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/cy82c693.c linux-3.2.71-pax/drivers/ide/cy82c693.c
--- linux-3.2.71/drivers/ide/cy82c693.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/cy82c693.c	2012-07-04 19:24:48.424063007 +0200
@@ -163,7 +163,7 @@ static const struct ide_port_ops cy82c69
 	.set_dma_mode		= cy82c693_set_dma_mode,
 };
 
-static const struct ide_port_info cy82c693_chipset __devinitdata = {
+static const struct ide_port_info cy82c693_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.init_iops	= init_iops_cy82c693,
 	.port_ops	= &cy82c693_port_ops,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/hpt366.c linux-3.2.71-pax/drivers/ide/hpt366.c
--- linux-3.2.71/drivers/ide/hpt366.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/hpt366.c	2012-07-04 19:24:48.424063007 +0200
@@ -443,7 +443,7 @@ static struct hpt_timings hpt37x_timings
 	}
 };
 
-static const struct hpt_info hpt36x __devinitdata = {
+static const struct hpt_info hpt36x __devinitconst = {
 	.chip_name	= "HPT36x",
 	.chip_type	= HPT36x,
 	.udma_mask	= HPT366_ALLOW_ATA66_3 ? (HPT366_ALLOW_ATA66_4 ? ATA_UDMA4 : ATA_UDMA3) : ATA_UDMA2,
@@ -451,7 +451,7 @@ static const struct hpt_info hpt36x __de
 	.timings	= &hpt36x_timings
 };
 
-static const struct hpt_info hpt370 __devinitdata = {
+static const struct hpt_info hpt370 __devinitconst = {
 	.chip_name	= "HPT370",
 	.chip_type	= HPT370,
 	.udma_mask	= HPT370_ALLOW_ATA100_5 ? ATA_UDMA5 : ATA_UDMA4,
@@ -459,7 +459,7 @@ static const struct hpt_info hpt370 __de
 	.timings	= &hpt37x_timings
 };
 
-static const struct hpt_info hpt370a __devinitdata = {
+static const struct hpt_info hpt370a __devinitconst = {
 	.chip_name	= "HPT370A",
 	.chip_type	= HPT370A,
 	.udma_mask	= HPT370_ALLOW_ATA100_5 ? ATA_UDMA5 : ATA_UDMA4,
@@ -467,7 +467,7 @@ static const struct hpt_info hpt370a __d
 	.timings	= &hpt37x_timings
 };
 
-static const struct hpt_info hpt374 __devinitdata = {
+static const struct hpt_info hpt374 __devinitconst = {
 	.chip_name	= "HPT374",
 	.chip_type	= HPT374,
 	.udma_mask	= ATA_UDMA5,
@@ -475,7 +475,7 @@ static const struct hpt_info hpt374 __de
 	.timings	= &hpt37x_timings
 };
 
-static const struct hpt_info hpt372 __devinitdata = {
+static const struct hpt_info hpt372 __devinitconst = {
 	.chip_name	= "HPT372",
 	.chip_type	= HPT372,
 	.udma_mask	= HPT372_ALLOW_ATA133_6 ? ATA_UDMA6 : ATA_UDMA5,
@@ -483,7 +483,7 @@ static const struct hpt_info hpt372 __de
 	.timings	= &hpt37x_timings
 };
 
-static const struct hpt_info hpt372a __devinitdata = {
+static const struct hpt_info hpt372a __devinitconst = {
 	.chip_name	= "HPT372A",
 	.chip_type	= HPT372A,
 	.udma_mask	= HPT372_ALLOW_ATA133_6 ? ATA_UDMA6 : ATA_UDMA5,
@@ -491,7 +491,7 @@ static const struct hpt_info hpt372a __d
 	.timings	= &hpt37x_timings
 };
 
-static const struct hpt_info hpt302 __devinitdata = {
+static const struct hpt_info hpt302 __devinitconst = {
 	.chip_name	= "HPT302",
 	.chip_type	= HPT302,
 	.udma_mask	= HPT302_ALLOW_ATA133_6 ? ATA_UDMA6 : ATA_UDMA5,
@@ -499,7 +499,7 @@ static const struct hpt_info hpt302 __de
 	.timings	= &hpt37x_timings
 };
 
-static const struct hpt_info hpt371 __devinitdata = {
+static const struct hpt_info hpt371 __devinitconst = {
 	.chip_name	= "HPT371",
 	.chip_type	= HPT371,
 	.udma_mask	= HPT371_ALLOW_ATA133_6 ? ATA_UDMA6 : ATA_UDMA5,
@@ -507,7 +507,7 @@ static const struct hpt_info hpt371 __de
 	.timings	= &hpt37x_timings
 };
 
-static const struct hpt_info hpt372n __devinitdata = {
+static const struct hpt_info hpt372n __devinitconst = {
 	.chip_name	= "HPT372N",
 	.chip_type	= HPT372N,
 	.udma_mask	= HPT372_ALLOW_ATA133_6 ? ATA_UDMA6 : ATA_UDMA5,
@@ -515,7 +515,7 @@ static const struct hpt_info hpt372n __d
 	.timings	= &hpt37x_timings
 };
 
-static const struct hpt_info hpt302n __devinitdata = {
+static const struct hpt_info hpt302n __devinitconst = {
 	.chip_name	= "HPT302N",
 	.chip_type	= HPT302N,
 	.udma_mask	= HPT302_ALLOW_ATA133_6 ? ATA_UDMA6 : ATA_UDMA5,
@@ -523,7 +523,7 @@ static const struct hpt_info hpt302n __d
 	.timings	= &hpt37x_timings
 };
 
-static const struct hpt_info hpt371n __devinitdata = {
+static const struct hpt_info hpt371n __devinitconst = {
 	.chip_name	= "HPT371N",
 	.chip_type	= HPT371N,
 	.udma_mask	= HPT371_ALLOW_ATA133_6 ? ATA_UDMA6 : ATA_UDMA5,
@@ -1361,7 +1361,7 @@ static const struct ide_dma_ops hpt36x_d
 	.dma_sff_read_status	= ide_dma_sff_read_status,
 };
 
-static const struct ide_port_info hpt366_chipsets[] __devinitdata = {
+static const struct ide_port_info hpt366_chipsets[] __devinitconst = {
 	{	/* 0: HPT36x */
 		.name		= DRV_NAME,
 		.init_chipset	= init_chipset_hpt366,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/ide-cd.c linux-3.2.71-pax/drivers/ide/ide-cd.c
--- linux-3.2.71/drivers/ide/ide-cd.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/ide-cd.c	2012-07-04 19:24:48.424063007 +0200
@@ -768,7 +768,7 @@ static void cdrom_do_block_pc(ide_drive_
 		alignment = queue_dma_alignment(q) | q->dma_pad_mask;
 		if ((unsigned long)buf & alignment
 		    || blk_rq_bytes(rq) & q->dma_pad_mask
-		    || object_is_on_stack(buf))
+		    || object_starts_on_stack(buf))
 			drive->dma = 0;
 	}
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/ide-pci-generic.c linux-3.2.71-pax/drivers/ide/ide-pci-generic.c
--- linux-3.2.71/drivers/ide/ide-pci-generic.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/ide-pci-generic.c	2012-07-04 19:24:48.424063007 +0200
@@ -53,7 +53,7 @@ static const struct ide_port_ops netcell
 		.udma_mask	= ATA_UDMA6, \
 	}
 
-static const struct ide_port_info generic_chipsets[] __devinitdata = {
+static const struct ide_port_info generic_chipsets[] __devinitconst = {
 	/*  0: Unknown */
 	DECLARE_GENERIC_PCI_DEV(0),
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/it8172.c linux-3.2.71-pax/drivers/ide/it8172.c
--- linux-3.2.71/drivers/ide/it8172.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/it8172.c	2012-07-04 19:24:48.428063007 +0200
@@ -115,7 +115,7 @@ static const struct ide_port_ops it8172_
 	.set_dma_mode	= it8172_set_dma_mode,
 };
 
-static const struct ide_port_info it8172_port_info __devinitdata = {
+static const struct ide_port_info it8172_port_info __devinitconst = {
 	.name		= DRV_NAME,
 	.port_ops	= &it8172_port_ops,
 	.enablebits	= { {0x41, 0x80, 0x80}, {0x00, 0x00, 0x00} },
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/it8213.c linux-3.2.71-pax/drivers/ide/it8213.c
--- linux-3.2.71/drivers/ide/it8213.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/it8213.c	2012-07-04 19:24:48.428063007 +0200
@@ -156,7 +156,7 @@ static const struct ide_port_ops it8213_
 	.cable_detect		= it8213_cable_detect,
 };
 
-static const struct ide_port_info it8213_chipset __devinitdata = {
+static const struct ide_port_info it8213_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.enablebits	= { {0x41, 0x80, 0x80} },
 	.port_ops	= &it8213_port_ops,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/it821x.c linux-3.2.71-pax/drivers/ide/it821x.c
--- linux-3.2.71/drivers/ide/it821x.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/it821x.c	2012-07-04 19:24:48.428063007 +0200
@@ -630,7 +630,7 @@ static const struct ide_port_ops it821x_
 	.cable_detect		= it821x_cable_detect,
 };
 
-static const struct ide_port_info it821x_chipset __devinitdata = {
+static const struct ide_port_info it821x_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.init_chipset	= init_chipset_it821x,
 	.init_hwif	= init_hwif_it821x,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/jmicron.c linux-3.2.71-pax/drivers/ide/jmicron.c
--- linux-3.2.71/drivers/ide/jmicron.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/jmicron.c	2012-07-04 19:24:48.428063007 +0200
@@ -102,7 +102,7 @@ static const struct ide_port_ops jmicron
 	.cable_detect		= jmicron_cable_detect,
 };
 
-static const struct ide_port_info jmicron_chipset __devinitdata = {
+static const struct ide_port_info jmicron_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.enablebits	= { { 0x40, 0x01, 0x01 }, { 0x40, 0x10, 0x10 } },
 	.port_ops	= &jmicron_port_ops,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/ns87415.c linux-3.2.71-pax/drivers/ide/ns87415.c
--- linux-3.2.71/drivers/ide/ns87415.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/ns87415.c	2012-07-04 19:24:48.428063007 +0200
@@ -293,7 +293,7 @@ static const struct ide_dma_ops ns87415_
 	.dma_sff_read_status	= superio_dma_sff_read_status,
 };
 
-static const struct ide_port_info ns87415_chipset __devinitdata = {
+static const struct ide_port_info ns87415_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.init_hwif	= init_hwif_ns87415,
 	.tp_ops 	= &ns87415_tp_ops,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/opti621.c linux-3.2.71-pax/drivers/ide/opti621.c
--- linux-3.2.71/drivers/ide/opti621.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/opti621.c	2012-07-04 19:24:48.428063007 +0200
@@ -131,7 +131,7 @@ static const struct ide_port_ops opti621
 	.set_pio_mode		= opti621_set_pio_mode,
 };
 
-static const struct ide_port_info opti621_chipset __devinitdata = {
+static const struct ide_port_info opti621_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.enablebits	= { {0x45, 0x80, 0x00}, {0x40, 0x08, 0x00} },
 	.port_ops	= &opti621_port_ops,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/pdc202xx_new.c linux-3.2.71-pax/drivers/ide/pdc202xx_new.c
--- linux-3.2.71/drivers/ide/pdc202xx_new.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/pdc202xx_new.c	2012-07-04 19:24:48.432063007 +0200
@@ -465,7 +465,7 @@ static const struct ide_port_ops pdcnew_
 		.udma_mask	= udma, \
 	}
 
-static const struct ide_port_info pdcnew_chipsets[] __devinitdata = {
+static const struct ide_port_info pdcnew_chipsets[] __devinitconst = {
 	/* 0: PDC202{68,70} */		DECLARE_PDCNEW_DEV(ATA_UDMA5),
 	/* 1: PDC202{69,71,75,76,77} */	DECLARE_PDCNEW_DEV(ATA_UDMA6),
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/pdc202xx_old.c linux-3.2.71-pax/drivers/ide/pdc202xx_old.c
--- linux-3.2.71/drivers/ide/pdc202xx_old.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/pdc202xx_old.c	2012-07-04 19:24:48.432063007 +0200
@@ -270,7 +270,7 @@ static const struct ide_dma_ops pdc2026x
 		.max_sectors	= sectors, \
 	}
 
-static const struct ide_port_info pdc202xx_chipsets[] __devinitdata = {
+static const struct ide_port_info pdc202xx_chipsets[] __devinitconst = {
 	{	/* 0: PDC20246 */
 		.name		= DRV_NAME,
 		.init_chipset	= init_chipset_pdc202xx,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/piix.c linux-3.2.71-pax/drivers/ide/piix.c
--- linux-3.2.71/drivers/ide/piix.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/piix.c	2012-07-04 19:24:48.432063007 +0200
@@ -344,7 +344,7 @@ static const struct ide_port_ops ich_por
 		.udma_mask	= udma, \
 	}
 
-static const struct ide_port_info piix_pci_info[] __devinitdata = {
+static const struct ide_port_info piix_pci_info[] __devinitconst = {
 	/* 0: MPIIX */
 	{	/*
 		 * MPIIX actually has only a single IDE channel mapped to
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/rz1000.c linux-3.2.71-pax/drivers/ide/rz1000.c
--- linux-3.2.71/drivers/ide/rz1000.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/rz1000.c	2012-07-04 19:24:48.432063007 +0200
@@ -38,7 +38,7 @@ static int __devinit rz1000_disable_read
 	}
 }
 
-static const struct ide_port_info rz1000_chipset __devinitdata = {
+static const struct ide_port_info rz1000_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.host_flags	= IDE_HFLAG_NO_DMA,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/sc1200.c linux-3.2.71-pax/drivers/ide/sc1200.c
--- linux-3.2.71/drivers/ide/sc1200.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/sc1200.c	2012-07-04 19:24:48.432063007 +0200
@@ -291,7 +291,7 @@ static const struct ide_dma_ops sc1200_d
 	.dma_sff_read_status	= ide_dma_sff_read_status,
 };
 
-static const struct ide_port_info sc1200_chipset __devinitdata = {
+static const struct ide_port_info sc1200_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.port_ops	= &sc1200_port_ops,
 	.dma_ops	= &sc1200_dma_ops,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/scc_pata.c linux-3.2.71-pax/drivers/ide/scc_pata.c
--- linux-3.2.71/drivers/ide/scc_pata.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/scc_pata.c	2012-07-04 19:24:48.432063007 +0200
@@ -811,7 +811,7 @@ static const struct ide_dma_ops scc_dma_
 	.dma_sff_read_status	= scc_dma_sff_read_status,
 };
 
-static const struct ide_port_info scc_chipset __devinitdata = {
+static const struct ide_port_info scc_chipset __devinitconst = {
 	.name		= "sccIDE",
 	.init_iops	= init_iops_scc,
 	.init_dma	= scc_init_dma,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/serverworks.c linux-3.2.71-pax/drivers/ide/serverworks.c
--- linux-3.2.71/drivers/ide/serverworks.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/serverworks.c	2012-07-04 19:24:48.436063007 +0200
@@ -337,7 +337,7 @@ static const struct ide_port_ops svwks_p
 	.cable_detect		= svwks_cable_detect,
 };
 
-static const struct ide_port_info serverworks_chipsets[] __devinitdata = {
+static const struct ide_port_info serverworks_chipsets[] __devinitconst = {
 	{	/* 0: OSB4 */
 		.name		= DRV_NAME,
 		.init_chipset	= init_chipset_svwks,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/siimage.c linux-3.2.71-pax/drivers/ide/siimage.c
--- linux-3.2.71/drivers/ide/siimage.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/siimage.c	2012-07-04 19:24:48.436063007 +0200
@@ -719,7 +719,7 @@ static const struct ide_dma_ops sil_dma_
 		.udma_mask	= ATA_UDMA6,		\
 	}
 
-static const struct ide_port_info siimage_chipsets[] __devinitdata = {
+static const struct ide_port_info siimage_chipsets[] __devinitconst = {
 	/* 0: SiI680 */  DECLARE_SII_DEV(&sil_pata_port_ops),
 	/* 1: SiI3112 */ DECLARE_SII_DEV(&sil_sata_port_ops)
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/sis5513.c linux-3.2.71-pax/drivers/ide/sis5513.c
--- linux-3.2.71/drivers/ide/sis5513.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/sis5513.c	2012-07-04 19:24:48.436063007 +0200
@@ -563,7 +563,7 @@ static const struct ide_port_ops sis_ata
 	.cable_detect		= sis_cable_detect,
 };
 
-static const struct ide_port_info sis5513_chipset __devinitdata = {
+static const struct ide_port_info sis5513_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.init_chipset	= init_chipset_sis5513,
 	.enablebits	= { {0x4a, 0x02, 0x02}, {0x4a, 0x04, 0x04} },
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/sl82c105.c linux-3.2.71-pax/drivers/ide/sl82c105.c
--- linux-3.2.71/drivers/ide/sl82c105.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/sl82c105.c	2012-07-04 19:24:48.436063007 +0200
@@ -299,7 +299,7 @@ static const struct ide_dma_ops sl82c105
 	.dma_sff_read_status	= ide_dma_sff_read_status,
 };
 
-static const struct ide_port_info sl82c105_chipset __devinitdata = {
+static const struct ide_port_info sl82c105_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.init_chipset	= init_chipset_sl82c105,
 	.enablebits	= {{0x40,0x01,0x01}, {0x40,0x10,0x10}},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/slc90e66.c linux-3.2.71-pax/drivers/ide/slc90e66.c
--- linux-3.2.71/drivers/ide/slc90e66.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/slc90e66.c	2012-07-04 19:24:48.436063007 +0200
@@ -132,7 +132,7 @@ static const struct ide_port_ops slc90e6
 	.cable_detect		= slc90e66_cable_detect,
 };
 
-static const struct ide_port_info slc90e66_chipset __devinitdata = {
+static const struct ide_port_info slc90e66_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.enablebits	= { {0x41, 0x80, 0x80}, {0x43, 0x80, 0x80} },
 	.port_ops	= &slc90e66_port_ops,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/tc86c001.c linux-3.2.71-pax/drivers/ide/tc86c001.c
--- linux-3.2.71/drivers/ide/tc86c001.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/tc86c001.c	2012-07-04 19:24:48.436063007 +0200
@@ -192,7 +192,7 @@ static const struct ide_dma_ops tc86c001
 	.dma_sff_read_status	= ide_dma_sff_read_status,
 };
 
-static const struct ide_port_info tc86c001_chipset __devinitdata = {
+static const struct ide_port_info tc86c001_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.init_hwif	= init_hwif_tc86c001,
 	.port_ops	= &tc86c001_port_ops,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/triflex.c linux-3.2.71-pax/drivers/ide/triflex.c
--- linux-3.2.71/drivers/ide/triflex.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/triflex.c	2012-07-04 19:24:48.436063007 +0200
@@ -92,7 +92,7 @@ static const struct ide_port_ops triflex
 	.set_dma_mode		= triflex_set_mode,
 };
 
-static const struct ide_port_info triflex_device __devinitdata = {
+static const struct ide_port_info triflex_device __devinitconst = {
 	.name		= DRV_NAME,
 	.enablebits	= {{0x80, 0x01, 0x01}, {0x80, 0x02, 0x02}},
 	.port_ops	= &triflex_port_ops,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/trm290.c linux-3.2.71-pax/drivers/ide/trm290.c
--- linux-3.2.71/drivers/ide/trm290.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/trm290.c	2012-07-04 19:24:48.440063007 +0200
@@ -324,7 +324,7 @@ static struct ide_dma_ops trm290_dma_ops
 	.dma_check		= trm290_dma_check,
 };
 
-static const struct ide_port_info trm290_chipset __devinitdata = {
+static const struct ide_port_info trm290_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.init_hwif	= init_hwif_trm290,
 	.tp_ops 	= &trm290_tp_ops,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ide/via82cxxx.c linux-3.2.71-pax/drivers/ide/via82cxxx.c
--- linux-3.2.71/drivers/ide/via82cxxx.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ide/via82cxxx.c	2012-07-04 19:24:48.440063007 +0200
@@ -403,7 +403,7 @@ static const struct ide_port_ops via_por
 	.cable_detect		= via82cxxx_cable_detect,
 };
 
-static const struct ide_port_info via82cxxx_chipset __devinitdata = {
+static const struct ide_port_info via82cxxx_chipset __devinitconst = {
 	.name		= DRV_NAME,
 	.init_chipset	= init_chipset_via82cxxx,
 	.enablebits	= { { 0x40, 0x02, 0x02 }, { 0x40, 0x01, 0x01 } },
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/ieee802154/fakehard.c linux-3.2.71-pax/drivers/ieee802154/fakehard.c
--- linux-3.2.71/drivers/ieee802154/fakehard.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/ieee802154/fakehard.c	2012-07-04 19:24:48.440063007 +0200
@@ -386,7 +386,7 @@ static int __devinit ieee802154fake_prob
 	phy->transmit_power = 0xbf;
 
 	dev->netdev_ops = &fake_ops;
-	dev->ml_priv = &fake_mlme;
+	dev->ml_priv = (void *)&fake_mlme;
 
 	priv = netdev_priv(dev);
 	priv->phy = phy;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/core/cm.c linux-3.2.71-pax/drivers/infiniband/core/cm.c
--- linux-3.2.71/drivers/infiniband/core/cm.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/core/cm.c	2012-07-04 19:24:48.440063007 +0200
@@ -114,7 +114,7 @@ static char const counter_group_names[CM
 
 struct cm_counter_group {
 	struct kobject obj;
-	atomic_long_t counter[CM_ATTR_COUNT];
+	atomic_long_unchecked_t counter[CM_ATTR_COUNT];
 };
 
 struct cm_counter_attribute {
@@ -1394,7 +1394,7 @@ static void cm_dup_req_handler(struct cm
 	struct ib_mad_send_buf *msg = NULL;
 	int ret;
 
-	atomic_long_inc(&work->port->counter_group[CM_RECV_DUPLICATES].
+	atomic_long_inc_unchecked(&work->port->counter_group[CM_RECV_DUPLICATES].
 			counter[CM_REQ_COUNTER]);
 
 	/* Quick state check to discard duplicate REQs. */
@@ -1778,7 +1778,7 @@ static void cm_dup_rep_handler(struct cm
 	if (!cm_id_priv)
 		return;
 
-	atomic_long_inc(&work->port->counter_group[CM_RECV_DUPLICATES].
+	atomic_long_inc_unchecked(&work->port->counter_group[CM_RECV_DUPLICATES].
 			counter[CM_REP_COUNTER]);
 	ret = cm_alloc_response_msg(work->port, work->mad_recv_wc, &msg);
 	if (ret)
@@ -1945,7 +1945,7 @@ static int cm_rtu_handler(struct cm_work
 	if (cm_id_priv->id.state != IB_CM_REP_SENT &&
 	    cm_id_priv->id.state != IB_CM_MRA_REP_RCVD) {
 		spin_unlock_irq(&cm_id_priv->lock);
-		atomic_long_inc(&work->port->counter_group[CM_RECV_DUPLICATES].
+		atomic_long_inc_unchecked(&work->port->counter_group[CM_RECV_DUPLICATES].
 				counter[CM_RTU_COUNTER]);
 		goto out;
 	}
@@ -2128,7 +2128,7 @@ static int cm_dreq_handler(struct cm_wor
 	cm_id_priv = cm_acquire_id(dreq_msg->remote_comm_id,
 				   dreq_msg->local_comm_id);
 	if (!cm_id_priv) {
-		atomic_long_inc(&work->port->counter_group[CM_RECV_DUPLICATES].
+		atomic_long_inc_unchecked(&work->port->counter_group[CM_RECV_DUPLICATES].
 				counter[CM_DREQ_COUNTER]);
 		cm_issue_drep(work->port, work->mad_recv_wc);
 		return -EINVAL;
@@ -2153,7 +2153,7 @@ static int cm_dreq_handler(struct cm_wor
 	case IB_CM_MRA_REP_RCVD:
 		break;
 	case IB_CM_TIMEWAIT:
-		atomic_long_inc(&work->port->counter_group[CM_RECV_DUPLICATES].
+		atomic_long_inc_unchecked(&work->port->counter_group[CM_RECV_DUPLICATES].
 				counter[CM_DREQ_COUNTER]);
 		if (cm_alloc_response_msg(work->port, work->mad_recv_wc, &msg))
 			goto unlock;
@@ -2167,7 +2167,7 @@ static int cm_dreq_handler(struct cm_wor
 			cm_free_msg(msg);
 		goto deref;
 	case IB_CM_DREQ_RCVD:
-		atomic_long_inc(&work->port->counter_group[CM_RECV_DUPLICATES].
+		atomic_long_inc_unchecked(&work->port->counter_group[CM_RECV_DUPLICATES].
 				counter[CM_DREQ_COUNTER]);
 		goto unlock;
 	default:
@@ -2534,7 +2534,7 @@ static int cm_mra_handler(struct cm_work
 		    ib_modify_mad(cm_id_priv->av.port->mad_agent,
 				  cm_id_priv->msg, timeout)) {
 			if (cm_id_priv->id.lap_state == IB_CM_MRA_LAP_RCVD)
-				atomic_long_inc(&work->port->
+				atomic_long_inc_unchecked(&work->port->
 						counter_group[CM_RECV_DUPLICATES].
 						counter[CM_MRA_COUNTER]);
 			goto out;
@@ -2543,7 +2543,7 @@ static int cm_mra_handler(struct cm_work
 		break;
 	case IB_CM_MRA_REQ_RCVD:
 	case IB_CM_MRA_REP_RCVD:
-		atomic_long_inc(&work->port->counter_group[CM_RECV_DUPLICATES].
+		atomic_long_inc_unchecked(&work->port->counter_group[CM_RECV_DUPLICATES].
 				counter[CM_MRA_COUNTER]);
 		/* fall through */
 	default:
@@ -2705,7 +2705,7 @@ static int cm_lap_handler(struct cm_work
 	case IB_CM_LAP_IDLE:
 		break;
 	case IB_CM_MRA_LAP_SENT:
-		atomic_long_inc(&work->port->counter_group[CM_RECV_DUPLICATES].
+		atomic_long_inc_unchecked(&work->port->counter_group[CM_RECV_DUPLICATES].
 				counter[CM_LAP_COUNTER]);
 		if (cm_alloc_response_msg(work->port, work->mad_recv_wc, &msg))
 			goto unlock;
@@ -2721,7 +2721,7 @@ static int cm_lap_handler(struct cm_work
 			cm_free_msg(msg);
 		goto deref;
 	case IB_CM_LAP_RCVD:
-		atomic_long_inc(&work->port->counter_group[CM_RECV_DUPLICATES].
+		atomic_long_inc_unchecked(&work->port->counter_group[CM_RECV_DUPLICATES].
 				counter[CM_LAP_COUNTER]);
 		goto unlock;
 	default:
@@ -3005,7 +3005,7 @@ static int cm_sidr_req_handler(struct cm
 	cur_cm_id_priv = cm_insert_remote_sidr(cm_id_priv);
 	if (cur_cm_id_priv) {
 		spin_unlock_irq(&cm.lock);
-		atomic_long_inc(&work->port->counter_group[CM_RECV_DUPLICATES].
+		atomic_long_inc_unchecked(&work->port->counter_group[CM_RECV_DUPLICATES].
 				counter[CM_SIDR_REQ_COUNTER]);
 		goto out; /* Duplicate message. */
 	}
@@ -3217,10 +3217,10 @@ static void cm_send_handler(struct ib_ma
 	if (!msg->context[0] && (attr_index != CM_REJ_COUNTER))
 		msg->retries = 1;
 
-	atomic_long_add(1 + msg->retries,
+	atomic_long_add_unchecked(1 + msg->retries,
 			&port->counter_group[CM_XMIT].counter[attr_index]);
 	if (msg->retries)
-		atomic_long_add(msg->retries,
+		atomic_long_add_unchecked(msg->retries,
 				&port->counter_group[CM_XMIT_RETRIES].
 				counter[attr_index]);
 
@@ -3430,7 +3430,7 @@ static void cm_recv_handler(struct ib_ma
 	}
 
 	attr_id = be16_to_cpu(mad_recv_wc->recv_buf.mad->mad_hdr.attr_id);
-	atomic_long_inc(&port->counter_group[CM_RECV].
+	atomic_long_inc_unchecked(&port->counter_group[CM_RECV].
 			counter[attr_id - CM_ATTR_ID_OFFSET]);
 
 	work = kmalloc(sizeof *work + sizeof(struct ib_sa_path_rec) * paths,
@@ -3635,7 +3635,7 @@ static ssize_t cm_show_counter(struct ko
 	cm_attr = container_of(attr, struct cm_counter_attribute, attr);
 
 	return sprintf(buf, "%ld\n",
-		       atomic_long_read(&group->counter[cm_attr->index]));
+		       atomic_long_read_unchecked(&group->counter[cm_attr->index]));
 }
 
 static const struct sysfs_ops cm_counter_ops = {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/core/fmr_pool.c linux-3.2.71-pax/drivers/infiniband/core/fmr_pool.c
--- linux-3.2.71/drivers/infiniband/core/fmr_pool.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/core/fmr_pool.c	2012-07-04 19:24:48.444063007 +0200
@@ -98,8 +98,8 @@ struct ib_fmr_pool {
 
 	struct task_struct       *thread;
 
-	atomic_t                  req_ser;
-	atomic_t                  flush_ser;
+	atomic_unchecked_t        req_ser;
+	atomic_unchecked_t        flush_ser;
 
 	wait_queue_head_t         force_wait;
 };
@@ -180,10 +180,10 @@ static int ib_fmr_cleanup_thread(void *p
 	struct ib_fmr_pool *pool = pool_ptr;
 
 	do {
-		if (atomic_read(&pool->flush_ser) - atomic_read(&pool->req_ser) < 0) {
+		if (atomic_read_unchecked(&pool->flush_ser) - atomic_read_unchecked(&pool->req_ser) < 0) {
 			ib_fmr_batch_release(pool);
 
-			atomic_inc(&pool->flush_ser);
+			atomic_inc_unchecked(&pool->flush_ser);
 			wake_up_interruptible(&pool->force_wait);
 
 			if (pool->flush_function)
@@ -191,7 +191,7 @@ static int ib_fmr_cleanup_thread(void *p
 		}
 
 		set_current_state(TASK_INTERRUPTIBLE);
-		if (atomic_read(&pool->flush_ser) - atomic_read(&pool->req_ser) >= 0 &&
+		if (atomic_read_unchecked(&pool->flush_ser) - atomic_read_unchecked(&pool->req_ser) >= 0 &&
 		    !kthread_should_stop())
 			schedule();
 		__set_current_state(TASK_RUNNING);
@@ -283,8 +283,8 @@ struct ib_fmr_pool *ib_create_fmr_pool(s
 	pool->dirty_watermark = params->dirty_watermark;
 	pool->dirty_len       = 0;
 	spin_lock_init(&pool->pool_lock);
-	atomic_set(&pool->req_ser,   0);
-	atomic_set(&pool->flush_ser, 0);
+	atomic_set_unchecked(&pool->req_ser,   0);
+	atomic_set_unchecked(&pool->flush_ser, 0);
 	init_waitqueue_head(&pool->force_wait);
 
 	pool->thread = kthread_run(ib_fmr_cleanup_thread,
@@ -412,11 +412,11 @@ int ib_flush_fmr_pool(struct ib_fmr_pool
 	}
 	spin_unlock_irq(&pool->pool_lock);
 
-	serial = atomic_inc_return(&pool->req_ser);
+	serial = atomic_inc_return_unchecked(&pool->req_ser);
 	wake_up_process(pool->thread);
 
 	if (wait_event_interruptible(pool->force_wait,
-				     atomic_read(&pool->flush_ser) - serial >= 0))
+				     atomic_read_unchecked(&pool->flush_ser) - serial >= 0))
 		return -EINTR;
 
 	return 0;
@@ -526,7 +526,7 @@ int ib_fmr_pool_unmap(struct ib_pool_fmr
 		} else {
 			list_add_tail(&fmr->list, &pool->dirty_list);
 			if (++pool->dirty_len >= pool->dirty_watermark) {
-				atomic_inc(&pool->req_ser);
+				atomic_inc_unchecked(&pool->req_ser);
 				wake_up_process(pool->thread);
 			}
 		}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/core/uverbs_cmd.c linux-3.2.71-pax/drivers/infiniband/core/uverbs_cmd.c
--- linux-3.2.71/drivers/infiniband/core/uverbs_cmd.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/core/uverbs_cmd.c	2015-04-03 01:52:50.296419397 +0200
@@ -928,6 +928,9 @@ ssize_t ib_uverbs_reg_mr(struct ib_uverb
 	if (copy_from_user(&cmd, buf, sizeof cmd))
 		return -EFAULT;
 
+	if (!access_ok_noprefault(VERIFY_READ, cmd.start, cmd.length))
+		return -EFAULT;
+
 	INIT_UDATA(&udata, buf + sizeof cmd,
 		   (unsigned long) cmd.response + sizeof resp,
 		   in_len - sizeof cmd, out_len - sizeof resp);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/cxgb4/mem.c linux-3.2.71-pax/drivers/infiniband/hw/cxgb4/mem.c
--- linux-3.2.71/drivers/infiniband/hw/cxgb4/mem.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/cxgb4/mem.c	2012-07-04 19:24:48.444063007 +0200
@@ -122,7 +122,7 @@ static int write_tpt_entry(struct c4iw_r
 	int err;
 	struct fw_ri_tpte tpt;
 	u32 stag_idx;
-	static atomic_t key;
+	static atomic_unchecked_t key;
 
 	if (c4iw_fatal_error(rdev))
 		return -EIO;
@@ -135,7 +135,7 @@ static int write_tpt_entry(struct c4iw_r
 					     &rdev->resource.tpt_fifo_lock);
 		if (!stag_idx)
 			return -ENOMEM;
-		*stag = (stag_idx << 8) | (atomic_inc_return(&key) & 0xff);
+		*stag = (stag_idx << 8) | (atomic_inc_return_unchecked(&key) & 0xff);
 	}
 	PDBG("%s stag_state 0x%0x type 0x%0x pdid 0x%0x, stag_idx 0x%x\n",
 	     __func__, stag_state, type, pdid, stag_idx);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/ehca/ehca_irq.c linux-3.2.71-pax/drivers/infiniband/hw/ehca/ehca_irq.c
--- linux-3.2.71/drivers/infiniband/hw/ehca/ehca_irq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/ehca/ehca_irq.c	2013-02-20 01:22:38.662016495 +0100
@@ -883,7 +883,7 @@ static int __cpuinit comp_pool_callback(
 	return NOTIFY_OK;
 }
 
-static struct notifier_block comp_pool_callback_nb __cpuinitdata = {
+static struct notifier_block comp_pool_callback_nb = {
 	.notifier_call	= comp_pool_callback,
 	.priority	= 0,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/ipath/ipath_rc.c linux-3.2.71-pax/drivers/infiniband/hw/ipath/ipath_rc.c
--- linux-3.2.71/drivers/infiniband/hw/ipath/ipath_rc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/ipath/ipath_rc.c	2012-07-04 19:24:48.444063007 +0200
@@ -1868,7 +1868,7 @@ void ipath_rc_rcv(struct ipath_ibdev *de
 		struct ib_atomic_eth *ateth;
 		struct ipath_ack_entry *e;
 		u64 vaddr;
-		atomic64_t *maddr;
+		atomic64_unchecked_t *maddr;
 		u64 sdata;
 		u32 rkey;
 		u8 next;
@@ -1903,11 +1903,11 @@ void ipath_rc_rcv(struct ipath_ibdev *de
 					    IB_ACCESS_REMOTE_ATOMIC)))
 			goto nack_acc_unlck;
 		/* Perform atomic OP and save result. */
-		maddr = (atomic64_t *) qp->r_sge.sge.vaddr;
+		maddr = (atomic64_unchecked_t *) qp->r_sge.sge.vaddr;
 		sdata = be64_to_cpu(ateth->swap_data);
 		e = &qp->s_ack_queue[qp->r_head_ack_queue];
 		e->atomic_data = (opcode == OP(FETCH_ADD)) ?
-			(u64) atomic64_add_return(sdata, maddr) - sdata :
+			(u64) atomic64_add_return_unchecked(sdata, maddr) - sdata :
 			(u64) cmpxchg((u64 *) qp->r_sge.sge.vaddr,
 				      be64_to_cpu(ateth->compare_data),
 				      sdata);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/ipath/ipath_ruc.c linux-3.2.71-pax/drivers/infiniband/hw/ipath/ipath_ruc.c
--- linux-3.2.71/drivers/infiniband/hw/ipath/ipath_ruc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/ipath/ipath_ruc.c	2012-07-04 19:24:48.444063007 +0200
@@ -266,7 +266,7 @@ static void ipath_ruc_loopback(struct ip
 	unsigned long flags;
 	struct ib_wc wc;
 	u64 sdata;
-	atomic64_t *maddr;
+	atomic64_unchecked_t *maddr;
 	enum ib_wc_status send_status;
 
 	/*
@@ -382,11 +382,11 @@ again:
 					    IB_ACCESS_REMOTE_ATOMIC)))
 			goto acc_err;
 		/* Perform atomic OP and save result. */
-		maddr = (atomic64_t *) qp->r_sge.sge.vaddr;
+		maddr = (atomic64_unchecked_t *) qp->r_sge.sge.vaddr;
 		sdata = wqe->wr.wr.atomic.compare_add;
 		*(u64 *) sqp->s_sge.sge.vaddr =
 			(wqe->wr.opcode == IB_WR_ATOMIC_FETCH_AND_ADD) ?
-			(u64) atomic64_add_return(sdata, maddr) - sdata :
+			(u64) atomic64_add_return_unchecked(sdata, maddr) - sdata :
 			(u64) cmpxchg((u64 *) qp->r_sge.sge.vaddr,
 				      sdata, wqe->wr.wr.atomic.swap);
 		goto send_comp;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/mthca/mthca_cmd.c linux-3.2.71-pax/drivers/infiniband/hw/mthca/mthca_cmd.c
--- linux-3.2.71/drivers/infiniband/hw/mthca/mthca_cmd.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/mthca/mthca_cmd.c	2013-11-23 18:07:03.557937071 +0100
@@ -772,7 +772,7 @@ static void mthca_setup_cmd_doorbells(st
 	mthca_dbg(dev, "Mapped doorbell page for posting FW commands\n");
 }
 
-int mthca_QUERY_FW(struct mthca_dev *dev)
+int __intentional_overflow(-1) mthca_QUERY_FW(struct mthca_dev *dev)
 {
 	struct mthca_mailbox *mailbox;
 	u32 *outbox;
@@ -1612,7 +1612,7 @@ int mthca_HW2SW_MPT(struct mthca_dev *de
 			     CMD_TIME_CLASS_B);
 }
 
-int mthca_WRITE_MTT(struct mthca_dev *dev, struct mthca_mailbox *mailbox,
+int __intentional_overflow(-1) mthca_WRITE_MTT(struct mthca_dev *dev, struct mthca_mailbox *mailbox,
 		    int num_mtt)
 {
 	return mthca_cmd(dev, mailbox->dma, num_mtt, 0, CMD_WRITE_MTT,
@@ -1634,7 +1634,7 @@ int mthca_MAP_EQ(struct mthca_dev *dev,
 			 0, CMD_MAP_EQ, CMD_TIME_CLASS_B);
 }
 
-int mthca_SW2HW_EQ(struct mthca_dev *dev, struct mthca_mailbox *mailbox,
+int __intentional_overflow(-1) mthca_SW2HW_EQ(struct mthca_dev *dev, struct mthca_mailbox *mailbox,
 		   int eq_num)
 {
 	return mthca_cmd(dev, mailbox->dma, eq_num, 0, CMD_SW2HW_EQ,
@@ -1857,7 +1857,7 @@ int mthca_CONF_SPECIAL_QP(struct mthca_d
 			 CMD_TIME_CLASS_B);
 }
 
-int mthca_MAD_IFC(struct mthca_dev *dev, int ignore_mkey, int ignore_bkey,
+int __intentional_overflow(-1) mthca_MAD_IFC(struct mthca_dev *dev, int ignore_mkey, int ignore_bkey,
 		  int port, struct ib_wc *in_wc, struct ib_grh *in_grh,
 		  void *in_mad, void *response_mad)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/mthca/mthca_main.c linux-3.2.71-pax/drivers/infiniband/hw/mthca/mthca_main.c
--- linux-3.2.71/drivers/infiniband/hw/mthca/mthca_main.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/mthca/mthca_main.c	2013-11-23 18:07:03.565937071 +0100
@@ -692,7 +692,7 @@ err_close:
 	return err;
 }
 
-static int mthca_setup_hca(struct mthca_dev *dev)
+static int __intentional_overflow(-1) mthca_setup_hca(struct mthca_dev *dev)
 {
 	int err;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/mthca/mthca_mr.c linux-3.2.71-pax/drivers/infiniband/hw/mthca/mthca_mr.c
--- linux-3.2.71/drivers/infiniband/hw/mthca/mthca_mr.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/mthca/mthca_mr.c	2013-11-23 18:07:03.569937071 +0100
@@ -81,7 +81,7 @@ struct mthca_mpt_entry {
  * through the bitmaps)
  */
 
-static u32 mthca_buddy_alloc(struct mthca_buddy *buddy, int order)
+static u32 __intentional_overflow(-1) mthca_buddy_alloc(struct mthca_buddy *buddy, int order)
 {
 	int o;
 	int m;
@@ -426,7 +426,7 @@ static inline u32 adjust_key(struct mthc
 		return key;
 }
 
-int mthca_mr_alloc(struct mthca_dev *dev, u32 pd, int buffer_size_shift,
+int __intentional_overflow(-1) mthca_mr_alloc(struct mthca_dev *dev, u32 pd, int buffer_size_shift,
 		   u64 iova, u64 total_size, u32 access, struct mthca_mr *mr)
 {
 	struct mthca_mailbox *mailbox;
@@ -516,7 +516,7 @@ int mthca_mr_alloc_notrans(struct mthca_
 	return mthca_mr_alloc(dev, pd, 12, 0, ~0ULL, access, mr);
 }
 
-int mthca_mr_alloc_phys(struct mthca_dev *dev, u32 pd,
+int __intentional_overflow(-1) mthca_mr_alloc_phys(struct mthca_dev *dev, u32 pd,
 			u64 *buffer_list, int buffer_size_shift,
 			int list_len, u64 iova, u64 total_size,
 			u32 access, struct mthca_mr *mr)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/mthca/mthca_provider.c linux-3.2.71-pax/drivers/infiniband/hw/mthca/mthca_provider.c
--- linux-3.2.71/drivers/infiniband/hw/mthca/mthca_provider.c	2014-04-30 18:53:45.456223431 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/mthca/mthca_provider.c	2014-04-30 18:53:50.428223420 +0200
@@ -764,7 +764,7 @@ unlock:
 	return 0;
 }
 
-static int mthca_resize_cq(struct ib_cq *ibcq, int entries, struct ib_udata *udata)
+static int __intentional_overflow(-1) mthca_resize_cq(struct ib_cq *ibcq, int entries, struct ib_udata *udata)
 {
 	struct mthca_dev *dev = to_mdev(ibcq->device);
 	struct mthca_cq *cq = to_mcq(ibcq);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/nes/nes.c linux-3.2.71-pax/drivers/infiniband/hw/nes/nes.c
--- linux-3.2.71/drivers/infiniband/hw/nes/nes.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/nes/nes.c	2012-07-04 19:24:48.448063007 +0200
@@ -103,7 +103,7 @@ MODULE_PARM_DESC(limit_maxrdreqsz, "Limi
 LIST_HEAD(nes_adapter_list);
 static LIST_HEAD(nes_dev_list);
 
-atomic_t qps_destroyed;
+atomic_unchecked_t qps_destroyed;
 
 static unsigned int ee_flsh_adapter;
 static unsigned int sysfs_nonidx_addr;
@@ -272,7 +272,7 @@ static void nes_cqp_rem_ref_callback(str
 	struct nes_qp *nesqp = cqp_request->cqp_callback_pointer;
 	struct nes_adapter *nesadapter = nesdev->nesadapter;
 
-	atomic_inc(&qps_destroyed);
+	atomic_inc_unchecked(&qps_destroyed);
 
 	/* Free the control structures */
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/nes/nes_cm.c linux-3.2.71-pax/drivers/infiniband/hw/nes/nes_cm.c
--- linux-3.2.71/drivers/infiniband/hw/nes/nes_cm.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/nes/nes_cm.c	2012-07-04 19:24:48.448063007 +0200
@@ -68,14 +68,14 @@ u32 cm_packets_dropped;
 u32 cm_packets_retrans;
 u32 cm_packets_created;
 u32 cm_packets_received;
-atomic_t cm_listens_created;
-atomic_t cm_listens_destroyed;
+atomic_unchecked_t cm_listens_created;
+atomic_unchecked_t cm_listens_destroyed;
 u32 cm_backlog_drops;
-atomic_t cm_loopbacks;
-atomic_t cm_nodes_created;
-atomic_t cm_nodes_destroyed;
-atomic_t cm_accel_dropped_pkts;
-atomic_t cm_resets_recvd;
+atomic_unchecked_t cm_loopbacks;
+atomic_unchecked_t cm_nodes_created;
+atomic_unchecked_t cm_nodes_destroyed;
+atomic_unchecked_t cm_accel_dropped_pkts;
+atomic_unchecked_t cm_resets_recvd;
 
 static inline int mini_cm_accelerated(struct nes_cm_core *, struct nes_cm_node *);
 static struct nes_cm_listener *mini_cm_listen(struct nes_cm_core *, struct nes_vnic *, struct nes_cm_info *);
@@ -148,13 +148,13 @@ static struct nes_cm_ops nes_cm_api = {
 
 static struct nes_cm_core *g_cm_core;
 
-atomic_t cm_connects;
-atomic_t cm_accepts;
-atomic_t cm_disconnects;
-atomic_t cm_closes;
-atomic_t cm_connecteds;
-atomic_t cm_connect_reqs;
-atomic_t cm_rejects;
+atomic_unchecked_t cm_connects;
+atomic_unchecked_t cm_accepts;
+atomic_unchecked_t cm_disconnects;
+atomic_unchecked_t cm_closes;
+atomic_unchecked_t cm_connecteds;
+atomic_unchecked_t cm_connect_reqs;
+atomic_unchecked_t cm_rejects;
 
 int nes_add_ref_cm_node(struct nes_cm_node *cm_node)
 {
@@ -1271,7 +1271,7 @@ static int mini_cm_dec_refcnt_listen(str
 		kfree(listener);
 		listener = NULL;
 		ret = 0;
-		atomic_inc(&cm_listens_destroyed);
+		atomic_inc_unchecked(&cm_listens_destroyed);
 	} else {
 		spin_unlock_irqrestore(&cm_core->listen_list_lock, flags);
 	}
@@ -1473,7 +1473,7 @@ static struct nes_cm_node *make_cm_node(
 		  cm_node->rem_mac);
 
 	add_hte_node(cm_core, cm_node);
-	atomic_inc(&cm_nodes_created);
+	atomic_inc_unchecked(&cm_nodes_created);
 
 	return cm_node;
 }
@@ -1531,7 +1531,7 @@ static int rem_ref_cm_node(struct nes_cm
 	}
 
 	atomic_dec(&cm_core->node_cnt);
-	atomic_inc(&cm_nodes_destroyed);
+	atomic_inc_unchecked(&cm_nodes_destroyed);
 	nesqp = cm_node->nesqp;
 	if (nesqp) {
 		nesqp->cm_node = NULL;
@@ -1595,7 +1595,7 @@ static int process_options(struct nes_cm
 
 static void drop_packet(struct sk_buff *skb)
 {
-	atomic_inc(&cm_accel_dropped_pkts);
+	atomic_inc_unchecked(&cm_accel_dropped_pkts);
 	dev_kfree_skb_any(skb);
 }
 
@@ -1658,7 +1658,7 @@ static void handle_rst_pkt(struct nes_cm
 {
 
 	int	reset = 0;	/* whether to send reset in case of err.. */
-	atomic_inc(&cm_resets_recvd);
+	atomic_inc_unchecked(&cm_resets_recvd);
 	nes_debug(NES_DBG_CM, "Received Reset, cm_node = %p, state = %u."
 			" refcnt=%d\n", cm_node, cm_node->state,
 			atomic_read(&cm_node->ref_count));
@@ -2299,7 +2299,7 @@ static struct nes_cm_node *mini_cm_conne
 				rem_ref_cm_node(cm_node->cm_core, cm_node);
 				return NULL;
 			}
-			atomic_inc(&cm_loopbacks);
+			atomic_inc_unchecked(&cm_loopbacks);
 			loopbackremotenode->loopbackpartner = cm_node;
 			loopbackremotenode->tcp_cntxt.rcv_wscale =
 				NES_CM_DEFAULT_RCV_WND_SCALE;
@@ -2574,7 +2574,7 @@ static int mini_cm_recv_pkt(struct nes_c
 				nes_queue_mgt_skbs(skb, nesvnic, cm_node->nesqp);
 			else {
 				rem_ref_cm_node(cm_core, cm_node);
-				atomic_inc(&cm_accel_dropped_pkts);
+				atomic_inc_unchecked(&cm_accel_dropped_pkts);
 				dev_kfree_skb_any(skb);
 			}
 			break;
@@ -2880,7 +2880,7 @@ static int nes_cm_disconn_true(struct ne
 
 	if ((cm_id) && (cm_id->event_handler)) {
 		if (issue_disconn) {
-			atomic_inc(&cm_disconnects);
+			atomic_inc_unchecked(&cm_disconnects);
 			cm_event.event = IW_CM_EVENT_DISCONNECT;
 			cm_event.status = disconn_status;
 			cm_event.local_addr = cm_id->local_addr;
@@ -2902,7 +2902,7 @@ static int nes_cm_disconn_true(struct ne
 		}
 
 		if (issue_close) {
-			atomic_inc(&cm_closes);
+			atomic_inc_unchecked(&cm_closes);
 			nes_disconnect(nesqp, 1);
 
 			cm_id->provider_data = nesqp;
@@ -3038,7 +3038,7 @@ int nes_accept(struct iw_cm_id *cm_id, s
 
 	nes_debug(NES_DBG_CM, "QP%u, cm_node=%p, jiffies = %lu listener = %p\n",
 		nesqp->hwqp.qp_id, cm_node, jiffies, cm_node->listener);
-	atomic_inc(&cm_accepts);
+	atomic_inc_unchecked(&cm_accepts);
 
 	nes_debug(NES_DBG_CM, "netdev refcnt = %u.\n",
 			netdev_refcnt_read(nesvnic->netdev));
@@ -3240,7 +3240,7 @@ int nes_reject(struct iw_cm_id *cm_id, c
 	struct nes_cm_core *cm_core;
 	u8 *start_buff;
 
-	atomic_inc(&cm_rejects);
+	atomic_inc_unchecked(&cm_rejects);
 	cm_node = (struct nes_cm_node *)cm_id->provider_data;
 	loopback = cm_node->loopbackpartner;
 	cm_core = cm_node->cm_core;
@@ -3300,7 +3300,7 @@ int nes_connect(struct iw_cm_id *cm_id,
 		  ntohl(cm_id->local_addr.sin_addr.s_addr),
 		  ntohs(cm_id->local_addr.sin_port));
 
-	atomic_inc(&cm_connects);
+	atomic_inc_unchecked(&cm_connects);
 	nesqp->active_conn = 1;
 
 	/* cache the cm_id in the qp */
@@ -3406,7 +3406,7 @@ int nes_create_listen(struct iw_cm_id *c
 			g_cm_core->api->stop_listener(g_cm_core, (void *)cm_node);
 			return err;
 		}
-		atomic_inc(&cm_listens_created);
+		atomic_inc_unchecked(&cm_listens_created);
 	}
 
 	cm_id->add_ref(cm_id);
@@ -3507,7 +3507,7 @@ static void cm_event_connected(struct ne
 
 	if (nesqp->destroyed)
 		return;
-	atomic_inc(&cm_connecteds);
+	atomic_inc_unchecked(&cm_connecteds);
 	nes_debug(NES_DBG_CM, "QP%u attempting to connect to  0x%08X:0x%04X on"
 		  " local port 0x%04X. jiffies = %lu.\n",
 		  nesqp->hwqp.qp_id,
@@ -3694,7 +3694,7 @@ static void cm_event_reset(struct nes_cm
 
 	cm_id->add_ref(cm_id);
 	ret = cm_id->event_handler(cm_id, &cm_event);
-	atomic_inc(&cm_closes);
+	atomic_inc_unchecked(&cm_closes);
 	cm_event.event = IW_CM_EVENT_CLOSE;
 	cm_event.status = 0;
 	cm_event.provider_data = cm_id->provider_data;
@@ -3730,7 +3730,7 @@ static void cm_event_mpa_req(struct nes_
 		return;
 	cm_id = cm_node->cm_id;
 
-	atomic_inc(&cm_connect_reqs);
+	atomic_inc_unchecked(&cm_connect_reqs);
 	nes_debug(NES_DBG_CM, "cm_node = %p - cm_id = %p, jiffies = %lu\n",
 		  cm_node, cm_id, jiffies);
 
@@ -3770,7 +3770,7 @@ static void cm_event_mpa_reject(struct n
 		return;
 	cm_id = cm_node->cm_id;
 
-	atomic_inc(&cm_connect_reqs);
+	atomic_inc_unchecked(&cm_connect_reqs);
 	nes_debug(NES_DBG_CM, "cm_node = %p - cm_id = %p, jiffies = %lu\n",
 		  cm_node, cm_id, jiffies);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/nes/nes.h linux-3.2.71-pax/drivers/infiniband/hw/nes/nes.h
--- linux-3.2.71/drivers/infiniband/hw/nes/nes.h	2013-01-16 18:47:48.647057775 +0100
+++ linux-3.2.71-pax/drivers/infiniband/hw/nes/nes.h	2013-01-16 18:47:52.927057676 +0100
@@ -178,17 +178,17 @@ extern unsigned int nes_debug_level;
 extern unsigned int wqm_quanta;
 extern struct list_head nes_adapter_list;
 
-extern atomic_t cm_connects;
-extern atomic_t cm_accepts;
-extern atomic_t cm_disconnects;
-extern atomic_t cm_closes;
-extern atomic_t cm_connecteds;
-extern atomic_t cm_connect_reqs;
-extern atomic_t cm_rejects;
-extern atomic_t mod_qp_timouts;
-extern atomic_t qps_created;
-extern atomic_t qps_destroyed;
-extern atomic_t sw_qps_destroyed;
+extern atomic_unchecked_t cm_connects;
+extern atomic_unchecked_t cm_accepts;
+extern atomic_unchecked_t cm_disconnects;
+extern atomic_unchecked_t cm_closes;
+extern atomic_unchecked_t cm_connecteds;
+extern atomic_unchecked_t cm_connect_reqs;
+extern atomic_unchecked_t cm_rejects;
+extern atomic_unchecked_t mod_qp_timouts;
+extern atomic_unchecked_t qps_created;
+extern atomic_unchecked_t qps_destroyed;
+extern atomic_unchecked_t sw_qps_destroyed;
 extern u32 mh_detected;
 extern u32 mh_pauses_sent;
 extern u32 cm_packets_sent;
@@ -197,16 +197,16 @@ extern u32 cm_packets_created;
 extern u32 cm_packets_received;
 extern u32 cm_packets_dropped;
 extern u32 cm_packets_retrans;
-extern atomic_t cm_listens_created;
-extern atomic_t cm_listens_destroyed;
+extern atomic_unchecked_t cm_listens_created;
+extern atomic_unchecked_t cm_listens_destroyed;
 extern u32 cm_backlog_drops;
-extern atomic_t cm_loopbacks;
-extern atomic_t cm_nodes_created;
-extern atomic_t cm_nodes_destroyed;
-extern atomic_t cm_accel_dropped_pkts;
-extern atomic_t cm_resets_recvd;
-extern atomic_t pau_qps_created;
-extern atomic_t pau_qps_destroyed;
+extern atomic_unchecked_t cm_loopbacks;
+extern atomic_unchecked_t cm_nodes_created;
+extern atomic_unchecked_t cm_nodes_destroyed;
+extern atomic_unchecked_t cm_accel_dropped_pkts;
+extern atomic_unchecked_t cm_resets_recvd;
+extern atomic_unchecked_t pau_qps_created;
+extern atomic_unchecked_t pau_qps_destroyed;
 
 extern u32 int_mod_timer_init;
 extern u32 int_mod_cq_depth_256;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/nes/nes_mgt.c linux-3.2.71-pax/drivers/infiniband/hw/nes/nes_mgt.c
--- linux-3.2.71/drivers/infiniband/hw/nes/nes_mgt.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/nes/nes_mgt.c	2012-07-04 19:24:48.448063007 +0200
@@ -40,8 +40,8 @@
 #include "nes.h"
 #include "nes_mgt.h"
 
-atomic_t pau_qps_created;
-atomic_t pau_qps_destroyed;
+atomic_unchecked_t pau_qps_created;
+atomic_unchecked_t pau_qps_destroyed;
 
 static void nes_replenish_mgt_rq(struct nes_vnic_mgt *mgtvnic)
 {
@@ -621,7 +621,7 @@ void nes_destroy_pau_qp(struct nes_devic
 {
 	struct sk_buff *skb;
 	unsigned long flags;
-	atomic_inc(&pau_qps_destroyed);
+	atomic_inc_unchecked(&pau_qps_destroyed);
 
 	/* Free packets that have not yet been forwarded */
 	/* Lock is acquired by skb_dequeue when removing the skb */
@@ -812,7 +812,7 @@ static void nes_mgt_ce_handler(struct ne
 					cq->cq_vbase[head].cqe_words[NES_NIC_CQE_HASH_RCVNXT]);
 				skb_queue_head_init(&nesqp->pau_list);
 				spin_lock_init(&nesqp->pau_lock);
-				atomic_inc(&pau_qps_created);
+				atomic_inc_unchecked(&pau_qps_created);
 				nes_change_quad_hash(nesdev, mgtvnic->nesvnic, nesqp);
 			}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/nes/nes_nic.c linux-3.2.71-pax/drivers/infiniband/hw/nes/nes_nic.c
--- linux-3.2.71/drivers/infiniband/hw/nes/nes_nic.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/nes/nes_nic.c	2012-07-04 19:24:48.452063007 +0200
@@ -1277,39 +1277,39 @@ static void nes_netdev_get_ethtool_stats
 	target_stat_values[++index] = mh_detected;
 	target_stat_values[++index] = mh_pauses_sent;
 	target_stat_values[++index] = nesvnic->endnode_ipv4_tcp_retransmits;
-	target_stat_values[++index] = atomic_read(&cm_connects);
-	target_stat_values[++index] = atomic_read(&cm_accepts);
-	target_stat_values[++index] = atomic_read(&cm_disconnects);
-	target_stat_values[++index] = atomic_read(&cm_connecteds);
-	target_stat_values[++index] = atomic_read(&cm_connect_reqs);
-	target_stat_values[++index] = atomic_read(&cm_rejects);
-	target_stat_values[++index] = atomic_read(&mod_qp_timouts);
-	target_stat_values[++index] = atomic_read(&qps_created);
-	target_stat_values[++index] = atomic_read(&sw_qps_destroyed);
-	target_stat_values[++index] = atomic_read(&qps_destroyed);
-	target_stat_values[++index] = atomic_read(&cm_closes);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_connects);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_accepts);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_disconnects);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_connecteds);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_connect_reqs);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_rejects);
+	target_stat_values[++index] = atomic_read_unchecked(&mod_qp_timouts);
+	target_stat_values[++index] = atomic_read_unchecked(&qps_created);
+	target_stat_values[++index] = atomic_read_unchecked(&sw_qps_destroyed);
+	target_stat_values[++index] = atomic_read_unchecked(&qps_destroyed);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_closes);
 	target_stat_values[++index] = cm_packets_sent;
 	target_stat_values[++index] = cm_packets_bounced;
 	target_stat_values[++index] = cm_packets_created;
 	target_stat_values[++index] = cm_packets_received;
 	target_stat_values[++index] = cm_packets_dropped;
 	target_stat_values[++index] = cm_packets_retrans;
-	target_stat_values[++index] = atomic_read(&cm_listens_created);
-	target_stat_values[++index] = atomic_read(&cm_listens_destroyed);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_listens_created);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_listens_destroyed);
 	target_stat_values[++index] = cm_backlog_drops;
-	target_stat_values[++index] = atomic_read(&cm_loopbacks);
-	target_stat_values[++index] = atomic_read(&cm_nodes_created);
-	target_stat_values[++index] = atomic_read(&cm_nodes_destroyed);
-	target_stat_values[++index] = atomic_read(&cm_accel_dropped_pkts);
-	target_stat_values[++index] = atomic_read(&cm_resets_recvd);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_loopbacks);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_nodes_created);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_nodes_destroyed);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_accel_dropped_pkts);
+	target_stat_values[++index] = atomic_read_unchecked(&cm_resets_recvd);
 	target_stat_values[++index] = nesadapter->free_4kpbl;
 	target_stat_values[++index] = nesadapter->free_256pbl;
 	target_stat_values[++index] = int_mod_timer_init;
 	target_stat_values[++index] = nesvnic->lro_mgr.stats.aggregated;
 	target_stat_values[++index] = nesvnic->lro_mgr.stats.flushed;
 	target_stat_values[++index] = nesvnic->lro_mgr.stats.no_desc;
-	target_stat_values[++index] = atomic_read(&pau_qps_created);
-	target_stat_values[++index] = atomic_read(&pau_qps_destroyed);
+	target_stat_values[++index] = atomic_read_unchecked(&pau_qps_created);
+	target_stat_values[++index] = atomic_read_unchecked(&pau_qps_destroyed);
 }
 
 /**
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/nes/nes_verbs.c linux-3.2.71-pax/drivers/infiniband/hw/nes/nes_verbs.c
--- linux-3.2.71/drivers/infiniband/hw/nes/nes_verbs.c	2014-04-30 18:53:45.488223431 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/nes/nes_verbs.c	2014-04-30 18:53:50.432223420 +0200
@@ -46,9 +46,9 @@
 
 #include <rdma/ib_umem.h>
 
-atomic_t mod_qp_timouts;
-atomic_t qps_created;
-atomic_t sw_qps_destroyed;
+atomic_unchecked_t mod_qp_timouts;
+atomic_unchecked_t qps_created;
+atomic_unchecked_t sw_qps_destroyed;
 
 static void nes_unregister_ofa_device(struct nes_ib_device *nesibdev);
 
@@ -1131,7 +1131,7 @@ static struct ib_qp *nes_create_qp(struc
 	if (init_attr->create_flags)
 		return ERR_PTR(-EINVAL);
 
-	atomic_inc(&qps_created);
+	atomic_inc_unchecked(&qps_created);
 	switch (init_attr->qp_type) {
 		case IB_QPT_RC:
 			if (nes_drv_opt & NES_DRV_OPT_NO_INLINE_DATA) {
@@ -1462,7 +1462,7 @@ static int nes_destroy_qp(struct ib_qp *
 	struct iw_cm_event cm_event;
 	int ret = 0;
 
-	atomic_inc(&sw_qps_destroyed);
+	atomic_inc_unchecked(&sw_qps_destroyed);
 	nesqp->destroyed = 1;
 
 	/* Blow away the connection if it exists. */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/infiniband/hw/qib/qib.h linux-3.2.71-pax/drivers/infiniband/hw/qib/qib.h
--- linux-3.2.71/drivers/infiniband/hw/qib/qib.h	2015-05-10 09:22:37.147493035 +0200
+++ linux-3.2.71-pax/drivers/infiniband/hw/qib/qib.h	2015-05-10 09:23:09.007494765 +0200
@@ -51,6 +51,7 @@
 #include <linux/completion.h>
 #include <linux/kref.h>
 #include <linux/sched.h>
+#include <linux/slab.h>
 
 #include "qib_common.h"
 #include "qib_verbs.h"
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/input/gameport/gameport.c linux-3.2.71-pax/drivers/input/gameport/gameport.c
--- linux-3.2.71/drivers/input/gameport/gameport.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/input/gameport/gameport.c	2012-07-04 19:24:48.456063007 +0200
@@ -488,14 +488,14 @@ EXPORT_SYMBOL(gameport_set_phys);
  */
 static void gameport_init_port(struct gameport *gameport)
 {
-	static atomic_t gameport_no = ATOMIC_INIT(0);
+	static atomic_unchecked_t gameport_no = ATOMIC_INIT(0);
 
 	__module_get(THIS_MODULE);
 
 	mutex_init(&gameport->drv_mutex);
 	device_initialize(&gameport->dev);
 	dev_set_name(&gameport->dev, "gameport%lu",
-			(unsigned long)atomic_inc_return(&gameport_no) - 1);
+			(unsigned long)atomic_inc_return_unchecked(&gameport_no) - 1);
 	gameport->dev.bus = &gameport_bus;
 	gameport->dev.release = gameport_release_port;
 	if (gameport->parent)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/input/input.c linux-3.2.71-pax/drivers/input/input.c
--- linux-3.2.71/drivers/input/input.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/input/input.c	2012-07-04 19:24:48.460063007 +0200
@@ -1814,7 +1814,7 @@ static void input_cleanse_bitmasks(struc
  */
 int input_register_device(struct input_dev *dev)
 {
-	static atomic_t input_no = ATOMIC_INIT(0);
+	static atomic_unchecked_t input_no = ATOMIC_INIT(0);
 	struct input_handler *handler;
 	const char *path;
 	int error;
@@ -1851,7 +1851,7 @@ int input_register_device(struct input_d
 		dev->setkeycode = input_default_setkeycode;
 
 	dev_set_name(&dev->dev, "input%ld",
-		     (unsigned long) atomic_inc_return(&input_no) - 1);
+		     (unsigned long) atomic_inc_return_unchecked(&input_no) - 1);
 
 	error = device_add(&dev->dev);
 	if (error)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/input/joystick/sidewinder.c linux-3.2.71-pax/drivers/input/joystick/sidewinder.c
--- linux-3.2.71/drivers/input/joystick/sidewinder.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/input/joystick/sidewinder.c	2012-07-04 19:24:48.460063007 +0200
@@ -30,6 +30,7 @@
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/slab.h>
+#include <linux/sched.h>
 #include <linux/init.h>
 #include <linux/input.h>
 #include <linux/gameport.h>
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/input/joystick/xpad.c linux-3.2.71-pax/drivers/input/joystick/xpad.c
--- linux-3.2.71/drivers/input/joystick/xpad.c	2014-12-14 21:13:45.062054818 +0100
+++ linux-3.2.71-pax/drivers/input/joystick/xpad.c	2014-12-14 21:13:52.778069233 +0100
@@ -714,7 +714,7 @@ static void xpad_led_set(struct led_clas
 
 static int xpad_led_probe(struct usb_xpad *xpad)
 {
-	static atomic_t led_seq	= ATOMIC_INIT(0);
+	static atomic_unchecked_t led_seq	= ATOMIC_INIT(0);
 	long led_no;
 	struct xpad_led *led;
 	struct led_classdev *led_cdev;
@@ -727,7 +727,7 @@ static int xpad_led_probe(struct usb_xpa
 	if (!led)
 		return -ENOMEM;
 
-	led_no = (long)atomic_inc_return(&led_seq) - 1;
+	led_no = (long)atomic_inc_return_unchecked(&led_seq) - 1;
 
 	snprintf(led->name, sizeof(led->name), "xpad%ld", led_no);
 	led->xpad = xpad;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/input/mouse/psmouse.h linux-3.2.71-pax/drivers/input/mouse/psmouse.h
--- linux-3.2.71/drivers/input/mouse/psmouse.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/input/mouse/psmouse.h	2013-03-28 01:35:23.276427949 +0100
@@ -110,7 +110,7 @@ struct psmouse_attribute {
 	ssize_t (*set)(struct psmouse *psmouse, void *data,
 			const char *buf, size_t count);
 	bool protect;
-};
+} __do_const;
 #define to_psmouse_attr(a)	container_of((a), struct psmouse_attribute, dattr)
 
 ssize_t psmouse_attr_show_helper(struct device *dev, struct device_attribute *attr,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/input/mousedev.c linux-3.2.71-pax/drivers/input/mousedev.c
--- linux-3.2.71/drivers/input/mousedev.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/input/mousedev.c	2012-07-04 19:24:48.460063007 +0200
@@ -763,7 +763,7 @@ static ssize_t mousedev_read(struct file
 
 	spin_unlock_irq(&client->packet_lock);
 
-	if (copy_to_user(buffer, data, count))
+	if (count > sizeof(data) || copy_to_user(buffer, data, count))
 		return -EFAULT;
 
 	return count;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/input/serio/serio.c linux-3.2.71-pax/drivers/input/serio/serio.c
--- linux-3.2.71/drivers/input/serio/serio.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/input/serio/serio.c	2012-07-04 19:24:48.460063007 +0200
@@ -497,7 +497,7 @@ static void serio_release_port(struct de
  */
 static void serio_init_port(struct serio *serio)
 {
-	static atomic_t serio_no = ATOMIC_INIT(0);
+	static atomic_unchecked_t serio_no = ATOMIC_INIT(0);
 
 	__module_get(THIS_MODULE);
 
@@ -508,7 +508,7 @@ static void serio_init_port(struct serio
 	mutex_init(&serio->drv_mutex);
 	device_initialize(&serio->dev);
 	dev_set_name(&serio->dev, "serio%ld",
-			(long)atomic_inc_return(&serio_no) - 1);
+			(long)atomic_inc_return_unchecked(&serio_no) - 1);
 	serio->dev.bus = &serio_bus;
 	serio->dev.release = serio_release_port;
 	serio->dev.groups = serio_device_attr_groups;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/input/serio/serio_raw.c linux-3.2.71-pax/drivers/input/serio/serio_raw.c
--- linux-3.2.71/drivers/input/serio/serio_raw.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/input/serio/serio_raw.c	2013-09-01 20:04:19.179830683 +0200
@@ -280,7 +280,7 @@ static irqreturn_t serio_raw_interrupt(s
 
 static int serio_raw_connect(struct serio *serio, struct serio_driver *drv)
 {
-	static atomic_t serio_raw_no = ATOMIC_INIT(0);
+	static atomic_unchecked_t serio_raw_no = ATOMIC_INIT(0);
 	struct serio_raw *serio_raw;
 	int err;
 
@@ -291,7 +291,7 @@ static int serio_raw_connect(struct seri
 	}
 
 	snprintf(serio_raw->name, sizeof(serio_raw->name),
-		 "serio_raw%ld", (long)atomic_inc_return(&serio_raw_no) - 1);
+		 "serio_raw%ld", (long)atomic_inc_return_unchecked(&serio_raw_no) - 1);
 	kref_init(&serio_raw->kref);
 	INIT_LIST_HEAD(&serio_raw->client_list);
 	init_waitqueue_head(&serio_raw->wait);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/input/touchscreen/htcpen.c linux-3.2.71-pax/drivers/input/touchscreen/htcpen.c
--- linux-3.2.71/drivers/input/touchscreen/htcpen.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/input/touchscreen/htcpen.c	2015-04-30 03:11:24.988539057 +0200
@@ -227,7 +227,7 @@ static struct isa_driver htcpen_isa_driv
 	}
 };
 
-static struct dmi_system_id __initdata htcshift_dmi_table[] = {
+static const struct dmi_system_id __initconst htcshift_dmi_table[] = {
 	{
 		.ident = "Shift",
 		.matches = {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/isdn/capi/capi.c linux-3.2.71-pax/drivers/isdn/capi/capi.c
--- linux-3.2.71/drivers/isdn/capi/capi.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/isdn/capi/capi.c	2012-07-04 19:24:48.464063007 +0200
@@ -83,8 +83,8 @@ struct capiminor {
 
 	struct capi20_appl	*ap;
 	u32			ncci;
-	atomic_t		datahandle;
-	atomic_t		msgid;
+	atomic_unchecked_t	datahandle;
+	atomic_unchecked_t	msgid;
 
 	struct tty_port port;
 	int                ttyinstop;
@@ -397,7 +397,7 @@ gen_data_b3_resp_for(struct capiminor *m
 		capimsg_setu16(s, 2, mp->ap->applid);
 		capimsg_setu8 (s, 4, CAPI_DATA_B3);
 		capimsg_setu8 (s, 5, CAPI_RESP);
-		capimsg_setu16(s, 6, atomic_inc_return(&mp->msgid));
+		capimsg_setu16(s, 6, atomic_inc_return_unchecked(&mp->msgid));
 		capimsg_setu32(s, 8, mp->ncci);
 		capimsg_setu16(s, 12, datahandle);
 	}
@@ -518,14 +518,14 @@ static void handle_minor_send(struct cap
 		mp->outbytes -= len;
 		spin_unlock_bh(&mp->outlock);
 
-		datahandle = atomic_inc_return(&mp->datahandle);
+		datahandle = atomic_inc_return_unchecked(&mp->datahandle);
 		skb_push(skb, CAPI_DATA_B3_REQ_LEN);
 		memset(skb->data, 0, CAPI_DATA_B3_REQ_LEN);
 		capimsg_setu16(skb->data, 0, CAPI_DATA_B3_REQ_LEN);
 		capimsg_setu16(skb->data, 2, mp->ap->applid);
 		capimsg_setu8 (skb->data, 4, CAPI_DATA_B3);
 		capimsg_setu8 (skb->data, 5, CAPI_REQ);
-		capimsg_setu16(skb->data, 6, atomic_inc_return(&mp->msgid));
+		capimsg_setu16(skb->data, 6, atomic_inc_return_unchecked(&mp->msgid));
 		capimsg_setu32(skb->data, 8, mp->ncci);	/* NCCI */
 		capimsg_setu32(skb->data, 12, (u32)(long)skb->data);/* Data32 */
 		capimsg_setu16(skb->data, 16, len);	/* Data length */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/isdn/gigaset/common.c linux-3.2.71-pax/drivers/isdn/gigaset/common.c
--- linux-3.2.71/drivers/isdn/gigaset/common.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/isdn/gigaset/common.c	2012-07-04 19:24:48.464063007 +0200
@@ -723,7 +723,7 @@ struct cardstate *gigaset_initcs(struct
 	cs->commands_pending = 0;
 	cs->cur_at_seq = 0;
 	cs->gotfwver = -1;
-	cs->open_count = 0;
+	local_set(&cs->open_count, 0);
 	cs->dev = NULL;
 	cs->tty = NULL;
 	cs->tty_dev = NULL;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/isdn/gigaset/gigaset.h linux-3.2.71-pax/drivers/isdn/gigaset/gigaset.h
--- linux-3.2.71/drivers/isdn/gigaset/gigaset.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/isdn/gigaset/gigaset.h	2012-07-04 19:24:48.468063007 +0200
@@ -35,6 +35,7 @@
 #include <linux/tty_driver.h>
 #include <linux/list.h>
 #include <linux/atomic.h>
+#include <asm/local.h>
 
 #define GIG_VERSION {0, 5, 0, 0}
 #define GIG_COMPAT  {0, 4, 0, 0}
@@ -433,7 +434,7 @@ struct cardstate {
 	spinlock_t cmdlock;
 	unsigned curlen, cmdbytes;
 
-	unsigned open_count;
+	local_t open_count;
 	struct tty_struct *tty;
 	struct tasklet_struct if_wake_tasklet;
 	unsigned control_state;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/isdn/gigaset/interface.c linux-3.2.71-pax/drivers/isdn/gigaset/interface.c
--- linux-3.2.71/drivers/isdn/gigaset/interface.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/isdn/gigaset/interface.c	2012-07-04 19:24:48.472063007 +0200
@@ -163,9 +163,7 @@ static int if_open(struct tty_struct *tt
 	}
 	tty->driver_data = cs;
 
-	++cs->open_count;
-
-	if (cs->open_count == 1) {
+	if (local_inc_return(&cs->open_count) == 1) {
 		spin_lock_irqsave(&cs->lock, flags);
 		cs->tty = tty;
 		spin_unlock_irqrestore(&cs->lock, flags);
@@ -193,10 +191,10 @@ static void if_close(struct tty_struct *
 
 	if (!cs->connected)
 		gig_dbg(DEBUG_IF, "not connected");	/* nothing to do */
-	else if (!cs->open_count)
+	else if (!local_read(&cs->open_count))
 		dev_warn(cs->dev, "%s: device not opened\n", __func__);
 	else {
-		if (!--cs->open_count) {
+		if (!local_dec_return(&cs->open_count)) {
 			spin_lock_irqsave(&cs->lock, flags);
 			cs->tty = NULL;
 			spin_unlock_irqrestore(&cs->lock, flags);
@@ -231,7 +229,7 @@ static int if_ioctl(struct tty_struct *t
 	if (!cs->connected) {
 		gig_dbg(DEBUG_IF, "not connected");
 		retval = -ENODEV;
-	} else if (!cs->open_count)
+	} else if (!local_read(&cs->open_count))
 		dev_warn(cs->dev, "%s: device not opened\n", __func__);
 	else {
 		retval = 0;
@@ -361,7 +359,7 @@ static int if_write(struct tty_struct *t
 		retval = -ENODEV;
 		goto done;
 	}
-	if (!cs->open_count) {
+	if (!local_read(&cs->open_count)) {
 		dev_warn(cs->dev, "%s: device not opened\n", __func__);
 		retval = -ENODEV;
 		goto done;
@@ -414,7 +412,7 @@ static int if_write_room(struct tty_stru
 	if (!cs->connected) {
 		gig_dbg(DEBUG_IF, "not connected");
 		retval = -ENODEV;
-	} else if (!cs->open_count)
+	} else if (!local_read(&cs->open_count))
 		dev_warn(cs->dev, "%s: device not opened\n", __func__);
 	else if (cs->mstate != MS_LOCKED) {
 		dev_warn(cs->dev, "can't write to unlocked device\n");
@@ -444,7 +442,7 @@ static int if_chars_in_buffer(struct tty
 
 	if (!cs->connected)
 		gig_dbg(DEBUG_IF, "not connected");
-	else if (!cs->open_count)
+	else if (!local_read(&cs->open_count))
 		dev_warn(cs->dev, "%s: device not opened\n", __func__);
 	else if (cs->mstate != MS_LOCKED)
 		dev_warn(cs->dev, "can't write to unlocked device\n");
@@ -472,7 +470,7 @@ static void if_throttle(struct tty_struc
 
 	if (!cs->connected)
 		gig_dbg(DEBUG_IF, "not connected");	/* nothing to do */
-	else if (!cs->open_count)
+	else if (!local_read(&cs->open_count))
 		dev_warn(cs->dev, "%s: device not opened\n", __func__);
 	else
 		gig_dbg(DEBUG_IF, "%s: not implemented\n", __func__);
@@ -496,7 +494,7 @@ static void if_unthrottle(struct tty_str
 
 	if (!cs->connected)
 		gig_dbg(DEBUG_IF, "not connected");	/* nothing to do */
-	else if (!cs->open_count)
+	else if (!local_read(&cs->open_count))
 		dev_warn(cs->dev, "%s: device not opened\n", __func__);
 	else
 		gig_dbg(DEBUG_IF, "%s: not implemented\n", __func__);
@@ -527,7 +525,7 @@ static void if_set_termios(struct tty_st
 		goto out;
 	}
 
-	if (!cs->open_count) {
+	if (!local_read(&cs->open_count)) {
 		dev_warn(cs->dev, "%s: device not opened\n", __func__);
 		goto out;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/isdn/gigaset/usb-gigaset.c linux-3.2.71-pax/drivers/isdn/gigaset/usb-gigaset.c
--- linux-3.2.71/drivers/isdn/gigaset/usb-gigaset.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/isdn/gigaset/usb-gigaset.c	2013-08-31 15:32:40.938196950 +0200
@@ -546,7 +546,7 @@ static int gigaset_brkchars(struct cards
 	gigaset_dbg_buffer(DEBUG_USBREQ, "brkchars", 6, buf);
 	memcpy(cs->hw.usb->bchars, buf, 6);
 	return usb_control_msg(udev, usb_sndctrlpipe(udev, 0), 0x19, 0x41,
-			       0, 0, &buf, 6, 2000);
+			       0, 0, buf, 6, 2000);
 }
 
 static int gigaset_freebcshw(struct bc_state *bcs)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/isdn/hardware/avm/b1.c linux-3.2.71-pax/drivers/isdn/hardware/avm/b1.c
--- linux-3.2.71/drivers/isdn/hardware/avm/b1.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/isdn/hardware/avm/b1.c	2012-07-04 19:24:48.476063007 +0200
@@ -176,7 +176,7 @@ int b1_load_t4file(avmcard *card, capilo
 	}
 	if (left) {
 		if (t4file->user) {
-			if (copy_from_user(buf, dp, left))
+			if (left > sizeof buf || copy_from_user(buf, dp, left))
 				return -EFAULT;
 		} else {
 			memcpy(buf, dp, left);
@@ -224,7 +224,7 @@ int b1_load_config(avmcard *card, capilo
 	}
 	if (left) {
 		if (config->user) {
-			if (copy_from_user(buf, dp, left))
+			if (left > sizeof buf || copy_from_user(buf, dp, left))
 				return -EFAULT;
 		} else {
 			memcpy(buf, dp, left);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/isdn/i4l/isdn_common.c linux-3.2.71-pax/drivers/isdn/i4l/isdn_common.c
--- linux-3.2.71/drivers/isdn/i4l/isdn_common.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/isdn/i4l/isdn_common.c	2013-08-31 15:33:12.286195276 +0200
@@ -1656,6 +1656,8 @@ isdn_ioctl(struct file *file, uint cmd,
 				} else
 					return -EINVAL;
 			case IIOCDBGVAR:
+				if (!capable(CAP_SYS_RAWIO))
+					return -EPERM;
 				if (arg) {
 					if (copy_to_user(argp, &dev, sizeof(ulong)))
 						return -EFAULT;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/isdn/icn/icn.c linux-3.2.71-pax/drivers/isdn/icn/icn.c
--- linux-3.2.71/drivers/isdn/icn/icn.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/isdn/icn/icn.c	2012-07-04 19:24:48.476063007 +0200
@@ -1045,7 +1045,7 @@ icn_writecmd(const u_char * buf, int len
 		if (count > len)
 			count = len;
 		if (user) {
-			if (copy_from_user(msg, buf, count))
+			if (count > sizeof msg || copy_from_user(msg, buf, count))
 				return -EFAULT;
 		} else
 			memcpy(msg, buf, count);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/isdn/mISDN/dsp_cmx.c linux-3.2.71-pax/drivers/isdn/mISDN/dsp_cmx.c
--- linux-3.2.71/drivers/isdn/mISDN/dsp_cmx.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/isdn/mISDN/dsp_cmx.c	2013-11-23 18:07:03.581937071 +0100
@@ -1623,7 +1623,7 @@ u32	dsp_spl_jiffies; /* calculate the ne
 static u16	dsp_count; /* last sample count */
 static int	dsp_count_valid ; /* if we have last sample count */
 
-void
+void __intentional_overflow(-1)
 dsp_cmx_send(void *arg)
 {
 	struct dsp_conf *conf;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/leds/leds-clevo-mail.c linux-3.2.71-pax/drivers/leds/leds-clevo-mail.c
--- linux-3.2.71/drivers/leds/leds-clevo-mail.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/leds/leds-clevo-mail.c	2013-03-28 02:44:13.712207416 +0100
@@ -39,7 +39,7 @@ static int __init clevo_mail_led_dmi_cal
  * detected as working, but in reality it is not) as low as
  * possible.
  */
-static struct dmi_system_id __initdata mail_led_whitelist[] = {
+static const struct dmi_system_id __initconst mail_led_whitelist[] = {
 	{
 		.callback = clevo_mail_led_dmi_callback,
 		.ident = "Clevo D410J",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/leds/leds-ss4200.c linux-3.2.71-pax/drivers/leds/leds-ss4200.c
--- linux-3.2.71/drivers/leds/leds-ss4200.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/leds/leds-ss4200.c	2013-03-28 01:35:23.280427949 +0100
@@ -92,7 +92,7 @@ MODULE_PARM_DESC(nodetect, "Skip DMI-bas
  * detected as working, but in reality it is not) as low as
  * possible.
  */
-static struct dmi_system_id __initdata nas_led_whitelist[] = {
+static const struct dmi_system_id __initconst nas_led_whitelist[] = {
 	{
 		.callback = ss4200_led_dmi_callback,
 		.ident = "Intel SS4200-E",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/lguest/core.c linux-3.2.71-pax/drivers/lguest/core.c
--- linux-3.2.71/drivers/lguest/core.c	2015-08-07 11:37:20.463789890 +0200
+++ linux-3.2.71-pax/drivers/lguest/core.c	2015-08-07 11:37:43.003790553 +0200
@@ -92,9 +92,17 @@ static __init int map_switcher(void)
 	 * it's worked so far.  The end address needs +1 because __get_vm_area
 	 * allocates an extra guard page, so we need space for that.
 	 */
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+	switcher_vma = __get_vm_area(TOTAL_SWITCHER_PAGES * PAGE_SIZE,
+				     VM_ALLOC | VM_KERNEXEC, SWITCHER_ADDR, SWITCHER_ADDR
+				     + (TOTAL_SWITCHER_PAGES+1) * PAGE_SIZE);
+#else
 	switcher_vma = __get_vm_area(TOTAL_SWITCHER_PAGES * PAGE_SIZE,
 				     VM_ALLOC, SWITCHER_ADDR, SWITCHER_ADDR
 				     + (TOTAL_SWITCHER_PAGES+1) * PAGE_SIZE);
+#endif
+
 	if (!switcher_vma) {
 		err = -ENOMEM;
 		printk("lguest: could not map switcher pages high\n");
@@ -119,7 +127,7 @@ static __init int map_switcher(void)
 	 * Now the Switcher is mapped at the right address, we can't fail!
 	 * Copy in the compiled-in Switcher code (from x86/switcher_32.S).
 	 */
-	memcpy(switcher_vma->addr, start_switcher_text,
+	memcpy(switcher_vma->addr, ktla_ktva(start_switcher_text),
 	       end_switcher_text - start_switcher_text);
 
 	printk(KERN_INFO "lguest: mapped switcher at %p\n",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/lguest/page_tables.c linux-3.2.71-pax/drivers/lguest/page_tables.c
--- linux-3.2.71/drivers/lguest/page_tables.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/lguest/page_tables.c	2013-03-28 04:10:58.175929538 +0100
@@ -532,7 +532,7 @@ void pin_page(struct lg_cpu *cpu, unsign
 /*:*/
 
 #ifdef CONFIG_X86_PAE
-static void release_pmd(pmd_t *spmd)
+static void __intentional_overflow(-1) release_pmd(pmd_t *spmd)
 {
 	/* If the entry's not present, there's nothing to release. */
 	if (pmd_flags(*spmd) & _PAGE_PRESENT) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/lguest/x86/core.c linux-3.2.71-pax/drivers/lguest/x86/core.c
--- linux-3.2.71/drivers/lguest/x86/core.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/lguest/x86/core.c	2012-07-04 19:24:48.476063007 +0200
@@ -59,7 +59,7 @@ static struct {
 /* Offset from where switcher.S was compiled to where we've copied it */
 static unsigned long switcher_offset(void)
 {
-	return SWITCHER_ADDR - (unsigned long)start_switcher_text;
+	return SWITCHER_ADDR - (unsigned long)ktla_ktva(start_switcher_text);
 }
 
 /* This cpu's struct lguest_pages. */
@@ -100,7 +100,13 @@ static void copy_in_guest_info(struct lg
 	 * These copies are pretty cheap, so we do them unconditionally: */
 	/* Save the current Host top-level page directory.
 	 */
+
+#ifdef CONFIG_PAX_PER_CPU_PGD
+	pages->state.host_cr3 = read_cr3();
+#else
 	pages->state.host_cr3 = __pa(current->mm->pgd);
+#endif
+
 	/*
 	 * Set up the Guest's page tables to see this CPU's pages (and no
 	 * other CPU's pages).
@@ -472,7 +478,7 @@ void __init lguest_arch_host_init(void)
 	 * compiled-in switcher code and the high-mapped copy we just made.
 	 */
 	for (i = 0; i < IDT_ENTRIES; i++)
-		default_idt_entries[i] += switcher_offset();
+		default_idt_entries[i] = ktla_ktva(default_idt_entries[i]) + switcher_offset();
 
 	/*
 	 * Set up the Switcher's per-cpu areas.
@@ -555,7 +561,7 @@ void __init lguest_arch_host_init(void)
 	 * it will be undisturbed when we switch.  To change %cs and jump we
 	 * need this structure to feed to Intel's "lcall" instruction.
 	 */
-	lguest_entry.offset = (long)switch_to_guest + switcher_offset();
+	lguest_entry.offset = (long)ktla_ktva(switch_to_guest) + switcher_offset();
 	lguest_entry.segment = LGUEST_CS;
 
 	/*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/lguest/x86/switcher_32.S linux-3.2.71-pax/drivers/lguest/x86/switcher_32.S
--- linux-3.2.71/drivers/lguest/x86/switcher_32.S	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/lguest/x86/switcher_32.S	2012-07-04 19:24:48.480063007 +0200
@@ -87,6 +87,7 @@
 #include <asm/page.h>
 #include <asm/segment.h>
 #include <asm/lguest.h>
+#include <asm/processor-flags.h>
 
 // We mark the start of the code to copy
 // It's placed in .text tho it's never run here
@@ -149,6 +150,13 @@ ENTRY(switch_to_guest)
 	// Changes type when we load it: damn Intel!
 	// For after we switch over our page tables
 	// That entry will be read-only: we'd crash.
+
+#ifdef CONFIG_PAX_KERNEXEC
+	mov	%cr0, %edx
+	xor	$X86_CR0_WP, %edx
+	mov	%edx, %cr0
+#endif
+
 	movl	$(GDT_ENTRY_TSS*8), %edx
 	ltr	%dx
 
@@ -157,9 +165,15 @@ ENTRY(switch_to_guest)
 	// Let's clear it again for our return.
 	// The GDT descriptor of the Host
 	// Points to the table after two "size" bytes
-	movl	(LGUEST_PAGES_host_gdt_desc+2)(%eax), %edx
+	movl	(LGUEST_PAGES_host_gdt_desc+2)(%eax), %eax
 	// Clear "used" from type field (byte 5, bit 2)
-	andb	$0xFD, (GDT_ENTRY_TSS*8 + 5)(%edx)
+	andb	$0xFD, (GDT_ENTRY_TSS*8 + 5)(%eax)
+
+#ifdef CONFIG_PAX_KERNEXEC
+	mov	%cr0, %eax
+	xor	$X86_CR0_WP, %eax
+	mov	%eax, %cr0
+#endif
 
 	// Once our page table's switched, the Guest is live!
 	// The Host fades as we run this final step.
@@ -295,13 +309,12 @@ deliver_to_host:
 	// I consulted gcc, and it gave
 	// These instructions, which I gladly credit:
 	leal	(%edx,%ebx,8), %eax
-	movzwl	(%eax),%edx
-	movl	4(%eax), %eax
-	xorw	%ax, %ax
-	orl	%eax, %edx
+	movl	4(%eax), %edx
+	movw	(%eax), %dx
 	// Now the address of the handler's in %edx
 	// We call it now: its "iret" drops us home.
-	jmp	*%edx
+	ljmp	$__KERNEL_CS, $1f
+1:	jmp	*%edx
 
 // Every interrupt can come to us here
 // But we must truly tell each apart.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/macintosh/macio_asic.c linux-3.2.71-pax/drivers/macintosh/macio_asic.c
--- linux-3.2.71/drivers/macintosh/macio_asic.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/macintosh/macio_asic.c	2012-07-04 19:24:48.480063007 +0200
@@ -748,7 +748,7 @@ static void __devexit macio_pci_remove(s
  * MacIO is matched against any Apple ID, it's probe() function
  * will then decide wether it applies or not
  */
-static const struct pci_device_id __devinitdata pci_ids [] = { {
+static const struct pci_device_id __devinitconst pci_ids [] = { {
 	.vendor		= PCI_VENDOR_ID_APPLE,
 	.device		= PCI_ANY_ID,
 	.subvendor	= PCI_ANY_ID,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/md/dm.c linux-3.2.71-pax/drivers/md/dm.c
--- linux-3.2.71/drivers/md/dm.c	2015-05-10 09:22:37.215493038 +0200
+++ linux-3.2.71-pax/drivers/md/dm.c	2015-05-10 09:23:09.043494767 +0200
@@ -177,9 +177,9 @@ struct mapped_device {
 	/*
 	 * Event handling.
 	 */
-	atomic_t event_nr;
+	atomic_unchecked_t event_nr;
 	wait_queue_head_t eventq;
-	atomic_t uevent_seq;
+	atomic_unchecked_t uevent_seq;
 	struct list_head uevent_list;
 	spinlock_t uevent_lock; /* Protect access to uevent_list */
 
@@ -1871,8 +1871,8 @@ static struct mapped_device *alloc_dev(i
 	rwlock_init(&md->map_lock);
 	atomic_set(&md->holders, 1);
 	atomic_set(&md->open_count, 0);
-	atomic_set(&md->event_nr, 0);
-	atomic_set(&md->uevent_seq, 0);
+	atomic_set_unchecked(&md->event_nr, 0);
+	atomic_set_unchecked(&md->uevent_seq, 0);
 	INIT_LIST_HEAD(&md->uevent_list);
 	spin_lock_init(&md->uevent_lock);
 
@@ -2007,7 +2007,7 @@ static void event_callback(void *context
 
 	dm_send_uevents(&uevents, &disk_to_dev(md->disk)->kobj);
 
-	atomic_inc(&md->event_nr);
+	atomic_inc_unchecked(&md->event_nr);
 	wake_up(&md->eventq);
 }
 
@@ -2648,18 +2648,18 @@ int dm_kobject_uevent(struct mapped_devi
 
 uint32_t dm_next_uevent_seq(struct mapped_device *md)
 {
-	return atomic_add_return(1, &md->uevent_seq);
+	return atomic_add_return_unchecked(1, &md->uevent_seq);
 }
 
 uint32_t dm_get_event_nr(struct mapped_device *md)
 {
-	return atomic_read(&md->event_nr);
+	return atomic_read_unchecked(&md->event_nr);
 }
 
 int dm_wait_event(struct mapped_device *md, int event_nr)
 {
 	return wait_event_interruptible(md->eventq,
-			(event_nr != atomic_read(&md->event_nr)));
+			(event_nr != atomic_read_unchecked(&md->event_nr)));
 }
 
 void dm_uevent_add(struct mapped_device *md, struct list_head *elist)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/md/dm-ioctl.c linux-3.2.71-pax/drivers/md/dm-ioctl.c
--- linux-3.2.71/drivers/md/dm-ioctl.c	2013-03-29 02:18:38.691676284 +0100
+++ linux-3.2.71-pax/drivers/md/dm-ioctl.c	2013-03-29 02:20:31.335670270 +0100
@@ -1601,7 +1601,7 @@ static int validate_params(uint cmd, str
 	    cmd == DM_LIST_VERSIONS_CMD)
 		return 0;
 
-	if ((cmd == DM_DEV_CREATE_CMD)) {
+	if (cmd == DM_DEV_CREATE_CMD) {
 		if (!*param->name) {
 			DMWARN("name not supplied when creating device");
 			return -EINVAL;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/md/dm-raid1.c linux-3.2.71-pax/drivers/md/dm-raid1.c
--- linux-3.2.71/drivers/md/dm-raid1.c	2015-05-10 09:22:37.203493038 +0200
+++ linux-3.2.71-pax/drivers/md/dm-raid1.c	2015-05-10 09:23:09.043494767 +0200
@@ -40,7 +40,7 @@ enum dm_raid1_error {
 
 struct mirror {
 	struct mirror_set *ms;
-	atomic_t error_count;
+	atomic_unchecked_t error_count;
 	unsigned long error_type;
 	struct dm_dev *dev;
 	sector_t offset;
@@ -185,7 +185,7 @@ static struct mirror *get_valid_mirror(s
 	struct mirror *m;
 
 	for (m = ms->mirror; m < ms->mirror + ms->nr_mirrors; m++)
-		if (!atomic_read(&m->error_count))
+		if (!atomic_read_unchecked(&m->error_count))
 			return m;
 
 	return NULL;
@@ -217,7 +217,7 @@ static void fail_mirror(struct mirror *m
 	 * simple way to tell if a device has encountered
 	 * errors.
 	 */
-	atomic_inc(&m->error_count);
+	atomic_inc_unchecked(&m->error_count);
 
 	if (test_and_set_bit(error_type, &m->error_type))
 		return;
@@ -408,7 +408,7 @@ static struct mirror *choose_mirror(stru
 	struct mirror *m = get_default_mirror(ms);
 
 	do {
-		if (likely(!atomic_read(&m->error_count)))
+		if (likely(!atomic_read_unchecked(&m->error_count)))
 			return m;
 
 		if (m-- == ms->mirror)
@@ -422,7 +422,7 @@ static int default_ok(struct mirror *m)
 {
 	struct mirror *default_mirror = get_default_mirror(m->ms);
 
-	return !atomic_read(&default_mirror->error_count);
+	return !atomic_read_unchecked(&default_mirror->error_count);
 }
 
 static int mirror_available(struct mirror_set *ms, struct bio *bio)
@@ -559,7 +559,7 @@ static void do_reads(struct mirror_set *
 		 */
 		if (likely(region_in_sync(ms, region, 1)))
 			m = choose_mirror(ms, bio->bi_sector);
-		else if (m && atomic_read(&m->error_count))
+		else if (m && atomic_read_unchecked(&m->error_count))
 			m = NULL;
 
 		if (likely(m))
@@ -946,7 +946,7 @@ static int get_mirror(struct mirror_set
 	}
 
 	ms->mirror[mirror].ms = ms;
-	atomic_set(&(ms->mirror[mirror].error_count), 0);
+	atomic_set_unchecked(&(ms->mirror[mirror].error_count), 0);
 	ms->mirror[mirror].error_type = 0;
 	ms->mirror[mirror].offset = offset;
 
@@ -1357,7 +1357,7 @@ static void mirror_resume(struct dm_targ
  */
 static char device_status_char(struct mirror *m)
 {
-	if (!atomic_read(&(m->error_count)))
+	if (!atomic_read_unchecked(&(m->error_count)))
 		return 'A';
 
 	return (test_bit(DM_RAID1_FLUSH_ERROR, &(m->error_type))) ? 'F' :
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/md/dm-stripe.c linux-3.2.71-pax/drivers/md/dm-stripe.c
--- linux-3.2.71/drivers/md/dm-stripe.c	2013-03-29 02:18:38.695676284 +0100
+++ linux-3.2.71-pax/drivers/md/dm-stripe.c	2013-03-29 02:20:31.335670270 +0100
@@ -20,7 +20,7 @@ struct stripe {
 	struct dm_dev *dev;
 	sector_t physical_start;
 
-	atomic_t error_count;
+	atomic_unchecked_t error_count;
 };
 
 struct stripe_c {
@@ -192,7 +192,7 @@ static int stripe_ctr(struct dm_target *
 			kfree(sc);
 			return r;
 		}
-		atomic_set(&(sc->stripe[i].error_count), 0);
+		atomic_set_unchecked(&(sc->stripe[i].error_count), 0);
 	}
 
 	ti->private = sc;
@@ -314,7 +314,7 @@ static void stripe_status(struct dm_targ
 		DMEMIT("%d ", sc->stripes);
 		for (i = 0; i < sc->stripes; i++)  {
 			DMEMIT("%s ", sc->stripe[i].dev->name);
-			buffer[i] = atomic_read(&(sc->stripe[i].error_count)) ?
+			buffer[i] = atomic_read_unchecked(&(sc->stripe[i].error_count)) ?
 				'D' : 'A';
 		}
 		buffer[i] = '\0';
@@ -360,8 +360,8 @@ static int stripe_end_io(struct dm_targe
 	 */
 	for (i = 0; i < sc->stripes; i++)
 		if (!strcmp(sc->stripe[i].dev->name, major_minor)) {
-			atomic_inc(&(sc->stripe[i].error_count));
-			if (atomic_read(&(sc->stripe[i].error_count)) <
+			atomic_inc_unchecked(&(sc->stripe[i].error_count));
+			if (atomic_read_unchecked(&(sc->stripe[i].error_count)) <
 			    DM_IO_ERROR_THRESHOLD)
 				schedule_work(&sc->trigger_event);
 		}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/md/dm-table.c linux-3.2.71-pax/drivers/md/dm-table.c
--- linux-3.2.71/drivers/md/dm-table.c	2014-01-03 15:48:44.820070574 +0100
+++ linux-3.2.71-pax/drivers/md/dm-table.c	2014-01-03 15:48:49.536070322 +0100
@@ -328,7 +328,7 @@ static struct dm_dev_internal *find_devi
 static int open_dev(struct dm_dev_internal *d, dev_t dev,
 		    struct mapped_device *md)
 {
-	static char *_claim_ptr = "I belong to device-mapper";
+	static char _claim_ptr[] = "I belong to device-mapper";
 	struct block_device *bdev;
 
 	int r;
@@ -396,7 +396,7 @@ static int device_area_is_invalid(struct
 	if (!dev_size)
 		return 0;
 
-	if ((start >= dev_size) || (start + len > dev_size)) {
+	if ((start >= dev_size) || (len > dev_size - start)) {
 		DMWARN("%s: %s too small for target: "
 		       "start=%llu, len=%llu, dev_size=%llu",
 		       dm_device_name(ti->table->md), bdevname(bdev, b),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/md/dm-thin-metadata.c linux-3.2.71-pax/drivers/md/dm-thin-metadata.c
--- linux-3.2.71/drivers/md/dm-thin-metadata.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/md/dm-thin-metadata.c	2012-07-04 19:24:48.484063007 +0200
@@ -432,7 +432,7 @@ static int init_pmd(struct dm_pool_metad
 
 	pmd->info.tm = tm;
 	pmd->info.levels = 2;
-	pmd->info.value_type.context = pmd->data_sm;
+	pmd->info.value_type.context = (dm_space_map_no_const *)pmd->data_sm;
 	pmd->info.value_type.size = sizeof(__le64);
 	pmd->info.value_type.inc = data_block_inc;
 	pmd->info.value_type.dec = data_block_dec;
@@ -451,7 +451,7 @@ static int init_pmd(struct dm_pool_metad
 
 	pmd->bl_info.tm = tm;
 	pmd->bl_info.levels = 1;
-	pmd->bl_info.value_type.context = pmd->data_sm;
+	pmd->bl_info.value_type.context = (dm_space_map_no_const *)pmd->data_sm;
 	pmd->bl_info.value_type.size = sizeof(__le64);
 	pmd->bl_info.value_type.inc = data_block_inc;
 	pmd->bl_info.value_type.dec = data_block_dec;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/md/md.c linux-3.2.71-pax/drivers/md/md.c
--- linux-3.2.71/drivers/md/md.c	2014-08-06 23:17:21.029614204 +0200
+++ linux-3.2.71-pax/drivers/md/md.c	2014-08-06 23:17:25.997614193 +0200
@@ -278,10 +278,10 @@ EXPORT_SYMBOL_GPL(md_trim_bio);
  *  start build, activate spare
  */
 static DECLARE_WAIT_QUEUE_HEAD(md_event_waiters);
-static atomic_t md_event_count;
+static atomic_unchecked_t md_event_count;
 void md_new_event(struct mddev *mddev)
 {
-	atomic_inc(&md_event_count);
+	atomic_inc_unchecked(&md_event_count);
 	wake_up(&md_event_waiters);
 }
 EXPORT_SYMBOL_GPL(md_new_event);
@@ -291,7 +291,7 @@ EXPORT_SYMBOL_GPL(md_new_event);
  */
 static void md_new_event_inintr(struct mddev *mddev)
 {
-	atomic_inc(&md_event_count);
+	atomic_inc_unchecked(&md_event_count);
 	wake_up(&md_event_waiters);
 }
 
@@ -1534,7 +1534,7 @@ static int super_1_load(struct md_rdev *
 
 	rdev->preferred_minor = 0xffff;
 	rdev->data_offset = le64_to_cpu(sb->data_offset);
-	atomic_set(&rdev->corrected_errors, le32_to_cpu(sb->cnt_corrected_read));
+	atomic_set_unchecked(&rdev->corrected_errors, le32_to_cpu(sb->cnt_corrected_read));
 
 	rdev->sb_size = le32_to_cpu(sb->max_dev) * 2 + 256;
 	bmask = queue_logical_block_size(rdev->bdev->bd_disk->queue)-1;
@@ -1751,7 +1751,7 @@ static void super_1_sync(struct mddev *m
 	else
 		sb->resync_offset = cpu_to_le64(0);
 
-	sb->cnt_corrected_read = cpu_to_le32(atomic_read(&rdev->corrected_errors));
+	sb->cnt_corrected_read = cpu_to_le32(atomic_read_unchecked(&rdev->corrected_errors));
 
 	sb->raid_disks = cpu_to_le32(mddev->raid_disks);
 	sb->size = cpu_to_le64(mddev->dev_sectors);
@@ -2649,7 +2649,7 @@ __ATTR(state, S_IRUGO|S_IWUSR, state_sho
 static ssize_t
 errors_show(struct md_rdev *rdev, char *page)
 {
-	return sprintf(page, "%d\n", atomic_read(&rdev->corrected_errors));
+	return sprintf(page, "%d\n", atomic_read_unchecked(&rdev->corrected_errors));
 }
 
 static ssize_t
@@ -2658,7 +2658,7 @@ errors_store(struct md_rdev *rdev, const
 	char *e;
 	unsigned long n = simple_strtoul(buf, &e, 10);
 	if (*buf && (*e == 0 || *e == '\n')) {
-		atomic_set(&rdev->corrected_errors, n);
+		atomic_set_unchecked(&rdev->corrected_errors, n);
 		return len;
 	}
 	return -EINVAL;
@@ -3052,8 +3052,8 @@ int md_rdev_init(struct md_rdev *rdev)
 	rdev->sb_loaded = 0;
 	rdev->bb_page = NULL;
 	atomic_set(&rdev->nr_pending, 0);
-	atomic_set(&rdev->read_errors, 0);
-	atomic_set(&rdev->corrected_errors, 0);
+	atomic_set_unchecked(&rdev->read_errors, 0);
+	atomic_set_unchecked(&rdev->corrected_errors, 0);
 
 	INIT_LIST_HEAD(&rdev->same_set);
 	init_waitqueue_head(&rdev->blocked_wait);
@@ -6703,7 +6703,7 @@ static int md_seq_show(struct seq_file *
 
 		spin_unlock(&pers_lock);
 		seq_printf(seq, "\n");
-		seq->poll_event = atomic_read(&md_event_count);
+		seq->poll_event = atomic_read_unchecked(&md_event_count);
 		return 0;
 	}
 	if (v == (void*)2) {
@@ -6792,7 +6792,7 @@ static int md_seq_show(struct seq_file *
 				chunk_kb ? "KB" : "B");
 			if (bitmap->file) {
 				seq_printf(seq, ", file: ");
-				seq_path(seq, &bitmap->file->f_path, " \t\n");
+				seq_path(seq, &bitmap->file->f_path, " \t\n\\");
 			}
 
 			seq_printf(seq, "\n");
@@ -6823,7 +6823,7 @@ static int md_seq_open(struct inode *ino
 		return error;
 
 	seq = file->private_data;
-	seq->poll_event = atomic_read(&md_event_count);
+	seq->poll_event = atomic_read_unchecked(&md_event_count);
 	return error;
 }
 
@@ -6837,7 +6837,7 @@ static unsigned int mdstat_poll(struct f
 	/* always allow read */
 	mask = POLLIN | POLLRDNORM;
 
-	if (seq->poll_event != atomic_read(&md_event_count))
+	if (seq->poll_event != atomic_read_unchecked(&md_event_count))
 		mask |= POLLERR | POLLPRI;
 	return mask;
 }
@@ -6881,7 +6881,7 @@ static int is_mddev_idle(struct mddev *m
 		struct gendisk *disk = rdev->bdev->bd_contains->bd_disk;
 		curr_events = (int)part_stat_read(&disk->part0, sectors[0]) +
 			      (int)part_stat_read(&disk->part0, sectors[1]) -
-			      atomic_read(&disk->sync_io);
+			      atomic_read_unchecked(&disk->sync_io);
 		/* sync IO will cause sync_io to increase before the disk_stats
 		 * as sync_io is counted when a request starts, and
 		 * disk_stats is counted when it completes.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/md/md.h linux-3.2.71-pax/drivers/md/md.h
--- linux-3.2.71/drivers/md/md.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/md/md.h	2012-07-04 19:24:48.488063007 +0200
@@ -120,13 +120,13 @@ struct md_rdev {
 					 * only maintained for arrays that
 					 * support hot removal
 					 */
-	atomic_t	read_errors;	/* number of consecutive read errors that
+	atomic_unchecked_t	read_errors;	/* number of consecutive read errors that
 					 * we have tried to ignore.
 					 */
 	struct timespec last_read_error;	/* monotonic time since our
 						 * last read error
 						 */
-	atomic_t	corrected_errors; /* number of corrected read errors,
+	atomic_unchecked_t	corrected_errors; /* number of corrected read errors,
 					   * for reporting to userspace and storing
 					   * in superblock.
 					   */
@@ -410,7 +410,7 @@ static inline void rdev_dec_pending(stru
 
 static inline void md_sync_acct(struct block_device *bdev, unsigned long nr_sectors)
 {
-        atomic_add(nr_sectors, &bdev->bd_contains->bd_disk->sync_io);
+	atomic_add_unchecked(nr_sectors, &bdev->bd_contains->bd_disk->sync_io);
 }
 
 struct md_personality
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/md/persistent-data/dm-space-map-checker.c linux-3.2.71-pax/drivers/md/persistent-data/dm-space-map-checker.c
--- linux-3.2.71/drivers/md/persistent-data/dm-space-map-checker.c	2012-07-12 18:23:34.721071952 +0200
+++ linux-3.2.71-pax/drivers/md/persistent-data/dm-space-map-checker.c	2012-07-12 18:23:40.301071697 +0200
@@ -167,7 +167,7 @@ static int ca_commit(struct count_array
 /*----------------------------------------------------------------*/
 
 struct sm_checker {
-	struct dm_space_map sm;
+	dm_space_map_no_const sm;
 
 	struct count_array old_counts;
 	struct count_array counts;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/md/persistent-data/dm-space-map.h linux-3.2.71-pax/drivers/md/persistent-data/dm-space-map.h
--- linux-3.2.71/drivers/md/persistent-data/dm-space-map.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/md/persistent-data/dm-space-map.h	2012-07-04 19:24:48.492063007 +0200
@@ -60,6 +60,7 @@ struct dm_space_map {
 	int (*root_size)(struct dm_space_map *sm, size_t *result);
 	int (*copy_root)(struct dm_space_map *sm, void *copy_to_here_le, size_t len);
 };
+typedef struct dm_space_map __no_const dm_space_map_no_const;
 
 /*----------------------------------------------------------------*/
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/md/raid10.c linux-3.2.71-pax/drivers/md/raid10.c
--- linux-3.2.71/drivers/md/raid10.c	2014-09-14 14:10:58.878117848 +0200
+++ linux-3.2.71-pax/drivers/md/raid10.c	2014-09-14 14:11:25.974138365 +0200
@@ -1465,7 +1465,7 @@ static void end_sync_read(struct bio *bi
 		/* The write handler will notice the lack of
 		 * R10BIO_Uptodate and record any errors etc
 		 */
-		atomic_add(r10_bio->sectors,
+		atomic_add_unchecked(r10_bio->sectors,
 			   &conf->mirrors[d].rdev->corrected_errors);
 
 	/* for reconstruct, we always reschedule after a read.
@@ -1765,7 +1765,7 @@ static void check_decay_read_errors(stru
 {
 	struct timespec cur_time_mon;
 	unsigned long hours_since_last;
-	unsigned int read_errors = atomic_read(&rdev->read_errors);
+	unsigned int read_errors = atomic_read_unchecked(&rdev->read_errors);
 
 	ktime_get_ts(&cur_time_mon);
 
@@ -1787,9 +1787,9 @@ static void check_decay_read_errors(stru
 	 * overflowing the shift of read_errors by hours_since_last.
 	 */
 	if (hours_since_last >= 8 * sizeof(read_errors))
-		atomic_set(&rdev->read_errors, 0);
+		atomic_set_unchecked(&rdev->read_errors, 0);
 	else
-		atomic_set(&rdev->read_errors, read_errors >> hours_since_last);
+		atomic_set_unchecked(&rdev->read_errors, read_errors >> hours_since_last);
 }
 
 static int r10_sync_page_io(struct md_rdev *rdev, sector_t sector,
@@ -1839,8 +1839,8 @@ static void fix_read_error(struct r10con
 		return;
 
 	check_decay_read_errors(mddev, rdev);
-	atomic_inc(&rdev->read_errors);
-	if (atomic_read(&rdev->read_errors) > max_read_errors) {
+	atomic_inc_unchecked(&rdev->read_errors);
+	if (atomic_read_unchecked(&rdev->read_errors) > max_read_errors) {
 		char b[BDEVNAME_SIZE];
 		bdevname(rdev->bdev, b);
 
@@ -1848,7 +1848,7 @@ static void fix_read_error(struct r10con
 		       "md/raid10:%s: %s: Raid device exceeded "
 		       "read_error threshold [cur %d:max %d]\n",
 		       mdname(mddev), b,
-		       atomic_read(&rdev->read_errors), max_read_errors);
+		       atomic_read_unchecked(&rdev->read_errors), max_read_errors);
 		printk(KERN_NOTICE
 		       "md/raid10:%s: %s: Failing raid device\n",
 		       mdname(mddev), b);
@@ -1993,7 +1993,7 @@ static void fix_read_error(struct r10con
 				       (unsigned long long)(
 					       sect + rdev->data_offset),
 				       bdevname(rdev->bdev, b));
-				atomic_add(s, &rdev->corrected_errors);
+				atomic_add_unchecked(s, &rdev->corrected_errors);
 			}
 
 			rdev_dec_pending(rdev, mddev);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/md/raid1.c linux-3.2.71-pax/drivers/md/raid1.c
--- linux-3.2.71/drivers/md/raid1.c	2015-08-14 21:48:35.152707921 +0200
+++ linux-3.2.71-pax/drivers/md/raid1.c	2015-08-14 21:48:45.588707364 +0200
@@ -1591,7 +1591,7 @@ static int fix_sync_read_error(struct r1
 			if (r1_sync_page_io(rdev, sect, s,
 					    bio->bi_io_vec[idx].bv_page,
 					    READ) != 0)
-				atomic_add(s, &rdev->corrected_errors);
+				atomic_add_unchecked(s, &rdev->corrected_errors);
 		}
 		sectors -= s;
 		sect += s;
@@ -1810,7 +1810,7 @@ static void fix_read_error(struct r1conf
 			    test_bit(In_sync, &rdev->flags)) {
 				if (r1_sync_page_io(rdev, sect, s,
 						    conf->tmppage, READ)) {
-					atomic_add(s, &rdev->corrected_errors);
+					atomic_add_unchecked(s, &rdev->corrected_errors);
 					printk(KERN_INFO
 					       "md/raid1:%s: read error corrected "
 					       "(%d sectors at %llu on %s)\n",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/md/raid5.c linux-3.2.71-pax/drivers/md/raid5.c
--- linux-3.2.71/drivers/md/raid5.c	2015-08-07 11:37:20.463789890 +0200
+++ linux-3.2.71-pax/drivers/md/raid5.c	2015-08-07 11:37:43.003790553 +0200
@@ -598,23 +598,23 @@ async_copy_data(int frombio, struct bio
 	struct bio_vec *bvl;
 	struct page *bio_page;
 	int i;
-	int page_offset;
+	s64 page_offset;
 	struct async_submit_ctl submit;
 	enum async_tx_flags flags = 0;
 
 	if (bio->bi_sector >= sector)
-		page_offset = (signed)(bio->bi_sector - sector) * 512;
+		page_offset = (s64)(bio->bi_sector - sector) * 512;
 	else
-		page_offset = (signed)(sector - bio->bi_sector) * -512;
+		page_offset = (s64)(sector - bio->bi_sector) * -512;
 
 	if (frombio)
 		flags |= ASYNC_TX_FENCE;
 	init_async_submit(&submit, flags, tx, NULL, NULL, NULL);
 
 	bio_for_each_segment(bvl, bio, i) {
-		int len = bvl->bv_len;
-		int clen;
-		int b_offset = 0;
+		s64 len = bvl->bv_len;
+		s64 clen;
+		s64 b_offset = 0;
 
 		if (page_offset < 0) {
 			b_offset = -page_offset;
@@ -1619,19 +1619,19 @@ static void raid5_end_read_request(struc
 				(unsigned long long)(sh->sector
 						     + rdev->data_offset),
 				bdevname(rdev->bdev, b));
-			atomic_add(STRIPE_SECTORS, &rdev->corrected_errors);
+			atomic_add_unchecked(STRIPE_SECTORS, &rdev->corrected_errors);
 			clear_bit(R5_ReadError, &sh->dev[i].flags);
 			clear_bit(R5_ReWrite, &sh->dev[i].flags);
 		}
-		if (atomic_read(&conf->disks[i].rdev->read_errors))
-			atomic_set(&conf->disks[i].rdev->read_errors, 0);
+		if (atomic_read_unchecked(&conf->disks[i].rdev->read_errors))
+			atomic_set_unchecked(&conf->disks[i].rdev->read_errors, 0);
 	} else {
 		const char *bdn = bdevname(conf->disks[i].rdev->bdev, b);
 		int retry = 0;
 		rdev = conf->disks[i].rdev;
 
 		clear_bit(R5_UPTODATE, &sh->dev[i].flags);
-		atomic_inc(&rdev->read_errors);
+		atomic_inc_unchecked(&rdev->read_errors);
 		if (conf->mddev->degraded >= conf->max_degraded)
 			printk_ratelimited(
 				KERN_WARNING
@@ -1651,7 +1651,7 @@ static void raid5_end_read_request(struc
 				(unsigned long long)(sh->sector
 						     + rdev->data_offset),
 				bdn);
-		else if (atomic_read(&rdev->read_errors)
+		else if (atomic_read_unchecked(&rdev->read_errors)
 			 > conf->max_nr_stripes)
 			printk(KERN_WARNING
 			       "md/raid:%s: Too many read errors, failing device %s.\n",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/dvb/ddbridge/ddbridge-core.c linux-3.2.71-pax/drivers/media/dvb/ddbridge/ddbridge-core.c
--- linux-3.2.71/drivers/media/dvb/ddbridge/ddbridge-core.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/dvb/ddbridge/ddbridge-core.c	2012-07-04 19:24:48.496063007 +0200
@@ -1678,7 +1678,7 @@ static struct ddb_info ddb_v6 = {
 	.subvendor   = _subvend, .subdevice = _subdev, \
 	.driver_data = (unsigned long)&_driverdata }
 
-static const struct pci_device_id ddb_id_tbl[] __devinitdata = {
+static const struct pci_device_id ddb_id_tbl[] __devinitconst = {
 	DDB_ID(DDVID, 0x0002, DDVID, 0x0001, ddb_octopus),
 	DDB_ID(DDVID, 0x0003, DDVID, 0x0001, ddb_octopus),
 	DDB_ID(DDVID, 0x0003, DDVID, 0x0002, ddb_octopus_le),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/dvb/dvb-core/dvbdev.c linux-3.2.71-pax/drivers/media/dvb/dvb-core/dvbdev.c
--- linux-3.2.71/drivers/media/dvb/dvb-core/dvbdev.c	2012-07-27 22:08:37.742372801 +0200
+++ linux-3.2.71-pax/drivers/media/dvb/dvb-core/dvbdev.c	2012-07-27 22:08:49.662373150 +0200
@@ -192,7 +192,7 @@ int dvb_register_device(struct dvb_adapt
 			const struct dvb_device *template, void *priv, int type)
 {
 	struct dvb_device *dvbdev;
-	struct file_operations *dvbdevfops;
+	file_operations_no_const *dvbdevfops;
 	struct device *clsdev;
 	int minor;
 	int id;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/dvb/dvb-usb/cxusb.c linux-3.2.71-pax/drivers/media/dvb/dvb-usb/cxusb.c
--- linux-3.2.71/drivers/media/dvb/dvb-usb/cxusb.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/dvb/dvb-usb/cxusb.c	2013-01-16 23:16:18.278685502 +0100
@@ -1069,7 +1069,7 @@ static struct dib0070_config dib7070p_di
 struct dib0700_adapter_state {
 	int (*set_param_save) (struct dvb_frontend *,
 			       struct dvb_frontend_parameters *);
-};
+} __no_const;
 
 static int dib7070_set_param_override(struct dvb_frontend *fe,
 				      struct dvb_frontend_parameters *fep)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/dvb/dvb-usb/dw2102.c linux-3.2.71-pax/drivers/media/dvb/dvb-usb/dw2102.c
--- linux-3.2.71/drivers/media/dvb/dvb-usb/dw2102.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/dvb/dvb-usb/dw2102.c	2013-01-16 23:16:37.074685068 +0100
@@ -95,7 +95,7 @@ struct su3000_state {
 
 struct s6x0_state {
 	int (*old_set_voltage)(struct dvb_frontend *f, fe_sec_voltage_t v);
-};
+} __no_const;
 
 /* debug */
 static int dvb_usb_dw2102_debug;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/dvb/frontends/dib3000.h linux-3.2.71-pax/drivers/media/dvb/frontends/dib3000.h
--- linux-3.2.71/drivers/media/dvb/frontends/dib3000.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/dvb/frontends/dib3000.h	2012-07-04 19:24:48.500063007 +0200
@@ -39,7 +39,7 @@ struct dib_fe_xfer_ops
 	int (*fifo_ctrl)(struct dvb_frontend *fe, int onoff);
 	int (*pid_ctrl)(struct dvb_frontend *fe, int index, int pid, int onoff);
 	int (*tuner_pass_ctrl)(struct dvb_frontend *fe, int onoff, u8 pll_ctrl);
-};
+} __no_const;
 
 #if defined(CONFIG_DVB_DIB3000MB) || (defined(CONFIG_DVB_DIB3000MB_MODULE) && defined(MODULE))
 extern struct dvb_frontend* dib3000mb_attach(const struct dib3000_config* config,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/dvb/ngene/ngene-cards.c linux-3.2.71-pax/drivers/media/dvb/ngene/ngene-cards.c
--- linux-3.2.71/drivers/media/dvb/ngene/ngene-cards.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/dvb/ngene/ngene-cards.c	2012-07-04 19:24:48.504063007 +0200
@@ -477,7 +477,7 @@ static struct ngene_info ngene_info_m780
 
 /****************************************************************************/
 
-static const struct pci_device_id ngene_id_tbl[] __devinitdata = {
+static const struct pci_device_id ngene_id_tbl[] __devinitconst = {
 	NGENE_ID(0x18c3, 0xabc3, ngene_info_cineS2),
 	NGENE_ID(0x18c3, 0xabc4, ngene_info_cineS2),
 	NGENE_ID(0x18c3, 0xdb01, ngene_info_satixS2),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/radio/radio-cadet.c linux-3.2.71-pax/drivers/media/radio/radio-cadet.c
--- linux-3.2.71/drivers/media/radio/radio-cadet.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/radio/radio-cadet.c	2012-07-04 19:24:48.504063007 +0200
@@ -326,6 +326,8 @@ static ssize_t cadet_read(struct file *f
 	unsigned char readbuf[RDS_BUFFER];
 	int i = 0;
 
+	if (count > RDS_BUFFER)
+		return -EFAULT;
 	mutex_lock(&dev->lock);
 	if (dev->rdsstat == 0) {
 		dev->rdsstat = 1;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/radio/wl128x/fmdrv_common.c linux-3.2.71-pax/drivers/media/radio/wl128x/fmdrv_common.c
--- linux-3.2.71/drivers/media/radio/wl128x/fmdrv_common.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/radio/wl128x/fmdrv_common.c	2015-02-20 11:22:52.465418006 +0100
@@ -71,7 +71,7 @@ module_param(default_rds_buf, uint, 0444
 MODULE_PARM_DESC(rds_buf, "RDS buffer entries");
 
 /* Radio Nr */
-static u32 radio_nr = -1;
+static int radio_nr = -1;
 module_param(radio_nr, int, 0444);
 MODULE_PARM_DESC(radio_nr, "Radio Nr");
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/rc/rc-main.c linux-3.2.71-pax/drivers/media/rc/rc-main.c
--- linux-3.2.71/drivers/media/rc/rc-main.c	2013-03-29 02:18:30.087676743 +0100
+++ linux-3.2.71-pax/drivers/media/rc/rc-main.c	2013-09-01 20:07:39.507819987 +0200
@@ -1031,7 +1031,7 @@ EXPORT_SYMBOL_GPL(rc_free_device);
 
 int rc_register_device(struct rc_dev *dev)
 {
-	static atomic_t devno = ATOMIC_INIT(0);
+	static atomic_unchecked_t devno = ATOMIC_INIT(0);
 	struct rc_map *rc_map;
 	const char *path;
 	int rc;
@@ -1063,7 +1063,7 @@ int rc_register_device(struct rc_dev *de
 	 */
 	mutex_lock(&dev->lock);
 
-	dev->devno = (unsigned long)(atomic_inc_return(&devno) - 1);
+	dev->devno = (unsigned long)(atomic_inc_return_unchecked(&devno) - 1);
 	dev_set_name(&dev->dev, "rc%ld", dev->devno);
 	dev_set_drvdata(&dev->dev, dev);
 	rc = device_add(&dev->dev);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/rc/redrat3.c linux-3.2.71-pax/drivers/media/rc/redrat3.c
--- linux-3.2.71/drivers/media/rc/redrat3.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/rc/redrat3.c	2012-07-04 19:24:48.504063007 +0200
@@ -905,7 +905,7 @@ static int redrat3_set_tx_carrier(struct
 	return carrier;
 }
 
-static int redrat3_transmit_ir(struct rc_dev *rcdev, int *txbuf, u32 n)
+static int redrat3_transmit_ir(struct rc_dev *rcdev, unsigned *txbuf, u32 n)
 {
 	struct redrat3_dev *rr3 = rcdev->priv;
 	struct device *dev = rr3->dev;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/video/cx88/cx88-alsa.c linux-3.2.71-pax/drivers/media/video/cx88/cx88-alsa.c
--- linux-3.2.71/drivers/media/video/cx88/cx88-alsa.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/video/cx88/cx88-alsa.c	2012-07-04 19:24:48.504063007 +0200
@@ -766,7 +766,7 @@ static struct snd_kcontrol_new snd_cx88_
  * Only boards with eeprom and byte 1 at eeprom=1 have it
  */
 
-static const struct pci_device_id const cx88_audio_pci_tbl[] __devinitdata = {
+static const struct pci_device_id const cx88_audio_pci_tbl[] __devinitconst = {
 	{0x14f1,0x8801,PCI_ANY_ID,PCI_ANY_ID,0,0,0},
 	{0x14f1,0x8811,PCI_ANY_ID,PCI_ANY_ID,0,0,0},
 	{0, }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/video/cx88/cx88-video.c linux-3.2.71-pax/drivers/media/video/cx88/cx88-video.c
--- linux-3.2.71/drivers/media/video/cx88/cx88-video.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/video/cx88/cx88-video.c	2013-04-03 23:43:03.816179968 +0200
@@ -49,9 +49,9 @@ MODULE_VERSION(CX88_VERSION);
 
 /* ------------------------------------------------------------------ */
 
-static unsigned int video_nr[] = {[0 ... (CX88_MAXBOARDS - 1)] = UNSET };
-static unsigned int vbi_nr[]   = {[0 ... (CX88_MAXBOARDS - 1)] = UNSET };
-static unsigned int radio_nr[] = {[0 ... (CX88_MAXBOARDS - 1)] = UNSET };
+static int video_nr[] = {[0 ... (CX88_MAXBOARDS - 1)] = UNSET };
+static int vbi_nr[]   = {[0 ... (CX88_MAXBOARDS - 1)] = UNSET };
+static int radio_nr[] = {[0 ... (CX88_MAXBOARDS - 1)] = UNSET };
 
 module_param_array(video_nr, int, NULL, 0444);
 module_param_array(vbi_nr,   int, NULL, 0444);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/video/ivtv/ivtv-driver.c linux-3.2.71-pax/drivers/media/video/ivtv/ivtv-driver.c
--- linux-3.2.71/drivers/media/video/ivtv/ivtv-driver.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/video/ivtv/ivtv-driver.c	2013-09-01 20:06:34.363823465 +0200
@@ -80,7 +80,7 @@ static struct pci_device_id ivtv_pci_tbl
 MODULE_DEVICE_TABLE(pci,ivtv_pci_tbl);
 
 /* ivtv instance counter */
-static atomic_t ivtv_instance = ATOMIC_INIT(0);
+static atomic_unchecked_t ivtv_instance = ATOMIC_INIT(0);
 
 /* Parameter declarations */
 static int cardtype[IVTV_MAX_CARDS];
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/video/omap/omap_vout.c linux-3.2.71-pax/drivers/media/video/omap/omap_vout.c
--- linux-3.2.71/drivers/media/video/omap/omap_vout.c	2013-03-29 02:18:30.091676743 +0100
+++ linux-3.2.71-pax/drivers/media/video/omap/omap_vout.c	2013-03-29 02:19:02.079675035 +0100
@@ -64,7 +64,6 @@ enum omap_vout_channels {
 	OMAP_VIDEO2,
 };
 
-static struct videobuf_queue_ops video_vbq_ops;
 /* Variables configurable through module params*/
 static u32 video1_numbuffers = 3;
 static u32 video2_numbuffers = 3;
@@ -1001,6 +1000,12 @@ static int omap_vout_open(struct file *f
 {
 	struct videobuf_queue *q;
 	struct omap_vout_device *vout = NULL;
+	static struct videobuf_queue_ops video_vbq_ops = {
+		.buf_setup = omap_vout_buffer_setup,
+		.buf_prepare = omap_vout_buffer_prepare,
+		.buf_release = omap_vout_buffer_release,
+		.buf_queue = omap_vout_buffer_queue,
+	};
 
 	vout = video_drvdata(file);
 	v4l2_dbg(1, debug, &vout->vid_dev->v4l2_dev, "Entering %s\n", __func__);
@@ -1018,10 +1023,6 @@ static int omap_vout_open(struct file *f
 	vout->type = V4L2_BUF_TYPE_VIDEO_OUTPUT;
 
 	q = &vout->vbq;
-	video_vbq_ops.buf_setup = omap_vout_buffer_setup;
-	video_vbq_ops.buf_prepare = omap_vout_buffer_prepare;
-	video_vbq_ops.buf_release = omap_vout_buffer_release;
-	video_vbq_ops.buf_queue = omap_vout_buffer_queue;
 	spin_lock_init(&vout->vbq_lock);
 
 	videobuf_queue_dma_contig_init(q, &video_vbq_ops, q->dev,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/video/timblogiw.c linux-3.2.71-pax/drivers/media/video/timblogiw.c
--- linux-3.2.71/drivers/media/video/timblogiw.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/video/timblogiw.c	2013-01-16 23:19:07.998681580 +0100
@@ -745,7 +745,7 @@ static int timblogiw_mmap(struct file *f
 
 /* Platform device functions */
 
-static __devinitconst struct v4l2_ioctl_ops timblogiw_ioctl_ops = {
+static struct v4l2_ioctl_ops timblogiw_ioctl_ops = {
 	.vidioc_querycap		= timblogiw_querycap,
 	.vidioc_enum_fmt_vid_cap	= timblogiw_enum_fmt,
 	.vidioc_g_fmt_vid_cap		= timblogiw_g_fmt,
@@ -767,7 +767,7 @@ static __devinitconst struct v4l2_ioctl_
 	.vidioc_enum_framesizes		= timblogiw_enum_framesizes,
 };
 
-static __devinitconst struct v4l2_file_operations timblogiw_fops = {
+static struct v4l2_file_operations timblogiw_fops = {
 	.owner		= THIS_MODULE,
 	.open		= timblogiw_open,
 	.release	= timblogiw_close,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/video/v4l2-compat-ioctl32.c linux-3.2.71-pax/drivers/media/video/v4l2-compat-ioctl32.c
--- linux-3.2.71/drivers/media/video/v4l2-compat-ioctl32.c	2014-06-10 10:59:38.766436244 +0200
+++ linux-3.2.71-pax/drivers/media/video/v4l2-compat-ioctl32.c	2014-06-10 10:59:44.150435956 +0200
@@ -334,7 +334,7 @@ struct v4l2_buffer32 {
 	__u32			reserved;
 };
 
-static int get_v4l2_plane32(struct v4l2_plane *up, struct v4l2_plane32 *up32,
+static int get_v4l2_plane32(struct v4l2_plane __user *up, struct v4l2_plane32 __user *up32,
 				enum v4l2_memory memory)
 {
 	void __user *up_pln;
@@ -360,7 +360,7 @@ static int get_v4l2_plane32(struct v4l2_
 	return 0;
 }
 
-static int put_v4l2_plane32(struct v4l2_plane *up, struct v4l2_plane32 *up32,
+static int put_v4l2_plane32(struct v4l2_plane __user *up, struct v4l2_plane32 __user *up32,
 				enum v4l2_memory memory)
 {
 	if (copy_in_user(up32, up, 2 * sizeof(__u32)) ||
@@ -426,7 +426,7 @@ static int get_v4l2_buffer32(struct v4l2
 		 * by passing a very big num_planes value */
 		uplane = compat_alloc_user_space(num_planes *
 						sizeof(struct v4l2_plane));
-		kp->m.planes = uplane;
+		kp->m.planes = (struct v4l2_plane __force_kernel *)uplane;
 
 		while (--num_planes >= 0) {
 			ret = get_v4l2_plane32(uplane, uplane32, kp->memory);
@@ -493,7 +493,7 @@ static int put_v4l2_buffer32(struct v4l2
 		if (num_planes == 0)
 			return 0;
 
-		uplane = kp->m.planes;
+		uplane = (struct v4l2_plane __force_user *)kp->m.planes;
 		if (get_user(p, &up->m.planes))
 			return -EFAULT;
 		uplane32 = compat_ptr(p);
@@ -543,7 +543,7 @@ static int get_v4l2_framebuffer32(struct
 		get_user(kp->capability, &up->capability) ||
 		get_user(kp->flags, &up->flags))
 			return -EFAULT;
-	kp->base = compat_ptr(tmp);
+	kp->base = (void __force_kernel *)compat_ptr(tmp);
 	get_v4l2_pix_format(&kp->fmt, &up->fmt);
 	return 0;
 }
@@ -649,7 +649,7 @@ static int get_v4l2_ext_controls32(struc
 			n * sizeof(struct v4l2_ext_control32)))
 		return -EFAULT;
 	kcontrols = compat_alloc_user_space(n * sizeof(struct v4l2_ext_control));
-	kp->controls = kcontrols;
+	kp->controls = (struct v4l2_ext_control __force_kernel *)kcontrols;
 	while (--n >= 0) {
 		if (copy_in_user(kcontrols, ucontrols, sizeof(*ucontrols)))
 			return -EFAULT;
@@ -671,7 +671,7 @@ static int get_v4l2_ext_controls32(struc
 static int put_v4l2_ext_controls32(struct v4l2_ext_controls *kp, struct v4l2_ext_controls32 __user *up)
 {
 	struct v4l2_ext_control32 __user *ucontrols;
-	struct v4l2_ext_control __user *kcontrols = kp->controls;
+	struct v4l2_ext_control __user *kcontrols = (struct v4l2_ext_control __force_user *)kp->controls;
 	int n = kp->count;
 	compat_caddr_t p;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/video/v4l2-ctrls.c linux-3.2.71-pax/drivers/media/video/v4l2-ctrls.c
--- linux-3.2.71/drivers/media/video/v4l2-ctrls.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/video/v4l2-ctrls.c	2014-01-28 03:55:24.421158847 +0100
@@ -1075,8 +1075,8 @@ static int validate_new(const struct v4l
 		return 0;
 
 	case V4L2_CTRL_TYPE_STRING:
-		len = strlen(s);
-		if (len < ctrl->minimum)
+		len = strlen_user(s);
+		if (!len || len < ctrl->minimum)
 			return -ERANGE;
 		if ((len - ctrl->minimum) % ctrl->step)
 			return -ERANGE;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/video/v4l2-device.c linux-3.2.71-pax/drivers/media/video/v4l2-device.c
--- linux-3.2.71/drivers/media/video/v4l2-device.c	2013-03-29 02:18:30.091676743 +0100
+++ linux-3.2.71-pax/drivers/media/video/v4l2-device.c	2013-09-01 20:05:00.263828490 +0200
@@ -74,9 +74,9 @@ int v4l2_device_put(struct v4l2_device *
 EXPORT_SYMBOL_GPL(v4l2_device_put);
 
 int v4l2_device_set_name(struct v4l2_device *v4l2_dev, const char *basename,
-						atomic_t *instance)
+						atomic_unchecked_t *instance)
 {
-	int num = atomic_inc_return(instance) - 1;
+	int num = atomic_inc_return_unchecked(instance) - 1;
 	int len = strlen(basename);
 
 	if (basename[len - 1] >= '0' && basename[len - 1] <= '9')
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/video/v4l2-ioctl.c linux-3.2.71-pax/drivers/media/video/v4l2-ioctl.c
--- linux-3.2.71/drivers/media/video/v4l2-ioctl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/video/v4l2-ioctl.c	2014-01-28 04:20:33.957078249 +0100
@@ -2197,7 +2197,7 @@ static unsigned long cmd_input_size(unsi
 }
 
 static int check_array_args(unsigned int cmd, void *parg, size_t *array_size,
-			    void * __user *user_ptr, void ***kernel_ptr)
+			    void __user **user_ptr, void ***kernel_ptr)
 {
 	int ret = 0;
 
@@ -2212,7 +2212,7 @@ static int check_array_args(unsigned int
 				ret = -EINVAL;
 				break;
 			}
-			*user_ptr = (void __user *)buf->m.planes;
+			*user_ptr = (void __force_user *)buf->m.planes;
 			*kernel_ptr = (void *)&buf->m.planes;
 			*array_size = sizeof(struct v4l2_plane) * buf->length;
 			ret = 1;
@@ -2230,7 +2230,7 @@ static int check_array_args(unsigned int
 				ret = -EINVAL;
 				break;
 			}
-			*user_ptr = (void __user *)ctrls->controls;
+			*user_ptr = (void __force_user *)ctrls->controls;
 			*kernel_ptr = (void *)&ctrls->controls;
 			*array_size = sizeof(struct v4l2_ext_control)
 				    * ctrls->count;
@@ -2312,7 +2312,7 @@ video_usercopy(struct file *file, unsign
 		err = -EINVAL;
 
 	if (has_array_args) {
-		*kernel_ptr = user_ptr;
+		*kernel_ptr = (void __force_kernel *)user_ptr;
 		if (copy_to_user(user_ptr, mbuf, array_size))
 			err = -EFAULT;
 		goto out_array_args;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/media/video/vivi.c linux-3.2.71-pax/drivers/media/video/vivi.c
--- linux-3.2.71/drivers/media/video/vivi.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/media/video/vivi.c	2014-01-16 02:57:52.238175942 +0100
@@ -51,8 +51,8 @@ MODULE_AUTHOR("Mauro Carvalho Chehab, Te
 MODULE_LICENSE("Dual BSD/GPL");
 MODULE_VERSION(VIVI_VERSION);
 
-static unsigned video_nr = -1;
-module_param(video_nr, uint, 0644);
+static int video_nr = -1;
+module_param(video_nr, int, 0644);
 MODULE_PARM_DESC(video_nr, "videoX start number, -1 is autodetect");
 
 static unsigned n_devs = 1;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/message/fusion/mptsas.c linux-3.2.71-pax/drivers/message/fusion/mptsas.c
--- linux-3.2.71/drivers/message/fusion/mptsas.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/message/fusion/mptsas.c	2012-07-04 19:24:48.512063007 +0200
@@ -446,6 +446,23 @@ mptsas_is_end_device(struct mptsas_devin
 		return 0;
 }
 
+static inline void
+mptsas_set_rphy(MPT_ADAPTER *ioc, struct mptsas_phyinfo *phy_info, struct sas_rphy *rphy)
+{
+	if (phy_info->port_details) {
+		phy_info->port_details->rphy = rphy;
+		dsaswideprintk(ioc, printk(MYIOC_s_DEBUG_FMT "sas_rphy_add: rphy=%p\n",
+		    ioc->name, rphy));
+	}
+
+	if (rphy) {
+		dsaswideprintk(ioc, dev_printk(KERN_DEBUG,
+		    &rphy->dev, MYIOC_s_FMT "add:", ioc->name));
+		dsaswideprintk(ioc, printk(MYIOC_s_DEBUG_FMT "rphy=%p release=%p\n",
+		    ioc->name, rphy, rphy->dev.release));
+	}
+}
+
 /* no mutex */
 static void
 mptsas_port_delete(MPT_ADAPTER *ioc, struct mptsas_portinfo_details * port_details)
@@ -484,23 +501,6 @@ mptsas_get_rphy(struct mptsas_phyinfo *p
 		return NULL;
 }
 
-static inline void
-mptsas_set_rphy(MPT_ADAPTER *ioc, struct mptsas_phyinfo *phy_info, struct sas_rphy *rphy)
-{
-	if (phy_info->port_details) {
-		phy_info->port_details->rphy = rphy;
-		dsaswideprintk(ioc, printk(MYIOC_s_DEBUG_FMT "sas_rphy_add: rphy=%p\n",
-		    ioc->name, rphy));
-	}
-
-	if (rphy) {
-		dsaswideprintk(ioc, dev_printk(KERN_DEBUG,
-		    &rphy->dev, MYIOC_s_FMT "add:", ioc->name));
-		dsaswideprintk(ioc, printk(MYIOC_s_DEBUG_FMT "rphy=%p release=%p\n",
-		    ioc->name, rphy, rphy->dev.release));
-	}
-}
-
 static inline struct sas_port *
 mptsas_get_port(struct mptsas_phyinfo *phy_info)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/message/fusion/mptscsih.c linux-3.2.71-pax/drivers/message/fusion/mptscsih.c
--- linux-3.2.71/drivers/message/fusion/mptscsih.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/message/fusion/mptscsih.c	2012-07-04 19:24:48.512063007 +0200
@@ -1270,15 +1270,16 @@ mptscsih_info(struct Scsi_Host *SChost)
 
 	h = shost_priv(SChost);
 
-	if (h) {
-		if (h->info_kbuf == NULL)
-			if ((h->info_kbuf = kmalloc(0x1000 /* 4Kb */, GFP_KERNEL)) == NULL)
-				return h->info_kbuf;
-		h->info_kbuf[0] = '\0';
+	if (!h)
+		return NULL;
 
-		mpt_print_ioc_summary(h->ioc, h->info_kbuf, &size, 0, 0);
-		h->info_kbuf[size-1] = '\0';
-	}
+	if (h->info_kbuf == NULL)
+		if ((h->info_kbuf = kmalloc(0x1000 /* 4Kb */, GFP_KERNEL)) == NULL)
+			return h->info_kbuf;
+	h->info_kbuf[0] = '\0';
+
+	mpt_print_ioc_summary(h->ioc, h->info_kbuf, &size, 0, 0);
+	h->info_kbuf[size-1] = '\0';
 
 	return h->info_kbuf;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/message/i2o/i2o_proc.c linux-3.2.71-pax/drivers/message/i2o/i2o_proc.c
--- linux-3.2.71/drivers/message/i2o/i2o_proc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/message/i2o/i2o_proc.c	2013-11-12 01:24:47.197411853 +0100
@@ -255,13 +255,6 @@ static char *scsi_devices[] = {
 	"Array Controller Device"
 };
 
-static char *chtostr(u8 * chars, int n)
-{
-	char tmp[256];
-	tmp[0] = 0;
-	return strncat(tmp, (char *)chars, n);
-}
-
 static int i2o_report_query_status(struct seq_file *seq, int block_status,
 				   char *group)
 {
@@ -721,9 +714,9 @@ static int i2o_seq_show_status(struct se
 static int i2o_seq_show_hw(struct seq_file *seq, void *v)
 {
 	struct i2o_controller *c = (struct i2o_controller *)seq->private;
-	static u32 work32[5];
-	static u8 *work8 = (u8 *) work32;
-	static u16 *work16 = (u16 *) work32;
+	u32 work32[5];
+	u8 *work8 = (u8 *) work32;
+	u16 *work16 = (u16 *) work32;
 	int token;
 	u32 hwcap;
 
@@ -838,8 +831,7 @@ static int i2o_seq_show_ddm_table(struct
 
 		seq_printf(seq, "%-#7x", ddm_table.i2o_vendor_id);
 		seq_printf(seq, "%-#8x", ddm_table.module_id);
-		seq_printf(seq, "%-29s",
-			   chtostr(ddm_table.module_name_version, 28));
+		seq_printf(seq, "%-.28s", ddm_table.module_name_version);
 		seq_printf(seq, "%9d  ", ddm_table.data_size);
 		seq_printf(seq, "%8d", ddm_table.code_size);
 
@@ -940,8 +932,8 @@ static int i2o_seq_show_drivers_stored(s
 
 		seq_printf(seq, "%-#7x", dst->i2o_vendor_id);
 		seq_printf(seq, "%-#8x", dst->module_id);
-		seq_printf(seq, "%-29s", chtostr(dst->module_name_version, 28));
-		seq_printf(seq, "%-9s", chtostr(dst->date, 8));
+		seq_printf(seq, "%-.28s", dst->module_name_version);
+		seq_printf(seq, "%-.8s", dst->date);
 		seq_printf(seq, "%8d ", dst->module_size);
 		seq_printf(seq, "%8d ", dst->mpb_size);
 		seq_printf(seq, "0x%04x", dst->module_flags);
@@ -1257,9 +1249,9 @@ static int i2o_seq_show_authorized_users
 static int i2o_seq_show_dev_identity(struct seq_file *seq, void *v)
 {
 	struct i2o_device *d = (struct i2o_device *)seq->private;
-	static u32 work32[128];	// allow for "stuff" + up to 256 byte (max) serial number
+	u32 work32[128];	// allow for "stuff" + up to 256 byte (max) serial number
 	// == (allow) 512d bytes (max)
-	static u16 *work16 = (u16 *) work32;
+	u16 *work16 = (u16 *) work32;
 	int token;
 
 	token = i2o_parm_field_get(d, 0xF100, -1, &work32, sizeof(work32));
@@ -1272,14 +1264,10 @@ static int i2o_seq_show_dev_identity(str
 	seq_printf(seq, "Device Class  : %s\n", i2o_get_class_name(work16[0]));
 	seq_printf(seq, "Owner TID     : %0#5x\n", work16[2]);
 	seq_printf(seq, "Parent TID    : %0#5x\n", work16[3]);
-	seq_printf(seq, "Vendor info   : %s\n",
-		   chtostr((u8 *) (work32 + 2), 16));
-	seq_printf(seq, "Product info  : %s\n",
-		   chtostr((u8 *) (work32 + 6), 16));
-	seq_printf(seq, "Description   : %s\n",
-		   chtostr((u8 *) (work32 + 10), 16));
-	seq_printf(seq, "Product rev.  : %s\n",
-		   chtostr((u8 *) (work32 + 14), 8));
+	seq_printf(seq, "Vendor info   : %.16s\n", (u8 *) (work32 + 2));
+	seq_printf(seq, "Product info  : %.16s\n", (u8 *) (work32 + 6));
+	seq_printf(seq, "Description   : %.16s\n", (u8 *) (work32 + 10));
+	seq_printf(seq, "Product rev.  : %.8s\n", (u8 *) (work32 + 14));
 
 	seq_printf(seq, "Serial number : ");
 	print_serial_number(seq, (u8 *) (work32 + 16),
@@ -1324,10 +1312,8 @@ static int i2o_seq_show_ddm_identity(str
 	}
 
 	seq_printf(seq, "Registering DDM TID : 0x%03x\n", result.ddm_tid);
-	seq_printf(seq, "Module name         : %s\n",
-		   chtostr(result.module_name, 24));
-	seq_printf(seq, "Module revision     : %s\n",
-		   chtostr(result.module_rev, 8));
+	seq_printf(seq, "Module name         : %.24s\n", result.module_name);
+	seq_printf(seq, "Module revision     : %.8s\n", result.module_rev);
 
 	seq_printf(seq, "Serial number       : ");
 	print_serial_number(seq, result.serial_number, sizeof(result) - 36);
@@ -1358,14 +1344,10 @@ static int i2o_seq_show_uinfo(struct seq
 		return 0;
 	}
 
-	seq_printf(seq, "Device name     : %s\n",
-		   chtostr(result.device_name, 64));
-	seq_printf(seq, "Service name    : %s\n",
-		   chtostr(result.service_name, 64));
-	seq_printf(seq, "Physical name   : %s\n",
-		   chtostr(result.physical_location, 64));
-	seq_printf(seq, "Instance number : %s\n",
-		   chtostr(result.instance_number, 4));
+	seq_printf(seq, "Device name     : %.64s\n", result.device_name);
+	seq_printf(seq, "Service name    : %.64s\n", result.service_name);
+	seq_printf(seq, "Physical name   : %.64s\n", result.physical_location);
+	seq_printf(seq, "Instance number : %.4s\n", result.instance_number);
 
 	return 0;
 }
@@ -1374,9 +1356,9 @@ static int i2o_seq_show_uinfo(struct seq
 static int i2o_seq_show_sgl_limits(struct seq_file *seq, void *v)
 {
 	struct i2o_device *d = (struct i2o_device *)seq->private;
-	static u32 work32[12];
-	static u16 *work16 = (u16 *) work32;
-	static u8 *work8 = (u8 *) work32;
+	u32 work32[12];
+	u16 *work16 = (u16 *) work32;
+	u8 *work8 = (u8 *) work32;
 	int token;
 
 	token = i2o_parm_field_get(d, 0xF103, -1, &work32, sizeof(work32));
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/message/i2o/iop.c linux-3.2.71-pax/drivers/message/i2o/iop.c
--- linux-3.2.71/drivers/message/i2o/iop.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/message/i2o/iop.c	2012-07-04 19:24:48.516063007 +0200
@@ -111,10 +111,10 @@ u32 i2o_cntxt_list_add(struct i2o_contro
 
 	spin_lock_irqsave(&c->context_list_lock, flags);
 
-	if (unlikely(atomic_inc_and_test(&c->context_list_counter)))
-		atomic_inc(&c->context_list_counter);
+	if (unlikely(atomic_inc_and_test_unchecked(&c->context_list_counter)))
+		atomic_inc_unchecked(&c->context_list_counter);
 
-	entry->context = atomic_read(&c->context_list_counter);
+	entry->context = atomic_read_unchecked(&c->context_list_counter);
 
 	list_add(&entry->list, &c->context_list);
 
@@ -1077,7 +1077,7 @@ struct i2o_controller *i2o_iop_alloc(voi
 
 #if BITS_PER_LONG == 64
 	spin_lock_init(&c->context_list_lock);
-	atomic_set(&c->context_list_counter, 0);
+	atomic_set_unchecked(&c->context_list_counter, 0);
 	INIT_LIST_HEAD(&c->context_list);
 #endif
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/mfd/max8925-i2c.c linux-3.2.71-pax/drivers/mfd/max8925-i2c.c
--- linux-3.2.71/drivers/mfd/max8925-i2c.c	2014-04-30 18:53:45.596223430 +0200
+++ linux-3.2.71-pax/drivers/mfd/max8925-i2c.c	2014-04-30 18:53:50.444223420 +0200
@@ -139,7 +139,7 @@ static int __devinit max8925_probe(struc
 				   const struct i2c_device_id *id)
 {
 	struct max8925_platform_data *pdata = client->dev.platform_data;
-	static struct max8925_chip *chip;
+	struct max8925_chip *chip;
 
 	if (!pdata) {
 		pr_info("%s: platform data is missing\n", __func__);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/mfd/mfd-core.c linux-3.2.71-pax/drivers/mfd/mfd-core.c
--- linux-3.2.71/drivers/mfd/mfd-core.c	2013-01-03 19:05:13.348036821 +0100
+++ linux-3.2.71-pax/drivers/mfd/mfd-core.c	2013-02-04 02:52:59.604237963 +0100
@@ -167,7 +167,7 @@ int mfd_add_devices(struct device *paren
 	atomic_t *cnts;
 
 	/* initialize reference counting for all cells */
-	cnts = kcalloc(sizeof(*cnts), n_devs, GFP_KERNEL);
+	cnts = kcalloc(n_devs, sizeof(*cnts), GFP_KERNEL);
 	if (!cnts)
 		return -ENOMEM;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/mfd/twl4030-irq.c linux-3.2.71-pax/drivers/mfd/twl4030-irq.c
--- linux-3.2.71/drivers/mfd/twl4030-irq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/mfd/twl4030-irq.c	2013-03-28 03:26:29.748072011 +0100
@@ -33,6 +33,7 @@
 #include <linux/slab.h>
 
 #include <linux/i2c/twl.h>
+#include <asm/pgtable.h>
 
 #include "twl-core.h"
 
@@ -713,10 +714,12 @@ int twl4030_init_irq(int irq_num, unsign
 	/* install an irq handler for each of the SIH modules;
 	 * clone dummy irq_chip since PIH can't *do* anything
 	 */
-	twl4030_irq_chip = dummy_irq_chip;
-	twl4030_irq_chip.name = "twl4030";
+	pax_open_kernel();
+	memcpy((void *)&twl4030_irq_chip, &dummy_irq_chip, sizeof twl4030_irq_chip);
+	*(const char **)&twl4030_irq_chip.name = "twl4030";
 
-	twl4030_sih_irq_chip.irq_ack = dummy_irq_chip.irq_ack;
+	*(void **)&twl4030_sih_irq_chip.irq_ack = dummy_irq_chip.irq_ack;
+	pax_close_kernel();
 
 	for (i = irq_base; i < irq_end; i++) {
 		irq_set_chip_and_handler(i, &twl4030_irq_chip,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/mfd/twl6030-irq.c linux-3.2.71-pax/drivers/mfd/twl6030-irq.c
--- linux-3.2.71/drivers/mfd/twl6030-irq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/mfd/twl6030-irq.c	2013-03-28 03:27:29.348068829 +0100
@@ -376,10 +376,12 @@ int twl6030_init_irq(int irq_num, unsign
 	/* install an irq handler for each of the modules;
 	 * clone dummy irq_chip since PIH can't *do* anything
 	 */
-	twl6030_irq_chip = dummy_irq_chip;
-	twl6030_irq_chip.name = "twl6030";
-	twl6030_irq_chip.irq_set_type = NULL;
-	twl6030_irq_chip.irq_set_wake = twl6030_irq_set_wake;
+	pax_open_kernel();
+	memcpy((void *)&twl6030_irq_chip, &dummy_irq_chip, sizeof twl6030_irq_chip);
+	*(const char **)&twl6030_irq_chip.name = "twl6030";
+	*(void **)&twl6030_irq_chip.irq_set_type = NULL;
+	*(void **)&twl6030_irq_chip.irq_set_wake = twl6030_irq_set_wake;
+	pax_close_kernel();
 
 	for (i = irq_base; i < irq_end; i++) {
 		irq_set_chip_and_handler(i, &twl6030_irq_chip,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/misc/c2port/core.c linux-3.2.71-pax/drivers/misc/c2port/core.c
--- linux-3.2.71/drivers/misc/c2port/core.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/misc/c2port/core.c	2013-03-28 01:35:23.284427949 +0100
@@ -924,7 +924,9 @@ struct c2port_device *c2port_device_regi
 	mutex_init(&c2dev->mutex);
 
 	/* Create binary file */
-	c2port_bin_attrs.size = ops->blocks_num * ops->block_size;
+	pax_open_kernel();
+	*(size_t *)&c2port_bin_attrs.size = ops->blocks_num * ops->block_size;
+	pax_close_kernel();
 	ret = device_create_bin_file(c2dev->dev, &c2port_bin_attrs);
 	if (unlikely(ret))
 		goto error_device_create_bin_file;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/misc/kgdbts.c linux-3.2.71-pax/drivers/misc/kgdbts.c
--- linux-3.2.71/drivers/misc/kgdbts.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/misc/kgdbts.c	2012-12-14 19:33:32.717556908 +0100
@@ -832,7 +832,7 @@ static void run_plant_and_detach_test(in
 	char before[BREAK_INSTR_SIZE];
 	char after[BREAK_INSTR_SIZE];
 
-	probe_kernel_read(before, (char *)kgdbts_break_test,
+	probe_kernel_read(before, ktla_ktva((char *)kgdbts_break_test),
 	  BREAK_INSTR_SIZE);
 	init_simple_test();
 	ts.tst = plant_and_detach_test;
@@ -840,7 +840,7 @@ static void run_plant_and_detach_test(in
 	/* Activate test with initial breakpoint */
 	if (!is_early)
 		kgdb_breakpoint();
-	probe_kernel_read(after, (char *)kgdbts_break_test,
+	probe_kernel_read(after, ktla_ktva((char *)kgdbts_break_test),
 	  BREAK_INSTR_SIZE);
 	if (memcmp(before, after, BREAK_INSTR_SIZE)) {
 		printk(KERN_CRIT "kgdbts: ERROR kgdb corrupted memory\n");
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/misc/lis3lv02d/lis3lv02d.c linux-3.2.71-pax/drivers/misc/lis3lv02d/lis3lv02d.c
--- linux-3.2.71/drivers/misc/lis3lv02d/lis3lv02d.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/misc/lis3lv02d/lis3lv02d.c	2012-07-04 19:24:48.520063007 +0200
@@ -464,7 +464,7 @@ static irqreturn_t lis302dl_interrupt(in
 	 * the lid is closed. This leads to interrupts as soon as a little move
 	 * is done.
 	 */
-	atomic_inc(&lis3->count);
+	atomic_inc_unchecked(&lis3->count);
 
 	wake_up_interruptible(&lis3->misc_wait);
 	kill_fasync(&lis3->async_queue, SIGIO, POLL_IN);
@@ -550,7 +550,7 @@ static int lis3lv02d_misc_open(struct in
 	if (lis3->pm_dev)
 		pm_runtime_get_sync(lis3->pm_dev);
 
-	atomic_set(&lis3->count, 0);
+	atomic_set_unchecked(&lis3->count, 0);
 	return 0;
 }
 
@@ -583,7 +583,7 @@ static ssize_t lis3lv02d_misc_read(struc
 	add_wait_queue(&lis3->misc_wait, &wait);
 	while (true) {
 		set_current_state(TASK_INTERRUPTIBLE);
-		data = atomic_xchg(&lis3->count, 0);
+		data = atomic_xchg_unchecked(&lis3->count, 0);
 		if (data)
 			break;
 
@@ -624,7 +624,7 @@ static unsigned int lis3lv02d_misc_poll(
 					      struct lis3lv02d, miscdev);
 
 	poll_wait(file, &lis3->misc_wait, wait);
-	if (atomic_read(&lis3->count))
+	if (atomic_read_unchecked(&lis3->count))
 		return POLLIN | POLLRDNORM;
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/misc/lis3lv02d/lis3lv02d.h linux-3.2.71-pax/drivers/misc/lis3lv02d/lis3lv02d.h
--- linux-3.2.71/drivers/misc/lis3lv02d/lis3lv02d.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/misc/lis3lv02d/lis3lv02d.h	2012-07-04 19:24:48.520063007 +0200
@@ -266,7 +266,7 @@ struct lis3lv02d {
 	struct input_polled_dev	*idev;     /* input device */
 	struct platform_device	*pdev;     /* platform device */
 	struct regulator_bulk_data regulators[2];
-	atomic_t		count;     /* interrupt count after last read */
+	atomic_unchecked_t	count;     /* interrupt count after last read */
 	union axis_conversion	ac;        /* hw -> logical axis */
 	int			mapped_btns[3];
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/misc/sgi-gru/gruhandles.c linux-3.2.71-pax/drivers/misc/sgi-gru/gruhandles.c
--- linux-3.2.71/drivers/misc/sgi-gru/gruhandles.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/misc/sgi-gru/gruhandles.c	2012-07-04 19:24:48.520063007 +0200
@@ -44,8 +44,8 @@ static void update_mcs_stats(enum mcs_op
 	unsigned long nsec;
 
 	nsec = CLKS2NSEC(clks);
-	atomic_long_inc(&mcs_op_statistics[op].count);
-	atomic_long_add(nsec, &mcs_op_statistics[op].total);
+	atomic_long_inc_unchecked(&mcs_op_statistics[op].count);
+	atomic_long_add_unchecked(nsec, &mcs_op_statistics[op].total);
 	if (mcs_op_statistics[op].max < nsec)
 		mcs_op_statistics[op].max = nsec;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/misc/sgi-gru/gruprocfs.c linux-3.2.71-pax/drivers/misc/sgi-gru/gruprocfs.c
--- linux-3.2.71/drivers/misc/sgi-gru/gruprocfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/misc/sgi-gru/gruprocfs.c	2012-07-04 19:24:48.520063007 +0200
@@ -32,9 +32,9 @@
 
 #define printstat(s, f)		printstat_val(s, &gru_stats.f, #f)
 
-static void printstat_val(struct seq_file *s, atomic_long_t *v, char *id)
+static void printstat_val(struct seq_file *s, atomic_long_unchecked_t *v, char *id)
 {
-	unsigned long val = atomic_long_read(v);
+	unsigned long val = atomic_long_read_unchecked(v);
 
 	seq_printf(s, "%16lu %s\n", val, id);
 }
@@ -134,8 +134,8 @@ static int mcs_statistics_show(struct se
 
 	seq_printf(s, "%-20s%12s%12s%12s\n", "#id", "count", "aver-clks", "max-clks");
 	for (op = 0; op < mcsop_last; op++) {
-		count = atomic_long_read(&mcs_op_statistics[op].count);
-		total = atomic_long_read(&mcs_op_statistics[op].total);
+		count = atomic_long_read_unchecked(&mcs_op_statistics[op].count);
+		total = atomic_long_read_unchecked(&mcs_op_statistics[op].total);
 		max = mcs_op_statistics[op].max;
 		seq_printf(s, "%-20s%12ld%12ld%12ld\n", id[op], count,
 			   count ? total / count : 0, max);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/misc/sgi-gru/grutables.h linux-3.2.71-pax/drivers/misc/sgi-gru/grutables.h
--- linux-3.2.71/drivers/misc/sgi-gru/grutables.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/misc/sgi-gru/grutables.h	2012-07-04 19:24:48.520063007 +0200
@@ -167,82 +167,82 @@ extern unsigned int gru_max_gids;
  * GRU statistics.
  */
 struct gru_stats_s {
-	atomic_long_t vdata_alloc;
-	atomic_long_t vdata_free;
-	atomic_long_t gts_alloc;
-	atomic_long_t gts_free;
-	atomic_long_t gms_alloc;
-	atomic_long_t gms_free;
-	atomic_long_t gts_double_allocate;
-	atomic_long_t assign_context;
-	atomic_long_t assign_context_failed;
-	atomic_long_t free_context;
-	atomic_long_t load_user_context;
-	atomic_long_t load_kernel_context;
-	atomic_long_t lock_kernel_context;
-	atomic_long_t unlock_kernel_context;
-	atomic_long_t steal_user_context;
-	atomic_long_t steal_kernel_context;
-	atomic_long_t steal_context_failed;
-	atomic_long_t nopfn;
-	atomic_long_t asid_new;
-	atomic_long_t asid_next;
-	atomic_long_t asid_wrap;
-	atomic_long_t asid_reuse;
-	atomic_long_t intr;
-	atomic_long_t intr_cbr;
-	atomic_long_t intr_tfh;
-	atomic_long_t intr_spurious;
-	atomic_long_t intr_mm_lock_failed;
-	atomic_long_t call_os;
-	atomic_long_t call_os_wait_queue;
-	atomic_long_t user_flush_tlb;
-	atomic_long_t user_unload_context;
-	atomic_long_t user_exception;
-	atomic_long_t set_context_option;
-	atomic_long_t check_context_retarget_intr;
-	atomic_long_t check_context_unload;
-	atomic_long_t tlb_dropin;
-	atomic_long_t tlb_preload_page;
-	atomic_long_t tlb_dropin_fail_no_asid;
-	atomic_long_t tlb_dropin_fail_upm;
-	atomic_long_t tlb_dropin_fail_invalid;
-	atomic_long_t tlb_dropin_fail_range_active;
-	atomic_long_t tlb_dropin_fail_idle;
-	atomic_long_t tlb_dropin_fail_fmm;
-	atomic_long_t tlb_dropin_fail_no_exception;
-	atomic_long_t tfh_stale_on_fault;
-	atomic_long_t mmu_invalidate_range;
-	atomic_long_t mmu_invalidate_page;
-	atomic_long_t flush_tlb;
-	atomic_long_t flush_tlb_gru;
-	atomic_long_t flush_tlb_gru_tgh;
-	atomic_long_t flush_tlb_gru_zero_asid;
-
-	atomic_long_t copy_gpa;
-	atomic_long_t read_gpa;
-
-	atomic_long_t mesq_receive;
-	atomic_long_t mesq_receive_none;
-	atomic_long_t mesq_send;
-	atomic_long_t mesq_send_failed;
-	atomic_long_t mesq_noop;
-	atomic_long_t mesq_send_unexpected_error;
-	atomic_long_t mesq_send_lb_overflow;
-	atomic_long_t mesq_send_qlimit_reached;
-	atomic_long_t mesq_send_amo_nacked;
-	atomic_long_t mesq_send_put_nacked;
-	atomic_long_t mesq_page_overflow;
-	atomic_long_t mesq_qf_locked;
-	atomic_long_t mesq_qf_noop_not_full;
-	atomic_long_t mesq_qf_switch_head_failed;
-	atomic_long_t mesq_qf_unexpected_error;
-	atomic_long_t mesq_noop_unexpected_error;
-	atomic_long_t mesq_noop_lb_overflow;
-	atomic_long_t mesq_noop_qlimit_reached;
-	atomic_long_t mesq_noop_amo_nacked;
-	atomic_long_t mesq_noop_put_nacked;
-	atomic_long_t mesq_noop_page_overflow;
+	atomic_long_unchecked_t vdata_alloc;
+	atomic_long_unchecked_t vdata_free;
+	atomic_long_unchecked_t gts_alloc;
+	atomic_long_unchecked_t gts_free;
+	atomic_long_unchecked_t gms_alloc;
+	atomic_long_unchecked_t gms_free;
+	atomic_long_unchecked_t gts_double_allocate;
+	atomic_long_unchecked_t assign_context;
+	atomic_long_unchecked_t assign_context_failed;
+	atomic_long_unchecked_t free_context;
+	atomic_long_unchecked_t load_user_context;
+	atomic_long_unchecked_t load_kernel_context;
+	atomic_long_unchecked_t lock_kernel_context;
+	atomic_long_unchecked_t unlock_kernel_context;
+	atomic_long_unchecked_t steal_user_context;
+	atomic_long_unchecked_t steal_kernel_context;
+	atomic_long_unchecked_t steal_context_failed;
+	atomic_long_unchecked_t nopfn;
+	atomic_long_unchecked_t asid_new;
+	atomic_long_unchecked_t asid_next;
+	atomic_long_unchecked_t asid_wrap;
+	atomic_long_unchecked_t asid_reuse;
+	atomic_long_unchecked_t intr;
+	atomic_long_unchecked_t intr_cbr;
+	atomic_long_unchecked_t intr_tfh;
+	atomic_long_unchecked_t intr_spurious;
+	atomic_long_unchecked_t intr_mm_lock_failed;
+	atomic_long_unchecked_t call_os;
+	atomic_long_unchecked_t call_os_wait_queue;
+	atomic_long_unchecked_t user_flush_tlb;
+	atomic_long_unchecked_t user_unload_context;
+	atomic_long_unchecked_t user_exception;
+	atomic_long_unchecked_t set_context_option;
+	atomic_long_unchecked_t check_context_retarget_intr;
+	atomic_long_unchecked_t check_context_unload;
+	atomic_long_unchecked_t tlb_dropin;
+	atomic_long_unchecked_t tlb_preload_page;
+	atomic_long_unchecked_t tlb_dropin_fail_no_asid;
+	atomic_long_unchecked_t tlb_dropin_fail_upm;
+	atomic_long_unchecked_t tlb_dropin_fail_invalid;
+	atomic_long_unchecked_t tlb_dropin_fail_range_active;
+	atomic_long_unchecked_t tlb_dropin_fail_idle;
+	atomic_long_unchecked_t tlb_dropin_fail_fmm;
+	atomic_long_unchecked_t tlb_dropin_fail_no_exception;
+	atomic_long_unchecked_t tfh_stale_on_fault;
+	atomic_long_unchecked_t mmu_invalidate_range;
+	atomic_long_unchecked_t mmu_invalidate_page;
+	atomic_long_unchecked_t flush_tlb;
+	atomic_long_unchecked_t flush_tlb_gru;
+	atomic_long_unchecked_t flush_tlb_gru_tgh;
+	atomic_long_unchecked_t flush_tlb_gru_zero_asid;
+
+	atomic_long_unchecked_t copy_gpa;
+	atomic_long_unchecked_t read_gpa;
+
+	atomic_long_unchecked_t mesq_receive;
+	atomic_long_unchecked_t mesq_receive_none;
+	atomic_long_unchecked_t mesq_send;
+	atomic_long_unchecked_t mesq_send_failed;
+	atomic_long_unchecked_t mesq_noop;
+	atomic_long_unchecked_t mesq_send_unexpected_error;
+	atomic_long_unchecked_t mesq_send_lb_overflow;
+	atomic_long_unchecked_t mesq_send_qlimit_reached;
+	atomic_long_unchecked_t mesq_send_amo_nacked;
+	atomic_long_unchecked_t mesq_send_put_nacked;
+	atomic_long_unchecked_t mesq_page_overflow;
+	atomic_long_unchecked_t mesq_qf_locked;
+	atomic_long_unchecked_t mesq_qf_noop_not_full;
+	atomic_long_unchecked_t mesq_qf_switch_head_failed;
+	atomic_long_unchecked_t mesq_qf_unexpected_error;
+	atomic_long_unchecked_t mesq_noop_unexpected_error;
+	atomic_long_unchecked_t mesq_noop_lb_overflow;
+	atomic_long_unchecked_t mesq_noop_qlimit_reached;
+	atomic_long_unchecked_t mesq_noop_amo_nacked;
+	atomic_long_unchecked_t mesq_noop_put_nacked;
+	atomic_long_unchecked_t mesq_noop_page_overflow;
 
 };
 
@@ -251,8 +251,8 @@ enum mcs_op {cchop_allocate, cchop_start
 	tghop_invalidate, mcsop_last};
 
 struct mcs_op_statistic {
-	atomic_long_t	count;
-	atomic_long_t	total;
+	atomic_long_unchecked_t	count;
+	atomic_long_unchecked_t	total;
 	unsigned long	max;
 };
 
@@ -275,7 +275,7 @@ extern struct mcs_op_statistic mcs_op_st
 
 #define STAT(id)	do {						\
 				if (gru_options & OPT_STATS)		\
-					atomic_long_inc(&gru_stats.id);	\
+					atomic_long_inc_unchecked(&gru_stats.id);	\
 			} while (0)
 
 #ifdef CONFIG_SGI_GRU_DEBUG
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/misc/sgi-xp/xpc.h linux-3.2.71-pax/drivers/misc/sgi-xp/xpc.h
--- linux-3.2.71/drivers/misc/sgi-xp/xpc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/misc/sgi-xp/xpc.h	2012-07-04 19:24:48.520063007 +0200
@@ -835,6 +835,7 @@ struct xpc_arch_operations {
 	void (*received_payload) (struct xpc_channel *, void *);
 	void (*notify_senders_of_disconnect) (struct xpc_channel *);
 };
+typedef struct xpc_arch_operations __no_const xpc_arch_operations_no_const;
 
 /* struct xpc_partition act_state values (for XPC HB) */
 
@@ -876,7 +877,7 @@ extern struct xpc_registration xpc_regis
 /* found in xpc_main.c */
 extern struct device *xpc_part;
 extern struct device *xpc_chan;
-extern struct xpc_arch_operations xpc_arch_ops;
+extern xpc_arch_operations_no_const xpc_arch_ops;
 extern int xpc_disengage_timelimit;
 extern int xpc_disengage_timedout;
 extern int xpc_activate_IRQ_rcvd;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/misc/sgi-xp/xpc_main.c linux-3.2.71-pax/drivers/misc/sgi-xp/xpc_main.c
--- linux-3.2.71/drivers/misc/sgi-xp/xpc_main.c	2013-01-03 19:05:13.356036821 +0100
+++ linux-3.2.71-pax/drivers/misc/sgi-xp/xpc_main.c	2013-02-04 03:03:27.204204454 +0100
@@ -166,7 +166,7 @@ static struct notifier_block xpc_die_not
 	.notifier_call = xpc_system_die,
 };
 
-struct xpc_arch_operations xpc_arch_ops;
+xpc_arch_operations_no_const xpc_arch_ops;
 
 /*
  * Timer function to enforce the timelimit on the partition disengage.
@@ -1210,7 +1210,7 @@ xpc_system_die(struct notifier_block *nb
 
 		if (((die_args->trapnr == X86_TRAP_MF) ||
 		     (die_args->trapnr == X86_TRAP_XF)) &&
-		    !user_mode_vm(die_args->regs))
+		    !user_mode(die_args->regs))
 			xpc_die_deactivate();
 
 		break;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/misc/sgi-xp/xp.h linux-3.2.71-pax/drivers/misc/sgi-xp/xp.h
--- linux-3.2.71/drivers/misc/sgi-xp/xp.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/misc/sgi-xp/xp.h	2012-07-04 19:24:48.524063007 +0200
@@ -289,7 +289,7 @@ struct xpc_interface {
 					xpc_notify_func, void *);
 	void (*received) (short, int, void *);
 	enum xp_retval (*partid_to_nasids) (short, void *);
-};
+} __no_const;
 
 extern struct xpc_interface xpc_interface;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/mmc/card/block.c linux-3.2.71-pax/drivers/mmc/card/block.c
--- linux-3.2.71/drivers/mmc/card/block.c	2015-08-14 21:48:35.168707920 +0200
+++ linux-3.2.71-pax/drivers/mmc/card/block.c	2015-08-14 21:48:45.588707364 +0200
@@ -399,7 +399,7 @@ static int mmc_blk_ioctl_cmd(struct bloc
 	if (idata->ic.postsleep_min_us)
 		usleep_range(idata->ic.postsleep_min_us, idata->ic.postsleep_max_us);
 
-	if (copy_to_user(&(ic_ptr->response), cmd.resp, sizeof(cmd.resp))) {
+	if (copy_to_user(ic_ptr->response, cmd.resp, sizeof(cmd.resp))) {
 		err = -EFAULT;
 		goto cmd_rel_host;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/mmc/host/sdhci-pci.c linux-3.2.71-pax/drivers/mmc/host/sdhci-pci.c
--- linux-3.2.71/drivers/mmc/host/sdhci-pci.c	2012-08-03 01:53:47.266140443 +0200
+++ linux-3.2.71-pax/drivers/mmc/host/sdhci-pci.c	2012-08-03 01:53:52.762140150 +0200
@@ -674,7 +674,7 @@ static const struct sdhci_pci_fixes sdhc
 	.probe		= via_probe,
 };
 
-static const struct pci_device_id pci_ids[] __devinitdata = {
+static const struct pci_device_id pci_ids[] __devinitconst = {
 	{
 		.vendor		= PCI_VENDOR_ID_RICOH,
 		.device		= PCI_DEVICE_ID_RICOH_R5C822,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/mtd/chips/cfi_cmdset_0020.c linux-3.2.71-pax/drivers/mtd/chips/cfi_cmdset_0020.c
--- linux-3.2.71/drivers/mtd/chips/cfi_cmdset_0020.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/mtd/chips/cfi_cmdset_0020.c	2013-11-12 01:27:23.781403493 +0100
@@ -674,7 +674,7 @@ cfi_staa_writev(struct mtd_info *mtd, co
 	size_t	 totlen = 0, thislen;
 	int	 ret = 0;
 	size_t	 buflen = 0;
-	static char *buffer;
+	char *buffer;
 
 	if (!ECCBUF_SIZE) {
 		/* We should fall back to a general writev implementation.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/mtd/devices/doc2000.c linux-3.2.71-pax/drivers/mtd/devices/doc2000.c
--- linux-3.2.71/drivers/mtd/devices/doc2000.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/mtd/devices/doc2000.c	2012-07-04 19:24:48.524063007 +0200
@@ -773,7 +773,7 @@ static int doc_write(struct mtd_info *mt
 
 		/* The ECC will not be calculated correctly if less than 512 is written */
 /* DBB-
-		if (len != 0x200 && eccbuf)
+		if (len != 0x200)
 			printk(KERN_WARNING
 			       "ECC needs a full sector write (adr: %lx size %lx)\n",
 			       (long) to, (long) len);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/mtd/devices/doc2001.c linux-3.2.71-pax/drivers/mtd/devices/doc2001.c
--- linux-3.2.71/drivers/mtd/devices/doc2001.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/mtd/devices/doc2001.c	2012-07-04 19:24:48.528063007 +0200
@@ -392,7 +392,7 @@ static int doc_read (struct mtd_info *mt
 	struct Nand *mychip = &this->chips[from >> (this->chipshift)];
 
 	/* Don't allow read past end of device */
-	if (from >= this->totlen)
+	if (from >= this->totlen || !len)
 		return -EINVAL;
 
 	/* Don't allow a single read to cross a 512-byte block boundary */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/mtd/nand/denali.c linux-3.2.71-pax/drivers/mtd/nand/denali.c
--- linux-3.2.71/drivers/mtd/nand/denali.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/mtd/nand/denali.c	2012-07-04 19:24:48.528063007 +0200
@@ -26,6 +26,7 @@
 #include <linux/pci.h>
 #include <linux/mtd/mtd.h>
 #include <linux/module.h>
+#include <linux/slab.h>
 
 #include "denali.h"
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/mtd/nftlmount.c linux-3.2.71-pax/drivers/mtd/nftlmount.c
--- linux-3.2.71/drivers/mtd/nftlmount.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/mtd/nftlmount.c	2012-07-04 19:24:48.528063007 +0200
@@ -24,6 +24,7 @@
 #include <asm/errno.h>
 #include <linux/delay.h>
 #include <linux/slab.h>
+#include <linux/sched.h>
 #include <linux/mtd/mtd.h>
 #include <linux/mtd/nand.h>
 #include <linux/mtd/nftl.h>
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/mtd/sm_ftl.c linux-3.2.71-pax/drivers/mtd/sm_ftl.c
--- linux-3.2.71/drivers/mtd/sm_ftl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/mtd/sm_ftl.c	2013-03-28 01:35:23.284427949 +0100
@@ -56,7 +56,7 @@ ssize_t sm_attr_show(struct device *dev,
 #define SM_CIS_VENDOR_OFFSET 0x59
 struct attribute_group *sm_create_sysfs_attributes(struct sm_ftl *ftl)
 {
-	struct attribute_group *attr_group;
+	attribute_group_no_const *attr_group;
 	struct attribute **attributes;
 	struct sm_sysfs_attribute *vendor_attribute;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/bonding/bond_main.c linux-3.2.71-pax/drivers/net/bonding/bond_main.c
--- linux-3.2.71/drivers/net/bonding/bond_main.c	2014-06-10 10:59:38.766436244 +0200
+++ linux-3.2.71-pax/drivers/net/bonding/bond_main.c	2014-06-10 10:59:44.150435956 +0200
@@ -4803,7 +4803,7 @@ static int bond_get_tx_queues(struct net
 	return 0;
 }
 
-static struct rtnl_link_ops bond_link_ops __read_mostly = {
+static struct rtnl_link_ops bond_link_ops = {
 	.kind		= "bond",
 	.priv_size	= sizeof(struct bonding),
 	.setup		= bond_setup,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/can/dev.c linux-3.2.71-pax/drivers/net/can/dev.c
--- linux-3.2.71/drivers/net/can/dev.c	2015-05-10 09:22:37.331493045 +0200
+++ linux-3.2.71-pax/drivers/net/can/dev.c	2015-05-10 09:23:09.055494768 +0200
@@ -730,7 +730,7 @@ static int can_newlink(struct net *src_n
 	return -EOPNOTSUPP;
 }
 
-static struct rtnl_link_ops can_link_ops __read_mostly = {
+static struct rtnl_link_ops can_link_ops = {
 	.kind		= "can",
 	.maxtype	= IFLA_CAN_MAX,
 	.policy		= can_policy,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/can/vcan.c linux-3.2.71-pax/drivers/net/can/vcan.c
--- linux-3.2.71/drivers/net/can/vcan.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/can/vcan.c	2015-01-05 18:25:29.899672937 +0100
@@ -154,7 +154,7 @@ static void vcan_setup(struct net_device
 	dev->destructor		= free_netdev;
 }
 
-static struct rtnl_link_ops vcan_link_ops __read_mostly = {
+static struct rtnl_link_ops vcan_link_ops = {
 	.kind	= "vcan",
 	.setup	= vcan_setup,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/dummy.c linux-3.2.71-pax/drivers/net/dummy.c
--- linux-3.2.71/drivers/net/dummy.c	2013-08-03 22:17:28.974408868 +0200
+++ linux-3.2.71-pax/drivers/net/dummy.c	2015-01-05 18:25:41.719678739 +0100
@@ -150,7 +150,7 @@ static int dummy_validate(struct nlattr
 	return 0;
 }
 
-static struct rtnl_link_ops dummy_link_ops __read_mostly = {
+static struct rtnl_link_ops dummy_link_ops = {
 	.kind		= "dummy",
 	.setup		= dummy_setup,
 	.validate	= dummy_validate,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/8390/ax88796.c linux-3.2.71-pax/drivers/net/ethernet/8390/ax88796.c
--- linux-3.2.71/drivers/net/ethernet/8390/ax88796.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/8390/ax88796.c	2013-01-16 21:27:01.698837016 +0100
@@ -872,9 +872,11 @@ static int ax_probe(struct platform_devi
 	if (ax->plat->reg_offsets)
 		ei_local->reg_offset = ax->plat->reg_offsets;
 	else {
+		resource_size_t _mem_size = mem_size;
+		do_div(_mem_size, 0x18);
 		ei_local->reg_offset = ax->reg_offsets;
 		for (ret = 0; ret < 0x18; ret++)
-			ax->reg_offsets[ret] = (mem_size / 0x18) * ret;
+			ax->reg_offsets[ret] = _mem_size * ret;
 	}
 
 	if (!request_mem_region(mem->start, mem_size, pdev->name)) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/atheros/atlx/atl2.c linux-3.2.71-pax/drivers/net/ethernet/atheros/atlx/atl2.c
--- linux-3.2.71/drivers/net/ethernet/atheros/atlx/atl2.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/atheros/atlx/atl2.c	2012-07-04 19:24:48.528063007 +0200
@@ -2857,7 +2857,7 @@ static void atl2_force_ps(struct atl2_hw
  */
 
 #define ATL2_PARAM(X, desc) \
-    static const int __devinitdata X[ATL2_MAX_NIC + 1] = ATL2_PARAM_INIT; \
+    static const int __devinitconst X[ATL2_MAX_NIC + 1] = ATL2_PARAM_INIT; \
     MODULE_PARM(X, "1-" __MODULE_STRING(ATL2_MAX_NIC) "i"); \
     MODULE_PARM_DESC(X, desc);
 #else
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h linux-3.2.71-pax/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h
--- linux-3.2.71/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h	2013-01-16 21:27:01.698837016 +0100
@@ -1240,7 +1240,7 @@ static inline u8 bnx2x_get_path_func_num
 static inline void bnx2x_init_bp_objs(struct bnx2x *bp)
 {
 	/* RX_MODE controlling object */
-	bnx2x_init_rx_mode_obj(bp, &bp->rx_mode_obj);
+	bnx2x_init_rx_mode_obj(bp);
 
 	/* multicast configuration controlling object */
 	bnx2x_init_mcast_obj(bp, &bp->mcast_obj, bp->fp->cl_id, bp->fp->cid,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c linux-3.2.71-pax/drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c
--- linux-3.2.71/drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.c	2013-01-16 21:27:01.698837016 +0100
@@ -2290,15 +2290,14 @@ int bnx2x_config_rx_mode(struct bnx2x *b
 	return rc;
 }
 
-void bnx2x_init_rx_mode_obj(struct bnx2x *bp,
-			    struct bnx2x_rx_mode_obj *o)
+void bnx2x_init_rx_mode_obj(struct bnx2x *bp)
 {
 	if (CHIP_IS_E1x(bp)) {
-		o->wait_comp      = bnx2x_empty_rx_mode_wait;
-		o->config_rx_mode = bnx2x_set_rx_mode_e1x;
+		bp->rx_mode_obj.wait_comp      = bnx2x_empty_rx_mode_wait;
+		bp->rx_mode_obj.config_rx_mode = bnx2x_set_rx_mode_e1x;
 	} else {
-		o->wait_comp      = bnx2x_wait_rx_mode_comp_e2;
-		o->config_rx_mode = bnx2x_set_rx_mode_e2;
+		bp->rx_mode_obj.wait_comp      = bnx2x_wait_rx_mode_comp_e2;
+		bp->rx_mode_obj.config_rx_mode = bnx2x_set_rx_mode_e2;
 	}
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h linux-3.2.71-pax/drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h
--- linux-3.2.71/drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/broadcom/bnx2x/bnx2x_sp.h	2013-01-16 22:01:18.670789482 +0100
@@ -1207,8 +1207,7 @@ int bnx2x_vlan_mac_move(struct bnx2x *bp
 
 /********************* RX MODE ****************/
 
-void bnx2x_init_rx_mode_obj(struct bnx2x *bp,
-			    struct bnx2x_rx_mode_obj *o);
+void bnx2x_init_rx_mode_obj(struct bnx2x *bp);
 
 /**
  * Send and RX_MODE ramrod according to the provided parameters.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/broadcom/tg3.h linux-3.2.71-pax/drivers/net/ethernet/broadcom/tg3.h
--- linux-3.2.71/drivers/net/ethernet/broadcom/tg3.h	2014-04-02 03:15:41.663672550 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/broadcom/tg3.h	2014-04-02 03:15:49.239672146 +0200
@@ -134,6 +134,7 @@
 #define  CHIPREV_ID_5750_A0		 0x4000
 #define  CHIPREV_ID_5750_A1		 0x4001
 #define  CHIPREV_ID_5750_A3		 0x4003
+#define  CHIPREV_ID_5750_C1		 0x4201
 #define  CHIPREV_ID_5750_C2		 0x4202
 #define  CHIPREV_ID_5752_A0_HW		 0x5000
 #define  CHIPREV_ID_5752_A0		 0x6000
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/chelsio/cxgb3/l2t.h linux-3.2.71-pax/drivers/net/ethernet/chelsio/cxgb3/l2t.h
--- linux-3.2.71/drivers/net/ethernet/chelsio/cxgb3/l2t.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/chelsio/cxgb3/l2t.h	2012-07-04 19:24:48.532063007 +0200
@@ -87,7 +87,7 @@ typedef void (*arp_failure_handler_func)
  */
 struct l2t_skb_cb {
 	arp_failure_handler_func arp_failure_handler;
-};
+} __no_const;
 
 #define L2T_SKB_CB(skb) ((struct l2t_skb_cb *)(skb)->cb)
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/chelsio/cxgb3/sge.c linux-3.2.71-pax/drivers/net/ethernet/chelsio/cxgb3/sge.c
--- linux-3.2.71/drivers/net/ethernet/chelsio/cxgb3/sge.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/chelsio/cxgb3/sge.c	2013-09-19 00:44:23.289606292 +0200
@@ -1537,9 +1537,9 @@ static void deferred_unmap_destructor(st
 	dui = (struct deferred_unmap_info *)skb->head;
 	p = dui->addr;
 
-	if (skb->tail - skb->transport_header)
+	if (skb_tail_pointer(skb) - skb_transport_header(skb))
 		pci_unmap_single(dui->pdev, *p++,
-				 skb->tail - skb->transport_header,
+				 skb_tail_pointer(skb) - skb_transport_header(skb),
 				 PCI_DMA_TODEVICE);
 
 	si = skb_shinfo(skb);
@@ -1600,7 +1600,7 @@ static void write_ofld_wr(struct adapter
 	flits = skb_transport_offset(skb) / 8;
 	sgp = ndesc == 1 ? (struct sg_ent *)&d->flit[flits] : sgl;
 	sgl_flits = make_sgl(skb, sgp, skb_transport_header(skb),
-			     skb->tail - skb->transport_header,
+			     skb_tail_pointer(skb) - skb_transport_header(skb),
 			     adap->pdev);
 	if (need_skb_unmap()) {
 		setup_deferred_unmapping(skb, adap->pdev, sgp, sgl_flits);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/dec/tulip/de4x5.c linux-3.2.71-pax/drivers/net/ethernet/dec/tulip/de4x5.c
--- linux-3.2.71/drivers/net/ethernet/dec/tulip/de4x5.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/dec/tulip/de4x5.c	2012-07-04 19:24:48.536063007 +0200
@@ -5397,7 +5397,7 @@ de4x5_ioctl(struct net_device *dev, stru
 	for (i=0; i<ETH_ALEN; i++) {
 	    tmp.addr[i] = dev->dev_addr[i];
 	}
-	if (copy_to_user(ioc->data, tmp.addr, ioc->len)) return -EFAULT;
+	if (ioc->len > sizeof tmp.addr || copy_to_user(ioc->data, tmp.addr, ioc->len)) return -EFAULT;
 	break;
 
     case DE4X5_SET_HWADDR:           /* Set the hardware address */
@@ -5437,7 +5437,7 @@ de4x5_ioctl(struct net_device *dev, stru
 	spin_lock_irqsave(&lp->lock, flags);
 	memcpy(&statbuf, &lp->pktStats, ioc->len);
 	spin_unlock_irqrestore(&lp->lock, flags);
-	if (copy_to_user(ioc->data, &statbuf, ioc->len))
+	if (ioc->len > sizeof statbuf || copy_to_user(ioc->data, &statbuf, ioc->len))
 		return -EFAULT;
 	break;
     }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/dec/tulip/eeprom.c linux-3.2.71-pax/drivers/net/ethernet/dec/tulip/eeprom.c
--- linux-3.2.71/drivers/net/ethernet/dec/tulip/eeprom.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/dec/tulip/eeprom.c	2012-07-04 19:24:48.536063007 +0200
@@ -79,7 +79,7 @@ static struct eeprom_fixup eeprom_fixups
   {NULL}};
 
 
-static const char *block_name[] __devinitdata = {
+static const char *block_name[] __devinitconst = {
 	"21140 non-MII",
 	"21140 MII PHY",
 	"21142 Serial PHY",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/dec/tulip/winbond-840.c linux-3.2.71-pax/drivers/net/ethernet/dec/tulip/winbond-840.c
--- linux-3.2.71/drivers/net/ethernet/dec/tulip/winbond-840.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/dec/tulip/winbond-840.c	2012-07-04 19:24:48.536063007 +0200
@@ -236,7 +236,7 @@ struct pci_id_info {
         int drv_flags;		/* Driver use, intended as capability flags. */
 };
 
-static const struct pci_id_info pci_id_tbl[] __devinitdata = {
+static const struct pci_id_info pci_id_tbl[] __devinitconst = {
 	{ 				/* Sometime a Level-One switch card. */
 	  "Winbond W89c840",	CanHaveMII | HasBrokenTx | FDXOnNoMII},
 	{ "Winbond W89c840",	CanHaveMII | HasBrokenTx},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/dlink/sundance.c linux-3.2.71-pax/drivers/net/ethernet/dlink/sundance.c
--- linux-3.2.71/drivers/net/ethernet/dlink/sundance.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/dlink/sundance.c	2012-07-04 19:24:48.540063007 +0200
@@ -218,7 +218,7 @@ enum {
 struct pci_id_info {
         const char *name;
 };
-static const struct pci_id_info pci_id_tbl[] __devinitdata = {
+static const struct pci_id_info pci_id_tbl[] __devinitconst = {
 	{"D-Link DFE-550TX FAST Ethernet Adapter"},
 	{"D-Link DFE-550FX 100Mbps Fiber-optics Adapter"},
 	{"D-Link DFE-580TX 4 port Server Adapter"},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/emulex/benet/be_main.c linux-3.2.71-pax/drivers/net/ethernet/emulex/benet/be_main.c
--- linux-3.2.71/drivers/net/ethernet/emulex/benet/be_main.c	2015-05-10 09:22:37.543493056 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/emulex/benet/be_main.c	2015-05-10 09:23:09.079494769 +0200
@@ -397,7 +397,7 @@ static void accumulate_16bit_val(u32 *ac
 
 	if (wrapped)
 		newacc += 65536;
-	ACCESS_ONCE(*acc) = newacc;
+	ACCESS_ONCE_RW(*acc) = newacc;
 }
 
 void be_parse_stats(struct be_adapter *adapter)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/faraday/ftgmac100.c linux-3.2.71-pax/drivers/net/ethernet/faraday/ftgmac100.c
--- linux-3.2.71/drivers/net/ethernet/faraday/ftgmac100.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/faraday/ftgmac100.c	2012-07-04 19:24:48.540063007 +0200
@@ -30,6 +30,8 @@
 #include <linux/netdevice.h>
 #include <linux/phy.h>
 #include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/irqreturn.h>
 #include <net/ip.h>
 
 #include "ftgmac100.h"
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/faraday/ftmac100.c linux-3.2.71-pax/drivers/net/ethernet/faraday/ftmac100.c
--- linux-3.2.71/drivers/net/ethernet/faraday/ftmac100.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/faraday/ftmac100.c	2012-07-04 19:24:48.544063007 +0200
@@ -30,6 +30,8 @@
 #include <linux/module.h>
 #include <linux/netdevice.h>
 #include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/irqreturn.h>
 
 #include "ftmac100.h"
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/fealnx.c linux-3.2.71-pax/drivers/net/ethernet/fealnx.c
--- linux-3.2.71/drivers/net/ethernet/fealnx.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/fealnx.c	2012-07-04 19:24:48.544063007 +0200
@@ -150,7 +150,7 @@ struct chip_info {
 	int flags;
 };
 
-static const struct chip_info skel_netdrv_tbl[] __devinitdata = {
+static const struct chip_info skel_netdrv_tbl[] __devinitconst = {
  	{ "100/10M Ethernet PCI Adapter",	HAS_MII_XCVR },
 	{ "100/10M Ethernet PCI Adapter",	HAS_CHIP_XCVR },
 	{ "1000/100/10M Ethernet PCI Adapter",	HAS_MII_XCVR },
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/ibm/emac/core.c linux-3.2.71-pax/drivers/net/ethernet/ibm/emac/core.c
--- linux-3.2.71/drivers/net/ethernet/ibm/emac/core.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/ibm/emac/core.c	2013-02-20 01:22:46.346016085 +0100
@@ -2309,7 +2309,7 @@ static int __devinit emac_of_bus_notify(
 	return 0;
 }
 
-static struct notifier_block emac_of_bus_notifier __devinitdata = {
+static struct notifier_block emac_of_bus_notifier = {
 	.notifier_call = emac_of_bus_notify
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/intel/e1000e/80003es2lan.c linux-3.2.71-pax/drivers/net/ethernet/intel/e1000e/80003es2lan.c
--- linux-3.2.71/drivers/net/ethernet/intel/e1000e/80003es2lan.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/intel/e1000e/80003es2lan.c	2013-01-17 00:38:23.690571682 +0100
@@ -205,7 +205,6 @@ static s32 e1000_init_mac_params_80003es
 {
 	struct e1000_hw *hw = &adapter->hw;
 	struct e1000_mac_info *mac = &hw->mac;
-	struct e1000_mac_operations *func = &mac->ops;
 
 	/* Set media type */
 	switch (adapter->pdev->device) {
@@ -233,16 +232,16 @@ static s32 e1000_init_mac_params_80003es
 	/* check for link */
 	switch (hw->phy.media_type) {
 	case e1000_media_type_copper:
-		func->setup_physical_interface = e1000_setup_copper_link_80003es2lan;
-		func->check_for_link = e1000e_check_for_copper_link;
+		mac->ops.setup_physical_interface = e1000_setup_copper_link_80003es2lan;
+		mac->ops.check_for_link = e1000e_check_for_copper_link;
 		break;
 	case e1000_media_type_fiber:
-		func->setup_physical_interface = e1000e_setup_fiber_serdes_link;
-		func->check_for_link = e1000e_check_for_fiber_link;
+		mac->ops.setup_physical_interface = e1000e_setup_fiber_serdes_link;
+		mac->ops.check_for_link = e1000e_check_for_fiber_link;
 		break;
 	case e1000_media_type_internal_serdes:
-		func->setup_physical_interface = e1000e_setup_fiber_serdes_link;
-		func->check_for_link = e1000e_check_for_serdes_link;
+		mac->ops.setup_physical_interface = e1000e_setup_fiber_serdes_link;
+		mac->ops.check_for_link = e1000e_check_for_serdes_link;
 		break;
 	default:
 		return -E1000_ERR_CONFIG;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/intel/e1000e/82571.c linux-3.2.71-pax/drivers/net/ethernet/intel/e1000e/82571.c
--- linux-3.2.71/drivers/net/ethernet/intel/e1000e/82571.c	2012-08-22 14:04:04.897098699 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/intel/e1000e/82571.c	2013-01-17 00:37:47.170572526 +0100
@@ -239,7 +239,6 @@ static s32 e1000_init_mac_params_82571(s
 {
 	struct e1000_hw *hw = &adapter->hw;
 	struct e1000_mac_info *mac = &hw->mac;
-	struct e1000_mac_operations *func = &mac->ops;
 	u32 swsm = 0;
 	u32 swsm2 = 0;
 	bool force_clear_smbi = false;
@@ -272,22 +271,22 @@ static s32 e1000_init_mac_params_82571(s
 	/* check for link */
 	switch (hw->phy.media_type) {
 	case e1000_media_type_copper:
-		func->setup_physical_interface = e1000_setup_copper_link_82571;
-		func->check_for_link = e1000e_check_for_copper_link;
-		func->get_link_up_info = e1000e_get_speed_and_duplex_copper;
+		mac->ops.setup_physical_interface = e1000_setup_copper_link_82571;
+		mac->ops.check_for_link = e1000e_check_for_copper_link;
+		mac->ops.get_link_up_info = e1000e_get_speed_and_duplex_copper;
 		break;
 	case e1000_media_type_fiber:
-		func->setup_physical_interface =
+		mac->ops.setup_physical_interface =
 			e1000_setup_fiber_serdes_link_82571;
-		func->check_for_link = e1000e_check_for_fiber_link;
-		func->get_link_up_info =
+		mac->ops.check_for_link = e1000e_check_for_fiber_link;
+		mac->ops.get_link_up_info =
 			e1000e_get_speed_and_duplex_fiber_serdes;
 		break;
 	case e1000_media_type_internal_serdes:
-		func->setup_physical_interface =
+		mac->ops.setup_physical_interface =
 			e1000_setup_fiber_serdes_link_82571;
-		func->check_for_link = e1000_check_for_serdes_link_82571;
-		func->get_link_up_info =
+		mac->ops.check_for_link = e1000_check_for_serdes_link_82571;
+		mac->ops.get_link_up_info =
 			e1000e_get_speed_and_duplex_fiber_serdes;
 		break;
 	default:
@@ -297,10 +296,10 @@ static s32 e1000_init_mac_params_82571(s
 
 	switch (hw->mac.type) {
 	case e1000_82573:
-		func->set_lan_id = e1000_set_lan_id_single_port;
-		func->check_mng_mode = e1000e_check_mng_mode_generic;
-		func->led_on = e1000e_led_on_generic;
-		func->blink_led = e1000e_blink_led_generic;
+		mac->ops.set_lan_id = e1000_set_lan_id_single_port;
+		mac->ops.check_mng_mode = e1000e_check_mng_mode_generic;
+		mac->ops.led_on = e1000e_led_on_generic;
+		mac->ops.blink_led = e1000e_blink_led_generic;
 
 		/* FWSM register */
 		mac->has_fwsm = true;
@@ -314,14 +313,14 @@ static s32 e1000_init_mac_params_82571(s
 		break;
 	case e1000_82574:
 	case e1000_82583:
-		func->set_lan_id = e1000_set_lan_id_single_port;
-		func->check_mng_mode = e1000_check_mng_mode_82574;
-		func->led_on = e1000_led_on_82574;
+		mac->ops.set_lan_id = e1000_set_lan_id_single_port;
+		mac->ops.check_mng_mode = e1000_check_mng_mode_82574;
+		mac->ops.led_on = e1000_led_on_82574;
 		break;
 	default:
-		func->check_mng_mode = e1000e_check_mng_mode_generic;
-		func->led_on = e1000e_led_on_generic;
-		func->blink_led = e1000e_blink_led_generic;
+		mac->ops.check_mng_mode = e1000e_check_mng_mode_generic;
+		mac->ops.led_on = e1000e_led_on_generic;
+		mac->ops.blink_led = e1000e_blink_led_generic;
 
 		/* FWSM register */
 		mac->has_fwsm = true;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/mellanox/mlx4/eq.c linux-3.2.71-pax/drivers/net/ethernet/mellanox/mlx4/eq.c
--- linux-3.2.71/drivers/net/ethernet/mellanox/mlx4/eq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/mellanox/mlx4/eq.c	2013-02-13 13:28:31.307777367 +0100
@@ -570,8 +570,8 @@ int mlx4_init_eq_table(struct mlx4_dev *
 	int err;
 	int i;
 
-	priv->eq_table.uar_map = kcalloc(sizeof *priv->eq_table.uar_map,
-					 mlx4_num_eq_uar(dev), GFP_KERNEL);
+	priv->eq_table.uar_map = kcalloc(mlx4_num_eq_uar(dev),
+					 sizeof *priv->eq_table.uar_map, GFP_KERNEL);
 	if (!priv->eq_table.uar_map) {
 		err = -ENOMEM;
 		goto err_out_free;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/mellanox/mlx4/main.c linux-3.2.71-pax/drivers/net/ethernet/mellanox/mlx4/main.c
--- linux-3.2.71/drivers/net/ethernet/mellanox/mlx4/main.c	2014-07-12 17:42:33.816954216 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/mellanox/mlx4/main.c	2014-07-12 17:42:44.740954191 +0200
@@ -40,6 +40,7 @@
 #include <linux/dma-mapping.h>
 #include <linux/slab.h>
 #include <linux/io-mapping.h>
+#include <linux/sched.h>
 
 #include <linux/mlx4/device.h>
 #include <linux/mlx4/doorbell.h>
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/neterion/vxge/vxge-config.c linux-3.2.71-pax/drivers/net/ethernet/neterion/vxge/vxge-config.c
--- linux-3.2.71/drivers/net/ethernet/neterion/vxge/vxge-config.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/neterion/vxge/vxge-config.c	2013-01-16 21:27:01.702837016 +0100
@@ -3461,7 +3461,10 @@ __vxge_hw_fifo_create(struct __vxge_hw_v
 	struct __vxge_hw_fifo *fifo;
 	struct vxge_hw_fifo_config *config;
 	u32 txdl_size, txdl_per_memblock;
-	struct vxge_hw_mempool_cbs fifo_mp_callback;
+	static struct vxge_hw_mempool_cbs fifo_mp_callback = {
+		.item_func_alloc = __vxge_hw_fifo_mempool_item_alloc,
+	};
+
 	struct __vxge_hw_virtualpath *vpath;
 
 	if ((vp == NULL) || (attr == NULL)) {
@@ -3544,8 +3547,6 @@ __vxge_hw_fifo_create(struct __vxge_hw_v
 		goto exit;
 	}
 
-	fifo_mp_callback.item_func_alloc = __vxge_hw_fifo_mempool_item_alloc;
-
 	fifo->mempool =
 		__vxge_hw_mempool_create(vpath->hldev,
 			fifo->config->memblock_size,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/realtek/r8169.c linux-3.2.71-pax/drivers/net/ethernet/realtek/r8169.c
--- linux-3.2.71/drivers/net/ethernet/realtek/r8169.c	2015-05-10 09:22:37.735493066 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/realtek/r8169.c	2015-05-10 09:23:09.095494770 +0200
@@ -704,17 +704,17 @@ struct rtl8169_private {
 	struct mdio_ops {
 		void (*write)(void __iomem *, int, int);
 		int (*read)(void __iomem *, int);
-	} mdio_ops;
+	} __no_const mdio_ops;
 
 	struct pll_power_ops {
 		void (*down)(struct rtl8169_private *);
 		void (*up)(struct rtl8169_private *);
-	} pll_power_ops;
+	} __no_const pll_power_ops;
 
 	struct jumbo_ops {
 		void (*enable)(struct rtl8169_private *);
 		void (*disable)(struct rtl8169_private *);
-	} jumbo_ops;
+	} __no_const jumbo_ops;
 
 	int (*set_speed)(struct net_device *, u8 aneg, u16 sp, u8 dpx, u32 adv);
 	int (*get_settings)(struct net_device *, struct ethtool_cmd *);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/sis/sis190.c linux-3.2.71-pax/drivers/net/ethernet/sis/sis190.c
--- linux-3.2.71/drivers/net/ethernet/sis/sis190.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/sis/sis190.c	2012-07-04 19:24:48.556063007 +0200
@@ -1624,7 +1624,7 @@ static int __devinit sis190_get_mac_addr
 static int __devinit sis190_get_mac_addr_from_apc(struct pci_dev *pdev,
 						  struct net_device *dev)
 {
-	static const u16 __devinitdata ids[] = { 0x0965, 0x0966, 0x0968 };
+	static const u16 __devinitconst ids[] = { 0x0965, 0x0966, 0x0968 };
 	struct sis190_private *tp = netdev_priv(dev);
 	struct pci_dev *isa_bridge;
 	u8 reg, tmp8;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/stmicro/stmmac/mmc_core.c linux-3.2.71-pax/drivers/net/ethernet/stmicro/stmmac/mmc_core.c
--- linux-3.2.71/drivers/net/ethernet/stmicro/stmmac/mmc_core.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/ethernet/stmicro/stmmac/mmc_core.c	2012-07-04 19:24:48.560063007 +0200
@@ -140,8 +140,8 @@ void dwmac_mmc_ctrl(void __iomem *ioaddr
 
 	writel(value, ioaddr + MMC_CNTRL);
 
-	pr_debug("stmmac: MMC ctrl register (offset 0x%x): 0x%08x\n",
-		 MMC_CNTRL, value);
+//	pr_debug("stmmac: MMC ctrl register (offset 0x%x): 0x%08x\n",
+//		 MMC_CNTRL, value);
 }
 
 /* To mask all all interrupts.*/
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ethernet/via/via-rhine.c linux-3.2.71-pax/drivers/net/ethernet/via/via-rhine.c
--- linux-3.2.71/drivers/net/ethernet/via/via-rhine.c	2013-10-27 17:59:57.456642374 +0100
+++ linux-3.2.71-pax/drivers/net/ethernet/via/via-rhine.c	2015-04-30 03:14:12.232543974 +0200
@@ -2299,7 +2299,7 @@ static struct pci_driver rhine_driver =
 	.shutdown =	rhine_shutdown,
 };
 
-static struct dmi_system_id __initdata rhine_dmi_table[] = {
+static const struct dmi_system_id __initconst rhine_dmi_table[] = {
 	{
 		.ident = "EPIA-M",
 		.matches = {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ifb.c linux-3.2.71-pax/drivers/net/ifb.c
--- linux-3.2.71/drivers/net/ifb.c	2013-09-10 17:24:55.417739122 +0200
+++ linux-3.2.71-pax/drivers/net/ifb.c	2015-01-05 18:25:55.903685735 +0100
@@ -251,7 +251,7 @@ static int ifb_validate(struct nlattr *t
 	return 0;
 }
 
-static struct rtnl_link_ops ifb_link_ops __read_mostly = {
+static struct rtnl_link_ops ifb_link_ops = {
 	.kind		= "ifb",
 	.priv_size	= sizeof(struct ifb_private),
 	.setup		= ifb_setup,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/loopback.c linux-3.2.71-pax/drivers/net/loopback.c
--- linux-3.2.71/drivers/net/loopback.c	2013-02-20 12:30:42.052171943 +0100
+++ linux-3.2.71-pax/drivers/net/loopback.c	2013-03-29 04:02:30.659343545 +0100
@@ -216,6 +216,6 @@ out:
 }
 
 /* Registered in net/core/dev.c */
-struct pernet_operations __net_initdata loopback_net_ops = {
+struct pernet_operations __net_initconst loopback_net_ops = {
        .init = loopback_net_init,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/macvlan.c linux-3.2.71-pax/drivers/net/macvlan.c
--- linux-3.2.71/drivers/net/macvlan.c	2014-09-14 14:10:59.038117969 +0200
+++ linux-3.2.71-pax/drivers/net/macvlan.c	2014-09-14 14:11:25.986138373 +0200
@@ -790,13 +790,15 @@ static const struct nla_policy macvlan_p
 int macvlan_link_register(struct rtnl_link_ops *ops)
 {
 	/* common fields */
-	ops->priv_size		= sizeof(struct macvlan_dev);
-	ops->validate		= macvlan_validate;
-	ops->maxtype		= IFLA_MACVLAN_MAX;
-	ops->policy		= macvlan_policy;
-	ops->changelink		= macvlan_changelink;
-	ops->get_size		= macvlan_get_size;
-	ops->fill_info		= macvlan_fill_info;
+	pax_open_kernel();
+	*(size_t *)&ops->priv_size	= sizeof(struct macvlan_dev);
+	*(void **)&ops->validate	= macvlan_validate;
+	*(int *)&ops->maxtype		= IFLA_MACVLAN_MAX;
+	*(const void **)&ops->policy	= macvlan_policy;
+	*(void **)&ops->changelink	= macvlan_changelink;
+	*(void **)&ops->get_size	= macvlan_get_size;
+	*(void **)&ops->fill_info	= macvlan_fill_info;
+	pax_close_kernel();
 
 	return rtnl_link_register(ops);
 };
@@ -852,7 +854,7 @@ static int macvlan_device_event(struct n
 	return NOTIFY_DONE;
 }
 
-static struct notifier_block macvlan_notifier_block __read_mostly = {
+static struct notifier_block macvlan_notifier_block = {
 	.notifier_call	= macvlan_device_event,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/macvtap.c linux-3.2.71-pax/drivers/net/macvtap.c
--- linux-3.2.71/drivers/net/macvtap.c	2015-05-10 09:22:37.751493067 +0200
+++ linux-3.2.71-pax/drivers/net/macvtap.c	2015-05-10 09:23:09.095494770 +0200
@@ -351,7 +351,7 @@ static void macvtap_setup(struct net_dev
 	dev->tx_queue_len = TUN_READQ_SIZE;
 }
 
-static struct rtnl_link_ops macvtap_link_ops __read_mostly = {
+static struct rtnl_link_ops macvtap_link_ops = {
 	.kind		= "macvtap",
 	.setup		= macvtap_setup,
 	.newlink	= macvtap_newlink,
@@ -936,7 +936,7 @@ static long macvtap_ioctl(struct file *f
 			return -ENOLINK;
 
 		ret = 0;
-		if (copy_to_user(&ifr->ifr_name, vlan->dev->name, IFNAMSIZ) ||
+		if (copy_to_user(ifr->ifr_name, vlan->dev->name, IFNAMSIZ) ||
 		    put_user(q->flags, &ifr->ifr_flags))
 			ret = -EFAULT;
 		dev_put(vlan->dev);
@@ -1097,7 +1097,7 @@ static int macvtap_device_event(struct n
 	return NOTIFY_DONE;
 }
 
-static struct notifier_block macvtap_notifier_block __read_mostly = {
+static struct notifier_block macvtap_notifier_block = {
 	.notifier_call	= macvtap_device_event,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/phy/phy_device.c linux-3.2.71-pax/drivers/net/phy/phy_device.c
--- linux-3.2.71/drivers/net/phy/phy_device.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/phy/phy_device.c	2015-02-20 11:24:22.137413218 +0100
@@ -207,7 +207,7 @@ static struct phy_device* phy_device_cre
  * Description: Reads the ID registers of the PHY at @addr on the
  *   @bus, stores it in @phy_id and returns zero on success.
  */
-int get_phy_id(struct mii_bus *bus, int addr, u32 *phy_id)
+int get_phy_id(struct mii_bus *bus, int addr, int *phy_id)
 {
 	int phy_reg;
 
@@ -243,7 +243,7 @@ EXPORT_SYMBOL(get_phy_id);
 struct phy_device * get_phy_device(struct mii_bus *bus, int addr)
 {
 	struct phy_device *dev = NULL;
-	u32 phy_id;
+	int phy_id;
 	int r;
 
 	r = get_phy_id(bus, addr, &phy_id);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/ppp/ppp_generic.c linux-3.2.71-pax/drivers/net/ppp/ppp_generic.c
--- linux-3.2.71/drivers/net/ppp/ppp_generic.c	2014-12-14 21:13:45.102054892 +0100
+++ linux-3.2.71-pax/drivers/net/ppp/ppp_generic.c	2014-12-14 21:13:52.786069247 +0100
@@ -986,7 +986,6 @@ ppp_net_ioctl(struct net_device *dev, st
 	void __user *addr = (void __user *) ifr->ifr_ifru.ifru_data;
 	struct ppp_stats stats;
 	struct ppp_comp_stats cstats;
-	char *vers;
 
 	switch (cmd) {
 	case SIOCGPPPSTATS:
@@ -1008,8 +1007,7 @@ ppp_net_ioctl(struct net_device *dev, st
 		break;
 
 	case SIOCGPPPVER:
-		vers = PPP_VERSION;
-		if (copy_to_user(addr, vers, strlen(vers) + 1))
+		if (copy_to_user(addr, PPP_VERSION, sizeof(PPP_VERSION)))
 			break;
 		err = 0;
 		break;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/slip/slhc.c linux-3.2.71-pax/drivers/net/slip/slhc.c
--- linux-3.2.71/drivers/net/slip/slhc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/slip/slhc.c	2013-05-13 13:23:53.323740069 +0200
@@ -489,7 +489,7 @@ slhc_uncompress(struct slcompress *comp,
 	register struct tcphdr *thp;
 	register struct iphdr *ip;
 	register struct cstate *cs;
-	int len, hdrlen;
+	long len, hdrlen;
 	unsigned char *cp = icp;
 
 	/* We've got a compressed packet; read the change byte */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/tokenring/abyss.c linux-3.2.71-pax/drivers/net/tokenring/abyss.c
--- linux-3.2.71/drivers/net/tokenring/abyss.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/tokenring/abyss.c	2012-07-04 19:24:48.560063007 +0200
@@ -451,10 +451,12 @@ static struct pci_driver abyss_driver =
 
 static int __init abyss_init (void)
 {
-	abyss_netdev_ops = tms380tr_netdev_ops;
+	pax_open_kernel();
+	memcpy((void *)&abyss_netdev_ops, &tms380tr_netdev_ops, sizeof(tms380tr_netdev_ops));
 
-	abyss_netdev_ops.ndo_open = abyss_open;
-	abyss_netdev_ops.ndo_stop = abyss_close;
+	*(void **)&abyss_netdev_ops.ndo_open = abyss_open;
+	*(void **)&abyss_netdev_ops.ndo_stop = abyss_close;
+	pax_close_kernel();
 
 	return pci_register_driver(&abyss_driver);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/tokenring/madgemc.c linux-3.2.71-pax/drivers/net/tokenring/madgemc.c
--- linux-3.2.71/drivers/net/tokenring/madgemc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/tokenring/madgemc.c	2012-07-04 19:24:48.560063007 +0200
@@ -744,9 +744,11 @@ static struct mca_driver madgemc_driver
 
 static int __init madgemc_init (void)
 {
-	madgemc_netdev_ops = tms380tr_netdev_ops;
-	madgemc_netdev_ops.ndo_open = madgemc_open;
-	madgemc_netdev_ops.ndo_stop = madgemc_close;
+	pax_open_kernel();
+	memcpy((void *)&madgemc_netdev_ops, &tms380tr_netdev_ops, sizeof(tms380tr_netdev_ops));
+	*(void **)&madgemc_netdev_ops.ndo_open = madgemc_open;
+	*(void **)&madgemc_netdev_ops.ndo_stop = madgemc_close;
+	pax_close_kernel();
 
 	return mca_register_driver (&madgemc_driver);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/tokenring/proteon.c linux-3.2.71-pax/drivers/net/tokenring/proteon.c
--- linux-3.2.71/drivers/net/tokenring/proteon.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/tokenring/proteon.c	2012-07-04 19:24:48.560063007 +0200
@@ -353,9 +353,11 @@ static int __init proteon_init(void)
 	struct platform_device *pdev;
 	int i, num = 0, err = 0;
 
-	proteon_netdev_ops = tms380tr_netdev_ops;
-	proteon_netdev_ops.ndo_open = proteon_open;
-	proteon_netdev_ops.ndo_stop = tms380tr_close;
+	pax_open_kernel();
+	memcpy((void *)&proteon_netdev_ops, &tms380tr_netdev_ops, sizeof(tms380tr_netdev_ops));
+	*(void **)&proteon_netdev_ops.ndo_open = proteon_open;
+	*(void **)&proteon_netdev_ops.ndo_stop = tms380tr_close;
+	pax_close_kernel();
 
 	err = platform_driver_register(&proteon_driver);
 	if (err)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/tokenring/skisa.c linux-3.2.71-pax/drivers/net/tokenring/skisa.c
--- linux-3.2.71/drivers/net/tokenring/skisa.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/tokenring/skisa.c	2012-07-04 19:24:48.560063007 +0200
@@ -363,9 +363,11 @@ static int __init sk_isa_init(void)
 	struct platform_device *pdev;
 	int i, num = 0, err = 0;
 
-	sk_isa_netdev_ops = tms380tr_netdev_ops;
-	sk_isa_netdev_ops.ndo_open = sk_isa_open;
-	sk_isa_netdev_ops.ndo_stop = tms380tr_close;
+	pax_open_kernel();
+	memcpy((void *)&sk_isa_netdev_ops, &tms380tr_netdev_ops, sizeof(tms380tr_netdev_ops));
+	*(void **)&sk_isa_netdev_ops.ndo_open = sk_isa_open;
+	*(void **)&sk_isa_netdev_ops.ndo_stop = tms380tr_close;
+	pax_close_kernel();
 
 	err = platform_driver_register(&sk_isa_driver);
 	if (err)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/tun.c linux-3.2.71-pax/drivers/net/tun.c
--- linux-3.2.71/drivers/net/tun.c	2015-01-01 15:15:24.280069618 +0100
+++ linux-3.2.71-pax/drivers/net/tun.c	2015-01-05 18:26:30.523702852 +0100
@@ -931,7 +931,7 @@ static int tun_validate(struct nlattr *t
 	return -EINVAL;
 }
 
-static struct rtnl_link_ops tun_link_ops __read_mostly = {
+static struct rtnl_link_ops tun_link_ops = {
 	.kind		= DRV_NAME,
 	.priv_size	= sizeof(struct tun_struct),
 	.setup		= tun_setup,
@@ -1241,7 +1241,7 @@ static int set_offload(struct tun_struct
 }
 
 static long __tun_chr_ioctl(struct file *file, unsigned int cmd,
-			    unsigned long arg, int ifreq_len)
+			    unsigned long arg, size_t ifreq_len)
 {
 	struct tun_file *tfile = file->private_data;
 	struct tun_struct *tun;
@@ -1252,6 +1252,9 @@ static long __tun_chr_ioctl(struct file
 	int vnet_hdr_sz;
 	int ret;
 
+	if (ifreq_len > sizeof ifr)
+		return -EFAULT;
+
 	if (cmd == TUNSETIFF || _IOC_TYPE(cmd) == 0x89) {
 		if (copy_from_user(&ifr, argp, ifreq_len))
 			return -EFAULT;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/usb/hso.c linux-3.2.71-pax/drivers/net/usb/hso.c
--- linux-3.2.71/drivers/net/usb/hso.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/usb/hso.c	2012-07-04 19:24:48.564063008 +0200
@@ -71,7 +71,7 @@
 #include <asm/byteorder.h>
 #include <linux/serial_core.h>
 #include <linux/serial.h>
-
+#include <asm/local.h>
 
 #define MOD_AUTHOR			"Option Wireless"
 #define MOD_DESCRIPTION			"USB High Speed Option driver"
@@ -257,7 +257,7 @@ struct hso_serial {
 
 	/* from usb_serial_port */
 	struct tty_struct *tty;
-	int open_count;
+	local_t open_count;
 	spinlock_t serial_lock;
 
 	int (*write_data) (struct hso_serial *serial);
@@ -1190,7 +1190,7 @@ static void put_rxbuf_data_and_resubmit_
 	struct urb *urb;
 
 	urb = serial->rx_urb[0];
-	if (serial->open_count > 0) {
+	if (local_read(&serial->open_count) > 0) {
 		count = put_rxbuf_data(urb, serial);
 		if (count == -1)
 			return;
@@ -1226,7 +1226,7 @@ static void hso_std_serial_read_bulk_cal
 	DUMP1(urb->transfer_buffer, urb->actual_length);
 
 	/* Anyone listening? */
-	if (serial->open_count == 0)
+	if (local_read(&serial->open_count) == 0)
 		return;
 
 	if (status == 0) {
@@ -1311,8 +1311,7 @@ static int hso_serial_open(struct tty_st
 	spin_unlock_irq(&serial->serial_lock);
 
 	/* check for port already opened, if not set the termios */
-	serial->open_count++;
-	if (serial->open_count == 1) {
+	if (local_inc_return(&serial->open_count) == 1) {
 		serial->rx_state = RX_IDLE;
 		/* Force default termio settings */
 		_hso_serial_set_termios(tty, NULL);
@@ -1324,7 +1323,7 @@ static int hso_serial_open(struct tty_st
 		result = hso_start_serial_device(serial->parent, GFP_KERNEL);
 		if (result) {
 			hso_stop_serial_device(serial->parent);
-			serial->open_count--;
+			local_dec(&serial->open_count);
 			kref_put(&serial->parent->ref, hso_serial_ref_free);
 		}
 	} else {
@@ -1361,10 +1360,10 @@ static void hso_serial_close(struct tty_
 
 	/* reset the rts and dtr */
 	/* do the actual close */
-	serial->open_count--;
+	local_dec(&serial->open_count);
 
-	if (serial->open_count <= 0) {
-		serial->open_count = 0;
+	if (local_read(&serial->open_count) <= 0) {
+		local_set(&serial->open_count,  0);
 		spin_lock_irq(&serial->serial_lock);
 		if (serial->tty == tty) {
 			serial->tty->driver_data = NULL;
@@ -1446,7 +1445,7 @@ static void hso_serial_set_termios(struc
 
 	/* the actual setup */
 	spin_lock_irqsave(&serial->serial_lock, flags);
-	if (serial->open_count)
+	if (local_read(&serial->open_count))
 		_hso_serial_set_termios(tty, old);
 	else
 		tty->termios = old;
@@ -1905,7 +1904,7 @@ static void intr_callback(struct urb *ur
 				D1("Pending read interrupt on port %d\n", i);
 				spin_lock(&serial->serial_lock);
 				if (serial->rx_state == RX_IDLE &&
-					serial->open_count > 0) {
+					local_read(&serial->open_count) > 0) {
 					/* Setup and send a ctrl req read on
 					 * port i */
 					if (!serial->rx_urb_filled[0]) {
@@ -3098,7 +3097,7 @@ static int hso_resume(struct usb_interfa
 	/* Start all serial ports */
 	for (i = 0; i < HSO_SERIAL_TTY_MINORS; i++) {
 		if (serial_table[i] && (serial_table[i]->interface == iface)) {
-			if (dev2ser(serial_table[i])->open_count) {
+			if (local_read(&dev2ser(serial_table[i])->open_count)) {
 				result =
 				    hso_start_serial_device(serial_table[i], GFP_NOIO);
 				hso_kick_transmit(dev2ser(serial_table[i]));
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/usb/sierra_net.c linux-3.2.71-pax/drivers/net/usb/sierra_net.c
--- linux-3.2.71/drivers/net/usb/sierra_net.c	2012-10-10 11:02:19.595865883 +0200
+++ linux-3.2.71-pax/drivers/net/usb/sierra_net.c	2013-09-01 20:08:25.543817529 +0200
@@ -52,7 +52,7 @@ static const char driver_name[] = "sierr
 /* atomic counter partially included in MAC address to make sure 2 devices
  * do not end up with the same MAC - concept breaks in case of > 255 ifaces
  */
-static	atomic_t iface_counter = ATOMIC_INIT(0);
+static	atomic_unchecked_t iface_counter = ATOMIC_INIT(0);
 
 /*
  * SYNC Timer Delay definition used to set the expiry time
@@ -738,7 +738,7 @@ static int sierra_net_bind(struct usbnet
 	dev->net->netdev_ops = &sierra_net_device_ops;
 
 	/* change MAC addr to include, ifacenum, and to be unique */
-	dev->net->dev_addr[ETH_ALEN-2] = atomic_inc_return(&iface_counter);
+	dev->net->dev_addr[ETH_ALEN-2] = atomic_inc_return_unchecked(&iface_counter);
 	dev->net->dev_addr[ETH_ALEN-1] = ifacenum;
 
 	/* we will have to manufacture ethernet headers, prepare template */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/vmxnet3/vmxnet3_ethtool.c linux-3.2.71-pax/drivers/net/vmxnet3/vmxnet3_ethtool.c
--- linux-3.2.71/drivers/net/vmxnet3/vmxnet3_ethtool.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/vmxnet3/vmxnet3_ethtool.c	2012-07-04 19:24:48.564063008 +0200
@@ -601,8 +601,7 @@ vmxnet3_set_rss_indir(struct net_device
 		 * Return with error code if any of the queue indices
 		 * is out of range
 		 */
-		if (p->ring_index[i] < 0 ||
-		    p->ring_index[i] >= adapter->num_rx_queues)
+		if (p->ring_index[i] >= adapter->num_rx_queues)
 			return -EINVAL;
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/airo.c linux-3.2.71-pax/drivers/net/wireless/airo.c
--- linux-3.2.71/drivers/net/wireless/airo.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/wireless/airo.c	2013-11-12 01:28:57.493398489 +0100
@@ -7885,7 +7885,7 @@ static int writerids(struct net_device *
 	struct airo_info *ai = dev->ml_priv;
 	int  ridcode;
         int  enabled;
-	static int (* writer)(struct airo_info *, u16 rid, const void *, int, int);
+	int (* writer)(struct airo_info *, u16 rid, const void *, int, int);
 	unsigned char *iobuf;
 
 	/* Only super-user can write RIDs */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/at76c50x-usb.c linux-3.2.71-pax/drivers/net/wireless/at76c50x-usb.c
--- linux-3.2.71/drivers/net/wireless/at76c50x-usb.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/wireless/at76c50x-usb.c	2013-03-28 04:10:58.179929538 +0100
@@ -353,7 +353,7 @@ static u8 at76_dfu_get_state(struct usb_
 }
 
 /* Convert timeout from the DFU status to jiffies */
-static inline unsigned long at76_get_timeout(struct dfu_status *s)
+static inline unsigned long __intentional_overflow(-1) at76_get_timeout(struct dfu_status *s)
 {
 	return msecs_to_jiffies((s->poll_timeout[2] << 16)
 				| (s->poll_timeout[1] << 8)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/ath/ath9k/ar9002_mac.c linux-3.2.71-pax/drivers/net/wireless/ath/ath9k/ar9002_mac.c
--- linux-3.2.71/drivers/net/wireless/ath/ath9k/ar9002_mac.c	2014-02-16 00:01:51.656847719 +0100
+++ linux-3.2.71-pax/drivers/net/wireless/ath/ath9k/ar9002_mac.c	2014-02-16 00:01:57.716847395 +0100
@@ -217,8 +217,8 @@ ar9002_set_txdesc(struct ath_hw *ah, voi
 	ads->ds_txstatus6 = ads->ds_txstatus7 = 0;
 	ads->ds_txstatus8 = ads->ds_txstatus9 = 0;
 
-	ACCESS_ONCE(ads->ds_link) = i->link;
-	ACCESS_ONCE(ads->ds_data) = i->buf_addr[0];
+	ACCESS_ONCE_RW(ads->ds_link) = i->link;
+	ACCESS_ONCE_RW(ads->ds_data) = i->buf_addr[0];
 
 	ctl1 = i->buf_len[0] | (i->is_last ? 0 : AR_TxMore);
 	ctl6 = SM(i->keytype, AR_EncrType);
@@ -232,26 +232,26 @@ ar9002_set_txdesc(struct ath_hw *ah, voi
 
 	if ((i->is_first || i->is_last) &&
 	    i->aggr != AGGR_BUF_MIDDLE && i->aggr != AGGR_BUF_LAST) {
-		ACCESS_ONCE(ads->ds_ctl2) = set11nTries(i->rates, 0)
+		ACCESS_ONCE_RW(ads->ds_ctl2) = set11nTries(i->rates, 0)
 			| set11nTries(i->rates, 1)
 			| set11nTries(i->rates, 2)
 			| set11nTries(i->rates, 3)
 			| (i->dur_update ? AR_DurUpdateEna : 0)
 			| SM(0, AR_BurstDur);
 
-		ACCESS_ONCE(ads->ds_ctl3) = set11nRate(i->rates, 0)
+		ACCESS_ONCE_RW(ads->ds_ctl3) = set11nRate(i->rates, 0)
 			| set11nRate(i->rates, 1)
 			| set11nRate(i->rates, 2)
 			| set11nRate(i->rates, 3);
 	} else {
-		ACCESS_ONCE(ads->ds_ctl2) = 0;
-		ACCESS_ONCE(ads->ds_ctl3) = 0;
+		ACCESS_ONCE_RW(ads->ds_ctl2) = 0;
+		ACCESS_ONCE_RW(ads->ds_ctl3) = 0;
 	}
 
 	if (!i->is_first) {
-		ACCESS_ONCE(ads->ds_ctl0) = 0;
-		ACCESS_ONCE(ads->ds_ctl1) = ctl1;
-		ACCESS_ONCE(ads->ds_ctl6) = ctl6;
+		ACCESS_ONCE_RW(ads->ds_ctl0) = 0;
+		ACCESS_ONCE_RW(ads->ds_ctl1) = ctl1;
+		ACCESS_ONCE_RW(ads->ds_ctl6) = ctl6;
 		return;
 	}
 
@@ -276,7 +276,7 @@ ar9002_set_txdesc(struct ath_hw *ah, voi
 		break;
 	}
 
-	ACCESS_ONCE(ads->ds_ctl0) = (i->pkt_len & AR_FrameLen)
+	ACCESS_ONCE_RW(ads->ds_ctl0) = (i->pkt_len & AR_FrameLen)
 		| (i->flags & ATH9K_TXDESC_VMF ? AR_VirtMoreFrag : 0)
 		| SM(i->txpower, AR_XmitPower)
 		| (i->flags & ATH9K_TXDESC_VEOL ? AR_VEOL : 0)
@@ -286,19 +286,19 @@ ar9002_set_txdesc(struct ath_hw *ah, voi
 		| (i->flags & ATH9K_TXDESC_RTSENA ? AR_RTSEnable :
 		   (i->flags & ATH9K_TXDESC_CTSENA ? AR_CTSEnable : 0));
 
-	ACCESS_ONCE(ads->ds_ctl1) = ctl1;
-	ACCESS_ONCE(ads->ds_ctl6) = ctl6;
+	ACCESS_ONCE_RW(ads->ds_ctl1) = ctl1;
+	ACCESS_ONCE_RW(ads->ds_ctl6) = ctl6;
 
 	if (i->aggr == AGGR_BUF_MIDDLE || i->aggr == AGGR_BUF_LAST)
 		return;
 
-	ACCESS_ONCE(ads->ds_ctl4) = set11nPktDurRTSCTS(i->rates, 0)
+	ACCESS_ONCE_RW(ads->ds_ctl4) = set11nPktDurRTSCTS(i->rates, 0)
 		| set11nPktDurRTSCTS(i->rates, 1);
 
-	ACCESS_ONCE(ads->ds_ctl5) = set11nPktDurRTSCTS(i->rates, 2)
+	ACCESS_ONCE_RW(ads->ds_ctl5) = set11nPktDurRTSCTS(i->rates, 2)
 		| set11nPktDurRTSCTS(i->rates, 3);
 
-	ACCESS_ONCE(ads->ds_ctl7) = set11nRateFlags(i->rates, 0)
+	ACCESS_ONCE_RW(ads->ds_ctl7) = set11nRateFlags(i->rates, 0)
 		| set11nRateFlags(i->rates, 1)
 		| set11nRateFlags(i->rates, 2)
 		| set11nRateFlags(i->rates, 3)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/ath/ath9k/ar9003_mac.c linux-3.2.71-pax/drivers/net/wireless/ath/ath9k/ar9003_mac.c
--- linux-3.2.71/drivers/net/wireless/ath/ath9k/ar9003_mac.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/wireless/ath/ath9k/ar9003_mac.c	2012-07-04 19:24:48.564063008 +0200
@@ -35,47 +35,47 @@ ar9003_set_txdesc(struct ath_hw *ah, voi
 	      (i->qcu << AR_TxQcuNum_S) | 0x17;
 
 	checksum += val;
-	ACCESS_ONCE(ads->info) = val;
+	ACCESS_ONCE_RW(ads->info) = val;
 
 	checksum += i->link;
-	ACCESS_ONCE(ads->link) = i->link;
+	ACCESS_ONCE_RW(ads->link) = i->link;
 
 	checksum += i->buf_addr[0];
-	ACCESS_ONCE(ads->data0) = i->buf_addr[0];
+	ACCESS_ONCE_RW(ads->data0) = i->buf_addr[0];
 	checksum += i->buf_addr[1];
-	ACCESS_ONCE(ads->data1) = i->buf_addr[1];
+	ACCESS_ONCE_RW(ads->data1) = i->buf_addr[1];
 	checksum += i->buf_addr[2];
-	ACCESS_ONCE(ads->data2) = i->buf_addr[2];
+	ACCESS_ONCE_RW(ads->data2) = i->buf_addr[2];
 	checksum += i->buf_addr[3];
-	ACCESS_ONCE(ads->data3) = i->buf_addr[3];
+	ACCESS_ONCE_RW(ads->data3) = i->buf_addr[3];
 
 	checksum += (val = (i->buf_len[0] << AR_BufLen_S) & AR_BufLen);
-	ACCESS_ONCE(ads->ctl3) = val;
+	ACCESS_ONCE_RW(ads->ctl3) = val;
 	checksum += (val = (i->buf_len[1] << AR_BufLen_S) & AR_BufLen);
-	ACCESS_ONCE(ads->ctl5) = val;
+	ACCESS_ONCE_RW(ads->ctl5) = val;
 	checksum += (val = (i->buf_len[2] << AR_BufLen_S) & AR_BufLen);
-	ACCESS_ONCE(ads->ctl7) = val;
+	ACCESS_ONCE_RW(ads->ctl7) = val;
 	checksum += (val = (i->buf_len[3] << AR_BufLen_S) & AR_BufLen);
-	ACCESS_ONCE(ads->ctl9) = val;
+	ACCESS_ONCE_RW(ads->ctl9) = val;
 
 	checksum = (u16) (((checksum & 0xffff) + (checksum >> 16)) & 0xffff);
-	ACCESS_ONCE(ads->ctl10) = checksum;
+	ACCESS_ONCE_RW(ads->ctl10) = checksum;
 
 	if (i->is_first || i->is_last) {
-		ACCESS_ONCE(ads->ctl13) = set11nTries(i->rates, 0)
+		ACCESS_ONCE_RW(ads->ctl13) = set11nTries(i->rates, 0)
 			| set11nTries(i->rates, 1)
 			| set11nTries(i->rates, 2)
 			| set11nTries(i->rates, 3)
 			| (i->dur_update ? AR_DurUpdateEna : 0)
 			| SM(0, AR_BurstDur);
 
-		ACCESS_ONCE(ads->ctl14) = set11nRate(i->rates, 0)
+		ACCESS_ONCE_RW(ads->ctl14) = set11nRate(i->rates, 0)
 			| set11nRate(i->rates, 1)
 			| set11nRate(i->rates, 2)
 			| set11nRate(i->rates, 3);
 	} else {
-		ACCESS_ONCE(ads->ctl13) = 0;
-		ACCESS_ONCE(ads->ctl14) = 0;
+		ACCESS_ONCE_RW(ads->ctl13) = 0;
+		ACCESS_ONCE_RW(ads->ctl14) = 0;
 	}
 
 	ads->ctl20 = 0;
@@ -84,17 +84,17 @@ ar9003_set_txdesc(struct ath_hw *ah, voi
 
 	ctl17 = SM(i->keytype, AR_EncrType);
 	if (!i->is_first) {
-		ACCESS_ONCE(ads->ctl11) = 0;
-		ACCESS_ONCE(ads->ctl12) = i->is_last ? 0 : AR_TxMore;
-		ACCESS_ONCE(ads->ctl15) = 0;
-		ACCESS_ONCE(ads->ctl16) = 0;
-		ACCESS_ONCE(ads->ctl17) = ctl17;
-		ACCESS_ONCE(ads->ctl18) = 0;
-		ACCESS_ONCE(ads->ctl19) = 0;
+		ACCESS_ONCE_RW(ads->ctl11) = 0;
+		ACCESS_ONCE_RW(ads->ctl12) = i->is_last ? 0 : AR_TxMore;
+		ACCESS_ONCE_RW(ads->ctl15) = 0;
+		ACCESS_ONCE_RW(ads->ctl16) = 0;
+		ACCESS_ONCE_RW(ads->ctl17) = ctl17;
+		ACCESS_ONCE_RW(ads->ctl18) = 0;
+		ACCESS_ONCE_RW(ads->ctl19) = 0;
 		return;
 	}
 
-	ACCESS_ONCE(ads->ctl11) = (i->pkt_len & AR_FrameLen)
+	ACCESS_ONCE_RW(ads->ctl11) = (i->pkt_len & AR_FrameLen)
 		| (i->flags & ATH9K_TXDESC_VMF ? AR_VirtMoreFrag : 0)
 		| SM(i->txpower, AR_XmitPower)
 		| (i->flags & ATH9K_TXDESC_VEOL ? AR_VEOL : 0)
@@ -130,22 +130,22 @@ ar9003_set_txdesc(struct ath_hw *ah, voi
 	val = (i->flags & ATH9K_TXDESC_PAPRD) >> ATH9K_TXDESC_PAPRD_S;
 	ctl12 |= SM(val, AR_PAPRDChainMask);
 
-	ACCESS_ONCE(ads->ctl12) = ctl12;
-	ACCESS_ONCE(ads->ctl17) = ctl17;
+	ACCESS_ONCE_RW(ads->ctl12) = ctl12;
+	ACCESS_ONCE_RW(ads->ctl17) = ctl17;
 
-	ACCESS_ONCE(ads->ctl15) = set11nPktDurRTSCTS(i->rates, 0)
+	ACCESS_ONCE_RW(ads->ctl15) = set11nPktDurRTSCTS(i->rates, 0)
 		| set11nPktDurRTSCTS(i->rates, 1);
 
-	ACCESS_ONCE(ads->ctl16) = set11nPktDurRTSCTS(i->rates, 2)
+	ACCESS_ONCE_RW(ads->ctl16) = set11nPktDurRTSCTS(i->rates, 2)
 		| set11nPktDurRTSCTS(i->rates, 3);
 
-	ACCESS_ONCE(ads->ctl18) = set11nRateFlags(i->rates, 0)
+	ACCESS_ONCE_RW(ads->ctl18) = set11nRateFlags(i->rates, 0)
 		| set11nRateFlags(i->rates, 1)
 		| set11nRateFlags(i->rates, 2)
 		| set11nRateFlags(i->rates, 3)
 		| SM(i->rtscts_rate, AR_RTSCTSRate);
 
-	ACCESS_ONCE(ads->ctl19) = AR_Not_Sounding;
+	ACCESS_ONCE_RW(ads->ctl19) = AR_Not_Sounding;
 }
 
 static u16 ar9003_calc_ptr_chksum(struct ar9003_txc *ads)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/ath/ath9k/hw.h linux-3.2.71-pax/drivers/net/wireless/ath/ath9k/hw.h
--- linux-3.2.71/drivers/net/wireless/ath/ath9k/hw.h	2015-02-20 12:37:33.109178774 +0100
+++ linux-3.2.71-pax/drivers/net/wireless/ath/ath9k/hw.h	2015-02-20 12:37:41.877178306 +0100
@@ -607,7 +607,7 @@ struct ath_hw_private_ops {
 
 	/* ANI */
 	void (*ani_cache_ini_regs)(struct ath_hw *ah);
-};
+} __no_const;
 
 /**
  * struct ath_hw_ops - callbacks used by hardware code and driver code
@@ -637,7 +637,7 @@ struct ath_hw_ops {
 	void (*antdiv_comb_conf_set)(struct ath_hw *ah,
 			struct ath_hw_antcomb_conf *antconf);
 
-};
+} __no_const;
 
 struct ath_nf_limits {
 	s16 max;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/b43/phy_lp.c linux-3.2.71-pax/drivers/net/wireless/b43/phy_lp.c
--- linux-3.2.71/drivers/net/wireless/b43/phy_lp.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/wireless/b43/phy_lp.c	2013-11-12 01:29:11.093397763 +0100
@@ -2520,7 +2520,7 @@ static int lpphy_b2063_tune(struct b43_w
 {
 	struct ssb_bus *bus = dev->dev->sdev->bus;
 
-	static const struct b206x_channel *chandata = NULL;
+	const struct b206x_channel *chandata = NULL;
 	u32 crystal_freq = bus->chipco.pmu.crystalfreq * 1000;
 	u32 freqref, vco_freq, val1, val2, val3, timeout, timeoutref, count;
 	u16 old_comm15, scale;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/brcm80211/brcmfmac/wl_cfg80211.h linux-3.2.71-pax/drivers/net/wireless/brcm80211/brcmfmac/wl_cfg80211.h
--- linux-3.2.71/drivers/net/wireless/brcm80211/brcmfmac/wl_cfg80211.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/wireless/brcm80211/brcmfmac/wl_cfg80211.h	2013-01-16 21:41:38.922816745 +0100
@@ -175,7 +175,7 @@ struct brcmf_cfg80211_event_loop {
 				     struct net_device *ndev,
 				     const struct brcmf_event_msg *e,
 				     void *data);
-};
+} __no_const;
 
 /* representing interface of cfg80211 plane */
 struct brcmf_cfg80211_iface {
@@ -239,7 +239,7 @@ struct brcmf_cfg80211_profile {
 struct brcmf_cfg80211_iscan_eloop {
 	s32 (*handler[WL_SCAN_ERSULTS_LAST])
 		(struct brcmf_cfg80211_priv *cfg_priv);
-};
+} __no_const;
 
 /* dongle iscan controller */
 struct brcmf_cfg80211_iscan_ctrl {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/iwlegacy/iwl3945-base.c linux-3.2.71-pax/drivers/net/wireless/iwlegacy/iwl3945-base.c
--- linux-3.2.71/drivers/net/wireless/iwlegacy/iwl3945-base.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/wireless/iwlegacy/iwl3945-base.c	2012-07-04 19:24:48.568063008 +0200
@@ -3685,7 +3685,9 @@ static int iwl3945_pci_probe(struct pci_
 	 */
 	if (iwl3945_mod_params.disable_hw_scan) {
 		IWL_DEBUG_INFO(priv, "Disabling hw_scan\n");
-		iwl3945_hw_ops.hw_scan = NULL;
+		pax_open_kernel();
+		*(void **)&iwl3945_hw_ops.hw_scan = NULL;
+		pax_close_kernel();
 	}
 
 	IWL_DEBUG_INFO(priv, "*** LOAD DRIVER ***\n");
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/iwlwifi/iwl-debugfs.c linux-3.2.71-pax/drivers/net/wireless/iwlwifi/iwl-debugfs.c
--- linux-3.2.71/drivers/net/wireless/iwlwifi/iwl-debugfs.c	2012-09-20 01:42:17.294672774 +0200
+++ linux-3.2.71-pax/drivers/net/wireless/iwlwifi/iwl-debugfs.c	2013-08-17 01:57:36.852234357 +0200
@@ -163,7 +163,7 @@ static ssize_t iwl_dbgfs_clear_traffic_s
 	struct iwl_priv *priv = file->private_data;
 	u32 clear_flag;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 
 	memset(buf, 0, sizeof(buf));
 	buf_size = min(count, sizeof(buf) -  1);
@@ -311,7 +311,7 @@ static ssize_t iwl_dbgfs_sram_write(stru
 {
 	struct iwl_priv *priv = file->private_data;
 	char buf[64];
-	int buf_size;
+	size_t buf_size;
 	u32 offset, len;
 
 	memset(buf, 0, sizeof(buf));
@@ -601,7 +601,7 @@ static ssize_t iwl_dbgfs_rx_handlers_wri
 	struct iwl_priv *priv = file->private_data;
 
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	u32 reset_flag;
 
 	memset(buf, 0, sizeof(buf));
@@ -682,7 +682,7 @@ static ssize_t iwl_dbgfs_disable_ht40_wr
 {
 	struct iwl_priv *priv = file->private_data;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	int ht40;
 
 	memset(buf, 0, sizeof(buf));
@@ -737,7 +737,7 @@ static ssize_t iwl_dbgfs_sleep_level_ove
 {
 	struct iwl_priv *priv = file->private_data;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	int value;
 
 	memset(buf, 0, sizeof(buf));
@@ -897,7 +897,7 @@ static ssize_t iwl_dbgfs_traffic_log_wri
 {
 	struct iwl_priv *priv = file->private_data;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	int traffic_log;
 
 	memset(buf, 0, sizeof(buf));
@@ -912,10 +912,10 @@ static ssize_t iwl_dbgfs_traffic_log_wri
 	return count;
 }
 
-static const char *fmt_value = "  %-30s %10u\n";
-static const char *fmt_hex   = "  %-30s       0x%02X\n";
-static const char *fmt_table = "  %-30s %10u  %10u  %10u  %10u\n";
-static const char *fmt_header =
+static const char fmt_value[] = "  %-30s %10u\n";
+static const char fmt_hex[]   = "  %-30s       0x%02X\n";
+static const char fmt_table[] = "  %-30s %10u  %10u  %10u  %10u\n";
+static const char fmt_header[] =
 	"%-32s    current  cumulative       delta         max\n";
 
 static int iwl_statistics_flag(struct iwl_priv *priv, char *buf, int bufsz)
@@ -2078,7 +2078,7 @@ static ssize_t iwl_dbgfs_clear_ucode_sta
 {
 	struct iwl_priv *priv = file->private_data;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	int clear;
 
 	memset(buf, 0, sizeof(buf));
@@ -2123,7 +2123,7 @@ static ssize_t iwl_dbgfs_ucode_tracing_w
 {
 	struct iwl_priv *priv = file->private_data;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	int trace;
 
 	memset(buf, 0, sizeof(buf));
@@ -2193,7 +2193,7 @@ static ssize_t iwl_dbgfs_missed_beacon_w
 {
 	struct iwl_priv *priv = file->private_data;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	int missed;
 
 	memset(buf, 0, sizeof(buf));
@@ -2234,7 +2234,7 @@ static ssize_t iwl_dbgfs_plcp_delta_writ
 
 	struct iwl_priv *priv = file->private_data;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	int plcp;
 
 	memset(buf, 0, sizeof(buf));
@@ -2288,7 +2288,7 @@ static ssize_t iwl_dbgfs_force_reset_wri
 
 	struct iwl_priv *priv = file->private_data;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	int reset, ret;
 
 	memset(buf, 0, sizeof(buf));
@@ -2314,7 +2314,7 @@ static ssize_t iwl_dbgfs_txfifo_flush_wr
 
 	struct iwl_priv *priv = file->private_data;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	int flush;
 
 	memset(buf, 0, sizeof(buf));
@@ -2338,7 +2338,7 @@ static ssize_t iwl_dbgfs_wd_timeout_writ
 {
 	struct iwl_priv *priv = file->private_data;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	int timeout;
 
 	memset(buf, 0, sizeof(buf));
@@ -2427,7 +2427,7 @@ static ssize_t iwl_dbgfs_protection_mode
 
 	struct iwl_priv *priv = file->private_data;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	int rts;
 
 	if (!priv->cfg->ht_params)
@@ -2452,7 +2452,7 @@ static ssize_t iwl_dbgfs_echo_test_write
 {
 	struct iwl_priv *priv = file->private_data;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 
 	memset(buf, 0, sizeof(buf));
 	buf_size = min(count, sizeof(buf) -  1);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/iwlwifi/iwl-debug.h linux-3.2.71-pax/drivers/net/wireless/iwlwifi/iwl-debug.h
--- linux-3.2.71/drivers/net/wireless/iwlwifi/iwl-debug.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/wireless/iwlwifi/iwl-debug.h	2012-07-04 19:24:48.568063008 +0200
@@ -71,8 +71,8 @@ do {
 } while (0)
 
 #else
-#define IWL_DEBUG(m, level, fmt, args...)
-#define IWL_DEBUG_LIMIT(m, level, fmt, args...)
+#define IWL_DEBUG(m, level, fmt, args...) do {} while (0)
+#define IWL_DEBUG_LIMIT(m, level, fmt, args...) do {} while (0)
 #define iwl_print_hex_dump(m, level, p, len)
 #endif				/* CONFIG_IWLWIFI_DEBUG */
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/iwlwifi/iwl-trans-pcie.c linux-3.2.71-pax/drivers/net/wireless/iwlwifi/iwl-trans-pcie.c
--- linux-3.2.71/drivers/net/wireless/iwlwifi/iwl-trans-pcie.c	2012-09-20 01:42:17.294672774 +0200
+++ linux-3.2.71-pax/drivers/net/wireless/iwlwifi/iwl-trans-pcie.c	2012-09-20 01:42:29.910672813 +0200
@@ -1890,7 +1890,7 @@ static ssize_t iwl_dbgfs_interrupt_write
 	struct isr_statistics *isr_stats = &trans_pcie->isr_stats;
 
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	u32 reset_flag;
 
 	memset(buf, 0, sizeof(buf));
@@ -1911,7 +1911,7 @@ static ssize_t iwl_dbgfs_csr_write(struc
 {
 	struct iwl_trans *trans = file->private_data;
 	char buf[8];
-	int buf_size;
+	size_t buf_size;
 	int csr;
 
 	memset(buf, 0, sizeof(buf));
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/mac80211_hwsim.c linux-3.2.71-pax/drivers/net/wireless/mac80211_hwsim.c
--- linux-3.2.71/drivers/net/wireless/mac80211_hwsim.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/wireless/mac80211_hwsim.c	2012-07-04 19:24:48.572063007 +0200
@@ -1678,9 +1678,11 @@ static int __init init_mac80211_hwsim(vo
 		return -EINVAL;
 
 	if (fake_hw_scan) {
-		mac80211_hwsim_ops.hw_scan = mac80211_hwsim_hw_scan;
-		mac80211_hwsim_ops.sw_scan_start = NULL;
-		mac80211_hwsim_ops.sw_scan_complete = NULL;
+		pax_open_kernel();
+		*(void **)&mac80211_hwsim_ops.hw_scan = mac80211_hwsim_hw_scan;
+		*(void **)&mac80211_hwsim_ops.sw_scan_start = NULL;
+		*(void **)&mac80211_hwsim_ops.sw_scan_complete = NULL;
+		pax_close_kernel();
 	}
 
 	spin_lock_init(&hwsim_radio_lock);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/rndis_wlan.c linux-3.2.71-pax/drivers/net/wireless/rndis_wlan.c
--- linux-3.2.71/drivers/net/wireless/rndis_wlan.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/wireless/rndis_wlan.c	2012-07-04 19:24:48.572063007 +0200
@@ -1275,7 +1275,7 @@ static int set_rts_threshold(struct usbn
 
 	netdev_dbg(usbdev->net, "%s(): %i\n", __func__, rts_threshold);
 
-	if (rts_threshold < 0 || rts_threshold > 2347)
+	if (rts_threshold > 2347)
 		rts_threshold = 2347;
 
 	tmp = cpu_to_le32(rts_threshold);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/net/wireless/wl1251/sdio.c linux-3.2.71-pax/drivers/net/wireless/wl1251/sdio.c
--- linux-3.2.71/drivers/net/wireless/wl1251/sdio.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/net/wireless/wl1251/sdio.c	2013-01-16 23:23:54.250674965 +0100
@@ -269,13 +269,17 @@ static int wl1251_sdio_probe(struct sdio
 
 		irq_set_irq_type(wl->irq, IRQ_TYPE_EDGE_RISING);
 
-		wl1251_sdio_ops.enable_irq = wl1251_enable_line_irq;
-		wl1251_sdio_ops.disable_irq = wl1251_disable_line_irq;
+		pax_open_kernel();
+		*(void **)&wl1251_sdio_ops.enable_irq = wl1251_enable_line_irq;
+		*(void **)&wl1251_sdio_ops.disable_irq = wl1251_disable_line_irq;
+		pax_close_kernel();
 
 		wl1251_info("using dedicated interrupt line");
 	} else {
-		wl1251_sdio_ops.enable_irq = wl1251_sdio_enable_irq;
-		wl1251_sdio_ops.disable_irq = wl1251_sdio_disable_irq;
+		pax_open_kernel();
+		*(void **)&wl1251_sdio_ops.enable_irq = wl1251_sdio_enable_irq;
+		*(void **)&wl1251_sdio_ops.disable_irq = wl1251_sdio_disable_irq;
+		pax_close_kernel();
 
 		wl1251_info("using SDIO interrupt");
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/nfc/nfcwilink.c linux-3.2.71-pax/drivers/nfc/nfcwilink.c
--- linux-3.2.71/drivers/nfc/nfcwilink.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/nfc/nfcwilink.c	2013-11-12 01:29:31.505396673 +0100
@@ -237,7 +237,7 @@ static struct nci_ops nfcwilink_ops = {
 
 static int nfcwilink_probe(struct platform_device *pdev)
 {
-	static struct nfcwilink *drv;
+	struct nfcwilink *drv;
 	int rc;
 	u32 protocols;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/oprofile/buffer_sync.c linux-3.2.71-pax/drivers/oprofile/buffer_sync.c
--- linux-3.2.71/drivers/oprofile/buffer_sync.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/oprofile/buffer_sync.c	2012-07-04 19:24:48.572063007 +0200
@@ -343,7 +343,7 @@ static void add_data(struct op_entry *en
 		if (cookie == NO_COOKIE)
 			offset = pc;
 		if (cookie == INVALID_COOKIE) {
-			atomic_inc(&oprofile_stats.sample_lost_no_mapping);
+			atomic_inc_unchecked(&oprofile_stats.sample_lost_no_mapping);
 			offset = pc;
 		}
 		if (cookie != last_cookie) {
@@ -387,14 +387,14 @@ add_sample(struct mm_struct *mm, struct
 	/* add userspace sample */
 
 	if (!mm) {
-		atomic_inc(&oprofile_stats.sample_lost_no_mm);
+		atomic_inc_unchecked(&oprofile_stats.sample_lost_no_mm);
 		return 0;
 	}
 
 	cookie = lookup_dcookie(mm, s->eip, &offset);
 
 	if (cookie == INVALID_COOKIE) {
-		atomic_inc(&oprofile_stats.sample_lost_no_mapping);
+		atomic_inc_unchecked(&oprofile_stats.sample_lost_no_mapping);
 		return 0;
 	}
 
@@ -563,7 +563,7 @@ void sync_buffer(int cpu)
 		/* ignore backtraces if failed to add a sample */
 		if (state == sb_bt_start) {
 			state = sb_bt_ignore;
-			atomic_inc(&oprofile_stats.bt_lost_no_mapping);
+			atomic_inc_unchecked(&oprofile_stats.bt_lost_no_mapping);
 		}
 	}
 	release_mm(mm);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/oprofile/event_buffer.c linux-3.2.71-pax/drivers/oprofile/event_buffer.c
--- linux-3.2.71/drivers/oprofile/event_buffer.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/oprofile/event_buffer.c	2012-07-04 19:24:48.576063007 +0200
@@ -53,7 +53,7 @@ void add_event_entry(unsigned long value
 	}
 
 	if (buffer_pos == buffer_size) {
-		atomic_inc(&oprofile_stats.event_lost_overflow);
+		atomic_inc_unchecked(&oprofile_stats.event_lost_overflow);
 		return;
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/oprofile/oprof.c linux-3.2.71-pax/drivers/oprofile/oprof.c
--- linux-3.2.71/drivers/oprofile/oprof.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/oprofile/oprof.c	2012-07-04 19:24:48.576063007 +0200
@@ -110,7 +110,7 @@ static void switch_worker(struct work_st
 	if (oprofile_ops.switch_events())
 		return;
 
-	atomic_inc(&oprofile_stats.multiplex_counter);
+	atomic_inc_unchecked(&oprofile_stats.multiplex_counter);
 	start_switch_worker();
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/oprofile/oprofile_files.c linux-3.2.71-pax/drivers/oprofile/oprofile_files.c
--- linux-3.2.71/drivers/oprofile/oprofile_files.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/oprofile/oprofile_files.c	2013-03-28 04:10:58.179929538 +0100
@@ -27,7 +27,7 @@ unsigned long oprofile_time_slice;
 
 #ifdef CONFIG_OPROFILE_EVENT_MULTIPLEX
 
-static ssize_t timeout_read(struct file *file, char __user *buf,
+static ssize_t __intentional_overflow(-1) timeout_read(struct file *file, char __user *buf,
 		size_t count, loff_t *offset)
 {
 	return oprofilefs_ulong_to_user(jiffies_to_msecs(oprofile_time_slice),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/oprofile/oprofilefs.c linux-3.2.71-pax/drivers/oprofile/oprofilefs.c
--- linux-3.2.71/drivers/oprofile/oprofilefs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/oprofile/oprofilefs.c	2012-07-04 19:24:48.576063007 +0200
@@ -193,7 +193,7 @@ static const struct file_operations atom
 
 
 int oprofilefs_create_ro_atomic(struct super_block *sb, struct dentry *root,
-	char const *name, atomic_t *val)
+	char const *name, atomic_unchecked_t *val)
 {
 	return __oprofilefs_create_file(sb, root, name,
 					&atomic_ro_fops, 0444, val);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/oprofile/oprofile_stats.c linux-3.2.71-pax/drivers/oprofile/oprofile_stats.c
--- linux-3.2.71/drivers/oprofile/oprofile_stats.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/oprofile/oprofile_stats.c	2012-07-04 19:24:48.576063007 +0200
@@ -30,11 +30,11 @@ void oprofile_reset_stats(void)
 		cpu_buf->sample_invalid_eip = 0;
 	}
 
-	atomic_set(&oprofile_stats.sample_lost_no_mm, 0);
-	atomic_set(&oprofile_stats.sample_lost_no_mapping, 0);
-	atomic_set(&oprofile_stats.event_lost_overflow, 0);
-	atomic_set(&oprofile_stats.bt_lost_no_mapping, 0);
-	atomic_set(&oprofile_stats.multiplex_counter, 0);
+	atomic_set_unchecked(&oprofile_stats.sample_lost_no_mm, 0);
+	atomic_set_unchecked(&oprofile_stats.sample_lost_no_mapping, 0);
+	atomic_set_unchecked(&oprofile_stats.event_lost_overflow, 0);
+	atomic_set_unchecked(&oprofile_stats.bt_lost_no_mapping, 0);
+	atomic_set_unchecked(&oprofile_stats.multiplex_counter, 0);
 }
 
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/oprofile/oprofile_stats.h linux-3.2.71-pax/drivers/oprofile/oprofile_stats.h
--- linux-3.2.71/drivers/oprofile/oprofile_stats.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/oprofile/oprofile_stats.h	2012-07-04 19:24:48.576063007 +0200
@@ -13,11 +13,11 @@
 #include <linux/atomic.h>
 
 struct oprofile_stat_struct {
-	atomic_t sample_lost_no_mm;
-	atomic_t sample_lost_no_mapping;
-	atomic_t bt_lost_no_mapping;
-	atomic_t event_lost_overflow;
-	atomic_t multiplex_counter;
+	atomic_unchecked_t sample_lost_no_mm;
+	atomic_unchecked_t sample_lost_no_mapping;
+	atomic_unchecked_t bt_lost_no_mapping;
+	atomic_unchecked_t event_lost_overflow;
+	atomic_unchecked_t multiplex_counter;
 };
 
 extern struct oprofile_stat_struct oprofile_stats;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/oprofile/timer_int.c linux-3.2.71-pax/drivers/oprofile/timer_int.c
--- linux-3.2.71/drivers/oprofile/timer_int.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/oprofile/timer_int.c	2013-02-20 01:19:15.902027321 +0100
@@ -93,7 +93,7 @@ static int __cpuinit oprofile_cpu_notify
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __refdata oprofile_cpu_notifier = {
+static struct notifier_block oprofile_cpu_notifier = {
 	.notifier_call = oprofile_cpu_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/parport/procfs.c linux-3.2.71-pax/drivers/parport/procfs.c
--- linux-3.2.71/drivers/parport/procfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/parport/procfs.c	2012-07-04 19:24:48.576063007 +0200
@@ -64,7 +64,7 @@ static int do_active_device(ctl_table *t
 
 	*ppos += len;
 
-	return copy_to_user(result, buffer, len) ? -EFAULT : 0;
+	return (len > sizeof buffer || copy_to_user(result, buffer, len)) ? -EFAULT : 0;
 }
 
 #ifdef CONFIG_PARPORT_1284
@@ -106,7 +106,7 @@ static int do_autoprobe(ctl_table *table
 
 	*ppos += len;
 
-	return copy_to_user (result, buffer, len) ? -EFAULT : 0;
+	return (len > sizeof buffer || copy_to_user (result, buffer, len)) ? -EFAULT : 0;
 }
 #endif /* IEEE1284.3 support. */
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pci/hotplug/acpiphp_ibm.c linux-3.2.71-pax/drivers/pci/hotplug/acpiphp_ibm.c
--- linux-3.2.71/drivers/pci/hotplug/acpiphp_ibm.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/pci/hotplug/acpiphp_ibm.c	2013-03-28 01:35:23.288427949 +0100
@@ -464,7 +464,9 @@ static int __init ibm_acpiphp_init(void)
 		goto init_cleanup;
 	}
 
-	ibm_apci_table_attr.size = ibm_get_table_from_acpi(NULL);
+	pax_open_kernel();
+	*(size_t *)&ibm_apci_table_attr.size = ibm_get_table_from_acpi(NULL);
+	pax_close_kernel();
 	retval = sysfs_create_bin_file(sysdir, &ibm_apci_table_attr);
 
 	return retval;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pci/hotplug/cpcihp_generic.c linux-3.2.71-pax/drivers/pci/hotplug/cpcihp_generic.c
--- linux-3.2.71/drivers/pci/hotplug/cpcihp_generic.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/pci/hotplug/cpcihp_generic.c	2013-01-16 21:27:14.794836714 +0100
@@ -73,7 +73,6 @@ static u16 port;
 static unsigned int enum_bit;
 static u8 enum_mask;
 
-static struct cpci_hp_controller_ops generic_hpc_ops;
 static struct cpci_hp_controller generic_hpc;
 
 static int __init validate_parameters(void)
@@ -139,6 +138,10 @@ static int query_enum(void)
 	return ((value & enum_mask) == enum_mask);
 }
 
+static struct cpci_hp_controller_ops generic_hpc_ops = {
+	.query_enum = query_enum,
+};
+
 static int __init cpcihp_generic_init(void)
 {
 	int status;
@@ -169,7 +172,6 @@ static int __init cpcihp_generic_init(vo
 	pci_dev_put(dev);
 
 	memset(&generic_hpc, 0, sizeof (struct cpci_hp_controller));
-	generic_hpc_ops.query_enum = query_enum;
 	generic_hpc.ops = &generic_hpc_ops;
 
 	status = cpci_hp_register_controller(&generic_hpc);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pci/hotplug/cpcihp_zt5550.c linux-3.2.71-pax/drivers/pci/hotplug/cpcihp_zt5550.c
--- linux-3.2.71/drivers/pci/hotplug/cpcihp_zt5550.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/pci/hotplug/cpcihp_zt5550.c	2013-01-16 21:45:35.226811284 +0100
@@ -59,7 +59,6 @@
 /* local variables */
 static int debug;
 static int poll;
-static struct cpci_hp_controller_ops zt5550_hpc_ops;
 static struct cpci_hp_controller zt5550_hpc;
 
 /* Primary cPCI bus bridge device */
@@ -205,6 +204,10 @@ static int zt5550_hc_disable_irq(void)
 	return 0;
 }
 
+static struct cpci_hp_controller_ops zt5550_hpc_ops = {
+	.query_enum = zt5550_hc_query_enum,
+};
+
 static int zt5550_hc_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)
 {
 	int status;
@@ -216,16 +219,17 @@ static int zt5550_hc_init_one (struct pc
 	dbg("returned from zt5550_hc_config");
 
 	memset(&zt5550_hpc, 0, sizeof (struct cpci_hp_controller));
-	zt5550_hpc_ops.query_enum = zt5550_hc_query_enum;
 	zt5550_hpc.ops = &zt5550_hpc_ops;
 	if(!poll) {
 		zt5550_hpc.irq = hc_dev->irq;
 		zt5550_hpc.irq_flags = IRQF_SHARED;
 		zt5550_hpc.dev_id = hc_dev;
 
-		zt5550_hpc_ops.enable_irq = zt5550_hc_enable_irq;
-		zt5550_hpc_ops.disable_irq = zt5550_hc_disable_irq;
-		zt5550_hpc_ops.check_irq = zt5550_hc_check_irq;
+		pax_open_kernel();
+		*(void **)&zt5550_hpc_ops.enable_irq = zt5550_hc_enable_irq;
+		*(void **)&zt5550_hpc_ops.disable_irq = zt5550_hc_disable_irq;
+		*(void **)&zt5550_hpc_ops.check_irq = zt5550_hc_check_irq;
+		pax_open_kernel();
 	} else {
 		info("using ENUM# polling mode");
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pci/hotplug/cpqphp_nvram.c linux-3.2.71-pax/drivers/pci/hotplug/cpqphp_nvram.c
--- linux-3.2.71/drivers/pci/hotplug/cpqphp_nvram.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/pci/hotplug/cpqphp_nvram.c	2012-07-04 19:24:48.576063007 +0200
@@ -428,9 +428,13 @@ static u32 store_HRT (void __iomem *rom_
 
 void compaq_nvram_init (void __iomem *rom_start)
 {
+
+#ifndef CONFIG_PAX_KERNEXEC
 	if (rom_start) {
 		compaq_int15_entry_point = (rom_start + ROM_INT15_PHY_ADDR - ROM_PHY_ADDR);
 	}
+#endif
+
 	dbg("int15 entry  = %p\n", compaq_int15_entry_point);
 
 	/* initialize our int15 lock */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pci/hotplug/pciehp_core.c linux-3.2.71-pax/drivers/pci/hotplug/pciehp_core.c
--- linux-3.2.71/drivers/pci/hotplug/pciehp_core.c	2014-12-14 21:13:45.114054915 +0100
+++ linux-3.2.71-pax/drivers/pci/hotplug/pciehp_core.c	2014-12-14 21:13:52.786069247 +0100
@@ -91,7 +91,7 @@ static int init_slot(struct controller *
 	struct slot *slot = ctrl->slot;
 	struct hotplug_slot *hotplug = NULL;
 	struct hotplug_slot_info *info = NULL;
-	struct hotplug_slot_ops *ops = NULL;
+	hotplug_slot_ops_no_const *ops = NULL;
 	char name[SLOT_NAME_SIZE];
 	int retval = -ENOMEM;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pci/hotplug/pci_hotplug_core.c linux-3.2.71-pax/drivers/pci/hotplug/pci_hotplug_core.c
--- linux-3.2.71/drivers/pci/hotplug/pci_hotplug_core.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/pci/hotplug/pci_hotplug_core.c	2013-03-28 01:35:23.292427948 +0100
@@ -448,8 +448,10 @@ int __pci_hp_register(struct hotplug_slo
 		return -EINVAL;
 	}
 
-	slot->ops->owner = owner;
-	slot->ops->mod_name = mod_name;
+	pax_open_kernel();
+	*(struct module **)&slot->ops->owner = owner;
+	*(const char **)&slot->ops->mod_name = mod_name;
+	pax_close_kernel();
 
 	mutex_lock(&pci_hp_mutex);
 	/*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pci/pcie/aspm.c linux-3.2.71-pax/drivers/pci/pcie/aspm.c
--- linux-3.2.71/drivers/pci/pcie/aspm.c	2013-02-09 01:12:40.748782285 +0100
+++ linux-3.2.71-pax/drivers/pci/pcie/aspm.c	2013-02-09 01:12:47.000782469 +0100
@@ -27,9 +27,9 @@
 #define MODULE_PARAM_PREFIX "pcie_aspm."
 
 /* Note: those are not register definitions */
-#define ASPM_STATE_L0S_UP	(1)	/* Upstream direction L0s state */
-#define ASPM_STATE_L0S_DW	(2)	/* Downstream direction L0s state */
-#define ASPM_STATE_L1		(4)	/* L1 state */
+#define ASPM_STATE_L0S_UP	(1U)	/* Upstream direction L0s state */
+#define ASPM_STATE_L0S_DW	(2U)	/* Downstream direction L0s state */
+#define ASPM_STATE_L1		(4U)	/* L1 state */
 #define ASPM_STATE_L0S		(ASPM_STATE_L0S_UP | ASPM_STATE_L0S_DW)
 #define ASPM_STATE_ALL		(ASPM_STATE_L0S | ASPM_STATE_L1)
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pci/pcie/portdrv_pci.c linux-3.2.71-pax/drivers/pci/pcie/portdrv_pci.c
--- linux-3.2.71/drivers/pci/pcie/portdrv_pci.c	2014-01-03 15:48:44.932070568 +0100
+++ linux-3.2.71-pax/drivers/pci/pcie/portdrv_pci.c	2015-04-30 03:07:38.404532395 +0200
@@ -337,7 +337,7 @@ static int __init dmi_pcie_pme_disable_m
 	return 0;
 }
 
-static struct dmi_system_id __initdata pcie_portdrv_dmi_table[] = {
+static const struct dmi_system_id __initconst pcie_portdrv_dmi_table[] = {
 	/*
 	 * Boxes that should not use MSI for PCIe PME signaling.
 	 */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pci/pci.h linux-3.2.71-pax/drivers/pci/pci.h
--- linux-3.2.71/drivers/pci/pci.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/pci/pci.h	2013-03-28 01:35:23.292427948 +0100
@@ -101,7 +101,7 @@ struct pci_vpd_ops {
 struct pci_vpd {
 	unsigned int len;
 	const struct pci_vpd_ops *ops;
-	struct bin_attribute *attr; /* descriptor for sysfs VPD entry */
+	bin_attribute_no_const *attr; /* descriptor for sysfs VPD entry */
 };
 
 extern int pci_vpd_pci22_init(struct pci_dev *dev);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pci/pci-sysfs.c linux-3.2.71-pax/drivers/pci/pci-sysfs.c
--- linux-3.2.71/drivers/pci/pci-sysfs.c	2014-12-14 21:13:45.114054915 +0100
+++ linux-3.2.71-pax/drivers/pci/pci-sysfs.c	2014-12-14 21:13:52.786069247 +0100
@@ -950,7 +950,7 @@ static int pci_create_attr(struct pci_de
 {
 	/* allocate attribute structure, piggyback attribute name */
 	int name_len = write_combine ? 13 : 10;
-	struct bin_attribute *res_attr;
+	bin_attribute_no_const *res_attr;
 	int retval;
 
 	res_attr = kzalloc(sizeof(*res_attr) + name_len, GFP_ATOMIC);
@@ -1135,7 +1135,7 @@ static struct device_attribute reset_att
 static int pci_create_capabilities_sysfs(struct pci_dev *dev)
 {
 	int retval;
-	struct bin_attribute *attr;
+	bin_attribute_no_const *attr;
 
 	/* If the device has VPD, try to expose it in sysfs. */
 	if (dev->vpd) {
@@ -1182,7 +1182,7 @@ int __must_check pci_create_sysfs_dev_fi
 {
 	int retval;
 	int rom_size = 0;
-	struct bin_attribute *attr;
+	bin_attribute_no_const *attr;
 
 	if (!sysfs_initialized)
 		return -EACCES;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pci/probe.c linux-3.2.71-pax/drivers/pci/probe.c
--- linux-3.2.71/drivers/pci/probe.c	2015-02-20 12:37:33.121178774 +0100
+++ linux-3.2.71-pax/drivers/pci/probe.c	2015-02-20 12:37:41.877178306 +0100
@@ -136,7 +136,7 @@ int __pci_read_base(struct pci_dev *dev,
 	u32 l, sz, mask;
 	u16 orig_cmd;
 
-	mask = type ? PCI_ROM_ADDRESS_MASK : ~0;
+	mask = type ? (u32)PCI_ROM_ADDRESS_MASK : ~0;
 
 	if (!dev->mmio_always_on) {
 		pci_read_config_word(dev, PCI_COMMAND, &orig_cmd);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/platform/x86/compal-laptop.c linux-3.2.71-pax/drivers/platform/x86/compal-laptop.c
--- linux-3.2.71/drivers/platform/x86/compal-laptop.c	2015-08-07 11:37:20.511789892 +0200
+++ linux-3.2.71-pax/drivers/platform/x86/compal-laptop.c	2015-08-07 11:37:43.007790553 +0200
@@ -775,7 +775,7 @@ static int dmi_check_cb_extra(const stru
 	return 1;
 }
 
-static struct dmi_system_id __initdata compal_dmi_table[] = {
+static const struct dmi_system_id __initconst compal_dmi_table[] = {
 	{
 		.ident = "FL90/IFL90",
 		.matches = {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/platform/x86/hdaps.c linux-3.2.71-pax/drivers/platform/x86/hdaps.c
--- linux-3.2.71/drivers/platform/x86/hdaps.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/platform/x86/hdaps.c	2015-04-30 03:07:38.404532395 +0200
@@ -511,7 +511,7 @@ static int __init hdaps_dmi_match_invert
    "ThinkPad T42p", so the order of the entries matters.
    If your ThinkPad is not recognized, please update to latest
    BIOS. This is especially the case for some R52 ThinkPads. */
-static struct dmi_system_id __initdata hdaps_whitelist[] = {
+static const struct dmi_system_id __initconst hdaps_whitelist[] = {
 	HDAPS_DMI_MATCH_INVERT("IBM", "ThinkPad R50p", HDAPS_BOTH_AXES),
 	HDAPS_DMI_MATCH_NORMAL("IBM", "ThinkPad R50"),
 	HDAPS_DMI_MATCH_NORMAL("IBM", "ThinkPad R51"),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/platform/x86/ibm_rtl.c linux-3.2.71-pax/drivers/platform/x86/ibm_rtl.c
--- linux-3.2.71/drivers/platform/x86/ibm_rtl.c	2013-02-09 01:12:40.748782285 +0100
+++ linux-3.2.71-pax/drivers/platform/x86/ibm_rtl.c	2015-04-30 03:07:38.404532395 +0200
@@ -238,7 +238,7 @@ static void rtl_teardown_sysfs(void) {
 }
 
 
-static struct dmi_system_id __initdata ibm_rtl_dmi_table[] = {
+static const struct dmi_system_id __initconst ibm_rtl_dmi_table[] = {
 	{                                                  \
 		.matches = {                               \
 			DMI_MATCH(DMI_SYS_VENDOR, "IBM"),  \
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/platform/x86/intel_oaktrail.c linux-3.2.71-pax/drivers/platform/x86/intel_oaktrail.c
--- linux-3.2.71/drivers/platform/x86/intel_oaktrail.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/platform/x86/intel_oaktrail.c	2015-04-30 03:07:38.404532395 +0200
@@ -303,7 +303,7 @@ static int dmi_check_cb(const struct dmi
 	return 0;
 }
 
-static struct dmi_system_id __initdata oaktrail_dmi_table[] = {
+static const struct dmi_system_id __initconst oaktrail_dmi_table[] = {
 	{
 		.ident = "OakTrail platform",
 		.matches = {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/platform/x86/msi-laptop.c linux-3.2.71-pax/drivers/platform/x86/msi-laptop.c
--- linux-3.2.71/drivers/platform/x86/msi-laptop.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/platform/x86/msi-laptop.c	2015-04-30 03:07:38.396532395 +0200
@@ -451,7 +451,7 @@ static int dmi_check_cb(const struct dmi
 	return 1;
 }
 
-static struct dmi_system_id __initdata msi_dmi_table[] = {
+static const struct dmi_system_id __initconst msi_dmi_table[] = {
 	{
 		.ident = "MSI S270",
 		.matches = {
@@ -815,12 +815,14 @@ static int __init load_scm_model_init(st
 	int result;
 
 	/* allow userland write sysfs file  */
-	dev_attr_bluetooth.store = store_bluetooth;
-	dev_attr_wlan.store = store_wlan;
-	dev_attr_threeg.store = store_threeg;
-	dev_attr_bluetooth.attr.mode |= S_IWUSR;
-	dev_attr_wlan.attr.mode |= S_IWUSR;
-	dev_attr_threeg.attr.mode |= S_IWUSR;
+	pax_open_kernel();
+	*(void **)&dev_attr_bluetooth.store = store_bluetooth;
+	*(void **)&dev_attr_wlan.store = store_wlan;
+	*(void **)&dev_attr_threeg.store = store_threeg;
+	*(umode_t *)&dev_attr_bluetooth.attr.mode |= S_IWUSR;
+	*(umode_t *)&dev_attr_wlan.attr.mode |= S_IWUSR;
+	*(umode_t *)&dev_attr_threeg.attr.mode |= S_IWUSR;
+	pax_close_kernel();
 
 	/* disable hardware control by fn key */
 	result = ec_read(MSI_STANDARD_EC_SCM_LOAD_ADDRESS, &data);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/platform/x86/msi-wmi.c linux-3.2.71-pax/drivers/platform/x86/msi-wmi.c
--- linux-3.2.71/drivers/platform/x86/msi-wmi.c	2013-04-30 00:45:09.559714481 +0200
+++ linux-3.2.71-pax/drivers/platform/x86/msi-wmi.c	2013-11-12 01:29:56.269395351 +0100
@@ -147,7 +147,7 @@ static const struct backlight_ops msi_ba
 static void msi_wmi_notify(u32 value, void *context)
 {
 	struct acpi_buffer response = { ACPI_ALLOCATE_BUFFER, NULL };
-	static struct key_entry *key;
+	struct key_entry *key;
 	union acpi_object *obj;
 	ktime_t cur;
 	acpi_status status;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/platform/x86/samsung-laptop.c linux-3.2.71-pax/drivers/platform/x86/samsung-laptop.c
--- linux-3.2.71/drivers/platform/x86/samsung-laptop.c	2013-02-09 01:12:40.748782285 +0100
+++ linux-3.2.71-pax/drivers/platform/x86/samsung-laptop.c	2015-04-30 03:12:07.096540295 +0200
@@ -543,7 +543,7 @@ static DEVICE_ATTR(performance_level, S_
 		   get_performance_level, set_performance_level);
 
 
-static struct dmi_system_id __initdata samsung_dmi_table[] = {
+static const struct dmi_system_id __initconst samsung_dmi_table[] = {
 	{
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/platform/x86/samsung-q10.c linux-3.2.71-pax/drivers/platform/x86/samsung-q10.c
--- linux-3.2.71/drivers/platform/x86/samsung-q10.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/platform/x86/samsung-q10.c	2015-04-30 03:07:38.404532395 +0200
@@ -130,7 +130,7 @@ static int __init dmi_check_callback(con
 	return 1;
 }
 
-static struct dmi_system_id __initdata samsungq10_dmi_table[] = {
+static const struct dmi_system_id __initconst samsungq10_dmi_table[] = {
 	{
 		.ident = "Samsung Q10",
 		.matches = {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/platform/x86/sony-laptop.c linux-3.2.71-pax/drivers/platform/x86/sony-laptop.c
--- linux-3.2.71/drivers/platform/x86/sony-laptop.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/platform/x86/sony-laptop.c	2015-04-30 03:11:47.352539715 +0200
@@ -3385,7 +3385,7 @@ static struct acpi_driver sony_pic_drive
 		},
 };
 
-static struct dmi_system_id __initdata sonypi_dmi_table[] = {
+static const struct dmi_system_id __initconst sonypi_dmi_table[] = {
 	{
 		.ident = "Sony Vaio",
 		.matches = {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/platform/x86/thinkpad_acpi.c linux-3.2.71-pax/drivers/platform/x86/thinkpad_acpi.c
--- linux-3.2.71/drivers/platform/x86/thinkpad_acpi.c	2014-06-10 10:59:38.778436243 +0200
+++ linux-3.2.71-pax/drivers/platform/x86/thinkpad_acpi.c	2014-06-10 10:59:44.162435956 +0200
@@ -2094,7 +2094,7 @@ static int hotkey_mask_get(void)
 	return 0;
 }
 
-void static hotkey_mask_warn_incomplete_mask(void)
+static void hotkey_mask_warn_incomplete_mask(void)
 {
 	/* log only what the user can fix... */
 	const u32 wantedmask = hotkey_driver_mask &
@@ -2325,11 +2325,6 @@ static void hotkey_read_nvram(struct tp_
 	}
 }
 
-static void hotkey_compare_and_issue_event(struct tp_nvram_state *oldn,
-					   struct tp_nvram_state *newn,
-					   const u32 event_mask)
-{
-
 #define TPACPI_COMPARE_KEY(__scancode, __member) \
 	do { \
 		if ((event_mask & (1 << __scancode)) && \
@@ -2343,36 +2338,42 @@ static void hotkey_compare_and_issue_eve
 			tpacpi_hotkey_send_key(__scancode); \
 	} while (0)
 
-	void issue_volchange(const unsigned int oldvol,
-			     const unsigned int newvol)
-	{
-		unsigned int i = oldvol;
-
-		while (i > newvol) {
-			TPACPI_MAY_SEND_KEY(TP_ACPI_HOTKEYSCAN_VOLUMEDOWN);
-			i--;
-		}
-		while (i < newvol) {
-			TPACPI_MAY_SEND_KEY(TP_ACPI_HOTKEYSCAN_VOLUMEUP);
-			i++;
-		}
+static void issue_volchange(const unsigned int oldvol,
+			    const unsigned int newvol,
+			    const u32 event_mask)
+{
+	unsigned int i = oldvol;
+
+	while (i > newvol) {
+		TPACPI_MAY_SEND_KEY(TP_ACPI_HOTKEYSCAN_VOLUMEDOWN);
+		i--;
 	}
+	while (i < newvol) {
+		TPACPI_MAY_SEND_KEY(TP_ACPI_HOTKEYSCAN_VOLUMEUP);
+		i++;
+	}
+}
 
-	void issue_brightnesschange(const unsigned int oldbrt,
-				    const unsigned int newbrt)
-	{
-		unsigned int i = oldbrt;
+static void issue_brightnesschange(const unsigned int oldbrt,
+				   const unsigned int newbrt,
+				   const u32 event_mask)
+{
+	unsigned int i = oldbrt;
 
-		while (i > newbrt) {
-			TPACPI_MAY_SEND_KEY(TP_ACPI_HOTKEYSCAN_FNEND);
-			i--;
-		}
-		while (i < newbrt) {
-			TPACPI_MAY_SEND_KEY(TP_ACPI_HOTKEYSCAN_FNHOME);
-			i++;
-		}
+	while (i > newbrt) {
+		TPACPI_MAY_SEND_KEY(TP_ACPI_HOTKEYSCAN_FNEND);
+		i--;
+	}
+	while (i < newbrt) {
+		TPACPI_MAY_SEND_KEY(TP_ACPI_HOTKEYSCAN_FNHOME);
+		i++;
 	}
+}
 
+static void hotkey_compare_and_issue_event(struct tp_nvram_state *oldn,
+					   struct tp_nvram_state *newn,
+					   const u32 event_mask)
+{
 	TPACPI_COMPARE_KEY(TP_ACPI_HOTKEYSCAN_THINKPAD, thinkpad_toggle);
 	TPACPI_COMPARE_KEY(TP_ACPI_HOTKEYSCAN_FNSPACE, zoom_toggle);
 	TPACPI_COMPARE_KEY(TP_ACPI_HOTKEYSCAN_FNF7, display_toggle);
@@ -2406,7 +2407,7 @@ static void hotkey_compare_and_issue_eve
 		    oldn->volume_level != newn->volume_level) {
 			/* recently muted, or repeated mute keypress, or
 			 * multiple presses ending in mute */
-			issue_volchange(oldn->volume_level, newn->volume_level);
+			issue_volchange(oldn->volume_level, newn->volume_level, event_mask);
 			TPACPI_MAY_SEND_KEY(TP_ACPI_HOTKEYSCAN_MUTE);
 		}
 	} else {
@@ -2416,7 +2417,7 @@ static void hotkey_compare_and_issue_eve
 			TPACPI_MAY_SEND_KEY(TP_ACPI_HOTKEYSCAN_VOLUMEUP);
 		}
 		if (oldn->volume_level != newn->volume_level) {
-			issue_volchange(oldn->volume_level, newn->volume_level);
+			issue_volchange(oldn->volume_level, newn->volume_level, event_mask);
 		} else if (oldn->volume_toggle != newn->volume_toggle) {
 			/* repeated vol up/down keypress at end of scale ? */
 			if (newn->volume_level == 0)
@@ -2429,7 +2430,8 @@ static void hotkey_compare_and_issue_eve
 	/* handle brightness */
 	if (oldn->brightness_level != newn->brightness_level) {
 		issue_brightnesschange(oldn->brightness_level,
-				       newn->brightness_level);
+				       newn->brightness_level,
+				       event_mask);
 	} else if (oldn->brightness_toggle != newn->brightness_toggle) {
 		/* repeated key presses that didn't change state */
 		if (newn->brightness_level == 0)
@@ -2438,10 +2440,10 @@ static void hotkey_compare_and_issue_eve
 				&& !tp_features.bright_unkfw)
 			TPACPI_MAY_SEND_KEY(TP_ACPI_HOTKEYSCAN_FNHOME);
 	}
+}
 
 #undef TPACPI_COMPARE_KEY
 #undef TPACPI_MAY_SEND_KEY
-}
 
 /*
  * Polling driver
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/platform/x86/wmi.c linux-3.2.71-pax/drivers/platform/x86/wmi.c
--- linux-3.2.71/drivers/platform/x86/wmi.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/platform/x86/wmi.c	2013-08-31 15:55:59.274122289 +0200
@@ -743,7 +743,7 @@ static int wmi_create_device(const struc
 	wblock->dev.class = &wmi_class;
 
 	wmi_gtoa(gblock->guid, guid_string);
-	dev_set_name(&wblock->dev, guid_string);
+	dev_set_name(&wblock->dev, "%s", guid_string);
 
 	dev_set_drvdata(&wblock->dev, wblock);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pnp/pnpbios/bioscalls.c linux-3.2.71-pax/drivers/pnp/pnpbios/bioscalls.c
--- linux-3.2.71/drivers/pnp/pnpbios/bioscalls.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/pnp/pnpbios/bioscalls.c	2012-07-04 19:24:48.584063008 +0200
@@ -59,7 +59,7 @@ do { \
 	set_desc_limit(&gdt[(selname) >> 3], (size) - 1); \
 } while(0)
 
-static struct desc_struct bad_bios_desc = GDT_ENTRY_INIT(0x4092,
+static const struct desc_struct bad_bios_desc = GDT_ENTRY_INIT(0x4093,
 			(unsigned long)__va(0x400UL), PAGE_SIZE - 0x400 - 1);
 
 /*
@@ -96,7 +96,10 @@ static inline u16 call_pnp_bios(u16 func
 
 	cpu = get_cpu();
 	save_desc_40 = get_cpu_gdt_table(cpu)[0x40 / 8];
+
+	pax_open_kernel();
 	get_cpu_gdt_table(cpu)[0x40 / 8] = bad_bios_desc;
+	pax_close_kernel();
 
 	/* On some boxes IRQ's during PnP BIOS calls are deadly.  */
 	spin_lock_irqsave(&pnp_bios_lock, flags);
@@ -134,7 +137,10 @@ static inline u16 call_pnp_bios(u16 func
 			     :"memory");
 	spin_unlock_irqrestore(&pnp_bios_lock, flags);
 
+	pax_open_kernel();
 	get_cpu_gdt_table(cpu)[0x40 / 8] = save_desc_40;
+	pax_close_kernel();
+
 	put_cpu();
 
 	/* If we get here and this is set then the PnP BIOS faulted on us. */
@@ -468,7 +474,7 @@ int pnp_bios_read_escd(char *data, u32 n
 	return status;
 }
 
-void pnpbios_calls_init(union pnp_bios_install_struct *header)
+void __init pnpbios_calls_init(union pnp_bios_install_struct *header)
 {
 	int i;
 
@@ -476,6 +482,8 @@ void pnpbios_calls_init(union pnp_bios_i
 	pnp_bios_callpoint.offset = header->fields.pm16offset;
 	pnp_bios_callpoint.segment = PNP_CS16;
 
+	pax_open_kernel();
+
 	for_each_possible_cpu(i) {
 		struct desc_struct *gdt = get_cpu_gdt_table(i);
 		if (!gdt)
@@ -487,4 +495,6 @@ void pnpbios_calls_init(union pnp_bios_i
 		set_desc_base(&gdt[GDT_ENTRY_PNPBIOS_DS],
 			 (unsigned long)__va(header->fields.pm16dseg));
 	}
+
+	pax_close_kernel();
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pnp/pnpbios/core.c linux-3.2.71-pax/drivers/pnp/pnpbios/core.c
--- linux-3.2.71/drivers/pnp/pnpbios/core.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/pnp/pnpbios/core.c	2015-04-30 03:07:38.404532395 +0200
@@ -492,7 +492,7 @@ static int __init exploding_pnp_bios(con
 	return 0;
 }
 
-static struct dmi_system_id pnpbios_dmi_table[] __initdata = {
+static const struct dmi_system_id pnpbios_dmi_table[] __initconst = {
 	{			/* PnPBIOS GPF on boot */
 	 .callback = exploding_pnp_bios,
 	 .ident = "Higraded P14H",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/pnp/resource.c linux-3.2.71-pax/drivers/pnp/resource.c
--- linux-3.2.71/drivers/pnp/resource.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/pnp/resource.c	2012-07-04 19:24:48.584063008 +0200
@@ -360,7 +360,7 @@ int pnp_check_irq(struct pnp_dev *dev, s
 		return 1;
 
 	/* check if the resource is valid */
-	if (*irq < 0 || *irq > 15)
+	if (*irq > 15)
 		return 0;
 
 	/* check if the resource is reserved */
@@ -424,7 +424,7 @@ int pnp_check_dma(struct pnp_dev *dev, s
 		return 1;
 
 	/* check if the resource is valid */
-	if (*dma < 0 || *dma == 4 || *dma > 7)
+	if (*dma == 4 || *dma > 7)
 		return 0;
 
 	/* check if the resource is reserved */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/power/power_supply_core.c linux-3.2.71-pax/drivers/power/power_supply_core.c
--- linux-3.2.71/drivers/power/power_supply_core.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/power/power_supply_core.c	2013-03-28 01:35:23.296427948 +0100
@@ -23,7 +23,10 @@
 struct class *power_supply_class;
 EXPORT_SYMBOL_GPL(power_supply_class);
 
-static struct device_type power_supply_dev_type;
+extern const struct attribute_group *power_supply_attr_groups[];
+static struct device_type power_supply_dev_type = {
+	.groups = power_supply_attr_groups,
+};
 
 static int __power_supply_changed_work(struct device *dev, void *data)
 {
@@ -215,7 +218,7 @@ static int __init power_supply_class_ini
 		return PTR_ERR(power_supply_class);
 
 	power_supply_class->dev_uevent = power_supply_uevent;
-	power_supply_init_attrs(&power_supply_dev_type);
+	power_supply_init_attrs();
 
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/power/power_supply.h linux-3.2.71-pax/drivers/power/power_supply.h
--- linux-3.2.71/drivers/power/power_supply.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/power/power_supply.h	2013-03-28 01:35:23.296427948 +0100
@@ -12,12 +12,12 @@
 
 #ifdef CONFIG_SYSFS
 
-extern void power_supply_init_attrs(struct device_type *dev_type);
+extern void power_supply_init_attrs(void);
 extern int power_supply_uevent(struct device *dev, struct kobj_uevent_env *env);
 
 #else
 
-static inline void power_supply_init_attrs(struct device_type *dev_type) {}
+static inline void power_supply_init_attrs(void) {}
 #define power_supply_uevent NULL
 
 #endif /* CONFIG_SYSFS */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/power/power_supply_sysfs.c linux-3.2.71-pax/drivers/power/power_supply_sysfs.c
--- linux-3.2.71/drivers/power/power_supply_sysfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/power/power_supply_sysfs.c	2013-03-28 01:35:23.300427948 +0100
@@ -208,17 +208,15 @@ static struct attribute_group power_supp
 	.is_visible = power_supply_attr_is_visible,
 };
 
-static const struct attribute_group *power_supply_attr_groups[] = {
+const struct attribute_group *power_supply_attr_groups[] = {
 	&power_supply_attr_group,
 	NULL,
 };
 
-void power_supply_init_attrs(struct device_type *dev_type)
+void power_supply_init_attrs(void)
 {
 	int i;
 
-	dev_type->groups = power_supply_attr_groups;
-
 	for (i = 0; i < ARRAY_SIZE(power_supply_attrs); i++)
 		__power_supply_attrs[i] = &power_supply_attrs[i].attr;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/regulator/core.c linux-3.2.71-pax/drivers/regulator/core.c
--- linux-3.2.71/drivers/regulator/core.c	2015-08-14 21:48:35.244707916 +0200
+++ linux-3.2.71-pax/drivers/regulator/core.c	2015-08-14 21:48:45.620707362 +0200
@@ -2641,7 +2641,7 @@ struct regulator_dev *regulator_register
 	struct device *dev, const struct regulator_init_data *init_data,
 	void *driver_data)
 {
-	static atomic_t regulator_no = ATOMIC_INIT(0);
+	static atomic_unchecked_t regulator_no = ATOMIC_INIT(0);
 	struct regulator_dev *rdev;
 	int ret, i;
 
@@ -2700,7 +2700,7 @@ struct regulator_dev *regulator_register
 	rdev->dev.class = &regulator_class;
 	rdev->dev.parent = dev;
 	dev_set_name(&rdev->dev, "regulator.%d",
-		     atomic_inc_return(&regulator_no) - 1);
+		     atomic_inc_return_unchecked(&regulator_no) - 1);
 	ret = device_register(&rdev->dev);
 	if (ret != 0) {
 		put_device(&rdev->dev);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/regulator/max8660.c linux-3.2.71-pax/drivers/regulator/max8660.c
--- linux-3.2.71/drivers/regulator/max8660.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/regulator/max8660.c	2012-07-04 19:24:48.584063008 +0200
@@ -383,8 +383,10 @@ static int __devinit max8660_probe(struc
 		max8660->shadow_regs[MAX8660_OVER1] = 5;
 	} else {
 		/* Otherwise devices can be toggled via software */
-		max8660_dcdc_ops.enable = max8660_dcdc_enable;
-		max8660_dcdc_ops.disable = max8660_dcdc_disable;
+		pax_open_kernel();
+		*(void **)&max8660_dcdc_ops.enable = max8660_dcdc_enable;
+		*(void **)&max8660_dcdc_ops.disable = max8660_dcdc_disable;
+		pax_close_kernel();
 	}
 
 	/*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/regulator/mc13892-regulator.c linux-3.2.71-pax/drivers/regulator/mc13892-regulator.c
--- linux-3.2.71/drivers/regulator/mc13892-regulator.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/regulator/mc13892-regulator.c	2012-07-04 19:24:48.584063008 +0200
@@ -565,10 +565,12 @@ static int __devinit mc13892_regulator_p
 	}
 	mc13xxx_unlock(mc13892);
 
-	mc13892_regulators[MC13892_VCAM].desc.ops->set_mode
+	pax_open_kernel();
+	*(void **)&mc13892_regulators[MC13892_VCAM].desc.ops->set_mode
 		= mc13892_vcam_set_mode;
-	mc13892_regulators[MC13892_VCAM].desc.ops->get_mode
+	*(void **)&mc13892_regulators[MC13892_VCAM].desc.ops->get_mode
 		= mc13892_vcam_get_mode;
+	pax_close_kernel();
 	for (i = 0; i < pdata->num_regulators; i++) {
 		init_data = &pdata->regulators[i];
 		priv->regulators[i] = regulator_register(
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/rtc/rtc-cmos.c linux-3.2.71-pax/drivers/rtc/rtc-cmos.c
--- linux-3.2.71/drivers/rtc/rtc-cmos.c	2014-04-02 03:15:41.927672536 +0200
+++ linux-3.2.71-pax/drivers/rtc/rtc-cmos.c	2014-04-02 03:15:49.247672145 +0200
@@ -772,7 +772,9 @@ cmos_do_probe(struct device *dev, struct
 	hpet_rtc_timer_init();
 
 	/* export at least the first block of NVRAM */
-	nvram.size = address_space - NVRAM_OFFSET;
+	pax_open_kernel();
+	*(size_t *)&nvram.size = address_space - NVRAM_OFFSET;
+	pax_close_kernel();
 	retval = sysfs_create_bin_file(&dev->kobj, &nvram);
 	if (retval < 0) {
 		dev_dbg(dev, "can't create nvram file? %d\n", retval);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/rtc/rtc-m48t59.c linux-3.2.71-pax/drivers/rtc/rtc-m48t59.c
--- linux-3.2.71/drivers/rtc/rtc-m48t59.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/rtc/rtc-m48t59.c	2013-03-28 01:35:23.300427948 +0100
@@ -482,7 +482,9 @@ static int __devinit m48t59_rtc_probe(st
 		goto out;
 	}
 
-	m48t59_nvram_attr.size = pdata->offset;
+	pax_open_kernel();
+	*(size_t *)&m48t59_nvram_attr.size = pdata->offset;
+	pax_close_kernel();
 
 	ret = sysfs_create_bin_file(&pdev->dev.kobj, &m48t59_nvram_attr);
 	if (ret) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/aacraid/linit.c linux-3.2.71-pax/drivers/scsi/aacraid/linit.c
--- linux-3.2.71/drivers/scsi/aacraid/linit.c	2013-11-29 01:58:28.670491619 +0100
+++ linux-3.2.71-pax/drivers/scsi/aacraid/linit.c	2013-11-29 01:58:37.678491884 +0100
@@ -93,7 +93,7 @@ static DECLARE_PCI_DEVICE_TABLE(aac_pci_
 #elif defined(__devinitconst)
 static const struct pci_device_id aac_pci_tbl[] __devinitconst = {
 #else
-static const struct pci_device_id aac_pci_tbl[] __devinitdata = {
+static const struct pci_device_id aac_pci_tbl[] __devinitconst = {
 #endif
 	{ 0x1028, 0x0001, 0x1028, 0x0001, 0, 0, 0 }, /* PERC 2/Si (Iguana/PERC2Si) */
 	{ 0x1028, 0x0002, 0x1028, 0x0002, 0, 0, 1 }, /* PERC 3/Di (Opal/PERC3Di) */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/aic7xxx/aic79xx_pci.c linux-3.2.71-pax/drivers/scsi/aic7xxx/aic79xx_pci.c
--- linux-3.2.71/drivers/scsi/aic7xxx/aic79xx_pci.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/aic7xxx/aic79xx_pci.c	2013-11-12 01:31:30.937390296 +0100
@@ -827,7 +827,7 @@ ahd_pci_intr(struct ahd_softc *ahd)
 		for (bit = 0; bit < 8; bit++) {
 
 			if ((pci_status[i] & (0x1 << bit)) != 0) {
-				static const char *s;
+				const char *s;
 
 				s = pci_status_strings[bit];
 				if (i == 7/*TARG*/ && bit == 3)
@@ -887,23 +887,15 @@ ahd_pci_split_intr(struct ahd_softc *ahd
 
 		for (bit = 0; bit < 8; bit++) {
 
-			if ((split_status[i] & (0x1 << bit)) != 0) {
-				static const char *s;
-
-				s = split_status_strings[bit];
-				printk(s, ahd_name(ahd),
+			if ((split_status[i] & (0x1 << bit)) != 0)
+				printk(split_status_strings[bit], ahd_name(ahd),
 				       split_status_source[i]);
-			}
 
 			if (i > 1)
 				continue;
 
-			if ((sg_split_status[i] & (0x1 << bit)) != 0) {
-				static const char *s;
-
-				s = split_status_strings[bit];
-				printk(s, ahd_name(ahd), "SG");
-			}
+			if ((sg_split_status[i] & (0x1 << bit)) != 0)
+				printk(split_status_strings[bit], ahd_name(ahd), "SG");
 		}
 	}
 	/*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/aic94xx/aic94xx_init.c linux-3.2.71-pax/drivers/scsi/aic94xx/aic94xx_init.c
--- linux-3.2.71/drivers/scsi/aic94xx/aic94xx_init.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/aic94xx/aic94xx_init.c	2012-07-04 19:24:48.588063007 +0200
@@ -1012,7 +1012,7 @@ static struct sas_domain_function_templa
 	.lldd_control_phy	= asd_control_phy,
 };
 
-static const struct pci_device_id aic94xx_pci_table[] __devinitdata = {
+static const struct pci_device_id aic94xx_pci_table[] __devinitconst = {
 	{PCI_DEVICE(PCI_VENDOR_ID_ADAPTEC2, 0x410),0, 0, 1},
 	{PCI_DEVICE(PCI_VENDOR_ID_ADAPTEC2, 0x412),0, 0, 1},
 	{PCI_DEVICE(PCI_VENDOR_ID_ADAPTEC2, 0x416),0, 0, 1},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/bfa/bfa_fcpim.h linux-3.2.71-pax/drivers/scsi/bfa/bfa_fcpim.h
--- linux-3.2.71/drivers/scsi/bfa/bfa_fcpim.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/bfa/bfa_fcpim.h	2013-01-16 21:47:23.898808773 +0100
@@ -36,7 +36,7 @@ struct bfa_iotag_s {
 
 struct bfa_itn_s {
 	bfa_isr_func_t isr;
-};
+} __no_const;
 
 void bfa_itn_create(struct bfa_s *bfa, struct bfa_rport_s *rport,
 		void (*isr)(struct bfa_s *bfa, struct bfi_msg_s *m));
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/bfa/bfa_ioc.h linux-3.2.71-pax/drivers/scsi/bfa/bfa_ioc.h
--- linux-3.2.71/drivers/scsi/bfa/bfa_ioc.h	2014-09-14 14:10:59.326118187 +0200
+++ linux-3.2.71-pax/drivers/scsi/bfa/bfa_ioc.h	2014-09-14 14:11:26.002138386 +0200
@@ -258,7 +258,7 @@ struct bfa_ioc_cbfn_s {
 	bfa_ioc_disable_cbfn_t	disable_cbfn;
 	bfa_ioc_hbfail_cbfn_t	hbfail_cbfn;
 	bfa_ioc_reset_cbfn_t	reset_cbfn;
-};
+} __no_const;
 
 /*
  * IOC event notification mechanism.
@@ -346,7 +346,7 @@ struct bfa_ioc_hwif_s {
 	void		(*ioc_sync_ack)		(struct bfa_ioc_s *ioc);
 	bfa_boolean_t	(*ioc_sync_complete)	(struct bfa_ioc_s *ioc);
 	bfa_boolean_t	(*ioc_lpu_read_stat)	(struct bfa_ioc_s *ioc);
-};
+} __no_const;
 
 /*
  * Queue element to wait for room in request queue. FIFO order is
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/hosts.c linux-3.2.71-pax/drivers/scsi/hosts.c
--- linux-3.2.71/drivers/scsi/hosts.c	2012-08-03 01:53:47.282140438 +0200
+++ linux-3.2.71-pax/drivers/scsi/hosts.c	2012-08-03 01:53:52.770140149 +0200
@@ -42,7 +42,7 @@
 #include "scsi_logging.h"
 
 
-static atomic_t scsi_host_next_hn;	/* host_no for next new host */
+static atomic_unchecked_t scsi_host_next_hn;	/* host_no for next new host */
 
 
 static void scsi_host_cls_release(struct device *dev)
@@ -358,7 +358,7 @@ struct Scsi_Host *scsi_host_alloc(struct
 	 * subtract one because we increment first then return, but we need to
 	 * know what the next host number was before increment
 	 */
-	shost->host_no = atomic_inc_return(&scsi_host_next_hn) - 1;
+	shost->host_no = atomic_inc_return_unchecked(&scsi_host_next_hn) - 1;
 	shost->dma_channel = 0xff;
 
 	/* These three are default values which can be overridden */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/hpsa.c linux-3.2.71-pax/drivers/scsi/hpsa.c
--- linux-3.2.71/drivers/scsi/hpsa.c	2014-12-14 21:13:45.134054953 +0100
+++ linux-3.2.71-pax/drivers/scsi/hpsa.c	2014-12-14 21:13:52.790069255 +0100
@@ -523,7 +523,7 @@ static inline u32 next_command(struct ct
 	u32 a;
 
 	if (unlikely(!(h->transMethod & CFGTBL_Trans_Performant)))
-		return h->access.command_completed(h);
+		return h->access->command_completed(h);
 
 	if ((*(h->reply_pool_head) & 1) == (h->reply_pool_wraparound)) {
 		a = *(h->reply_pool_head); /* Next cmd in ring buffer */
@@ -3034,7 +3034,7 @@ static void start_io(struct ctlr_info *h
 	while (!list_empty(&h->reqQ)) {
 		c = list_entry(h->reqQ.next, struct CommandList, list);
 		/* can't do anything if fifo is full */
-		if ((h->access.fifo_full(h))) {
+		if ((h->access->fifo_full(h))) {
 			dev_warn(&h->pdev->dev, "fifo full\n");
 			break;
 		}
@@ -3044,7 +3044,7 @@ static void start_io(struct ctlr_info *h
 		h->Qdepth--;
 
 		/* Tell the controller execute command */
-		h->access.submit_command(h, c);
+		h->access->submit_command(h, c);
 
 		/* Put job onto the completed Q */
 		addQ(&h->cmpQ, c);
@@ -3053,17 +3053,17 @@ static void start_io(struct ctlr_info *h
 
 static inline unsigned long get_next_completion(struct ctlr_info *h)
 {
-	return h->access.command_completed(h);
+	return h->access->command_completed(h);
 }
 
 static inline bool interrupt_pending(struct ctlr_info *h)
 {
-	return h->access.intr_pending(h);
+	return h->access->intr_pending(h);
 }
 
 static inline long interrupt_not_for_us(struct ctlr_info *h)
 {
-	return (h->access.intr_pending(h) == 0) ||
+	return (h->access->intr_pending(h) == 0) ||
 		(h->interrupts_enabled == 0);
 }
 
@@ -3963,7 +3963,7 @@ static int __devinit hpsa_pci_init(struc
 	if (prod_index < 0)
 		return -ENODEV;
 	h->product_name = products[prod_index].product_name;
-	h->access = *(products[prod_index].access);
+	h->access = products[prod_index].access;
 
 	if (hpsa_board_disabled(h->pdev)) {
 		dev_warn(&h->pdev->dev, "controller appears to be disabled\n");
@@ -4208,7 +4208,7 @@ static void controller_lockup_detected(s
 
 	assert_spin_locked(&lockup_detector_lock);
 	remove_ctlr_from_lockup_detector_list(h);
-	h->access.set_intr_mask(h, HPSA_INTR_OFF);
+	h->access->set_intr_mask(h, HPSA_INTR_OFF);
 	spin_lock_irqsave(&h->lock, flags);
 	h->lockup_detected = readl(h->vaddr + SA5_SCRATCHPAD_OFFSET);
 	spin_unlock_irqrestore(&h->lock, flags);
@@ -4384,7 +4384,7 @@ reinit_after_soft_reset:
 	}
 
 	/* make sure the board interrupts are off */
-	h->access.set_intr_mask(h, HPSA_INTR_OFF);
+	h->access->set_intr_mask(h, HPSA_INTR_OFF);
 
 	if (hpsa_request_irq(h, do_hpsa_intr_msi, do_hpsa_intr_intx))
 		goto clean2;
@@ -4418,7 +4418,7 @@ reinit_after_soft_reset:
 		 * fake ones to scoop up any residual completions.
 		 */
 		spin_lock_irqsave(&h->lock, flags);
-		h->access.set_intr_mask(h, HPSA_INTR_OFF);
+		h->access->set_intr_mask(h, HPSA_INTR_OFF);
 		spin_unlock_irqrestore(&h->lock, flags);
 		free_irq(h->intr[h->intr_mode], h);
 		rc = hpsa_request_irq(h, hpsa_msix_discard_completions,
@@ -4437,9 +4437,9 @@ reinit_after_soft_reset:
 		dev_info(&h->pdev->dev, "Board READY.\n");
 		dev_info(&h->pdev->dev,
 			"Waiting for stale completions to drain.\n");
-		h->access.set_intr_mask(h, HPSA_INTR_ON);
+		h->access->set_intr_mask(h, HPSA_INTR_ON);
 		msleep(10000);
-		h->access.set_intr_mask(h, HPSA_INTR_OFF);
+		h->access->set_intr_mask(h, HPSA_INTR_OFF);
 
 		rc = controller_reset_failed(h->cfgtable);
 		if (rc)
@@ -4460,7 +4460,7 @@ reinit_after_soft_reset:
 	}
 
 	/* Turn the interrupts on so we can service requests */
-	h->access.set_intr_mask(h, HPSA_INTR_ON);
+	h->access->set_intr_mask(h, HPSA_INTR_ON);
 
 	hpsa_hba_inquiry(h);
 	hpsa_register_scsi(h);	/* hook ourselves into SCSI subsystem */
@@ -4512,7 +4512,7 @@ static void hpsa_shutdown(struct pci_dev
 	 * To write all data in the battery backed cache to disks
 	 */
 	hpsa_flush_cache(h);
-	h->access.set_intr_mask(h, HPSA_INTR_OFF);
+	h->access->set_intr_mask(h, HPSA_INTR_OFF);
 	free_irq(h->intr[h->intr_mode], h);
 #ifdef CONFIG_PCI_MSI
 	if (h->msix_vector)
@@ -4676,7 +4676,7 @@ static __devinit void hpsa_enter_perform
 		return;
 	}
 	/* Change the access methods to the performant access methods */
-	h->access = SA5_performant_access;
+	h->access = &SA5_performant_access;
 	h->transMethod = CFGTBL_Trans_Performant;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/hpsa.h linux-3.2.71-pax/drivers/scsi/hpsa.h
--- linux-3.2.71/drivers/scsi/hpsa.h	2012-10-24 01:05:57.176814620 +0200
+++ linux-3.2.71-pax/drivers/scsi/hpsa.h	2012-10-24 01:06:03.060814933 +0200
@@ -73,7 +73,7 @@ struct ctlr_info {
 	unsigned int msix_vector;
 	unsigned int msi_vector;
 	int intr_mode; /* either PERF_MODE_INT or SIMPLE_MODE_INT */
-	struct access_method access;
+	struct access_method *access;
 
 	/* queue and queue Info */
 	struct list_head reqQ;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/libfc/fc_exch.c linux-3.2.71-pax/drivers/scsi/libfc/fc_exch.c
--- linux-3.2.71/drivers/scsi/libfc/fc_exch.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/libfc/fc_exch.c	2012-07-04 19:24:48.596063008 +0200
@@ -105,12 +105,12 @@ struct fc_exch_mgr {
 	 * all together if not used XXX
 	 */
 	struct {
-		atomic_t no_free_exch;
-		atomic_t no_free_exch_xid;
-		atomic_t xid_not_found;
-		atomic_t xid_busy;
-		atomic_t seq_not_found;
-		atomic_t non_bls_resp;
+		atomic_unchecked_t no_free_exch;
+		atomic_unchecked_t no_free_exch_xid;
+		atomic_unchecked_t xid_not_found;
+		atomic_unchecked_t xid_busy;
+		atomic_unchecked_t seq_not_found;
+		atomic_unchecked_t non_bls_resp;
 	} stats;
 };
 
@@ -719,7 +719,7 @@ static struct fc_exch *fc_exch_em_alloc(
 	/* allocate memory for exchange */
 	ep = mempool_alloc(mp->ep_pool, GFP_ATOMIC);
 	if (!ep) {
-		atomic_inc(&mp->stats.no_free_exch);
+		atomic_inc_unchecked(&mp->stats.no_free_exch);
 		goto out;
 	}
 	memset(ep, 0, sizeof(*ep));
@@ -780,7 +780,7 @@ out:
 	return ep;
 err:
 	spin_unlock_bh(&pool->lock);
-	atomic_inc(&mp->stats.no_free_exch_xid);
+	atomic_inc_unchecked(&mp->stats.no_free_exch_xid);
 	mempool_free(ep, mp->ep_pool);
 	return NULL;
 }
@@ -923,7 +923,7 @@ static enum fc_pf_rjt_reason fc_seq_look
 		xid = ntohs(fh->fh_ox_id);	/* we originated exch */
 		ep = fc_exch_find(mp, xid);
 		if (!ep) {
-			atomic_inc(&mp->stats.xid_not_found);
+			atomic_inc_unchecked(&mp->stats.xid_not_found);
 			reject = FC_RJT_OX_ID;
 			goto out;
 		}
@@ -953,7 +953,7 @@ static enum fc_pf_rjt_reason fc_seq_look
 		ep = fc_exch_find(mp, xid);
 		if ((f_ctl & FC_FC_FIRST_SEQ) && fc_sof_is_init(fr_sof(fp))) {
 			if (ep) {
-				atomic_inc(&mp->stats.xid_busy);
+				atomic_inc_unchecked(&mp->stats.xid_busy);
 				reject = FC_RJT_RX_ID;
 				goto rel;
 			}
@@ -964,7 +964,7 @@ static enum fc_pf_rjt_reason fc_seq_look
 			}
 			xid = ep->xid;	/* get our XID */
 		} else if (!ep) {
-			atomic_inc(&mp->stats.xid_not_found);
+			atomic_inc_unchecked(&mp->stats.xid_not_found);
 			reject = FC_RJT_RX_ID;	/* XID not found */
 			goto out;
 		}
@@ -981,7 +981,7 @@ static enum fc_pf_rjt_reason fc_seq_look
 	} else {
 		sp = &ep->seq;
 		if (sp->id != fh->fh_seq_id) {
-			atomic_inc(&mp->stats.seq_not_found);
+			atomic_inc_unchecked(&mp->stats.seq_not_found);
 			if (f_ctl & FC_FC_END_SEQ) {
 				/*
 				 * Update sequence_id based on incoming last
@@ -1431,22 +1431,22 @@ static void fc_exch_recv_seq_resp(struct
 
 	ep = fc_exch_find(mp, ntohs(fh->fh_ox_id));
 	if (!ep) {
-		atomic_inc(&mp->stats.xid_not_found);
+		atomic_inc_unchecked(&mp->stats.xid_not_found);
 		goto out;
 	}
 	if (ep->esb_stat & ESB_ST_COMPLETE) {
-		atomic_inc(&mp->stats.xid_not_found);
+		atomic_inc_unchecked(&mp->stats.xid_not_found);
 		goto rel;
 	}
 	if (ep->rxid == FC_XID_UNKNOWN)
 		ep->rxid = ntohs(fh->fh_rx_id);
 	if (ep->sid != 0 && ep->sid != ntoh24(fh->fh_d_id)) {
-		atomic_inc(&mp->stats.xid_not_found);
+		atomic_inc_unchecked(&mp->stats.xid_not_found);
 		goto rel;
 	}
 	if (ep->did != ntoh24(fh->fh_s_id) &&
 	    ep->did != FC_FID_FLOGI) {
-		atomic_inc(&mp->stats.xid_not_found);
+		atomic_inc_unchecked(&mp->stats.xid_not_found);
 		goto rel;
 	}
 	sof = fr_sof(fp);
@@ -1455,7 +1455,7 @@ static void fc_exch_recv_seq_resp(struct
 		sp->ssb_stat |= SSB_ST_RESP;
 		sp->id = fh->fh_seq_id;
 	} else if (sp->id != fh->fh_seq_id) {
-		atomic_inc(&mp->stats.seq_not_found);
+		atomic_inc_unchecked(&mp->stats.seq_not_found);
 		goto rel;
 	}
 
@@ -1519,9 +1519,9 @@ static void fc_exch_recv_resp(struct fc_
 	sp = fc_seq_lookup_orig(mp, fp);	/* doesn't hold sequence */
 
 	if (!sp)
-		atomic_inc(&mp->stats.xid_not_found);
+		atomic_inc_unchecked(&mp->stats.xid_not_found);
 	else
-		atomic_inc(&mp->stats.non_bls_resp);
+		atomic_inc_unchecked(&mp->stats.non_bls_resp);
 
 	fc_frame_free(fp);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/libsas/sas_ata.c linux-3.2.71-pax/drivers/scsi/libsas/sas_ata.c
--- linux-3.2.71/drivers/scsi/libsas/sas_ata.c	2014-01-03 15:48:44.956070566 +0100
+++ linux-3.2.71-pax/drivers/scsi/libsas/sas_ata.c	2014-01-03 15:48:49.564070320 +0100
@@ -368,7 +368,7 @@ static struct ata_port_operations sas_sa
 	.postreset		= ata_std_postreset,
 	.error_handler		= ata_std_error_handler,
 	.post_internal_cmd	= sas_ata_post_internal,
-	.qc_defer               = ata_std_qc_defer,
+	.qc_defer		= ata_std_qc_defer,
 	.qc_prep		= ata_noop_qc_prep,
 	.qc_issue		= sas_ata_qc_issue,
 	.qc_fill_rtf		= sas_ata_qc_fill_rtf,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/lpfc/lpfc_debugfs.c linux-3.2.71-pax/drivers/scsi/lpfc/lpfc_debugfs.c
--- linux-3.2.71/drivers/scsi/lpfc/lpfc_debugfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/lpfc/lpfc_debugfs.c	2012-07-04 19:24:48.600063008 +0200
@@ -106,7 +106,7 @@ MODULE_PARM_DESC(lpfc_debugfs_mask_disc_
 
 #include <linux/debugfs.h>
 
-static atomic_t lpfc_debugfs_seq_trc_cnt = ATOMIC_INIT(0);
+static atomic_unchecked_t lpfc_debugfs_seq_trc_cnt = ATOMIC_INIT(0);
 static unsigned long lpfc_debugfs_start_time = 0L;
 
 /* iDiag */
@@ -147,7 +147,7 @@ lpfc_debugfs_disc_trc_data(struct lpfc_v
 	lpfc_debugfs_enable = 0;
 
 	len = 0;
-	index = (atomic_read(&vport->disc_trc_cnt) + 1) &
+	index = (atomic_read_unchecked(&vport->disc_trc_cnt) + 1) &
 		(lpfc_debugfs_max_disc_trc - 1);
 	for (i = index; i < lpfc_debugfs_max_disc_trc; i++) {
 		dtp = vport->disc_trc + i;
@@ -213,7 +213,7 @@ lpfc_debugfs_slow_ring_trc_data(struct l
 	lpfc_debugfs_enable = 0;
 
 	len = 0;
-	index = (atomic_read(&phba->slow_ring_trc_cnt) + 1) &
+	index = (atomic_read_unchecked(&phba->slow_ring_trc_cnt) + 1) &
 		(lpfc_debugfs_max_slow_ring_trc - 1);
 	for (i = index; i < lpfc_debugfs_max_slow_ring_trc; i++) {
 		dtp = phba->slow_ring_trc + i;
@@ -636,14 +636,14 @@ lpfc_debugfs_disc_trc(struct lpfc_vport
 		!vport || !vport->disc_trc)
 		return;
 
-	index = atomic_inc_return(&vport->disc_trc_cnt) &
+	index = atomic_inc_return_unchecked(&vport->disc_trc_cnt) &
 		(lpfc_debugfs_max_disc_trc - 1);
 	dtp = vport->disc_trc + index;
 	dtp->fmt = fmt;
 	dtp->data1 = data1;
 	dtp->data2 = data2;
 	dtp->data3 = data3;
-	dtp->seq_cnt = atomic_inc_return(&lpfc_debugfs_seq_trc_cnt);
+	dtp->seq_cnt = atomic_inc_return_unchecked(&lpfc_debugfs_seq_trc_cnt);
 	dtp->jif = jiffies;
 #endif
 	return;
@@ -674,14 +674,14 @@ lpfc_debugfs_slow_ring_trc(struct lpfc_h
 		!phba || !phba->slow_ring_trc)
 		return;
 
-	index = atomic_inc_return(&phba->slow_ring_trc_cnt) &
+	index = atomic_inc_return_unchecked(&phba->slow_ring_trc_cnt) &
 		(lpfc_debugfs_max_slow_ring_trc - 1);
 	dtp = phba->slow_ring_trc + index;
 	dtp->fmt = fmt;
 	dtp->data1 = data1;
 	dtp->data2 = data2;
 	dtp->data3 = data3;
-	dtp->seq_cnt = atomic_inc_return(&lpfc_debugfs_seq_trc_cnt);
+	dtp->seq_cnt = atomic_inc_return_unchecked(&lpfc_debugfs_seq_trc_cnt);
 	dtp->jif = jiffies;
 #endif
 	return;
@@ -3986,7 +3986,7 @@ lpfc_debugfs_initialize(struct lpfc_vpor
 						 "slow_ring buffer\n");
 				goto debug_failed;
 			}
-			atomic_set(&phba->slow_ring_trc_cnt, 0);
+			atomic_set_unchecked(&phba->slow_ring_trc_cnt, 0);
 			memset(phba->slow_ring_trc, 0,
 				(sizeof(struct lpfc_debugfs_trc) *
 				lpfc_debugfs_max_slow_ring_trc));
@@ -4032,7 +4032,7 @@ lpfc_debugfs_initialize(struct lpfc_vpor
 				 "buffer\n");
 		goto debug_failed;
 	}
-	atomic_set(&vport->disc_trc_cnt, 0);
+	atomic_set_unchecked(&vport->disc_trc_cnt, 0);
 
 	snprintf(name, sizeof(name), "discovery_trace");
 	vport->debug_disc_trc =
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/lpfc/lpfc.h linux-3.2.71-pax/drivers/scsi/lpfc/lpfc.h
--- linux-3.2.71/drivers/scsi/lpfc/lpfc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/lpfc/lpfc.h	2012-07-04 19:24:48.600063008 +0200
@@ -425,7 +425,7 @@ struct lpfc_vport {
 	struct dentry *debug_nodelist;
 	struct dentry *vport_debugfs_root;
 	struct lpfc_debugfs_trc *disc_trc;
-	atomic_t disc_trc_cnt;
+	atomic_unchecked_t disc_trc_cnt;
 #endif
 	uint8_t stat_data_enabled;
 	uint8_t stat_data_blocked;
@@ -835,8 +835,8 @@ struct lpfc_hba {
 	struct timer_list fabric_block_timer;
 	unsigned long bit_flags;
 #define	FABRIC_COMANDS_BLOCKED	0
-	atomic_t num_rsrc_err;
-	atomic_t num_cmd_success;
+	atomic_unchecked_t num_rsrc_err;
+	atomic_unchecked_t num_cmd_success;
 	unsigned long last_rsrc_error_time;
 	unsigned long last_ramp_down_time;
 	unsigned long last_ramp_up_time;
@@ -866,7 +866,7 @@ struct lpfc_hba {
 
 	struct dentry *debug_slow_ring_trc;
 	struct lpfc_debugfs_trc *slow_ring_trc;
-	atomic_t slow_ring_trc_cnt;
+	atomic_unchecked_t slow_ring_trc_cnt;
 	/* iDiag debugfs sub-directory */
 	struct dentry *idiag_root;
 	struct dentry *idiag_pci_cfg;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/lpfc/lpfc_init.c linux-3.2.71-pax/drivers/scsi/lpfc/lpfc_init.c
--- linux-3.2.71/drivers/scsi/lpfc/lpfc_init.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/lpfc/lpfc_init.c	2012-07-04 19:24:48.604063007 +0200
@@ -10027,8 +10027,10 @@ lpfc_init(void)
 	printk(LPFC_COPYRIGHT "\n");
 
 	if (lpfc_enable_npiv) {
-		lpfc_transport_functions.vport_create = lpfc_vport_create;
-		lpfc_transport_functions.vport_delete = lpfc_vport_delete;
+		pax_open_kernel();
+		*(void **)&lpfc_transport_functions.vport_create = lpfc_vport_create;
+		*(void **)&lpfc_transport_functions.vport_delete = lpfc_vport_delete;
+		pax_close_kernel();
 	}
 	lpfc_transport_template =
 				fc_attach_transport(&lpfc_transport_functions);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/lpfc/lpfc_scsi.c linux-3.2.71-pax/drivers/scsi/lpfc/lpfc_scsi.c
--- linux-3.2.71/drivers/scsi/lpfc/lpfc_scsi.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/lpfc/lpfc_scsi.c	2012-07-04 19:24:48.604063007 +0200
@@ -305,7 +305,7 @@ lpfc_rampdown_queue_depth(struct lpfc_hb
 	uint32_t evt_posted;
 
 	spin_lock_irqsave(&phba->hbalock, flags);
-	atomic_inc(&phba->num_rsrc_err);
+	atomic_inc_unchecked(&phba->num_rsrc_err);
 	phba->last_rsrc_error_time = jiffies;
 
 	if ((phba->last_ramp_down_time + QUEUE_RAMP_DOWN_INTERVAL) > jiffies) {
@@ -346,7 +346,7 @@ lpfc_rampup_queue_depth(struct lpfc_vpor
 	unsigned long flags;
 	struct lpfc_hba *phba = vport->phba;
 	uint32_t evt_posted;
-	atomic_inc(&phba->num_cmd_success);
+	atomic_inc_unchecked(&phba->num_cmd_success);
 
 	if (vport->cfg_lun_queue_depth <= queue_depth)
 		return;
@@ -390,8 +390,8 @@ lpfc_ramp_down_queue_handler(struct lpfc
 	unsigned long num_rsrc_err, num_cmd_success;
 	int i;
 
-	num_rsrc_err = atomic_read(&phba->num_rsrc_err);
-	num_cmd_success = atomic_read(&phba->num_cmd_success);
+	num_rsrc_err = atomic_read_unchecked(&phba->num_rsrc_err);
+	num_cmd_success = atomic_read_unchecked(&phba->num_cmd_success);
 
 	vports = lpfc_create_vport_work_array(phba);
 	if (vports != NULL)
@@ -411,8 +411,8 @@ lpfc_ramp_down_queue_handler(struct lpfc
 			}
 		}
 	lpfc_destroy_vport_work_array(phba, vports);
-	atomic_set(&phba->num_rsrc_err, 0);
-	atomic_set(&phba->num_cmd_success, 0);
+	atomic_set_unchecked(&phba->num_rsrc_err, 0);
+	atomic_set_unchecked(&phba->num_cmd_success, 0);
 }
 
 /**
@@ -446,8 +446,8 @@ lpfc_ramp_up_queue_handler(struct lpfc_h
 			}
 		}
 	lpfc_destroy_vport_work_array(phba, vports);
-	atomic_set(&phba->num_rsrc_err, 0);
-	atomic_set(&phba->num_cmd_success, 0);
+	atomic_set_unchecked(&phba->num_rsrc_err, 0);
+	atomic_set_unchecked(&phba->num_cmd_success, 0);
 }
 
 /**
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/mpt2sas/mpt2sas_scsih.c linux-3.2.71-pax/drivers/scsi/mpt2sas/mpt2sas_scsih.c
--- linux-3.2.71/drivers/scsi/mpt2sas/mpt2sas_scsih.c	2014-06-10 10:59:38.790436243 +0200
+++ linux-3.2.71-pax/drivers/scsi/mpt2sas/mpt2sas_scsih.c	2014-06-10 10:59:44.162435956 +0200
@@ -1532,7 +1532,7 @@ _scsih_get_resync(struct device *dev)
 {
 	struct scsi_device *sdev = to_scsi_device(dev);
 	struct MPT2SAS_ADAPTER *ioc = shost_priv(sdev->host);
-	static struct _raid_device *raid_device;
+	struct _raid_device *raid_device;
 	unsigned long flags;
 	Mpi2RaidVolPage0_t vol_pg0;
 	Mpi2ConfigReply_t mpi_reply;
@@ -1571,7 +1571,7 @@ _scsih_get_state(struct device *dev)
 {
 	struct scsi_device *sdev = to_scsi_device(dev);
 	struct MPT2SAS_ADAPTER *ioc = shost_priv(sdev->host);
-	static struct _raid_device *raid_device;
+	struct _raid_device *raid_device;
 	unsigned long flags;
 	Mpi2RaidVolPage0_t vol_pg0;
 	Mpi2ConfigReply_t mpi_reply;
@@ -6532,7 +6532,7 @@ _scsih_sas_ir_operation_status_event(str
     struct fw_event_work *fw_event)
 {
 	Mpi2EventDataIrOperationStatus_t *event_data = fw_event->event_data;
-	static struct _raid_device *raid_device;
+	struct _raid_device *raid_device;
 	unsigned long flags;
 	u16 handle;
 
@@ -7005,7 +7005,7 @@ _scsih_scan_for_devices_after_reset(stru
 	u64 sas_address;
 	struct _sas_device *sas_device;
 	struct _sas_node *expander_device;
-	static struct _raid_device *raid_device;
+	struct _raid_device *raid_device;
 	u8 retry_count;
 
 	printk(MPT2SAS_INFO_FMT "scan devices: start\n", ioc->name);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/pmcraid.c linux-3.2.71-pax/drivers/scsi/pmcraid.c
--- linux-3.2.71/drivers/scsi/pmcraid.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/pmcraid.c	2012-07-04 19:24:48.608063007 +0200
@@ -200,8 +200,8 @@ static int pmcraid_slave_alloc(struct sc
 		res->scsi_dev = scsi_dev;
 		scsi_dev->hostdata = res;
 		res->change_detected = 0;
-		atomic_set(&res->read_failures, 0);
-		atomic_set(&res->write_failures, 0);
+		atomic_set_unchecked(&res->read_failures, 0);
+		atomic_set_unchecked(&res->write_failures, 0);
 		rc = 0;
 	}
 	spin_unlock_irqrestore(&pinstance->resource_lock, lock_flags);
@@ -2676,9 +2676,9 @@ static int pmcraid_error_handler(struct
 
 	/* If this was a SCSI read/write command keep count of errors */
 	if (SCSI_CMD_TYPE(scsi_cmd->cmnd[0]) == SCSI_READ_CMD)
-		atomic_inc(&res->read_failures);
+		atomic_inc_unchecked(&res->read_failures);
 	else if (SCSI_CMD_TYPE(scsi_cmd->cmnd[0]) == SCSI_WRITE_CMD)
-		atomic_inc(&res->write_failures);
+		atomic_inc_unchecked(&res->write_failures);
 
 	if (!RES_IS_GSCSI(res->cfg_entry) &&
 		masked_ioasc != PMCRAID_IOASC_HW_DEVICE_BUS_STATUS_ERROR) {
@@ -3534,7 +3534,7 @@ static int pmcraid_queuecommand_lck(
 	 * block of scsi_cmd which is re-used (e.g. cancel/abort), which uses
 	 * hrrq_id assigned here in queuecommand
 	 */
-	ioarcb->hrrq_id = atomic_add_return(1, &(pinstance->last_message_id)) %
+	ioarcb->hrrq_id = atomic_add_return_unchecked(1, &(pinstance->last_message_id)) %
 			  pinstance->num_hrrq;
 	cmd->cmd_done = pmcraid_io_done;
 
@@ -3859,7 +3859,7 @@ static long pmcraid_ioctl_passthrough(
 	 * block of scsi_cmd which is re-used (e.g. cancel/abort), which uses
 	 * hrrq_id assigned here in queuecommand
 	 */
-	ioarcb->hrrq_id = atomic_add_return(1, &(pinstance->last_message_id)) %
+	ioarcb->hrrq_id = atomic_add_return_unchecked(1, &(pinstance->last_message_id)) %
 			  pinstance->num_hrrq;
 
 	if (request_size) {
@@ -4497,7 +4497,7 @@ static void pmcraid_worker_function(stru
 
 	pinstance = container_of(workp, struct pmcraid_instance, worker_q);
 	/* add resources only after host is added into system */
-	if (!atomic_read(&pinstance->expose_resources))
+	if (!atomic_read_unchecked(&pinstance->expose_resources))
 		return;
 
 	fw_version = be16_to_cpu(pinstance->inq_data->fw_version);
@@ -5331,8 +5331,8 @@ static int __devinit pmcraid_init_instan
 	init_waitqueue_head(&pinstance->reset_wait_q);
 
 	atomic_set(&pinstance->outstanding_cmds, 0);
-	atomic_set(&pinstance->last_message_id, 0);
-	atomic_set(&pinstance->expose_resources, 0);
+	atomic_set_unchecked(&pinstance->last_message_id, 0);
+	atomic_set_unchecked(&pinstance->expose_resources, 0);
 
 	INIT_LIST_HEAD(&pinstance->free_res_q);
 	INIT_LIST_HEAD(&pinstance->used_res_q);
@@ -6047,7 +6047,7 @@ static int __devinit pmcraid_probe(
 	/* Schedule worker thread to handle CCN and take care of adding and
 	 * removing devices to OS
 	 */
-	atomic_set(&pinstance->expose_resources, 1);
+	atomic_set_unchecked(&pinstance->expose_resources, 1);
 	schedule_work(&pinstance->worker_q);
 	return rc;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/pmcraid.h linux-3.2.71-pax/drivers/scsi/pmcraid.h
--- linux-3.2.71/drivers/scsi/pmcraid.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/pmcraid.h	2012-07-04 19:24:48.608063007 +0200
@@ -748,7 +748,7 @@ struct pmcraid_instance {
 	struct pmcraid_isr_param hrrq_vector[PMCRAID_NUM_MSIX_VECTORS];
 
 	/* Message id as filled in last fired IOARCB, used to identify HRRQ */
-	atomic_t last_message_id;
+	atomic_unchecked_t last_message_id;
 
 	/* configuration table */
 	struct pmcraid_config_table *cfg_table;
@@ -777,7 +777,7 @@ struct pmcraid_instance {
 	atomic_t outstanding_cmds;
 
 	/* should add/delete resources to mid-layer now ?*/
-	atomic_t expose_resources;
+	atomic_unchecked_t expose_resources;
 
 
 
@@ -813,8 +813,8 @@ struct pmcraid_resource_entry {
 		struct pmcraid_config_table_entry_ext cfg_entry_ext;
 	};
 	struct scsi_device *scsi_dev;	/* Link scsi_device structure */
-	atomic_t read_failures;		/* count of failed READ commands */
-	atomic_t write_failures;	/* count of failed WRITE commands */
+	atomic_unchecked_t read_failures;	/* count of failed READ commands */
+	atomic_unchecked_t write_failures;	/* count of failed WRITE commands */
 
 	/* To indicate add/delete/modify during CCN */
 	u8 change_detected;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/qla2xxx/qla_os.c linux-3.2.71-pax/drivers/scsi/qla2xxx/qla_os.c
--- linux-3.2.71/drivers/scsi/qla2xxx/qla_os.c	2013-01-03 19:05:13.868036836 +0100
+++ linux-3.2.71-pax/drivers/scsi/qla2xxx/qla_os.c	2013-01-16 21:27:14.798836714 +0100
@@ -1429,8 +1429,10 @@ qla2x00_config_dma_addressing(struct qla
 		    !pci_set_consistent_dma_mask(ha->pdev, DMA_BIT_MASK(64))) {
 			/* Ok, a 64bit DMA mask is applicable. */
 			ha->flags.enable_64bit_addressing = 1;
-			ha->isp_ops->calc_req_entries = qla2x00_calc_iocbs_64;
-			ha->isp_ops->build_iocbs = qla2x00_build_scsi_iocbs_64;
+			pax_open_kernel();
+			*(void **)&ha->isp_ops->calc_req_entries = qla2x00_calc_iocbs_64;
+			*(void **)&ha->isp_ops->build_iocbs = qla2x00_build_scsi_iocbs_64;
+			pax_close_kernel();
 			return;
 		}
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/qla4xxx/ql4_def.h linux-3.2.71-pax/drivers/scsi/qla4xxx/ql4_def.h
--- linux-3.2.71/drivers/scsi/qla4xxx/ql4_def.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/qla4xxx/ql4_def.h	2012-07-04 19:24:48.608063007 +0200
@@ -258,7 +258,7 @@ struct ddb_entry {
 					   * (4000 only) */
 	atomic_t relogin_timer;		  /* Max Time to wait for
 					   * relogin to complete */
-	atomic_t relogin_retry_count;	  /* Num of times relogin has been
+	atomic_unchecked_t relogin_retry_count;	  /* Num of times relogin has been
 					   * retried */
 	uint32_t default_time2wait;	  /* Default Min time between
 					   * relogins (+aens) */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/qla4xxx/ql4_os.c linux-3.2.71-pax/drivers/scsi/qla4xxx/ql4_os.c
--- linux-3.2.71/drivers/scsi/qla4xxx/ql4_os.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/qla4xxx/ql4_os.c	2012-07-04 19:24:48.612063008 +0200
@@ -2104,12 +2104,12 @@ void qla4xxx_check_relogin_flash_ddb(str
 		 */
 		if (!iscsi_is_session_online(cls_sess)) {
 			/* Reset retry relogin timer */
-			atomic_inc(&ddb_entry->relogin_retry_count);
+			atomic_inc_unchecked(&ddb_entry->relogin_retry_count);
 			DEBUG2(ql4_printk(KERN_INFO, ha,
 				"%s: index[%d] relogin timed out-retrying"
 				" relogin (%d), retry (%d)\n", __func__,
 				ddb_entry->fw_ddb_index,
-				atomic_read(&ddb_entry->relogin_retry_count),
+				atomic_read_unchecked(&ddb_entry->relogin_retry_count),
 				ddb_entry->default_time2wait + 4));
 			set_bit(DPC_RELOGIN_DEVICE, &ha->dpc_flags);
 			atomic_set(&ddb_entry->retry_relogin_timer,
@@ -3835,7 +3835,7 @@ static void qla4xxx_setup_flash_ddb_entr
 
 	atomic_set(&ddb_entry->retry_relogin_timer, INVALID_ENTRY);
 	atomic_set(&ddb_entry->relogin_timer, 0);
-	atomic_set(&ddb_entry->relogin_retry_count, 0);
+	atomic_set_unchecked(&ddb_entry->relogin_retry_count, 0);
 
 	ddb_entry->default_relogin_timeout =
 		le16_to_cpu(ddb_entry->fw_ddb_entry.def_timeout);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/scsi.c linux-3.2.71-pax/drivers/scsi/scsi.c
--- linux-3.2.71/drivers/scsi/scsi.c	2012-08-03 01:53:47.290140442 +0200
+++ linux-3.2.71-pax/drivers/scsi/scsi.c	2015-06-26 17:57:12.058478695 +0200
@@ -655,7 +655,7 @@ int scsi_dispatch_cmd(struct scsi_cmnd *
 	unsigned long timeout;
 	int rtn = 0;
 
-	atomic_inc(&cmd->device->iorequest_cnt);
+	atomic_inc_unchecked(&cmd->device->iorequest_cnt);
 
 	/* check if the device is still usable */
 	if (unlikely(cmd->device->sdev_state == SDEV_DEL)) {
@@ -837,7 +837,7 @@ void scsi_finish_command(struct scsi_cmn
 
 	good_bytes = scsi_bufflen(cmd);
         if (cmd->request->cmd_type != REQ_TYPE_BLOCK_PC) {
-		int old_good_bytes = good_bytes;
+		unsigned int old_good_bytes = good_bytes;
 		drv = scsi_cmd_to_driver(cmd);
 		if (drv->done)
 			good_bytes = drv->done(cmd);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/scsi_lib.c linux-3.2.71-pax/drivers/scsi/scsi_lib.c
--- linux-3.2.71/drivers/scsi/scsi_lib.c	2015-05-10 09:22:37.955493078 +0200
+++ linux-3.2.71-pax/drivers/scsi/scsi_lib.c	2015-05-10 09:23:09.223494777 +0200
@@ -1437,7 +1437,7 @@ static void scsi_kill_request(struct req
 	shost = sdev->host;
 	scsi_init_cmd_errh(cmd);
 	cmd->result = DID_NO_CONNECT << 16;
-	atomic_inc(&cmd->device->iorequest_cnt);
+	atomic_inc_unchecked(&cmd->device->iorequest_cnt);
 
 	/*
 	 * SCSI request completion path will do scsi_device_unbusy(),
@@ -1463,9 +1463,9 @@ static void scsi_softirq_done(struct req
 
 	INIT_LIST_HEAD(&cmd->eh_entry);
 
-	atomic_inc(&cmd->device->iodone_cnt);
+	atomic_inc_unchecked(&cmd->device->iodone_cnt);
 	if (cmd->result)
-		atomic_inc(&cmd->device->ioerr_cnt);
+		atomic_inc_unchecked(&cmd->device->ioerr_cnt);
 
 	disposition = scsi_decide_disposition(cmd);
 	if (disposition != SUCCESS &&
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/scsi_sysfs.c linux-3.2.71-pax/drivers/scsi/scsi_sysfs.c
--- linux-3.2.71/drivers/scsi/scsi_sysfs.c	2014-07-12 17:42:33.848954215 +0200
+++ linux-3.2.71-pax/drivers/scsi/scsi_sysfs.c	2014-07-12 17:42:44.744954191 +0200
@@ -652,7 +652,7 @@ show_iostat_##field(struct device *dev,
 		    char *buf)						\
 {									\
 	struct scsi_device *sdev = to_scsi_device(dev);			\
-	unsigned long long count = atomic_read(&sdev->field);		\
+	unsigned long long count = atomic_read_unchecked(&sdev->field);	\
 	return snprintf(buf, 20, "0x%llx\n", count);			\
 }									\
 static DEVICE_ATTR(field, S_IRUGO, show_iostat_##field, NULL)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/scsi_tgt_lib.c linux-3.2.71-pax/drivers/scsi/scsi_tgt_lib.c
--- linux-3.2.71/drivers/scsi/scsi_tgt_lib.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/scsi_tgt_lib.c	2012-07-04 19:24:48.616063008 +0200
@@ -362,7 +362,7 @@ static int scsi_map_user_pages(struct sc
 	int err;
 
 	dprintk("%lx %u\n", uaddr, len);
-	err = blk_rq_map_user(q, rq, NULL, (void *)uaddr, len, GFP_KERNEL);
+	err = blk_rq_map_user(q, rq, NULL, (void __user *)uaddr, len, GFP_KERNEL);
 	if (err) {
 		/*
 		 * TODO: need to fixup sg_tablesize, max_segment_size,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/scsi_transport_fc.c linux-3.2.71-pax/drivers/scsi/scsi_transport_fc.c
--- linux-3.2.71/drivers/scsi/scsi_transport_fc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/scsi_transport_fc.c	2012-07-04 19:24:48.616063008 +0200
@@ -484,7 +484,7 @@ static DECLARE_TRANSPORT_CLASS(fc_vport_
  * Netlink Infrastructure
  */
 
-static atomic_t fc_event_seq;
+static atomic_unchecked_t fc_event_seq;
 
 /**
  * fc_get_event_number - Obtain the next sequential FC event number
@@ -497,7 +497,7 @@ static atomic_t fc_event_seq;
 u32
 fc_get_event_number(void)
 {
-	return atomic_add_return(1, &fc_event_seq);
+	return atomic_add_return_unchecked(1, &fc_event_seq);
 }
 EXPORT_SYMBOL(fc_get_event_number);
 
@@ -645,7 +645,7 @@ static __init int fc_transport_init(void
 {
 	int error;
 
-	atomic_set(&fc_event_seq, 0);
+	atomic_set_unchecked(&fc_event_seq, 0);
 
 	error = transport_class_register(&fc_host_class);
 	if (error)
@@ -835,7 +835,7 @@ static int fc_str_to_dev_loss(const char
 	char *cp;
 
 	*val = simple_strtoul(buf, &cp, 0);
-	if ((*cp && (*cp != '\n')) || (*val < 0))
+	if (*cp && (*cp != '\n'))
 		return -EINVAL;
 	/*
 	 * Check for overflow; dev_loss_tmo is u32
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/scsi_transport_iscsi.c linux-3.2.71-pax/drivers/scsi/scsi_transport_iscsi.c
--- linux-3.2.71/drivers/scsi/scsi_transport_iscsi.c	2013-10-27 17:59:57.784642356 +0100
+++ linux-3.2.71-pax/drivers/scsi/scsi_transport_iscsi.c	2013-10-27 18:00:09.516641730 +0100
@@ -79,7 +79,7 @@ struct iscsi_internal {
 	struct transport_container session_cont;
 };
 
-static atomic_t iscsi_session_nr; /* sysfs session id for next new session */
+static atomic_unchecked_t iscsi_session_nr; /* sysfs session id for next new session */
 static struct workqueue_struct *iscsi_eh_timer_workq;
 
 static DEFINE_IDA(iscsi_sess_ida);
@@ -1062,7 +1062,7 @@ int iscsi_add_session(struct iscsi_cls_s
 	int err;
 
 	ihost = shost->shost_data;
-	session->sid = atomic_add_return(1, &iscsi_session_nr);
+	session->sid = atomic_add_return_unchecked(1, &iscsi_session_nr);
 
 	if (target_id == ISCSI_MAX_TARGET) {
 		id = ida_simple_get(&iscsi_sess_ida, 0, 0, GFP_KERNEL);
@@ -2663,7 +2663,7 @@ static __init int iscsi_transport_init(v
 	printk(KERN_INFO "Loading iSCSI transport class v%s.\n",
 		ISCSI_TRANSPORT_VERSION);
 
-	atomic_set(&iscsi_session_nr, 0);
+	atomic_set_unchecked(&iscsi_session_nr, 0);
 
 	err = class_register(&iscsi_transport_class);
 	if (err)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/scsi_transport_srp.c linux-3.2.71-pax/drivers/scsi/scsi_transport_srp.c
--- linux-3.2.71/drivers/scsi/scsi_transport_srp.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/scsi_transport_srp.c	2012-07-04 19:24:48.616063008 +0200
@@ -33,7 +33,7 @@
 #include "scsi_transport_srp_internal.h"
 
 struct srp_host_attrs {
-	atomic_t next_port_id;
+	atomic_unchecked_t next_port_id;
 };
 #define to_srp_host_attrs(host)	((struct srp_host_attrs *)(host)->shost_data)
 
@@ -62,7 +62,7 @@ static int srp_host_setup(struct transpo
 	struct Scsi_Host *shost = dev_to_shost(dev);
 	struct srp_host_attrs *srp_host = to_srp_host_attrs(shost);
 
-	atomic_set(&srp_host->next_port_id, 0);
+	atomic_set_unchecked(&srp_host->next_port_id, 0);
 	return 0;
 }
 
@@ -211,7 +211,7 @@ struct srp_rport *srp_rport_add(struct S
 	memcpy(rport->port_id, ids->port_id, sizeof(rport->port_id));
 	rport->roles = ids->roles;
 
-	id = atomic_inc_return(&to_srp_host_attrs(shost)->next_port_id);
+	id = atomic_inc_return_unchecked(&to_srp_host_attrs(shost)->next_port_id);
 	dev_set_name(&rport->dev, "port-%d:%d", shost->host_no, id);
 
 	transport_setup_device(&rport->dev);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/sd.c linux-3.2.71-pax/drivers/scsi/sd.c
--- linux-3.2.71/drivers/scsi/sd.c	2015-08-07 11:37:20.539789893 +0200
+++ linux-3.2.71-pax/drivers/scsi/sd.c	2015-08-07 11:37:43.011790553 +0200
@@ -105,7 +105,7 @@ static void sd_shutdown(struct device *)
 static int sd_suspend(struct device *, pm_message_t state);
 static int sd_resume(struct device *);
 static void sd_rescan(struct device *);
-static int sd_done(struct scsi_cmnd *);
+static unsigned int sd_done(struct scsi_cmnd *);
 static void sd_read_capacity(struct scsi_disk *sdkp, unsigned char *buffer);
 static void scsi_disk_release(struct device *cdev);
 static void sd_print_sense_hdr(struct scsi_disk *, struct scsi_sense_hdr *);
@@ -1384,7 +1384,7 @@ static unsigned int sd_completed_bytes(s
  *
  *	Note: potentially run from within an ISR. Must not block.
  **/
-static int sd_done(struct scsi_cmnd *SCpnt)
+static unsigned int sd_done(struct scsi_cmnd *SCpnt)
 {
 	int result = SCpnt->result;
 	unsigned int good_bytes = result ? 0 : scsi_bufflen(SCpnt);
@@ -2626,7 +2626,7 @@ static int sd_probe(struct device *dev)
 	device_initialize(&sdkp->dev);
 	sdkp->dev.parent = dev;
 	sdkp->dev.class = &sd_disk_class;
-	dev_set_name(&sdkp->dev, dev_name(dev));
+	dev_set_name(&sdkp->dev, "%s", dev_name(dev));
 
 	if (device_add(&sdkp->dev))
 		goto out_free_index;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/sg.c linux-3.2.71-pax/drivers/scsi/sg.c
--- linux-3.2.71/drivers/scsi/sg.c	2015-08-07 11:37:20.539789893 +0200
+++ linux-3.2.71-pax/drivers/scsi/sg.c	2015-08-07 11:37:43.011790553 +0200
@@ -1077,7 +1077,7 @@ sg_ioctl(struct file *filp, unsigned int
 				       sdp->disk->disk_name,
 				       MKDEV(SCSI_GENERIC_MAJOR, sdp->index),
 				       NULL,
-				       (char *)arg);
+				       (char __user *)arg);
 	case BLKTRACESTART:
 		return blk_trace_startstop(sdp->device->request_queue, 1);
 	case BLKTRACESTOP:
@@ -2315,7 +2315,7 @@ struct sg_proc_leaf {
 	const struct file_operations * fops;
 };
 
-static struct sg_proc_leaf sg_proc_leaf_arr[] = {
+static const struct sg_proc_leaf sg_proc_leaf_arr[] = {
 	{"allow_dio", &adio_fops},
 	{"debug", &debug_fops},
 	{"def_reserved_size", &dressz_fops},
@@ -2330,7 +2330,7 @@ sg_proc_init(void)
 {
 	int k, mask;
 	int num_leaves = ARRAY_SIZE(sg_proc_leaf_arr);
-	struct sg_proc_leaf * leaf;
+	const struct sg_proc_leaf * leaf;
 
 	sg_proc_sgp = proc_mkdir(sg_proc_sg_dirname, NULL);
 	if (!sg_proc_sgp)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/scsi/sr.c linux-3.2.71-pax/drivers/scsi/sr.c
--- linux-3.2.71/drivers/scsi/sr.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/scsi/sr.c	2015-06-26 17:56:36.426478775 +0200
@@ -78,7 +78,7 @@ MODULE_ALIAS_SCSI_DEVICE(TYPE_WORM);
 static DEFINE_MUTEX(sr_mutex);
 static int sr_probe(struct device *);
 static int sr_remove(struct device *);
-static int sr_done(struct scsi_cmnd *);
+static unsigned int sr_done(struct scsi_cmnd *);
 
 static struct scsi_driver sr_template = {
 	.owner			= THIS_MODULE,
@@ -296,11 +296,11 @@ do_tur:
  * It will be notified on the end of a SCSI read / write, and will take one
  * of several actions based on success or failure.
  */
-static int sr_done(struct scsi_cmnd *SCpnt)
+static unsigned int sr_done(struct scsi_cmnd *SCpnt)
 {
 	int result = SCpnt->result;
-	int this_count = scsi_bufflen(SCpnt);
-	int good_bytes = (result == 0 ? this_count : 0);
+	unsigned int this_count = scsi_bufflen(SCpnt);
+	unsigned int good_bytes = (result == 0 ? this_count : 0);
 	int block_sectors = 0;
 	long error_sector;
 	struct scsi_cd *cd = scsi_cd(SCpnt->request->rq_disk);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/spi/spi.c linux-3.2.71-pax/drivers/spi/spi.c
--- linux-3.2.71/drivers/spi/spi.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/spi/spi.c	2012-07-04 19:24:48.620063007 +0200
@@ -1024,7 +1024,7 @@ int spi_bus_unlock(struct spi_master *ma
 EXPORT_SYMBOL_GPL(spi_bus_unlock);
 
 /* portable code must never pass more than 32 bytes */
-#define	SPI_BUFSIZ	max(32,SMP_CACHE_BYTES)
+#define	SPI_BUFSIZ	max(32UL,SMP_CACHE_BYTES)
 
 static u8	*buf;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/spi/spi-dw-pci.c linux-3.2.71-pax/drivers/spi/spi-dw-pci.c
--- linux-3.2.71/drivers/spi/spi-dw-pci.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/spi/spi-dw-pci.c	2012-07-04 19:24:48.620063007 +0200
@@ -149,7 +149,7 @@ static int spi_resume(struct pci_dev *pd
 #define spi_resume	NULL
 #endif
 
-static const struct pci_device_id pci_ids[] __devinitdata = {
+static const struct pci_device_id pci_ids[] __devinitconst = {
 	/* Intel MID platform SPI controller 0 */
 	{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x0800) },
 	{},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/gma500/power.c linux-3.2.71-pax/drivers/staging/gma500/power.c
--- linux-3.2.71/drivers/staging/gma500/power.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/gma500/power.c	2012-07-04 19:24:48.620063007 +0200
@@ -266,7 +266,7 @@ bool gma_power_begin(struct drm_device *
 	ret = gma_resume_pci(dev->pdev);
 	if (ret == 0) {
 		/* FIXME: we want to defer this for Medfield/Oaktrail */
-		gma_resume_display(dev);
+		gma_resume_display(dev->pdev);
 		psb_irq_preinstall(dev);
 		psb_irq_postinstall(dev);
 		pm_runtime_get(&dev->pdev->dev);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/hv/rndis_filter.c linux-3.2.71-pax/drivers/staging/hv/rndis_filter.c
--- linux-3.2.71/drivers/staging/hv/rndis_filter.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/hv/rndis_filter.c	2012-07-04 19:24:48.620063007 +0200
@@ -42,7 +42,7 @@ struct rndis_device {
 
 	enum rndis_device_state state;
 	bool link_state;
-	atomic_t new_req_id;
+	atomic_unchecked_t new_req_id;
 
 	spinlock_t request_lock;
 	struct list_head req_list;
@@ -116,7 +116,7 @@ static struct rndis_request *get_rndis_r
 	 * template
 	 */
 	set = &rndis_msg->msg.set_req;
-	set->req_id = atomic_inc_return(&dev->new_req_id);
+	set->req_id = atomic_inc_return_unchecked(&dev->new_req_id);
 
 	/* Add to the request list */
 	spin_lock_irqsave(&dev->request_lock, flags);
@@ -646,7 +646,7 @@ static void rndis_filter_halt_device(str
 
 	/* Setup the rndis set */
 	halt = &request->request_msg.msg.halt_req;
-	halt->req_id = atomic_inc_return(&dev->new_req_id);
+	halt->req_id = atomic_inc_return_unchecked(&dev->new_req_id);
 
 	/* Ignore return since this msg is optional. */
 	rndis_filter_send_request(dev, request);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/iio/buffer_generic.h linux-3.2.71-pax/drivers/staging/iio/buffer_generic.h
--- linux-3.2.71/drivers/staging/iio/buffer_generic.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/iio/buffer_generic.h	2012-07-04 19:24:48.620063007 +0200
@@ -64,7 +64,7 @@ struct iio_buffer_access_funcs {
 
 	int (*is_enabled)(struct iio_buffer *buffer);
 	int (*enable)(struct iio_buffer *buffer);
-};
+} __no_const;
 
 /**
  * struct iio_buffer_setup_ops - buffer setup related callbacks
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/iio/dac/ad5360.c linux-3.2.71-pax/drivers/staging/iio/dac/ad5360.c
--- linux-3.2.71/drivers/staging/iio/dac/ad5360.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/iio/dac/ad5360.c	2013-02-04 02:59:41.564216502 +0100
@@ -439,8 +439,8 @@ static int __devinit ad5360_alloc_channe
 	struct iio_chan_spec *channels;
 	unsigned int i;
 
-	channels = kcalloc(sizeof(struct iio_chan_spec),
-			st->chip_info->num_channels, GFP_KERNEL);
+	channels = kcalloc(st->chip_info->num_channels,
+			sizeof(struct iio_chan_spec), GFP_KERNEL);
 
 	if (!channels)
 		return -ENOMEM;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/iio/industrialio-core.c linux-3.2.71-pax/drivers/staging/iio/industrialio-core.c
--- linux-3.2.71/drivers/staging/iio/industrialio-core.c	2015-05-10 09:22:38.111493087 +0200
+++ linux-3.2.71-pax/drivers/staging/iio/industrialio-core.c	2015-05-10 09:23:09.295494781 +0200
@@ -398,7 +398,7 @@ static ssize_t iio_write_channel_info(st
 }
 
 static
-int __iio_device_attr_init(struct device_attribute *dev_attr,
+int __iio_device_attr_init(device_attribute_no_const *dev_attr,
 			   const char *postfix,
 			   struct iio_chan_spec const *chan,
 			   ssize_t (*readfunc)(struct device *dev,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/iio/ring_sw.c linux-3.2.71-pax/drivers/staging/iio/ring_sw.c
--- linux-3.2.71/drivers/staging/iio/ring_sw.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/iio/ring_sw.c	2013-05-13 13:25:29.567734930 +0200
@@ -173,7 +173,7 @@ static int iio_read_first_n_sw_rb(struct
 
 	u8 *initial_read_p, *initial_write_p, *current_read_p, *end_read_p;
 	u8 *data;
-	int ret, max_copied, bytes_to_rip, dead_offset;
+	long ret, max_copied, bytes_to_rip, dead_offset;
 
 	/* A userspace program has probably made an error if it tries to
 	 *  read something that is not a whole number of bpds.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/octeon/ethernet.c linux-3.2.71-pax/drivers/staging/octeon/ethernet.c
--- linux-3.2.71/drivers/staging/octeon/ethernet.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/octeon/ethernet.c	2012-07-04 19:24:48.624063007 +0200
@@ -258,11 +258,11 @@ static struct net_device_stats *cvm_oct_
 		 * since the RX tasklet also increments it.
 		 */
 #ifdef CONFIG_64BIT
-		atomic64_add(rx_status.dropped_packets,
-			     (atomic64_t *)&priv->stats.rx_dropped);
+		atomic64_add_unchecked(rx_status.dropped_packets,
+			     (atomic64_unchecked_t *)&priv->stats.rx_dropped);
 #else
-		atomic_add(rx_status.dropped_packets,
-			     (atomic_t *)&priv->stats.rx_dropped);
+		atomic_add_unchecked(rx_status.dropped_packets,
+			     (atomic_unchecked_t *)&priv->stats.rx_dropped);
 #endif
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/octeon/ethernet-rx.c linux-3.2.71-pax/drivers/staging/octeon/ethernet-rx.c
--- linux-3.2.71/drivers/staging/octeon/ethernet-rx.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/octeon/ethernet-rx.c	2014-03-14 14:11:22.596407023 +0100
@@ -420,11 +420,11 @@ static int cvm_oct_napi_poll(struct napi
 				/* Increment RX stats for virtual ports */
 				if (work->ipprt >= CVMX_PIP_NUM_INPUT_PORTS) {
 #ifdef CONFIG_64BIT
-					atomic64_add(1, (atomic64_t *)&priv->stats.rx_packets);
-					atomic64_add(skb->len, (atomic64_t *)&priv->stats.rx_bytes);
+					atomic64_add_unchecked(1, (atomic64_unchecked_t *)&priv->stats.rx_packets);
+					atomic64_add_unchecked(skb->len, (atomic64_unchecked_t *)&priv->stats.rx_bytes);
 #else
-					atomic_add(1, (atomic_t *)&priv->stats.rx_packets);
-					atomic_add(skb->len, (atomic_t *)&priv->stats.rx_bytes);
+					atomic_add_unchecked(1, (atomic_unchecked_t *)&priv->stats.rx_packets);
+					atomic_add_unchecked(skb->len, (atomic_unchecked_t *)&priv->stats.rx_bytes);
 #endif
 				}
 				netif_receive_skb(skb);
@@ -436,9 +436,9 @@ static int cvm_oct_napi_poll(struct napi
 					   dev->name);
 				*/
 #ifdef CONFIG_64BIT
-				atomic64_add(1, (atomic64_t *)&priv->stats.rx_dropped);
+				atomic64_add_unchecked(1, (atomic64_unchecked_t *)&priv->stats.rx_dropped);
 #else
-				atomic_add(1, (atomic_t *)&priv->stats.rx_dropped);
+				atomic_add_unchecked(1, (atomic_unchecked_t *)&priv->stats.rx_dropped);
 #endif
 				dev_kfree_skb_irq(skb);
 			}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/pohmelfs/inode.c linux-3.2.71-pax/drivers/staging/pohmelfs/inode.c
--- linux-3.2.71/drivers/staging/pohmelfs/inode.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/pohmelfs/inode.c	2012-07-04 19:24:48.624063007 +0200
@@ -1861,7 +1861,7 @@ static int pohmelfs_fill_super(struct su
 	mutex_init(&psb->mcache_lock);
 	psb->mcache_root = RB_ROOT;
 	psb->mcache_timeout = msecs_to_jiffies(5000);
-	atomic_long_set(&psb->mcache_gen, 0);
+	atomic_long_set_unchecked(&psb->mcache_gen, 0);
 
 	psb->trans_max_pages = 100;
 
@@ -1876,7 +1876,7 @@ static int pohmelfs_fill_super(struct su
 	INIT_LIST_HEAD(&psb->crypto_ready_list);
 	INIT_LIST_HEAD(&psb->crypto_active_list);
 
-	atomic_set(&psb->trans_gen, 1);
+	atomic_set_unchecked(&psb->trans_gen, 1);
 	atomic_long_set(&psb->total_inodes, 0);
 
 	mutex_init(&psb->state_lock);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/pohmelfs/mcache.c linux-3.2.71-pax/drivers/staging/pohmelfs/mcache.c
--- linux-3.2.71/drivers/staging/pohmelfs/mcache.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/pohmelfs/mcache.c	2012-07-04 19:24:48.624063007 +0200
@@ -121,7 +121,7 @@ struct pohmelfs_mcache *pohmelfs_mcache_
 	m->data = data;
 	m->start = start;
 	m->size = size;
-	m->gen = atomic_long_inc_return(&psb->mcache_gen);
+	m->gen = atomic_long_inc_return_unchecked(&psb->mcache_gen);
 
 	mutex_lock(&psb->mcache_lock);
 	err = pohmelfs_mcache_insert(psb, m);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/pohmelfs/netfs.h linux-3.2.71-pax/drivers/staging/pohmelfs/netfs.h
--- linux-3.2.71/drivers/staging/pohmelfs/netfs.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/pohmelfs/netfs.h	2012-07-04 19:24:48.624063007 +0200
@@ -571,14 +571,14 @@ struct pohmelfs_config;
 struct pohmelfs_sb {
 	struct rb_root		mcache_root;
 	struct mutex		mcache_lock;
-	atomic_long_t		mcache_gen;
+	atomic_long_unchecked_t	mcache_gen;
 	unsigned long		mcache_timeout;
 
 	unsigned int		idx;
 
 	unsigned int		trans_retries;
 
-	atomic_t		trans_gen;
+	atomic_unchecked_t	trans_gen;
 
 	unsigned int		crypto_attached_size;
 	unsigned int		crypto_align_size;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/pohmelfs/trans.c linux-3.2.71-pax/drivers/staging/pohmelfs/trans.c
--- linux-3.2.71/drivers/staging/pohmelfs/trans.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/pohmelfs/trans.c	2012-07-04 19:24:48.624063007 +0200
@@ -492,7 +492,7 @@ int netfs_trans_finish(struct netfs_tran
 	int err;
 	struct netfs_cmd *cmd = t->iovec.iov_base;
 
-	t->gen = atomic_inc_return(&psb->trans_gen);
+	t->gen = atomic_inc_return_unchecked(&psb->trans_gen);
 
 	cmd->size = t->iovec.iov_len - sizeof(struct netfs_cmd) +
 		t->attached_size + t->attached_pages * sizeof(struct netfs_cmd);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/rtl8712/rtl871x_io.h linux-3.2.71-pax/drivers/staging/rtl8712/rtl871x_io.h
--- linux-3.2.71/drivers/staging/rtl8712/rtl871x_io.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/rtl8712/rtl871x_io.h	2012-07-04 19:24:48.628063008 +0200
@@ -108,7 +108,7 @@ struct	_io_ops {
 			  u8 *pmem);
 	u32 (*_write_port)(struct intf_hdl *pintfhdl, u32 addr, u32 cnt,
 			   u8 *pmem);
-};
+} __no_const;
 
 struct io_req {
 	struct list_head list;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/sbe-2t3e3/netdev.c linux-3.2.71-pax/drivers/staging/sbe-2t3e3/netdev.c
--- linux-3.2.71/drivers/staging/sbe-2t3e3/netdev.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/sbe-2t3e3/netdev.c	2012-07-04 19:24:48.628063008 +0200
@@ -51,7 +51,7 @@ int t3e3_ioctl(struct net_device *dev, s
 	t3e3_if_config(sc, cmd_2t3e3, (char *)&param, &resp, &rlen);
 
 	if (rlen)
-		if (copy_to_user(data, &resp, rlen))
+		if (rlen > sizeof resp || copy_to_user(data, &resp, rlen))
 			return -EFAULT;
 
 	return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/usbip/vhci.h linux-3.2.71-pax/drivers/staging/usbip/vhci.h
--- linux-3.2.71/drivers/staging/usbip/vhci.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/usbip/vhci.h	2012-07-04 19:24:48.628063008 +0200
@@ -88,7 +88,7 @@ struct vhci_hcd {
 	unsigned resuming:1;
 	unsigned long re_timeout;
 
-	atomic_t seqnum;
+	atomic_unchecked_t seqnum;
 
 	/*
 	 * NOTE:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/usbip/vhci_hcd.c linux-3.2.71-pax/drivers/staging/usbip/vhci_hcd.c
--- linux-3.2.71/drivers/staging/usbip/vhci_hcd.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/usbip/vhci_hcd.c	2012-07-04 19:24:48.628063008 +0200
@@ -527,7 +527,7 @@ static void vhci_tx_urb(struct urb *urb)
 		return;
 	}
 
-	priv->seqnum = atomic_inc_return(&the_controller->seqnum);
+	priv->seqnum = atomic_inc_return_unchecked(&the_controller->seqnum);
 	if (priv->seqnum == 0xffff)
 		dev_info(&urb->dev->dev, "seqnum max\n");
 
@@ -779,7 +779,7 @@ static int vhci_urb_dequeue(struct usb_h
 			return -ENOMEM;
 		}
 
-		unlink->seqnum = atomic_inc_return(&the_controller->seqnum);
+		unlink->seqnum = atomic_inc_return_unchecked(&the_controller->seqnum);
 		if (unlink->seqnum == 0xffff)
 			pr_info("seqnum max\n");
 
@@ -969,7 +969,7 @@ static int vhci_start(struct usb_hcd *hc
 		vdev->rhport = rhport;
 	}
 
-	atomic_set(&vhci->seqnum, 0);
+	atomic_set_unchecked(&vhci->seqnum, 0);
 	spin_lock_init(&vhci->lock);
 
 	hcd->power_budget = 0; /* no limit */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/usbip/vhci_rx.c linux-3.2.71-pax/drivers/staging/usbip/vhci_rx.c
--- linux-3.2.71/drivers/staging/usbip/vhci_rx.c	2013-02-09 01:12:40.756782285 +0100
+++ linux-3.2.71-pax/drivers/staging/usbip/vhci_rx.c	2013-02-09 01:12:47.008782469 +0100
@@ -77,7 +77,7 @@ static void vhci_recv_ret_submit(struct
 	if (!urb) {
 		pr_err("cannot find a urb of seqnum %u\n", pdu->base.seqnum);
 		pr_info("max seqnum %d\n",
-			atomic_read(&the_controller->seqnum));
+			atomic_read_unchecked(&the_controller->seqnum));
 		usbip_event_add(ud, VDEV_EVENT_ERROR_TCP);
 		return;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/vt6655/hostap.c linux-3.2.71-pax/drivers/staging/vt6655/hostap.c
--- linux-3.2.71/drivers/staging/vt6655/hostap.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/vt6655/hostap.c	2012-07-04 19:24:48.628063008 +0200
@@ -79,14 +79,13 @@ static int          msglevel
  *
  */
 
+static net_device_ops_no_const apdev_netdev_ops;
+
 static int hostap_enable_hostapd(PSDevice pDevice, int rtnl_locked)
 {
     PSDevice apdev_priv;
 	struct net_device *dev = pDevice->dev;
 	int ret;
-	const struct net_device_ops apdev_netdev_ops = {
-		.ndo_start_xmit         = pDevice->tx_80211,
-	};
 
     DBG_PRT(MSG_LEVEL_DEBUG, KERN_INFO "%s: Enabling hostapd mode\n", dev->name);
 
@@ -98,6 +97,8 @@ static int hostap_enable_hostapd(PSDevic
     *apdev_priv = *pDevice;
 	memcpy(pDevice->apdev->dev_addr, dev->dev_addr, ETH_ALEN);
 
+	/* only half broken now */
+	apdev_netdev_ops.ndo_start_xmit = pDevice->tx_80211;
 	pDevice->apdev->netdev_ops = &apdev_netdev_ops;
 
 	pDevice->apdev->type = ARPHRD_IEEE80211;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/vt6656/hostap.c linux-3.2.71-pax/drivers/staging/vt6656/hostap.c
--- linux-3.2.71/drivers/staging/vt6656/hostap.c	2013-06-09 18:04:43.369591751 +0200
+++ linux-3.2.71-pax/drivers/staging/vt6656/hostap.c	2013-06-09 18:04:48.885591457 +0200
@@ -80,14 +80,13 @@ static int          msglevel
  *
  */
 
+static net_device_ops_no_const apdev_netdev_ops;
+
 static int hostap_enable_hostapd(PSDevice pDevice, int rtnl_locked)
 {
     PSDevice apdev_priv;
 	struct net_device *dev = pDevice->dev;
 	int ret;
-	const struct net_device_ops apdev_netdev_ops = {
-		.ndo_start_xmit         = pDevice->tx_80211,
-	};
 
     DBG_PRT(MSG_LEVEL_DEBUG, KERN_INFO "%s: Enabling hostapd mode\n", dev->name);
 
@@ -99,6 +98,8 @@ static int hostap_enable_hostapd(PSDevic
     *apdev_priv = *pDevice;
 	memcpy(pDevice->apdev->dev_addr, dev->dev_addr, ETH_ALEN);
 
+	/* only half broken now */
+	apdev_netdev_ops.ndo_start_xmit = pDevice->tx_80211;
 	pDevice->apdev->netdev_ops = &apdev_netdev_ops;
 
 	pDevice->apdev->type = ARPHRD_IEEE80211;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/zcache/tmem.c linux-3.2.71-pax/drivers/staging/zcache/tmem.c
--- linux-3.2.71/drivers/staging/zcache/tmem.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/zcache/tmem.c	2012-07-04 19:24:48.632063008 +0200
@@ -39,7 +39,7 @@
  * A tmem host implementation must use this function to register callbacks
  * for memory allocation.
  */
-static struct tmem_hostops tmem_hostops;
+static tmem_hostops_no_const tmem_hostops;
 
 static void tmem_objnode_tree_init(void);
 
@@ -53,7 +53,7 @@ void tmem_register_hostops(struct tmem_h
  * A tmem host implementation must use this function to register
  * callbacks for a page-accessible memory (PAM) implementation
  */
-static struct tmem_pamops tmem_pamops;
+static tmem_pamops_no_const tmem_pamops;
 
 void tmem_register_pamops(struct tmem_pamops *m)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/staging/zcache/tmem.h linux-3.2.71-pax/drivers/staging/zcache/tmem.h
--- linux-3.2.71/drivers/staging/zcache/tmem.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/staging/zcache/tmem.h	2012-07-04 19:24:48.632063008 +0200
@@ -180,6 +180,7 @@ struct tmem_pamops {
 	void (*new_obj)(struct tmem_obj *);
 	int (*replace_in_obj)(void *, struct tmem_obj *);
 };
+typedef struct tmem_pamops __no_const tmem_pamops_no_const;
 extern void tmem_register_pamops(struct tmem_pamops *m);
 
 /* memory allocation methods provided by the host implementation */
@@ -189,6 +190,7 @@ struct tmem_hostops {
 	struct tmem_objnode *(*objnode_alloc)(struct tmem_pool *);
 	void (*objnode_free)(struct tmem_objnode *, struct tmem_pool *);
 };
+typedef struct tmem_hostops __no_const tmem_hostops_no_const;
 extern void tmem_register_hostops(struct tmem_hostops *m);
 
 /* core tmem accessor functions */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/target/iscsi/iscsi_target.c linux-3.2.71-pax/drivers/target/iscsi/iscsi_target.c
--- linux-3.2.71/drivers/target/iscsi/iscsi_target.c	2015-08-14 21:48:35.280707914 +0200
+++ linux-3.2.71-pax/drivers/target/iscsi/iscsi_target.c	2015-08-14 21:48:45.620707362 +0200
@@ -1357,7 +1357,7 @@ static int iscsit_handle_data_out(struct
 		 * outstanding_r2ts reaches zero, go ahead and send the delayed
 		 * TASK_ABORTED status.
 		 */
-		if (atomic_read(&se_cmd->t_transport_aborted) != 0) {
+		if (atomic_read_unchecked(&se_cmd->t_transport_aborted) != 0) {
 			if (hdr->flags & ISCSI_FLAG_CMD_FINAL)
 				if (--cmd->outstanding_r2ts < 1) {
 					iscsit_stop_dataout_timer(cmd);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/target/target_core_tmr.c linux-3.2.71-pax/drivers/target/target_core_tmr.c
--- linux-3.2.71/drivers/target/target_core_tmr.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/target/target_core_tmr.c	2012-07-04 19:24:48.636063007 +0200
@@ -250,7 +250,7 @@ static void core_tmr_drain_task_list(
 			cmd->se_tfo->get_task_tag(cmd), cmd->pr_res_key,
 			cmd->t_task_list_num,
 			atomic_read(&cmd->t_task_cdbs_left),
-			atomic_read(&cmd->t_task_cdbs_sent),
+			atomic_read_unchecked(&cmd->t_task_cdbs_sent),
 			atomic_read(&cmd->t_transport_active),
 			atomic_read(&cmd->t_transport_stop),
 			atomic_read(&cmd->t_transport_sent));
@@ -281,7 +281,7 @@ static void core_tmr_drain_task_list(
 			pr_debug("LUN_RESET: got t_transport_active = 1 for"
 				" task: %p, t_fe_count: %d dev: %p\n", task,
 				fe_count, dev);
-			atomic_set(&cmd->t_transport_aborted, 1);
+			atomic_set_unchecked(&cmd->t_transport_aborted, 1);
 			spin_unlock_irqrestore(&cmd->t_state_lock, flags);
 
 			core_tmr_handle_tas_abort(tmr_nacl, cmd, tas, fe_count);
@@ -289,7 +289,7 @@ static void core_tmr_drain_task_list(
 		}
 		pr_debug("LUN_RESET: Got t_transport_active = 0 for task: %p,"
 			" t_fe_count: %d dev: %p\n", task, fe_count, dev);
-		atomic_set(&cmd->t_transport_aborted, 1);
+		atomic_set_unchecked(&cmd->t_transport_aborted, 1);
 		spin_unlock_irqrestore(&cmd->t_state_lock, flags);
 
 		core_tmr_handle_tas_abort(tmr_nacl, cmd, tas, fe_count);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/target/target_core_transport.c linux-3.2.71-pax/drivers/target/target_core_transport.c
--- linux-3.2.71/drivers/target/target_core_transport.c	2014-12-14 21:13:45.186055050 +0100
+++ linux-3.2.71-pax/drivers/target/target_core_transport.c	2014-12-14 21:13:52.798069270 +0100
@@ -1343,7 +1343,7 @@ struct se_device *transport_add_device_t
 
 	dev->queue_depth	= dev_limits->queue_depth;
 	atomic_set(&dev->depth_left, dev->queue_depth);
-	atomic_set(&dev->dev_ordered_id, 0);
+	atomic_set_unchecked(&dev->dev_ordered_id, 0);
 
 	se_dev_set_default_attribs(dev, dev_limits);
 
@@ -1531,7 +1531,7 @@ static int transport_check_alloc_task_at
 	 * Used to determine when ORDERED commands should go from
 	 * Dormant to Active status.
 	 */
-	cmd->se_ordered_id = atomic_inc_return(&cmd->se_dev->dev_ordered_id);
+	cmd->se_ordered_id = atomic_inc_return_unchecked(&cmd->se_dev->dev_ordered_id);
 	smp_mb__after_atomic_inc();
 	pr_debug("Allocated se_ordered_id: %u for Task Attr: 0x%02x on %s\n",
 			cmd->se_ordered_id, cmd->sam_task_attr,
@@ -1801,7 +1801,7 @@ static void transport_generic_request_fa
 		" t_transport_active: %d t_transport_stop: %d"
 		" t_transport_sent: %d\n", cmd->t_task_list_num,
 		atomic_read(&cmd->t_task_cdbs_left),
-		atomic_read(&cmd->t_task_cdbs_sent),
+		atomic_read_unchecked(&cmd->t_task_cdbs_sent),
 		atomic_read(&cmd->t_task_cdbs_ex_left),
 		atomic_read(&cmd->t_transport_active),
 		atomic_read(&cmd->t_transport_stop),
@@ -2091,9 +2091,9 @@ check_depth:
 
 	spin_lock_irqsave(&cmd->t_state_lock, flags);
 	task->task_flags |= (TF_ACTIVE | TF_SENT);
-	atomic_inc(&cmd->t_task_cdbs_sent);
+	atomic_inc_unchecked(&cmd->t_task_cdbs_sent);
 
-	if (atomic_read(&cmd->t_task_cdbs_sent) ==
+	if (atomic_read_unchecked(&cmd->t_task_cdbs_sent) ==
 	    cmd->t_task_list_num)
 		atomic_set(&cmd->t_transport_sent, 1);
 
@@ -4303,7 +4303,7 @@ bool transport_wait_for_tasks(struct se_
 		atomic_set(&cmd->transport_lun_stop, 0);
 	}
 	if (!atomic_read(&cmd->t_transport_active) ||
-	     atomic_read(&cmd->t_transport_aborted)) {
+	     atomic_read_unchecked(&cmd->t_transport_aborted)) {
 		spin_unlock_irqrestore(&cmd->t_state_lock, flags);
 		return false;
 	}
@@ -4561,7 +4561,7 @@ int transport_check_aborted_status(struc
 {
 	int ret = 0;
 
-	if (atomic_read(&cmd->t_transport_aborted) != 0) {
+	if (atomic_read_unchecked(&cmd->t_transport_aborted) != 0) {
 		if (!send_status ||
 		     (cmd->se_cmd_flags & SCF_SENT_DELAYED_TAS))
 			return 1;
@@ -4598,7 +4598,7 @@ void transport_send_task_abort(struct se
 	 */
 	if (cmd->data_direction == DMA_TO_DEVICE) {
 		if (cmd->se_tfo->write_pending_status(cmd) != 0) {
-			atomic_inc(&cmd->t_transport_aborted);
+			atomic_inc_unchecked(&cmd->t_transport_aborted);
 			smp_mb__after_atomic_inc();
 		}
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/tty/hvc/hvcs.c linux-3.2.71-pax/drivers/tty/hvc/hvcs.c
--- linux-3.2.71/drivers/tty/hvc/hvcs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/tty/hvc/hvcs.c	2012-07-04 19:24:48.640063007 +0200
@@ -83,6 +83,7 @@
 #include <asm/hvcserver.h>
 #include <asm/uaccess.h>
 #include <asm/vio.h>
+#include <asm/local.h>
 
 /*
  * 1.3.0 -> 1.3.1 In hvcs_open memset(..,0x00,..) instead of memset(..,0x3F,00).
@@ -270,7 +271,7 @@ struct hvcs_struct {
 	unsigned int index;
 
 	struct tty_struct *tty;
-	int open_count;
+	local_t open_count;
 
 	/*
 	 * Used to tell the driver kernel_thread what operations need to take
@@ -422,7 +423,7 @@ static ssize_t hvcs_vterm_state_store(st
 
 	spin_lock_irqsave(&hvcsd->lock, flags);
 
-	if (hvcsd->open_count > 0) {
+	if (local_read(&hvcsd->open_count) > 0) {
 		spin_unlock_irqrestore(&hvcsd->lock, flags);
 		printk(KERN_INFO "HVCS: vterm state unchanged.  "
 				"The hvcs device node is still in use.\n");
@@ -1145,7 +1146,7 @@ static int hvcs_open(struct tty_struct *
 		if ((retval = hvcs_partner_connect(hvcsd)))
 			goto error_release;
 
-	hvcsd->open_count = 1;
+	local_set(&hvcsd->open_count, 1);
 	hvcsd->tty = tty;
 	tty->driver_data = hvcsd;
 
@@ -1179,7 +1180,7 @@ fast_open:
 
 	spin_lock_irqsave(&hvcsd->lock, flags);
 	kref_get(&hvcsd->kref);
-	hvcsd->open_count++;
+	local_inc(&hvcsd->open_count);
 	hvcsd->todo_mask |= HVCS_SCHED_READ;
 	spin_unlock_irqrestore(&hvcsd->lock, flags);
 
@@ -1223,7 +1224,7 @@ static void hvcs_close(struct tty_struct
 	hvcsd = tty->driver_data;
 
 	spin_lock_irqsave(&hvcsd->lock, flags);
-	if (--hvcsd->open_count == 0) {
+	if (local_dec_and_test(&hvcsd->open_count)) {
 
 		vio_disable_interrupts(hvcsd->vdev);
 
@@ -1249,10 +1250,10 @@ static void hvcs_close(struct tty_struct
 		free_irq(irq, hvcsd);
 		kref_put(&hvcsd->kref, destroy_hvcs_struct);
 		return;
-	} else if (hvcsd->open_count < 0) {
+	} else if (local_read(&hvcsd->open_count) < 0) {
 		printk(KERN_ERR "HVCS: vty-server@%X open_count: %d"
 				" is missmanaged.\n",
-		hvcsd->vdev->unit_address, hvcsd->open_count);
+		hvcsd->vdev->unit_address, local_read(&hvcsd->open_count));
 	}
 
 	spin_unlock_irqrestore(&hvcsd->lock, flags);
@@ -1268,7 +1269,7 @@ static void hvcs_hangup(struct tty_struc
 
 	spin_lock_irqsave(&hvcsd->lock, flags);
 	/* Preserve this so that we know how many kref refs to put */
-	temp_open_count = hvcsd->open_count;
+	temp_open_count = local_read(&hvcsd->open_count);
 
 	/*
 	 * Don't kref put inside the spinlock because the destruction
@@ -1283,7 +1284,7 @@ static void hvcs_hangup(struct tty_struc
 	hvcsd->tty->driver_data = NULL;
 	hvcsd->tty = NULL;
 
-	hvcsd->open_count = 0;
+	local_set(&hvcsd->open_count, 0);
 
 	/* This will drop any buffered data on the floor which is OK in a hangup
 	 * scenario. */
@@ -1354,7 +1355,7 @@ static int hvcs_write(struct tty_struct
 	 * the middle of a write operation?  This is a crummy place to do this
 	 * but we want to keep it all in the spinlock.
 	 */
-	if (hvcsd->open_count <= 0) {
+	if (local_read(&hvcsd->open_count) <= 0) {
 		spin_unlock_irqrestore(&hvcsd->lock, flags);
 		return -ENODEV;
 	}
@@ -1428,7 +1429,7 @@ static int hvcs_write_room(struct tty_st
 {
 	struct hvcs_struct *hvcsd = tty->driver_data;
 
-	if (!hvcsd || hvcsd->open_count <= 0)
+	if (!hvcsd || local_read(&hvcsd->open_count) <= 0)
 		return 0;
 
 	return HVCS_BUFF_LEN - hvcsd->chars_in_buffer;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/tty/hvc/hvsi.c linux-3.2.71-pax/drivers/tty/hvc/hvsi.c
--- linux-3.2.71/drivers/tty/hvc/hvsi.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/tty/hvc/hvsi.c	2013-09-01 20:11:55.247806333 +0200
@@ -86,7 +86,7 @@ struct hvsi_struct {
 	int n_outbuf;
 	uint32_t vtermno;
 	uint32_t virq;
-	atomic_t seqno; /* HVSI packet sequence number */
+	atomic_unchecked_t seqno; /* HVSI packet sequence number */
 	uint16_t mctrl;
 	uint8_t state;  /* HVSI protocol state */
 	uint8_t flags;
@@ -297,7 +297,7 @@ static int hvsi_version_respond(struct h
 
 	packet.hdr.type = VS_QUERY_RESPONSE_PACKET_HEADER;
 	packet.hdr.len = sizeof(struct hvsi_query_response);
-	packet.hdr.seqno = atomic_inc_return(&hp->seqno);
+	packet.hdr.seqno = atomic_inc_return_unchecked(&hp->seqno);
 	packet.verb = VSV_SEND_VERSION_NUMBER;
 	packet.u.version = HVSI_VERSION;
 	packet.query_seqno = query_seqno+1;
@@ -581,7 +581,7 @@ static int hvsi_query(struct hvsi_struct
 
 	packet.hdr.type = VS_QUERY_PACKET_HEADER;
 	packet.hdr.len = sizeof(struct hvsi_query);
-	packet.hdr.seqno = atomic_inc_return(&hp->seqno);
+	packet.hdr.seqno = atomic_inc_return_unchecked(&hp->seqno);
 	packet.verb = verb;
 
 	pr_debug("%s: sending %i bytes\n", __func__, packet.hdr.len);
@@ -623,7 +623,7 @@ static int hvsi_set_mctrl(struct hvsi_st
 	int wrote;
 
 	packet.hdr.type = VS_CONTROL_PACKET_HEADER,
-	packet.hdr.seqno = atomic_inc_return(&hp->seqno);
+	packet.hdr.seqno = atomic_inc_return_unchecked(&hp->seqno);
 	packet.hdr.len = sizeof(struct hvsi_control);
 	packet.verb = VSV_SET_MODEM_CTL;
 	packet.mask = HVSI_TSDTR;
@@ -706,7 +706,7 @@ static int hvsi_put_chars(struct hvsi_st
 	BUG_ON(count > HVSI_MAX_OUTGOING_DATA);
 
 	packet.hdr.type = VS_DATA_PACKET_HEADER;
-	packet.hdr.seqno = atomic_inc_return(&hp->seqno);
+	packet.hdr.seqno = atomic_inc_return_unchecked(&hp->seqno);
 	packet.hdr.len = count + sizeof(struct hvsi_header);
 	memcpy(&packet.data, buf, count);
 
@@ -723,7 +723,7 @@ static void hvsi_close_protocol(struct h
 	struct hvsi_control packet __ALIGNED__;
 
 	packet.hdr.type = VS_CONTROL_PACKET_HEADER;
-	packet.hdr.seqno = atomic_inc_return(&hp->seqno);
+	packet.hdr.seqno = atomic_inc_return_unchecked(&hp->seqno);
 	packet.hdr.len = 6;
 	packet.verb = VSV_CLOSE_PROTOCOL;
 
@@ -755,7 +755,7 @@ static int hvsi_open(struct tty_struct *
 	spin_lock_irqsave(&hp->lock, flags);
 	hp->tty = tty;
 	hp->count++;
-	atomic_set(&hp->seqno, 0);
+	atomic_set_unchecked(&hp->seqno, 0);
 	h_vio_signal(hp->vtermno, VIO_IRQ_ENABLE);
 	spin_unlock_irqrestore(&hp->lock, flags);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/tty/hvc/hvsi_lib.c linux-3.2.71-pax/drivers/tty/hvc/hvsi_lib.c
--- linux-3.2.71/drivers/tty/hvc/hvsi_lib.c	2013-09-10 17:24:55.509739117 +0200
+++ linux-3.2.71-pax/drivers/tty/hvc/hvsi_lib.c	2013-09-10 17:24:59.061738928 +0200
@@ -9,7 +9,7 @@
 
 static int hvsi_send_packet(struct hvsi_priv *pv, struct hvsi_header *packet)
 {
-	packet->seqno = atomic_inc_return(&pv->seqno);
+	packet->seqno = atomic_inc_return_unchecked(&pv->seqno);
 
 	/* Assumes that always succeeds, works in practice */
 	return pv->put_chars(pv->termno, (char *)packet, packet->len);
@@ -21,7 +21,7 @@ static void hvsi_start_handshake(struct
 
 	/* Reset state */
 	pv->established = 0;
-	atomic_set(&pv->seqno, 0);
+	atomic_set_unchecked(&pv->seqno, 0);
 
 	pr_devel("HVSI@%x: Handshaking started\n", pv->termno);
 
@@ -265,7 +265,7 @@ int hvsilib_read_mctrl(struct hvsi_priv
 	pv->mctrl_update = 0;
 	q.hdr.type = VS_QUERY_PACKET_HEADER;
 	q.hdr.len = sizeof(struct hvsi_query);
-	q.hdr.seqno = atomic_inc_return(&pv->seqno);
+	q.hdr.seqno = atomic_inc_return_unchecked(&pv->seqno);
 	q.verb = VSV_SEND_MODEM_CTL_STATUS;
 	rc = hvsi_send_packet(pv, &q.hdr);
 	if (rc <= 0) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/tty/ipwireless/tty.c linux-3.2.71-pax/drivers/tty/ipwireless/tty.c
--- linux-3.2.71/drivers/tty/ipwireless/tty.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/tty/ipwireless/tty.c	2012-07-04 19:24:48.640063007 +0200
@@ -29,6 +29,7 @@
 #include <linux/tty_driver.h>
 #include <linux/tty_flip.h>
 #include <linux/uaccess.h>
+#include <asm/local.h>
 
 #include "tty.h"
 #include "network.h"
@@ -51,7 +52,7 @@ struct ipw_tty {
 	int tty_type;
 	struct ipw_network *network;
 	struct tty_struct *linux_tty;
-	int open_count;
+	local_t open_count;
 	unsigned int control_lines;
 	struct mutex ipw_tty_mutex;
 	int tx_bytes_queued;
@@ -127,10 +128,10 @@ static int ipw_open(struct tty_struct *l
 		mutex_unlock(&tty->ipw_tty_mutex);
 		return -ENODEV;
 	}
-	if (tty->open_count == 0)
+	if (local_read(&tty->open_count) == 0)
 		tty->tx_bytes_queued = 0;
 
-	tty->open_count++;
+	local_inc(&tty->open_count);
 
 	tty->linux_tty = linux_tty;
 	linux_tty->driver_data = tty;
@@ -146,9 +147,7 @@ static int ipw_open(struct tty_struct *l
 
 static void do_ipw_close(struct ipw_tty *tty)
 {
-	tty->open_count--;
-
-	if (tty->open_count == 0) {
+	if (local_dec_return(&tty->open_count) == 0) {
 		struct tty_struct *linux_tty = tty->linux_tty;
 
 		if (linux_tty != NULL) {
@@ -169,7 +168,7 @@ static void ipw_hangup(struct tty_struct
 		return;
 
 	mutex_lock(&tty->ipw_tty_mutex);
-	if (tty->open_count == 0) {
+	if (local_read(&tty->open_count) == 0) {
 		mutex_unlock(&tty->ipw_tty_mutex);
 		return;
 	}
@@ -198,7 +197,7 @@ void ipwireless_tty_received(struct ipw_
 		return;
 	}
 
-	if (!tty->open_count) {
+	if (!local_read(&tty->open_count)) {
 		mutex_unlock(&tty->ipw_tty_mutex);
 		return;
 	}
@@ -240,7 +239,7 @@ static int ipw_write(struct tty_struct *
 		return -ENODEV;
 
 	mutex_lock(&tty->ipw_tty_mutex);
-	if (!tty->open_count) {
+	if (!local_read(&tty->open_count)) {
 		mutex_unlock(&tty->ipw_tty_mutex);
 		return -EINVAL;
 	}
@@ -280,7 +279,7 @@ static int ipw_write_room(struct tty_str
 	if (!tty)
 		return -ENODEV;
 
-	if (!tty->open_count)
+	if (!local_read(&tty->open_count))
 		return -EINVAL;
 
 	room = IPWIRELESS_TX_QUEUE_SIZE - tty->tx_bytes_queued;
@@ -322,7 +321,7 @@ static int ipw_chars_in_buffer(struct tt
 	if (!tty)
 		return 0;
 
-	if (!tty->open_count)
+	if (!local_read(&tty->open_count))
 		return 0;
 
 	return tty->tx_bytes_queued;
@@ -403,7 +402,7 @@ static int ipw_tiocmget(struct tty_struc
 	if (!tty)
 		return -ENODEV;
 
-	if (!tty->open_count)
+	if (!local_read(&tty->open_count))
 		return -EINVAL;
 
 	return get_control_lines(tty);
@@ -419,7 +418,7 @@ ipw_tiocmset(struct tty_struct *linux_tt
 	if (!tty)
 		return -ENODEV;
 
-	if (!tty->open_count)
+	if (!local_read(&tty->open_count))
 		return -EINVAL;
 
 	return set_control_lines(tty, set, clear);
@@ -433,7 +432,7 @@ static int ipw_ioctl(struct tty_struct *
 	if (!tty)
 		return -ENODEV;
 
-	if (!tty->open_count)
+	if (!local_read(&tty->open_count))
 		return -EINVAL;
 
 	/* FIXME: Exactly how is the tty object locked here .. */
@@ -582,7 +581,7 @@ void ipwireless_tty_free(struct ipw_tty
 				   against a parallel ioctl etc */
 				mutex_lock(&ttyj->ipw_tty_mutex);
 			}
-			while (ttyj->open_count)
+			while (local_read(&ttyj->open_count))
 				do_ipw_close(ttyj);
 			ipwireless_disassociate_network_ttys(network,
 							     ttyj->channel_idx);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/tty/n_gsm.c linux-3.2.71-pax/drivers/tty/n_gsm.c
--- linux-3.2.71/drivers/tty/n_gsm.c	2014-04-02 03:15:42.651672497 +0200
+++ linux-3.2.71-pax/drivers/tty/n_gsm.c	2014-04-02 03:15:49.251672145 +0200
@@ -1649,7 +1649,7 @@ static struct gsm_dlci *gsm_dlci_alloc(s
 	kref_init(&dlci->ref);
 	mutex_init(&dlci->mutex);
 	dlci->fifo = &dlci->_fifo;
-	if (kfifo_alloc(&dlci->_fifo, 4096, GFP_KERNEL) < 0) {
+	if (kfifo_alloc(&dlci->_fifo, 4096, GFP_KERNEL)) {
 		kfree(dlci);
 		return NULL;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/tty/n_tty.c linux-3.2.71-pax/drivers/tty/n_tty.c
--- linux-3.2.71/drivers/tty/n_tty.c	2014-05-20 01:19:02.415997849 +0200
+++ linux-3.2.71-pax/drivers/tty/n_tty.c	2014-05-20 01:19:07.587997573 +0200
@@ -1639,6 +1639,7 @@ static int copy_from_read_buf(struct tty
 	int retval;
 	size_t n;
 	unsigned long flags;
+	bool is_eof;
 
 	retval = 0;
 	spin_lock_irqsave(&tty->read_lock, flags);
@@ -1648,15 +1649,15 @@ static int copy_from_read_buf(struct tty
 	if (n) {
 		retval = copy_to_user(*b, &tty->read_buf[tty->read_tail], n);
 		n -= retval;
+		is_eof = n == 1 &&
+			tty->read_buf[tty->read_tail] == EOF_CHAR(tty);
 		tty_audit_add_data(tty, &tty->read_buf[tty->read_tail], n);
 		spin_lock_irqsave(&tty->read_lock, flags);
 		tty->read_tail = (tty->read_tail + n) & (N_TTY_BUF_SIZE-1);
 		tty->read_cnt -= n;
 		/* Turn single EOF into zero-length read */
-		if (L_EXTPROC(tty) && tty->icanon && n == 1) {
-			if (!tty->read_cnt && (*b)[n-1] == EOF_CHAR(tty))
-				n--;
-		}
+		if (L_EXTPROC(tty) && tty->icanon && is_eof && !tty->read_cnt)
+			n = 0;
 		spin_unlock_irqrestore(&tty->read_lock, flags);
 		*b += n;
 		*nr -= n;
@@ -2134,6 +2135,7 @@ void n_tty_inherit_ops(struct tty_ldisc_
 {
 	*ops = tty_ldisc_N_TTY;
 	ops->owner = NULL;
-	ops->refcount = ops->flags = 0;
+	atomic_set(&ops->refcount, 0);
+	ops->flags = 0;
 }
 EXPORT_SYMBOL_GPL(n_tty_inherit_ops);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/tty/pty.c linux-3.2.71-pax/drivers/tty/pty.c
--- linux-3.2.71/drivers/tty/pty.c	2015-05-10 09:22:38.323493098 +0200
+++ linux-3.2.71-pax/drivers/tty/pty.c	2015-05-10 09:23:09.371494785 +0200
@@ -778,8 +778,10 @@ static void __init unix98_pty_init(void)
 	register_sysctl_table(pty_root_table);
 
 	/* Now create the /dev/ptmx special device */
+	pax_open_kernel();
 	tty_default_fops(&ptmx_fops);
-	ptmx_fops.open = ptmx_open;
+	*(void **)&ptmx_fops.open = ptmx_open;
+	pax_close_kernel();
 
 	cdev_init(&ptmx_cdev, &ptmx_fops);
 	if (cdev_add(&ptmx_cdev, MKDEV(TTYAUX_MAJOR, 2), 1) ||
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/tty/serial/ioc4_serial.c linux-3.2.71-pax/drivers/tty/serial/ioc4_serial.c
--- linux-3.2.71/drivers/tty/serial/ioc4_serial.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/tty/serial/ioc4_serial.c	2013-09-01 20:14:13.143798970 +0200
@@ -438,7 +438,7 @@ struct ioc4_soft {
 		} is_intr_info[MAX_IOC4_INTR_ENTS];
 
 		/* Number of entries active in the above array */
-		atomic_t is_num_intrs;
+		atomic_unchecked_t is_num_intrs;
 	} is_intr_type[IOC4_NUM_INTR_TYPES];
 
 	/* is_ir_lock must be held while
@@ -975,7 +975,7 @@ intr_connect(struct ioc4_soft *soft, int
 	BUG_ON(!((type == IOC4_SIO_INTR_TYPE)
 	       || (type == IOC4_OTHER_INTR_TYPE)));
 
-	i = atomic_inc(&soft-> is_intr_type[type].is_num_intrs) - 1;
+	i = atomic_inc_return_unchecked(&soft-> is_intr_type[type].is_num_intrs) - 1;
 	BUG_ON(!(i < MAX_IOC4_INTR_ENTS || (printk("i %d\n", i), 0)));
 
 	/* Save off the lower level interrupt handler */
@@ -1002,7 +1002,7 @@ static irqreturn_t ioc4_intr(int irq, vo
 
 	soft = arg;
 	for (intr_type = 0; intr_type < IOC4_NUM_INTR_TYPES; intr_type++) {
-		num_intrs = (int)atomic_read(
+		num_intrs = (int)atomic_read_unchecked(
 				&soft->is_intr_type[intr_type].is_num_intrs);
 
 		this_mir = this_ir = pending_intrs(soft, intr_type);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/tty/serial/kgdboc.c linux-3.2.71-pax/drivers/tty/serial/kgdboc.c
--- linux-3.2.71/drivers/tty/serial/kgdboc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/tty/serial/kgdboc.c	2012-07-04 19:24:48.644063008 +0200
@@ -24,8 +24,9 @@
 #define MAX_CONFIG_LEN		40
 
 static struct kgdb_io		kgdboc_io_ops;
+static struct kgdb_io		kgdboc_io_ops_console;
 
-/* -1 = init not run yet, 0 = unconfigured, 1 = configured. */
+/* -1 = init not run yet, 0 = unconfigured, 1/2 = configured. */
 static int configured		= -1;
 
 static char config[MAX_CONFIG_LEN];
@@ -148,6 +149,8 @@ static void cleanup_kgdboc(void)
 	kgdboc_unregister_kbd();
 	if (configured == 1)
 		kgdb_unregister_io_module(&kgdboc_io_ops);
+	else if (configured == 2)
+		kgdb_unregister_io_module(&kgdboc_io_ops_console);
 }
 
 static int configure_kgdboc(void)
@@ -157,13 +160,13 @@ static int configure_kgdboc(void)
 	int err;
 	char *cptr = config;
 	struct console *cons;
+	int is_console = 0;
 
 	err = kgdboc_option_setup(config);
 	if (err || !strlen(config) || isspace(config[0]))
 		goto noconfig;
 
 	err = -ENODEV;
-	kgdboc_io_ops.is_console = 0;
 	kgdb_tty_driver = NULL;
 
 	kgdboc_use_kms = 0;
@@ -184,7 +187,7 @@ static int configure_kgdboc(void)
 		int idx;
 		if (cons->device && cons->device(cons, &idx) == p &&
 		    idx == tty_line) {
-			kgdboc_io_ops.is_console = 1;
+			is_console = 1;
 			break;
 		}
 		cons = cons->next;
@@ -194,12 +197,16 @@ static int configure_kgdboc(void)
 	kgdb_tty_line = tty_line;
 
 do_register:
-	err = kgdb_register_io_module(&kgdboc_io_ops);
+	if (is_console) {
+		err = kgdb_register_io_module(&kgdboc_io_ops_console);
+		configured = 2;
+	} else {
+		err = kgdb_register_io_module(&kgdboc_io_ops);
+		configured = 1;
+	}
 	if (err)
 		goto noconfig;
 
-	configured = 1;
-
 	return 0;
 
 noconfig:
@@ -213,7 +220,7 @@ noconfig:
 static int __init init_kgdboc(void)
 {
 	/* Already configured? */
-	if (configured == 1)
+	if (configured >= 1)
 		return 0;
 
 	return configure_kgdboc();
@@ -262,7 +269,7 @@ static int param_set_kgdboc_var(const ch
 	if (config[len - 1] == '\n')
 		config[len - 1] = '\0';
 
-	if (configured == 1)
+	if (configured >= 1)
 		cleanup_kgdboc();
 
 	/* Go and configure with the new params. */
@@ -302,6 +309,15 @@ static struct kgdb_io kgdboc_io_ops = {
 	.post_exception		= kgdboc_post_exp_handler,
 };
 
+static struct kgdb_io kgdboc_io_ops_console = {
+	.name			= "kgdboc",
+	.read_char		= kgdboc_get_char,
+	.write_char		= kgdboc_put_char,
+	.pre_exception		= kgdboc_pre_exp_handler,
+	.post_exception		= kgdboc_post_exp_handler,
+	.is_console		= 1
+};
+
 #ifdef CONFIG_KGDB_SERIAL_CONSOLE
 /* This is only available if kgdboc is a built in for early debugging */
 static int __init kgdboc_early_init(char *opt)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/tty/serial/msm_serial.c linux-3.2.71-pax/drivers/tty/serial/msm_serial.c
--- linux-3.2.71/drivers/tty/serial/msm_serial.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/tty/serial/msm_serial.c	2013-09-01 20:15:26.815795036 +0200
@@ -857,7 +857,7 @@ static struct uart_driver msm_uart_drive
 	.cons = MSM_CONSOLE,
 };
 
-static atomic_t msm_uart_next_id = ATOMIC_INIT(0);
+static atomic_unchecked_t msm_uart_next_id = ATOMIC_INIT(0);
 
 static int __init msm_serial_probe(struct platform_device *pdev)
 {
@@ -867,7 +867,7 @@ static int __init msm_serial_probe(struc
 	int irq;
 
 	if (pdev->id == -1)
-		pdev->id = atomic_inc_return(&msm_uart_next_id) - 1;
+		pdev->id = atomic_inc_return_unchecked(&msm_uart_next_id) - 1;
 
 	if (unlikely(pdev->id < 0 || pdev->id >= UART_NR))
 		return -ENXIO;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/tty/serial/samsung.c linux-3.2.71-pax/drivers/tty/serial/samsung.c
--- linux-3.2.71/drivers/tty/serial/samsung.c	2015-02-20 12:37:33.189178770 +0100
+++ linux-3.2.71-pax/drivers/tty/serial/samsung.c	2015-02-20 12:37:41.885178306 +0100
@@ -440,11 +440,16 @@ static void s3c24xx_serial_shutdown(stru
 	}
 }
 
+static int s3c64xx_serial_startup(struct uart_port *port);
 static int s3c24xx_serial_startup(struct uart_port *port)
 {
 	struct s3c24xx_uart_port *ourport = to_ourport(port);
 	int ret;
 
+	/* Startup sequence is different for s3c64xx and higher SoC's */
+	if (s3c24xx_serial_has_interrupt_mask(port))
+		return s3c64xx_serial_startup(port);
+
 	dbg("s3c24xx_serial_startup: port=%p (%08lx,%p)\n",
 	    port->mapbase, port->membase);
 
@@ -1153,10 +1158,6 @@ static int s3c24xx_serial_init_port(stru
 	port->dev	= &platdev->dev;
 	ourport->info	= info;
 
-	/* Startup sequence is different for s3c64xx and higher SoC's */
-	if (s3c24xx_serial_has_interrupt_mask(port))
-		s3c24xx_serial_ops.startup = s3c64xx_serial_startup;
-
 	/* copy the info in from provided structure */
 	ourport->port.fifosize = info->fifosize;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/tty/tty_io.c linux-3.2.71-pax/drivers/tty/tty_io.c
--- linux-3.2.71/drivers/tty/tty_io.c	2015-05-10 09:22:38.343493099 +0200
+++ linux-3.2.71-pax/drivers/tty/tty_io.c	2015-05-10 09:23:09.371494785 +0200
@@ -3255,7 +3255,7 @@ EXPORT_SYMBOL_GPL(get_current_tty);
 
 void tty_default_fops(struct file_operations *fops)
 {
-	*fops = tty_fops;
+	memcpy((void *)fops, &tty_fops, sizeof(tty_fops));
 }
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/tty/tty_ldisc.c linux-3.2.71-pax/drivers/tty/tty_ldisc.c
--- linux-3.2.71/drivers/tty/tty_ldisc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/tty/tty_ldisc.c	2012-07-04 19:24:48.644063008 +0200
@@ -75,7 +75,7 @@ static void put_ldisc(struct tty_ldisc *
 	if (atomic_dec_and_lock(&ld->users, &tty_ldisc_lock)) {
 		struct tty_ldisc_ops *ldo = ld->ops;
 
-		ldo->refcount--;
+		atomic_dec(&ldo->refcount);
 		module_put(ldo->owner);
 		spin_unlock_irqrestore(&tty_ldisc_lock, flags);
 
@@ -110,7 +110,7 @@ int tty_register_ldisc(int disc, struct
 	spin_lock_irqsave(&tty_ldisc_lock, flags);
 	tty_ldiscs[disc] = new_ldisc;
 	new_ldisc->num = disc;
-	new_ldisc->refcount = 0;
+	atomic_set(&new_ldisc->refcount, 0);
 	spin_unlock_irqrestore(&tty_ldisc_lock, flags);
 
 	return ret;
@@ -138,7 +138,7 @@ int tty_unregister_ldisc(int disc)
 		return -EINVAL;
 
 	spin_lock_irqsave(&tty_ldisc_lock, flags);
-	if (tty_ldiscs[disc]->refcount)
+	if (atomic_read(&tty_ldiscs[disc]->refcount))
 		ret = -EBUSY;
 	else
 		tty_ldiscs[disc] = NULL;
@@ -159,7 +159,7 @@ static struct tty_ldisc_ops *get_ldops(i
 	if (ldops) {
 		ret = ERR_PTR(-EAGAIN);
 		if (try_module_get(ldops->owner)) {
-			ldops->refcount++;
+			atomic_inc(&ldops->refcount);
 			ret = ldops;
 		}
 	}
@@ -172,7 +172,7 @@ static void put_ldops(struct tty_ldisc_o
 	unsigned long flags;
 
 	spin_lock_irqsave(&tty_ldisc_lock, flags);
-	ldops->refcount--;
+	atomic_dec(&ldops->refcount);
 	module_put(ldops->owner);
 	spin_unlock_irqrestore(&tty_ldisc_lock, flags);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/uio/uio.c linux-3.2.71-pax/drivers/uio/uio.c
--- linux-3.2.71/drivers/uio/uio.c	2013-11-29 01:58:28.702491620 +0100
+++ linux-3.2.71-pax/drivers/uio/uio.c	2013-11-29 01:58:37.682491884 +0100
@@ -25,6 +25,7 @@
 #include <linux/kobject.h>
 #include <linux/cdev.h>
 #include <linux/uio_driver.h>
+#include <asm/local.h>
 
 #define UIO_MAX_DEVICES		(1U << MINORBITS)
 
@@ -32,10 +33,10 @@ struct uio_device {
 	struct module		*owner;
 	struct device		*dev;
 	int			minor;
-	atomic_t		event;
+	atomic_unchecked_t	event;
 	struct fasync_struct	*async_queue;
 	wait_queue_head_t	wait;
-	int			vma_count;
+	local_t			vma_count;
 	struct uio_info		*info;
 	struct kobject		*map_dir;
 	struct kobject		*portio_dir;
@@ -242,7 +243,7 @@ static ssize_t show_event(struct device
 			  struct device_attribute *attr, char *buf)
 {
 	struct uio_device *idev = dev_get_drvdata(dev);
-	return sprintf(buf, "%u\n", (unsigned int)atomic_read(&idev->event));
+	return sprintf(buf, "%u\n", (unsigned int)atomic_read_unchecked(&idev->event));
 }
 
 static struct device_attribute uio_class_attributes[] = {
@@ -408,7 +409,7 @@ void uio_event_notify(struct uio_info *i
 {
 	struct uio_device *idev = info->uio_dev;
 
-	atomic_inc(&idev->event);
+	atomic_inc_unchecked(&idev->event);
 	wake_up_interruptible(&idev->wait);
 	kill_fasync(&idev->async_queue, SIGIO, POLL_IN);
 }
@@ -461,7 +462,7 @@ static int uio_open(struct inode *inode,
 	}
 
 	listener->dev = idev;
-	listener->event_count = atomic_read(&idev->event);
+	listener->event_count = atomic_read_unchecked(&idev->event);
 	filep->private_data = listener;
 
 	if (idev->info->open) {
@@ -512,7 +513,7 @@ static unsigned int uio_poll(struct file
 		return -EIO;
 
 	poll_wait(filep, &idev->wait, wait);
-	if (listener->event_count != atomic_read(&idev->event))
+	if (listener->event_count != atomic_read_unchecked(&idev->event))
 		return POLLIN | POLLRDNORM;
 	return 0;
 }
@@ -537,7 +538,7 @@ static ssize_t uio_read(struct file *fil
 	do {
 		set_current_state(TASK_INTERRUPTIBLE);
 
-		event_count = atomic_read(&idev->event);
+		event_count = atomic_read_unchecked(&idev->event);
 		if (event_count != listener->event_count) {
 			if (copy_to_user(buf, &event_count, count))
 				retval = -EFAULT;
@@ -606,13 +607,13 @@ static int uio_find_mem_index(struct vm_
 static void uio_vma_open(struct vm_area_struct *vma)
 {
 	struct uio_device *idev = vma->vm_private_data;
-	idev->vma_count++;
+	local_inc(&idev->vma_count);
 }
 
 static void uio_vma_close(struct vm_area_struct *vma)
 {
 	struct uio_device *idev = vma->vm_private_data;
-	idev->vma_count--;
+	local_dec(&idev->vma_count);
 }
 
 static int uio_vma_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
@@ -833,7 +834,7 @@ int __uio_register_device(struct module
 	idev->owner = owner;
 	idev->info = info;
 	init_waitqueue_head(&idev->wait);
-	atomic_set(&idev->event, 0);
+	atomic_set_unchecked(&idev->event, 0);
 
 	ret = uio_get_minor(idev);
 	if (ret)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/atm/cxacru.c linux-3.2.71-pax/drivers/usb/atm/cxacru.c
--- linux-3.2.71/drivers/usb/atm/cxacru.c	2013-06-09 18:04:43.381591751 +0200
+++ linux-3.2.71-pax/drivers/usb/atm/cxacru.c	2013-06-09 18:04:48.889591456 +0200
@@ -473,7 +473,7 @@ static ssize_t cxacru_sysfs_store_adsl_c
 		ret = sscanf(buf + pos, "%x=%x%n", &index, &value, &tmp);
 		if (ret < 2)
 			return -EINVAL;
-		if (index < 0 || index > 0x7f)
+		if (index > 0x7f)
 			return -EINVAL;
 		pos += tmp;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/atm/usbatm.c linux-3.2.71-pax/drivers/usb/atm/usbatm.c
--- linux-3.2.71/drivers/usb/atm/usbatm.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/usb/atm/usbatm.c	2012-07-04 19:24:48.648063008 +0200
@@ -333,7 +333,7 @@ static void usbatm_extract_one_cell(stru
 		if (printk_ratelimit())
 			atm_warn(instance, "%s: OAM not supported (vpi %d, vci %d)!\n",
 				__func__, vpi, vci);
-		atomic_inc(&vcc->stats->rx_err);
+		atomic_inc_unchecked(&vcc->stats->rx_err);
 		return;
 	}
 
@@ -361,7 +361,7 @@ static void usbatm_extract_one_cell(stru
 		if (length > ATM_MAX_AAL5_PDU) {
 			atm_rldbg(instance, "%s: bogus length %u (vcc: 0x%p)!\n",
 				  __func__, length, vcc);
-			atomic_inc(&vcc->stats->rx_err);
+			atomic_inc_unchecked(&vcc->stats->rx_err);
 			goto out;
 		}
 
@@ -370,14 +370,14 @@ static void usbatm_extract_one_cell(stru
 		if (sarb->len < pdu_length) {
 			atm_rldbg(instance, "%s: bogus pdu_length %u (sarb->len: %u, vcc: 0x%p)!\n",
 				  __func__, pdu_length, sarb->len, vcc);
-			atomic_inc(&vcc->stats->rx_err);
+			atomic_inc_unchecked(&vcc->stats->rx_err);
 			goto out;
 		}
 
 		if (crc32_be(~0, skb_tail_pointer(sarb) - pdu_length, pdu_length) != 0xc704dd7b) {
 			atm_rldbg(instance, "%s: packet failed crc check (vcc: 0x%p)!\n",
 				  __func__, vcc);
-			atomic_inc(&vcc->stats->rx_err);
+			atomic_inc_unchecked(&vcc->stats->rx_err);
 			goto out;
 		}
 
@@ -387,7 +387,7 @@ static void usbatm_extract_one_cell(stru
 			if (printk_ratelimit())
 				atm_err(instance, "%s: no memory for skb (length: %u)!\n",
 					__func__, length);
-			atomic_inc(&vcc->stats->rx_drop);
+			atomic_inc_unchecked(&vcc->stats->rx_drop);
 			goto out;
 		}
 
@@ -412,7 +412,7 @@ static void usbatm_extract_one_cell(stru
 
 		vcc->push(vcc, skb);
 
-		atomic_inc(&vcc->stats->rx);
+		atomic_inc_unchecked(&vcc->stats->rx);
 	out:
 		skb_trim(sarb, 0);
 	}
@@ -615,7 +615,7 @@ static void usbatm_tx_process(unsigned l
 			struct atm_vcc *vcc = UDSL_SKB(skb)->atm.vcc;
 
 			usbatm_pop(vcc, skb);
-			atomic_inc(&vcc->stats->tx);
+			atomic_inc_unchecked(&vcc->stats->tx);
 
 			skb = skb_dequeue(&instance->sndqueue);
 		}
@@ -773,11 +773,11 @@ static int usbatm_atm_proc_read(struct a
 	if (!left--)
 		return sprintf(page,
 			       "AAL5: tx %d ( %d err ), rx %d ( %d err, %d drop )\n",
-			       atomic_read(&atm_dev->stats.aal5.tx),
-			       atomic_read(&atm_dev->stats.aal5.tx_err),
-			       atomic_read(&atm_dev->stats.aal5.rx),
-			       atomic_read(&atm_dev->stats.aal5.rx_err),
-			       atomic_read(&atm_dev->stats.aal5.rx_drop));
+			       atomic_read_unchecked(&atm_dev->stats.aal5.tx),
+			       atomic_read_unchecked(&atm_dev->stats.aal5.tx_err),
+			       atomic_read_unchecked(&atm_dev->stats.aal5.rx),
+			       atomic_read_unchecked(&atm_dev->stats.aal5.rx_err),
+			       atomic_read_unchecked(&atm_dev->stats.aal5.rx_drop));
 
 	if (!left--) {
 		if (instance->disconnected)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/core/devices.c linux-3.2.71-pax/drivers/usb/core/devices.c
--- linux-3.2.71/drivers/usb/core/devices.c	2012-10-10 11:02:19.603865894 +0200
+++ linux-3.2.71-pax/drivers/usb/core/devices.c	2012-10-10 11:02:25.411866441 +0200
@@ -126,7 +126,7 @@ static const char format_endpt[] =
  * time it gets called.
  */
 static struct device_connect_event {
-	atomic_t count;
+	atomic_unchecked_t count;
 	wait_queue_head_t wait;
 } device_event = {
 	.count = ATOMIC_INIT(1),
@@ -164,7 +164,7 @@ static const struct class_info clas_info
 
 void usbfs_conn_disc_event(void)
 {
-	atomic_add(2, &device_event.count);
+	atomic_add_unchecked(2, &device_event.count);
 	wake_up(&device_event.wait);
 }
 
@@ -648,7 +648,7 @@ static unsigned int usb_device_poll(stru
 
 	poll_wait(file, &device_event.wait, wait);
 
-	event_count = atomic_read(&device_event.count);
+	event_count = atomic_read_unchecked(&device_event.count);
 	if (file->f_version != event_count) {
 		file->f_version = event_count;
 		return POLLIN | POLLRDNORM;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/core/devio.c linux-3.2.71-pax/drivers/usb/core/devio.c
--- linux-3.2.71/drivers/usb/core/devio.c	2015-05-10 09:22:38.451493105 +0200
+++ linux-3.2.71-pax/drivers/usb/core/devio.c	2015-05-10 09:23:09.403494786 +0200
@@ -147,7 +147,7 @@ static ssize_t usbdev_read(struct file *
 	struct dev_state *ps = file->private_data;
 	struct usb_device *dev = ps->dev;
 	ssize_t ret = 0;
-	unsigned len;
+	size_t len;
 	loff_t pos;
 	int i;
 
@@ -189,22 +189,22 @@ static ssize_t usbdev_read(struct file *
 	for (i = 0; nbytes && i < dev->descriptor.bNumConfigurations; i++) {
 		struct usb_config_descriptor *config =
 			(struct usb_config_descriptor *)dev->rawdescriptors[i];
-		unsigned int length = le16_to_cpu(config->wTotalLength);
+		size_t length = le16_to_cpu(config->wTotalLength);
 
 		if (*ppos < pos + length) {
 
 			/* The descriptor may claim to be longer than it
 			 * really is.  Here is the actual allocated length. */
-			unsigned alloclen =
+			size_t alloclen =
 				le16_to_cpu(dev->config[i].desc.wTotalLength);
 
-			len = length - (*ppos - pos);
+			len = length + pos - *ppos;
 			if (len > nbytes)
 				len = nbytes;
 
 			/* Simply don't write (skip over) unallocated parts */
 			if (alloclen > (*ppos - pos)) {
-				alloclen -= (*ppos - pos);
+				alloclen = alloclen + pos - *ppos;
 				if (copy_to_user(buf,
 				    dev->rawdescriptors[i] + (*ppos - pos),
 				    min(len, alloclen))) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/core/hcd.c linux-3.2.71-pax/drivers/usb/core/hcd.c
--- linux-3.2.71/drivers/usb/core/hcd.c	2015-05-10 09:22:38.451493105 +0200
+++ linux-3.2.71-pax/drivers/usb/core/hcd.c	2015-05-10 09:23:09.403494786 +0200
@@ -1475,7 +1475,7 @@ int usb_hcd_submit_urb (struct urb *urb,
 	 */
 	usb_get_urb(urb);
 	atomic_inc(&urb->use_count);
-	atomic_inc(&urb->dev->urbnum);
+	atomic_inc_unchecked(&urb->dev->urbnum);
 	usbmon_urb_submit(&hcd->self, urb);
 
 	/* NOTE requirements on root-hub callers (usbfs and the hub
@@ -1502,7 +1502,7 @@ int usb_hcd_submit_urb (struct urb *urb,
 		urb->hcpriv = NULL;
 		INIT_LIST_HEAD(&urb->urb_list);
 		atomic_dec(&urb->use_count);
-		atomic_dec(&urb->dev->urbnum);
+		atomic_dec_unchecked(&urb->dev->urbnum);
 		if (atomic_read(&urb->reject))
 			wake_up(&usb_kill_urb_queue);
 		usb_put_urb(urb);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/core/message.c linux-3.2.71-pax/drivers/usb/core/message.c
--- linux-3.2.71/drivers/usb/core/message.c	2013-01-03 19:05:14.284036848 +0100
+++ linux-3.2.71-pax/drivers/usb/core/message.c	2013-11-23 18:07:03.589937072 +0100
@@ -129,7 +129,7 @@ static int usb_internal_control_msg(stru
  * method can wait for it to complete.  Since you don't have a handle on the
  * URB used, you can't cancel the request.
  */
-int usb_control_msg(struct usb_device *dev, unsigned int pipe, __u8 request,
+int __intentional_overflow(-1) usb_control_msg(struct usb_device *dev, unsigned int pipe, __u8 request,
 		    __u8 requesttype, __u16 value, __u16 index, void *data,
 		    __u16 size, int timeout)
 {
@@ -182,7 +182,7 @@ EXPORT_SYMBOL_GPL(usb_control_msg);
  * complete.  Since you don't have a handle on the URB used, you can't cancel
  * the request.
  */
-int usb_interrupt_msg(struct usb_device *usb_dev, unsigned int pipe,
+int __intentional_overflow(-1) usb_interrupt_msg(struct usb_device *usb_dev, unsigned int pipe,
 		      void *data, int len, int *actual_length, int timeout)
 {
 	return usb_bulk_msg(usb_dev, pipe, data, len, actual_length, timeout);
@@ -220,7 +220,7 @@ EXPORT_SYMBOL_GPL(usb_interrupt_msg);
  * interrupt endpoints.  We will take the liberty of creating an interrupt URB
  * (with the default interval) if the target is an interrupt endpoint.
  */
-int usb_bulk_msg(struct usb_device *usb_dev, unsigned int pipe,
+int __intentional_overflow(-1) usb_bulk_msg(struct usb_device *usb_dev, unsigned int pipe,
 		 void *data, int len, int *actual_length, int timeout)
 {
 	struct urb *urb;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/core/sysfs.c linux-3.2.71-pax/drivers/usb/core/sysfs.c
--- linux-3.2.71/drivers/usb/core/sysfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/usb/core/sysfs.c	2012-12-03 22:33:35.111763929 +0100
@@ -226,7 +226,7 @@ show_urbnum(struct device *dev, struct d
 	struct usb_device *udev;
 
 	udev = to_usb_device(dev);
-	return sprintf(buf, "%d\n", atomic_read(&udev->urbnum));
+	return sprintf(buf, "%d\n", atomic_read_unchecked(&udev->urbnum));
 }
 static DEVICE_ATTR(urbnum, S_IRUGO, show_urbnum, NULL);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/core/usb.c linux-3.2.71-pax/drivers/usb/core/usb.c
--- linux-3.2.71/drivers/usb/core/usb.c	2015-05-10 09:22:38.455493106 +0200
+++ linux-3.2.71-pax/drivers/usb/core/usb.c	2015-05-10 09:23:09.403494786 +0200
@@ -396,7 +396,7 @@ struct usb_device *usb_alloc_dev(struct
 	dev->dev.dma_mask = bus->controller->dma_mask;
 	set_dev_node(&dev->dev, dev_to_node(bus->controller));
 	dev->state = USB_STATE_ATTACHED;
-	atomic_set(&dev->urbnum, 0);
+	atomic_set_unchecked(&dev->urbnum, 0);
 
 	INIT_LIST_HEAD(&dev->ep0.urb_list);
 	dev->ep0.desc.bLength = USB_DT_ENDPOINT_SIZE;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/early/ehci-dbgp.c linux-3.2.71-pax/drivers/usb/early/ehci-dbgp.c
--- linux-3.2.71/drivers/usb/early/ehci-dbgp.c	2012-08-12 12:28:43.033231783 +0200
+++ linux-3.2.71-pax/drivers/usb/early/ehci-dbgp.c	2012-08-12 12:28:56.905231173 +0200
@@ -97,7 +97,8 @@ static inline u32 dbgp_len_update(u32 x,
 
 #ifdef CONFIG_KGDB
 static struct kgdb_io kgdbdbgp_io_ops;
-#define dbgp_kgdb_mode (dbg_io_ops == &kgdbdbgp_io_ops)
+static struct kgdb_io kgdbdbgp_io_ops_console;
+#define dbgp_kgdb_mode (dbg_io_ops == &kgdbdbgp_io_ops || dbg_io_ops == &kgdbdbgp_io_ops_console)
 #else
 #define dbgp_kgdb_mode (0)
 #endif
@@ -1035,6 +1036,13 @@ static struct kgdb_io kgdbdbgp_io_ops =
 	.write_char = kgdbdbgp_write_char,
 };
 
+static struct kgdb_io kgdbdbgp_io_ops_console = {
+	.name = "kgdbdbgp",
+	.read_char = kgdbdbgp_read_char,
+	.write_char = kgdbdbgp_write_char,
+	.is_console = 1
+};
+
 static int kgdbdbgp_wait_time;
 
 static int __init kgdbdbgp_parse_config(char *str)
@@ -1050,8 +1058,10 @@ static int __init kgdbdbgp_parse_config(
 		ptr++;
 		kgdbdbgp_wait_time = simple_strtoul(ptr, &ptr, 10);
 	}
-	kgdb_register_io_module(&kgdbdbgp_io_ops);
-	kgdbdbgp_io_ops.is_console = early_dbgp_console.index != -1;
+	if (early_dbgp_console.index != -1)
+		kgdb_register_io_module(&kgdbdbgp_io_ops_console);
+	else
+		kgdb_register_io_module(&kgdbdbgp_io_ops);
 
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/gadget/file_storage.c linux-3.2.71-pax/drivers/usb/gadget/file_storage.c
--- linux-3.2.71/drivers/usb/gadget/file_storage.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/usb/gadget/file_storage.c	2013-03-28 15:43:07.129712214 +0100
@@ -3329,18 +3329,20 @@ static int __init fsg_bind(struct usb_ga
 	if ((rc = check_parameters(fsg)) != 0)
 		goto out;
 
+	pax_open_kernel();
 	if (mod_data.removable) {	// Enable the store_xxx attributes
-		dev_attr_file.attr.mode = 0644;
-		dev_attr_file.store = fsg_store_file;
+		*(mode_t *)&dev_attr_file.attr.mode = 0644;
+		*(void **)&dev_attr_file.store = fsg_store_file;
 		if (!mod_data.cdrom) {
-			dev_attr_ro.attr.mode = 0644;
-			dev_attr_ro.store = fsg_store_ro;
+			*(mode_t *)&dev_attr_ro.attr.mode = 0644;
+			*(void **)&dev_attr_ro.store = fsg_store_ro;
 		}
 	}
 
 	/* Only for removable media? */
-	dev_attr_nofua.attr.mode = 0644;
-	dev_attr_nofua.store = fsg_store_nofua;
+	*(mode_t *)&dev_attr_nofua.attr.mode = 0644;
+	*(void **)&dev_attr_nofua.store = fsg_store_nofua;
+	pax_close_kernel();
 
 	/* Find out how many LUNs there should be */
 	i = mod_data.nluns;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/misc/appledisplay.c linux-3.2.71-pax/drivers/usb/misc/appledisplay.c
--- linux-3.2.71/drivers/usb/misc/appledisplay.c	2013-05-14 13:33:40.620285673 +0200
+++ linux-3.2.71-pax/drivers/usb/misc/appledisplay.c	2013-09-01 20:15:45.747794026 +0200
@@ -83,7 +83,7 @@ struct appledisplay {
 	spinlock_t lock;
 };
 
-static atomic_t count_displays = ATOMIC_INIT(0);
+static atomic_unchecked_t count_displays = ATOMIC_INIT(0);
 static struct workqueue_struct *wq;
 
 static void appledisplay_complete(struct urb *urb)
@@ -281,7 +281,7 @@ static int appledisplay_probe(struct usb
 
 	/* Register backlight device */
 	snprintf(bl_name, sizeof(bl_name), "appledisplay%d",
-		atomic_inc_return(&count_displays) - 1);
+		atomic_inc_return_unchecked(&count_displays) - 1);
 	memset(&props, 0, sizeof(struct backlight_properties));
 	props.type = BACKLIGHT_RAW;
 	props.max_brightness = 0xff;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/serial/console.c linux-3.2.71-pax/drivers/usb/serial/console.c
--- linux-3.2.71/drivers/usb/serial/console.c	2015-02-20 12:37:33.209178769 +0100
+++ linux-3.2.71-pax/drivers/usb/serial/console.c	2015-02-20 12:37:41.889178306 +0100
@@ -205,7 +205,7 @@ static int usb_console_setup(struct cons
 static void usb_console_write(struct console *co,
 					const char *buf, unsigned count)
 {
-	static struct usbcons_info *info = &usbcons_info;
+	struct usbcons_info *info = &usbcons_info;
 	struct usb_serial_port *port = info->port;
 	struct usb_serial *serial;
 	int retval = -ENODEV;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/storage/usb.h linux-3.2.71-pax/drivers/usb/storage/usb.h
--- linux-3.2.71/drivers/usb/storage/usb.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/usb/storage/usb.h	2013-03-28 01:35:23.304427948 +0100
@@ -63,7 +63,7 @@ struct us_unusual_dev {
 	__u8  useProtocol;
 	__u8  useTransport;
 	int (*initFunction)(struct us_data *);
-};
+} __do_const;
 
 
 /* Dynamic bitflag definitions (us->dflags): used in set_bit() etc. */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/wusbcore/wa-hc.h linux-3.2.71-pax/drivers/usb/wusbcore/wa-hc.h
--- linux-3.2.71/drivers/usb/wusbcore/wa-hc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/usb/wusbcore/wa-hc.h	2012-07-04 19:24:48.648063008 +0200
@@ -192,7 +192,7 @@ struct wahc {
 	struct list_head xfer_delayed_list;
 	spinlock_t xfer_list_lock;
 	struct work_struct xfer_work;
-	atomic_t xfer_id_count;
+	atomic_unchecked_t xfer_id_count;
 };
 
 
@@ -246,7 +246,7 @@ static inline void wa_init(struct wahc *
 	INIT_LIST_HEAD(&wa->xfer_delayed_list);
 	spin_lock_init(&wa->xfer_list_lock);
 	INIT_WORK(&wa->xfer_work, wa_urb_enqueue_run);
-	atomic_set(&wa->xfer_id_count, 1);
+	atomic_set_unchecked(&wa->xfer_id_count, 1);
 }
 
 /**
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/usb/wusbcore/wa-xfer.c linux-3.2.71-pax/drivers/usb/wusbcore/wa-xfer.c
--- linux-3.2.71/drivers/usb/wusbcore/wa-xfer.c	2014-01-03 15:48:45.004070564 +0100
+++ linux-3.2.71-pax/drivers/usb/wusbcore/wa-xfer.c	2014-01-03 15:48:49.580070319 +0100
@@ -297,7 +297,7 @@ out:
  */
 static void wa_xfer_id_init(struct wa_xfer *xfer)
 {
-	xfer->id = atomic_add_return(1, &xfer->wa->xfer_id_count);
+	xfer->id = atomic_add_return_unchecked(1, &xfer->wa->xfer_id_count);
 }
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/vhost/vhost.c linux-3.2.71-pax/drivers/vhost/vhost.c
--- linux-3.2.71/drivers/vhost/vhost.c	2015-08-14 21:48:35.288707914 +0200
+++ linux-3.2.71-pax/drivers/vhost/vhost.c	2015-08-14 21:48:45.668707360 +0200
@@ -631,7 +631,7 @@ static long vhost_set_memory(struct vhos
 	return 0;
 }
 
-static long vhost_set_vring(struct vhost_dev *d, int ioctl, void __user *argp)
+static long vhost_set_vring(struct vhost_dev *d, unsigned int ioctl, void __user *argp)
 {
 	struct file *eventfp, *filep = NULL,
 		    *pollstart = NULL, *pollstop = NULL;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/aty/aty128fb.c linux-3.2.71-pax/drivers/video/aty/aty128fb.c
--- linux-3.2.71/drivers/video/aty/aty128fb.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/aty/aty128fb.c	2012-07-04 19:24:48.652063007 +0200
@@ -148,7 +148,7 @@ enum {
 };
 
 /* Must match above enum */
-static const char *r128_family[] __devinitdata = {
+static const char *r128_family[] __devinitconst = {
 	"AGP",
 	"PCI",
 	"PRO AGP",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/aty/atyfb_base.c linux-3.2.71-pax/drivers/video/aty/atyfb_base.c
--- linux-3.2.71/drivers/video/aty/atyfb_base.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/aty/atyfb_base.c	2013-03-28 01:35:23.304427948 +0100
@@ -1325,10 +1325,14 @@ static int atyfb_set_par(struct fb_info
 	par->accel_flags = var->accel_flags; /* hack */
 
 	if (var->accel_flags) {
-		info->fbops->fb_sync = atyfb_sync;
+		pax_open_kernel();
+		*(void **)&info->fbops->fb_sync = atyfb_sync;
+		pax_close_kernel();
 		info->flags &= ~FBINFO_HWACCEL_DISABLED;
 	} else {
-		info->fbops->fb_sync = NULL;
+		pax_open_kernel();
+		*(void **)&info->fbops->fb_sync = NULL;
+		pax_close_kernel();
 		info->flags |= FBINFO_HWACCEL_DISABLED;
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/aty/mach64_cursor.c linux-3.2.71-pax/drivers/video/aty/mach64_cursor.c
--- linux-3.2.71/drivers/video/aty/mach64_cursor.c	2014-04-30 18:53:45.872223430 +0200
+++ linux-3.2.71-pax/drivers/video/aty/mach64_cursor.c	2014-04-30 18:54:25.460223341 +0200
@@ -8,6 +8,7 @@
 #include "../fb_draw.h"
 
 #include <asm/io.h>
+#include <asm/pgtable.h>
 
 #ifdef __sparc__
 #include <asm/fbio.h>
@@ -218,7 +219,9 @@ int __devinit aty_init_cursor(struct fb_
 	info->sprite.buf_align = 16; 	/* and 64 lines tall. */
 	info->sprite.flags = FB_PIXMAP_IO;
 
-	info->fbops->fb_cursor = atyfb_cursor;
+	pax_open_kernel();
+	*(void **)&info->fbops->fb_cursor = atyfb_cursor;
+	pax_close_kernel();
 
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/backlight/backlight.c linux-3.2.71-pax/drivers/video/backlight/backlight.c
--- linux-3.2.71/drivers/video/backlight/backlight.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/backlight/backlight.c	2013-08-17 01:58:42.952236300 +0200
@@ -303,7 +303,7 @@ struct backlight_device *backlight_devic
 	new_bd->dev.class = backlight_class;
 	new_bd->dev.parent = parent;
 	new_bd->dev.release = bl_device_release;
-	dev_set_name(&new_bd->dev, name);
+	dev_set_name(&new_bd->dev, "%s", name);
 	dev_set_drvdata(&new_bd->dev, devdata);
 
 	/* Set default properties */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/backlight/kb3886_bl.c linux-3.2.71-pax/drivers/video/backlight/kb3886_bl.c
--- linux-3.2.71/drivers/video/backlight/kb3886_bl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/backlight/kb3886_bl.c	2013-03-28 01:35:23.304427948 +0100
@@ -78,7 +78,7 @@ static struct kb3886bl_machinfo *bl_mach
 static unsigned long kb3886bl_flags;
 #define KB3886BL_SUSPENDED     0x01
 
-static struct dmi_system_id __initdata kb3886bl_device_table[] = {
+static const struct dmi_system_id __initconst kb3886bl_device_table[] = {
 	{
 		.ident = "Sahara Touch-iT",
 		.matches = {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/backlight/lcd.c linux-3.2.71-pax/drivers/video/backlight/lcd.c
--- linux-3.2.71/drivers/video/backlight/lcd.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/backlight/lcd.c	2013-08-17 01:58:27.748235853 +0200
@@ -209,7 +209,7 @@ struct lcd_device *lcd_device_register(c
 	new_ld->dev.class = lcd_class;
 	new_ld->dev.parent = parent;
 	new_ld->dev.release = lcd_device_release;
-	dev_set_name(&new_ld->dev, name);
+	dev_set_name(&new_ld->dev, "%s", name);
 	dev_set_drvdata(&new_ld->dev, devdata);
 
 	rc = device_register(&new_ld->dev);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/fbcmap.c linux-3.2.71-pax/drivers/video/fbcmap.c
--- linux-3.2.71/drivers/video/fbcmap.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/fbcmap.c	2012-07-04 19:24:48.652063007 +0200
@@ -285,8 +285,7 @@ int fb_set_user_cmap(struct fb_cmap_user
 		rc = -ENODEV;
 		goto out;
 	}
-	if (cmap->start < 0 || (!info->fbops->fb_setcolreg &&
-				!info->fbops->fb_setcmap)) {
+	if (!info->fbops->fb_setcolreg && !info->fbops->fb_setcmap) {
 		rc = -EINVAL;
 		goto out1;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/fb_defio.c linux-3.2.71-pax/drivers/video/fb_defio.c
--- linux-3.2.71/drivers/video/fb_defio.c	2015-02-20 12:37:33.209178769 +0100
+++ linux-3.2.71-pax/drivers/video/fb_defio.c	2015-02-20 12:37:41.889178306 +0100
@@ -201,7 +201,9 @@ void fb_deferred_io_init(struct fb_info
 
 	BUG_ON(!fbdefio);
 	mutex_init(&fbdefio->lock);
-	info->fbops->fb_mmap = fb_deferred_io_mmap;
+	pax_open_kernel();
+	*(void **)&info->fbops->fb_mmap = fb_deferred_io_mmap;
+	pax_close_kernel();
 	INIT_DELAYED_WORK(&info->deferred_work, fb_deferred_io_work);
 	INIT_LIST_HEAD(&fbdefio->pagelist);
 	if (fbdefio->delay == 0) /* set a default of 1 s */
@@ -232,7 +234,7 @@ void fb_deferred_io_cleanup(struct fb_in
 		page->mapping = NULL;
 	}
 
-	info->fbops->fb_mmap = NULL;
+	*(void **)&info->fbops->fb_mmap = NULL;
 	mutex_destroy(&fbdefio->lock);
 }
 EXPORT_SYMBOL_GPL(fb_deferred_io_cleanup);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/fbmem.c linux-3.2.71-pax/drivers/video/fbmem.c
--- linux-3.2.71/drivers/video/fbmem.c	2013-05-14 13:33:40.636285672 +0200
+++ linux-3.2.71-pax/drivers/video/fbmem.c	2014-01-28 04:21:56.129073862 +0100
@@ -428,7 +428,7 @@ static void fb_do_show_logo(struct fb_in
 			image->dx += image->width + 8;
 		}
 	} else if (rotate == FB_ROTATE_UD) {
-		for (x = 0; x < num && image->dx >= 0; x++) {
+		for (x = 0; x < num && (__s32)image->dx >= 0; x++) {
 			info->fbops->fb_imageblit(info, image);
 			image->dx -= image->width + 8;
 		}
@@ -440,7 +440,7 @@ static void fb_do_show_logo(struct fb_in
 			image->dy += image->height + 8;
 		}
 	} else if (rotate == FB_ROTATE_CCW) {
-		for (x = 0; x < num && image->dy >= 0; x++) {
+		for (x = 0; x < num && (__s32)image->dy >= 0; x++) {
 			info->fbops->fb_imageblit(info, image);
 			image->dy -= image->height + 8;
 		}
@@ -1143,7 +1143,7 @@ static long do_fb_ioctl(struct fb_info *
 			return -EFAULT;
 		if (con2fb.console < 1 || con2fb.console > MAX_NR_CONSOLES)
 			return -EINVAL;
-		if (con2fb.framebuffer < 0 || con2fb.framebuffer >= FB_MAX)
+		if (con2fb.framebuffer >= FB_MAX)
 			return -EINVAL;
 		if (!registered_fb[con2fb.framebuffer])
 			request_module("fb%d", con2fb.framebuffer);
@@ -1260,7 +1260,7 @@ static int do_fscreeninfo_to_user(struct
 	__u32 data;
 	int err;
 
-	err = copy_to_user(&fix32->id, &fix->id, sizeof(fix32->id));
+	err = copy_to_user(fix32->id, &fix->id, sizeof(fix32->id));
 
 	data = (__u32) (unsigned long) fix->smem_start;
 	err |= put_user(data, &fix32->smem_start);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/geode/gx1fb_core.c linux-3.2.71-pax/drivers/video/geode/gx1fb_core.c
--- linux-3.2.71/drivers/video/geode/gx1fb_core.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/geode/gx1fb_core.c	2012-07-04 19:24:48.656063007 +0200
@@ -29,7 +29,7 @@ static int  crt_option = 1;
 static char panel_option[32] = "";
 
 /* Modes relevant to the GX1 (taken from modedb.c) */
-static const struct fb_videomode __devinitdata gx1_modedb[] = {
+static const struct fb_videomode __devinitconst gx1_modedb[] = {
 	/* 640x480-60 VESA */
 	{ NULL, 60, 640, 480, 39682,  48, 16, 33, 10, 96, 2,
 	  0, FB_VMODE_NONINTERLACED, FB_MODE_IS_VESA },
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/gxt4500.c linux-3.2.71-pax/drivers/video/gxt4500.c
--- linux-3.2.71/drivers/video/gxt4500.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/gxt4500.c	2012-07-04 19:24:48.656063007 +0200
@@ -156,7 +156,7 @@ struct gxt4500_par {
 static char *mode_option;
 
 /* default mode: 1280x1024 @ 60 Hz, 8 bpp */
-static const struct fb_videomode defaultmode __devinitdata = {
+static const struct fb_videomode defaultmode __devinitconst = {
 	.refresh = 60,
 	.xres = 1280,
 	.yres = 1024,
@@ -581,7 +581,7 @@ static int gxt4500_blank(int blank, stru
 	return 0;
 }
 
-static const struct fb_fix_screeninfo gxt4500_fix __devinitdata = {
+static const struct fb_fix_screeninfo gxt4500_fix __devinitconst = {
 	.id = "IBM GXT4500P",
 	.type = FB_TYPE_PACKED_PIXELS,
 	.visual = FB_VISUAL_PSEUDOCOLOR,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/i810/i810_accel.c linux-3.2.71-pax/drivers/video/i810/i810_accel.c
--- linux-3.2.71/drivers/video/i810/i810_accel.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/i810/i810_accel.c	2012-07-04 19:24:48.656063007 +0200
@@ -73,6 +73,7 @@ static inline int wait_for_space(struct
 		}
 	}
 	printk("ringbuffer lockup!!!\n");
+	printk("head:%u tail:%u iring.size:%u space:%u\n", head, tail, par->iring.size, space);
 	i810_report_error(mmio); 
 	par->dev_flags |= LOCKUP;
 	info->pixmap.scan_align = 1;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/i810/i810_main.c linux-3.2.71-pax/drivers/video/i810/i810_main.c
--- linux-3.2.71/drivers/video/i810/i810_main.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/i810/i810_main.c	2012-07-04 19:24:48.656063007 +0200
@@ -97,7 +97,7 @@ static int i810fb_blank      (int blank_
 static void i810fb_release_resource       (struct fb_info *info, struct i810fb_par *par);
 
 /* PCI */
-static const char *i810_pci_list[] __devinitdata = {
+static const char *i810_pci_list[] __devinitconst = {
 	"Intel(R) 810 Framebuffer Device"                                 ,
 	"Intel(R) 810-DC100 Framebuffer Device"                           ,
 	"Intel(R) 810E Framebuffer Device"                                ,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/jz4740_fb.c linux-3.2.71-pax/drivers/video/jz4740_fb.c
--- linux-3.2.71/drivers/video/jz4740_fb.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/jz4740_fb.c	2012-07-04 19:24:48.656063007 +0200
@@ -136,7 +136,7 @@ struct jzfb {
 	uint32_t pseudo_palette[16];
 };
 
-static const struct fb_fix_screeninfo jzfb_fix __devinitdata = {
+static const struct fb_fix_screeninfo jzfb_fix __devinitconst = {
 	.id		= "JZ4740 FB",
 	.type		= FB_TYPE_PACKED_PIXELS,
 	.visual		= FB_VISUAL_TRUECOLOR,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/mb862xx/mb862xxfb_accel.c linux-3.2.71-pax/drivers/video/mb862xx/mb862xxfb_accel.c
--- linux-3.2.71/drivers/video/mb862xx/mb862xxfb_accel.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/mb862xx/mb862xxfb_accel.c	2013-03-28 01:35:23.308427948 +0100
@@ -312,14 +312,18 @@ void mb862xxfb_init_accel(struct fb_info
 	struct mb862xxfb_par *par = info->par;
 
 	if (info->var.bits_per_pixel == 32) {
-		info->fbops->fb_fillrect = cfb_fillrect;
-		info->fbops->fb_copyarea = cfb_copyarea;
-		info->fbops->fb_imageblit = cfb_imageblit;
+		pax_open_kernel();
+		*(void **)&info->fbops->fb_fillrect = cfb_fillrect;
+		*(void **)&info->fbops->fb_copyarea = cfb_copyarea;
+		*(void **)&info->fbops->fb_imageblit = cfb_imageblit;
+		pax_close_kernel();
 	} else {
 		outreg(disp, GC_L0EM, 3);
-		info->fbops->fb_fillrect = mb86290fb_fillrect;
-		info->fbops->fb_copyarea = mb86290fb_copyarea;
-		info->fbops->fb_imageblit = mb86290fb_imageblit;
+		pax_open_kernel();
+		*(void **)&info->fbops->fb_fillrect = mb86290fb_fillrect;
+		*(void **)&info->fbops->fb_copyarea = mb86290fb_copyarea;
+		*(void **)&info->fbops->fb_imageblit = mb86290fb_imageblit;
+		pax_close_kernel();
 	}
 	outreg(draw, GDC_REG_DRAW_BASE, 0);
 	outreg(draw, GDC_REG_MODE_MISC, 0x8000);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/nvidia/nvidia.c linux-3.2.71-pax/drivers/video/nvidia/nvidia.c
--- linux-3.2.71/drivers/video/nvidia/nvidia.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/nvidia/nvidia.c	2013-03-28 01:35:23.308427948 +0100
@@ -669,19 +669,23 @@ static int nvidiafb_set_par(struct fb_in
 	info->fix.line_length = (info->var.xres_virtual *
 				 info->var.bits_per_pixel) >> 3;
 	if (info->var.accel_flags) {
-		info->fbops->fb_imageblit = nvidiafb_imageblit;
-		info->fbops->fb_fillrect = nvidiafb_fillrect;
-		info->fbops->fb_copyarea = nvidiafb_copyarea;
-		info->fbops->fb_sync = nvidiafb_sync;
+		pax_open_kernel();
+		*(void **)&info->fbops->fb_imageblit = nvidiafb_imageblit;
+		*(void **)&info->fbops->fb_fillrect = nvidiafb_fillrect;
+		*(void **)&info->fbops->fb_copyarea = nvidiafb_copyarea;
+		*(void **)&info->fbops->fb_sync = nvidiafb_sync;
+		pax_close_kernel();
 		info->pixmap.scan_align = 4;
 		info->flags &= ~FBINFO_HWACCEL_DISABLED;
 		info->flags |= FBINFO_READS_FAST;
 		NVResetGraphics(info);
 	} else {
-		info->fbops->fb_imageblit = cfb_imageblit;
-		info->fbops->fb_fillrect = cfb_fillrect;
-		info->fbops->fb_copyarea = cfb_copyarea;
-		info->fbops->fb_sync = NULL;
+		pax_open_kernel();
+		*(void **)&info->fbops->fb_imageblit = cfb_imageblit;
+		*(void **)&info->fbops->fb_fillrect = cfb_fillrect;
+		*(void **)&info->fbops->fb_copyarea = cfb_copyarea;
+		*(void **)&info->fbops->fb_sync = NULL;
+		pax_close_kernel();
 		info->pixmap.scan_align = 1;
 		info->flags |= FBINFO_HWACCEL_DISABLED;
 		info->flags &= ~FBINFO_READS_FAST;
@@ -1173,8 +1177,11 @@ static int __devinit nvidia_set_fbinfo(s
 	info->pixmap.size = 8 * 1024;
 	info->pixmap.flags = FB_PIXMAP_SYSTEM;
 
-	if (!hwcur)
-	    info->fbops->fb_cursor = NULL;
+	if (!hwcur) {
+		pax_open_kernel();
+		*(void **)&info->fbops->fb_cursor = NULL;
+		pax_close_kernel();
+	}
 
 	info->var.accel_flags = (!noaccel);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/output.c linux-3.2.71-pax/drivers/video/output.c
--- linux-3.2.71/drivers/video/output.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/output.c	2013-06-21 20:15:56.434564312 +0200
@@ -97,7 +97,7 @@ struct output_device *video_output_regis
 	new_dev->props = op;
 	new_dev->dev.class = &video_output_class;
 	new_dev->dev.parent = dev;
-	dev_set_name(&new_dev->dev, name);
+	dev_set_name(&new_dev->dev, "%s", name);
 	dev_set_drvdata(&new_dev->dev, devdata);
 	ret_code = device_register(&new_dev->dev);
 	if (ret_code) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/s1d13xxxfb.c linux-3.2.71-pax/drivers/video/s1d13xxxfb.c
--- linux-3.2.71/drivers/video/s1d13xxxfb.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/s1d13xxxfb.c	2013-03-28 01:35:23.312427947 +0100
@@ -883,8 +883,10 @@ s1d13xxxfb_probe(struct platform_device
 
 	switch(prod_id) {
 	case S1D13506_PROD_ID:	/* activate acceleration */
-		s1d13xxxfb_fbops.fb_fillrect = s1d13xxxfb_bitblt_solidfill;
-		s1d13xxxfb_fbops.fb_copyarea = s1d13xxxfb_bitblt_copyarea;
+		pax_open_kernel();
+		*(void **)&s1d13xxxfb_fbops.fb_fillrect = s1d13xxxfb_bitblt_solidfill;
+		*(void **)&s1d13xxxfb_fbops.fb_copyarea = s1d13xxxfb_bitblt_copyarea;
+		pax_close_kernel();
 		info->flags = FBINFO_DEFAULT | FBINFO_HWACCEL_YPAN |
 			FBINFO_HWACCEL_FILLRECT | FBINFO_HWACCEL_COPYAREA;
 		break;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/smscufx.c linux-3.2.71-pax/drivers/video/smscufx.c
--- linux-3.2.71/drivers/video/smscufx.c	2012-08-12 12:28:43.037231782 +0200
+++ linux-3.2.71-pax/drivers/video/smscufx.c	2013-03-28 01:35:23.312427947 +0100
@@ -1172,7 +1172,9 @@ static int ufx_ops_release(struct fb_inf
 		fb_deferred_io_cleanup(info);
 		kfree(info->fbdefio);
 		info->fbdefio = NULL;
-		info->fbops->fb_mmap = ufx_ops_mmap;
+		pax_open_kernel();
+		*(void **)&info->fbops->fb_mmap = ufx_ops_mmap;
+		pax_close_kernel();
 	}
 
 	pr_debug("released /dev/fb%d user=%d count=%d",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/udlfb.c linux-3.2.71-pax/drivers/video/udlfb.c
--- linux-3.2.71/drivers/video/udlfb.c	2012-10-31 13:04:04.483702975 +0100
+++ linux-3.2.71-pax/drivers/video/udlfb.c	2013-03-28 01:35:23.136427957 +0100
@@ -619,11 +619,11 @@ int dlfb_handle_damage(struct dlfb_data
 		dlfb_urb_completion(urb);
 
 error:
-	atomic_add(bytes_sent, &dev->bytes_sent);
-	atomic_add(bytes_identical, &dev->bytes_identical);
-	atomic_add(width*height*2, &dev->bytes_rendered);
+	atomic_add_unchecked(bytes_sent, &dev->bytes_sent);
+	atomic_add_unchecked(bytes_identical, &dev->bytes_identical);
+	atomic_add_unchecked(width*height*2, &dev->bytes_rendered);
 	end_cycles = get_cycles();
-	atomic_add(((unsigned int) ((end_cycles - start_cycles)
+	atomic_add_unchecked(((unsigned int) ((end_cycles - start_cycles)
 		    >> 10)), /* Kcycles */
 		   &dev->cpu_kcycles_used);
 
@@ -744,11 +744,11 @@ static void dlfb_dpy_deferred_io(struct
 		dlfb_urb_completion(urb);
 
 error:
-	atomic_add(bytes_sent, &dev->bytes_sent);
-	atomic_add(bytes_identical, &dev->bytes_identical);
-	atomic_add(bytes_rendered, &dev->bytes_rendered);
+	atomic_add_unchecked(bytes_sent, &dev->bytes_sent);
+	atomic_add_unchecked(bytes_identical, &dev->bytes_identical);
+	atomic_add_unchecked(bytes_rendered, &dev->bytes_rendered);
 	end_cycles = get_cycles();
-	atomic_add(((unsigned int) ((end_cycles - start_cycles)
+	atomic_add_unchecked(((unsigned int) ((end_cycles - start_cycles)
 		    >> 10)), /* Kcycles */
 		   &dev->cpu_kcycles_used);
 }
@@ -986,7 +986,9 @@ static int dlfb_ops_release(struct fb_in
 		fb_deferred_io_cleanup(info);
 		kfree(info->fbdefio);
 		info->fbdefio = NULL;
-		info->fbops->fb_mmap = dlfb_ops_mmap;
+		pax_open_kernel();
+		*(void **)&info->fbops->fb_mmap = dlfb_ops_mmap;
+		pax_close_kernel();
 	}
 
 	pr_warn("released /dev/fb%d user=%d count=%d\n",
@@ -1368,7 +1370,7 @@ static ssize_t metrics_bytes_rendered_sh
 	struct fb_info *fb_info = dev_get_drvdata(fbdev);
 	struct dlfb_data *dev = fb_info->par;
 	return snprintf(buf, PAGE_SIZE, "%u\n",
-			atomic_read(&dev->bytes_rendered));
+			atomic_read_unchecked(&dev->bytes_rendered));
 }
 
 static ssize_t metrics_bytes_identical_show(struct device *fbdev,
@@ -1376,7 +1378,7 @@ static ssize_t metrics_bytes_identical_s
 	struct fb_info *fb_info = dev_get_drvdata(fbdev);
 	struct dlfb_data *dev = fb_info->par;
 	return snprintf(buf, PAGE_SIZE, "%u\n",
-			atomic_read(&dev->bytes_identical));
+			atomic_read_unchecked(&dev->bytes_identical));
 }
 
 static ssize_t metrics_bytes_sent_show(struct device *fbdev,
@@ -1384,7 +1386,7 @@ static ssize_t metrics_bytes_sent_show(s
 	struct fb_info *fb_info = dev_get_drvdata(fbdev);
 	struct dlfb_data *dev = fb_info->par;
 	return snprintf(buf, PAGE_SIZE, "%u\n",
-			atomic_read(&dev->bytes_sent));
+			atomic_read_unchecked(&dev->bytes_sent));
 }
 
 static ssize_t metrics_cpu_kcycles_used_show(struct device *fbdev,
@@ -1392,7 +1394,7 @@ static ssize_t metrics_cpu_kcycles_used_
 	struct fb_info *fb_info = dev_get_drvdata(fbdev);
 	struct dlfb_data *dev = fb_info->par;
 	return snprintf(buf, PAGE_SIZE, "%u\n",
-			atomic_read(&dev->cpu_kcycles_used));
+			atomic_read_unchecked(&dev->cpu_kcycles_used));
 }
 
 static ssize_t edid_show(
@@ -1449,10 +1451,10 @@ static ssize_t metrics_reset_store(struc
 	struct fb_info *fb_info = dev_get_drvdata(fbdev);
 	struct dlfb_data *dev = fb_info->par;
 
-	atomic_set(&dev->bytes_rendered, 0);
-	atomic_set(&dev->bytes_identical, 0);
-	atomic_set(&dev->bytes_sent, 0);
-	atomic_set(&dev->cpu_kcycles_used, 0);
+	atomic_set_unchecked(&dev->bytes_rendered, 0);
+	atomic_set_unchecked(&dev->bytes_identical, 0);
+	atomic_set_unchecked(&dev->bytes_sent, 0);
+	atomic_set_unchecked(&dev->cpu_kcycles_used, 0);
 
 	return count;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/uvesafb.c linux-3.2.71-pax/drivers/video/uvesafb.c
--- linux-3.2.71/drivers/video/uvesafb.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/uvesafb.c	2013-03-28 03:19:50.548093326 +0100
@@ -19,6 +19,7 @@
 #include <linux/io.h>
 #include <linux/mutex.h>
 #include <linux/slab.h>
+#include <linux/moduleloader.h>
 #include <video/edid.h>
 #include <video/uvesafb.h>
 #ifdef CONFIG_X86
@@ -121,7 +122,7 @@ static int uvesafb_helper_start(void)
 		NULL,
 	};
 
-	return call_usermodehelper(v86d_path, argv, envp, 1);
+	return call_usermodehelper(v86d_path, argv, envp, UMH_WAIT_PROC);
 }
 
 /*
@@ -569,10 +570,32 @@ static int __devinit uvesafb_vbe_getpmi(
 	if ((task->t.regs.eax & 0xffff) != 0x4f || task->t.regs.es < 0xc000) {
 		par->pmi_setpal = par->ypan = 0;
 	} else {
+
+#ifdef CONFIG_PAX_KERNEXEC
+#ifdef CONFIG_MODULES
+		par->pmi_code = module_alloc_exec((u16)task->t.regs.ecx);
+#endif
+		if (!par->pmi_code) {
+			par->pmi_setpal = par->ypan = 0;
+			return 0;
+		}
+#endif
+
 		par->pmi_base = (u16 *)phys_to_virt(((u32)task->t.regs.es << 4)
 						+ task->t.regs.edi);
+
+#if defined(CONFIG_MODULES) && defined(CONFIG_PAX_KERNEXEC)
+		pax_open_kernel();
+		memcpy(par->pmi_code, par->pmi_base, (u16)task->t.regs.ecx);
+		pax_close_kernel();
+
+		par->pmi_start = ktva_ktla(par->pmi_code + par->pmi_base[1]);
+		par->pmi_pal = ktva_ktla(par->pmi_code + par->pmi_base[2]);
+#else
 		par->pmi_start = (u8 *)par->pmi_base + par->pmi_base[1];
 		par->pmi_pal = (u8 *)par->pmi_base + par->pmi_base[2];
+#endif
+
 		printk(KERN_INFO "uvesafb: protected mode interface info at "
 				 "%04x:%04x\n",
 				 (u16)task->t.regs.es, (u16)task->t.regs.edi);
@@ -816,13 +839,14 @@ static int __devinit uvesafb_vbe_init(st
 	par->ypan = ypan;
 
 	if (par->pmi_setpal || par->ypan) {
+#if !defined(CONFIG_MODULES) || !defined(CONFIG_PAX_KERNEXEC)
 		if (__supported_pte_mask & _PAGE_NX) {
 			par->pmi_setpal = par->ypan = 0;
 			printk(KERN_WARNING "uvesafb: NX protection is actively."
 				"We have better not to use the PMI.\n");
-		} else {
+		} else
+#endif
 			uvesafb_vbe_getpmi(task, par);
-		}
 	}
 #else
 	/* The protected mode interface is not available on non-x86. */
@@ -1449,8 +1473,11 @@ static void __devinit uvesafb_init_info(
 	info->fix.ywrapstep = (par->ypan > 1) ? 1 : 0;
 
 	/* Disable blanking if the user requested so. */
-	if (!blank)
-		info->fbops->fb_blank = NULL;
+	if (!blank) {
+		pax_open_kernel();
+		*(void **)&info->fbops->fb_blank = NULL;
+		pax_close_kernel();
+	}
 
 	/*
 	 * Find out how much IO memory is required for the mode with
@@ -1526,8 +1553,11 @@ static void __devinit uvesafb_init_info(
 	info->flags = FBINFO_FLAG_DEFAULT |
 			(par->ypan ? FBINFO_HWACCEL_YPAN : 0);
 
-	if (!par->ypan)
-		info->fbops->fb_pan_display = NULL;
+	if (!par->ypan) {
+		pax_open_kernel();
+		*(void **)&info->fbops->fb_pan_display = NULL;
+		pax_close_kernel();
+	}
 }
 
 static void __devinit uvesafb_init_mtrr(struct fb_info *info)
@@ -1828,6 +1858,11 @@ out:
 	if (par->vbe_modes)
 		kfree(par->vbe_modes);
 
+#if defined(CONFIG_MODULES) && defined(CONFIG_PAX_KERNEXEC)
+	if (par->pmi_code)
+		module_free_exec(NULL, par->pmi_code);
+#endif
+
 	framebuffer_release(info);
 	return err;
 }
@@ -1854,6 +1889,12 @@ static int uvesafb_remove(struct platfor
 				kfree(par->vbe_state_orig);
 			if (par->vbe_state_saved)
 				kfree(par->vbe_state_saved);
+
+#if defined(CONFIG_MODULES) && defined(CONFIG_PAX_KERNEXEC)
+			if (par->pmi_code)
+				module_free_exec(NULL, par->pmi_code);
+#endif
+
 		}
 
 		framebuffer_release(info);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/vesafb.c linux-3.2.71-pax/drivers/video/vesafb.c
--- linux-3.2.71/drivers/video/vesafb.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/vesafb.c	2013-03-28 04:34:45.195853346 +0100
@@ -9,6 +9,7 @@
  */
 
 #include <linux/module.h>
+#include <linux/moduleloader.h>
 #include <linux/kernel.h>
 #include <linux/errno.h>
 #include <linux/string.h>
@@ -52,8 +53,8 @@ static int   vram_remap __initdata;		/*
 static int   vram_total __initdata;		/* Set total amount of memory */
 static int   pmi_setpal __read_mostly = 1;	/* pmi for palette changes ??? */
 static int   ypan       __read_mostly;		/* 0..nothing, 1..ypan, 2..ywrap */
-static void  (*pmi_start)(void) __read_mostly;
-static void  (*pmi_pal)  (void) __read_mostly;
+static void  (*pmi_start)(void) __read_only;
+static void  (*pmi_pal)  (void) __read_only;
 static int   depth      __read_mostly;
 static int   vga_compat __read_mostly;
 /* --------------------------------------------------------------------- */
@@ -233,6 +234,7 @@ static int __init vesafb_probe(struct pl
 	unsigned int size_vmode;
 	unsigned int size_remap;
 	unsigned int size_total;
+	void *pmi_code = NULL;
 
 	if (screen_info.orig_video_isVGA != VIDEO_TYPE_VLFB)
 		return -ENODEV;
@@ -275,10 +277,6 @@ static int __init vesafb_probe(struct pl
 		size_remap = size_total;
 	vesafb_fix.smem_len = size_remap;
 
-#ifndef __i386__
-	screen_info.vesapm_seg = 0;
-#endif
-
 	if (!request_mem_region(vesafb_fix.smem_start, size_total, "vesafb")) {
 		printk(KERN_WARNING
 		       "vesafb: cannot reserve video memory at 0x%lx\n",
@@ -307,9 +305,21 @@ static int __init vesafb_probe(struct pl
 	printk(KERN_INFO "vesafb: mode is %dx%dx%d, linelength=%d, pages=%d\n",
 	       vesafb_defined.xres, vesafb_defined.yres, vesafb_defined.bits_per_pixel, vesafb_fix.line_length, screen_info.pages);
 
+#ifdef __i386__
+
+#if defined(CONFIG_MODULES) && defined(CONFIG_PAX_KERNEXEC)
+	pmi_code = module_alloc_exec(screen_info.vesapm_size);
+	if (!pmi_code)
+#elif !defined(CONFIG_PAX_KERNEXEC)
+	if (0)
+#endif
+
+#endif
+	screen_info.vesapm_seg = 0;
+
 	if (screen_info.vesapm_seg) {
-		printk(KERN_INFO "vesafb: protected mode interface info at %04x:%04x\n",
-		       screen_info.vesapm_seg,screen_info.vesapm_off);
+		printk(KERN_INFO "vesafb: protected mode interface info at %04x:%04x %04x bytes\n",
+		       screen_info.vesapm_seg,screen_info.vesapm_off,screen_info.vesapm_size);
 	}
 
 	if (screen_info.vesapm_seg < 0xc000)
@@ -317,9 +327,25 @@ static int __init vesafb_probe(struct pl
 
 	if (ypan || pmi_setpal) {
 		unsigned short *pmi_base;
+
 		pmi_base  = (unsigned short*)phys_to_virt(((unsigned long)screen_info.vesapm_seg << 4) + screen_info.vesapm_off);
-		pmi_start = (void*)((char*)pmi_base + pmi_base[1]);
-		pmi_pal   = (void*)((char*)pmi_base + pmi_base[2]);
+
+#if defined(CONFIG_MODULES) && defined(CONFIG_PAX_KERNEXEC)
+		pax_open_kernel();
+		memcpy(pmi_code, pmi_base, screen_info.vesapm_size);
+#else
+		pmi_code  = pmi_base;
+#endif
+
+		pmi_start = (void*)((char*)pmi_code + pmi_base[1]);
+		pmi_pal   = (void*)((char*)pmi_code + pmi_base[2]);
+
+#if defined(CONFIG_MODULES) && defined(CONFIG_PAX_KERNEXEC)
+		pmi_start = ktva_ktla(pmi_start);
+		pmi_pal = ktva_ktla(pmi_pal);
+		pax_close_kernel();
+#endif
+
 		printk(KERN_INFO "vesafb: pmi: set display start = %p, set palette = %p\n",pmi_start,pmi_pal);
 		if (pmi_base[3]) {
 			printk(KERN_INFO "vesafb: pmi: ports = ");
@@ -472,8 +498,11 @@ static int __init vesafb_probe(struct pl
 	info->flags = FBINFO_FLAG_DEFAULT | FBINFO_MISC_FIRMWARE |
 		(ypan ? FBINFO_HWACCEL_YPAN : 0);
 
-	if (!ypan)
-		info->fbops->fb_pan_display = NULL;
+	if (!ypan) {
+		pax_open_kernel();
+		*(void **)&info->fbops->fb_pan_display = NULL;
+		pax_close_kernel();
+	}
 
 	if (fb_alloc_cmap(&info->cmap, 256, 0) < 0) {
 		err = -ENOMEM;
@@ -488,6 +517,11 @@ static int __init vesafb_probe(struct pl
 	       info->node, info->fix.id);
 	return 0;
 err:
+
+#if defined(__i386__) && defined(CONFIG_MODULES) && defined(CONFIG_PAX_KERNEXEC)
+	module_free_exec(NULL, pmi_code);
+#endif
+
 	if (info->screen_base)
 		iounmap(info->screen_base);
 	framebuffer_release(info);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/video/via/via_clock.h linux-3.2.71-pax/drivers/video/via/via_clock.h
--- linux-3.2.71/drivers/video/via/via_clock.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/drivers/video/via/via_clock.h	2012-07-04 19:24:48.660063008 +0200
@@ -56,7 +56,7 @@ struct via_clock {
 
 	void (*set_engine_pll_state)(u8 state);
 	void (*set_engine_pll)(struct via_pll_config config);
-};
+} __no_const;
 
 
 static inline u32 get_pll_internal_frequency(u32 ref_freq,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/drivers/xen/events.c linux-3.2.71-pax/drivers/xen/events.c
--- linux-3.2.71/drivers/xen/events.c	2015-08-07 11:37:20.607789895 +0200
+++ linux-3.2.71-pax/drivers/xen/events.c	2015-08-07 11:37:43.019790554 +0200
@@ -1636,7 +1636,7 @@ void xen_irq_resume(void)
 	restore_pirqs();
 }
 
-static struct irq_chip xen_dynamic_chip __read_mostly = {
+static struct irq_chip xen_dynamic_chip = {
 	.name			= "xen-dyn",
 
 	.irq_disable		= disable_dynirq,
@@ -1650,7 +1650,7 @@ static struct irq_chip xen_dynamic_chip
 	.irq_retrigger		= retrigger_dynirq,
 };
 
-static struct irq_chip xen_pirq_chip __read_mostly = {
+static struct irq_chip xen_pirq_chip = {
 	.name			= "xen-pirq",
 
 	.irq_startup		= startup_pirq,
@@ -1670,7 +1670,7 @@ static struct irq_chip xen_pirq_chip __r
 	.irq_retrigger		= retrigger_dynirq,
 };
 
-static struct irq_chip xen_percpu_chip __read_mostly = {
+static struct irq_chip xen_percpu_chip = {
 	.name			= "xen-percpu",
 
 	.irq_disable		= disable_dynirq,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/9p/vfs_addr.c linux-3.2.71-pax/fs/9p/vfs_addr.c
--- linux-3.2.71/fs/9p/vfs_addr.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/9p/vfs_addr.c	2013-06-21 19:34:10.638698102 +0200
@@ -185,7 +185,7 @@ static int v9fs_vfs_writepage_locked(str
 
 	retval = v9fs_file_write_internal(inode,
 					  v9inode->writeback_fid,
-					  (__force const char __user *)buffer,
+					  (const char __force_user *)buffer,
 					  len, &offset, 0);
 	if (retval > 0)
 		retval = 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/9p/vfs_inode.c linux-3.2.71-pax/fs/9p/vfs_inode.c
--- linux-3.2.71/fs/9p/vfs_inode.c	2015-08-14 21:48:35.308707913 +0200
+++ linux-3.2.71-pax/fs/9p/vfs_inode.c	2015-08-14 21:48:45.668707360 +0200
@@ -1285,7 +1285,7 @@ static void *v9fs_vfs_follow_link(struct
 void
 v9fs_vfs_put_link(struct dentry *dentry, struct nameidata *nd, void *p)
 {
-	char *s = nd_get_link(nd);
+	const char *s = nd_get_link(nd);
 
 	P9_DPRINTK(P9_DEBUG_VFS, " %s %s\n", dentry->d_name.name,
 		IS_ERR(s) ? "<error>" : s);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/afs/inode.c linux-3.2.71-pax/fs/afs/inode.c
--- linux-3.2.71/fs/afs/inode.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/afs/inode.c	2013-09-01 20:16:04.979792999 +0200
@@ -141,7 +141,7 @@ struct inode *afs_iget_autocell(struct i
 	struct afs_vnode *vnode;
 	struct super_block *sb;
 	struct inode *inode;
-	static atomic_t afs_autocell_ino;
+	static atomic_unchecked_t afs_autocell_ino;
 
 	_enter("{%x:%u},%*.*s,",
 	       AFS_FS_I(dir)->fid.vid, AFS_FS_I(dir)->fid.vnode,
@@ -154,7 +154,7 @@ struct inode *afs_iget_autocell(struct i
 	data.fid.unique = 0;
 	data.fid.vnode = 0;
 
-	inode = iget5_locked(sb, atomic_inc_return(&afs_autocell_ino),
+	inode = iget5_locked(sb, atomic_inc_return_unchecked(&afs_autocell_ino),
 			     afs_iget5_autocell_test, afs_iget5_set,
 			     &data);
 	if (!inode) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/aio.c linux-3.2.71-pax/fs/aio.c
--- linux-3.2.71/fs/aio.c	2014-11-05 23:20:30.081389750 +0100
+++ linux-3.2.71-pax/fs/aio.c	2014-11-05 23:20:50.493398812 +0100
@@ -119,7 +119,7 @@ static int aio_setup_ring(struct kioctx
 	size += sizeof(struct io_event) * nr_events;
 	nr_pages = (size + PAGE_SIZE-1) >> PAGE_SHIFT;
 
-	if (nr_pages < 0)
+	if (nr_pages <= 0)
 		return -EINVAL;
 
 	nr_events = (PAGE_SIZE * nr_pages - sizeof(struct aio_ring)) / sizeof(struct io_event);
@@ -1468,18 +1468,19 @@ static ssize_t aio_fsync(struct kiocb *i
 static ssize_t aio_setup_vectored_rw(int type, struct kiocb *kiocb, bool compat)
 {
 	ssize_t ret;
+	struct iovec iovstack;
 
 #ifdef CONFIG_COMPAT
 	if (compat)
 		ret = compat_rw_copy_check_uvector(type,
 				(struct compat_iovec __user *)kiocb->ki_buf,
-				kiocb->ki_nbytes, 1, &kiocb->ki_inline_vec,
+				kiocb->ki_nbytes, 1, &iovstack,
 				&kiocb->ki_iovec, 1);
 	else
 #endif
 		ret = rw_copy_check_uvector(type,
 				(struct iovec __user *)kiocb->ki_buf,
-				kiocb->ki_nbytes, 1, &kiocb->ki_inline_vec,
+				kiocb->ki_nbytes, 1, &iovstack,
 				&kiocb->ki_iovec, 1);
 	if (ret < 0)
 		goto out;
@@ -1488,6 +1489,10 @@ static ssize_t aio_setup_vectored_rw(int
 	if (ret < 0)
 		goto out;
 
+	if (kiocb->ki_iovec == &iovstack) {
+		kiocb->ki_inline_vec = iovstack;
+		kiocb->ki_iovec = &kiocb->ki_inline_vec;
+	}
 	kiocb->ki_nr_segs = kiocb->ki_nbytes;
 	kiocb->ki_cur_seg = 0;
 	/* ki_nbytes/left now reflect bytes instead of segs */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/autofs4/waitq.c linux-3.2.71-pax/fs/autofs4/waitq.c
--- linux-3.2.71/fs/autofs4/waitq.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/autofs4/waitq.c	2012-07-04 19:24:48.664063008 +0200
@@ -60,7 +60,7 @@ static int autofs4_write(struct file *fi
 {
 	unsigned long sigpipe, flags;
 	mm_segment_t fs;
-	const char *data = (const char *)addr;
+	const char __user *data = (const char __force_user *)addr;
 	ssize_t wr = 0;
 
 	/** WARNING: this is not safe for writing more than PIPE_BUF bytes! **/
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/befs/endian.h linux-3.2.71-pax/fs/befs/endian.h
--- linux-3.2.71/fs/befs/endian.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/befs/endian.h	2013-03-28 04:10:58.183929538 +0100
@@ -11,7 +11,7 @@
 
 #include <asm/byteorder.h>
 
-static inline u64
+static inline u64 __intentional_overflow(-1)
 fs64_to_cpu(const struct super_block *sb, fs64 n)
 {
 	if (BEFS_SB(sb)->byte_order == BEFS_BYTESEX_LE)
@@ -29,7 +29,7 @@ cpu_to_fs64(const struct super_block *sb
 		return (__force fs64)cpu_to_be64(n);
 }
 
-static inline u32
+static inline u32 __intentional_overflow(-1)
 fs32_to_cpu(const struct super_block *sb, fs32 n)
 {
 	if (BEFS_SB(sb)->byte_order == BEFS_BYTESEX_LE)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/befs/linuxvfs.c linux-3.2.71-pax/fs/befs/linuxvfs.c
--- linux-3.2.71/fs/befs/linuxvfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/befs/linuxvfs.c	2012-07-04 19:24:48.664063008 +0200
@@ -503,7 +503,7 @@ static void befs_put_link(struct dentry
 {
 	befs_inode_info *befs_ino = BEFS_I(dentry->d_inode);
 	if (befs_ino->i_flags & BEFS_LONG_SYMLINK) {
-		char *link = nd_get_link(nd);
+		const char *link = nd_get_link(nd);
 		if (!IS_ERR(link))
 			kfree(link);
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/binfmt_aout.c linux-3.2.71-pax/fs/binfmt_aout.c
--- linux-3.2.71/fs/binfmt_aout.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/binfmt_aout.c	2012-07-04 19:24:48.664063008 +0200
@@ -262,6 +262,27 @@ static int load_aout_binary(struct linux
 	install_exec_creds(bprm);
  	current->flags &= ~PF_FORKNOEXEC;
 
+#if defined(CONFIG_PAX_NOEXEC) || defined(CONFIG_PAX_ASLR)
+	current->mm->pax_flags = 0UL;
+#endif
+
+#ifdef CONFIG_PAX_PAGEEXEC
+	if (!(N_FLAGS(ex) & F_PAX_PAGEEXEC)) {
+		current->mm->pax_flags |= MF_PAX_PAGEEXEC;
+
+#ifdef CONFIG_PAX_EMUTRAMP
+		if (N_FLAGS(ex) & F_PAX_EMUTRAMP)
+			current->mm->pax_flags |= MF_PAX_EMUTRAMP;
+#endif
+
+#ifdef CONFIG_PAX_MPROTECT
+		if (!(N_FLAGS(ex) & F_PAX_MPROTECT))
+			current->mm->pax_flags |= MF_PAX_MPROTECT;
+#endif
+
+	}
+#endif
+
 	if (N_MAGIC(ex) == OMAGIC) {
 		unsigned long text_addr, map_size;
 		loff_t pos;
@@ -334,7 +355,7 @@ static int load_aout_binary(struct linux
 
 		down_write(&current->mm->mmap_sem);
  		error = do_mmap(bprm->file, N_DATADDR(ex), ex.a_data,
-				PROT_READ | PROT_WRITE | PROT_EXEC,
+				PROT_READ | PROT_WRITE,
 				MAP_FIXED | MAP_PRIVATE | MAP_DENYWRITE | MAP_EXECUTABLE,
 				fd_offset + ex.a_text);
 		up_write(&current->mm->mmap_sem);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/binfmt_elf.c linux-3.2.71-pax/fs/binfmt_elf.c
--- linux-3.2.71/fs/binfmt_elf.c	2015-08-07 11:37:20.619789895 +0200
+++ linux-3.2.71-pax/fs/binfmt_elf.c	2015-08-07 11:39:06.691793014 +0200
@@ -32,6 +32,7 @@
 #include <linux/elf.h>
 #include <linux/utsname.h>
 #include <linux/coredump.h>
+#include <linux/xattr.h>
 #include <asm/uaccess.h>
 #include <asm/param.h>
 #include <asm/page.h>
@@ -39,7 +40,7 @@
 static int load_elf_binary(struct linux_binprm *bprm, struct pt_regs *regs);
 static int load_elf_library(struct file *);
 static unsigned long elf_map(struct file *, unsigned long, struct elf_phdr *,
-				int, int, unsigned long);
+				int, int, unsigned long) __intentional_overflow(-1);
 
 /*
  * If we don't support core dumping, then supply a NULL so we
@@ -51,6 +52,10 @@ static int elf_core_dump(struct coredump
 #define elf_core_dump	NULL
 #endif
 
+#ifdef CONFIG_PAX_MPROTECT
+static void elf_handle_mprotect(struct vm_area_struct *vma, unsigned long newflags);
+#endif
+
 #if ELF_EXEC_PAGESIZE > PAGE_SIZE
 #define ELF_MIN_ALIGN	ELF_EXEC_PAGESIZE
 #else
@@ -70,6 +75,11 @@ static struct linux_binfmt elf_format =
 	.load_binary	= load_elf_binary,
 	.load_shlib	= load_elf_library,
 	.core_dump	= elf_core_dump,
+
+#ifdef CONFIG_PAX_MPROTECT
+	.handle_mprotect= elf_handle_mprotect,
+#endif
+
 	.min_coredump	= ELF_EXEC_PAGESIZE,
 };
 
@@ -77,6 +87,8 @@ static struct linux_binfmt elf_format =
 
 static int set_brk(unsigned long start, unsigned long end)
 {
+	unsigned long e = end;
+
 	start = ELF_PAGEALIGN(start);
 	end = ELF_PAGEALIGN(end);
 	if (end > start) {
@@ -87,7 +99,7 @@ static int set_brk(unsigned long start,
 		if (BAD_ADDR(addr))
 			return addr;
 	}
-	current->mm->start_brk = current->mm->brk = end;
+	current->mm->start_brk = current->mm->brk = e;
 	return 0;
 }
 
@@ -148,12 +160,13 @@ create_elf_tables(struct linux_binprm *b
 	elf_addr_t __user *u_rand_bytes;
 	const char *k_platform = ELF_PLATFORM;
 	const char *k_base_platform = ELF_BASE_PLATFORM;
-	unsigned char k_rand_bytes[16];
+	u32 k_rand_bytes[4];
 	int items;
 	elf_addr_t *elf_info;
 	int ei_index = 0;
 	const struct cred *cred = current_cred();
 	struct vm_area_struct *vma;
+	unsigned long saved_auxv[AT_VECTOR_SIZE];
 
 	/*
 	 * In some cases (e.g. Hyper-Threading), we want to avoid L1
@@ -195,8 +208,12 @@ create_elf_tables(struct linux_binprm *b
 	 * Generate 16 random bytes for userspace PRNG seeding.
 	 */
 	get_random_bytes(k_rand_bytes, sizeof(k_rand_bytes));
-	u_rand_bytes = (elf_addr_t __user *)
-		       STACK_ALLOC(p, sizeof(k_rand_bytes));
+	srandom32(k_rand_bytes[0] ^ random32());
+	srandom32(k_rand_bytes[1] ^ random32());
+	srandom32(k_rand_bytes[2] ^ random32());
+	srandom32(k_rand_bytes[3] ^ random32());
+	p = STACK_ROUND(p, sizeof(k_rand_bytes));
+	u_rand_bytes = (elf_addr_t __user *) p;
 	if (__copy_to_user(u_rand_bytes, k_rand_bytes, sizeof(k_rand_bytes)))
 		return -EFAULT;
 
@@ -308,9 +325,11 @@ create_elf_tables(struct linux_binprm *b
 		return -EFAULT;
 	current->mm->env_end = p;
 
+	memcpy(saved_auxv, elf_info, ei_index * sizeof(elf_addr_t));
+
 	/* Put the elf_info on the stack in the right place.  */
 	sp = (elf_addr_t __user *)envp + 1;
-	if (copy_to_user(sp, elf_info, ei_index * sizeof(elf_addr_t)))
+	if (copy_to_user(sp, saved_auxv, ei_index * sizeof(elf_addr_t)))
 		return -EFAULT;
 	return 0;
 }
@@ -376,15 +395,14 @@ static unsigned long total_mapping_size(
    an ELF header */
 
 static unsigned long load_elf_interp(struct elfhdr *interp_elf_ex,
-		struct file *interpreter, unsigned long *interp_map_addr,
-		unsigned long no_base)
+		struct file *interpreter, unsigned long no_base)
 {
 	struct elf_phdr *elf_phdata;
 	struct elf_phdr *eppnt;
-	unsigned long load_addr = 0;
+	unsigned long load_addr = 0, pax_task_size = TASK_SIZE;
 	int load_addr_set = 0;
 	unsigned long last_bss = 0, elf_bss = 0;
-	unsigned long error = ~0UL;
+	unsigned long error = -EINVAL;
 	unsigned long total_size;
 	int retval, i, size;
 
@@ -430,6 +448,11 @@ static unsigned long load_elf_interp(str
 		goto out_close;
 	}
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (current->mm->pax_flags & MF_PAX_SEGMEXEC)
+		pax_task_size = SEGMEXEC_TASK_SIZE;
+#endif
+
 	eppnt = elf_phdata;
 	for (i = 0; i < interp_elf_ex->e_phnum; i++, eppnt++) {
 		if (eppnt->p_type == PT_LOAD) {
@@ -453,8 +476,6 @@ static unsigned long load_elf_interp(str
 			map_addr = elf_map(interpreter, load_addr + vaddr,
 					eppnt, elf_prot, elf_type, total_size);
 			total_size = 0;
-			if (!*interp_map_addr)
-				*interp_map_addr = map_addr;
 			error = map_addr;
 			if (BAD_ADDR(map_addr))
 				goto out_close;
@@ -473,8 +494,8 @@ static unsigned long load_elf_interp(str
 			k = load_addr + eppnt->p_vaddr;
 			if (BAD_ADDR(k) ||
 			    eppnt->p_filesz > eppnt->p_memsz ||
-			    eppnt->p_memsz > TASK_SIZE ||
-			    TASK_SIZE - eppnt->p_memsz < k) {
+			    eppnt->p_memsz > pax_task_size ||
+			    pax_task_size - eppnt->p_memsz < k) {
 				error = -ENOMEM;
 				goto out_close;
 			}
@@ -513,11 +534,13 @@ static unsigned long load_elf_interp(str
 		elf_bss = ELF_PAGESTART(elf_bss + ELF_MIN_ALIGN - 1);
 
 		/* Map the last of the bss segment */
-		down_write(&current->mm->mmap_sem);
-		error = do_brk(elf_bss, last_bss - elf_bss);
-		up_write(&current->mm->mmap_sem);
-		if (BAD_ADDR(error))
-			goto out_close;
+		if (last_bss > elf_bss) {
+			down_write(&current->mm->mmap_sem);
+			error = do_brk(elf_bss, last_bss - elf_bss);
+			up_write(&current->mm->mmap_sem);
+			if (BAD_ADDR(error))
+				goto out_close;
+		}
 	}
 
 	error = load_addr;
@@ -528,6 +551,336 @@ out:
 	return error;
 }
 
+#ifdef CONFIG_PAX_PT_PAX_FLAGS
+#ifdef CONFIG_PAX_SOFTMODE
+static unsigned long pax_parse_pt_pax_softmode(const struct elf_phdr * const elf_phdata)
+{
+	unsigned long pax_flags = 0UL;
+
+#ifdef CONFIG_PAX_PAGEEXEC
+	if (elf_phdata->p_flags & PF_PAGEEXEC)
+		pax_flags |= MF_PAX_PAGEEXEC;
+#endif
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (elf_phdata->p_flags & PF_SEGMEXEC)
+		pax_flags |= MF_PAX_SEGMEXEC;
+#endif
+
+#ifdef CONFIG_PAX_EMUTRAMP
+	if ((elf_phdata->p_flags & PF_EMUTRAMP) && (pax_flags & (MF_PAX_PAGEEXEC | MF_PAX_SEGMEXEC)))
+		pax_flags |= MF_PAX_EMUTRAMP;
+#endif
+
+#ifdef CONFIG_PAX_MPROTECT
+	if (elf_phdata->p_flags & PF_MPROTECT)
+		pax_flags |= MF_PAX_MPROTECT;
+#endif
+
+#if defined(CONFIG_PAX_RANDMMAP) || defined(CONFIG_PAX_RANDUSTACK)
+	if (randomize_va_space && (elf_phdata->p_flags & PF_RANDMMAP))
+		pax_flags |= MF_PAX_RANDMMAP;
+#endif
+
+	return pax_flags;
+}
+#endif
+
+static unsigned long pax_parse_pt_pax_hardmode(const struct elf_phdr * const elf_phdata)
+{
+	unsigned long pax_flags = 0UL;
+
+#ifdef CONFIG_PAX_PAGEEXEC
+	if (!(elf_phdata->p_flags & PF_NOPAGEEXEC))
+		pax_flags |= MF_PAX_PAGEEXEC;
+#endif
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (!(elf_phdata->p_flags & PF_NOSEGMEXEC))
+		pax_flags |= MF_PAX_SEGMEXEC;
+#endif
+
+#ifdef CONFIG_PAX_EMUTRAMP
+	if (!(elf_phdata->p_flags & PF_NOEMUTRAMP))
+		pax_flags |= MF_PAX_EMUTRAMP;
+#endif
+
+#ifdef CONFIG_PAX_MPROTECT
+	if (!(elf_phdata->p_flags & PF_NOMPROTECT))
+		pax_flags |= MF_PAX_MPROTECT;
+#endif
+
+#if defined(CONFIG_PAX_RANDMMAP) || defined(CONFIG_PAX_RANDUSTACK)
+	if (randomize_va_space && !(elf_phdata->p_flags & PF_NORANDMMAP))
+		pax_flags |= MF_PAX_RANDMMAP;
+#endif
+
+	return pax_flags;
+}
+#endif
+
+#ifdef CONFIG_PAX_XATTR_PAX_FLAGS
+#ifdef CONFIG_PAX_SOFTMODE
+static unsigned long pax_parse_xattr_pax_softmode(unsigned long pax_flags_softmode)
+{
+	unsigned long pax_flags = 0UL;
+
+#ifdef CONFIG_PAX_PAGEEXEC
+	if (pax_flags_softmode & MF_PAX_PAGEEXEC)
+		pax_flags |= MF_PAX_PAGEEXEC;
+#endif
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (pax_flags_softmode & MF_PAX_SEGMEXEC)
+		pax_flags |= MF_PAX_SEGMEXEC;
+#endif
+
+#ifdef CONFIG_PAX_EMUTRAMP
+	if ((pax_flags_softmode & MF_PAX_EMUTRAMP) && (pax_flags & (MF_PAX_PAGEEXEC | MF_PAX_SEGMEXEC)))
+		pax_flags |= MF_PAX_EMUTRAMP;
+#endif
+
+#ifdef CONFIG_PAX_MPROTECT
+	if (pax_flags_softmode & MF_PAX_MPROTECT)
+		pax_flags |= MF_PAX_MPROTECT;
+#endif
+
+#if defined(CONFIG_PAX_RANDMMAP) || defined(CONFIG_PAX_RANDUSTACK)
+	if (randomize_va_space && (pax_flags_softmode & MF_PAX_RANDMMAP))
+		pax_flags |= MF_PAX_RANDMMAP;
+#endif
+
+	return pax_flags;
+}
+#endif
+
+static unsigned long pax_parse_xattr_pax_hardmode(unsigned long pax_flags_hardmode)
+{
+	unsigned long pax_flags = 0UL;
+
+#ifdef CONFIG_PAX_PAGEEXEC
+	if (!(pax_flags_hardmode & MF_PAX_PAGEEXEC))
+		pax_flags |= MF_PAX_PAGEEXEC;
+#endif
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (!(pax_flags_hardmode & MF_PAX_SEGMEXEC))
+		pax_flags |= MF_PAX_SEGMEXEC;
+#endif
+
+#ifdef CONFIG_PAX_EMUTRAMP
+	if (!(pax_flags_hardmode & MF_PAX_EMUTRAMP))
+		pax_flags |= MF_PAX_EMUTRAMP;
+#endif
+
+#ifdef CONFIG_PAX_MPROTECT
+	if (!(pax_flags_hardmode & MF_PAX_MPROTECT))
+		pax_flags |= MF_PAX_MPROTECT;
+#endif
+
+#if defined(CONFIG_PAX_RANDMMAP) || defined(CONFIG_PAX_RANDUSTACK)
+	if (randomize_va_space && !(pax_flags_hardmode & MF_PAX_RANDMMAP))
+		pax_flags |= MF_PAX_RANDMMAP;
+#endif
+
+	return pax_flags;
+}
+#endif
+
+#if defined(CONFIG_PAX_NOEXEC) || defined(CONFIG_PAX_ASLR)
+static unsigned long pax_parse_defaults(void)
+{
+	unsigned long pax_flags = 0UL;
+
+#ifdef CONFIG_PAX_SOFTMODE
+	if (pax_softmode)
+		return pax_flags;
+#endif
+
+#ifdef CONFIG_PAX_PAGEEXEC
+	pax_flags |= MF_PAX_PAGEEXEC;
+#endif
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	pax_flags |= MF_PAX_SEGMEXEC;
+#endif
+
+#ifdef CONFIG_PAX_MPROTECT
+	pax_flags |= MF_PAX_MPROTECT;
+#endif
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (randomize_va_space)
+		pax_flags |= MF_PAX_RANDMMAP;
+#endif
+
+	return pax_flags;
+}
+
+static unsigned long pax_parse_ei_pax(const struct elfhdr * const elf_ex)
+{
+	unsigned long pax_flags = PAX_PARSE_FLAGS_FALLBACK;
+
+#ifdef CONFIG_PAX_EI_PAX
+
+#ifdef CONFIG_PAX_SOFTMODE
+	if (pax_softmode)
+		return pax_flags;
+#endif
+
+	pax_flags = 0UL;
+
+#ifdef CONFIG_PAX_PAGEEXEC
+	if (!(elf_ex->e_ident[EI_PAX] & EF_PAX_PAGEEXEC))
+		pax_flags |= MF_PAX_PAGEEXEC;
+#endif
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (!(elf_ex->e_ident[EI_PAX] & EF_PAX_SEGMEXEC))
+		pax_flags |= MF_PAX_SEGMEXEC;
+#endif
+
+#ifdef CONFIG_PAX_EMUTRAMP
+	if ((pax_flags & (MF_PAX_PAGEEXEC | MF_PAX_SEGMEXEC)) && (elf_ex->e_ident[EI_PAX] & EF_PAX_EMUTRAMP))
+		pax_flags |= MF_PAX_EMUTRAMP;
+#endif
+
+#ifdef CONFIG_PAX_MPROTECT
+	if ((pax_flags & (MF_PAX_PAGEEXEC | MF_PAX_SEGMEXEC)) && !(elf_ex->e_ident[EI_PAX] & EF_PAX_MPROTECT))
+		pax_flags |= MF_PAX_MPROTECT;
+#endif
+
+#ifdef CONFIG_PAX_ASLR
+	if (randomize_va_space && !(elf_ex->e_ident[EI_PAX] & EF_PAX_RANDMMAP))
+		pax_flags |= MF_PAX_RANDMMAP;
+#endif
+
+#endif
+
+	return pax_flags;
+
+}
+
+static unsigned long pax_parse_pt_pax(const struct elfhdr * const elf_ex, const struct elf_phdr * const elf_phdata)
+{
+
+#ifdef CONFIG_PAX_PT_PAX_FLAGS
+	unsigned long i;
+
+	for (i = 0UL; i < elf_ex->e_phnum; i++)
+		if (elf_phdata[i].p_type == PT_PAX_FLAGS) {
+			if (((elf_phdata[i].p_flags & PF_PAGEEXEC) && (elf_phdata[i].p_flags & PF_NOPAGEEXEC)) ||
+			    ((elf_phdata[i].p_flags & PF_SEGMEXEC) && (elf_phdata[i].p_flags & PF_NOSEGMEXEC)) ||
+			    ((elf_phdata[i].p_flags & PF_EMUTRAMP) && (elf_phdata[i].p_flags & PF_NOEMUTRAMP)) ||
+			    ((elf_phdata[i].p_flags & PF_MPROTECT) && (elf_phdata[i].p_flags & PF_NOMPROTECT)) ||
+			    ((elf_phdata[i].p_flags & PF_RANDMMAP) && (elf_phdata[i].p_flags & PF_NORANDMMAP)))
+				return PAX_PARSE_FLAGS_FALLBACK;
+
+#ifdef CONFIG_PAX_SOFTMODE
+			if (pax_softmode)
+				return pax_parse_pt_pax_softmode(&elf_phdata[i]);
+			else
+#endif
+
+				return pax_parse_pt_pax_hardmode(&elf_phdata[i]);
+			break;
+		}
+#endif
+
+	return PAX_PARSE_FLAGS_FALLBACK;
+}
+
+static unsigned long pax_parse_xattr_pax(struct file * const file)
+{
+
+#ifdef CONFIG_PAX_XATTR_PAX_FLAGS
+	ssize_t xattr_size, i;
+	unsigned char xattr_value[sizeof("pemrs") - 1];
+	unsigned long pax_flags_hardmode = 0UL, pax_flags_softmode = 0UL;
+
+	xattr_size = pax_getxattr(file->f_path.dentry, xattr_value, sizeof xattr_value);
+	if (xattr_size < 0 || xattr_size > sizeof xattr_value)
+		return PAX_PARSE_FLAGS_FALLBACK;
+
+	for (i = 0; i < xattr_size; i++)
+		switch (xattr_value[i]) {
+		default:
+			return PAX_PARSE_FLAGS_FALLBACK;
+
+#define parse_flag(option1, option2, flag)			\
+		case option1:					\
+			if (pax_flags_hardmode & MF_PAX_##flag)	\
+				return PAX_PARSE_FLAGS_FALLBACK;\
+			pax_flags_hardmode |= MF_PAX_##flag;	\
+			break;					\
+		case option2:					\
+			if (pax_flags_softmode & MF_PAX_##flag)	\
+				return PAX_PARSE_FLAGS_FALLBACK;\
+			pax_flags_softmode |= MF_PAX_##flag;	\
+			break;
+
+		parse_flag('p', 'P', PAGEEXEC);
+		parse_flag('e', 'E', EMUTRAMP);
+		parse_flag('m', 'M', MPROTECT);
+		parse_flag('r', 'R', RANDMMAP);
+		parse_flag('s', 'S', SEGMEXEC);
+
+#undef parse_flag
+		}
+
+	if (pax_flags_hardmode & pax_flags_softmode)
+		return PAX_PARSE_FLAGS_FALLBACK;
+
+#ifdef CONFIG_PAX_SOFTMODE
+	if (pax_softmode)
+		return pax_parse_xattr_pax_softmode(pax_flags_softmode);
+	else
+#endif
+
+		return pax_parse_xattr_pax_hardmode(pax_flags_hardmode);
+#else
+	return PAX_PARSE_FLAGS_FALLBACK;
+#endif
+
+}
+
+static long pax_parse_pax_flags(const struct elfhdr * const elf_ex, const struct elf_phdr * const elf_phdata, struct file * const file)
+{
+	unsigned long pax_flags, ei_pax_flags,  pt_pax_flags, xattr_pax_flags;
+
+	pax_flags = pax_parse_defaults();
+	ei_pax_flags = pax_parse_ei_pax(elf_ex);
+	pt_pax_flags = pax_parse_pt_pax(elf_ex, elf_phdata);
+	xattr_pax_flags = pax_parse_xattr_pax(file);
+
+	if (pt_pax_flags != PAX_PARSE_FLAGS_FALLBACK &&
+	    xattr_pax_flags != PAX_PARSE_FLAGS_FALLBACK &&
+	    pt_pax_flags != xattr_pax_flags)
+		return -EINVAL;
+	if (xattr_pax_flags != PAX_PARSE_FLAGS_FALLBACK)
+		pax_flags = xattr_pax_flags;
+	else if (pt_pax_flags != PAX_PARSE_FLAGS_FALLBACK)
+		pax_flags = pt_pax_flags;
+	else if (ei_pax_flags != PAX_PARSE_FLAGS_FALLBACK)
+		pax_flags = ei_pax_flags;
+
+#if defined(CONFIG_PAX_PAGEEXEC) && defined(CONFIG_PAX_SEGMEXEC)
+	if ((pax_flags & (MF_PAX_PAGEEXEC | MF_PAX_SEGMEXEC)) == (MF_PAX_PAGEEXEC | MF_PAX_SEGMEXEC)) {
+		if ((__supported_pte_mask & _PAGE_NX))
+			pax_flags &= ~MF_PAX_SEGMEXEC;
+		else
+			pax_flags &= ~MF_PAX_PAGEEXEC;
+	}
+#endif
+
+	if (0 > pax_check_flags(&pax_flags))
+		return -EINVAL;
+
+	current->mm->pax_flags = pax_flags;
+	return 0;
+}
+#endif
+
 /*
  * These are the functions used to load ELF style executables and shared
  * libraries.  There is no binary dependent code anywhere else.
@@ -544,6 +897,11 @@ static unsigned long randomize_stack_top
 {
 	unsigned long random_variable = 0;
 
+#ifdef CONFIG_PAX_RANDUSTACK
+	if (current->mm->pax_flags & MF_PAX_RANDMMAP)
+		return stack_top - current->mm->delta_stack;
+#endif
+
 	if ((current->flags & PF_RANDOMIZE) &&
 		!(current->personality & ADDR_NO_RANDOMIZE)) {
 		random_variable = (unsigned long) get_random_int();
@@ -563,7 +921,7 @@ static int load_elf_binary(struct linux_
  	unsigned long load_addr = 0, load_bias = 0;
 	int load_addr_set = 0;
 	char * elf_interpreter = NULL;
-	unsigned long error;
+	unsigned long error = 0;
 	struct elf_phdr *elf_ppnt, *elf_phdata;
 	unsigned long elf_bss, elf_brk;
 	int retval, i;
@@ -573,11 +931,11 @@ static int load_elf_binary(struct linux_
 	unsigned long start_code, end_code, start_data, end_data;
 	unsigned long reloc_func_desc __maybe_unused = 0;
 	int executable_stack = EXSTACK_DEFAULT;
-	unsigned long def_flags = 0;
 	struct {
 		struct elfhdr elf_ex;
 		struct elfhdr interp_elf_ex;
 	} *loc;
+	unsigned long pax_task_size;
 
 	loc = kmalloc(sizeof(*loc), GFP_KERNEL);
 	if (!loc) {
@@ -714,11 +1072,82 @@ static int load_elf_binary(struct linux_
 
 	/* OK, This is the point of no return */
 	current->flags &= ~PF_FORKNOEXEC;
-	current->mm->def_flags = def_flags;
+	current->mm->def_flags = 0;
 
 	/* Do this immediately, since STACK_TOP as used in setup_arg_pages
 	   may depend on the personality.  */
 	SET_PERSONALITY(loc->elf_ex);
+
+#if defined(CONFIG_PAX_NOEXEC) || defined(CONFIG_PAX_ASLR)
+	current->mm->pax_flags = 0UL;
+#endif
+
+#ifdef CONFIG_PAX_DLRESOLVE
+	current->mm->call_dl_resolve = 0UL;
+#endif
+
+#if defined(CONFIG_PPC32) && defined(CONFIG_PAX_EMUSIGRT)
+	current->mm->call_syscall = 0UL;
+#endif
+
+#ifdef CONFIG_PAX_ASLR
+	current->mm->delta_mmap = 0UL;
+	current->mm->delta_stack = 0UL;
+#endif
+
+#if defined(CONFIG_PAX_NOEXEC) || defined(CONFIG_PAX_ASLR)
+	if (0 > pax_parse_pax_flags(&loc->elf_ex, elf_phdata, bprm->file)) {
+		send_sig(SIGKILL, current, 0);
+		goto out_free_dentry;
+	}
+#endif
+
+#ifdef CONFIG_PAX_HAVE_ACL_FLAGS
+	pax_set_initial_flags(bprm);
+#elif defined(CONFIG_PAX_HOOK_ACL_FLAGS)
+	if (pax_set_initial_flags_func)
+		(pax_set_initial_flags_func)(bprm);
+#endif
+
+#ifdef CONFIG_ARCH_TRACK_EXEC_LIMIT
+	if ((current->mm->pax_flags & MF_PAX_PAGEEXEC) && !(__supported_pte_mask & _PAGE_NX)) {
+		current->mm->context.user_cs_limit = PAGE_SIZE;
+		current->mm->def_flags |= VM_PAGEEXEC | VM_NOHUGEPAGE;
+	}
+#endif
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (current->mm->pax_flags & MF_PAX_SEGMEXEC) {
+		current->mm->context.user_cs_base = SEGMEXEC_TASK_SIZE;
+		current->mm->context.user_cs_limit = TASK_SIZE-SEGMEXEC_TASK_SIZE;
+		pax_task_size = SEGMEXEC_TASK_SIZE;
+		current->mm->def_flags |= VM_NOHUGEPAGE;
+	} else
+#endif
+
+	pax_task_size = TASK_SIZE;
+
+#if defined(CONFIG_ARCH_TRACK_EXEC_LIMIT) || defined(CONFIG_PAX_SEGMEXEC)
+	if (current->mm->pax_flags & (MF_PAX_PAGEEXEC | MF_PAX_SEGMEXEC)) {
+		set_user_cs(current->mm->context.user_cs_base, current->mm->context.user_cs_limit, get_cpu());
+		put_cpu();
+	}
+#endif
+
+#ifdef CONFIG_PAX_ASLR
+	if (current->mm->pax_flags & MF_PAX_RANDMMAP) {
+		current->mm->delta_mmap = (pax_get_random_long() & ((1UL << PAX_DELTA_MMAP_LEN)-1)) << PAGE_SHIFT;
+		current->mm->delta_stack = (pax_get_random_long() & ((1UL << PAX_DELTA_STACK_LEN)-1)) << PAGE_SHIFT;
+	}
+#endif
+
+#if defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC)
+	if (current->mm->pax_flags & (MF_PAX_PAGEEXEC | MF_PAX_SEGMEXEC)) {
+		executable_stack = EXSTACK_DISABLE_X;
+		current->personality &= ~READ_IMPLIES_EXEC;
+	} else
+#endif
+
 	if (elf_read_implies_exec(loc->elf_ex, executable_stack))
 		current->personality |= READ_IMPLIES_EXEC;
 
@@ -810,8 +1239,21 @@ static int load_elf_binary(struct linux_
 #else
 			load_bias = ELF_PAGESTART(ELF_ET_DYN_BASE - vaddr);
 #endif
-			total_size = total_mapping_size(elf_phdata,
-							loc->elf_ex.e_phnum);
+
+#ifdef CONFIG_PAX_RANDMMAP
+			/* PaX: randomize base address at the default exe base if requested */
+			if ((current->mm->pax_flags & MF_PAX_RANDMMAP) && elf_interpreter) {
+#ifdef CONFIG_SPARC64
+				load_bias = (pax_get_random_long() & ((1UL << PAX_DELTA_MMAP_LEN) - 1)) << (PAGE_SHIFT+1);
+#else
+				load_bias = (pax_get_random_long() & ((1UL << PAX_DELTA_MMAP_LEN) - 1)) << PAGE_SHIFT;
+#endif
+				load_bias = ELF_PAGESTART(PAX_ELF_ET_DYN_BASE - vaddr + load_bias);
+				elf_flags |= MAP_FIXED;
+			}
+#endif
+
+			total_size = total_mapping_size(elf_phdata, loc->elf_ex.e_phnum);
 			if (!total_size) {
 				retval = -EINVAL;
 				goto out_free_dentry;
@@ -848,9 +1290,9 @@ static int load_elf_binary(struct linux_
 		 * allowed task size. Note that p_filesz must always be
 		 * <= p_memsz so it is only necessary to check p_memsz.
 		 */
-		if (BAD_ADDR(k) || elf_ppnt->p_filesz > elf_ppnt->p_memsz ||
-		    elf_ppnt->p_memsz > TASK_SIZE ||
-		    TASK_SIZE - elf_ppnt->p_memsz < k) {
+		if (k >= pax_task_size || elf_ppnt->p_filesz > elf_ppnt->p_memsz ||
+		    elf_ppnt->p_memsz > pax_task_size ||
+		    pax_task_size - elf_ppnt->p_memsz < k) {
 			/* set_brk can never work. Avoid overflows. */
 			send_sig(SIGKILL, current, 0);
 			retval = -EINVAL;
@@ -889,17 +1331,44 @@ static int load_elf_binary(struct linux_
 		goto out_free_dentry;
 	}
 	if (likely(elf_bss != elf_brk) && unlikely(padzero(elf_bss))) {
-		send_sig(SIGSEGV, current, 0);
-		retval = -EFAULT; /* Nobody gets to see this, but.. */
-		goto out_free_dentry;
+		/*
+		 * This bss-zeroing can fail if the ELF
+		 * file specifies odd protections. So
+		 * we don't check the return value
+		 */
 	}
 
-	if (elf_interpreter) {
-		unsigned long uninitialized_var(interp_map_addr);
+#ifdef CONFIG_PAX_RANDMMAP
+	if (current->mm->pax_flags & MF_PAX_RANDMMAP) {
+		unsigned long start, size, flags, vm_flags;
+
+		start = ELF_PAGEALIGN(elf_brk);
+		size = PAGE_SIZE + ((pax_get_random_long() & ((1UL << 22) - 1UL)) << 4);
+		flags = MAP_FIXED | MAP_PRIVATE;
+		vm_flags = VM_DONTEXPAND | VM_RESERVED;
 
+		down_write(&current->mm->mmap_sem);
+		start = get_unmapped_area(NULL, start, PAGE_ALIGN(size), 0, flags);
+		retval = -ENOMEM;
+		if (!IS_ERR_VALUE(start) && !find_vma_intersection(current->mm, start, start + size + PAGE_SIZE)) {
+//			if (current->personality & ADDR_NO_RANDOMIZE)
+//				vm_flags |= VM_READ | VM_MAYREAD;
+			start = mmap_region(NULL, start, PAGE_ALIGN(size), flags, vm_flags, 0);
+			retval = IS_ERR_VALUE(start) ? start : 0;
+		}
+		up_write(&current->mm->mmap_sem);
+		if (retval == 0)
+			retval = set_brk(start + size, start + size + PAGE_SIZE);
+		if (retval < 0) {
+			send_sig(SIGKILL, current, 0);
+			goto out_free_dentry;
+		}
+	}
+#endif
+
+	if (elf_interpreter) {
 		elf_entry = load_elf_interp(&loc->interp_elf_ex,
 					    interpreter,
-					    &interp_map_addr,
 					    load_bias);
 		if (!IS_ERR((void *)elf_entry)) {
 			/*
@@ -1106,7 +1575,7 @@ out:
  * Decide what to dump of a segment, part, all or none.
  */
 static unsigned long vma_dump_size(struct vm_area_struct *vma,
-				   unsigned long mm_flags)
+				   unsigned long mm_flags, long signr)
 {
 #define FILTER(type)	(mm_flags & (1UL << MMF_DUMP_##type))
 
@@ -1140,7 +1609,7 @@ static unsigned long vma_dump_size(struc
 	if (vma->vm_file == NULL)
 		return 0;
 
-	if (FILTER(MAPPED_PRIVATE))
+	if (signr == SIGKILL || FILTER(MAPPED_PRIVATE))
 		goto whole;
 
 	/*
@@ -1362,9 +1831,9 @@ static void fill_auxv_note(struct memelf
 {
 	elf_addr_t *auxv = (elf_addr_t *) mm->saved_auxv;
 	int i = 0;
-	do
+	do {
 		i += 2;
-	while (auxv[i - 2] != AT_NULL);
+	} while (auxv[i - 2] != AT_NULL);
 	fill_note(note, "CORE", NT_AUXV, i * sizeof(elf_addr_t), auxv);
 }
 
@@ -1859,14 +2328,14 @@ static void fill_extnum_info(struct elfh
 }
 
 static size_t elf_core_vma_data_size(struct vm_area_struct *gate_vma,
-				     unsigned long mm_flags)
+				     struct coredump_params *cprm)
 {
 	struct vm_area_struct *vma;
 	size_t size = 0;
 
 	for (vma = first_vma(current, gate_vma); vma != NULL;
 	     vma = next_vma(vma, gate_vma))
-		size += vma_dump_size(vma, mm_flags);
+		size += vma_dump_size(vma, cprm->mm_flags, cprm->signr);
 	return size;
 }
 
@@ -1960,7 +2429,7 @@ static int elf_core_dump(struct coredump
 
 	dataoff = offset = roundup(offset, ELF_EXEC_PAGESIZE);
 
-	offset += elf_core_vma_data_size(gate_vma, cprm->mm_flags);
+	offset += elf_core_vma_data_size(gate_vma, cprm);
 	offset += elf_core_extra_data_size();
 	e_shoff = offset;
 
@@ -1991,7 +2460,7 @@ static int elf_core_dump(struct coredump
 		phdr.p_offset = offset;
 		phdr.p_vaddr = vma->vm_start;
 		phdr.p_paddr = 0;
-		phdr.p_filesz = vma_dump_size(vma, cprm->mm_flags);
+		phdr.p_filesz = vma_dump_size(vma, cprm->mm_flags, cprm->signr);
 		phdr.p_memsz = vma->vm_end - vma->vm_start;
 		offset += phdr.p_filesz;
 		phdr.p_flags = vma->vm_flags & VM_READ ? PF_R : 0;
@@ -2026,7 +2495,7 @@ static int elf_core_dump(struct coredump
 		unsigned long addr;
 		unsigned long end;
 
-		end = vma->vm_start + vma_dump_size(vma, cprm->mm_flags);
+		end = vma->vm_start + vma_dump_size(vma, cprm->mm_flags, cprm->signr);
 
 		for (addr = vma->vm_start; addr < end; addr += PAGE_SIZE) {
 			struct page *page;
@@ -2072,6 +2541,137 @@ out:
 
 #endif		/* CONFIG_ELF_CORE */
 
+#ifdef CONFIG_PAX_MPROTECT
+/* PaX: non-PIC ELF libraries need relocations on their executable segments
+ * therefore we'll grant them VM_MAYWRITE once during their life. Similarly
+ * we'll remove VM_MAYWRITE for good on RELRO segments.
+ *
+ * The checks favour ld-linux.so behaviour which operates on a per ELF segment
+ * basis because we want to allow the common case and not the special ones.
+ */
+static void elf_handle_mprotect(struct vm_area_struct *vma, unsigned long newflags)
+{
+	struct elfhdr elf_h;
+	struct elf_phdr elf_p;
+	unsigned long i;
+	unsigned long oldflags;
+	bool is_textrel_rw, is_textrel_rx, is_relro;
+
+	if (!(vma->vm_mm->pax_flags & MF_PAX_MPROTECT))
+		return;
+
+	oldflags = vma->vm_flags & (VM_MAYEXEC | VM_MAYWRITE | VM_MAYREAD | VM_EXEC | VM_WRITE | VM_READ);
+	newflags &= VM_MAYEXEC | VM_MAYWRITE | VM_MAYREAD | VM_EXEC | VM_WRITE | VM_READ;
+
+#ifdef CONFIG_PAX_ELFRELOCS
+	/* possible TEXTREL */
+	is_textrel_rw = vma->vm_file && !vma->anon_vma && oldflags == (VM_MAYEXEC | VM_MAYREAD | VM_EXEC | VM_READ) && newflags == (VM_WRITE | VM_READ);
+	is_textrel_rx = vma->vm_file && vma->anon_vma && oldflags == (VM_MAYEXEC | VM_MAYWRITE | VM_MAYREAD | VM_WRITE | VM_READ) && newflags == (VM_EXEC | VM_READ);
+#else
+	is_textrel_rw = false;
+	is_textrel_rx = false;
+#endif
+
+	/* possible RELRO */
+	is_relro = vma->vm_file && vma->anon_vma && oldflags == (VM_MAYWRITE | VM_MAYREAD | VM_READ) && newflags == (VM_MAYWRITE | VM_MAYREAD | VM_READ);
+
+	if (!is_textrel_rw && !is_textrel_rx && !is_relro)
+		return;
+
+	if (sizeof(elf_h) != kernel_read(vma->vm_file, 0UL, (char *)&elf_h, sizeof(elf_h)) ||
+	    memcmp(elf_h.e_ident, ELFMAG, SELFMAG) ||
+
+#ifdef CONFIG_PAX_ETEXECRELOCS
+	    ((is_textrel_rw || is_textrel_rx) && (elf_h.e_type != ET_DYN && elf_h.e_type != ET_EXEC)) ||
+#else
+	    ((is_textrel_rw || is_textrel_rx) && elf_h.e_type != ET_DYN) ||
+#endif
+
+	    (is_relro && (elf_h.e_type != ET_DYN && elf_h.e_type != ET_EXEC)) ||
+	    !elf_check_arch(&elf_h) ||
+	    elf_h.e_phentsize != sizeof(struct elf_phdr) ||
+	    elf_h.e_phnum > 65536UL / sizeof(struct elf_phdr))
+		return;
+
+	for (i = 0UL; i < elf_h.e_phnum; i++) {
+		if (sizeof(elf_p) != kernel_read(vma->vm_file, elf_h.e_phoff + i*sizeof(elf_p), (char *)&elf_p, sizeof(elf_p)))
+			return;
+		switch (elf_p.p_type) {
+		case PT_DYNAMIC:
+			if (!is_textrel_rw && !is_textrel_rx)
+				continue;
+			i = 0UL;
+			while ((i+1) * sizeof(elf_dyn) <= elf_p.p_filesz) {
+				elf_dyn dyn;
+
+				if (sizeof(dyn) != kernel_read(vma->vm_file, elf_p.p_offset + i*sizeof(dyn), (char *)&dyn, sizeof(dyn)))
+					break;
+				if (dyn.d_tag == DT_NULL)
+					break;
+				if (dyn.d_tag == DT_TEXTREL || (dyn.d_tag == DT_FLAGS && (dyn.d_un.d_val & DF_TEXTREL))) {
+					if (is_textrel_rw)
+						vma->vm_flags |= VM_MAYWRITE;
+					else
+						/* PaX: disallow write access after relocs are done, hopefully noone else needs it... */
+						vma->vm_flags &= ~VM_MAYWRITE;
+					break;
+				}
+				i++;
+			}
+			is_textrel_rw = false;
+			is_textrel_rx = false;
+			continue;
+
+		case PT_GNU_RELRO:
+			if (!is_relro)
+				continue;
+			if ((elf_p.p_offset >> PAGE_SHIFT) == vma->vm_pgoff && ELF_PAGEALIGN(elf_p.p_memsz) == vma->vm_end - vma->vm_start)
+				vma->vm_flags &= ~VM_MAYWRITE;
+			is_relro = false;
+			continue;
+
+#ifdef CONFIG_PAX_PT_PAX_FLAGS
+		case PT_PAX_FLAGS: {
+			const char *msg_mprotect = "", *msg_emutramp = "";
+			char *buffer_lib, *buffer_exe;
+
+			if (elf_p.p_flags & PF_NOMPROTECT)
+				msg_mprotect = "MPROTECT disabled";
+
+#ifdef CONFIG_PAX_EMUTRAMP
+			if (!(vma->vm_mm->pax_flags & MF_PAX_EMUTRAMP) && !(elf_p.p_flags & PF_NOEMUTRAMP))
+				msg_emutramp = "EMUTRAMP enabled";
+#endif
+
+			if (!msg_mprotect[0] && !msg_emutramp[0])
+				continue;
+
+			if (!printk_ratelimit())
+				continue;
+
+			buffer_lib = (char *)__get_free_page(GFP_KERNEL);
+			buffer_exe = (char *)__get_free_page(GFP_KERNEL);
+			if (buffer_lib && buffer_exe) {
+				char *path_lib, *path_exe;
+
+				path_lib = pax_get_path(&vma->vm_file->f_path, buffer_lib, PAGE_SIZE);
+				path_exe = pax_get_path(&vma->vm_mm->exe_file->f_path, buffer_exe, PAGE_SIZE);
+
+				pr_info("PAX: %s wants %s%s%s on %s\n", path_lib, msg_mprotect,
+					(msg_mprotect[0] && msg_emutramp[0] ? " and " : ""), msg_emutramp, path_exe);
+
+			}
+			free_page((unsigned long)buffer_exe);
+			free_page((unsigned long)buffer_lib);
+			continue;
+		}
+#endif
+
+		}
+	}
+}
+#endif
+
 static int __init init_elf_binfmt(void)
 {
 	return register_binfmt(&elf_format);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/binfmt_flat.c linux-3.2.71-pax/fs/binfmt_flat.c
--- linux-3.2.71/fs/binfmt_flat.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/binfmt_flat.c	2012-07-04 19:24:48.668063007 +0200
@@ -567,7 +567,9 @@ static int load_flat_file(struct linux_b
 				realdatastart = (unsigned long) -ENOMEM;
 			printk("Unable to allocate RAM for process data, errno %d\n",
 					(int)-realdatastart);
+			down_write(&current->mm->mmap_sem);
 			do_munmap(current->mm, textpos, text_len);
+			up_write(&current->mm->mmap_sem);
 			ret = realdatastart;
 			goto err;
 		}
@@ -591,8 +593,10 @@ static int load_flat_file(struct linux_b
 		}
 		if (IS_ERR_VALUE(result)) {
 			printk("Unable to read data+bss, errno %d\n", (int)-result);
+			down_write(&current->mm->mmap_sem);
 			do_munmap(current->mm, textpos, text_len);
 			do_munmap(current->mm, realdatastart, len);
+			up_write(&current->mm->mmap_sem);
 			ret = result;
 			goto err;
 		}
@@ -661,8 +665,10 @@ static int load_flat_file(struct linux_b
 		}
 		if (IS_ERR_VALUE(result)) {
 			printk("Unable to read code+data+bss, errno %d\n",(int)-result);
+			down_write(&current->mm->mmap_sem);
 			do_munmap(current->mm, textpos, text_len + data_len + extra +
 				MAX_SHARED_LIBS * sizeof(unsigned long));
+			up_write(&current->mm->mmap_sem);
 			ret = result;
 			goto err;
 		}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/bio.c linux-3.2.71-pax/fs/bio.c
--- linux-3.2.71/fs/bio.c	2013-09-10 17:24:55.537739116 +0200
+++ linux-3.2.71-pax/fs/bio.c	2013-09-10 17:25:39.397736774 +0200
@@ -848,7 +848,7 @@ struct bio *bio_copy_user_iov(struct req
 		/*
 		 * Overflow, abort
 		 */
-		if (end < start)
+		if (end < start || end - start > INT_MAX - nr_pages)
 			return ERR_PTR(-EINVAL);
 
 		nr_pages += end - start;
@@ -982,7 +982,7 @@ static struct bio *__bio_map_user_iov(st
 		/*
 		 * Overflow, abort
 		 */
-		if (end < start)
+		if (end < start || end - start > INT_MAX - nr_pages)
 			return ERR_PTR(-EINVAL);
 
 		nr_pages += end - start;
@@ -1244,7 +1244,7 @@ static void bio_copy_kern_endio(struct b
 	const int read = bio_data_dir(bio) == READ;
 	struct bio_map_data *bmd = bio->bi_private;
 	int i;
-	char *p = bmd->sgvecs[0].iov_base;
+	char *p = (char __force_kernel *)bmd->sgvecs[0].iov_base;
 
 	bio_for_each_segment_all(bvec, bio, i) {
 		char *addr = page_address(bvec->bv_page);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/block_dev.c linux-3.2.71-pax/fs/block_dev.c
--- linux-3.2.71/fs/block_dev.c	2013-07-27 11:12:22.431992798 +0200
+++ linux-3.2.71-pax/fs/block_dev.c	2013-07-27 11:12:26.599992575 +0200
@@ -690,7 +690,7 @@ static bool bd_may_claim(struct block_de
 	else if (bdev->bd_contains == bdev)
 		return true;  	 /* is a whole device which isn't held */
 
-	else if (whole->bd_holder == bd_may_claim)
+	else if (whole->bd_holder == (void *)bd_may_claim)
 		return true; 	 /* is a partition of a device that is being partitioned */
 	else if (whole->bd_holder != NULL)
 		return false;	 /* is a partition of a held device */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/btrfs/ctree.c linux-3.2.71-pax/fs/btrfs/ctree.c
--- linux-3.2.71/fs/btrfs/ctree.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/btrfs/ctree.c	2012-07-04 19:24:48.668063007 +0200
@@ -488,9 +488,12 @@ static noinline int __btrfs_cow_block(st
 		free_extent_buffer(buf);
 		add_root_to_dirty_list(root);
 	} else {
-		if (root->root_key.objectid == BTRFS_TREE_RELOC_OBJECTID)
-			parent_start = parent->start;
-		else
+		if (root->root_key.objectid == BTRFS_TREE_RELOC_OBJECTID) {
+			if (parent)
+				parent_start = parent->start;
+			else
+				parent_start = 0;
+		} else
 			parent_start = 0;
 
 		WARN_ON(trans->transid != btrfs_header_generation(parent));
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/btrfs/extent-tree.c linux-3.2.71-pax/fs/btrfs/extent-tree.c
--- linux-3.2.71/fs/btrfs/extent-tree.c	2015-08-07 11:37:20.623789895 +0200
+++ linux-3.2.71-pax/fs/btrfs/extent-tree.c	2015-08-07 11:37:43.019790554 +0200
@@ -5644,7 +5644,7 @@ again:
 
 	if (ret == -ENOSPC && num_bytes > min_alloc_size) {
 		num_bytes = num_bytes >> 1;
-		num_bytes = num_bytes & ~(root->sectorsize - 1);
+		num_bytes = num_bytes & ~((u64)root->sectorsize - 1);
 		num_bytes = max(num_bytes, min_alloc_size);
 		do_chunk_alloc(trans, root->fs_info->extent_root,
 			       num_bytes, data, CHUNK_ALLOC_FORCE);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/btrfs/ioctl.c linux-3.2.71-pax/fs/btrfs/ioctl.c
--- linux-3.2.71/fs/btrfs/ioctl.c	2015-08-14 21:48:35.308707913 +0200
+++ linux-3.2.71-pax/fs/btrfs/ioctl.c	2015-08-14 21:48:45.668707360 +0200
@@ -2789,7 +2789,7 @@ long btrfs_ioctl_space_info(struct btrfs
 		up_read(&info->groups_sem);
 	}
 
-	user_dest = (struct btrfs_ioctl_space_info *)
+	user_dest = (struct btrfs_ioctl_space_info __user *)
 		(arg + sizeof(struct btrfs_ioctl_space_args));
 
 	if (copy_to_user(user_dest, dest_orig, alloc_size))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/btrfs/relocation.c linux-3.2.71-pax/fs/btrfs/relocation.c
--- linux-3.2.71/fs/btrfs/relocation.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/btrfs/relocation.c	2012-07-04 19:24:48.672063007 +0200
@@ -1244,7 +1244,7 @@ static int __update_reloc_root(struct bt
 	}
 	spin_unlock(&rc->reloc_root_tree.lock);
 
-	BUG_ON((struct btrfs_root *)node->data != root);
+	BUG_ON(!node || (struct btrfs_root *)node->data != root);
 
 	if (!del) {
 		spin_lock(&rc->reloc_root_tree.lock);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/buffer.c linux-3.2.71-pax/fs/buffer.c
--- linux-3.2.71/fs/buffer.c	2015-08-14 21:48:35.320707912 +0200
+++ linux-3.2.71-pax/fs/buffer.c	2015-08-14 21:48:45.668707360 +0200
@@ -3333,7 +3333,7 @@ void __init buffer_init(void)
 	bh_cachep = kmem_cache_create("buffer_head",
 			sizeof(struct buffer_head), 0,
 				(SLAB_RECLAIM_ACCOUNT|SLAB_PANIC|
-				SLAB_MEM_SPREAD),
+				SLAB_MEM_SPREAD|SLAB_NO_SANITIZE),
 				NULL);
 
 	/*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/cachefiles/bind.c linux-3.2.71-pax/fs/cachefiles/bind.c
--- linux-3.2.71/fs/cachefiles/bind.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/cachefiles/bind.c	2012-07-04 19:24:48.672063007 +0200
@@ -39,13 +39,11 @@ int cachefiles_daemon_bind(struct cachef
 	       args);
 
 	/* start by checking things over */
-	ASSERT(cache->fstop_percent >= 0 &&
-	       cache->fstop_percent < cache->fcull_percent &&
+	ASSERT(cache->fstop_percent < cache->fcull_percent &&
 	       cache->fcull_percent < cache->frun_percent &&
 	       cache->frun_percent  < 100);
 
-	ASSERT(cache->bstop_percent >= 0 &&
-	       cache->bstop_percent < cache->bcull_percent &&
+	ASSERT(cache->bstop_percent < cache->bcull_percent &&
 	       cache->bcull_percent < cache->brun_percent &&
 	       cache->brun_percent  < 100);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/cachefiles/daemon.c linux-3.2.71-pax/fs/cachefiles/daemon.c
--- linux-3.2.71/fs/cachefiles/daemon.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/cachefiles/daemon.c	2012-07-04 19:24:48.672063007 +0200
@@ -196,7 +196,7 @@ static ssize_t cachefiles_daemon_read(st
 	if (n > buflen)
 		return -EMSGSIZE;
 
-	if (copy_to_user(_buffer, buffer, n) != 0)
+	if (n > sizeof(buffer) || copy_to_user(_buffer, buffer, n) != 0)
 		return -EFAULT;
 
 	return n;
@@ -222,7 +222,7 @@ static ssize_t cachefiles_daemon_write(s
 	if (test_bit(CACHEFILES_DEAD, &cache->flags))
 		return -EIO;
 
-	if (datalen < 0 || datalen > PAGE_SIZE - 1)
+	if (datalen > PAGE_SIZE - 1)
 		return -EOPNOTSUPP;
 
 	/* drag the command string into the kernel so we can parse it */
@@ -386,7 +386,7 @@ static int cachefiles_daemon_fstop(struc
 	if (args[0] != '%' || args[1] != '\0')
 		return -EINVAL;
 
-	if (fstop < 0 || fstop >= cache->fcull_percent)
+	if (fstop >= cache->fcull_percent)
 		return cachefiles_daemon_range_error(cache, args);
 
 	cache->fstop_percent = fstop;
@@ -458,7 +458,7 @@ static int cachefiles_daemon_bstop(struc
 	if (args[0] != '%' || args[1] != '\0')
 		return -EINVAL;
 
-	if (bstop < 0 || bstop >= cache->bcull_percent)
+	if (bstop >= cache->bcull_percent)
 		return cachefiles_daemon_range_error(cache, args);
 
 	cache->bstop_percent = bstop;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/cachefiles/internal.h linux-3.2.71-pax/fs/cachefiles/internal.h
--- linux-3.2.71/fs/cachefiles/internal.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/cachefiles/internal.h	2012-07-04 19:24:48.676063008 +0200
@@ -57,7 +57,7 @@ struct cachefiles_cache {
 	wait_queue_head_t		daemon_pollwq;	/* poll waitqueue for daemon */
 	struct rb_root			active_nodes;	/* active nodes (can't be culled) */
 	rwlock_t			active_lock;	/* lock for active_nodes */
-	atomic_t			gravecounter;	/* graveyard uniquifier */
+	atomic_unchecked_t		gravecounter;	/* graveyard uniquifier */
 	unsigned			frun_percent;	/* when to stop culling (% files) */
 	unsigned			fcull_percent;	/* when to start culling (% files) */
 	unsigned			fstop_percent;	/* when to stop allocating (% files) */
@@ -169,19 +169,19 @@ extern int cachefiles_check_in_use(struc
  * proc.c
  */
 #ifdef CONFIG_CACHEFILES_HISTOGRAM
-extern atomic_t cachefiles_lookup_histogram[HZ];
-extern atomic_t cachefiles_mkdir_histogram[HZ];
-extern atomic_t cachefiles_create_histogram[HZ];
+extern atomic_unchecked_t cachefiles_lookup_histogram[HZ];
+extern atomic_unchecked_t cachefiles_mkdir_histogram[HZ];
+extern atomic_unchecked_t cachefiles_create_histogram[HZ];
 
 extern int __init cachefiles_proc_init(void);
 extern void cachefiles_proc_cleanup(void);
 static inline
-void cachefiles_hist(atomic_t histogram[], unsigned long start_jif)
+void cachefiles_hist(atomic_unchecked_t histogram[], unsigned long start_jif)
 {
 	unsigned long jif = jiffies - start_jif;
 	if (jif >= HZ)
 		jif = HZ - 1;
-	atomic_inc(&histogram[jif]);
+	atomic_inc_unchecked(&histogram[jif]);
 }
 
 #else
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/cachefiles/namei.c linux-3.2.71-pax/fs/cachefiles/namei.c
--- linux-3.2.71/fs/cachefiles/namei.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/cachefiles/namei.c	2012-07-04 19:24:48.676063008 +0200
@@ -318,7 +318,7 @@ try_again:
 	/* first step is to make up a grave dentry in the graveyard */
 	sprintf(nbuffer, "%08x%08x",
 		(uint32_t) get_seconds(),
-		(uint32_t) atomic_inc_return(&cache->gravecounter));
+		(uint32_t) atomic_inc_return_unchecked(&cache->gravecounter));
 
 	/* do the multiway lock magic */
 	trap = lock_rename(cache->graveyard, dir);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/cachefiles/proc.c linux-3.2.71-pax/fs/cachefiles/proc.c
--- linux-3.2.71/fs/cachefiles/proc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/cachefiles/proc.c	2012-07-04 19:24:48.676063008 +0200
@@ -14,9 +14,9 @@
 #include <linux/seq_file.h>
 #include "internal.h"
 
-atomic_t cachefiles_lookup_histogram[HZ];
-atomic_t cachefiles_mkdir_histogram[HZ];
-atomic_t cachefiles_create_histogram[HZ];
+atomic_unchecked_t cachefiles_lookup_histogram[HZ];
+atomic_unchecked_t cachefiles_mkdir_histogram[HZ];
+atomic_unchecked_t cachefiles_create_histogram[HZ];
 
 /*
  * display the latency histogram
@@ -35,9 +35,9 @@ static int cachefiles_histogram_show(str
 		return 0;
 	default:
 		index = (unsigned long) v - 3;
-		x = atomic_read(&cachefiles_lookup_histogram[index]);
-		y = atomic_read(&cachefiles_mkdir_histogram[index]);
-		z = atomic_read(&cachefiles_create_histogram[index]);
+		x = atomic_read_unchecked(&cachefiles_lookup_histogram[index]);
+		y = atomic_read_unchecked(&cachefiles_mkdir_histogram[index]);
+		z = atomic_read_unchecked(&cachefiles_create_histogram[index]);
 		if (x == 0 && y == 0 && z == 0)
 			return 0;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/cachefiles/rdwr.c linux-3.2.71-pax/fs/cachefiles/rdwr.c
--- linux-3.2.71/fs/cachefiles/rdwr.c	2013-03-29 02:18:30.175676739 +0100
+++ linux-3.2.71-pax/fs/cachefiles/rdwr.c	2013-03-29 02:19:02.107675034 +0100
@@ -945,7 +945,7 @@ int cachefiles_write_page(struct fscache
 			old_fs = get_fs();
 			set_fs(KERNEL_DS);
 			ret = file->f_op->write(
-				file, (const void __user *) data, len, &pos);
+				file, (const void __force_user *) data, len, &pos);
 			set_fs(old_fs);
 			kunmap(page);
 			if (ret != len)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ceph/dir.c linux-3.2.71-pax/fs/ceph/dir.c
--- linux-3.2.71/fs/ceph/dir.c	2015-01-01 15:15:24.488069624 +0100
+++ linux-3.2.71-pax/fs/ceph/dir.c	2015-01-01 15:15:29.556069757 +0100
@@ -244,7 +244,7 @@ static int ceph_readdir(struct file *fil
 	struct ceph_fs_client *fsc = ceph_inode_to_client(inode);
 	struct ceph_mds_client *mdsc = fsc->mdsc;
 	unsigned frag = fpos_frag(filp->f_pos);
-	int off = fpos_off(filp->f_pos);
+	unsigned int off = fpos_off(filp->f_pos);
 	int err;
 	u32 ftype;
 	struct ceph_mds_reply_info_parsed *rinfo;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ceph/super.c linux-3.2.71-pax/fs/ceph/super.c
--- linux-3.2.71/fs/ceph/super.c	2015-02-20 12:37:33.213178769 +0100
+++ linux-3.2.71-pax/fs/ceph/super.c	2015-02-20 12:37:41.893178305 +0100
@@ -785,7 +785,7 @@ static int ceph_compare_super(struct sup
 /*
  * construct our own bdi so we can control readahead, etc.
  */
-static atomic_long_t bdi_seq = ATOMIC_LONG_INIT(0);
+static atomic_long_unchecked_t bdi_seq = ATOMIC_LONG_INIT(0);
 
 static int ceph_register_bdi(struct super_block *sb,
 			     struct ceph_fs_client *fsc)
@@ -802,7 +802,7 @@ static int ceph_register_bdi(struct supe
 			default_backing_dev_info.ra_pages;
 
 	err = bdi_register(&fsc->backing_dev_info, NULL, "ceph-%d",
-			   atomic_long_inc_return(&bdi_seq));
+			   atomic_long_inc_return_unchecked(&bdi_seq));
 	if (!err)
 		sb->s_bdi = &fsc->backing_dev_info;
 	return err;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/cifs/cifs_debug.c linux-3.2.71-pax/fs/cifs/cifs_debug.c
--- linux-3.2.71/fs/cifs/cifs_debug.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/cifs/cifs_debug.c	2012-07-04 19:24:48.680063008 +0200
@@ -265,8 +265,8 @@ static ssize_t cifs_stats_proc_write(str
 
 	if (c == '1' || c == 'y' || c == 'Y' || c == '0') {
 #ifdef CONFIG_CIFS_STATS2
-		atomic_set(&totBufAllocCount, 0);
-		atomic_set(&totSmBufAllocCount, 0);
+		atomic_set_unchecked(&totBufAllocCount, 0);
+		atomic_set_unchecked(&totSmBufAllocCount, 0);
 #endif /* CONFIG_CIFS_STATS2 */
 		spin_lock(&cifs_tcp_ses_lock);
 		list_for_each(tmp1, &cifs_tcp_ses_list) {
@@ -279,25 +279,25 @@ static ssize_t cifs_stats_proc_write(str
 					tcon = list_entry(tmp3,
 							  struct cifs_tcon,
 							  tcon_list);
-					atomic_set(&tcon->num_smbs_sent, 0);
-					atomic_set(&tcon->num_writes, 0);
-					atomic_set(&tcon->num_reads, 0);
-					atomic_set(&tcon->num_oplock_brks, 0);
-					atomic_set(&tcon->num_opens, 0);
-					atomic_set(&tcon->num_posixopens, 0);
-					atomic_set(&tcon->num_posixmkdirs, 0);
-					atomic_set(&tcon->num_closes, 0);
-					atomic_set(&tcon->num_deletes, 0);
-					atomic_set(&tcon->num_mkdirs, 0);
-					atomic_set(&tcon->num_rmdirs, 0);
-					atomic_set(&tcon->num_renames, 0);
-					atomic_set(&tcon->num_t2renames, 0);
-					atomic_set(&tcon->num_ffirst, 0);
-					atomic_set(&tcon->num_fnext, 0);
-					atomic_set(&tcon->num_fclose, 0);
-					atomic_set(&tcon->num_hardlinks, 0);
-					atomic_set(&tcon->num_symlinks, 0);
-					atomic_set(&tcon->num_locks, 0);
+					atomic_set_unchecked(&tcon->num_smbs_sent, 0);
+					atomic_set_unchecked(&tcon->num_writes, 0);
+					atomic_set_unchecked(&tcon->num_reads, 0);
+					atomic_set_unchecked(&tcon->num_oplock_brks, 0);
+					atomic_set_unchecked(&tcon->num_opens, 0);
+					atomic_set_unchecked(&tcon->num_posixopens, 0);
+					atomic_set_unchecked(&tcon->num_posixmkdirs, 0);
+					atomic_set_unchecked(&tcon->num_closes, 0);
+					atomic_set_unchecked(&tcon->num_deletes, 0);
+					atomic_set_unchecked(&tcon->num_mkdirs, 0);
+					atomic_set_unchecked(&tcon->num_rmdirs, 0);
+					atomic_set_unchecked(&tcon->num_renames, 0);
+					atomic_set_unchecked(&tcon->num_t2renames, 0);
+					atomic_set_unchecked(&tcon->num_ffirst, 0);
+					atomic_set_unchecked(&tcon->num_fnext, 0);
+					atomic_set_unchecked(&tcon->num_fclose, 0);
+					atomic_set_unchecked(&tcon->num_hardlinks, 0);
+					atomic_set_unchecked(&tcon->num_symlinks, 0);
+					atomic_set_unchecked(&tcon->num_locks, 0);
 				}
 			}
 		}
@@ -327,8 +327,8 @@ static int cifs_stats_proc_show(struct s
 			smBufAllocCount.counter, cifs_min_small);
 #ifdef CONFIG_CIFS_STATS2
 	seq_printf(m, "Total Large %d Small %d Allocations\n",
-				atomic_read(&totBufAllocCount),
-				atomic_read(&totSmBufAllocCount));
+				atomic_read_unchecked(&totBufAllocCount),
+				atomic_read_unchecked(&totSmBufAllocCount));
 #endif /* CONFIG_CIFS_STATS2 */
 
 	seq_printf(m, "Operations (MIDs): %d\n", atomic_read(&midCount));
@@ -357,41 +357,41 @@ static int cifs_stats_proc_show(struct s
 				if (tcon->need_reconnect)
 					seq_puts(m, "\tDISCONNECTED ");
 				seq_printf(m, "\nSMBs: %d Oplock Breaks: %d",
-					atomic_read(&tcon->num_smbs_sent),
-					atomic_read(&tcon->num_oplock_brks));
+					atomic_read_unchecked(&tcon->num_smbs_sent),
+					atomic_read_unchecked(&tcon->num_oplock_brks));
 				seq_printf(m, "\nReads:  %d Bytes: %lld",
-					atomic_read(&tcon->num_reads),
+					atomic_read_unchecked(&tcon->num_reads),
 					(long long)(tcon->bytes_read));
 				seq_printf(m, "\nWrites: %d Bytes: %lld",
-					atomic_read(&tcon->num_writes),
+					atomic_read_unchecked(&tcon->num_writes),
 					(long long)(tcon->bytes_written));
 				seq_printf(m, "\nFlushes: %d",
-					atomic_read(&tcon->num_flushes));
+					atomic_read_unchecked(&tcon->num_flushes));
 				seq_printf(m, "\nLocks: %d HardLinks: %d "
 					      "Symlinks: %d",
-					atomic_read(&tcon->num_locks),
-					atomic_read(&tcon->num_hardlinks),
-					atomic_read(&tcon->num_symlinks));
+					atomic_read_unchecked(&tcon->num_locks),
+					atomic_read_unchecked(&tcon->num_hardlinks),
+					atomic_read_unchecked(&tcon->num_symlinks));
 				seq_printf(m, "\nOpens: %d Closes: %d "
 					      "Deletes: %d",
-					atomic_read(&tcon->num_opens),
-					atomic_read(&tcon->num_closes),
-					atomic_read(&tcon->num_deletes));
+					atomic_read_unchecked(&tcon->num_opens),
+					atomic_read_unchecked(&tcon->num_closes),
+					atomic_read_unchecked(&tcon->num_deletes));
 				seq_printf(m, "\nPosix Opens: %d "
 					      "Posix Mkdirs: %d",
-					atomic_read(&tcon->num_posixopens),
-					atomic_read(&tcon->num_posixmkdirs));
+					atomic_read_unchecked(&tcon->num_posixopens),
+					atomic_read_unchecked(&tcon->num_posixmkdirs));
 				seq_printf(m, "\nMkdirs: %d Rmdirs: %d",
-					atomic_read(&tcon->num_mkdirs),
-					atomic_read(&tcon->num_rmdirs));
+					atomic_read_unchecked(&tcon->num_mkdirs),
+					atomic_read_unchecked(&tcon->num_rmdirs));
 				seq_printf(m, "\nRenames: %d T2 Renames %d",
-					atomic_read(&tcon->num_renames),
-					atomic_read(&tcon->num_t2renames));
+					atomic_read_unchecked(&tcon->num_renames),
+					atomic_read_unchecked(&tcon->num_t2renames));
 				seq_printf(m, "\nFindFirst: %d FNext %d "
 					      "FClose %d",
-					atomic_read(&tcon->num_ffirst),
-					atomic_read(&tcon->num_fnext),
-					atomic_read(&tcon->num_fclose));
+					atomic_read_unchecked(&tcon->num_ffirst),
+					atomic_read_unchecked(&tcon->num_fnext),
+					atomic_read_unchecked(&tcon->num_fclose));
 			}
 		}
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/cifs/cifsfs.c linux-3.2.71-pax/fs/cifs/cifsfs.c
--- linux-3.2.71/fs/cifs/cifsfs.c	2013-03-29 02:18:43.423676031 +0100
+++ linux-3.2.71-pax/fs/cifs/cifsfs.c	2013-03-29 02:22:27.831664050 +0100
@@ -1018,7 +1018,7 @@ cifs_init_request_bufs(void)
 	cifs_req_cachep = kmem_cache_create("cifs_request",
 					    CIFSMaxBufSize +
 					    MAX_CIFS_HDR_SIZE, 0,
-					    SLAB_HWCACHE_ALIGN, NULL);
+					    SLAB_HWCACHE_ALIGN | SLAB_USERCOPY, NULL);
 	if (cifs_req_cachep == NULL)
 		return -ENOMEM;
 
@@ -1045,7 +1045,7 @@ cifs_init_request_bufs(void)
 	efficient to alloc 1 per page off the slab compared to 17K (5page)
 	alloc of large cifs buffers even when page debugging is on */
 	cifs_sm_req_cachep = kmem_cache_create("cifs_small_rq",
-			MAX_CIFS_SMALL_BUFFER_SIZE, 0, SLAB_HWCACHE_ALIGN,
+			MAX_CIFS_SMALL_BUFFER_SIZE, 0, SLAB_HWCACHE_ALIGN | SLAB_USERCOPY,
 			NULL);
 	if (cifs_sm_req_cachep == NULL) {
 		mempool_destroy(cifs_req_poolp);
@@ -1130,8 +1130,8 @@ init_cifs(void)
 	atomic_set(&bufAllocCount, 0);
 	atomic_set(&smBufAllocCount, 0);
 #ifdef CONFIG_CIFS_STATS2
-	atomic_set(&totBufAllocCount, 0);
-	atomic_set(&totSmBufAllocCount, 0);
+	atomic_set_unchecked(&totBufAllocCount, 0);
+	atomic_set_unchecked(&totSmBufAllocCount, 0);
 #endif /* CONFIG_CIFS_STATS2 */
 
 	atomic_set(&midCount, 0);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/cifs/cifsglob.h linux-3.2.71-pax/fs/cifs/cifsglob.h
--- linux-3.2.71/fs/cifs/cifsglob.h	2013-09-10 17:24:55.537739116 +0200
+++ linux-3.2.71-pax/fs/cifs/cifsglob.h	2013-09-10 17:24:59.077738927 +0200
@@ -390,28 +390,28 @@ struct cifs_tcon {
 	__u16 Flags;		/* optional support bits */
 	enum statusEnum tidStatus;
 #ifdef CONFIG_CIFS_STATS
-	atomic_t num_smbs_sent;
-	atomic_t num_writes;
-	atomic_t num_reads;
-	atomic_t num_flushes;
-	atomic_t num_oplock_brks;
-	atomic_t num_opens;
-	atomic_t num_closes;
-	atomic_t num_deletes;
-	atomic_t num_mkdirs;
-	atomic_t num_posixopens;
-	atomic_t num_posixmkdirs;
-	atomic_t num_rmdirs;
-	atomic_t num_renames;
-	atomic_t num_t2renames;
-	atomic_t num_ffirst;
-	atomic_t num_fnext;
-	atomic_t num_fclose;
-	atomic_t num_hardlinks;
-	atomic_t num_symlinks;
-	atomic_t num_locks;
-	atomic_t num_acl_get;
-	atomic_t num_acl_set;
+	atomic_unchecked_t num_smbs_sent;
+	atomic_unchecked_t num_writes;
+	atomic_unchecked_t num_reads;
+	atomic_unchecked_t num_flushes;
+	atomic_unchecked_t num_oplock_brks;
+	atomic_unchecked_t num_opens;
+	atomic_unchecked_t num_closes;
+	atomic_unchecked_t num_deletes;
+	atomic_unchecked_t num_mkdirs;
+	atomic_unchecked_t num_posixopens;
+	atomic_unchecked_t num_posixmkdirs;
+	atomic_unchecked_t num_rmdirs;
+	atomic_unchecked_t num_renames;
+	atomic_unchecked_t num_t2renames;
+	atomic_unchecked_t num_ffirst;
+	atomic_unchecked_t num_fnext;
+	atomic_unchecked_t num_fclose;
+	atomic_unchecked_t num_hardlinks;
+	atomic_unchecked_t num_symlinks;
+	atomic_unchecked_t num_locks;
+	atomic_unchecked_t num_acl_get;
+	atomic_unchecked_t num_acl_set;
 #ifdef CONFIG_CIFS_STATS2
 	unsigned long long time_writes;
 	unsigned long long time_reads;
@@ -626,7 +626,7 @@ convert_delimiter(char *path, char delim
 }
 
 #ifdef CONFIG_CIFS_STATS
-#define cifs_stats_inc atomic_inc
+#define cifs_stats_inc atomic_inc_unchecked
 
 static inline void cifs_stats_bytes_written(struct cifs_tcon *tcon,
 					    unsigned int bytes)
@@ -983,8 +983,8 @@ GLOBAL_EXTERN atomic_t tconInfoReconnect
 /* Various Debug counters */
 GLOBAL_EXTERN atomic_t bufAllocCount;    /* current number allocated  */
 #ifdef CONFIG_CIFS_STATS2
-GLOBAL_EXTERN atomic_t totBufAllocCount; /* total allocated over all time */
-GLOBAL_EXTERN atomic_t totSmBufAllocCount;
+GLOBAL_EXTERN atomic_unchecked_t totBufAllocCount; /* total allocated over all time */
+GLOBAL_EXTERN atomic_unchecked_t totSmBufAllocCount;
 #endif
 GLOBAL_EXTERN atomic_t smBufAllocCount;
 GLOBAL_EXTERN atomic_t midCount;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/cifs/file.c linux-3.2.71-pax/fs/cifs/file.c
--- linux-3.2.71/fs/cifs/file.c	2015-05-10 09:22:38.719493120 +0200
+++ linux-3.2.71-pax/fs/cifs/file.c	2015-05-10 09:23:09.455494789 +0200
@@ -1691,10 +1691,14 @@ static int cifs_writepages(struct addres
 		index = mapping->writeback_index; /* Start from prev offset */
 		end = -1;
 	} else {
-		index = wbc->range_start >> PAGE_CACHE_SHIFT;
-		end = wbc->range_end >> PAGE_CACHE_SHIFT;
-		if (wbc->range_start == 0 && wbc->range_end == LLONG_MAX)
+		if (wbc->range_start == 0 && wbc->range_end == LLONG_MAX) {
 			range_whole = true;
+			index = 0;
+			end = ULONG_MAX;
+		} else {
+			index = wbc->range_start >> PAGE_CACHE_SHIFT;
+			end = wbc->range_end >> PAGE_CACHE_SHIFT;
+		}
 		scanned = true;
 	}
 retry:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/cifs/link.c linux-3.2.71-pax/fs/cifs/link.c
--- linux-3.2.71/fs/cifs/link.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/cifs/link.c	2012-07-04 19:24:48.680063008 +0200
@@ -600,7 +600,7 @@ symlink_exit:
 
 void cifs_put_link(struct dentry *direntry, struct nameidata *nd, void *cookie)
 {
-	char *p = nd_get_link(nd);
+	const char *p = nd_get_link(nd);
 	if (!IS_ERR(p))
 		kfree(p);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/cifs/misc.c linux-3.2.71-pax/fs/cifs/misc.c
--- linux-3.2.71/fs/cifs/misc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/cifs/misc.c	2012-07-04 19:24:48.680063008 +0200
@@ -156,7 +156,7 @@ cifs_buf_get(void)
 		memset(ret_buf, 0, sizeof(struct smb_hdr) + 3);
 		atomic_inc(&bufAllocCount);
 #ifdef CONFIG_CIFS_STATS2
-		atomic_inc(&totBufAllocCount);
+		atomic_inc_unchecked(&totBufAllocCount);
 #endif /* CONFIG_CIFS_STATS2 */
 	}
 
@@ -191,7 +191,7 @@ cifs_small_buf_get(void)
 	/*	memset(ret_buf, 0, sizeof(struct smb_hdr) + 27);*/
 		atomic_inc(&smBufAllocCount);
 #ifdef CONFIG_CIFS_STATS2
-		atomic_inc(&totSmBufAllocCount);
+		atomic_inc_unchecked(&totSmBufAllocCount);
 #endif /* CONFIG_CIFS_STATS2 */
 
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/coda/cache.c linux-3.2.71-pax/fs/coda/cache.c
--- linux-3.2.71/fs/coda/cache.c	2015-01-01 15:15:24.508069625 +0100
+++ linux-3.2.71-pax/fs/coda/cache.c	2015-01-01 15:15:29.628069760 +0100
@@ -24,7 +24,7 @@
 #include "coda_linux.h"
 #include "coda_cache.h"
 
-static atomic_t permission_epoch = ATOMIC_INIT(0);
+static atomic_unchecked_t permission_epoch = ATOMIC_INIT(0);
 
 /* replace or extend an acl cache hit */
 void coda_cache_enter(struct inode *inode, int mask)
@@ -32,7 +32,7 @@ void coda_cache_enter(struct inode *inod
 	struct coda_inode_info *cii = ITOC(inode);
 
 	spin_lock(&cii->c_lock);
-	cii->c_cached_epoch = atomic_read(&permission_epoch);
+	cii->c_cached_epoch = atomic_read_unchecked(&permission_epoch);
 	if (cii->c_uid != current_fsuid()) {
 		cii->c_uid = current_fsuid();
                 cii->c_cached_perm = mask;
@@ -46,14 +46,14 @@ void coda_cache_clear_inode(struct inode
 {
 	struct coda_inode_info *cii = ITOC(inode);
 	spin_lock(&cii->c_lock);
-	cii->c_cached_epoch = atomic_read(&permission_epoch) - 1;
+	cii->c_cached_epoch = atomic_read_unchecked(&permission_epoch) - 1;
 	spin_unlock(&cii->c_lock);
 }
 
 /* remove all acl caches */
 void coda_cache_clear_all(struct super_block *sb)
 {
-	atomic_inc(&permission_epoch);
+	atomic_inc_unchecked(&permission_epoch);
 }
 
 
@@ -66,7 +66,7 @@ int coda_cache_check(struct inode *inode
 	spin_lock(&cii->c_lock);
 	hit = (mask & cii->c_cached_perm) == mask &&
 	    cii->c_uid == current_fsuid() &&
-	    cii->c_cached_epoch == atomic_read(&permission_epoch);
+	    cii->c_cached_epoch == atomic_read_unchecked(&permission_epoch);
 	spin_unlock(&cii->c_lock);
 
 	return hit;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/compat_binfmt_elf.c linux-3.2.71-pax/fs/compat_binfmt_elf.c
--- linux-3.2.71/fs/compat_binfmt_elf.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/compat_binfmt_elf.c	2012-07-04 19:24:48.680063008 +0200
@@ -30,11 +30,13 @@
 #undef	elf_phdr
 #undef	elf_shdr
 #undef	elf_note
+#undef	elf_dyn
 #undef	elf_addr_t
 #define elfhdr		elf32_hdr
 #define elf_phdr	elf32_phdr
 #define elf_shdr	elf32_shdr
 #define elf_note	elf32_note
+#define elf_dyn		Elf32_Dyn
 #define elf_addr_t	Elf32_Addr
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/compat.c linux-3.2.71-pax/fs/compat.c
--- linux-3.2.71/fs/compat.c	2013-03-29 02:18:38.731676282 +0100
+++ linux-3.2.71-pax/fs/compat.c	2013-03-29 02:20:31.359670268 +0100
@@ -132,8 +132,8 @@ asmlinkage long compat_sys_utimes(const
 static int cp_compat_stat(struct kstat *stat, struct compat_stat __user *ubuf)
 {
 	compat_ino_t ino = stat->ino;
-	typeof(ubuf->st_uid) uid = 0;
-	typeof(ubuf->st_gid) gid = 0;
+	typeof(((struct compat_stat *)0)->st_uid) uid = 0;
+	typeof(((struct compat_stat *)0)->st_gid) gid = 0;
 	int err;
 
 	SET_UID(uid, stat->uid);
@@ -504,7 +504,7 @@ compat_sys_io_setup(unsigned nr_reqs, u3
 
 	set_fs(KERNEL_DS);
 	/* The __user pointer cast is valid because of the set_fs() */
-	ret = sys_io_setup(nr_reqs, (aio_context_t __user *) &ctx64);
+	ret = sys_io_setup(nr_reqs, (aio_context_t __force_user *) &ctx64);
 	set_fs(oldfs);
 	/* truncating is ok because it's a user address */
 	if (!ret)
@@ -562,7 +562,7 @@ ssize_t compat_rw_copy_check_uvector(int
 		goto out;
 
 	ret = -EINVAL;
-	if (nr_segs > UIO_MAXIOV || nr_segs < 0)
+	if (nr_segs > UIO_MAXIOV)
 		goto out;
 	if (nr_segs > fast_segs) {
 		ret = -ENOMEM;
@@ -1080,7 +1080,7 @@ asmlinkage long compat_sys_getdents64(un
 		error = buf.error;
 	lastdirent = buf.previous;
 	if (lastdirent) {
-		typeof(lastdirent->d_off) d_off = file->f_pos;
+		typeof(((struct linux_dirent64 *)0)->d_off) d_off = file->f_pos;
 		if (__put_user_unaligned(d_off, &lastdirent->d_off))
 			error = -EFAULT;
 		else
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/compat_ioctl.c linux-3.2.71-pax/fs/compat_ioctl.c
--- linux-3.2.71/fs/compat_ioctl.c	2012-10-31 13:04:04.555702982 +0100
+++ linux-3.2.71-pax/fs/compat_ioctl.c	2014-07-27 23:41:39.577093822 +0200
@@ -623,7 +623,7 @@ static int serial_struct_ioctl(unsigned
 			return -EFAULT;
                 if (__get_user(udata, &ss32->iomem_base))
 			return -EFAULT;
-                ss.iomem_base = compat_ptr(udata);
+                ss.iomem_base = (unsigned char __force_kernel *)compat_ptr(udata);
                 if (__get_user(ss.iomem_reg_shift, &ss32->iomem_reg_shift) ||
 		    __get_user(ss.port_high, &ss32->port_high))
 			return -EFAULT;
@@ -704,8 +704,8 @@ static int do_i2c_rdwr_ioctl(unsigned in
 	for (i = 0; i < nmsgs; i++) {
 		if (copy_in_user(&tmsgs[i].addr, &umsgs[i].addr, 3*sizeof(u16)))
 			return -EFAULT;
-		if (get_user(datap, &umsgs[i].buf) ||
-		    put_user(compat_ptr(datap), &tmsgs[i].buf))
+		if (get_user(datap, (compat_caddr_t __user *)&umsgs[i].buf) ||
+		    put_user(compat_ptr(datap), (u8 __user * __user *)&tmsgs[i].buf))
 			return -EFAULT;
 	}
 	return sys_ioctl(fd, cmd, (unsigned long)tdata);
@@ -798,7 +798,7 @@ static int compat_ioctl_preallocate(stru
 	    copy_in_user(&p->l_len,	&p32->l_len,	sizeof(s64)) ||
 	    copy_in_user(&p->l_sysid,	&p32->l_sysid,	sizeof(s32)) ||
 	    copy_in_user(&p->l_pid,	&p32->l_pid,	sizeof(u32)) ||
-	    copy_in_user(&p->l_pad,	&p32->l_pad,	4*sizeof(u32)))
+	    copy_in_user(p->l_pad,	p32->l_pad,	4*sizeof(u32)))
 		return -EFAULT;
 
 	return ioctl_preallocate(file, p);
@@ -1646,8 +1646,8 @@ asmlinkage long compat_sys_ioctl(unsigne
 static int __init init_sys32_ioctl_cmp(const void *p, const void *q)
 {
 	unsigned int a, b;
-	a = *(unsigned int *)p;
-	b = *(unsigned int *)q;
+	a = *(const unsigned int *)p;
+	b = *(const unsigned int *)q;
 	if (a > b)
 		return 1;
 	if (a < b)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/configfs/dir.c linux-3.2.71-pax/fs/configfs/dir.c
--- linux-3.2.71/fs/configfs/dir.c	2014-01-03 15:48:45.016070563 +0100
+++ linux-3.2.71-pax/fs/configfs/dir.c	2014-01-03 15:48:49.584070319 +0100
@@ -1587,7 +1587,8 @@ static int configfs_readdir(struct file
 			}
 			for (p=q->next; p!= &parent_sd->s_children; p=p->next) {
 				struct configfs_dirent *next;
-				const char * name;
+				const unsigned char * name;
+				char d_name[sizeof(next->s_dentry->d_iname)];
 				int len;
 				struct inode *inode = NULL;
 
@@ -1597,7 +1598,12 @@ static int configfs_readdir(struct file
 					continue;
 
 				name = configfs_get_name(next);
-				len = strlen(name);
+				if (next->s_dentry && name == next->s_dentry->d_iname) {
+					len =  next->s_dentry->d_name.len;
+					memcpy(d_name, name, len);
+					name = d_name;
+				} else
+					len = strlen(name);
 
 				/*
 				 * We'll have a dentry and an inode for
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/dcache.c linux-3.2.71-pax/fs/dcache.c
--- linux-3.2.71/fs/dcache.c	2015-08-07 11:37:20.639789896 +0200
+++ linux-3.2.71-pax/fs/dcache.c	2015-08-07 11:37:43.019790554 +0200
@@ -3082,7 +3082,8 @@ void __init vfs_caches_init(unsigned lon
 	mempages -= reserve;
 
 	names_cachep = kmem_cache_create("names_cache", PATH_MAX, 0,
-			SLAB_HWCACHE_ALIGN|SLAB_PANIC, NULL);
+			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_USERCOPY|
+			SLAB_NO_SANITIZE, NULL);
 
 	dcache_init();
 	inode_init();
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ecryptfs/inode.c linux-3.2.71-pax/fs/ecryptfs/inode.c
--- linux-3.2.71/fs/ecryptfs/inode.c	2014-12-14 21:13:45.238055147 +0100
+++ linux-3.2.71-pax/fs/ecryptfs/inode.c	2014-12-14 21:13:52.818069307 +0100
@@ -705,7 +705,7 @@ static int ecryptfs_readlink_lower(struc
 	old_fs = get_fs();
 	set_fs(get_ds());
 	rc = lower_dentry->d_inode->i_op->readlink(lower_dentry,
-						   (char __user *)lower_buf,
+						   (char __force_user *)lower_buf,
 						   lower_bufsiz);
 	set_fs(old_fs);
 	if (rc < 0)
@@ -751,7 +751,7 @@ static void *ecryptfs_follow_link(struct
 	}
 	old_fs = get_fs();
 	set_fs(get_ds());
-	rc = dentry->d_inode->i_op->readlink(dentry, (char __user *)buf, len);
+	rc = dentry->d_inode->i_op->readlink(dentry, (char __force_user *)buf, len);
 	set_fs(old_fs);
 	if (rc < 0) {
 		kfree(buf);
@@ -766,7 +766,7 @@ out:
 static void
 ecryptfs_put_link(struct dentry *dentry, struct nameidata *nd, void *ptr)
 {
-	char *buf = nd_get_link(nd);
+	const char *buf = nd_get_link(nd);
 	if (!IS_ERR(buf)) {
 		/* Free the char* */
 		kfree(buf);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ecryptfs/miscdev.c linux-3.2.71-pax/fs/ecryptfs/miscdev.c
--- linux-3.2.71/fs/ecryptfs/miscdev.c	2012-07-27 22:08:37.542372795 +0200
+++ linux-3.2.71-pax/fs/ecryptfs/miscdev.c	2012-07-27 22:08:48.938373130 +0200
@@ -338,7 +338,7 @@ check_list:
 		goto out_unlock_msg_ctx;
 	i = 5;
 	if (msg_ctx->msg) {
-		if (copy_to_user(&buf[i], packet_length, packet_length_size))
+		if (packet_length_size > sizeof(packet_length) || copy_to_user(&buf[i], packet_length, packet_length_size))
 			goto out_unlock_msg_ctx;
 		i += packet_length_size;
 		if (copy_to_user(&buf[i], msg_ctx->msg, msg_ctx->msg_size))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ecryptfs/read_write.c linux-3.2.71-pax/fs/ecryptfs/read_write.c
--- linux-3.2.71/fs/ecryptfs/read_write.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/ecryptfs/read_write.c	2012-07-04 19:24:48.688063007 +0200
@@ -48,7 +48,7 @@ int ecryptfs_write_lower(struct inode *e
 		return -EIO;
 	fs_save = get_fs();
 	set_fs(get_ds());
-	rc = vfs_write(lower_file, data, size, &offset);
+	rc = vfs_write(lower_file, (const char __force_user *)data, size, &offset);
 	set_fs(fs_save);
 	mark_inode_dirty_sync(ecryptfs_inode);
 	return rc;
@@ -244,7 +244,7 @@ int ecryptfs_read_lower(char *data, loff
 		return -EIO;
 	fs_save = get_fs();
 	set_fs(get_ds());
-	rc = vfs_read(lower_file, data, size, &offset);
+	rc = vfs_read(lower_file, (char __force_user *)data, size, &offset);
 	set_fs(fs_save);
 	return rc;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/exec.c linux-3.2.71-pax/fs/exec.c
--- linux-3.2.71/fs/exec.c	2015-05-10 09:22:38.739493121 +0200
+++ linux-3.2.71-pax/fs/exec.c	2015-06-26 17:58:48.558478480 +0200
@@ -55,12 +55,32 @@
 #include <linux/pipe_fs_i.h>
 #include <linux/oom.h>
 #include <linux/compat.h>
+#include <linux/random.h>
+#include <linux/seq_file.h>
+#include <linux/mman.h>
+
+#ifdef CONFIG_PAX_REFCOUNT
+#include <linux/kallsyms.h>
+#include <linux/kdebug.h>
+#endif
 
 #include <asm/uaccess.h>
 #include <asm/mmu_context.h>
 #include <asm/tlb.h>
 #include "internal.h"
 
+#ifdef CONFIG_PAX_HAVE_ACL_FLAGS
+void __weak pax_set_initial_flags(struct linux_binprm *bprm)
+{
+	pr_warn_once("PAX: PAX_HAVE_ACL_FLAGS was enabled without providing the pax_set_initial_flags callback, this is probably not what you wanted.\n");
+}
+#endif
+
+#ifdef CONFIG_PAX_HOOK_ACL_FLAGS
+void (*pax_set_initial_flags_func)(struct linux_binprm *bprm);
+EXPORT_SYMBOL(pax_set_initial_flags_func);
+#endif
+
 int core_uses_pid;
 char core_pattern[CORENAME_MAX_SIZE] = "core";
 unsigned int core_pipe_limit;
@@ -70,7 +90,7 @@ struct core_name {
 	char *corename;
 	int used, size;
 };
-static atomic_t call_count = ATOMIC_INIT(1);
+static atomic_unchecked_t call_count = ATOMIC_INIT(1);
 
 /* The maximal length of core_pattern is also specified in sysctl.c */
 
@@ -82,8 +102,8 @@ int __register_binfmt(struct linux_binfm
 	if (!fmt)
 		return -EINVAL;
 	write_lock(&binfmt_lock);
-	insert ? list_add(&fmt->lh, &formats) :
-		 list_add_tail(&fmt->lh, &formats);
+	insert ? pax_list_add((struct list_head *)&fmt->lh, &formats) :
+		 pax_list_add_tail((struct list_head *)&fmt->lh, &formats);
 	write_unlock(&binfmt_lock);
 	return 0;	
 }
@@ -93,7 +113,7 @@ EXPORT_SYMBOL(__register_binfmt);
 void unregister_binfmt(struct linux_binfmt * fmt)
 {
 	write_lock(&binfmt_lock);
-	list_del(&fmt->lh);
+	pax_list_del((struct list_head *)&fmt->lh);
 	write_unlock(&binfmt_lock);
 }
 
@@ -188,18 +208,10 @@ static struct page *get_arg_page(struct
 		int write)
 {
 	struct page *page;
-	int ret;
 
-#ifdef CONFIG_STACK_GROWSUP
-	if (write) {
-		ret = expand_downwards(bprm->vma, pos);
-		if (ret < 0)
-			return NULL;
-	}
-#endif
-	ret = get_user_pages(current, bprm->mm, pos,
-			1, write, 1, &page, NULL);
-	if (ret <= 0)
+	if (0 > expand_downwards(bprm->vma, pos))
+		return NULL;
+	if (0 >= get_user_pages(current, bprm->mm, pos, 1, write, 1, &page, NULL))
 		return NULL;
 
 	if (write) {
@@ -274,6 +286,11 @@ static int __bprm_mm_init(struct linux_b
 	vma->vm_end = STACK_TOP_MAX;
 	vma->vm_start = vma->vm_end - PAGE_SIZE;
 	vma->vm_flags = VM_STACK_FLAGS | VM_STACK_INCOMPLETE_SETUP;
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	vma->vm_flags &= ~(VM_EXEC | VM_MAYEXEC);
+#endif
+
 	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
 	INIT_LIST_HEAD(&vma->anon_vma_chain);
 
@@ -288,6 +305,12 @@ static int __bprm_mm_init(struct linux_b
 	mm->stack_vm = mm->total_vm = 1;
 	up_write(&mm->mmap_sem);
 	bprm->p = vma->vm_end - sizeof(void *);
+
+#ifdef CONFIG_PAX_RANDUSTACK
+	if (randomize_va_space)
+		bprm->p ^= (pax_get_random_long() & ~15) & ~PAGE_MASK;
+#endif
+
 	return 0;
 err:
 	up_write(&mm->mmap_sem);
@@ -417,14 +440,14 @@ static const char __user *get_user_arg_p
 		compat_uptr_t compat;
 
 		if (get_user(compat, argv.ptr.compat + nr))
-			return ERR_PTR(-EFAULT);
+			return (const char __force_user *)ERR_PTR(-EFAULT);
 
 		return compat_ptr(compat);
 	}
 #endif
 
 	if (get_user(native, argv.ptr.native + nr))
-		return ERR_PTR(-EFAULT);
+		return (const char __force_user *)ERR_PTR(-EFAULT);
 
 	return native;
 }
@@ -443,7 +466,7 @@ static int count(struct user_arg_ptr arg
 			if (!p)
 				break;
 
-			if (IS_ERR(p))
+			if (IS_ERR((const char __force_kernel *)p))
 				return -EFAULT;
 
 			if (i++ >= max)
@@ -477,7 +500,7 @@ static int copy_strings(int argc, struct
 
 		ret = -EFAULT;
 		str = get_user_arg_ptr(argv, argc);
-		if (IS_ERR(str))
+		if (IS_ERR((const char __force_kernel *)str))
 			goto out;
 
 		len = strnlen_user(str, MAX_ARG_STRLEN);
@@ -559,7 +582,7 @@ int copy_strings_kernel(int argc, const
 	int r;
 	mm_segment_t oldfs = get_fs();
 	struct user_arg_ptr argv = {
-		.ptr.native = (const char __user *const  __user *)__argv,
+		.ptr.native = (const char __user * const __force_user *)__argv,
 	};
 
 	set_fs(KERNEL_DS);
@@ -594,7 +617,8 @@ static int shift_arg_pages(struct vm_are
 	unsigned long new_end = old_end - shift;
 	struct mmu_gather tlb;
 
-	BUG_ON(new_start > new_end);
+	if (new_start >= new_end || new_start < mmap_min_addr)
+		return -ENOMEM;
 
 	/*
 	 * ensure there are no vmas between where we want to go
@@ -603,6 +627,10 @@ static int shift_arg_pages(struct vm_are
 	if (vma != find_vma(mm, new_start))
 		return -EFAULT;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	BUG_ON(pax_find_mirror_vma(vma));
+#endif
+
 	/*
 	 * cover the whole range: [new_start, old_end)
 	 */
@@ -683,10 +711,6 @@ int setup_arg_pages(struct linux_binprm
 	stack_top = arch_align_stack(stack_top);
 	stack_top = PAGE_ALIGN(stack_top);
 
-	if (unlikely(stack_top < mmap_min_addr) ||
-	    unlikely(vma->vm_end - vma->vm_start >= stack_top - mmap_min_addr))
-		return -ENOMEM;
-
 	stack_shift = vma->vm_end - stack_top;
 
 	bprm->p -= stack_shift;
@@ -698,8 +722,28 @@ int setup_arg_pages(struct linux_binprm
 	bprm->exec -= stack_shift;
 
 	down_write(&mm->mmap_sem);
+
+	/* Move stack pages down in memory. */
+	if (stack_shift) {
+		ret = shift_arg_pages(vma, stack_shift);
+		if (ret)
+			goto out_unlock;
+	}
+
 	vm_flags = VM_STACK_FLAGS;
 
+#if defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC)
+	if (mm->pax_flags & (MF_PAX_PAGEEXEC | MF_PAX_SEGMEXEC)) {
+		vm_flags &= ~VM_EXEC;
+
+#ifdef CONFIG_PAX_MPROTECT
+		if (mm->pax_flags & MF_PAX_MPROTECT)
+			vm_flags &= ~VM_MAYEXEC;
+#endif
+
+	}
+#endif
+
 	/*
 	 * Adjust stack execute permissions; explicitly enable for
 	 * EXSTACK_ENABLE_X, disable for EXSTACK_DISABLE_X and leave alone
@@ -718,13 +762,6 @@ int setup_arg_pages(struct linux_binprm
 		goto out_unlock;
 	BUG_ON(prev != vma);
 
-	/* Move stack pages down in memory. */
-	if (stack_shift) {
-		ret = shift_arg_pages(vma, stack_shift);
-		if (ret)
-			goto out_unlock;
-	}
-
 	/* mprotect_fixup is overkill to remove the temporary stack flags */
 	vma->vm_flags &= ~VM_STACK_INCOMPLETE_SETUP;
 
@@ -748,6 +785,27 @@ int setup_arg_pages(struct linux_binprm
 #endif
 	current->mm->start_stack = bprm->p;
 	ret = expand_stack(vma, stack_base);
+
+#if !defined(CONFIG_STACK_GROWSUP) && defined(CONFIG_PAX_RANDMMAP)
+	if (!ret && (mm->pax_flags & MF_PAX_RANDMMAP) && STACK_TOP <= 0xFFFFFFFFU && STACK_TOP > vma->vm_end) {
+		unsigned long size, flags, vm_flags;
+
+		size = STACK_TOP - vma->vm_end;
+		flags = MAP_FIXED | MAP_PRIVATE;
+		vm_flags = VM_DONTEXPAND | VM_RESERVED;
+
+		ret = vma->vm_end != mmap_region(NULL, vma->vm_end, size, flags, vm_flags, 0);
+
+#ifdef CONFIG_X86
+		if (!ret) {
+			size = PAGE_SIZE + mmap_min_addr + ((mm->delta_mmap ^ mm->delta_stack) & (0xFFUL << PAGE_SHIFT));
+			ret = 0 != mmap_region(NULL, 0, PAGE_ALIGN(size), flags, vm_flags, 0);
+		}
+#endif
+
+	}
+#endif
+
 	if (ret)
 		ret = -EFAULT;
 
@@ -805,7 +863,7 @@ int kernel_read(struct file *file, loff_
 	old_fs = get_fs();
 	set_fs(get_ds());
 	/* The cast to a user pointer is valid due to the set_fs() */
-	result = vfs_read(file, (void __user *)addr, count, &pos);
+	result = vfs_read(file, (void __force_user *)addr, count, &pos);
 	set_fs(old_fs);
 	return result;
 }
@@ -1268,7 +1326,7 @@ int check_unsafe_exec(struct linux_binpr
 	}
 	rcu_read_unlock();
 
-	if (p->fs->users > n_fs) {
+	if (atomic_read(&p->fs->users) > n_fs) {
 		bprm->unsafe |= LSM_UNSAFE_SHARE;
 	} else {
 		res = -EAGAIN;
@@ -1654,7 +1712,7 @@ static int expand_corename(struct core_n
 {
 	char *old_corename = cn->corename;
 
-	cn->size = CORENAME_MAX_SIZE * atomic_inc_return(&call_count);
+	cn->size = CORENAME_MAX_SIZE * atomic_inc_return_unchecked(&call_count);
 	cn->corename = krealloc(old_corename, cn->size, GFP_KERNEL);
 
 	if (!cn->corename) {
@@ -1751,7 +1809,7 @@ static int format_corename(struct core_n
 	int pid_in_pattern = 0;
 	int err = 0;
 
-	cn->size = CORENAME_MAX_SIZE * atomic_read(&call_count);
+	cn->size = CORENAME_MAX_SIZE * atomic_read_unchecked(&call_count);
 	cn->corename = kmalloc(cn->size, GFP_KERNEL);
 	cn->used = 0;
 
@@ -1848,6 +1906,238 @@ out:
 	return ispipe;
 }
 
+int pax_check_flags(unsigned long *flags)
+{
+	int retval = 0;
+
+#if !defined(CONFIG_X86_32) || !defined(CONFIG_PAX_SEGMEXEC)
+	if (*flags & MF_PAX_SEGMEXEC)
+	{
+		*flags &= ~MF_PAX_SEGMEXEC;
+		retval = -EINVAL;
+	}
+#endif
+
+	if ((*flags & MF_PAX_PAGEEXEC)
+
+#ifdef CONFIG_PAX_PAGEEXEC
+	    &&  (*flags & MF_PAX_SEGMEXEC)
+#endif
+
+	   )
+	{
+		*flags &= ~MF_PAX_PAGEEXEC;
+		retval = -EINVAL;
+	}
+
+	if ((*flags & MF_PAX_MPROTECT)
+
+#ifdef CONFIG_PAX_MPROTECT
+	    && !(*flags & (MF_PAX_PAGEEXEC | MF_PAX_SEGMEXEC))
+#endif
+
+	   )
+	{
+		*flags &= ~MF_PAX_MPROTECT;
+		retval = -EINVAL;
+	}
+
+	if ((*flags & MF_PAX_EMUTRAMP)
+
+#ifdef CONFIG_PAX_EMUTRAMP
+	    && !(*flags & (MF_PAX_PAGEEXEC | MF_PAX_SEGMEXEC))
+#endif
+
+	   )
+	{
+		*flags &= ~MF_PAX_EMUTRAMP;
+		retval = -EINVAL;
+	}
+
+	return retval;
+}
+
+EXPORT_SYMBOL(pax_check_flags);
+
+#if defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC)
+char *pax_get_path(const struct path *path, char *buf, int buflen)
+{
+	char *pathname = d_path(path, buf, buflen);
+
+	if (IS_ERR(pathname))
+		goto toolong;
+
+	pathname = mangle_path(buf, pathname, "\t\n\\");
+	if (!pathname)
+		goto toolong;
+
+	*pathname = 0;
+	return buf;
+
+toolong:
+	return "<path too long>";
+}
+EXPORT_SYMBOL(pax_get_path);
+
+void pax_report_fault(struct pt_regs *regs, void *pc, void *sp)
+{
+	struct task_struct *tsk = current;
+	struct mm_struct *mm = current->mm;
+	char *buffer_exec = (char *)__get_free_page(GFP_KERNEL);
+	char *buffer_fault = (char *)__get_free_page(GFP_KERNEL);
+	char *path_exec = NULL;
+	char *path_fault = NULL;
+	unsigned long start = 0UL, end = 0UL, offset = 0UL;
+
+	if (buffer_exec && buffer_fault) {
+		struct vm_area_struct *vma, *vma_exec = NULL, *vma_fault = NULL;
+
+		down_read(&mm->mmap_sem);
+		vma = mm->mmap;
+		while (vma && (!vma_exec || !vma_fault)) {
+			if ((vma->vm_flags & VM_EXECUTABLE) && vma->vm_file)
+				vma_exec = vma;
+			if (vma->vm_start <= (unsigned long)pc && (unsigned long)pc < vma->vm_end)
+				vma_fault = vma;
+			vma = vma->vm_next;
+		}
+		if (vma_exec)
+			path_exec = pax_get_path(&vma_exec->vm_file->f_path, buffer_exec, PAGE_SIZE);
+		if (vma_fault) {
+			start = vma_fault->vm_start;
+			end = vma_fault->vm_end;
+			offset = vma_fault->vm_pgoff << PAGE_SHIFT;
+			if (vma_fault->vm_file)
+				path_fault = pax_get_path(&vma_fault->vm_file->f_path, buffer_fault, PAGE_SIZE);
+			else
+				path_fault = "<anonymous mapping>";
+		}
+		up_read(&mm->mmap_sem);
+	}
+	printk(KERN_ERR "PAX: execution attempt in: %s, %08lx-%08lx %08lx\n", path_fault, start, end, offset);
+	printk(KERN_ERR "PAX: terminating task: %s(%s):%d, uid/euid: %u/%u, "
+			"PC: %p, SP: %p\n", path_exec, tsk->comm, task_pid_nr(tsk),
+			task_uid(tsk), task_euid(tsk), pc, sp);
+	free_page((unsigned long)buffer_exec);
+	free_page((unsigned long)buffer_fault);
+	pax_report_insns(regs, pc, sp);
+	do_coredump(SIGKILL, SIGKILL, regs);
+}
+#endif
+
+#ifdef CONFIG_PAX_REFCOUNT
+void pax_report_refcount_overflow(struct pt_regs *regs)
+{
+	printk(KERN_EMERG "PAX: refcount overflow detected in: %s:%d, uid/euid: %u/%u\n",
+			 current->comm, task_pid_nr(current), current_uid(), current_euid());
+	print_symbol(KERN_EMERG "PAX: refcount overflow occured at: %s\n", instruction_pointer(regs));
+	preempt_disable();
+	show_regs(regs);
+	preempt_enable();
+	force_sig_info(SIGKILL, SEND_SIG_FORCED, current);
+}
+#endif
+
+#ifdef CONFIG_PAX_USERCOPY
+/* 0: not at all, 1: fully, 2: fully inside frame, -1: partially (implies an error) */
+static noinline int check_stack_object(const void *obj, unsigned long len)
+{
+	const void * const stack = task_stack_page(current);
+	const void * const stackend = stack + THREAD_SIZE;
+
+#if defined(CONFIG_FRAME_POINTER) && defined(CONFIG_X86)
+	const void *frame = NULL;
+	const void *oldframe;
+#endif
+
+	if (obj + len < obj)
+		return -1;
+
+	if (obj + len <= stack || stackend <= obj)
+		return 0;
+
+	if (obj < stack || stackend < obj + len)
+		return -1;
+
+#if defined(CONFIG_FRAME_POINTER) && defined(CONFIG_X86)
+	oldframe = __builtin_frame_address(1);
+	if (oldframe)
+		frame = __builtin_frame_address(2);
+	/*
+	  low ----------------------------------------------> high
+	  [saved bp][saved ip][args][local vars][saved bp][saved ip]
+			      ^----------------^
+			  allow copies only within here
+	*/
+	while (stack <= frame && frame < stackend) {
+		/* if obj + len extends past the last frame, this
+		   check won't pass and the next frame will be 0,
+		   causing us to bail out and correctly report
+		   the copy as invalid
+		*/
+		if (obj + len <= frame)
+			return obj >= oldframe + 2 * sizeof(void *) ? 2 : -1;
+		oldframe = frame;
+		frame = *(const void * const *)frame;
+	}
+	return -1;
+#else
+	return 1;
+#endif
+}
+
+static __noreturn void pax_report_usercopy(const void *ptr, unsigned long len, bool to, const char *type)
+{
+	printk(KERN_EMERG "PAX: kernel memory %s attempt detected %s %p (%s) (%lu bytes)\n",
+		to ? "leak" : "overwrite", to ? "from" : "to", ptr, type ? : "unknown", len);
+	dump_stack();
+	do_group_exit(SIGKILL);
+}
+#endif
+
+void __check_object_size(const void *ptr, unsigned long n, bool to)
+{
+
+#ifdef CONFIG_PAX_USERCOPY
+	const char *type;
+
+	if (!n)
+		return;
+
+	type = check_heap_object(ptr, n);
+	if (!type) {
+		if (check_stack_object(ptr, n) != -1)
+			return;
+		type = "<process stack>";
+	}
+
+	pax_report_usercopy(ptr, n, to, type);
+#endif
+
+}
+EXPORT_SYMBOL(__check_object_size);
+
+#ifdef CONFIG_PAX_MEMORY_STACKLEAK
+void pax_track_stack(void)
+{
+	unsigned long sp = (unsigned long)&sp;
+	if (sp < current_thread_info()->lowest_stack &&
+	    sp >= (unsigned long)task_stack_page(current) + 2 * sizeof(unsigned long))
+		current_thread_info()->lowest_stack = sp;
+}
+EXPORT_SYMBOL(pax_track_stack);
+#endif
+
+#ifdef CONFIG_PAX_SIZE_OVERFLOW
+void report_size_overflow(const char *file, unsigned int line, const char *func, const char *ssa_name)
+{
+	printk(KERN_EMERG "PAX: size overflow detected in function %s %s:%u %s", func, file, line, ssa_name);
+	dump_stack();
+	do_group_exit(SIGKILL);
+}
+EXPORT_SYMBOL(report_size_overflow);
+#endif
+
 static int zap_process(struct task_struct *start, int exit_code)
 {
 	struct task_struct *t;
@@ -2065,17 +2355,17 @@ static void wait_for_dump_helpers(struct
 	pipe = file->f_path.dentry->d_inode->i_pipe;
 
 	pipe_lock(pipe);
-	pipe->readers++;
-	pipe->writers--;
+	atomic_inc(&pipe->readers);
+	atomic_dec(&pipe->writers);
 
-	while ((pipe->readers > 1) && (!signal_pending(current))) {
+	while ((atomic_read(&pipe->readers) > 1) && (!signal_pending(current))) {
 		wake_up_interruptible_sync(&pipe->wait);
 		kill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);
 		pipe_wait(pipe);
 	}
 
-	pipe->readers--;
-	pipe->writers++;
+	atomic_dec(&pipe->readers);
+	atomic_inc(&pipe->writers);
 	pipe_unlock(pipe);
 
 }
@@ -2136,7 +2426,7 @@ void do_coredump(long signr, int exit_co
 	int retval = 0;
 	int flag = 0;
 	int ispipe;
-	static atomic_t core_dump_count = ATOMIC_INIT(0);
+	static atomic_unchecked_t core_dump_count = ATOMIC_INIT(0);
 	struct coredump_params cprm = {
 		.signr = signr,
 		.regs = regs,
@@ -2218,7 +2508,7 @@ void do_coredump(long signr, int exit_co
 		}
 		cprm.limit = RLIM_INFINITY;
 
-		dump_count = atomic_inc_return(&core_dump_count);
+		dump_count = atomic_inc_return_unchecked(&core_dump_count);
 		if (core_pipe_limit && (core_pipe_limit < dump_count)) {
 			printk(KERN_WARNING "Pid %d(%s) over core_pipe_limit\n",
 			       task_tgid_vnr(current), current->comm);
@@ -2288,7 +2578,7 @@ close_fail:
 		filp_close(cprm.file, NULL);
 fail_dropcount:
 	if (ispipe)
-		atomic_dec(&core_dump_count);
+		atomic_dec_unchecked(&core_dump_count);
 fail_unlock:
 	kfree(cn.corename);
 fail_corename:
@@ -2307,7 +2597,7 @@ fail:
  */
 int dump_write(struct file *file, const void *addr, int nr)
 {
-	return access_ok(VERIFY_READ, addr, nr) && file->f_op->write(file, addr, nr, &file->f_pos) == nr;
+	return access_ok(VERIFY_READ, addr, nr) && file->f_op->write(file, (const char __force_user *)addr, nr, &file->f_pos) == nr;
 }
 EXPORT_SYMBOL(dump_write);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ext2/xattr.c linux-3.2.71-pax/fs/ext2/xattr.c
--- linux-3.2.71/fs/ext2/xattr.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/ext2/xattr.c	2013-11-23 18:07:03.593937072 +0100
@@ -248,7 +248,7 @@ ext2_xattr_list(struct dentry *dentry, c
 	struct buffer_head *bh = NULL;
 	struct ext2_xattr_entry *entry;
 	char *end;
-	size_t rest = buffer_size;
+	size_t rest = buffer_size, total_size = 0;
 	int error;
 
 	ea_idebug(inode, "buffer=%p, buffer_size=%ld",
@@ -306,9 +306,10 @@ bad_block:	ext2_error(inode->i_sb, "ext2
 				buffer += size;
 			}
 			rest -= size;
+			total_size += size;
 		}
 	}
-	error = buffer_size - rest;  /* total size */
+	error = total_size;
 
 cleanup:
 	brelse(bh);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ext3/xattr.c linux-3.2.71-pax/fs/ext3/xattr.c
--- linux-3.2.71/fs/ext3/xattr.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/ext3/xattr.c	2013-11-23 18:07:03.597937072 +0100
@@ -335,7 +335,7 @@ static int
 ext3_xattr_list_entries(struct dentry *dentry, struct ext3_xattr_entry *entry,
 			char *buffer, size_t buffer_size)
 {
-	size_t rest = buffer_size;
+	size_t rest = buffer_size, total_size = 0;
 
 	for (; !IS_LAST_ENTRY(entry); entry = EXT3_XATTR_NEXT(entry)) {
 		const struct xattr_handler *handler =
@@ -352,9 +352,10 @@ ext3_xattr_list_entries(struct dentry *d
 				buffer += size;
 			}
 			rest -= size;
+			total_size += size;
 		}
 	}
-	return buffer_size - rest;
+	return total_size;
 }
 
 static int
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ext4/ext4.h linux-3.2.71-pax/fs/ext4/ext4.h
--- linux-3.2.71/fs/ext4/ext4.h	2014-12-14 21:13:45.242055154 +0100
+++ linux-3.2.71-pax/fs/ext4/ext4.h	2014-12-14 21:13:52.818069307 +0100
@@ -1218,19 +1218,19 @@ struct ext4_sb_info {
 	unsigned long s_mb_last_start;
 
 	/* stats for buddy allocator */
-	atomic_t s_bal_reqs;	/* number of reqs with len > 1 */
-	atomic_t s_bal_success;	/* we found long enough chunks */
-	atomic_t s_bal_allocated;	/* in blocks */
-	atomic_t s_bal_ex_scanned;	/* total extents scanned */
-	atomic_t s_bal_goals;	/* goal hits */
-	atomic_t s_bal_breaks;	/* too long searches */
-	atomic_t s_bal_2orders;	/* 2^order hits */
+	atomic_unchecked_t s_bal_reqs;	/* number of reqs with len > 1 */
+	atomic_unchecked_t s_bal_success;	/* we found long enough chunks */
+	atomic_unchecked_t s_bal_allocated;	/* in blocks */
+	atomic_unchecked_t s_bal_ex_scanned;	/* total extents scanned */
+	atomic_unchecked_t s_bal_goals;	/* goal hits */
+	atomic_unchecked_t s_bal_breaks;	/* too long searches */
+	atomic_unchecked_t s_bal_2orders;	/* 2^order hits */
 	spinlock_t s_bal_lock;
 	unsigned long s_mb_buddies_generated;
 	unsigned long long s_mb_generation_time;
-	atomic_t s_mb_lost_chunks;
-	atomic_t s_mb_preallocated;
-	atomic_t s_mb_discarded;
+	atomic_unchecked_t s_mb_lost_chunks;
+	atomic_unchecked_t s_mb_preallocated;
+	atomic_unchecked_t s_mb_discarded;
 	atomic_t s_lock_busy;
 
 	/* locality groups */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ext4/mballoc.c linux-3.2.71-pax/fs/ext4/mballoc.c
--- linux-3.2.71/fs/ext4/mballoc.c	2015-08-14 21:48:35.324707912 +0200
+++ linux-3.2.71-pax/fs/ext4/mballoc.c	2015-08-14 21:48:45.672707359 +0200
@@ -1796,7 +1796,7 @@ void ext4_mb_simple_scan_group(struct ex
 		BUG_ON(ac->ac_b_ex.fe_len != ac->ac_g_ex.fe_len);
 
 		if (EXT4_SB(sb)->s_mb_stats)
-			atomic_inc(&EXT4_SB(sb)->s_bal_2orders);
+			atomic_inc_unchecked(&EXT4_SB(sb)->s_bal_2orders);
 
 		break;
 	}
@@ -2094,7 +2094,7 @@ repeat:
 			ac->ac_status = AC_STATUS_CONTINUE;
 			ac->ac_flags |= EXT4_MB_HINT_FIRST;
 			cr = 3;
-			atomic_inc(&sbi->s_mb_lost_chunks);
+			atomic_inc_unchecked(&sbi->s_mb_lost_chunks);
 			goto repeat;
 		}
 	}
@@ -2601,25 +2601,25 @@ int ext4_mb_release(struct super_block *
 	if (sbi->s_mb_stats) {
 		ext4_msg(sb, KERN_INFO,
 		       "mballoc: %u blocks %u reqs (%u success)",
-				atomic_read(&sbi->s_bal_allocated),
-				atomic_read(&sbi->s_bal_reqs),
-				atomic_read(&sbi->s_bal_success));
+				atomic_read_unchecked(&sbi->s_bal_allocated),
+				atomic_read_unchecked(&sbi->s_bal_reqs),
+				atomic_read_unchecked(&sbi->s_bal_success));
 		ext4_msg(sb, KERN_INFO,
 		      "mballoc: %u extents scanned, %u goal hits, "
 				"%u 2^N hits, %u breaks, %u lost",
-				atomic_read(&sbi->s_bal_ex_scanned),
-				atomic_read(&sbi->s_bal_goals),
-				atomic_read(&sbi->s_bal_2orders),
-				atomic_read(&sbi->s_bal_breaks),
-				atomic_read(&sbi->s_mb_lost_chunks));
+				atomic_read_unchecked(&sbi->s_bal_ex_scanned),
+				atomic_read_unchecked(&sbi->s_bal_goals),
+				atomic_read_unchecked(&sbi->s_bal_2orders),
+				atomic_read_unchecked(&sbi->s_bal_breaks),
+				atomic_read_unchecked(&sbi->s_mb_lost_chunks));
 		ext4_msg(sb, KERN_INFO,
 		       "mballoc: %lu generated and it took %Lu",
 				sbi->s_mb_buddies_generated,
 				sbi->s_mb_generation_time);
 		ext4_msg(sb, KERN_INFO,
 		       "mballoc: %u preallocated, %u discarded",
-				atomic_read(&sbi->s_mb_preallocated),
-				atomic_read(&sbi->s_mb_discarded));
+				atomic_read_unchecked(&sbi->s_mb_preallocated),
+				atomic_read_unchecked(&sbi->s_mb_discarded));
 	}
 
 	free_percpu(sbi->s_locality_groups);
@@ -3103,16 +3103,16 @@ static void ext4_mb_collect_stats(struct
 	struct ext4_sb_info *sbi = EXT4_SB(ac->ac_sb);
 
 	if (sbi->s_mb_stats && ac->ac_g_ex.fe_len > 1) {
-		atomic_inc(&sbi->s_bal_reqs);
-		atomic_add(ac->ac_b_ex.fe_len, &sbi->s_bal_allocated);
+		atomic_inc_unchecked(&sbi->s_bal_reqs);
+		atomic_add_unchecked(ac->ac_b_ex.fe_len, &sbi->s_bal_allocated);
 		if (ac->ac_b_ex.fe_len >= ac->ac_o_ex.fe_len)
-			atomic_inc(&sbi->s_bal_success);
-		atomic_add(ac->ac_found, &sbi->s_bal_ex_scanned);
+			atomic_inc_unchecked(&sbi->s_bal_success);
+		atomic_add_unchecked(ac->ac_found, &sbi->s_bal_ex_scanned);
 		if (ac->ac_g_ex.fe_start == ac->ac_b_ex.fe_start &&
 				ac->ac_g_ex.fe_group == ac->ac_b_ex.fe_group)
-			atomic_inc(&sbi->s_bal_goals);
+			atomic_inc_unchecked(&sbi->s_bal_goals);
 		if (ac->ac_found > sbi->s_mb_max_to_scan)
-			atomic_inc(&sbi->s_bal_breaks);
+			atomic_inc_unchecked(&sbi->s_bal_breaks);
 	}
 
 	if (ac->ac_op == EXT4_MB_HISTORY_ALLOC)
@@ -3539,7 +3539,7 @@ ext4_mb_new_inode_pa(struct ext4_allocat
 	trace_ext4_mb_new_inode_pa(ac, pa);
 
 	ext4_mb_use_inode_pa(ac, pa);
-	atomic_add(pa->pa_free, &sbi->s_mb_preallocated);
+	atomic_add_unchecked(pa->pa_free, &sbi->s_mb_preallocated);
 
 	ei = EXT4_I(ac->ac_inode);
 	grp = ext4_get_group_info(sb, ac->ac_b_ex.fe_group);
@@ -3599,7 +3599,7 @@ ext4_mb_new_group_pa(struct ext4_allocat
 	trace_ext4_mb_new_group_pa(ac, pa);
 
 	ext4_mb_use_group_pa(ac, pa);
-	atomic_add(pa->pa_free, &EXT4_SB(sb)->s_mb_preallocated);
+	atomic_add_unchecked(pa->pa_free, &EXT4_SB(sb)->s_mb_preallocated);
 
 	grp = ext4_get_group_info(sb, ac->ac_b_ex.fe_group);
 	lg = ac->ac_lg;
@@ -3688,7 +3688,7 @@ ext4_mb_release_inode_pa(struct ext4_bud
 		 * from the bitmap and continue.
 		 */
 	}
-	atomic_add(free, &sbi->s_mb_discarded);
+	atomic_add_unchecked(free, &sbi->s_mb_discarded);
 
 	return err;
 }
@@ -3706,7 +3706,7 @@ ext4_mb_release_group_pa(struct ext4_bud
 	ext4_get_group_no_and_offset(sb, pa->pa_pstart, &group, &bit);
 	BUG_ON(group != e4b->bd_group && pa->pa_len != 0);
 	mb_free_blocks(pa->pa_inode, e4b, bit, pa->pa_len);
-	atomic_add(pa->pa_len, &EXT4_SB(sb)->s_mb_discarded);
+	atomic_add_unchecked(pa->pa_len, &EXT4_SB(sb)->s_mb_discarded);
 	trace_ext4_mballoc_discard(sb, NULL, group, bit, pa->pa_len);
 
 	return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ext4/mmp.c linux-3.2.71-pax/fs/ext4/mmp.c
--- linux-3.2.71/fs/ext4/mmp.c	2013-03-29 02:18:30.179676738 +0100
+++ linux-3.2.71-pax/fs/ext4/mmp.c	2013-06-21 20:15:56.434564312 +0200
@@ -73,7 +73,7 @@ static int read_mmp_block(struct super_b
 void __dump_mmp_msg(struct super_block *sb, struct mmp_struct *mmp,
 		    const char *function, unsigned int line, const char *msg)
 {
-	__ext4_warning(sb, function, line, msg);
+	__ext4_warning(sb, function, line, "%s", msg);
 	__ext4_warning(sb, function, line,
 		       "MMP failure info: last update time: %llu, last update "
 		       "node: %s, last update device: %s\n",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ext4/super.c linux-3.2.71-pax/fs/ext4/super.c
--- linux-3.2.71/fs/ext4/super.c	2015-08-14 21:48:35.324707912 +0200
+++ linux-3.2.71-pax/fs/ext4/super.c	2015-08-14 21:48:45.676707359 +0200
@@ -1439,7 +1439,7 @@ static ext4_fsblk_t get_sb_block(void **
 }
 
 #define DEFAULT_JOURNAL_IOPRIO (IOPRIO_PRIO_VALUE(IOPRIO_CLASS_BE, 3))
-static char deprecated_msg[] = "Mount option \"%s\" will be removed by %s\n"
+static const char deprecated_msg[] = "Mount option \"%s\" will be removed by %s\n"
 	"Contact linux-ext4@vger.kernel.org if you think we should keep it.\n";
 
 #ifdef CONFIG_QUOTA
@@ -2461,7 +2461,7 @@ struct ext4_attr {
 	ssize_t (*store)(struct ext4_attr *, struct ext4_sb_info *,
 			 const char *, size_t);
 	int offset;
-};
+} __do_const;
 
 static int parse_strtoul(const char *buf,
 		unsigned long max, unsigned long *value)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ext4/xattr.c linux-3.2.71-pax/fs/ext4/xattr.c
--- linux-3.2.71/fs/ext4/xattr.c	2014-12-14 21:13:45.246055162 +0100
+++ linux-3.2.71-pax/fs/ext4/xattr.c	2014-12-14 21:13:52.826069322 +0100
@@ -343,7 +343,7 @@ static int
 ext4_xattr_list_entries(struct dentry *dentry, struct ext4_xattr_entry *entry,
 			char *buffer, size_t buffer_size)
 {
-	size_t rest = buffer_size;
+	size_t rest = buffer_size, total_size = 0;
 
 	for (; !IS_LAST_ENTRY(entry); entry = EXT4_XATTR_NEXT(entry)) {
 		const struct xattr_handler *handler =
@@ -360,9 +360,10 @@ ext4_xattr_list_entries(struct dentry *d
 				buffer += size;
 			}
 			rest -= size;
+			total_size += size;
 		}
 	}
-	return buffer_size - rest;
+	return total_size;
 }
 
 static int
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/fcntl.c linux-3.2.71-pax/fs/fcntl.c
--- linux-3.2.71/fs/fcntl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/fcntl.c	2012-07-04 19:24:48.692063008 +0200
@@ -266,7 +266,7 @@ pid_t f_getown(struct file *filp)
 
 static int f_setown_ex(struct file *filp, unsigned long arg)
 {
-	struct f_owner_ex * __user owner_p = (void * __user)arg;
+	struct f_owner_ex __user *owner_p = (void __user *)arg;
 	struct f_owner_ex owner;
 	struct pid *pid;
 	int type;
@@ -306,7 +306,7 @@ static int f_setown_ex(struct file *filp
 
 static int f_getown_ex(struct file *filp, unsigned long arg)
 {
-	struct f_owner_ex * __user owner_p = (void * __user)arg;
+	struct f_owner_ex __user *owner_p = (void __user *)arg;
 	struct f_owner_ex owner;
 	int ret = 0;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/fifo.c linux-3.2.71-pax/fs/fifo.c
--- linux-3.2.71/fs/fifo.c	2012-07-27 22:08:38.018372809 +0200
+++ linux-3.2.71-pax/fs/fifo.c	2012-07-27 22:09:32.966374423 +0200
@@ -59,10 +59,10 @@ static int fifo_open(struct inode *inode
 	 */
 		filp->f_op = &read_pipefifo_fops;
 		pipe->r_counter++;
-		if (pipe->readers++ == 0)
+		if (atomic_inc_return(&pipe->readers) == 1)
 			wake_up_partner(inode);
 
-		if (!pipe->writers) {
+		if (!atomic_read(&pipe->writers)) {
 			if ((filp->f_flags & O_NONBLOCK)) {
 				/* suppress POLLHUP until we have
 				 * seen a writer */
@@ -81,15 +81,15 @@ static int fifo_open(struct inode *inode
 	 *  errno=ENXIO when there is no process reading the FIFO.
 	 */
 		ret = -ENXIO;
-		if ((filp->f_flags & O_NONBLOCK) && !pipe->readers)
+		if ((filp->f_flags & O_NONBLOCK) && !atomic_read(&pipe->readers))
 			goto err;
 
 		filp->f_op = &write_pipefifo_fops;
 		pipe->w_counter++;
-		if (!pipe->writers++)
+		if (atomic_inc_return(&pipe->writers) == 1)
 			wake_up_partner(inode);
 
-		if (!pipe->readers) {
+		if (!atomic_read(&pipe->readers)) {
 			if (wait_for_partner(inode, &pipe->r_counter))
 				goto err_wr;
 		}
@@ -104,11 +104,11 @@ static int fifo_open(struct inode *inode
 	 */
 		filp->f_op = &rdwr_pipefifo_fops;
 
-		pipe->readers++;
-		pipe->writers++;
+		atomic_inc(&pipe->readers);
+		atomic_inc(&pipe->writers);
 		pipe->r_counter++;
 		pipe->w_counter++;
-		if (pipe->readers == 1 || pipe->writers == 1)
+		if (atomic_read(&pipe->readers) == 1 || atomic_read(&pipe->writers) == 1)
 			wake_up_partner(inode);
 		break;
 
@@ -122,19 +122,19 @@ static int fifo_open(struct inode *inode
 	return 0;
 
 err_rd:
-	if (!--pipe->readers)
+	if (atomic_dec_and_test(&pipe->readers))
 		wake_up_interruptible(&pipe->wait);
 	ret = -ERESTARTSYS;
 	goto err;
 
 err_wr:
-	if (!--pipe->writers)
+	if (atomic_dec_and_test(&pipe->writers))
 		wake_up_interruptible(&pipe->wait);
 	ret = -ERESTARTSYS;
 	goto err;
 
 err:
-	if (!pipe->readers && !pipe->writers)
+	if (!atomic_read(&pipe->readers) && !atomic_read(&pipe->writers))
 		free_pipe_info(inode);
 
 err_nocleanup:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/file.c linux-3.2.71-pax/fs/file.c
--- linux-3.2.71/fs/file.c	2014-04-02 03:15:43.767672438 +0200
+++ linux-3.2.71-pax/fs/file.c	2014-04-02 03:15:49.263672144 +0200
@@ -199,7 +199,7 @@ out:
  * Return <0 error code on error; 1 on successful completion.
  * The files->file_lock should be held on entry, and will be held on exit.
  */
-static int expand_fdtable(struct files_struct *files, int nr)
+static int expand_fdtable(struct files_struct *files, unsigned int nr)
 	__releases(files->file_lock)
 	__acquires(files->file_lock)
 {
@@ -244,7 +244,7 @@ static int expand_fdtable(struct files_s
  * expanded and execution may have blocked.
  * The files->file_lock should be held on entry, and will be held on exit.
  */
-int expand_files(struct files_struct *files, int nr)
+int expand_files(struct files_struct *files, unsigned int nr)
 {
 	struct fdtable *fdt;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/fscache/cookie.c linux-3.2.71-pax/fs/fscache/cookie.c
--- linux-3.2.71/fs/fscache/cookie.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/fscache/cookie.c	2013-09-01 19:44:55.151892833 +0200
@@ -19,7 +19,7 @@
 
 struct kmem_cache *fscache_cookie_jar;
 
-static atomic_t fscache_object_debug_id = ATOMIC_INIT(0);
+static atomic_unchecked_t fscache_object_debug_id = ATOMIC_INIT(0);
 
 static int fscache_acquire_non_index_cookie(struct fscache_cookie *cookie);
 static int fscache_alloc_object(struct fscache_cache *cache,
@@ -68,11 +68,11 @@ struct fscache_cookie *__fscache_acquire
 	       parent ? (char *) parent->def->name : "<no-parent>",
 	       def->name, netfs_data);
 
-	fscache_stat(&fscache_n_acquires);
+	fscache_stat_unchecked(&fscache_n_acquires);
 
 	/* if there's no parent cookie, then we don't create one here either */
 	if (!parent) {
-		fscache_stat(&fscache_n_acquires_null);
+		fscache_stat_unchecked(&fscache_n_acquires_null);
 		_leave(" [no parent]");
 		return NULL;
 	}
@@ -87,7 +87,7 @@ struct fscache_cookie *__fscache_acquire
 	/* allocate and initialise a cookie */
 	cookie = kmem_cache_alloc(fscache_cookie_jar, GFP_KERNEL);
 	if (!cookie) {
-		fscache_stat(&fscache_n_acquires_oom);
+		fscache_stat_unchecked(&fscache_n_acquires_oom);
 		_leave(" [ENOMEM]");
 		return NULL;
 	}
@@ -109,13 +109,13 @@ struct fscache_cookie *__fscache_acquire
 
 	switch (cookie->def->type) {
 	case FSCACHE_COOKIE_TYPE_INDEX:
-		fscache_stat(&fscache_n_cookie_index);
+		fscache_stat_unchecked(&fscache_n_cookie_index);
 		break;
 	case FSCACHE_COOKIE_TYPE_DATAFILE:
-		fscache_stat(&fscache_n_cookie_data);
+		fscache_stat_unchecked(&fscache_n_cookie_data);
 		break;
 	default:
-		fscache_stat(&fscache_n_cookie_special);
+		fscache_stat_unchecked(&fscache_n_cookie_special);
 		break;
 	}
 
@@ -126,13 +126,13 @@ struct fscache_cookie *__fscache_acquire
 		if (fscache_acquire_non_index_cookie(cookie) < 0) {
 			atomic_dec(&parent->n_children);
 			__fscache_cookie_put(cookie);
-			fscache_stat(&fscache_n_acquires_nobufs);
+			fscache_stat_unchecked(&fscache_n_acquires_nobufs);
 			_leave(" = NULL");
 			return NULL;
 		}
 	}
 
-	fscache_stat(&fscache_n_acquires_ok);
+	fscache_stat_unchecked(&fscache_n_acquires_ok);
 	_leave(" = %p", cookie);
 	return cookie;
 }
@@ -168,7 +168,7 @@ static int fscache_acquire_non_index_coo
 	cache = fscache_select_cache_for_object(cookie->parent);
 	if (!cache) {
 		up_read(&fscache_addremove_sem);
-		fscache_stat(&fscache_n_acquires_no_cache);
+		fscache_stat_unchecked(&fscache_n_acquires_no_cache);
 		_leave(" = -ENOMEDIUM [no cache]");
 		return -ENOMEDIUM;
 	}
@@ -256,14 +256,14 @@ static int fscache_alloc_object(struct f
 	object = cache->ops->alloc_object(cache, cookie);
 	fscache_stat_d(&fscache_n_cop_alloc_object);
 	if (IS_ERR(object)) {
-		fscache_stat(&fscache_n_object_no_alloc);
+		fscache_stat_unchecked(&fscache_n_object_no_alloc);
 		ret = PTR_ERR(object);
 		goto error;
 	}
 
-	fscache_stat(&fscache_n_object_alloc);
+	fscache_stat_unchecked(&fscache_n_object_alloc);
 
-	object->debug_id = atomic_inc_return(&fscache_object_debug_id);
+	object->debug_id = atomic_inc_return_unchecked(&fscache_object_debug_id);
 
 	_debug("ALLOC OBJ%x: %s {%lx}",
 	       object->debug_id, cookie->def->name, object->events);
@@ -377,10 +377,10 @@ void __fscache_update_cookie(struct fsca
 	struct fscache_object *object;
 	struct hlist_node *_p;
 
-	fscache_stat(&fscache_n_updates);
+	fscache_stat_unchecked(&fscache_n_updates);
 
 	if (!cookie) {
-		fscache_stat(&fscache_n_updates_null);
+		fscache_stat_unchecked(&fscache_n_updates_null);
 		_leave(" [no cookie]");
 		return;
 	}
@@ -414,12 +414,12 @@ void __fscache_relinquish_cookie(struct
 	struct fscache_object *object;
 	unsigned long event;
 
-	fscache_stat(&fscache_n_relinquishes);
+	fscache_stat_unchecked(&fscache_n_relinquishes);
 	if (retire)
-		fscache_stat(&fscache_n_relinquishes_retire);
+		fscache_stat_unchecked(&fscache_n_relinquishes_retire);
 
 	if (!cookie) {
-		fscache_stat(&fscache_n_relinquishes_null);
+		fscache_stat_unchecked(&fscache_n_relinquishes_null);
 		_leave(" [no cookie]");
 		return;
 	}
@@ -435,7 +435,7 @@ void __fscache_relinquish_cookie(struct
 
 	/* wait for the cookie to finish being instantiated (or to fail) */
 	if (test_bit(FSCACHE_COOKIE_CREATING, &cookie->flags)) {
-		fscache_stat(&fscache_n_relinquishes_waitcrt);
+		fscache_stat_unchecked(&fscache_n_relinquishes_waitcrt);
 		wait_on_bit(&cookie->flags, FSCACHE_COOKIE_CREATING,
 			    fscache_wait_bit, TASK_UNINTERRUPTIBLE);
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/fscache/internal.h linux-3.2.71-pax/fs/fscache/internal.h
--- linux-3.2.71/fs/fscache/internal.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/fscache/internal.h	2012-07-04 19:24:48.696063008 +0200
@@ -144,94 +144,94 @@ extern void fscache_proc_cleanup(void);
 extern atomic_t fscache_n_ops_processed[FSCACHE_MAX_THREADS];
 extern atomic_t fscache_n_objs_processed[FSCACHE_MAX_THREADS];
 
-extern atomic_t fscache_n_op_pend;
-extern atomic_t fscache_n_op_run;
-extern atomic_t fscache_n_op_enqueue;
-extern atomic_t fscache_n_op_deferred_release;
-extern atomic_t fscache_n_op_release;
-extern atomic_t fscache_n_op_gc;
-extern atomic_t fscache_n_op_cancelled;
-extern atomic_t fscache_n_op_rejected;
-
-extern atomic_t fscache_n_attr_changed;
-extern atomic_t fscache_n_attr_changed_ok;
-extern atomic_t fscache_n_attr_changed_nobufs;
-extern atomic_t fscache_n_attr_changed_nomem;
-extern atomic_t fscache_n_attr_changed_calls;
-
-extern atomic_t fscache_n_allocs;
-extern atomic_t fscache_n_allocs_ok;
-extern atomic_t fscache_n_allocs_wait;
-extern atomic_t fscache_n_allocs_nobufs;
-extern atomic_t fscache_n_allocs_intr;
-extern atomic_t fscache_n_allocs_object_dead;
-extern atomic_t fscache_n_alloc_ops;
-extern atomic_t fscache_n_alloc_op_waits;
-
-extern atomic_t fscache_n_retrievals;
-extern atomic_t fscache_n_retrievals_ok;
-extern atomic_t fscache_n_retrievals_wait;
-extern atomic_t fscache_n_retrievals_nodata;
-extern atomic_t fscache_n_retrievals_nobufs;
-extern atomic_t fscache_n_retrievals_intr;
-extern atomic_t fscache_n_retrievals_nomem;
-extern atomic_t fscache_n_retrievals_object_dead;
-extern atomic_t fscache_n_retrieval_ops;
-extern atomic_t fscache_n_retrieval_op_waits;
-
-extern atomic_t fscache_n_stores;
-extern atomic_t fscache_n_stores_ok;
-extern atomic_t fscache_n_stores_again;
-extern atomic_t fscache_n_stores_nobufs;
-extern atomic_t fscache_n_stores_oom;
-extern atomic_t fscache_n_store_ops;
-extern atomic_t fscache_n_store_calls;
-extern atomic_t fscache_n_store_pages;
-extern atomic_t fscache_n_store_radix_deletes;
-extern atomic_t fscache_n_store_pages_over_limit;
-
-extern atomic_t fscache_n_store_vmscan_not_storing;
-extern atomic_t fscache_n_store_vmscan_gone;
-extern atomic_t fscache_n_store_vmscan_busy;
-extern atomic_t fscache_n_store_vmscan_cancelled;
-
-extern atomic_t fscache_n_marks;
-extern atomic_t fscache_n_uncaches;
-
-extern atomic_t fscache_n_acquires;
-extern atomic_t fscache_n_acquires_null;
-extern atomic_t fscache_n_acquires_no_cache;
-extern atomic_t fscache_n_acquires_ok;
-extern atomic_t fscache_n_acquires_nobufs;
-extern atomic_t fscache_n_acquires_oom;
-
-extern atomic_t fscache_n_updates;
-extern atomic_t fscache_n_updates_null;
-extern atomic_t fscache_n_updates_run;
-
-extern atomic_t fscache_n_relinquishes;
-extern atomic_t fscache_n_relinquishes_null;
-extern atomic_t fscache_n_relinquishes_waitcrt;
-extern atomic_t fscache_n_relinquishes_retire;
-
-extern atomic_t fscache_n_cookie_index;
-extern atomic_t fscache_n_cookie_data;
-extern atomic_t fscache_n_cookie_special;
-
-extern atomic_t fscache_n_object_alloc;
-extern atomic_t fscache_n_object_no_alloc;
-extern atomic_t fscache_n_object_lookups;
-extern atomic_t fscache_n_object_lookups_negative;
-extern atomic_t fscache_n_object_lookups_positive;
-extern atomic_t fscache_n_object_lookups_timed_out;
-extern atomic_t fscache_n_object_created;
-extern atomic_t fscache_n_object_avail;
-extern atomic_t fscache_n_object_dead;
-
-extern atomic_t fscache_n_checkaux_none;
-extern atomic_t fscache_n_checkaux_okay;
-extern atomic_t fscache_n_checkaux_update;
-extern atomic_t fscache_n_checkaux_obsolete;
+extern atomic_unchecked_t fscache_n_op_pend;
+extern atomic_unchecked_t fscache_n_op_run;
+extern atomic_unchecked_t fscache_n_op_enqueue;
+extern atomic_unchecked_t fscache_n_op_deferred_release;
+extern atomic_unchecked_t fscache_n_op_release;
+extern atomic_unchecked_t fscache_n_op_gc;
+extern atomic_unchecked_t fscache_n_op_cancelled;
+extern atomic_unchecked_t fscache_n_op_rejected;
+
+extern atomic_unchecked_t fscache_n_attr_changed;
+extern atomic_unchecked_t fscache_n_attr_changed_ok;
+extern atomic_unchecked_t fscache_n_attr_changed_nobufs;
+extern atomic_unchecked_t fscache_n_attr_changed_nomem;
+extern atomic_unchecked_t fscache_n_attr_changed_calls;
+
+extern atomic_unchecked_t fscache_n_allocs;
+extern atomic_unchecked_t fscache_n_allocs_ok;
+extern atomic_unchecked_t fscache_n_allocs_wait;
+extern atomic_unchecked_t fscache_n_allocs_nobufs;
+extern atomic_unchecked_t fscache_n_allocs_intr;
+extern atomic_unchecked_t fscache_n_allocs_object_dead;
+extern atomic_unchecked_t fscache_n_alloc_ops;
+extern atomic_unchecked_t fscache_n_alloc_op_waits;
+
+extern atomic_unchecked_t fscache_n_retrievals;
+extern atomic_unchecked_t fscache_n_retrievals_ok;
+extern atomic_unchecked_t fscache_n_retrievals_wait;
+extern atomic_unchecked_t fscache_n_retrievals_nodata;
+extern atomic_unchecked_t fscache_n_retrievals_nobufs;
+extern atomic_unchecked_t fscache_n_retrievals_intr;
+extern atomic_unchecked_t fscache_n_retrievals_nomem;
+extern atomic_unchecked_t fscache_n_retrievals_object_dead;
+extern atomic_unchecked_t fscache_n_retrieval_ops;
+extern atomic_unchecked_t fscache_n_retrieval_op_waits;
+
+extern atomic_unchecked_t fscache_n_stores;
+extern atomic_unchecked_t fscache_n_stores_ok;
+extern atomic_unchecked_t fscache_n_stores_again;
+extern atomic_unchecked_t fscache_n_stores_nobufs;
+extern atomic_unchecked_t fscache_n_stores_oom;
+extern atomic_unchecked_t fscache_n_store_ops;
+extern atomic_unchecked_t fscache_n_store_calls;
+extern atomic_unchecked_t fscache_n_store_pages;
+extern atomic_unchecked_t fscache_n_store_radix_deletes;
+extern atomic_unchecked_t fscache_n_store_pages_over_limit;
+
+extern atomic_unchecked_t fscache_n_store_vmscan_not_storing;
+extern atomic_unchecked_t fscache_n_store_vmscan_gone;
+extern atomic_unchecked_t fscache_n_store_vmscan_busy;
+extern atomic_unchecked_t fscache_n_store_vmscan_cancelled;
+
+extern atomic_unchecked_t fscache_n_marks;
+extern atomic_unchecked_t fscache_n_uncaches;
+
+extern atomic_unchecked_t fscache_n_acquires;
+extern atomic_unchecked_t fscache_n_acquires_null;
+extern atomic_unchecked_t fscache_n_acquires_no_cache;
+extern atomic_unchecked_t fscache_n_acquires_ok;
+extern atomic_unchecked_t fscache_n_acquires_nobufs;
+extern atomic_unchecked_t fscache_n_acquires_oom;
+
+extern atomic_unchecked_t fscache_n_updates;
+extern atomic_unchecked_t fscache_n_updates_null;
+extern atomic_unchecked_t fscache_n_updates_run;
+
+extern atomic_unchecked_t fscache_n_relinquishes;
+extern atomic_unchecked_t fscache_n_relinquishes_null;
+extern atomic_unchecked_t fscache_n_relinquishes_waitcrt;
+extern atomic_unchecked_t fscache_n_relinquishes_retire;
+
+extern atomic_unchecked_t fscache_n_cookie_index;
+extern atomic_unchecked_t fscache_n_cookie_data;
+extern atomic_unchecked_t fscache_n_cookie_special;
+
+extern atomic_unchecked_t fscache_n_object_alloc;
+extern atomic_unchecked_t fscache_n_object_no_alloc;
+extern atomic_unchecked_t fscache_n_object_lookups;
+extern atomic_unchecked_t fscache_n_object_lookups_negative;
+extern atomic_unchecked_t fscache_n_object_lookups_positive;
+extern atomic_unchecked_t fscache_n_object_lookups_timed_out;
+extern atomic_unchecked_t fscache_n_object_created;
+extern atomic_unchecked_t fscache_n_object_avail;
+extern atomic_unchecked_t fscache_n_object_dead;
+
+extern atomic_unchecked_t fscache_n_checkaux_none;
+extern atomic_unchecked_t fscache_n_checkaux_okay;
+extern atomic_unchecked_t fscache_n_checkaux_update;
+extern atomic_unchecked_t fscache_n_checkaux_obsolete;
 
 extern atomic_t fscache_n_cop_alloc_object;
 extern atomic_t fscache_n_cop_lookup_object;
@@ -255,6 +255,11 @@ static inline void fscache_stat(atomic_t
 	atomic_inc(stat);
 }
 
+static inline void fscache_stat_unchecked(atomic_unchecked_t *stat)
+{
+	atomic_inc_unchecked(stat);
+}
+
 static inline void fscache_stat_d(atomic_t *stat)
 {
 	atomic_dec(stat);
@@ -267,6 +272,7 @@ extern const struct file_operations fsca
 
 #define __fscache_stat(stat) (NULL)
 #define fscache_stat(stat) do {} while (0)
+#define fscache_stat_unchecked(stat) do {} while (0)
 #define fscache_stat_d(stat) do {} while (0)
 #endif
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/fscache/object.c linux-3.2.71-pax/fs/fscache/object.c
--- linux-3.2.71/fs/fscache/object.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/fscache/object.c	2012-07-04 19:24:48.696063008 +0200
@@ -128,7 +128,7 @@ static void fscache_object_state_machine
 		/* update the object metadata on disk */
 	case FSCACHE_OBJECT_UPDATING:
 		clear_bit(FSCACHE_OBJECT_EV_UPDATE, &object->events);
-		fscache_stat(&fscache_n_updates_run);
+		fscache_stat_unchecked(&fscache_n_updates_run);
 		fscache_stat(&fscache_n_cop_update_object);
 		object->cache->ops->update_object(object);
 		fscache_stat_d(&fscache_n_cop_update_object);
@@ -217,7 +217,7 @@ static void fscache_object_state_machine
 		spin_lock(&object->lock);
 		object->state = FSCACHE_OBJECT_DEAD;
 		spin_unlock(&object->lock);
-		fscache_stat(&fscache_n_object_dead);
+		fscache_stat_unchecked(&fscache_n_object_dead);
 		goto terminal_transit;
 
 		/* handle the parent cache of this object being withdrawn from
@@ -232,7 +232,7 @@ static void fscache_object_state_machine
 		spin_lock(&object->lock);
 		object->state = FSCACHE_OBJECT_DEAD;
 		spin_unlock(&object->lock);
-		fscache_stat(&fscache_n_object_dead);
+		fscache_stat_unchecked(&fscache_n_object_dead);
 		goto terminal_transit;
 
 		/* complain about the object being woken up once it is
@@ -461,7 +461,7 @@ static void fscache_lookup_object(struct
 	       parent->cookie->def->name, cookie->def->name,
 	       object->cache->tag->name);
 
-	fscache_stat(&fscache_n_object_lookups);
+	fscache_stat_unchecked(&fscache_n_object_lookups);
 	fscache_stat(&fscache_n_cop_lookup_object);
 	ret = object->cache->ops->lookup_object(object);
 	fscache_stat_d(&fscache_n_cop_lookup_object);
@@ -472,7 +472,7 @@ static void fscache_lookup_object(struct
 	if (ret == -ETIMEDOUT) {
 		/* probably stuck behind another object, so move this one to
 		 * the back of the queue */
-		fscache_stat(&fscache_n_object_lookups_timed_out);
+		fscache_stat_unchecked(&fscache_n_object_lookups_timed_out);
 		set_bit(FSCACHE_OBJECT_EV_REQUEUE, &object->events);
 	}
 
@@ -495,7 +495,7 @@ void fscache_object_lookup_negative(stru
 
 	spin_lock(&object->lock);
 	if (object->state == FSCACHE_OBJECT_LOOKING_UP) {
-		fscache_stat(&fscache_n_object_lookups_negative);
+		fscache_stat_unchecked(&fscache_n_object_lookups_negative);
 
 		/* transit here to allow write requests to begin stacking up
 		 * and read requests to begin returning ENODATA */
@@ -541,7 +541,7 @@ void fscache_obtained_object(struct fsca
 	 * result, in which case there may be data available */
 	spin_lock(&object->lock);
 	if (object->state == FSCACHE_OBJECT_LOOKING_UP) {
-		fscache_stat(&fscache_n_object_lookups_positive);
+		fscache_stat_unchecked(&fscache_n_object_lookups_positive);
 
 		clear_bit(FSCACHE_COOKIE_NO_DATA_YET, &cookie->flags);
 
@@ -555,7 +555,7 @@ void fscache_obtained_object(struct fsca
 		set_bit(FSCACHE_OBJECT_EV_REQUEUE, &object->events);
 	} else {
 		ASSERTCMP(object->state, ==, FSCACHE_OBJECT_CREATING);
-		fscache_stat(&fscache_n_object_created);
+		fscache_stat_unchecked(&fscache_n_object_created);
 
 		object->state = FSCACHE_OBJECT_AVAILABLE;
 		spin_unlock(&object->lock);
@@ -602,7 +602,7 @@ static void fscache_object_available(str
 	fscache_enqueue_dependents(object);
 
 	fscache_hist(fscache_obj_instantiate_histogram, object->lookup_jif);
-	fscache_stat(&fscache_n_object_avail);
+	fscache_stat_unchecked(&fscache_n_object_avail);
 
 	_leave("");
 }
@@ -861,7 +861,7 @@ enum fscache_checkaux fscache_check_aux(
 	enum fscache_checkaux result;
 
 	if (!object->cookie->def->check_aux) {
-		fscache_stat(&fscache_n_checkaux_none);
+		fscache_stat_unchecked(&fscache_n_checkaux_none);
 		return FSCACHE_CHECKAUX_OKAY;
 	}
 
@@ -870,17 +870,17 @@ enum fscache_checkaux fscache_check_aux(
 	switch (result) {
 		/* entry okay as is */
 	case FSCACHE_CHECKAUX_OKAY:
-		fscache_stat(&fscache_n_checkaux_okay);
+		fscache_stat_unchecked(&fscache_n_checkaux_okay);
 		break;
 
 		/* entry requires update */
 	case FSCACHE_CHECKAUX_NEEDS_UPDATE:
-		fscache_stat(&fscache_n_checkaux_update);
+		fscache_stat_unchecked(&fscache_n_checkaux_update);
 		break;
 
 		/* entry requires deletion */
 	case FSCACHE_CHECKAUX_OBSOLETE:
-		fscache_stat(&fscache_n_checkaux_obsolete);
+		fscache_stat_unchecked(&fscache_n_checkaux_obsolete);
 		break;
 
 	default:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/fscache/operation.c linux-3.2.71-pax/fs/fscache/operation.c
--- linux-3.2.71/fs/fscache/operation.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/fscache/operation.c	2012-07-04 19:24:48.696063008 +0200
@@ -17,7 +17,7 @@
 #include <linux/slab.h>
 #include "internal.h"
 
-atomic_t fscache_op_debug_id;
+atomic_unchecked_t fscache_op_debug_id;
 EXPORT_SYMBOL(fscache_op_debug_id);
 
 /**
@@ -38,7 +38,7 @@ void fscache_enqueue_operation(struct fs
 	ASSERTCMP(op->object->state, >=, FSCACHE_OBJECT_AVAILABLE);
 	ASSERTCMP(atomic_read(&op->usage), >, 0);
 
-	fscache_stat(&fscache_n_op_enqueue);
+	fscache_stat_unchecked(&fscache_n_op_enqueue);
 	switch (op->flags & FSCACHE_OP_TYPE) {
 	case FSCACHE_OP_ASYNC:
 		_debug("queue async");
@@ -69,7 +69,7 @@ static void fscache_run_op(struct fscach
 		wake_up_bit(&op->flags, FSCACHE_OP_WAITING);
 	if (op->processor)
 		fscache_enqueue_operation(op);
-	fscache_stat(&fscache_n_op_run);
+	fscache_stat_unchecked(&fscache_n_op_run);
 }
 
 /*
@@ -98,11 +98,11 @@ int fscache_submit_exclusive_op(struct f
 		if (object->n_ops > 1) {
 			atomic_inc(&op->usage);
 			list_add_tail(&op->pend_link, &object->pending_ops);
-			fscache_stat(&fscache_n_op_pend);
+			fscache_stat_unchecked(&fscache_n_op_pend);
 		} else if (!list_empty(&object->pending_ops)) {
 			atomic_inc(&op->usage);
 			list_add_tail(&op->pend_link, &object->pending_ops);
-			fscache_stat(&fscache_n_op_pend);
+			fscache_stat_unchecked(&fscache_n_op_pend);
 			fscache_start_operations(object);
 		} else {
 			ASSERTCMP(object->n_in_progress, ==, 0);
@@ -118,7 +118,7 @@ int fscache_submit_exclusive_op(struct f
 		object->n_exclusive++;	/* reads and writes must wait */
 		atomic_inc(&op->usage);
 		list_add_tail(&op->pend_link, &object->pending_ops);
-		fscache_stat(&fscache_n_op_pend);
+		fscache_stat_unchecked(&fscache_n_op_pend);
 		ret = 0;
 	} else {
 		/* not allowed to submit ops in any other state */
@@ -203,11 +203,11 @@ int fscache_submit_op(struct fscache_obj
 		if (object->n_exclusive > 0) {
 			atomic_inc(&op->usage);
 			list_add_tail(&op->pend_link, &object->pending_ops);
-			fscache_stat(&fscache_n_op_pend);
+			fscache_stat_unchecked(&fscache_n_op_pend);
 		} else if (!list_empty(&object->pending_ops)) {
 			atomic_inc(&op->usage);
 			list_add_tail(&op->pend_link, &object->pending_ops);
-			fscache_stat(&fscache_n_op_pend);
+			fscache_stat_unchecked(&fscache_n_op_pend);
 			fscache_start_operations(object);
 		} else {
 			ASSERTCMP(object->n_exclusive, ==, 0);
@@ -219,12 +219,12 @@ int fscache_submit_op(struct fscache_obj
 		object->n_ops++;
 		atomic_inc(&op->usage);
 		list_add_tail(&op->pend_link, &object->pending_ops);
-		fscache_stat(&fscache_n_op_pend);
+		fscache_stat_unchecked(&fscache_n_op_pend);
 		ret = 0;
 	} else if (object->state == FSCACHE_OBJECT_DYING ||
 		   object->state == FSCACHE_OBJECT_LC_DYING ||
 		   object->state == FSCACHE_OBJECT_WITHDRAWING) {
-		fscache_stat(&fscache_n_op_rejected);
+		fscache_stat_unchecked(&fscache_n_op_rejected);
 		ret = -ENOBUFS;
 	} else if (!test_bit(FSCACHE_IOERROR, &object->cache->flags)) {
 		fscache_report_unexpected_submission(object, op, ostate);
@@ -294,7 +294,7 @@ int fscache_cancel_op(struct fscache_ope
 
 	ret = -EBUSY;
 	if (!list_empty(&op->pend_link)) {
-		fscache_stat(&fscache_n_op_cancelled);
+		fscache_stat_unchecked(&fscache_n_op_cancelled);
 		list_del_init(&op->pend_link);
 		object->n_ops--;
 		if (test_bit(FSCACHE_OP_EXCLUSIVE, &op->flags))
@@ -331,7 +331,7 @@ void fscache_put_operation(struct fscach
 	if (test_and_set_bit(FSCACHE_OP_DEAD, &op->flags))
 		BUG();
 
-	fscache_stat(&fscache_n_op_release);
+	fscache_stat_unchecked(&fscache_n_op_release);
 
 	if (op->release) {
 		op->release(op);
@@ -348,7 +348,7 @@ void fscache_put_operation(struct fscach
 	 * lock, and defer it otherwise */
 	if (!spin_trylock(&object->lock)) {
 		_debug("defer put");
-		fscache_stat(&fscache_n_op_deferred_release);
+		fscache_stat_unchecked(&fscache_n_op_deferred_release);
 
 		cache = object->cache;
 		spin_lock(&cache->op_gc_list_lock);
@@ -410,7 +410,7 @@ void fscache_operation_gc(struct work_st
 
 		_debug("GC DEFERRED REL OBJ%x OP%x",
 		       object->debug_id, op->debug_id);
-		fscache_stat(&fscache_n_op_gc);
+		fscache_stat_unchecked(&fscache_n_op_gc);
 
 		ASSERTCMP(atomic_read(&op->usage), ==, 0);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/fscache/page.c linux-3.2.71-pax/fs/fscache/page.c
--- linux-3.2.71/fs/fscache/page.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/fscache/page.c	2012-07-04 19:24:48.696063008 +0200
@@ -60,7 +60,7 @@ bool __fscache_maybe_release_page(struct
 	val = radix_tree_lookup(&cookie->stores, page->index);
 	if (!val) {
 		rcu_read_unlock();
-		fscache_stat(&fscache_n_store_vmscan_not_storing);
+		fscache_stat_unchecked(&fscache_n_store_vmscan_not_storing);
 		__fscache_uncache_page(cookie, page);
 		return true;
 	}
@@ -90,11 +90,11 @@ bool __fscache_maybe_release_page(struct
 	spin_unlock(&cookie->stores_lock);
 
 	if (xpage) {
-		fscache_stat(&fscache_n_store_vmscan_cancelled);
-		fscache_stat(&fscache_n_store_radix_deletes);
+		fscache_stat_unchecked(&fscache_n_store_vmscan_cancelled);
+		fscache_stat_unchecked(&fscache_n_store_radix_deletes);
 		ASSERTCMP(xpage, ==, page);
 	} else {
-		fscache_stat(&fscache_n_store_vmscan_gone);
+		fscache_stat_unchecked(&fscache_n_store_vmscan_gone);
 	}
 
 	wake_up_bit(&cookie->flags, 0);
@@ -107,7 +107,7 @@ page_busy:
 	/* we might want to wait here, but that could deadlock the allocator as
 	 * the work threads writing to the cache may all end up sleeping
 	 * on memory allocation */
-	fscache_stat(&fscache_n_store_vmscan_busy);
+	fscache_stat_unchecked(&fscache_n_store_vmscan_busy);
 	return false;
 }
 EXPORT_SYMBOL(__fscache_maybe_release_page);
@@ -131,7 +131,7 @@ static void fscache_end_page_write(struc
 				     FSCACHE_COOKIE_STORING_TAG);
 		if (!radix_tree_tag_get(&cookie->stores, page->index,
 					FSCACHE_COOKIE_PENDING_TAG)) {
-			fscache_stat(&fscache_n_store_radix_deletes);
+			fscache_stat_unchecked(&fscache_n_store_radix_deletes);
 			xpage = radix_tree_delete(&cookie->stores, page->index);
 		}
 		spin_unlock(&cookie->stores_lock);
@@ -152,7 +152,7 @@ static void fscache_attr_changed_op(stru
 
 	_enter("{OBJ%x OP%x}", object->debug_id, op->debug_id);
 
-	fscache_stat(&fscache_n_attr_changed_calls);
+	fscache_stat_unchecked(&fscache_n_attr_changed_calls);
 
 	if (fscache_object_is_active(object)) {
 		fscache_stat(&fscache_n_cop_attr_changed);
@@ -177,11 +177,11 @@ int __fscache_attr_changed(struct fscach
 
 	ASSERTCMP(cookie->def->type, !=, FSCACHE_COOKIE_TYPE_INDEX);
 
-	fscache_stat(&fscache_n_attr_changed);
+	fscache_stat_unchecked(&fscache_n_attr_changed);
 
 	op = kzalloc(sizeof(*op), GFP_KERNEL);
 	if (!op) {
-		fscache_stat(&fscache_n_attr_changed_nomem);
+		fscache_stat_unchecked(&fscache_n_attr_changed_nomem);
 		_leave(" = -ENOMEM");
 		return -ENOMEM;
 	}
@@ -199,7 +199,7 @@ int __fscache_attr_changed(struct fscach
 	if (fscache_submit_exclusive_op(object, op) < 0)
 		goto nobufs;
 	spin_unlock(&cookie->lock);
-	fscache_stat(&fscache_n_attr_changed_ok);
+	fscache_stat_unchecked(&fscache_n_attr_changed_ok);
 	fscache_put_operation(op);
 	_leave(" = 0");
 	return 0;
@@ -207,7 +207,7 @@ int __fscache_attr_changed(struct fscach
 nobufs:
 	spin_unlock(&cookie->lock);
 	kfree(op);
-	fscache_stat(&fscache_n_attr_changed_nobufs);
+	fscache_stat_unchecked(&fscache_n_attr_changed_nobufs);
 	_leave(" = %d", -ENOBUFS);
 	return -ENOBUFS;
 }
@@ -243,7 +243,7 @@ static struct fscache_retrieval *fscache
 	/* allocate a retrieval operation and attempt to submit it */
 	op = kzalloc(sizeof(*op), GFP_NOIO);
 	if (!op) {
-		fscache_stat(&fscache_n_retrievals_nomem);
+		fscache_stat_unchecked(&fscache_n_retrievals_nomem);
 		return NULL;
 	}
 
@@ -271,13 +271,13 @@ static int fscache_wait_for_deferred_loo
 		return 0;
 	}
 
-	fscache_stat(&fscache_n_retrievals_wait);
+	fscache_stat_unchecked(&fscache_n_retrievals_wait);
 
 	jif = jiffies;
 	if (wait_on_bit(&cookie->flags, FSCACHE_COOKIE_LOOKING_UP,
 			fscache_wait_bit_interruptible,
 			TASK_INTERRUPTIBLE) != 0) {
-		fscache_stat(&fscache_n_retrievals_intr);
+		fscache_stat_unchecked(&fscache_n_retrievals_intr);
 		_leave(" = -ERESTARTSYS");
 		return -ERESTARTSYS;
 	}
@@ -295,8 +295,8 @@ static int fscache_wait_for_deferred_loo
  */
 static int fscache_wait_for_retrieval_activation(struct fscache_object *object,
 						 struct fscache_retrieval *op,
-						 atomic_t *stat_op_waits,
-						 atomic_t *stat_object_dead)
+						 atomic_unchecked_t *stat_op_waits,
+						 atomic_unchecked_t *stat_object_dead)
 {
 	int ret;
 
@@ -304,7 +304,7 @@ static int fscache_wait_for_retrieval_ac
 		goto check_if_dead;
 
 	_debug(">>> WT");
-	fscache_stat(stat_op_waits);
+	fscache_stat_unchecked(stat_op_waits);
 	if (wait_on_bit(&op->op.flags, FSCACHE_OP_WAITING,
 			fscache_wait_bit_interruptible,
 			TASK_INTERRUPTIBLE) < 0) {
@@ -321,7 +321,7 @@ static int fscache_wait_for_retrieval_ac
 
 check_if_dead:
 	if (unlikely(fscache_object_is_dead(object))) {
-		fscache_stat(stat_object_dead);
+		fscache_stat_unchecked(stat_object_dead);
 		return -ENOBUFS;
 	}
 	return 0;
@@ -348,7 +348,7 @@ int __fscache_read_or_alloc_page(struct
 
 	_enter("%p,%p,,,", cookie, page);
 
-	fscache_stat(&fscache_n_retrievals);
+	fscache_stat_unchecked(&fscache_n_retrievals);
 
 	if (hlist_empty(&cookie->backing_objects))
 		goto nobufs;
@@ -381,7 +381,7 @@ int __fscache_read_or_alloc_page(struct
 		goto nobufs_unlock;
 	spin_unlock(&cookie->lock);
 
-	fscache_stat(&fscache_n_retrieval_ops);
+	fscache_stat_unchecked(&fscache_n_retrieval_ops);
 
 	/* pin the netfs read context in case we need to do the actual netfs
 	 * read because we've encountered a cache read failure */
@@ -411,15 +411,15 @@ int __fscache_read_or_alloc_page(struct
 
 error:
 	if (ret == -ENOMEM)
-		fscache_stat(&fscache_n_retrievals_nomem);
+		fscache_stat_unchecked(&fscache_n_retrievals_nomem);
 	else if (ret == -ERESTARTSYS)
-		fscache_stat(&fscache_n_retrievals_intr);
+		fscache_stat_unchecked(&fscache_n_retrievals_intr);
 	else if (ret == -ENODATA)
-		fscache_stat(&fscache_n_retrievals_nodata);
+		fscache_stat_unchecked(&fscache_n_retrievals_nodata);
 	else if (ret < 0)
-		fscache_stat(&fscache_n_retrievals_nobufs);
+		fscache_stat_unchecked(&fscache_n_retrievals_nobufs);
 	else
-		fscache_stat(&fscache_n_retrievals_ok);
+		fscache_stat_unchecked(&fscache_n_retrievals_ok);
 
 	fscache_put_retrieval(op);
 	_leave(" = %d", ret);
@@ -429,7 +429,7 @@ nobufs_unlock:
 	spin_unlock(&cookie->lock);
 	kfree(op);
 nobufs:
-	fscache_stat(&fscache_n_retrievals_nobufs);
+	fscache_stat_unchecked(&fscache_n_retrievals_nobufs);
 	_leave(" = -ENOBUFS");
 	return -ENOBUFS;
 }
@@ -467,7 +467,7 @@ int __fscache_read_or_alloc_pages(struct
 
 	_enter("%p,,%d,,,", cookie, *nr_pages);
 
-	fscache_stat(&fscache_n_retrievals);
+	fscache_stat_unchecked(&fscache_n_retrievals);
 
 	if (hlist_empty(&cookie->backing_objects))
 		goto nobufs;
@@ -497,7 +497,7 @@ int __fscache_read_or_alloc_pages(struct
 		goto nobufs_unlock;
 	spin_unlock(&cookie->lock);
 
-	fscache_stat(&fscache_n_retrieval_ops);
+	fscache_stat_unchecked(&fscache_n_retrieval_ops);
 
 	/* pin the netfs read context in case we need to do the actual netfs
 	 * read because we've encountered a cache read failure */
@@ -527,15 +527,15 @@ int __fscache_read_or_alloc_pages(struct
 
 error:
 	if (ret == -ENOMEM)
-		fscache_stat(&fscache_n_retrievals_nomem);
+		fscache_stat_unchecked(&fscache_n_retrievals_nomem);
 	else if (ret == -ERESTARTSYS)
-		fscache_stat(&fscache_n_retrievals_intr);
+		fscache_stat_unchecked(&fscache_n_retrievals_intr);
 	else if (ret == -ENODATA)
-		fscache_stat(&fscache_n_retrievals_nodata);
+		fscache_stat_unchecked(&fscache_n_retrievals_nodata);
 	else if (ret < 0)
-		fscache_stat(&fscache_n_retrievals_nobufs);
+		fscache_stat_unchecked(&fscache_n_retrievals_nobufs);
 	else
-		fscache_stat(&fscache_n_retrievals_ok);
+		fscache_stat_unchecked(&fscache_n_retrievals_ok);
 
 	fscache_put_retrieval(op);
 	_leave(" = %d", ret);
@@ -545,7 +545,7 @@ nobufs_unlock:
 	spin_unlock(&cookie->lock);
 	kfree(op);
 nobufs:
-	fscache_stat(&fscache_n_retrievals_nobufs);
+	fscache_stat_unchecked(&fscache_n_retrievals_nobufs);
 	_leave(" = -ENOBUFS");
 	return -ENOBUFS;
 }
@@ -569,7 +569,7 @@ int __fscache_alloc_page(struct fscache_
 
 	_enter("%p,%p,,,", cookie, page);
 
-	fscache_stat(&fscache_n_allocs);
+	fscache_stat_unchecked(&fscache_n_allocs);
 
 	if (hlist_empty(&cookie->backing_objects))
 		goto nobufs;
@@ -595,7 +595,7 @@ int __fscache_alloc_page(struct fscache_
 		goto nobufs_unlock;
 	spin_unlock(&cookie->lock);
 
-	fscache_stat(&fscache_n_alloc_ops);
+	fscache_stat_unchecked(&fscache_n_alloc_ops);
 
 	ret = fscache_wait_for_retrieval_activation(
 		object, op,
@@ -611,11 +611,11 @@ int __fscache_alloc_page(struct fscache_
 
 error:
 	if (ret == -ERESTARTSYS)
-		fscache_stat(&fscache_n_allocs_intr);
+		fscache_stat_unchecked(&fscache_n_allocs_intr);
 	else if (ret < 0)
-		fscache_stat(&fscache_n_allocs_nobufs);
+		fscache_stat_unchecked(&fscache_n_allocs_nobufs);
 	else
-		fscache_stat(&fscache_n_allocs_ok);
+		fscache_stat_unchecked(&fscache_n_allocs_ok);
 
 	fscache_put_retrieval(op);
 	_leave(" = %d", ret);
@@ -625,7 +625,7 @@ nobufs_unlock:
 	spin_unlock(&cookie->lock);
 	kfree(op);
 nobufs:
-	fscache_stat(&fscache_n_allocs_nobufs);
+	fscache_stat_unchecked(&fscache_n_allocs_nobufs);
 	_leave(" = -ENOBUFS");
 	return -ENOBUFS;
 }
@@ -666,7 +666,7 @@ static void fscache_write_op(struct fsca
 
 	spin_lock(&cookie->stores_lock);
 
-	fscache_stat(&fscache_n_store_calls);
+	fscache_stat_unchecked(&fscache_n_store_calls);
 
 	/* find a page to store */
 	page = NULL;
@@ -677,7 +677,7 @@ static void fscache_write_op(struct fsca
 	page = results[0];
 	_debug("gang %d [%lx]", n, page->index);
 	if (page->index > op->store_limit) {
-		fscache_stat(&fscache_n_store_pages_over_limit);
+		fscache_stat_unchecked(&fscache_n_store_pages_over_limit);
 		goto superseded;
 	}
 
@@ -689,7 +689,7 @@ static void fscache_write_op(struct fsca
 	spin_unlock(&cookie->stores_lock);
 	spin_unlock(&object->lock);
 
-	fscache_stat(&fscache_n_store_pages);
+	fscache_stat_unchecked(&fscache_n_store_pages);
 	fscache_stat(&fscache_n_cop_write_page);
 	ret = object->cache->ops->write_page(op, page);
 	fscache_stat_d(&fscache_n_cop_write_page);
@@ -757,7 +757,7 @@ int __fscache_write_page(struct fscache_
 	ASSERTCMP(cookie->def->type, !=, FSCACHE_COOKIE_TYPE_INDEX);
 	ASSERT(PageFsCache(page));
 
-	fscache_stat(&fscache_n_stores);
+	fscache_stat_unchecked(&fscache_n_stores);
 
 	op = kzalloc(sizeof(*op), GFP_NOIO);
 	if (!op)
@@ -808,7 +808,7 @@ int __fscache_write_page(struct fscache_
 	spin_unlock(&cookie->stores_lock);
 	spin_unlock(&object->lock);
 
-	op->op.debug_id	= atomic_inc_return(&fscache_op_debug_id);
+	op->op.debug_id	= atomic_inc_return_unchecked(&fscache_op_debug_id);
 	op->store_limit = object->store_limit;
 
 	if (fscache_submit_op(object, &op->op) < 0)
@@ -816,8 +816,8 @@ int __fscache_write_page(struct fscache_
 
 	spin_unlock(&cookie->lock);
 	radix_tree_preload_end();
-	fscache_stat(&fscache_n_store_ops);
-	fscache_stat(&fscache_n_stores_ok);
+	fscache_stat_unchecked(&fscache_n_store_ops);
+	fscache_stat_unchecked(&fscache_n_stores_ok);
 
 	/* the work queue now carries its own ref on the object */
 	fscache_put_operation(&op->op);
@@ -825,14 +825,14 @@ int __fscache_write_page(struct fscache_
 	return 0;
 
 already_queued:
-	fscache_stat(&fscache_n_stores_again);
+	fscache_stat_unchecked(&fscache_n_stores_again);
 already_pending:
 	spin_unlock(&cookie->stores_lock);
 	spin_unlock(&object->lock);
 	spin_unlock(&cookie->lock);
 	radix_tree_preload_end();
 	kfree(op);
-	fscache_stat(&fscache_n_stores_ok);
+	fscache_stat_unchecked(&fscache_n_stores_ok);
 	_leave(" = 0");
 	return 0;
 
@@ -851,14 +851,14 @@ nobufs:
 	spin_unlock(&cookie->lock);
 	radix_tree_preload_end();
 	kfree(op);
-	fscache_stat(&fscache_n_stores_nobufs);
+	fscache_stat_unchecked(&fscache_n_stores_nobufs);
 	_leave(" = -ENOBUFS");
 	return -ENOBUFS;
 
 nomem_free:
 	kfree(op);
 nomem:
-	fscache_stat(&fscache_n_stores_oom);
+	fscache_stat_unchecked(&fscache_n_stores_oom);
 	_leave(" = -ENOMEM");
 	return -ENOMEM;
 }
@@ -876,7 +876,7 @@ void __fscache_uncache_page(struct fscac
 	ASSERTCMP(cookie->def->type, !=, FSCACHE_COOKIE_TYPE_INDEX);
 	ASSERTCMP(page, !=, NULL);
 
-	fscache_stat(&fscache_n_uncaches);
+	fscache_stat_unchecked(&fscache_n_uncaches);
 
 	/* cache withdrawal may beat us to it */
 	if (!PageFsCache(page))
@@ -929,7 +929,7 @@ void fscache_mark_pages_cached(struct fs
 	unsigned long loop;
 
 #ifdef CONFIG_FSCACHE_STATS
-	atomic_add(pagevec->nr, &fscache_n_marks);
+	atomic_add_unchecked(pagevec->nr, &fscache_n_marks);
 #endif
 
 	for (loop = 0; loop < pagevec->nr; loop++) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/fscache/stats.c linux-3.2.71-pax/fs/fscache/stats.c
--- linux-3.2.71/fs/fscache/stats.c	2013-05-14 13:33:40.648285671 +0200
+++ linux-3.2.71-pax/fs/fscache/stats.c	2013-05-14 13:33:46.580285354 +0200
@@ -18,95 +18,95 @@
 /*
  * operation counters
  */
-atomic_t fscache_n_op_pend;
-atomic_t fscache_n_op_run;
-atomic_t fscache_n_op_enqueue;
-atomic_t fscache_n_op_requeue;
-atomic_t fscache_n_op_deferred_release;
-atomic_t fscache_n_op_release;
-atomic_t fscache_n_op_gc;
-atomic_t fscache_n_op_cancelled;
-atomic_t fscache_n_op_rejected;
-
-atomic_t fscache_n_attr_changed;
-atomic_t fscache_n_attr_changed_ok;
-atomic_t fscache_n_attr_changed_nobufs;
-atomic_t fscache_n_attr_changed_nomem;
-atomic_t fscache_n_attr_changed_calls;
-
-atomic_t fscache_n_allocs;
-atomic_t fscache_n_allocs_ok;
-atomic_t fscache_n_allocs_wait;
-atomic_t fscache_n_allocs_nobufs;
-atomic_t fscache_n_allocs_intr;
-atomic_t fscache_n_allocs_object_dead;
-atomic_t fscache_n_alloc_ops;
-atomic_t fscache_n_alloc_op_waits;
-
-atomic_t fscache_n_retrievals;
-atomic_t fscache_n_retrievals_ok;
-atomic_t fscache_n_retrievals_wait;
-atomic_t fscache_n_retrievals_nodata;
-atomic_t fscache_n_retrievals_nobufs;
-atomic_t fscache_n_retrievals_intr;
-atomic_t fscache_n_retrievals_nomem;
-atomic_t fscache_n_retrievals_object_dead;
-atomic_t fscache_n_retrieval_ops;
-atomic_t fscache_n_retrieval_op_waits;
-
-atomic_t fscache_n_stores;
-atomic_t fscache_n_stores_ok;
-atomic_t fscache_n_stores_again;
-atomic_t fscache_n_stores_nobufs;
-atomic_t fscache_n_stores_oom;
-atomic_t fscache_n_store_ops;
-atomic_t fscache_n_store_calls;
-atomic_t fscache_n_store_pages;
-atomic_t fscache_n_store_radix_deletes;
-atomic_t fscache_n_store_pages_over_limit;
-
-atomic_t fscache_n_store_vmscan_not_storing;
-atomic_t fscache_n_store_vmscan_gone;
-atomic_t fscache_n_store_vmscan_busy;
-atomic_t fscache_n_store_vmscan_cancelled;
-
-atomic_t fscache_n_marks;
-atomic_t fscache_n_uncaches;
-
-atomic_t fscache_n_acquires;
-atomic_t fscache_n_acquires_null;
-atomic_t fscache_n_acquires_no_cache;
-atomic_t fscache_n_acquires_ok;
-atomic_t fscache_n_acquires_nobufs;
-atomic_t fscache_n_acquires_oom;
-
-atomic_t fscache_n_updates;
-atomic_t fscache_n_updates_null;
-atomic_t fscache_n_updates_run;
-
-atomic_t fscache_n_relinquishes;
-atomic_t fscache_n_relinquishes_null;
-atomic_t fscache_n_relinquishes_waitcrt;
-atomic_t fscache_n_relinquishes_retire;
-
-atomic_t fscache_n_cookie_index;
-atomic_t fscache_n_cookie_data;
-atomic_t fscache_n_cookie_special;
-
-atomic_t fscache_n_object_alloc;
-atomic_t fscache_n_object_no_alloc;
-atomic_t fscache_n_object_lookups;
-atomic_t fscache_n_object_lookups_negative;
-atomic_t fscache_n_object_lookups_positive;
-atomic_t fscache_n_object_lookups_timed_out;
-atomic_t fscache_n_object_created;
-atomic_t fscache_n_object_avail;
-atomic_t fscache_n_object_dead;
-
-atomic_t fscache_n_checkaux_none;
-atomic_t fscache_n_checkaux_okay;
-atomic_t fscache_n_checkaux_update;
-atomic_t fscache_n_checkaux_obsolete;
+atomic_unchecked_t fscache_n_op_pend;
+atomic_unchecked_t fscache_n_op_run;
+atomic_unchecked_t fscache_n_op_enqueue;
+atomic_unchecked_t fscache_n_op_requeue;
+atomic_unchecked_t fscache_n_op_deferred_release;
+atomic_unchecked_t fscache_n_op_release;
+atomic_unchecked_t fscache_n_op_gc;
+atomic_unchecked_t fscache_n_op_cancelled;
+atomic_unchecked_t fscache_n_op_rejected;
+
+atomic_unchecked_t fscache_n_attr_changed;
+atomic_unchecked_t fscache_n_attr_changed_ok;
+atomic_unchecked_t fscache_n_attr_changed_nobufs;
+atomic_unchecked_t fscache_n_attr_changed_nomem;
+atomic_unchecked_t fscache_n_attr_changed_calls;
+
+atomic_unchecked_t fscache_n_allocs;
+atomic_unchecked_t fscache_n_allocs_ok;
+atomic_unchecked_t fscache_n_allocs_wait;
+atomic_unchecked_t fscache_n_allocs_nobufs;
+atomic_unchecked_t fscache_n_allocs_intr;
+atomic_unchecked_t fscache_n_allocs_object_dead;
+atomic_unchecked_t fscache_n_alloc_ops;
+atomic_unchecked_t fscache_n_alloc_op_waits;
+
+atomic_unchecked_t fscache_n_retrievals;
+atomic_unchecked_t fscache_n_retrievals_ok;
+atomic_unchecked_t fscache_n_retrievals_wait;
+atomic_unchecked_t fscache_n_retrievals_nodata;
+atomic_unchecked_t fscache_n_retrievals_nobufs;
+atomic_unchecked_t fscache_n_retrievals_intr;
+atomic_unchecked_t fscache_n_retrievals_nomem;
+atomic_unchecked_t fscache_n_retrievals_object_dead;
+atomic_unchecked_t fscache_n_retrieval_ops;
+atomic_unchecked_t fscache_n_retrieval_op_waits;
+
+atomic_unchecked_t fscache_n_stores;
+atomic_unchecked_t fscache_n_stores_ok;
+atomic_unchecked_t fscache_n_stores_again;
+atomic_unchecked_t fscache_n_stores_nobufs;
+atomic_unchecked_t fscache_n_stores_oom;
+atomic_unchecked_t fscache_n_store_ops;
+atomic_unchecked_t fscache_n_store_calls;
+atomic_unchecked_t fscache_n_store_pages;
+atomic_unchecked_t fscache_n_store_radix_deletes;
+atomic_unchecked_t fscache_n_store_pages_over_limit;
+
+atomic_unchecked_t fscache_n_store_vmscan_not_storing;
+atomic_unchecked_t fscache_n_store_vmscan_gone;
+atomic_unchecked_t fscache_n_store_vmscan_busy;
+atomic_unchecked_t fscache_n_store_vmscan_cancelled;
+
+atomic_unchecked_t fscache_n_marks;
+atomic_unchecked_t fscache_n_uncaches;
+
+atomic_unchecked_t fscache_n_acquires;
+atomic_unchecked_t fscache_n_acquires_null;
+atomic_unchecked_t fscache_n_acquires_no_cache;
+atomic_unchecked_t fscache_n_acquires_ok;
+atomic_unchecked_t fscache_n_acquires_nobufs;
+atomic_unchecked_t fscache_n_acquires_oom;
+
+atomic_unchecked_t fscache_n_updates;
+atomic_unchecked_t fscache_n_updates_null;
+atomic_unchecked_t fscache_n_updates_run;
+
+atomic_unchecked_t fscache_n_relinquishes;
+atomic_unchecked_t fscache_n_relinquishes_null;
+atomic_unchecked_t fscache_n_relinquishes_waitcrt;
+atomic_unchecked_t fscache_n_relinquishes_retire;
+
+atomic_unchecked_t fscache_n_cookie_index;
+atomic_unchecked_t fscache_n_cookie_data;
+atomic_unchecked_t fscache_n_cookie_special;
+
+atomic_unchecked_t fscache_n_object_alloc;
+atomic_unchecked_t fscache_n_object_no_alloc;
+atomic_unchecked_t fscache_n_object_lookups;
+atomic_unchecked_t fscache_n_object_lookups_negative;
+atomic_unchecked_t fscache_n_object_lookups_positive;
+atomic_unchecked_t fscache_n_object_lookups_timed_out;
+atomic_unchecked_t fscache_n_object_created;
+atomic_unchecked_t fscache_n_object_avail;
+atomic_unchecked_t fscache_n_object_dead;
+
+atomic_unchecked_t fscache_n_checkaux_none;
+atomic_unchecked_t fscache_n_checkaux_okay;
+atomic_unchecked_t fscache_n_checkaux_update;
+atomic_unchecked_t fscache_n_checkaux_obsolete;
 
 atomic_t fscache_n_cop_alloc_object;
 atomic_t fscache_n_cop_lookup_object;
@@ -133,113 +133,113 @@ static int fscache_stats_show(struct seq
 	seq_puts(m, "FS-Cache statistics\n");
 
 	seq_printf(m, "Cookies: idx=%u dat=%u spc=%u\n",
-		   atomic_read(&fscache_n_cookie_index),
-		   atomic_read(&fscache_n_cookie_data),
-		   atomic_read(&fscache_n_cookie_special));
+		   atomic_read_unchecked(&fscache_n_cookie_index),
+		   atomic_read_unchecked(&fscache_n_cookie_data),
+		   atomic_read_unchecked(&fscache_n_cookie_special));
 
 	seq_printf(m, "Objects: alc=%u nal=%u avl=%u ded=%u\n",
-		   atomic_read(&fscache_n_object_alloc),
-		   atomic_read(&fscache_n_object_no_alloc),
-		   atomic_read(&fscache_n_object_avail),
-		   atomic_read(&fscache_n_object_dead));
+		   atomic_read_unchecked(&fscache_n_object_alloc),
+		   atomic_read_unchecked(&fscache_n_object_no_alloc),
+		   atomic_read_unchecked(&fscache_n_object_avail),
+		   atomic_read_unchecked(&fscache_n_object_dead));
 	seq_printf(m, "ChkAux : non=%u ok=%u upd=%u obs=%u\n",
-		   atomic_read(&fscache_n_checkaux_none),
-		   atomic_read(&fscache_n_checkaux_okay),
-		   atomic_read(&fscache_n_checkaux_update),
-		   atomic_read(&fscache_n_checkaux_obsolete));
+		   atomic_read_unchecked(&fscache_n_checkaux_none),
+		   atomic_read_unchecked(&fscache_n_checkaux_okay),
+		   atomic_read_unchecked(&fscache_n_checkaux_update),
+		   atomic_read_unchecked(&fscache_n_checkaux_obsolete));
 
 	seq_printf(m, "Pages  : mrk=%u unc=%u\n",
-		   atomic_read(&fscache_n_marks),
-		   atomic_read(&fscache_n_uncaches));
+		   atomic_read_unchecked(&fscache_n_marks),
+		   atomic_read_unchecked(&fscache_n_uncaches));
 
 	seq_printf(m, "Acquire: n=%u nul=%u noc=%u ok=%u nbf=%u"
 		   " oom=%u\n",
-		   atomic_read(&fscache_n_acquires),
-		   atomic_read(&fscache_n_acquires_null),
-		   atomic_read(&fscache_n_acquires_no_cache),
-		   atomic_read(&fscache_n_acquires_ok),
-		   atomic_read(&fscache_n_acquires_nobufs),
-		   atomic_read(&fscache_n_acquires_oom));
+		   atomic_read_unchecked(&fscache_n_acquires),
+		   atomic_read_unchecked(&fscache_n_acquires_null),
+		   atomic_read_unchecked(&fscache_n_acquires_no_cache),
+		   atomic_read_unchecked(&fscache_n_acquires_ok),
+		   atomic_read_unchecked(&fscache_n_acquires_nobufs),
+		   atomic_read_unchecked(&fscache_n_acquires_oom));
 
 	seq_printf(m, "Lookups: n=%u neg=%u pos=%u crt=%u tmo=%u\n",
-		   atomic_read(&fscache_n_object_lookups),
-		   atomic_read(&fscache_n_object_lookups_negative),
-		   atomic_read(&fscache_n_object_lookups_positive),
-		   atomic_read(&fscache_n_object_created),
-		   atomic_read(&fscache_n_object_lookups_timed_out));
+		   atomic_read_unchecked(&fscache_n_object_lookups),
+		   atomic_read_unchecked(&fscache_n_object_lookups_negative),
+		   atomic_read_unchecked(&fscache_n_object_lookups_positive),
+		   atomic_read_unchecked(&fscache_n_object_created),
+		   atomic_read_unchecked(&fscache_n_object_lookups_timed_out));
 
 	seq_printf(m, "Updates: n=%u nul=%u run=%u\n",
-		   atomic_read(&fscache_n_updates),
-		   atomic_read(&fscache_n_updates_null),
-		   atomic_read(&fscache_n_updates_run));
+		   atomic_read_unchecked(&fscache_n_updates),
+		   atomic_read_unchecked(&fscache_n_updates_null),
+		   atomic_read_unchecked(&fscache_n_updates_run));
 
 	seq_printf(m, "Relinqs: n=%u nul=%u wcr=%u rtr=%u\n",
-		   atomic_read(&fscache_n_relinquishes),
-		   atomic_read(&fscache_n_relinquishes_null),
-		   atomic_read(&fscache_n_relinquishes_waitcrt),
-		   atomic_read(&fscache_n_relinquishes_retire));
+		   atomic_read_unchecked(&fscache_n_relinquishes),
+		   atomic_read_unchecked(&fscache_n_relinquishes_null),
+		   atomic_read_unchecked(&fscache_n_relinquishes_waitcrt),
+		   atomic_read_unchecked(&fscache_n_relinquishes_retire));
 
 	seq_printf(m, "AttrChg: n=%u ok=%u nbf=%u oom=%u run=%u\n",
-		   atomic_read(&fscache_n_attr_changed),
-		   atomic_read(&fscache_n_attr_changed_ok),
-		   atomic_read(&fscache_n_attr_changed_nobufs),
-		   atomic_read(&fscache_n_attr_changed_nomem),
-		   atomic_read(&fscache_n_attr_changed_calls));
+		   atomic_read_unchecked(&fscache_n_attr_changed),
+		   atomic_read_unchecked(&fscache_n_attr_changed_ok),
+		   atomic_read_unchecked(&fscache_n_attr_changed_nobufs),
+		   atomic_read_unchecked(&fscache_n_attr_changed_nomem),
+		   atomic_read_unchecked(&fscache_n_attr_changed_calls));
 
 	seq_printf(m, "Allocs : n=%u ok=%u wt=%u nbf=%u int=%u\n",
-		   atomic_read(&fscache_n_allocs),
-		   atomic_read(&fscache_n_allocs_ok),
-		   atomic_read(&fscache_n_allocs_wait),
-		   atomic_read(&fscache_n_allocs_nobufs),
-		   atomic_read(&fscache_n_allocs_intr));
+		   atomic_read_unchecked(&fscache_n_allocs),
+		   atomic_read_unchecked(&fscache_n_allocs_ok),
+		   atomic_read_unchecked(&fscache_n_allocs_wait),
+		   atomic_read_unchecked(&fscache_n_allocs_nobufs),
+		   atomic_read_unchecked(&fscache_n_allocs_intr));
 	seq_printf(m, "Allocs : ops=%u owt=%u abt=%u\n",
-		   atomic_read(&fscache_n_alloc_ops),
-		   atomic_read(&fscache_n_alloc_op_waits),
-		   atomic_read(&fscache_n_allocs_object_dead));
+		   atomic_read_unchecked(&fscache_n_alloc_ops),
+		   atomic_read_unchecked(&fscache_n_alloc_op_waits),
+		   atomic_read_unchecked(&fscache_n_allocs_object_dead));
 
 	seq_printf(m, "Retrvls: n=%u ok=%u wt=%u nod=%u nbf=%u"
 		   " int=%u oom=%u\n",
-		   atomic_read(&fscache_n_retrievals),
-		   atomic_read(&fscache_n_retrievals_ok),
-		   atomic_read(&fscache_n_retrievals_wait),
-		   atomic_read(&fscache_n_retrievals_nodata),
-		   atomic_read(&fscache_n_retrievals_nobufs),
-		   atomic_read(&fscache_n_retrievals_intr),
-		   atomic_read(&fscache_n_retrievals_nomem));
+		   atomic_read_unchecked(&fscache_n_retrievals),
+		   atomic_read_unchecked(&fscache_n_retrievals_ok),
+		   atomic_read_unchecked(&fscache_n_retrievals_wait),
+		   atomic_read_unchecked(&fscache_n_retrievals_nodata),
+		   atomic_read_unchecked(&fscache_n_retrievals_nobufs),
+		   atomic_read_unchecked(&fscache_n_retrievals_intr),
+		   atomic_read_unchecked(&fscache_n_retrievals_nomem));
 	seq_printf(m, "Retrvls: ops=%u owt=%u abt=%u\n",
-		   atomic_read(&fscache_n_retrieval_ops),
-		   atomic_read(&fscache_n_retrieval_op_waits),
-		   atomic_read(&fscache_n_retrievals_object_dead));
+		   atomic_read_unchecked(&fscache_n_retrieval_ops),
+		   atomic_read_unchecked(&fscache_n_retrieval_op_waits),
+		   atomic_read_unchecked(&fscache_n_retrievals_object_dead));
 
 	seq_printf(m, "Stores : n=%u ok=%u agn=%u nbf=%u oom=%u\n",
-		   atomic_read(&fscache_n_stores),
-		   atomic_read(&fscache_n_stores_ok),
-		   atomic_read(&fscache_n_stores_again),
-		   atomic_read(&fscache_n_stores_nobufs),
-		   atomic_read(&fscache_n_stores_oom));
+		   atomic_read_unchecked(&fscache_n_stores),
+		   atomic_read_unchecked(&fscache_n_stores_ok),
+		   atomic_read_unchecked(&fscache_n_stores_again),
+		   atomic_read_unchecked(&fscache_n_stores_nobufs),
+		   atomic_read_unchecked(&fscache_n_stores_oom));
 	seq_printf(m, "Stores : ops=%u run=%u pgs=%u rxd=%u olm=%u\n",
-		   atomic_read(&fscache_n_store_ops),
-		   atomic_read(&fscache_n_store_calls),
-		   atomic_read(&fscache_n_store_pages),
-		   atomic_read(&fscache_n_store_radix_deletes),
-		   atomic_read(&fscache_n_store_pages_over_limit));
+		   atomic_read_unchecked(&fscache_n_store_ops),
+		   atomic_read_unchecked(&fscache_n_store_calls),
+		   atomic_read_unchecked(&fscache_n_store_pages),
+		   atomic_read_unchecked(&fscache_n_store_radix_deletes),
+		   atomic_read_unchecked(&fscache_n_store_pages_over_limit));
 
 	seq_printf(m, "VmScan : nos=%u gon=%u bsy=%u can=%u\n",
-		   atomic_read(&fscache_n_store_vmscan_not_storing),
-		   atomic_read(&fscache_n_store_vmscan_gone),
-		   atomic_read(&fscache_n_store_vmscan_busy),
-		   atomic_read(&fscache_n_store_vmscan_cancelled));
+		   atomic_read_unchecked(&fscache_n_store_vmscan_not_storing),
+		   atomic_read_unchecked(&fscache_n_store_vmscan_gone),
+		   atomic_read_unchecked(&fscache_n_store_vmscan_busy),
+		   atomic_read_unchecked(&fscache_n_store_vmscan_cancelled));
 
 	seq_printf(m, "Ops    : pend=%u run=%u enq=%u can=%u rej=%u\n",
-		   atomic_read(&fscache_n_op_pend),
-		   atomic_read(&fscache_n_op_run),
-		   atomic_read(&fscache_n_op_enqueue),
-		   atomic_read(&fscache_n_op_cancelled),
-		   atomic_read(&fscache_n_op_rejected));
+		   atomic_read_unchecked(&fscache_n_op_pend),
+		   atomic_read_unchecked(&fscache_n_op_run),
+		   atomic_read_unchecked(&fscache_n_op_enqueue),
+		   atomic_read_unchecked(&fscache_n_op_cancelled),
+		   atomic_read_unchecked(&fscache_n_op_rejected));
 	seq_printf(m, "Ops    : dfr=%u rel=%u gc=%u\n",
-		   atomic_read(&fscache_n_op_deferred_release),
-		   atomic_read(&fscache_n_op_release),
-		   atomic_read(&fscache_n_op_gc));
+		   atomic_read_unchecked(&fscache_n_op_deferred_release),
+		   atomic_read_unchecked(&fscache_n_op_release),
+		   atomic_read_unchecked(&fscache_n_op_gc));
 
 	seq_printf(m, "CacheOp: alo=%d luo=%d luc=%d gro=%d\n",
 		   atomic_read(&fscache_n_cop_alloc_object),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/fs_struct.c linux-3.2.71-pax/fs/fs_struct.c
--- linux-3.2.71/fs/fs_struct.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/fs_struct.c	2012-07-04 19:24:48.700063008 +0200
@@ -109,7 +109,7 @@ void exit_fs(struct task_struct *tsk)
 		spin_lock(&fs->lock);
 		write_seqcount_begin(&fs->seq);
 		tsk->fs = NULL;
-		kill = !--fs->users;
+		kill = !atomic_dec_return(&fs->users);
 		write_seqcount_end(&fs->seq);
 		spin_unlock(&fs->lock);
 		task_unlock(tsk);
@@ -123,7 +123,7 @@ struct fs_struct *copy_fs_struct(struct
 	struct fs_struct *fs = kmem_cache_alloc(fs_cachep, GFP_KERNEL);
 	/* We don't need to lock fs - think why ;-) */
 	if (fs) {
-		fs->users = 1;
+		atomic_set(&fs->users, 1);
 		fs->in_exec = 0;
 		spin_lock_init(&fs->lock);
 		seqcount_init(&fs->seq);
@@ -150,7 +150,7 @@ int unshare_fs_struct(void)
 
 	task_lock(current);
 	spin_lock(&fs->lock);
-	kill = !--fs->users;
+	kill = !atomic_dec_return(&fs->users);
 	current->fs = new_fs;
 	spin_unlock(&fs->lock);
 	task_unlock(current);
@@ -170,7 +170,7 @@ EXPORT_SYMBOL(current_umask);
 
 /* to be mentioned only in INIT_TASK */
 struct fs_struct init_fs = {
-	.users		= 1,
+	.users		= ATOMIC_INIT(1),
 	.lock		= __SPIN_LOCK_UNLOCKED(init_fs.lock),
 	.seq		= SEQCNT_ZERO,
 	.umask		= 0022,
@@ -186,12 +186,12 @@ void daemonize_fs_struct(void)
 		task_lock(current);
 
 		spin_lock(&init_fs.lock);
-		init_fs.users++;
+		atomic_inc(&init_fs.users);
 		spin_unlock(&init_fs.lock);
 
 		spin_lock(&fs->lock);
 		current->fs = &init_fs;
-		kill = !--fs->users;
+		kill = !atomic_dec_return(&fs->users);
 		spin_unlock(&fs->lock);
 
 		task_unlock(current);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/fuse/cuse.c linux-3.2.71-pax/fs/fuse/cuse.c
--- linux-3.2.71/fs/fuse/cuse.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/fuse/cuse.c	2012-07-04 19:24:48.700063008 +0200
@@ -587,10 +587,12 @@ static int __init cuse_init(void)
 		INIT_LIST_HEAD(&cuse_conntbl[i]);
 
 	/* inherit and extend fuse_dev_operations */
-	cuse_channel_fops		= fuse_dev_operations;
-	cuse_channel_fops.owner		= THIS_MODULE;
-	cuse_channel_fops.open		= cuse_channel_open;
-	cuse_channel_fops.release	= cuse_channel_release;
+	pax_open_kernel();
+	memcpy((void *)&cuse_channel_fops, &fuse_dev_operations, sizeof(fuse_dev_operations));
+	*(void **)&cuse_channel_fops.owner	= THIS_MODULE;
+	*(void **)&cuse_channel_fops.open	= cuse_channel_open;
+	*(void **)&cuse_channel_fops.release	= cuse_channel_release;
+	pax_close_kernel();
 
 	cuse_class = class_create(THIS_MODULE, "cuse");
 	if (IS_ERR(cuse_class))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/fuse/dev.c linux-3.2.71-pax/fs/fuse/dev.c
--- linux-3.2.71/fs/fuse/dev.c	2015-05-10 09:22:38.751493122 +0200
+++ linux-3.2.71-pax/fs/fuse/dev.c	2015-05-10 09:23:09.459494789 +0200
@@ -1226,7 +1226,7 @@ static ssize_t fuse_dev_splice_read(stru
 	ret = 0;
 	pipe_lock(pipe);
 
-	if (!pipe->readers) {
+	if (!atomic_read(&pipe->readers)) {
 		send_sig(SIGPIPE, current, 0);
 		if (!ret)
 			ret = -EPIPE;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/fuse/dir.c linux-3.2.71-pax/fs/fuse/dir.c
--- linux-3.2.71/fs/fuse/dir.c	2014-08-06 23:17:21.609614202 +0200
+++ linux-3.2.71-pax/fs/fuse/dir.c	2014-08-06 23:17:26.369614192 +0200
@@ -1150,7 +1150,7 @@ static char *read_link(struct dentry *de
 	return link;
 }
 
-static void free_link(char *link)
+static void free_link(const char *link)
 {
 	if (!IS_ERR(link))
 		free_page((unsigned long) link);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/gfs2/inode.c linux-3.2.71-pax/fs/gfs2/inode.c
--- linux-3.2.71/fs/gfs2/inode.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/gfs2/inode.c	2012-07-04 19:24:48.700063008 +0200
@@ -1490,7 +1490,7 @@ out:
 
 static void gfs2_put_link(struct dentry *dentry, struct nameidata *nd, void *p)
 {
-	char *s = nd_get_link(nd);
+	const char *s = nd_get_link(nd);
 	if (!IS_ERR(s))
 		kfree(s);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/hugetlbfs/inode.c linux-3.2.71-pax/fs/hugetlbfs/inode.c
--- linux-3.2.71/fs/hugetlbfs/inode.c	2012-08-03 01:53:46.374140493 +0200
+++ linux-3.2.71-pax/fs/hugetlbfs/inode.c	2014-03-23 21:07:12.204061946 +0100
@@ -146,18 +146,21 @@ hugetlb_get_unmapped_area(struct file *f
 		return addr;
 	}
 
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	if (addr) {
 		addr = ALIGN(addr, huge_page_size(h));
 		vma = find_vma(mm, addr);
-		if (TASK_SIZE - len >= addr &&
-		    (!vma || addr + len <= vma->vm_start))
+		if (TASK_SIZE - len >= addr && check_heap_stack_gap(vma, &addr, len))
 			return addr;
 	}
 
 	start_addr = mm->free_area_cache;
 
 	if (len <= mm->cached_hole_size)
-		start_addr = TASK_UNMAPPED_BASE;
+		start_addr = mm->mmap_base;
 
 full_search:
 	addr = ALIGN(start_addr, huge_page_size(h));
@@ -169,14 +172,14 @@ full_search:
 			 * Start a new search - just in case we missed
 			 * some holes.
 			 */
-			if (start_addr != TASK_UNMAPPED_BASE) {
-				start_addr = TASK_UNMAPPED_BASE;
+			if (start_addr != mm->mmap_base) {
+				start_addr = mm->mmap_base;
 				goto full_search;
 			}
 			return -ENOMEM;
 		}
 
-		if (!vma || addr + len <= vma->vm_start)
+		if (check_heap_stack_gap(vma, &addr, len))
 			return addr;
 		addr = ALIGN(vma->vm_end, huge_page_size(h));
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/inode.c linux-3.2.71-pax/fs/inode.c
--- linux-3.2.71/fs/inode.c	2013-04-30 00:45:09.619714478 +0200
+++ linux-3.2.71-pax/fs/inode.c	2013-04-30 00:45:13.179714288 +0200
@@ -787,8 +787,8 @@ unsigned int get_next_ino(void)
 
 #ifdef CONFIG_SMP
 	if (unlikely((res & (LAST_INO_BATCH-1)) == 0)) {
-		static atomic_t shared_last_ino;
-		int next = atomic_add_return(LAST_INO_BATCH, &shared_last_ino);
+		static atomic_unchecked_t shared_last_ino;
+		int next = atomic_add_return_unchecked(LAST_INO_BATCH, &shared_last_ino);
 
 		res = next - LAST_INO_BATCH;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/jffs2/erase.c linux-3.2.71-pax/fs/jffs2/erase.c
--- linux-3.2.71/fs/jffs2/erase.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/jffs2/erase.c	2012-07-04 19:24:48.704063008 +0200
@@ -439,7 +439,8 @@ static void jffs2_mark_erased_block(stru
 		struct jffs2_unknown_node marker = {
 			.magic =	cpu_to_je16(JFFS2_MAGIC_BITMASK),
 			.nodetype =	cpu_to_je16(JFFS2_NODETYPE_CLEANMARKER),
-			.totlen =	cpu_to_je32(c->cleanmarker_size)
+			.totlen =	cpu_to_je32(c->cleanmarker_size),
+			.hdr_crc =	cpu_to_je32(0)
 		};
 
 		jffs2_prealloc_raw_node_refs(c, jeb, 1);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/jffs2/wbuf.c linux-3.2.71-pax/fs/jffs2/wbuf.c
--- linux-3.2.71/fs/jffs2/wbuf.c	2012-10-24 01:05:57.348814644 +0200
+++ linux-3.2.71-pax/fs/jffs2/wbuf.c	2012-10-24 01:06:03.100814888 +0200
@@ -1011,7 +1011,8 @@ static const struct jffs2_unknown_node o
 {
 	.magic = constant_cpu_to_je16(JFFS2_MAGIC_BITMASK),
 	.nodetype = constant_cpu_to_je16(JFFS2_NODETYPE_CLEANMARKER),
-	.totlen = constant_cpu_to_je32(8)
+	.totlen = constant_cpu_to_je32(8),
+	.hdr_crc = constant_cpu_to_je32(0)
 };
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/jfs/super.c linux-3.2.71-pax/fs/jfs/super.c
--- linux-3.2.71/fs/jfs/super.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/jfs/super.c	2013-05-23 23:03:18.270325310 +0200
@@ -802,7 +802,7 @@ static int __init init_jfs_fs(void)
 
 	jfs_inode_cachep =
 	    kmem_cache_create("jfs_ip", sizeof(struct jfs_inode_info), 0,
-			    SLAB_RECLAIM_ACCOUNT|SLAB_MEM_SPREAD,
+			    SLAB_RECLAIM_ACCOUNT|SLAB_MEM_SPREAD|SLAB_USERCOPY,
 			    init_once);
 	if (jfs_inode_cachep == NULL)
 		return -ENOMEM;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/Kconfig.binfmt linux-3.2.71-pax/fs/Kconfig.binfmt
--- linux-3.2.71/fs/Kconfig.binfmt	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/Kconfig.binfmt	2012-07-04 19:24:48.704063008 +0200
@@ -86,7 +86,7 @@ config HAVE_AOUT
 
 config BINFMT_AOUT
 	tristate "Kernel support for a.out and ECOFF binaries"
-	depends on HAVE_AOUT
+	depends on HAVE_AOUT && BROKEN
 	---help---
 	  A.out (Assembler.OUTput) is a set of formats for libraries and
 	  executables used in the earliest versions of UNIX.  Linux used
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/libfs.c linux-3.2.71-pax/fs/libfs.c
--- linux-3.2.71/fs/libfs.c	2015-01-01 15:15:24.636069628 +0100
+++ linux-3.2.71-pax/fs/libfs.c	2015-01-01 15:16:19.772071028 +0100
@@ -165,6 +165,9 @@ int dcache_readdir(struct file * filp, v
 
 			for (p=q->next; p != &dentry->d_subdirs; p=p->next) {
 				struct dentry *next;
+				char d_name[sizeof(next->d_iname)];
+				const unsigned char *name;
+
 				next = list_entry(p, struct dentry, d_child);
 				spin_lock_nested(&next->d_lock, DENTRY_D_LOCK_NESTED);
 				if (!simple_positive(next)) {
@@ -174,7 +177,12 @@ int dcache_readdir(struct file * filp, v
 
 				spin_unlock(&next->d_lock);
 				spin_unlock(&dentry->d_lock);
-				if (filldir(dirent, next->d_name.name, 
+				name = next->d_name.name;
+				if (name == next->d_iname) {
+					memcpy(d_name, name, next->d_name.len);
+					name = d_name;
+				}
+				if (filldir(dirent, name, 
 					    next->d_name.len, filp->f_pos, 
 					    next->d_inode->i_ino, 
 					    dt_type(next->d_inode)) < 0)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/lockd/clntproc.c linux-3.2.71-pax/fs/lockd/clntproc.c
--- linux-3.2.71/fs/lockd/clntproc.c	2013-05-14 13:33:40.652285671 +0200
+++ linux-3.2.71-pax/fs/lockd/clntproc.c	2013-05-14 13:33:46.584285354 +0200
@@ -36,11 +36,11 @@ static const struct rpc_call_ops nlmclnt
 /*
  * Cookie counter for NLM requests
  */
-static atomic_t	nlm_cookie = ATOMIC_INIT(0x1234);
+static atomic_unchecked_t	nlm_cookie = ATOMIC_INIT(0x1234);
 
 void nlmclnt_next_cookie(struct nlm_cookie *c)
 {
-	u32	cookie = atomic_inc_return(&nlm_cookie);
+	u32	cookie = atomic_inc_return_unchecked(&nlm_cookie);
 
 	memcpy(c->data, &cookie, 4);
 	c->len=4;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/lockd/svc.c linux-3.2.71-pax/fs/lockd/svc.c
--- linux-3.2.71/fs/lockd/svc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/lockd/svc.c	2013-06-21 19:44:38.450664582 +0200
@@ -295,7 +295,7 @@ int lockd_up(void)
 	svc_sock_update_bufs(serv);
 	serv->sv_maxconn = nlm_max_connections;
 
-	nlmsvc_task = kthread_run(lockd, nlmsvc_rqst, serv->sv_name);
+	nlmsvc_task = kthread_run(lockd, nlmsvc_rqst, "%s", serv->sv_name);
 	if (IS_ERR(nlmsvc_task)) {
 		error = PTR_ERR(nlmsvc_task);
 		svc_exit_thread(nlmsvc_rqst);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/locks.c linux-3.2.71-pax/fs/locks.c
--- linux-3.2.71/fs/locks.c	2014-05-20 01:19:02.431997848 +0200
+++ linux-3.2.71-pax/fs/locks.c	2014-05-20 01:19:07.603997572 +0200
@@ -2074,16 +2074,16 @@ void locks_remove_flock(struct file *fil
 		return;
 
 	if (filp->f_op && filp->f_op->flock) {
-		struct file_lock fl = {
+		struct file_lock flock = {
 			.fl_pid = current->tgid,
 			.fl_file = filp,
 			.fl_flags = FL_FLOCK,
 			.fl_type = F_UNLCK,
 			.fl_end = OFFSET_MAX,
 		};
-		filp->f_op->flock(filp, F_SETLKW, &fl);
-		if (fl.fl_ops && fl.fl_ops->fl_release_private)
-			fl.fl_ops->fl_release_private(&fl);
+		filp->f_op->flock(filp, F_SETLKW, &flock);
+		if (flock.fl_ops && flock.fl_ops->fl_release_private)
+			flock.fl_ops->fl_release_private(&flock);
 	}
 
 	lock_flocks();
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/namei.c linux-3.2.71-pax/fs/namei.c
--- linux-3.2.71/fs/namei.c	2015-02-20 12:37:33.217178769 +0100
+++ linux-3.2.71-pax/fs/namei.c	2015-02-20 12:37:41.901178305 +0100
@@ -656,7 +656,7 @@ follow_link(struct path *link, struct na
 	*p = dentry->d_inode->i_op->follow_link(dentry, nd);
 	error = PTR_ERR(*p);
 	if (!IS_ERR(*p)) {
-		char *s = nd_get_link(nd);
+		const char *s = nd_get_link(nd);
 		error = 0;
 		if (s)
 			error = __vfs_follow_link(nd, s);
@@ -3250,6 +3250,8 @@ SYSCALL_DEFINE2(rename, const char __use
 
 int vfs_readlink(struct dentry *dentry, char __user *buffer, int buflen, const char *link)
 {
+	char tmpbuf[64];
+	const char *newlink;
 	int len;
 
 	len = PTR_ERR(link);
@@ -3259,7 +3261,14 @@ int vfs_readlink(struct dentry *dentry,
 	len = strlen(link);
 	if (len > (unsigned) buflen)
 		len = buflen;
-	if (copy_to_user(buffer, link, len))
+
+	if (len < sizeof(tmpbuf)) {
+		memcpy(tmpbuf, link, len);
+		newlink = tmpbuf;
+	} else
+		newlink = link;
+
+	if (copy_to_user(buffer, newlink, len))
 		len = -EFAULT;
 out:
 	return len;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/namespace.c linux-3.2.71-pax/fs/namespace.c
--- linux-3.2.71/fs/namespace.c	2014-09-14 14:10:59.822118561 +0200
+++ linux-3.2.71-pax/fs/namespace.c	2014-09-14 14:11:26.062138431 +0200
@@ -1357,7 +1357,7 @@ static int do_umount(struct vfsmount *mn
  * unixes. Our API is identical to OSF/1 to avoid making a mess of AMD
  */
 
-SYSCALL_DEFINE2(umount, char __user *, name, int, flags)
+SYSCALL_DEFINE2(umount, const char __user *, name, int, flags)
 {
 	struct path path;
 	int retval;
@@ -1396,7 +1396,7 @@ out:
 /*
  *	The 2.0 compatible umount. No flags.
  */
-SYSCALL_DEFINE1(oldumount, char __user *, name)
+SYSCALL_DEFINE1(oldumount, const char __user *, name)
 {
 	return sys_umount(name, 0);
 }
@@ -2397,7 +2397,7 @@ void mnt_make_shortterm(struct vfsmount
  * Allocate a new namespace structure and populate it with contents
  * copied from the namespace of the passed in task structure.
  */
-static struct mnt_namespace *dup_mnt_ns(struct mnt_namespace *mnt_ns,
+static __latent_entropy struct mnt_namespace *dup_mnt_ns(struct mnt_namespace *mnt_ns,
 		struct fs_struct *fs)
 {
 	struct mnt_namespace *new_ns;
@@ -2526,8 +2526,8 @@ struct dentry *mount_subtree(struct vfsm
 }
 EXPORT_SYMBOL(mount_subtree);
 
-SYSCALL_DEFINE5(mount, char __user *, dev_name, char __user *, dir_name,
-		char __user *, type, unsigned long, flags, void __user *, data)
+SYSCALL_DEFINE5(mount, const char __user *, dev_name, const char __user *, dir_name,
+		const char __user *, type, unsigned long, flags, void __user *, data)
 {
 	int ret;
 	char *kernel_type;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/nfs/callback.c linux-3.2.71-pax/fs/nfs/callback.c
--- linux-3.2.71/fs/nfs/callback.c	2015-05-10 09:22:38.783493123 +0200
+++ linux-3.2.71-pax/fs/nfs/callback.c	2015-05-10 09:23:09.459494789 +0200
@@ -252,7 +252,6 @@ int nfs_callback_up(u32 minorversion, st
 	struct svc_rqst *rqstp;
 	int (*callback_svc)(void *vrqstp);
 	struct nfs_callback_data *cb_info = &nfs_callback_info[minorversion];
-	char svc_name[12];
 	int ret = 0;
 	int minorversion_setup;
 
@@ -282,10 +281,9 @@ int nfs_callback_up(u32 minorversion, st
 
 	svc_sock_update_bufs(serv);
 
-	sprintf(svc_name, "nfsv4.%u-svc", minorversion);
 	cb_info->serv = serv;
 	cb_info->rqst = rqstp;
-	cb_info->task = kthread_run(callback_svc, cb_info->rqst, svc_name);
+	cb_info->task = kthread_run(callback_svc, cb_info->rqst, "nfsv4.%u-svc", minorversion);
 	if (IS_ERR(cb_info->task)) {
 		ret = PTR_ERR(cb_info->task);
 		svc_exit_thread(cb_info->rqst);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/nfs/callback_xdr.c linux-3.2.71-pax/fs/nfs/callback_xdr.c
--- linux-3.2.71/fs/nfs/callback_xdr.c	2015-05-10 09:22:38.783493123 +0200
+++ linux-3.2.71-pax/fs/nfs/callback_xdr.c	2015-05-10 09:23:09.459494789 +0200
@@ -50,7 +50,7 @@ struct callback_op {
 	callback_decode_arg_t decode_args;
 	callback_encode_res_t encode_res;
 	long res_maxsize;
-};
+} __do_const;
 
 static struct callback_op callback_ops[];
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/nfs/inode.c linux-3.2.71-pax/fs/nfs/inode.c
--- linux-3.2.71/fs/nfs/inode.c	2012-09-20 01:42:17.434672774 +0200
+++ linux-3.2.71-pax/fs/nfs/inode.c	2012-09-20 01:43:38.590673029 +0200
@@ -1002,16 +1002,16 @@ static int nfs_size_need_update(const st
 	return nfs_size_to_loff_t(fattr->size) > i_size_read(inode);
 }
 
-static atomic_long_t nfs_attr_generation_counter;
+static atomic_long_unchecked_t nfs_attr_generation_counter;
 
 static unsigned long nfs_read_attr_generation_counter(void)
 {
-	return atomic_long_read(&nfs_attr_generation_counter);
+	return atomic_long_read_unchecked(&nfs_attr_generation_counter);
 }
 
 unsigned long nfs_inc_attr_generation_counter(void)
 {
-	return atomic_long_inc_return(&nfs_attr_generation_counter);
+	return atomic_long_inc_return_unchecked(&nfs_attr_generation_counter);
 }
 
 void nfs_fattr_init(struct nfs_fattr *fattr)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/nfsd/nfs4proc.c linux-3.2.71-pax/fs/nfsd/nfs4proc.c
--- linux-3.2.71/fs/nfsd/nfs4proc.c	2014-12-14 21:13:45.270055206 +0100
+++ linux-3.2.71-pax/fs/nfsd/nfs4proc.c	2014-12-14 21:13:52.830069330 +0100
@@ -1039,7 +1039,7 @@ struct nfsd4_operation {
 	char *op_name;
 	/* Try to get response size before operation */
 	nfsd4op_rsize op_rsize_bop;
-};
+} __do_const;
 
 static struct nfsd4_operation nfsd4_ops[];
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/nfsd/nfs4xdr.c linux-3.2.71-pax/fs/nfsd/nfs4xdr.c
--- linux-3.2.71/fs/nfsd/nfs4xdr.c	2014-08-06 23:17:21.737614202 +0200
+++ linux-3.2.71-pax/fs/nfsd/nfs4xdr.c	2014-08-06 23:17:26.421614192 +0200
@@ -1456,7 +1456,7 @@ nfsd4_decode_notsupp(struct nfsd4_compou
 
 typedef __be32(*nfsd4_dec)(struct nfsd4_compoundargs *argp, void *);
 
-static nfsd4_dec nfsd4_dec_ops[] = {
+static const nfsd4_dec nfsd4_dec_ops[] = {
 	[OP_ACCESS]		= (nfsd4_dec)nfsd4_decode_access,
 	[OP_CLOSE]		= (nfsd4_dec)nfsd4_decode_close,
 	[OP_COMMIT]		= (nfsd4_dec)nfsd4_decode_commit,
@@ -1496,7 +1496,7 @@ static nfsd4_dec nfsd4_dec_ops[] = {
 	[OP_RELEASE_LOCKOWNER]	= (nfsd4_dec)nfsd4_decode_release_lockowner,
 };
 
-static nfsd4_dec nfsd41_dec_ops[] = {
+static const nfsd4_dec nfsd41_dec_ops[] = {
 	[OP_ACCESS]		= (nfsd4_dec)nfsd4_decode_access,
 	[OP_CLOSE]		= (nfsd4_dec)nfsd4_decode_close,
 	[OP_COMMIT]		= (nfsd4_dec)nfsd4_decode_commit,
@@ -1558,7 +1558,7 @@ static nfsd4_dec nfsd41_dec_ops[] = {
 };
 
 struct nfsd4_minorversion_ops {
-	nfsd4_dec *decoders;
+	const nfsd4_dec *decoders;
 	int nops;
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/nfsd/nfscache.c linux-3.2.71-pax/fs/nfsd/nfscache.c
--- linux-3.2.71/fs/nfsd/nfscache.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/nfsd/nfscache.c	2013-06-21 20:15:56.162564327 +0200
@@ -259,13 +259,16 @@ nfsd_cache_update(struct svc_rqst *rqstp
 {
 	struct svc_cacherep *rp;
 	struct kvec	*resv = &rqstp->rq_res.head[0], *cachv;
-	int		len;
+	long		len;
 
 	if (!(rp = rqstp->rq_cacherep) || cache_disabled)
 		return;
 
-	len = resv->iov_len - ((char*)statp - (char*)resv->iov_base);
-	len >>= 2;
+	if (statp) {
+		len = (char*)statp - (char*)resv->iov_base;
+		len = resv->iov_len - len;
+		len >>= 2;
+	}
 
 	/* Don't cache excessive amounts of data and XDR failures */
 	if (!statp || len > (256 >> 2)) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/nfsd/vfs.c linux-3.2.71-pax/fs/nfsd/vfs.c
--- linux-3.2.71/fs/nfsd/vfs.c	2014-11-05 23:20:30.121389768 +0100
+++ linux-3.2.71-pax/fs/nfsd/vfs.c	2014-11-05 23:20:50.501398815 +0100
@@ -960,7 +960,7 @@ nfsd_vfs_read(struct svc_rqst *rqstp, st
 	} else {
 		oldfs = get_fs();
 		set_fs(KERNEL_DS);
-		host_err = vfs_readv(file, (struct iovec __user *)vec, vlen, &offset);
+		host_err = vfs_readv(file, (struct iovec __force_user *)vec, vlen, &offset);
 		set_fs(oldfs);
 	}
 
@@ -1064,7 +1064,7 @@ nfsd_vfs_write(struct svc_rqst *rqstp, s
 
 	/* Write the data. */
 	oldfs = get_fs(); set_fs(KERNEL_DS);
-	host_err = vfs_writev(file, (struct iovec __user *)vec, vlen, &offset);
+	host_err = vfs_writev(file, (struct iovec __force_user *)vec, vlen, &offset);
 	set_fs(oldfs);
 	if (host_err < 0)
 		goto out_nfserr;
@@ -1605,7 +1605,7 @@ nfsd_readlink(struct svc_rqst *rqstp, st
 	 */
 
 	oldfs = get_fs(); set_fs(KERNEL_DS);
-	host_err = inode->i_op->readlink(dentry, buf, *lenp);
+	host_err = inode->i_op->readlink(dentry, (char __force_user *)buf, *lenp);
 	set_fs(oldfs);
 
 	if (host_err < 0)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/nls/nls_base.c linux-3.2.71-pax/fs/nls/nls_base.c
--- linux-3.2.71/fs/nls/nls_base.c	2013-03-29 02:18:38.735676282 +0100
+++ linux-3.2.71-pax/fs/nls/nls_base.c	2013-03-29 02:20:31.363670268 +0100
@@ -234,20 +234,22 @@ EXPORT_SYMBOL(utf16s_to_utf8s);
 
 int register_nls(struct nls_table * nls)
 {
-	struct nls_table ** tmp = &tables;
+	struct nls_table *tmp = tables;
 
 	if (nls->next)
 		return -EBUSY;
 
 	spin_lock(&nls_lock);
-	while (*tmp) {
-		if (nls == *tmp) {
+	while (tmp) {
+		if (nls == tmp) {
 			spin_unlock(&nls_lock);
 			return -EBUSY;
 		}
-		tmp = &(*tmp)->next;
+		tmp = tmp->next;
 	}
-	nls->next = tables;
+	pax_open_kernel();
+	*(struct nls_table **)&nls->next = tables;
+	pax_close_kernel();
 	tables = nls;
 	spin_unlock(&nls_lock);
 	return 0;	
@@ -255,12 +257,14 @@ int register_nls(struct nls_table * nls)
 
 int unregister_nls(struct nls_table * nls)
 {
-	struct nls_table ** tmp = &tables;
+	struct nls_table * const * tmp = &tables;
 
 	spin_lock(&nls_lock);
 	while (*tmp) {
 		if (nls == *tmp) {
-			*tmp = nls->next;
+			pax_open_kernel();
+			*(struct nls_table **)tmp = nls->next;
+			pax_close_kernel();
 			spin_unlock(&nls_lock);
 			return 0;
 		}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/nls/nls_euc-jp.c linux-3.2.71-pax/fs/nls/nls_euc-jp.c
--- linux-3.2.71/fs/nls/nls_euc-jp.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/nls/nls_euc-jp.c	2013-03-28 01:35:23.324427947 +0100
@@ -561,8 +561,10 @@ static int __init init_nls_euc_jp(void)
 	p_nls = load_nls("cp932");
 
 	if (p_nls) {
-		table.charset2upper = p_nls->charset2upper;
-		table.charset2lower = p_nls->charset2lower;
+		pax_open_kernel();
+		*(const unsigned char **)&table.charset2upper = p_nls->charset2upper;
+		*(const unsigned char **)&table.charset2lower = p_nls->charset2lower;
+		pax_close_kernel();
 		return register_nls(&table);
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/nls/nls_koi8-ru.c linux-3.2.71-pax/fs/nls/nls_koi8-ru.c
--- linux-3.2.71/fs/nls/nls_koi8-ru.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/nls/nls_koi8-ru.c	2013-03-28 01:35:23.324427947 +0100
@@ -63,8 +63,10 @@ static int __init init_nls_koi8_ru(void)
 	p_nls = load_nls("koi8-u");
 
 	if (p_nls) {
-		table.charset2upper = p_nls->charset2upper;
-		table.charset2lower = p_nls->charset2lower;
+		pax_open_kernel();
+		*(const unsigned char **)&table.charset2upper = p_nls->charset2upper;
+		*(const unsigned char **)&table.charset2lower = p_nls->charset2lower;
+		pax_close_kernel();
 		return register_nls(&table);
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/notify/fanotify/fanotify_user.c linux-3.2.71-pax/fs/notify/fanotify/fanotify_user.c
--- linux-3.2.71/fs/notify/fanotify/fanotify_user.c	2014-12-14 21:13:45.270055206 +0100
+++ linux-3.2.71-pax/fs/notify/fanotify/fanotify_user.c	2014-12-14 21:13:52.830069330 +0100
@@ -277,7 +277,8 @@ static ssize_t copy_event_to_user(struct
 		goto out_close_fd;
 
 	ret = -EFAULT;
-	if (copy_to_user(buf, &fanotify_event_metadata,
+	if (fanotify_event_metadata.event_len > sizeof fanotify_event_metadata ||
+	    copy_to_user(buf, &fanotify_event_metadata,
 			 fanotify_event_metadata.event_len))
 		goto out_kill_access_response;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/notify/notification.c linux-3.2.71-pax/fs/notify/notification.c
--- linux-3.2.71/fs/notify/notification.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/notify/notification.c	2012-07-04 19:24:48.712063008 +0200
@@ -57,7 +57,7 @@ static struct kmem_cache *fsnotify_event
  * get set to 0 so it will never get 'freed'
  */
 static struct fsnotify_event *q_overflow_event;
-static atomic_t fsnotify_sync_cookie = ATOMIC_INIT(0);
+static atomic_unchecked_t fsnotify_sync_cookie = ATOMIC_INIT(0);
 
 /**
  * fsnotify_get_cookie - return a unique cookie for use in synchronizing events.
@@ -65,7 +65,7 @@ static atomic_t fsnotify_sync_cookie = A
  */
 u32 fsnotify_get_cookie(void)
 {
-	return atomic_inc_return(&fsnotify_sync_cookie);
+	return atomic_inc_return_unchecked(&fsnotify_sync_cookie);
 }
 EXPORT_SYMBOL_GPL(fsnotify_get_cookie);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ntfs/dir.c linux-3.2.71-pax/fs/ntfs/dir.c
--- linux-3.2.71/fs/ntfs/dir.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/ntfs/dir.c	2012-07-04 19:24:48.716063008 +0200
@@ -1329,7 +1329,7 @@ find_next_index_buffer:
 	ia = (INDEX_ALLOCATION*)(kaddr + (ia_pos & ~PAGE_CACHE_MASK &
 			~(s64)(ndir->itype.index.block_size - 1)));
 	/* Bounds checks. */
-	if (unlikely((u8*)ia < kaddr || (u8*)ia > kaddr + PAGE_CACHE_SIZE)) {
+	if (unlikely(!kaddr || (u8*)ia < kaddr || (u8*)ia > kaddr + PAGE_CACHE_SIZE)) {
 		ntfs_error(sb, "Out of bounds check failed. Corrupt directory "
 				"inode 0x%lx or driver bug.", vdir->i_ino);
 		goto err_out;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ntfs/file.c linux-3.2.71-pax/fs/ntfs/file.c
--- linux-3.2.71/fs/ntfs/file.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/ntfs/file.c	2013-09-17 02:17:41.121645864 +0200
@@ -1281,7 +1281,7 @@ static inline size_t ntfs_copy_from_user
 	char *addr;
 	size_t total = 0;
 	unsigned len;
-	int left;
+	unsigned left;
 
 	do {
 		len = PAGE_CACHE_SIZE - ofs;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ntfs/super.c linux-3.2.71-pax/fs/ntfs/super.c
--- linux-3.2.71/fs/ntfs/super.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/ntfs/super.c	2013-08-31 16:13:59.774064599 +0200
@@ -661,7 +661,7 @@ static struct buffer_head *read_ntfs_boo
 		if (!silent)
 			ntfs_error(sb, "Primary boot sector is invalid.");
 	} else if (!silent)
-		ntfs_error(sb, read_err_str, "primary");
+		ntfs_error(sb, read_err_str, "%s", "primary");
 	if (!(NTFS_SB(sb)->on_errors & ON_ERRORS_RECOVER)) {
 		if (bh_primary)
 			brelse(bh_primary);
@@ -677,7 +677,7 @@ static struct buffer_head *read_ntfs_boo
 			goto hotfix_primary_boot_sector;
 		brelse(bh_backup);
 	} else if (!silent)
-		ntfs_error(sb, read_err_str, "backup");
+		ntfs_error(sb, read_err_str, "%s", "backup");
 	/* Try to read NT3.51- backup boot sector. */
 	if ((bh_backup = sb_bread(sb, nr_blocks >> 1))) {
 		if (is_boot_sector_ntfs(sb, (NTFS_BOOT_SECTOR*)
@@ -688,7 +688,7 @@ static struct buffer_head *read_ntfs_boo
 					"sector.");
 		brelse(bh_backup);
 	} else if (!silent)
-		ntfs_error(sb, read_err_str, "backup");
+		ntfs_error(sb, read_err_str, "%s", "backup");
 	/* We failed. Cleanup and return. */
 	if (bh_primary)
 		brelse(bh_primary);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ocfs2/localalloc.c linux-3.2.71-pax/fs/ocfs2/localalloc.c
--- linux-3.2.71/fs/ocfs2/localalloc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/ocfs2/localalloc.c	2012-07-04 19:24:48.716063008 +0200
@@ -1283,7 +1283,7 @@ static int ocfs2_local_alloc_slide_windo
 		goto bail;
 	}
 
-	atomic_inc(&osb->alloc_stats.moves);
+	atomic_inc_unchecked(&osb->alloc_stats.moves);
 
 bail:
 	if (handle)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ocfs2/ocfs2.h linux-3.2.71-pax/fs/ocfs2/ocfs2.h
--- linux-3.2.71/fs/ocfs2/ocfs2.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/ocfs2/ocfs2.h	2012-07-04 19:24:48.716063008 +0200
@@ -235,11 +235,11 @@ enum ocfs2_vol_state
 
 struct ocfs2_alloc_stats
 {
-	atomic_t moves;
-	atomic_t local_data;
-	atomic_t bitmap_data;
-	atomic_t bg_allocs;
-	atomic_t bg_extends;
+	atomic_unchecked_t moves;
+	atomic_unchecked_t local_data;
+	atomic_unchecked_t bitmap_data;
+	atomic_unchecked_t bg_allocs;
+	atomic_unchecked_t bg_extends;
 };
 
 enum ocfs2_local_alloc_state
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ocfs2/suballoc.c linux-3.2.71-pax/fs/ocfs2/suballoc.c
--- linux-3.2.71/fs/ocfs2/suballoc.c	2013-03-29 02:18:30.187676738 +0100
+++ linux-3.2.71-pax/fs/ocfs2/suballoc.c	2013-03-29 02:19:02.123675033 +0100
@@ -872,7 +872,7 @@ static int ocfs2_reserve_suballoc_bits(s
 				mlog_errno(status);
 			goto bail;
 		}
-		atomic_inc(&osb->alloc_stats.bg_extends);
+		atomic_inc_unchecked(&osb->alloc_stats.bg_extends);
 
 		/* You should never ask for this much metadata */
 		BUG_ON(bits_wanted >
@@ -2007,7 +2007,7 @@ int ocfs2_claim_metadata(handle_t *handl
 		mlog_errno(status);
 		goto bail;
 	}
-	atomic_inc(&OCFS2_SB(ac->ac_inode->i_sb)->alloc_stats.bg_allocs);
+	atomic_inc_unchecked(&OCFS2_SB(ac->ac_inode->i_sb)->alloc_stats.bg_allocs);
 
 	*suballoc_loc = res.sr_bg_blkno;
 	*suballoc_bit_start = res.sr_bit_offset;
@@ -2171,7 +2171,7 @@ int ocfs2_claim_new_inode_at_loc(handle_
 	trace_ocfs2_claim_new_inode_at_loc((unsigned long long)di_blkno,
 					   res->sr_bits);
 
-	atomic_inc(&OCFS2_SB(ac->ac_inode->i_sb)->alloc_stats.bg_allocs);
+	atomic_inc_unchecked(&OCFS2_SB(ac->ac_inode->i_sb)->alloc_stats.bg_allocs);
 
 	BUG_ON(res->sr_bits != 1);
 
@@ -2213,7 +2213,7 @@ int ocfs2_claim_new_inode(handle_t *hand
 		mlog_errno(status);
 		goto bail;
 	}
-	atomic_inc(&OCFS2_SB(ac->ac_inode->i_sb)->alloc_stats.bg_allocs);
+	atomic_inc_unchecked(&OCFS2_SB(ac->ac_inode->i_sb)->alloc_stats.bg_allocs);
 
 	BUG_ON(res.sr_bits != 1);
 
@@ -2317,7 +2317,7 @@ int __ocfs2_claim_clusters(handle_t *han
 						      cluster_start,
 						      num_clusters);
 		if (!status)
-			atomic_inc(&osb->alloc_stats.local_data);
+			atomic_inc_unchecked(&osb->alloc_stats.local_data);
 	} else {
 		if (min_clusters > (osb->bitmap_cpg - 1)) {
 			/* The only paths asking for contiguousness
@@ -2343,7 +2343,7 @@ int __ocfs2_claim_clusters(handle_t *han
 				ocfs2_desc_bitmap_to_cluster_off(ac->ac_inode,
 								 res.sr_bg_blkno,
 								 res.sr_bit_offset);
-			atomic_inc(&osb->alloc_stats.bitmap_data);
+			atomic_inc_unchecked(&osb->alloc_stats.bitmap_data);
 			*num_clusters = res.sr_bits;
 		}
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ocfs2/super.c linux-3.2.71-pax/fs/ocfs2/super.c
--- linux-3.2.71/fs/ocfs2/super.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/ocfs2/super.c	2012-07-04 19:24:48.720063008 +0200
@@ -301,11 +301,11 @@ static int ocfs2_osb_dump(struct ocfs2_s
 			"%10s => GlobalAllocs: %d  LocalAllocs: %d  "
 			"SubAllocs: %d  LAWinMoves: %d  SAExtends: %d\n",
 			"Stats",
-			atomic_read(&osb->alloc_stats.bitmap_data),
-			atomic_read(&osb->alloc_stats.local_data),
-			atomic_read(&osb->alloc_stats.bg_allocs),
-			atomic_read(&osb->alloc_stats.moves),
-			atomic_read(&osb->alloc_stats.bg_extends));
+			atomic_read_unchecked(&osb->alloc_stats.bitmap_data),
+			atomic_read_unchecked(&osb->alloc_stats.local_data),
+			atomic_read_unchecked(&osb->alloc_stats.bg_allocs),
+			atomic_read_unchecked(&osb->alloc_stats.moves),
+			atomic_read_unchecked(&osb->alloc_stats.bg_extends));
 
 	out += snprintf(buf + out, len - out,
 			"%10s => State: %u  Descriptor: %llu  Size: %u bits  "
@@ -2119,11 +2119,11 @@ static int ocfs2_initialize_super(struct
 	spin_lock_init(&osb->osb_xattr_lock);
 	ocfs2_init_steal_slots(osb);
 
-	atomic_set(&osb->alloc_stats.moves, 0);
-	atomic_set(&osb->alloc_stats.local_data, 0);
-	atomic_set(&osb->alloc_stats.bitmap_data, 0);
-	atomic_set(&osb->alloc_stats.bg_allocs, 0);
-	atomic_set(&osb->alloc_stats.bg_extends, 0);
+	atomic_set_unchecked(&osb->alloc_stats.moves, 0);
+	atomic_set_unchecked(&osb->alloc_stats.local_data, 0);
+	atomic_set_unchecked(&osb->alloc_stats.bitmap_data, 0);
+	atomic_set_unchecked(&osb->alloc_stats.bg_allocs, 0);
+	atomic_set_unchecked(&osb->alloc_stats.bg_extends, 0);
 
 	/* Copy the blockcheck stats from the superblock probe */
 	osb->osb_ecc_stats = *stats;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ocfs2/symlink.c linux-3.2.71-pax/fs/ocfs2/symlink.c
--- linux-3.2.71/fs/ocfs2/symlink.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/ocfs2/symlink.c	2012-07-04 19:24:48.720063008 +0200
@@ -142,7 +142,7 @@ bail:
 
 static void ocfs2_fast_put_link(struct dentry *dentry, struct nameidata *nd, void *cookie)
 {
-	char *link = nd_get_link(nd);
+	const char *link = nd_get_link(nd);
 	if (!IS_ERR(link))
 		kfree(link);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/partitions/efi.c linux-3.2.71-pax/fs/partitions/efi.c
--- linux-3.2.71/fs/partitions/efi.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/partitions/efi.c	2012-07-04 19:24:48.720063008 +0200
@@ -234,14 +234,14 @@ static gpt_entry *alloc_read_gpt_entries
 	if (!gpt)
 		return NULL;
 
-	count = le32_to_cpu(gpt->num_partition_entries) *
-                le32_to_cpu(gpt->sizeof_partition_entry);
-	if (!count)
+	if (!le32_to_cpu(gpt->num_partition_entries))
 		return NULL;
-	pte = kzalloc(count, GFP_KERNEL);
+	pte = kcalloc(le32_to_cpu(gpt->num_partition_entries), le32_to_cpu(gpt->sizeof_partition_entry), GFP_KERNEL);
 	if (!pte)
 		return NULL;
 
+	count = le32_to_cpu(gpt->num_partition_entries) *
+                le32_to_cpu(gpt->sizeof_partition_entry);
 	if (read_lba(state, le64_to_cpu(gpt->partition_entry_lba),
                      (u8 *) pte,
 		     count) < count) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/pipe.c linux-3.2.71-pax/fs/pipe.c
--- linux-3.2.71/fs/pipe.c	2015-08-07 11:37:20.687789897 +0200
+++ linux-3.2.71-pax/fs/pipe.c	2015-08-07 11:37:43.023790554 +0200
@@ -33,7 +33,7 @@ unsigned int pipe_max_size = 1048576;
 /*
  * Minimum pipe size, as required by POSIX
  */
-unsigned int pipe_min_size = PAGE_SIZE;
+unsigned int pipe_min_size __read_only = PAGE_SIZE;
 
 /*
  * We use a start+len construction, which provides full use of the 
@@ -442,9 +442,9 @@ redo:
 		}
 		if (bufs)	/* More to do? */
 			continue;
-		if (!pipe->writers)
+		if (!atomic_read(&pipe->writers))
 			break;
-		if (!pipe->waiting_writers) {
+		if (!atomic_read(&pipe->waiting_writers)) {
 			/* syscall merging: Usually we must not sleep
 			 * if O_NONBLOCK is set, or if we got some data.
 			 * But if a writer sleeps in kernel space, then
@@ -508,7 +508,7 @@ pipe_write(struct kiocb *iocb, const str
 	mutex_lock(&inode->i_mutex);
 	pipe = inode->i_pipe;
 
-	if (!pipe->readers) {
+	if (!atomic_read(&pipe->readers)) {
 		send_sig(SIGPIPE, current, 0);
 		ret = -EPIPE;
 		goto out;
@@ -558,7 +558,7 @@ redo1:
 	for (;;) {
 		int bufs;
 
-		if (!pipe->readers) {
+		if (!atomic_read(&pipe->readers)) {
 			send_sig(SIGPIPE, current, 0);
 			if (!ret)
 				ret = -EPIPE;
@@ -652,9 +652,9 @@ redo2:
 			kill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);
 			do_wakeup = 0;
 		}
-		pipe->waiting_writers++;
+		atomic_inc(&pipe->waiting_writers);
 		pipe_wait(pipe);
-		pipe->waiting_writers--;
+		atomic_dec(&pipe->waiting_writers);
 	}
 out:
 	mutex_unlock(&inode->i_mutex);
@@ -721,7 +721,7 @@ pipe_poll(struct file *filp, poll_table
 	mask = 0;
 	if (filp->f_mode & FMODE_READ) {
 		mask = (nrbufs > 0) ? POLLIN | POLLRDNORM : 0;
-		if (!pipe->writers && filp->f_version != pipe->w_counter)
+		if (!atomic_read(&pipe->writers) && filp->f_version != pipe->w_counter)
 			mask |= POLLHUP;
 	}
 
@@ -731,7 +731,7 @@ pipe_poll(struct file *filp, poll_table
 		 * Most Unices do not set POLLERR for FIFOs but on Linux they
 		 * behave exactly like pipes for poll().
 		 */
-		if (!pipe->readers)
+		if (!atomic_read(&pipe->readers))
 			mask |= POLLERR;
 	}
 
@@ -745,10 +745,10 @@ pipe_release(struct inode *inode, int de
 
 	mutex_lock(&inode->i_mutex);
 	pipe = inode->i_pipe;
-	pipe->readers -= decr;
-	pipe->writers -= decw;
+	atomic_sub(decr, &pipe->readers);
+	atomic_sub(decw, &pipe->writers);
 
-	if (!pipe->readers && !pipe->writers) {
+	if (!atomic_read(&pipe->readers) && !atomic_read(&pipe->writers)) {
 		free_pipe_info(inode);
 	} else {
 		wake_up_interruptible_sync_poll(&pipe->wait, POLLIN | POLLOUT | POLLRDNORM | POLLWRNORM | POLLERR | POLLHUP);
@@ -838,7 +838,7 @@ pipe_read_open(struct inode *inode, stru
 
 	if (inode->i_pipe) {
 		ret = 0;
-		inode->i_pipe->readers++;
+		atomic_inc(&inode->i_pipe->readers);
 	}
 
 	mutex_unlock(&inode->i_mutex);
@@ -855,7 +855,7 @@ pipe_write_open(struct inode *inode, str
 
 	if (inode->i_pipe) {
 		ret = 0;
-		inode->i_pipe->writers++;
+		atomic_inc(&inode->i_pipe->writers);
 	}
 
 	mutex_unlock(&inode->i_mutex);
@@ -876,9 +876,9 @@ pipe_rdwr_open(struct inode *inode, stru
 	if (inode->i_pipe) {
 		ret = 0;
 		if (filp->f_mode & FMODE_READ)
-			inode->i_pipe->readers++;
+			atomic_inc(&inode->i_pipe->readers);
 		if (filp->f_mode & FMODE_WRITE)
-			inode->i_pipe->writers++;
+			atomic_inc(&inode->i_pipe->writers);
 	}
 
 	mutex_unlock(&inode->i_mutex);
@@ -1000,7 +1000,8 @@ static struct inode * get_pipe_inode(voi
 		goto fail_iput;
 	inode->i_pipe = pipe;
 
-	pipe->readers = pipe->writers = 1;
+	atomic_set(&pipe->readers, 1);
+	atomic_set(&pipe->writers, 1);
 	inode->i_fop = &rdwr_pipefifo_fops;
 
 	/*
@@ -1212,7 +1213,7 @@ static long pipe_set_size(struct pipe_in
  * Currently we rely on the pipe array holding a power-of-2 number
  * of pages.
  */
-static inline unsigned int round_pipe_size(unsigned int size)
+static inline unsigned long round_pipe_size(unsigned long size)
 {
 	unsigned long nr_pages;
 
@@ -1262,13 +1263,16 @@ long pipe_fcntl(struct file *file, unsig
 
 	switch (cmd) {
 	case F_SETPIPE_SZ: {
-		unsigned int size, nr_pages;
+		unsigned long size, nr_pages;
+
+		ret = -EINVAL;
+		if (arg < pipe_min_size)
+			goto out;
 
 		size = round_pipe_size(arg);
 		nr_pages = size >> PAGE_SHIFT;
 
-		ret = -EINVAL;
-		if (!nr_pages)
+		if (size < pipe_min_size)
 			goto out;
 
 		if (!capable(CAP_SYS_RESOURCE) && size > pipe_max_size) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/proc/array.c linux-3.2.71-pax/fs/proc/array.c
--- linux-3.2.71/fs/proc/array.c	2013-01-03 19:05:14.696036860 +0100
+++ linux-3.2.71-pax/fs/proc/array.c	2013-01-03 19:05:22.116037079 +0100
@@ -337,6 +337,21 @@ static void task_cpus_allowed(struct seq
 	seq_putc(m, '\n');
 }
 
+#if defined(CONFIG_PAX_NOEXEC) || defined(CONFIG_PAX_ASLR)
+static inline void task_pax(struct seq_file *m, struct task_struct *p)
+{
+	if (p->mm)
+		seq_printf(m, "PaX:\t%c%c%c%c%c\n",
+			   p->mm->pax_flags & MF_PAX_PAGEEXEC ? 'P' : 'p',
+			   p->mm->pax_flags & MF_PAX_EMUTRAMP ? 'E' : 'e',
+			   p->mm->pax_flags & MF_PAX_MPROTECT ? 'M' : 'm',
+			   p->mm->pax_flags & MF_PAX_RANDMMAP ? 'R' : 'r',
+			   p->mm->pax_flags & MF_PAX_SEGMEXEC ? 'S' : 's');
+	else
+		seq_printf(m, "PaX:\t-----\n");
+}
+#endif
+
 int proc_pid_status(struct seq_file *m, struct pid_namespace *ns,
 			struct pid *pid, struct task_struct *task)
 {
@@ -354,6 +369,11 @@ int proc_pid_status(struct seq_file *m,
 	task_cpus_allowed(m, task);
 	cpuset_task_status_allowed(m, task);
 	task_context_switch_counts(m, task);
+
+#if defined(CONFIG_PAX_NOEXEC) || defined(CONFIG_PAX_ASLR)
+	task_pax(m, task);
+#endif
+
 	return 0;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/proc/base.c linux-3.2.71-pax/fs/proc/base.c
--- linux-3.2.71/fs/proc/base.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/proc/base.c	2013-04-05 20:10:58.100926293 +0200
@@ -809,7 +809,7 @@ static ssize_t mem_rw(struct file *file,
 		goto free;
 
 	while (count > 0) {
-		int this_len = min_t(int, count, PAGE_SIZE);
+		ssize_t this_len = min_t(ssize_t, count, PAGE_SIZE);
 
 		if (write && copy_from_user(page, buf, this_len)) {
 			copied = -EFAULT;
@@ -891,7 +891,7 @@ static ssize_t environ_read(struct file
 	struct task_struct *task = get_proc_task(file->f_dentry->d_inode);
 	char *page;
 	unsigned long src = *ppos;
-	int ret = -ESRCH;
+	ssize_t ret = -ESRCH;
 	struct mm_struct *mm;
 
 	if (!task)
@@ -910,7 +910,7 @@ static ssize_t environ_read(struct file
 
 	ret = 0;
 	while (count > 0) {
-		int this_len, retval, max_len;
+		long this_len, retval, max_len;
 
 		this_len = mm->env_end - (mm->env_start + src);
 
@@ -2510,7 +2510,7 @@ static void *proc_self_follow_link(struc
 static void proc_self_put_link(struct dentry *dentry, struct nameidata *nd,
 				void *cookie)
 {
-	char *s = nd_get_link(nd);
+	const char *s = nd_get_link(nd);
 	if (!IS_ERR(s))
 		__putname(s);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/proc/kcore.c linux-3.2.71-pax/fs/proc/kcore.c
--- linux-3.2.71/fs/proc/kcore.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/proc/kcore.c	2015-05-13 00:51:51.465517398 +0200
@@ -478,9 +478,10 @@ read_kcore(struct file *file, char __use
 	 * the addresses in the elf_phdr on our list.
 	 */
 	start = kc_offset_to_vaddr(*fpos - elf_buflen);
-	if ((tsz = (PAGE_SIZE - (start & ~PAGE_MASK))) > buflen)
+	tsz = PAGE_SIZE - (start & ~PAGE_MASK);
+	if (tsz > buflen)
 		tsz = buflen;
-		
+
 	while (buflen) {
 		struct kcore_list *m;
 
@@ -510,19 +511,20 @@ read_kcore(struct file *file, char __use
 		} else {
 			if (kern_addr_valid(start)) {
 				unsigned long n;
+				char *elf_buf;
+				mm_segment_t oldfs;
 
-				n = copy_to_user(buffer, (char *)start, tsz);
-				/*
-				 * We cannot distingush between fault on source
-				 * and fault on destination. When this happens
-				 * we clear too and hope it will trigger the
-				 * EFAULT again.
-				 */
-				if (n) { 
-					if (clear_user(buffer + tsz - n,
-								n))
-						return -EFAULT;
-				}
+				elf_buf = kzalloc(tsz, GFP_KERNEL);
+				if (!elf_buf)
+					return -ENOMEM;
+				oldfs = get_fs();
+				set_fs(KERNEL_DS);
+				n = __copy_from_user(elf_buf, (const void __user *)start, tsz);
+				set_fs(oldfs);
+				n = copy_to_user(buffer, elf_buf, tsz);
+				kfree(elf_buf);
+				if (n)
+					return -EFAULT;
 			} else {
 				if (clear_user(buffer, tsz))
 					return -EFAULT;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/proc/meminfo.c linux-3.2.71-pax/fs/proc/meminfo.c
--- linux-3.2.71/fs/proc/meminfo.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/proc/meminfo.c	2012-07-04 19:24:48.724063008 +0200
@@ -158,7 +158,7 @@ static int meminfo_proc_show(struct seq_
 		vmi.used >> 10,
 		vmi.largest_chunk >> 10
 #ifdef CONFIG_MEMORY_FAILURE
-		,atomic_long_read(&mce_bad_pages) << (PAGE_SHIFT - 10)
+		,atomic_long_read_unchecked(&mce_bad_pages) << (PAGE_SHIFT - 10)
 #endif
 #ifdef CONFIG_TRANSPARENT_HUGEPAGE
 		,K(global_page_state(NR_ANON_TRANSPARENT_HUGEPAGES) *
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/proc/nommu.c linux-3.2.71-pax/fs/proc/nommu.c
--- linux-3.2.71/fs/proc/nommu.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/proc/nommu.c	2012-07-04 19:24:48.724063008 +0200
@@ -66,7 +66,7 @@ static int nommu_region_show(struct seq_
 		if (len < 1)
 			len = 1;
 		seq_printf(m, "%*c", len, ' ');
-		seq_path(m, &file->f_path, "");
+		seq_path(m, &file->f_path, "\n\\");
 	}
 
 	seq_putc(m, '\n');
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/proc/proc_net.c linux-3.2.71-pax/fs/proc/proc_net.c
--- linux-3.2.71/fs/proc/proc_net.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/proc/proc_net.c	2013-03-29 04:02:48.959342568 +0100
@@ -228,7 +228,7 @@ static __net_exit void proc_net_ns_exit(
 	kfree(net->proc_net);
 }
 
-static struct pernet_operations __net_initdata proc_net_ns_ops = {
+static struct pernet_operations __net_initconst proc_net_ns_ops = {
 	.init = proc_net_ns_init,
 	.exit = proc_net_ns_exit,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/proc/task_mmu.c linux-3.2.71-pax/fs/proc/task_mmu.c
--- linux-3.2.71/fs/proc/task_mmu.c	2015-05-10 09:22:38.863493128 +0200
+++ linux-3.2.71-pax/fs/proc/task_mmu.c	2015-05-10 09:23:09.475494790 +0200
@@ -52,8 +52,13 @@ void task_mem(struct seq_file *m, struct
 		"VmExe:\t%8lu kB\n"
 		"VmLib:\t%8lu kB\n"
 		"VmPTE:\t%8lu kB\n"
-		"VmSwap:\t%8lu kB\n",
-		hiwater_vm << (PAGE_SHIFT-10),
+		"VmSwap:\t%8lu kB\n"
+
+#ifdef CONFIG_ARCH_TRACK_EXEC_LIMIT
+		"CsBase:\t%8lx\nCsLim:\t%8lx\n"
+#endif
+
+		,hiwater_vm << (PAGE_SHIFT-10),
 		(total_vm - mm->reserved_vm) << (PAGE_SHIFT-10),
 		mm->locked_vm << (PAGE_SHIFT-10),
 		mm->pinned_vm << (PAGE_SHIFT-10),
@@ -62,7 +67,13 @@ void task_mem(struct seq_file *m, struct
 		data << (PAGE_SHIFT-10),
 		mm->stack_vm << (PAGE_SHIFT-10), text, lib,
 		(PTRS_PER_PTE*sizeof(pte_t)*mm->nr_ptes) >> 10,
-		swap << (PAGE_SHIFT-10));
+		swap << (PAGE_SHIFT-10)
+
+#ifdef CONFIG_ARCH_TRACK_EXEC_LIMIT
+		, mm->context.user_cs_base, mm->context.user_cs_limit
+#endif
+
+	);
 }
 
 unsigned long task_vsize(struct mm_struct *mm)
@@ -227,20 +238,23 @@ static void show_map_vma(struct seq_file
 		pgoff = ((loff_t)vma->vm_pgoff) << PAGE_SHIFT;
 	}
 
-	/* We don't show the stack guard page in /proc/maps */
 	start = vma->vm_start;
-	if (stack_guard_page_start(vma, start))
-		start += PAGE_SIZE;
 	end = vma->vm_end;
-	if (stack_guard_page_end(vma, end))
-		end -= PAGE_SIZE;
 
 	seq_printf(m, "%08lx-%08lx %c%c%c%c %08llx %02x:%02x %lu %n",
 			start,
 			end,
+
+#if 0
+			flags & VM_MAYREAD ? flags & VM_READ ? 'R' : '+' : flags & VM_READ ? 'r' : '-',
+			flags & VM_MAYWRITE ? flags & VM_WRITE ? 'W' : '+' : flags & VM_WRITE ? 'w' : '-',
+			flags & VM_MAYEXEC ? flags & VM_EXEC ? 'X' : '+' : flags & VM_EXEC ? 'x' : '-',
+#else
 			flags & VM_READ ? 'r' : '-',
 			flags & VM_WRITE ? 'w' : '-',
 			flags & VM_EXEC ? 'x' : '-',
+#endif
+
 			flags & VM_MAYSHARE ? 's' : 'p',
 			pgoff,
 			MAJOR(dev), MINOR(dev), ino, &len);
@@ -251,7 +265,7 @@ static void show_map_vma(struct seq_file
 	 */
 	if (file) {
 		pad_len_spaces(m, len);
-		seq_path(m, &file->f_path, "\n");
+		seq_path(m, &file->f_path, "\n\\");
 	} else {
 		const char *name = arch_vma_name(vma);
 		if (!name) {
@@ -259,8 +273,9 @@ static void show_map_vma(struct seq_file
 				if (vma->vm_start <= mm->brk &&
 						vma->vm_end >= mm->start_brk) {
 					name = "[heap]";
-				} else if (vma->vm_start <= mm->start_stack &&
-					   vma->vm_end >= mm->start_stack) {
+				} else if ((vma->vm_flags & (VM_GROWSDOWN | VM_GROWSUP)) ||
+					   (vma->vm_start <= mm->start_stack &&
+					    vma->vm_end >= mm->start_stack)) {
 					name = "[stack]";
 				}
 			} else {
@@ -1055,7 +1070,7 @@ static int show_numa_map(struct seq_file
 
 	if (file) {
 		seq_printf(m, " file=");
-		seq_path(m, &file->f_path, "\n\t= ");
+		seq_path(m, &file->f_path, "\n\t\\= ");
 	} else if (vma->vm_start <= mm->brk && vma->vm_end >= mm->start_brk) {
 		seq_printf(m, " heap");
 	} else if (vma->vm_start <= mm->start_stack &&
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/proc/task_nommu.c linux-3.2.71-pax/fs/proc/task_nommu.c
--- linux-3.2.71/fs/proc/task_nommu.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/proc/task_nommu.c	2012-07-04 19:24:48.728063008 +0200
@@ -51,7 +51,7 @@ void task_mem(struct seq_file *m, struct
 	else
 		bytes += kobjsize(mm);
 	
-	if (current->fs && current->fs->users > 1)
+	if (current->fs && atomic_read(&current->fs->users) > 1)
 		sbytes += kobjsize(current->fs);
 	else
 		bytes += kobjsize(current->fs);
@@ -166,7 +166,7 @@ static int nommu_vma_show(struct seq_fil
 
 	if (file) {
 		pad_len_spaces(m, len);
-		seq_path(m, &file->f_path, "");
+		seq_path(m, &file->f_path, "\n\\");
 	} else if (mm) {
 		if (vma->vm_start <= mm->start_stack &&
 			vma->vm_end >= mm->start_stack) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/proc/vmcore.c linux-3.2.71-pax/fs/proc/vmcore.c
--- linux-3.2.71/fs/proc/vmcore.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/proc/vmcore.c	2013-06-21 19:34:10.638698102 +0200
@@ -97,9 +97,13 @@ static ssize_t read_from_oldmem(char *bu
 			nr_bytes = count;
 
 		/* If pfn is not ram, return zeros for sparse dump files */
-		if (pfn_is_ram(pfn) == 0)
-			memset(buf, 0, nr_bytes);
-		else {
+		if (pfn_is_ram(pfn) == 0) {
+			if (userbuf) {
+				if (clear_user((char __force_user *)buf, nr_bytes))
+					return -EFAULT;
+			} else
+				memset(buf, 0, nr_bytes);
+		} else {
 			tmp = copy_oldmem_page(pfn, buf, nr_bytes,
 						offset, userbuf);
 			if (tmp < 0)
@@ -184,7 +188,7 @@ static ssize_t read_vmcore(struct file *
 		tsz = nr_bytes;
 
 	while (buflen) {
-		tmp = read_from_oldmem(buffer, tsz, &start, 1);
+		tmp = read_from_oldmem((char __force_kernel *)buffer, tsz, &start, 1);
 		if (tmp < 0)
 			return tmp;
 		buflen -= tsz;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/quota/netlink.c linux-3.2.71-pax/fs/quota/netlink.c
--- linux-3.2.71/fs/quota/netlink.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/quota/netlink.c	2012-07-04 19:24:48.728063008 +0200
@@ -33,7 +33,7 @@ static struct genl_family quota_genl_fam
 void quota_send_warning(short type, unsigned int id, dev_t dev,
 			const char warntype)
 {
-	static atomic_t seq;
+	static atomic_unchecked_t seq;
 	struct sk_buff *skb;
 	void *msg_head;
 	int ret;
@@ -49,7 +49,7 @@ void quota_send_warning(short type, unsi
 		  "VFS: Not enough memory to send quota warning.\n");
 		return;
 	}
-	msg_head = genlmsg_put(skb, 0, atomic_add_return(1, &seq),
+	msg_head = genlmsg_put(skb, 0, atomic_add_return_unchecked(1, &seq),
 			&quota_genl_family, 0, QUOTA_NL_C_WARNING);
 	if (!msg_head) {
 		printk(KERN_ERR
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/readdir.c linux-3.2.71-pax/fs/readdir.c
--- linux-3.2.71/fs/readdir.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/readdir.c	2012-07-04 19:24:48.728063008 +0200
@@ -299,7 +299,7 @@ SYSCALL_DEFINE3(getdents64, unsigned int
 		error = buf.error;
 	lastdirent = buf.previous;
 	if (lastdirent) {
-		typeof(lastdirent->d_off) d_off = file->f_pos;
+		typeof(((struct linux_dirent64 *)0)->d_off) d_off = file->f_pos;
 		if (__put_user(d_off, &lastdirent->d_off))
 			error = -EFAULT;
 		else
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/reiserfs/do_balan.c linux-3.2.71-pax/fs/reiserfs/do_balan.c
--- linux-3.2.71/fs/reiserfs/do_balan.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/reiserfs/do_balan.c	2012-07-04 19:24:48.728063008 +0200
@@ -2051,7 +2051,7 @@ void do_balance(struct tree_balance *tb,
 		return;
 	}
 
-	atomic_inc(&(fs_generation(tb->tb_sb)));
+	atomic_inc_unchecked(&(fs_generation(tb->tb_sb)));
 	do_balance_starts(tb);
 
 	/* balance leaf returns 0 except if combining L R and S into
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/reiserfs/procfs.c linux-3.2.71-pax/fs/reiserfs/procfs.c
--- linux-3.2.71/fs/reiserfs/procfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/reiserfs/procfs.c	2012-07-04 19:24:48.728063008 +0200
@@ -113,7 +113,7 @@ static int show_super(struct seq_file *m
 		   "SMALL_TAILS " : "NO_TAILS ",
 		   replay_only(sb) ? "REPLAY_ONLY " : "",
 		   convert_reiserfs(sb) ? "CONV " : "",
-		   atomic_read(&r->s_generation_counter),
+		   atomic_read_unchecked(&r->s_generation_counter),
 		   SF(s_disk_reads), SF(s_disk_writes), SF(s_fix_nodes),
 		   SF(s_do_balance), SF(s_unneeded_left_neighbor),
 		   SF(s_good_search_by_key_reada), SF(s_bmaps),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/seq_file.c linux-3.2.71-pax/fs/seq_file.c
--- linux-3.2.71/fs/seq_file.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/seq_file.c	2013-11-23 18:07:03.681937074 +0100
@@ -132,7 +132,7 @@ Eoverflow:
 ssize_t seq_read(struct file *file, char __user *buf, size_t size, loff_t *ppos)
 {
 	struct seq_file *m = file->private_data;
-	size_t copied = 0;
+	ssize_t copied = 0;
 	loff_t pos;
 	size_t n;
 	void *p;
@@ -549,7 +549,7 @@ static void single_stop(struct seq_file
 int single_open(struct file *file, int (*show)(struct seq_file *, void *),
 		void *data)
 {
-	struct seq_operations *op = kmalloc(sizeof(*op), GFP_KERNEL);
+	seq_operations_no_const *op = kzalloc(sizeof(*op), GFP_KERNEL);
 	int res = -ENOMEM;
 
 	if (op) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/splice.c linux-3.2.71-pax/fs/splice.c
--- linux-3.2.71/fs/splice.c	2015-02-20 12:37:33.229178768 +0100
+++ linux-3.2.71-pax/fs/splice.c	2015-02-20 12:37:41.901178305 +0100
@@ -195,7 +195,7 @@ ssize_t splice_to_pipe(struct pipe_inode
 	pipe_lock(pipe);
 
 	for (;;) {
-		if (!pipe->readers) {
+		if (!atomic_read(&pipe->readers)) {
 			send_sig(SIGPIPE, current, 0);
 			if (!ret)
 				ret = -EPIPE;
@@ -249,9 +249,9 @@ ssize_t splice_to_pipe(struct pipe_inode
 			do_wakeup = 0;
 		}
 
-		pipe->waiting_writers++;
+		atomic_inc(&pipe->waiting_writers);
 		pipe_wait(pipe);
-		pipe->waiting_writers--;
+		atomic_dec(&pipe->waiting_writers);
 	}
 
 	pipe_unlock(pipe);
@@ -582,7 +582,7 @@ static ssize_t kernel_readv(struct file
 	old_fs = get_fs();
 	set_fs(get_ds());
 	/* The cast to a user pointer is valid due to the set_fs() */
-	res = vfs_readv(file, (const struct iovec __user *)vec, vlen, &pos);
+	res = vfs_readv(file, (const struct iovec __force_user *)vec, vlen, &pos);
 	set_fs(old_fs);
 
 	return res;
@@ -597,7 +597,7 @@ static ssize_t kernel_write(struct file
 	old_fs = get_fs();
 	set_fs(get_ds());
 	/* The cast to a user pointer is valid due to the set_fs() */
-	res = vfs_write(file, (const char __user *)buf, count, &pos);
+	res = vfs_write(file, (const char __force_user *)buf, count, &pos);
 	set_fs(old_fs);
 
 	return res;
@@ -649,7 +649,7 @@ ssize_t default_file_splice_read(struct
 			goto err;
 
 		this_len = min_t(size_t, len, PAGE_CACHE_SIZE - offset);
-		vec[i].iov_base = (void __user *) page_address(page);
+		vec[i].iov_base = (void __force_user *) page_address(page);
 		vec[i].iov_len = this_len;
 		spd.pages[i] = page;
 		spd.nr_pages++;
@@ -873,10 +873,10 @@ EXPORT_SYMBOL(splice_from_pipe_feed);
 int splice_from_pipe_next(struct pipe_inode_info *pipe, struct splice_desc *sd)
 {
 	while (!pipe->nrbufs) {
-		if (!pipe->writers)
+		if (!atomic_read(&pipe->writers))
 			return 0;
 
-		if (!pipe->waiting_writers && sd->num_spliced)
+		if (!atomic_read(&pipe->waiting_writers) && sd->num_spliced)
 			return 0;
 
 		if (sd->flags & SPLICE_F_NONBLOCK)
@@ -1213,7 +1213,7 @@ ssize_t splice_direct_to_actor(struct fi
 		 * out of the pipe right after the splice_to_pipe(). So set
 		 * PIPE_READERS appropriately.
 		 */
-		pipe->readers = 1;
+		atomic_set(&pipe->readers, 1);
 
 		current->splice_pipe = pipe;
 	}
@@ -1481,6 +1481,7 @@ static int get_iovec_page_array(const st
 
 			partial[buffers].offset = off;
 			partial[buffers].len = plen;
+			partial[buffers].private = 0;
 
 			off = 0;
 			len -= plen;
@@ -1766,9 +1767,9 @@ static int ipipe_prep(struct pipe_inode_
 			ret = -ERESTARTSYS;
 			break;
 		}
-		if (!pipe->writers)
+		if (!atomic_read(&pipe->writers))
 			break;
-		if (!pipe->waiting_writers) {
+		if (!atomic_read(&pipe->waiting_writers)) {
 			if (flags & SPLICE_F_NONBLOCK) {
 				ret = -EAGAIN;
 				break;
@@ -1800,7 +1801,7 @@ static int opipe_prep(struct pipe_inode_
 	pipe_lock(pipe);
 
 	while (pipe->nrbufs >= pipe->buffers) {
-		if (!pipe->readers) {
+		if (!atomic_read(&pipe->readers)) {
 			send_sig(SIGPIPE, current, 0);
 			ret = -EPIPE;
 			break;
@@ -1813,9 +1814,9 @@ static int opipe_prep(struct pipe_inode_
 			ret = -ERESTARTSYS;
 			break;
 		}
-		pipe->waiting_writers++;
+		atomic_inc(&pipe->waiting_writers);
 		pipe_wait(pipe);
-		pipe->waiting_writers--;
+		atomic_dec(&pipe->waiting_writers);
 	}
 
 	pipe_unlock(pipe);
@@ -1851,14 +1852,14 @@ retry:
 	pipe_double_lock(ipipe, opipe);
 
 	do {
-		if (!opipe->readers) {
+		if (!atomic_read(&opipe->readers)) {
 			send_sig(SIGPIPE, current, 0);
 			if (!ret)
 				ret = -EPIPE;
 			break;
 		}
 
-		if (!ipipe->nrbufs && !ipipe->writers)
+		if (!ipipe->nrbufs && !atomic_read(&ipipe->writers))
 			break;
 
 		/*
@@ -1955,7 +1956,7 @@ static int link_pipe(struct pipe_inode_i
 	pipe_double_lock(ipipe, opipe);
 
 	do {
-		if (!opipe->readers) {
+		if (!atomic_read(&opipe->readers)) {
 			send_sig(SIGPIPE, current, 0);
 			if (!ret)
 				ret = -EPIPE;
@@ -2000,7 +2001,7 @@ static int link_pipe(struct pipe_inode_i
 	 * return EAGAIN if we have the potential of some data in the
 	 * future, otherwise just return 0
 	 */
-	if (!ret && ipipe->waiting_writers && (flags & SPLICE_F_NONBLOCK))
+	if (!ret && atomic_read(&ipipe->waiting_writers) && (flags & SPLICE_F_NONBLOCK))
 		ret = -EAGAIN;
 
 	pipe_unlock(ipipe);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/squashfs/xattr.c linux-3.2.71-pax/fs/squashfs/xattr.c
--- linux-3.2.71/fs/squashfs/xattr.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/squashfs/xattr.c	2015-05-13 00:51:51.465517398 +0200
@@ -46,8 +46,8 @@ ssize_t squashfs_listxattr(struct dentry
 						 + msblk->xattr_table;
 	int offset = SQUASHFS_XATTR_OFFSET(squashfs_i(inode)->xattr);
 	int count = squashfs_i(inode)->xattr_count;
-	size_t rest = buffer_size;
-	int err;
+	size_t used = 0;
+	ssize_t err;
 
 	/* check that the file system has xattrs */
 	if (msblk->xattr_id_table == NULL)
@@ -68,11 +68,11 @@ ssize_t squashfs_listxattr(struct dentry
 		name_size = le16_to_cpu(entry.size);
 		handler = squashfs_xattr_handler(le16_to_cpu(entry.type));
 		if (handler)
-			prefix_size = handler->list(d, buffer, rest, NULL,
+			prefix_size = handler->list(d, buffer, buffer ? buffer_size - used : 0, NULL,
 				name_size, handler->flags);
 		if (prefix_size) {
 			if (buffer) {
-				if (prefix_size + name_size + 1 > rest) {
+				if (prefix_size + name_size + 1 > buffer_size - used) {
 					err = -ERANGE;
 					goto failed;
 				}
@@ -86,7 +86,7 @@ ssize_t squashfs_listxattr(struct dentry
 				buffer[name_size] = '\0';
 				buffer += name_size + 1;
 			}
-			rest -= prefix_size + name_size + 1;
+			used += prefix_size + name_size + 1;
 		} else  {
 			/* no handler or insuffficient privileges, so skip */
 			err = squashfs_read_metadata(sb, NULL, &start,
@@ -107,7 +107,7 @@ ssize_t squashfs_listxattr(struct dentry
 		if (err < 0)
 			goto failed;
 	}
-	err = buffer_size - rest;
+	err = used;
 
 failed:
 	return err;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/sysfs/bin.c linux-3.2.71-pax/fs/sysfs/bin.c
--- linux-3.2.71/fs/sysfs/bin.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/sysfs/bin.c	2013-04-05 19:58:05.772903585 +0200
@@ -233,13 +233,13 @@ static int bin_page_mkwrite(struct vm_ar
 	return ret;
 }
 
-static int bin_access(struct vm_area_struct *vma, unsigned long addr,
-		  void *buf, int len, int write)
+static ssize_t bin_access(struct vm_area_struct *vma, unsigned long addr,
+		  void *buf, size_t len, int write)
 {
 	struct file *file = vma->vm_file;
 	struct bin_buffer *bb = file->private_data;
 	struct sysfs_dirent *attr_sd = file->f_path.dentry->d_fsdata;
-	int ret;
+	ssize_t ret;
 
 	if (!bb->vm_ops)
 		return -EINVAL;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/sysfs/file.c linux-3.2.71-pax/fs/sysfs/file.c
--- linux-3.2.71/fs/sysfs/file.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/sysfs/file.c	2012-07-04 19:24:48.732063008 +0200
@@ -37,7 +37,7 @@ static DEFINE_SPINLOCK(sysfs_open_dirent
 
 struct sysfs_open_dirent {
 	atomic_t		refcnt;
-	atomic_t		event;
+	atomic_unchecked_t	event;
 	wait_queue_head_t	poll;
 	struct list_head	buffers; /* goes through sysfs_buffer.list */
 };
@@ -81,7 +81,7 @@ static int fill_read_buffer(struct dentr
 	if (!sysfs_get_active(attr_sd))
 		return -ENODEV;
 
-	buffer->event = atomic_read(&attr_sd->s_attr.open->event);
+	buffer->event = atomic_read_unchecked(&attr_sd->s_attr.open->event);
 	count = ops->show(kobj, attr_sd->s_attr.attr, buffer->page);
 
 	sysfs_put_active(attr_sd);
@@ -287,7 +287,7 @@ static int sysfs_get_open_dirent(struct
 		return -ENOMEM;
 
 	atomic_set(&new_od->refcnt, 0);
-	atomic_set(&new_od->event, 1);
+	atomic_set_unchecked(&new_od->event, 1);
 	init_waitqueue_head(&new_od->poll);
 	INIT_LIST_HEAD(&new_od->buffers);
 	goto retry;
@@ -432,7 +432,7 @@ static unsigned int sysfs_poll(struct fi
 
 	sysfs_put_active(attr_sd);
 
-	if (buffer->event != atomic_read(&od->event))
+	if (buffer->event != atomic_read_unchecked(&od->event))
 		goto trigger;
 
 	return DEFAULT_POLLMASK;
@@ -451,7 +451,7 @@ void sysfs_notify_dirent(struct sysfs_di
 
 	od = sd->s_attr.open;
 	if (od) {
-		atomic_inc(&od->event);
+		atomic_inc_unchecked(&od->event);
 		wake_up_interruptible(&od->poll);
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/sysfs/symlink.c linux-3.2.71-pax/fs/sysfs/symlink.c
--- linux-3.2.71/fs/sysfs/symlink.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/sysfs/symlink.c	2012-07-04 19:24:48.732063008 +0200
@@ -286,7 +286,7 @@ static void *sysfs_follow_link(struct de
 
 static void sysfs_put_link(struct dentry *dentry, struct nameidata *nd, void *cookie)
 {
-	char *page = nd_get_link(nd);
+	const char *page = nd_get_link(nd);
 	if (!IS_ERR(page))
 		free_page((unsigned long)page);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/sysv/sysv.h linux-3.2.71-pax/fs/sysv/sysv.h
--- linux-3.2.71/fs/sysv/sysv.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/sysv/sysv.h	2013-03-28 04:10:58.183929538 +0100
@@ -189,7 +189,7 @@ static inline u32 PDP_swab(u32 x)
 #endif
 }
 
-static inline __u32 fs32_to_cpu(struct sysv_sb_info *sbi, __fs32 n)
+static inline __u32 __intentional_overflow(-1) fs32_to_cpu(struct sysv_sb_info *sbi, __fs32 n)
 {
 	if (sbi->s_bytesex == BYTESEX_PDP)
 		return PDP_swab((__force __u32)n);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ubifs/io.c linux-3.2.71-pax/fs/ubifs/io.c
--- linux-3.2.71/fs/ubifs/io.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/ubifs/io.c	2013-03-28 04:10:58.183929538 +0100
@@ -156,7 +156,7 @@ int ubifs_leb_change(struct ubifs_info *
 	return err;
 }
 
-int ubifs_leb_unmap(struct ubifs_info *c, int lnum)
+int __intentional_overflow(-1) ubifs_leb_unmap(struct ubifs_info *c, int lnum)
 {
 	int err;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/udf/misc.c linux-3.2.71-pax/fs/udf/misc.c
--- linux-3.2.71/fs/udf/misc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/udf/misc.c	2012-07-04 19:24:48.732063008 +0200
@@ -289,7 +289,7 @@ void udf_new_tag(char *data, uint16_t id
 
 u8 udf_tag_checksum(const struct tag *t)
 {
-	u8 *data = (u8 *)t;
+	const u8 *data = (const u8 *)t;
 	u8 checksum = 0;
 	int i;
 	for (i = 0; i < sizeof(struct tag); ++i)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/ufs/swab.h linux-3.2.71-pax/fs/ufs/swab.h
--- linux-3.2.71/fs/ufs/swab.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/ufs/swab.h	2013-11-23 18:07:03.689937074 +0100
@@ -22,7 +22,7 @@ enum {
 	BYTESEX_BE
 };
 
-static inline u64
+static inline u64 __intentional_overflow(-1)
 fs64_to_cpu(struct super_block *sbp, __fs64 n)
 {
 	if (UFS_SB(sbp)->s_bytesex == BYTESEX_LE)
@@ -40,7 +40,7 @@ cpu_to_fs64(struct super_block *sbp, u64
 		return (__force __fs64)cpu_to_be64(n);
 }
 
-static inline u32
+static inline u32 __intentional_overflow(-1)
 fs32_to_cpu(struct super_block *sbp, __fs32 n)
 {
 	if (UFS_SB(sbp)->s_bytesex == BYTESEX_LE)
@@ -76,7 +76,7 @@ fs32_sub(struct super_block *sbp, __fs32
 		be32_add_cpu((__be32 *)n, -d);
 }
 
-static inline u16
+static inline u16 __intentional_overflow(-1)
 fs16_to_cpu(struct super_block *sbp, __fs16 n)
 {
 	if (UFS_SB(sbp)->s_bytesex == BYTESEX_LE)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/xattr_acl.c linux-3.2.71-pax/fs/xattr_acl.c
--- linux-3.2.71/fs/xattr_acl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/xattr_acl.c	2012-07-04 19:24:48.732063008 +0200
@@ -17,8 +17,8 @@
 struct posix_acl *
 posix_acl_from_xattr(const void *value, size_t size)
 {
-	posix_acl_xattr_header *header = (posix_acl_xattr_header *)value;
-	posix_acl_xattr_entry *entry = (posix_acl_xattr_entry *)(header+1), *end;
+	const posix_acl_xattr_header *header = (const posix_acl_xattr_header *)value;
+	const posix_acl_xattr_entry *entry = (const posix_acl_xattr_entry *)(header+1), *end;
 	int count;
 	struct posix_acl *acl;
 	struct posix_acl_entry *acl_e;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/xattr.c linux-3.2.71-pax/fs/xattr.c
--- linux-3.2.71/fs/xattr.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/xattr.c	2013-05-13 13:19:36.659753773 +0200
@@ -225,6 +225,27 @@ int vfs_xattr_cmp(struct dentry *dentry,
 	return rc;
 }
 
+#ifdef CONFIG_PAX_XATTR_PAX_FLAGS
+ssize_t
+pax_getxattr(struct dentry *dentry, void *value, size_t size)
+{
+	struct inode *inode = dentry->d_inode;
+	ssize_t error;
+
+	error = inode_permission(inode, MAY_EXEC);
+	if (error)
+		return error;
+
+	if (inode->i_op->getxattr)
+		error = inode->i_op->getxattr(dentry, XATTR_NAME_PAX_FLAGS, value, size);
+	else
+		error = -EOPNOTSUPP;
+
+	return error;
+}
+EXPORT_SYMBOL(pax_getxattr);
+#endif
+
 ssize_t
 vfs_getxattr(struct dentry *dentry, const char *name, void *value, size_t size)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/xfs/xfs_bmap.c linux-3.2.71-pax/fs/xfs/xfs_bmap.c
--- linux-3.2.71/fs/xfs/xfs_bmap.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/xfs/xfs_bmap.c	2012-07-04 19:24:48.736063008 +0200
@@ -190,7 +190,7 @@ xfs_bmap_validate_ret(
 	int			nmap,
 	int			ret_nmap);
 #else
-#define	xfs_bmap_validate_ret(bno,len,flags,mval,onmap,nmap)
+#define	xfs_bmap_validate_ret(bno,len,flags,mval,onmap,nmap) do {} while (0)
 #endif /* DEBUG */
 
 STATIC int
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/xfs/xfs_dir2_sf.c linux-3.2.71-pax/fs/xfs/xfs_dir2_sf.c
--- linux-3.2.71/fs/xfs/xfs_dir2_sf.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/fs/xfs/xfs_dir2_sf.c	2012-07-04 19:24:48.736063008 +0200
@@ -852,7 +852,15 @@ xfs_dir2_sf_getdents(
 		}
 
 		ino = xfs_dir2_sfe_get_ino(sfp, sfep);
-		if (filldir(dirent, (char *)sfep->name, sfep->namelen,
+		if (dp->i_df.if_u1.if_data == dp->i_df.if_u2.if_inline_data) {
+			char name[sfep->namelen];
+			memcpy(name, sfep->name, sfep->namelen);
+			if (filldir(dirent, name, sfep->namelen,
+			    off & 0x7fffffff, ino, DT_UNKNOWN)) {
+				*offset = off & 0x7fffffff;
+				return 0;
+			}
+		} else if (filldir(dirent, (char *)sfep->name, sfep->namelen,
 			    off & 0x7fffffff, ino, DT_UNKNOWN)) {
 			*offset = off & 0x7fffffff;
 			return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/xfs/xfs_ioctl.c linux-3.2.71-pax/fs/xfs/xfs_ioctl.c
--- linux-3.2.71/fs/xfs/xfs_ioctl.c	2014-01-03 15:48:45.032070562 +0100
+++ linux-3.2.71-pax/fs/xfs/xfs_ioctl.c	2014-01-03 15:48:49.592070319 +0100
@@ -128,7 +128,7 @@ xfs_find_handle(
 	}
 
 	error = -EFAULT;
-	if (copy_to_user(hreq->ohandle, &handle, hsize) ||
+	if (hsize > sizeof handle || copy_to_user(hreq->ohandle, &handle, hsize) ||
 	    copy_to_user(hreq->ohandlen, &hsize, sizeof(__s32)))
 		goto out_put;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/fs/xfs/xfs_iops.c linux-3.2.71-pax/fs/xfs/xfs_iops.c
--- linux-3.2.71/fs/xfs/xfs_iops.c	2015-05-10 09:22:38.891493129 +0200
+++ linux-3.2.71-pax/fs/xfs/xfs_iops.c	2015-05-10 09:23:09.479494791 +0200
@@ -447,7 +447,7 @@ xfs_vn_put_link(
 	struct nameidata *nd,
 	void		*p)
 {
-	char		*s = nd_get_link(nd);
+	const char	*s = nd_get_link(nd);
 
 	if (!IS_ERR(s))
 		kfree(s);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/4level-fixup.h linux-3.2.71-pax/include/asm-generic/4level-fixup.h
--- linux-3.2.71/include/asm-generic/4level-fixup.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/4level-fixup.h	2012-09-06 15:39:16.422757010 +0200
@@ -13,8 +13,10 @@
 #define pmd_alloc(mm, pud, address) \
 	((unlikely(pgd_none(*(pud))) && __pmd_alloc(mm, pud, address))? \
  		NULL: pmd_offset(pud, address))
+#define pmd_alloc_kernel(mm, pud, address) pmd_alloc((mm), (pud), (address))
 
 #define pud_alloc(mm, pgd, address)	(pgd)
+#define pud_alloc_kernel(mm, pgd, address)	pud_alloc((mm), (pgd), (address))
 #define pud_offset(pgd, start)		(pgd)
 #define pud_none(pud)			0
 #define pud_bad(pud)			0
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/atomic64.h linux-3.2.71-pax/include/asm-generic/atomic64.h
--- linux-3.2.71/include/asm-generic/atomic64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/atomic64.h	2012-07-04 19:24:48.740063008 +0200
@@ -16,6 +16,8 @@ typedef struct {
 	long long counter;
 } atomic64_t;
 
+typedef atomic64_t atomic64_unchecked_t;
+
 #define ATOMIC64_INIT(i)	{ (i) }
 
 extern long long atomic64_read(const atomic64_t *v);
@@ -39,4 +41,14 @@ extern int	 atomic64_add_unless(atomic64
 #define atomic64_dec_and_test(v)	(atomic64_dec_return((v)) == 0)
 #define atomic64_inc_not_zero(v) 	atomic64_add_unless((v), 1LL, 0LL)
 
+#define atomic64_read_unchecked(v) atomic64_read(v)
+#define atomic64_set_unchecked(v, i) atomic64_set((v), (i))
+#define atomic64_add_unchecked(a, v) atomic64_add((a), (v))
+#define atomic64_add_return_unchecked(a, v) atomic64_add_return((a), (v))
+#define atomic64_sub_unchecked(a, v) atomic64_sub((a), (v))
+#define atomic64_inc_unchecked(v) atomic64_inc(v)
+#define atomic64_inc_return_unchecked(v) atomic64_inc_return(v)
+#define atomic64_dec_unchecked(v) atomic64_dec(v)
+#define atomic64_cmpxchg_unchecked(v, o, n) atomic64_cmpxchg((v), (o), (n))
+
 #endif  /*  _ASM_GENERIC_ATOMIC64_H  */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/atomic.h linux-3.2.71-pax/include/asm-generic/atomic.h
--- linux-3.2.71/include/asm-generic/atomic.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/atomic.h	2012-07-21 10:46:40.672999081 +0200
@@ -158,7 +158,7 @@ static inline int __atomic_add_unless(at
  * Atomically clears the bits set in @mask from @v
  */
 #ifndef atomic_clear_mask
-static inline void atomic_clear_mask(unsigned long mask, atomic_t *v)
+static inline void atomic_clear_mask(unsigned int mask, atomic_t *v)
 {
 	unsigned long flags;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/atomic-long.h linux-3.2.71-pax/include/asm-generic/atomic-long.h
--- linux-3.2.71/include/asm-generic/atomic-long.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/atomic-long.h	2015-01-05 18:19:16.139492988 +0100
@@ -22,6 +22,12 @@
 
 typedef atomic64_t atomic_long_t;
 
+#ifdef CONFIG_PAX_REFCOUNT
+typedef atomic64_unchecked_t atomic_long_unchecked_t;
+#else
+typedef atomic64_t atomic_long_unchecked_t;
+#endif
+
 #define ATOMIC_LONG_INIT(i)	ATOMIC64_INIT(i)
 
 static inline long atomic_long_read(atomic_long_t *l)
@@ -31,6 +37,15 @@ static inline long atomic_long_read(atom
 	return (long)atomic64_read(v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline long atomic_long_read_unchecked(atomic_long_unchecked_t *l)
+{
+	atomic64_unchecked_t *v = (atomic64_unchecked_t *)l;
+
+	return (long)atomic64_read_unchecked(v);
+}
+#endif
+
 static inline void atomic_long_set(atomic_long_t *l, long i)
 {
 	atomic64_t *v = (atomic64_t *)l;
@@ -38,6 +53,15 @@ static inline void atomic_long_set(atomi
 	atomic64_set(v, i);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline void atomic_long_set_unchecked(atomic_long_unchecked_t *l, long i)
+{
+	atomic64_unchecked_t *v = (atomic64_unchecked_t *)l;
+
+	atomic64_set_unchecked(v, i);
+}
+#endif
+
 static inline void atomic_long_inc(atomic_long_t *l)
 {
 	atomic64_t *v = (atomic64_t *)l;
@@ -45,6 +69,15 @@ static inline void atomic_long_inc(atomi
 	atomic64_inc(v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline void atomic_long_inc_unchecked(atomic_long_unchecked_t *l)
+{
+	atomic64_unchecked_t *v = (atomic64_unchecked_t *)l;
+
+	atomic64_inc_unchecked(v);
+}
+#endif
+
 static inline void atomic_long_dec(atomic_long_t *l)
 {
 	atomic64_t *v = (atomic64_t *)l;
@@ -52,6 +85,15 @@ static inline void atomic_long_dec(atomi
 	atomic64_dec(v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline void atomic_long_dec_unchecked(atomic_long_unchecked_t *l)
+{
+	atomic64_unchecked_t *v = (atomic64_unchecked_t *)l;
+
+	atomic64_dec_unchecked(v);
+}
+#endif
+
 static inline void atomic_long_add(long i, atomic_long_t *l)
 {
 	atomic64_t *v = (atomic64_t *)l;
@@ -59,6 +101,15 @@ static inline void atomic_long_add(long
 	atomic64_add(i, v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline void atomic_long_add_unchecked(long i, atomic_long_unchecked_t *l)
+{
+	atomic64_unchecked_t *v = (atomic64_unchecked_t *)l;
+
+	atomic64_add_unchecked(i, v);
+}
+#endif
+
 static inline void atomic_long_sub(long i, atomic_long_t *l)
 {
 	atomic64_t *v = (atomic64_t *)l;
@@ -66,6 +117,15 @@ static inline void atomic_long_sub(long
 	atomic64_sub(i, v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline void atomic_long_sub_unchecked(long i, atomic_long_unchecked_t *l)
+{
+	atomic64_unchecked_t *v = (atomic64_unchecked_t *)l;
+
+	atomic64_sub_unchecked(i, v);
+}
+#endif
+
 static inline int atomic_long_sub_and_test(long i, atomic_long_t *l)
 {
 	atomic64_t *v = (atomic64_t *)l;
@@ -94,13 +154,22 @@ static inline int atomic_long_add_negati
 	return atomic64_add_negative(i, v);
 }
 
-static inline long atomic_long_add_return(long i, atomic_long_t *l)
+static inline long __intentional_overflow(-1) atomic_long_add_return(long i, atomic_long_t *l)
 {
 	atomic64_t *v = (atomic64_t *)l;
 
 	return (long)atomic64_add_return(i, v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline long atomic_long_add_return_unchecked(long i, atomic_long_unchecked_t *l)
+{
+	atomic64_unchecked_t *v = (atomic64_unchecked_t *)l;
+
+	return (long)atomic64_add_return_unchecked(i, v);
+}
+#endif
+
 static inline long atomic_long_sub_return(long i, atomic_long_t *l)
 {
 	atomic64_t *v = (atomic64_t *)l;
@@ -115,6 +184,15 @@ static inline long atomic_long_inc_retur
 	return (long)atomic64_inc_return(v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline long atomic_long_inc_return_unchecked(atomic_long_unchecked_t *l)
+{
+	atomic64_unchecked_t *v = (atomic64_unchecked_t *)l;
+
+	return (long)atomic64_inc_return_unchecked(v);
+}
+#endif
+
 static inline long atomic_long_dec_return(atomic_long_t *l)
 {
 	atomic64_t *v = (atomic64_t *)l;
@@ -140,6 +218,12 @@ static inline long atomic_long_add_unles
 
 typedef atomic_t atomic_long_t;
 
+#ifdef CONFIG_PAX_REFCOUNT
+typedef atomic_unchecked_t atomic_long_unchecked_t;
+#else
+typedef atomic_t atomic_long_unchecked_t;
+#endif
+
 #define ATOMIC_LONG_INIT(i)	ATOMIC_INIT(i)
 static inline long atomic_long_read(atomic_long_t *l)
 {
@@ -148,6 +232,15 @@ static inline long atomic_long_read(atom
 	return (long)atomic_read(v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline long atomic_long_read_unchecked(atomic_long_unchecked_t *l)
+{
+	atomic_unchecked_t *v = (atomic_unchecked_t *)l;
+
+	return (long)atomic_read_unchecked(v);
+}
+#endif
+
 static inline void atomic_long_set(atomic_long_t *l, long i)
 {
 	atomic_t *v = (atomic_t *)l;
@@ -155,6 +248,15 @@ static inline void atomic_long_set(atomi
 	atomic_set(v, i);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline void atomic_long_set_unchecked(atomic_long_unchecked_t *l, long i)
+{
+	atomic_unchecked_t *v = (atomic_unchecked_t *)l;
+
+	atomic_set_unchecked(v, i);
+}
+#endif
+
 static inline void atomic_long_inc(atomic_long_t *l)
 {
 	atomic_t *v = (atomic_t *)l;
@@ -162,6 +264,15 @@ static inline void atomic_long_inc(atomi
 	atomic_inc(v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline void atomic_long_inc_unchecked(atomic_long_unchecked_t *l)
+{
+	atomic_unchecked_t *v = (atomic_unchecked_t *)l;
+
+	atomic_inc_unchecked(v);
+}
+#endif
+
 static inline void atomic_long_dec(atomic_long_t *l)
 {
 	atomic_t *v = (atomic_t *)l;
@@ -169,6 +280,15 @@ static inline void atomic_long_dec(atomi
 	atomic_dec(v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline void atomic_long_dec_unchecked(atomic_long_unchecked_t *l)
+{
+	atomic_unchecked_t *v = (atomic_unchecked_t *)l;
+
+	atomic_dec_unchecked(v);
+}
+#endif
+
 static inline void atomic_long_add(long i, atomic_long_t *l)
 {
 	atomic_t *v = (atomic_t *)l;
@@ -176,6 +296,15 @@ static inline void atomic_long_add(long
 	atomic_add(i, v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline void atomic_long_add_unchecked(long i, atomic_long_unchecked_t *l)
+{
+	atomic_unchecked_t *v = (atomic_unchecked_t *)l;
+
+	atomic_add_unchecked(i, v);
+}
+#endif
+
 static inline void atomic_long_sub(long i, atomic_long_t *l)
 {
 	atomic_t *v = (atomic_t *)l;
@@ -183,6 +312,15 @@ static inline void atomic_long_sub(long
 	atomic_sub(i, v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline void atomic_long_sub_unchecked(long i, atomic_long_unchecked_t *l)
+{
+	atomic_unchecked_t *v = (atomic_unchecked_t *)l;
+
+	atomic_sub_unchecked(i, v);
+}
+#endif
+
 static inline int atomic_long_sub_and_test(long i, atomic_long_t *l)
 {
 	atomic_t *v = (atomic_t *)l;
@@ -211,13 +349,23 @@ static inline int atomic_long_add_negati
 	return atomic_add_negative(i, v);
 }
 
-static inline long atomic_long_add_return(long i, atomic_long_t *l)
+static inline long __intentional_overflow(-1) atomic_long_add_return(long i, atomic_long_t *l)
 {
 	atomic_t *v = (atomic_t *)l;
 
 	return (long)atomic_add_return(i, v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline long atomic_long_add_return_unchecked(long i, atomic_long_unchecked_t *l)
+{
+	atomic_unchecked_t *v = (atomic_unchecked_t *)l;
+
+	return (long)atomic_add_return_unchecked(i, v);
+}
+
+#endif
+
 static inline long atomic_long_sub_return(long i, atomic_long_t *l)
 {
 	atomic_t *v = (atomic_t *)l;
@@ -232,6 +380,15 @@ static inline long atomic_long_inc_retur
 	return (long)atomic_inc_return(v);
 }
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline long atomic_long_inc_return_unchecked(atomic_long_unchecked_t *l)
+{
+	atomic_unchecked_t *v = (atomic_unchecked_t *)l;
+
+	return (long)atomic_inc_return_unchecked(v);
+}
+#endif
+
 static inline long atomic_long_dec_return(atomic_long_t *l)
 {
 	atomic_t *v = (atomic_t *)l;
@@ -255,4 +412,57 @@ static inline long atomic_long_add_unles
 
 #endif  /*  BITS_PER_LONG == 64  */
 
+#ifdef CONFIG_PAX_REFCOUNT
+static inline void pax_refcount_needs_these_functions(void)
+{
+	atomic_read_unchecked((atomic_unchecked_t *)NULL);
+	atomic_set_unchecked((atomic_unchecked_t *)NULL, 0);
+	atomic_add_unchecked(0, (atomic_unchecked_t *)NULL);
+	atomic_sub_unchecked(0, (atomic_unchecked_t *)NULL);
+	atomic_inc_unchecked((atomic_unchecked_t *)NULL);
+	(void)atomic_inc_and_test_unchecked((atomic_unchecked_t *)NULL);
+	atomic_inc_return_unchecked((atomic_unchecked_t *)NULL);
+	atomic_add_return_unchecked(0, (atomic_unchecked_t *)NULL);
+	atomic_dec_unchecked((atomic_unchecked_t *)NULL);
+	atomic_cmpxchg_unchecked((atomic_unchecked_t *)NULL, 0, 0);
+	(void)atomic_xchg_unchecked((atomic_unchecked_t *)NULL, 0);
+#ifdef CONFIG_X86
+	atomic_clear_mask_unchecked(0, NULL);
+	atomic_set_mask_unchecked(0, NULL);
+#endif
+
+	atomic_long_read_unchecked((atomic_long_unchecked_t *)NULL);
+	atomic_long_set_unchecked((atomic_long_unchecked_t *)NULL, 0);
+	atomic_long_add_unchecked(0, (atomic_long_unchecked_t *)NULL);
+	atomic_long_sub_unchecked(0, (atomic_long_unchecked_t *)NULL);
+	atomic_long_inc_unchecked((atomic_long_unchecked_t *)NULL);
+	atomic_long_add_return_unchecked(0, (atomic_long_unchecked_t *)NULL);
+	atomic_long_inc_return_unchecked((atomic_long_unchecked_t *)NULL);
+	atomic_long_dec_unchecked((atomic_long_unchecked_t *)NULL);
+}
+#else
+#define atomic_read_unchecked(v) atomic_read(v)
+#define atomic_set_unchecked(v, i) atomic_set((v), (i))
+#define atomic_add_unchecked(i, v) atomic_add((i), (v))
+#define atomic_sub_unchecked(i, v) atomic_sub((i), (v))
+#define atomic_inc_unchecked(v) atomic_inc(v)
+#define atomic_inc_and_test_unchecked(v) atomic_inc_and_test(v)
+#define atomic_inc_return_unchecked(v) atomic_inc_return(v)
+#define atomic_add_return_unchecked(i, v) atomic_add_return((i), (v))
+#define atomic_dec_unchecked(v) atomic_dec(v)
+#define atomic_cmpxchg_unchecked(v, o, n) atomic_cmpxchg((v), (o), (n))
+#define atomic_xchg_unchecked(v, i) atomic_xchg((v), (i))
+#define atomic_clear_mask_unchecked(mask, v) atomic_clear_mask((mask), (v))
+#define atomic_set_mask_unchecked(mask, v) atomic_set_mask((mask), (v))
+
+#define atomic_long_read_unchecked(v) atomic_long_read(v)
+#define atomic_long_set_unchecked(v, i) atomic_long_set((v), (i))
+#define atomic_long_add_unchecked(i, v) atomic_long_add((i), (v))
+#define atomic_long_sub_unchecked(i, v) atomic_long_sub((i), (v))
+#define atomic_long_inc_unchecked(v) atomic_long_inc(v)
+#define atomic_long_add_return_unchecked(i, v) atomic_long_add_return((i), (v))
+#define atomic_long_inc_return_unchecked(v) atomic_long_inc_return(v)
+#define atomic_long_dec_unchecked(v) atomic_long_dec(v)
+#endif
+
 #endif  /*  _ASM_GENERIC_ATOMIC_LONG_H  */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/bitops/fls64.h linux-3.2.71-pax/include/asm-generic/bitops/fls64.h
--- linux-3.2.71/include/asm-generic/bitops/fls64.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/bitops/fls64.h	2013-12-03 02:19:10.934699987 +0100
@@ -15,7 +15,7 @@
  * at position 64.
  */
 #if BITS_PER_LONG == 32
-static __always_inline int fls64(__u64 x)
+static __always_inline int __intentional_overflow(-1) fls64(__u64 x)
 {
 	__u32 h = x >> 32;
 	if (h)
@@ -23,7 +23,7 @@ static __always_inline int fls64(__u64 x
 	return fls(x);
 }
 #elif BITS_PER_LONG == 64
-static __always_inline int fls64(__u64 x)
+static __always_inline int __intentional_overflow(-1) fls64(__u64 x)
 {
 	if (x == 0)
 		return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/bitops/__fls.h linux-3.2.71-pax/include/asm-generic/bitops/__fls.h
--- linux-3.2.71/include/asm-generic/bitops/__fls.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/bitops/__fls.h	2013-12-07 22:27:48.142121160 +0100
@@ -9,7 +9,7 @@
  *
  * Undefined if no set bit exists, so code should check against 0 first.
  */
-static __always_inline unsigned long __fls(unsigned long word)
+static __always_inline unsigned long __intentional_overflow(-1) __fls(unsigned long word)
 {
 	int num = BITS_PER_LONG - 1;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/bitops/fls.h linux-3.2.71-pax/include/asm-generic/bitops/fls.h
--- linux-3.2.71/include/asm-generic/bitops/fls.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/bitops/fls.h	2013-12-03 02:19:10.938699987 +0100
@@ -9,7 +9,7 @@
  * Note fls(0) = 0, fls(1) = 1, fls(0x80000000) = 32.
  */
 
-static __always_inline int fls(int x)
+static __always_inline int __intentional_overflow(-1) fls(int x)
 {
 	int r = 32;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/cache.h linux-3.2.71-pax/include/asm-generic/cache.h
--- linux-3.2.71/include/asm-generic/cache.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/cache.h	2012-07-04 19:24:48.740063008 +0200
@@ -6,7 +6,7 @@
  * cache lines need to provide their own cache.h.
  */
 
-#define L1_CACHE_SHIFT		5
-#define L1_CACHE_BYTES		(1 << L1_CACHE_SHIFT)
+#define L1_CACHE_SHIFT		5UL
+#define L1_CACHE_BYTES		(1UL << L1_CACHE_SHIFT)
 
 #endif /* __ASM_GENERIC_CACHE_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/emergency-restart.h linux-3.2.71-pax/include/asm-generic/emergency-restart.h
--- linux-3.2.71/include/asm-generic/emergency-restart.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/emergency-restart.h	2012-07-04 19:24:48.740063008 +0200
@@ -1,7 +1,7 @@
 #ifndef _ASM_GENERIC_EMERGENCY_RESTART_H
 #define _ASM_GENERIC_EMERGENCY_RESTART_H
 
-static inline void machine_emergency_restart(void)
+static inline __noreturn void machine_emergency_restart(void)
 {
 	machine_restart(NULL);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/kmap_types.h linux-3.2.71-pax/include/asm-generic/kmap_types.h
--- linux-3.2.71/include/asm-generic/kmap_types.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/kmap_types.h	2012-07-04 19:24:48.740063008 +0200
@@ -29,10 +29,11 @@ KMAP_D(16)	KM_IRQ_PTE,
 KMAP_D(17)	KM_NMI,
 KMAP_D(18)	KM_NMI_PTE,
 KMAP_D(19)	KM_KDB,
+KMAP_D(20)	KM_CLEARPAGE,
 /*
  * Remember to update debug_kmap_atomic() when adding new kmap types!
  */
-KMAP_D(20)	KM_TYPE_NR
+KMAP_D(21)	KM_TYPE_NR
 };
 
 #undef KMAP_D
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/local.h linux-3.2.71-pax/include/asm-generic/local.h
--- linux-3.2.71/include/asm-generic/local.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/local.h	2012-12-14 19:33:32.713556879 +0100
@@ -23,24 +23,37 @@ typedef struct
 	atomic_long_t a;
 } local_t;
 
+typedef struct {
+	atomic_long_unchecked_t a;
+} local_unchecked_t;
+
 #define LOCAL_INIT(i)	{ ATOMIC_LONG_INIT(i) }
 
 #define local_read(l)	atomic_long_read(&(l)->a)
+#define local_read_unchecked(l)	atomic_long_read_unchecked(&(l)->a)
 #define local_set(l,i)	atomic_long_set((&(l)->a),(i))
+#define local_set_unchecked(l,i)	atomic_long_set_unchecked((&(l)->a),(i))
 #define local_inc(l)	atomic_long_inc(&(l)->a)
+#define local_inc_unchecked(l)	atomic_long_inc_unchecked(&(l)->a)
 #define local_dec(l)	atomic_long_dec(&(l)->a)
+#define local_dec_unchecked(l)	atomic_long_dec_unchecked(&(l)->a)
 #define local_add(i,l)	atomic_long_add((i),(&(l)->a))
+#define local_add_unchecked(i,l)	atomic_long_add_unchecked((i),(&(l)->a))
 #define local_sub(i,l)	atomic_long_sub((i),(&(l)->a))
+#define local_sub_unchecked(i,l)	atomic_long_sub_unchecked((i),(&(l)->a))
 
 #define local_sub_and_test(i, l) atomic_long_sub_and_test((i), (&(l)->a))
 #define local_dec_and_test(l) atomic_long_dec_and_test(&(l)->a)
 #define local_inc_and_test(l) atomic_long_inc_and_test(&(l)->a)
 #define local_add_negative(i, l) atomic_long_add_negative((i), (&(l)->a))
 #define local_add_return(i, l) atomic_long_add_return((i), (&(l)->a))
+#define local_add_return_unchecked(i, l) atomic_long_add_return_unchecked((i), (&(l)->a))
 #define local_sub_return(i, l) atomic_long_sub_return((i), (&(l)->a))
 #define local_inc_return(l) atomic_long_inc_return(&(l)->a)
+#define local_dec_return(l) atomic_long_dec_return(&(l)->a)
 
 #define local_cmpxchg(l, o, n) atomic_long_cmpxchg((&(l)->a), (o), (n))
+#define local_cmpxchg_unchecked(l, o, n) atomic_long_cmpxchg((&(l)->a), (o), (n))
 #define local_xchg(l, n) atomic_long_xchg((&(l)->a), (n))
 #define local_add_unless(l, _a, u) atomic_long_add_unless((&(l)->a), (_a), (u))
 #define local_inc_not_zero(l) atomic_long_inc_not_zero(&(l)->a)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/pgtable.h linux-3.2.71-pax/include/asm-generic/pgtable.h
--- linux-3.2.71/include/asm-generic/pgtable.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/pgtable.h	2013-09-17 02:05:17.689685557 +0200
@@ -530,6 +530,22 @@ static inline int pmd_trans_unstable(pmd
 #endif
 }
 
+#ifndef __HAVE_ARCH_PAX_OPEN_KERNEL
+#ifdef CONFIG_PAX_KERNEXEC
+#error KERNEXEC requires pax_open_kernel
+#else
+static inline unsigned long pax_open_kernel(void) { return 0; }
+#endif
+#endif
+
+#ifndef __HAVE_ARCH_PAX_CLOSE_KERNEL
+#ifdef CONFIG_PAX_KERNEXEC
+#error KERNEXEC requires pax_close_kernel
+#else
+static inline unsigned long pax_close_kernel(void) { return 0; }
+#endif
+#endif
+
 #endif /* CONFIG_MMU */
 
 #endif /* !__ASSEMBLY__ */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/pgtable-nopmd.h linux-3.2.71-pax/include/asm-generic/pgtable-nopmd.h
--- linux-3.2.71/include/asm-generic/pgtable-nopmd.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/pgtable-nopmd.h	2012-07-04 19:24:48.744063008 +0200
@@ -1,14 +1,19 @@
 #ifndef _PGTABLE_NOPMD_H
 #define _PGTABLE_NOPMD_H
 
-#ifndef __ASSEMBLY__
-
 #include <asm-generic/pgtable-nopud.h>
 
-struct mm_struct;
-
 #define __PAGETABLE_PMD_FOLDED
 
+#define PMD_SHIFT	PUD_SHIFT
+#define PTRS_PER_PMD	1
+#define PMD_SIZE  	(_AC(1,UL) << PMD_SHIFT)
+#define PMD_MASK  	(~(PMD_SIZE-1))
+
+#ifndef __ASSEMBLY__
+
+struct mm_struct;
+
 /*
  * Having the pmd type consist of a pud gets the size right, and allows
  * us to conceptually access the pud entry that this pmd is folded into
@@ -16,11 +21,6 @@ struct mm_struct;
  */
 typedef struct { pud_t pud; } pmd_t;
 
-#define PMD_SHIFT	PUD_SHIFT
-#define PTRS_PER_PMD	1
-#define PMD_SIZE  	(1UL << PMD_SHIFT)
-#define PMD_MASK  	(~(PMD_SIZE-1))
-
 /*
  * The "pud_xxx()" functions here are trivial for a folded two-level
  * setup: the pmd is never bad, and a pmd always exists (as it's folded
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/pgtable-nopud.h linux-3.2.71-pax/include/asm-generic/pgtable-nopud.h
--- linux-3.2.71/include/asm-generic/pgtable-nopud.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/pgtable-nopud.h	2012-07-04 19:24:48.744063008 +0200
@@ -1,10 +1,15 @@
 #ifndef _PGTABLE_NOPUD_H
 #define _PGTABLE_NOPUD_H
 
-#ifndef __ASSEMBLY__
-
 #define __PAGETABLE_PUD_FOLDED
 
+#define PUD_SHIFT	PGDIR_SHIFT
+#define PTRS_PER_PUD	1
+#define PUD_SIZE  	(_AC(1,UL) << PUD_SHIFT)
+#define PUD_MASK  	(~(PUD_SIZE-1))
+
+#ifndef __ASSEMBLY__
+
 /*
  * Having the pud type consist of a pgd gets the size right, and allows
  * us to conceptually access the pgd entry that this pud is folded into
@@ -12,11 +17,6 @@
  */
 typedef struct { pgd_t pgd; } pud_t;
 
-#define PUD_SHIFT	PGDIR_SHIFT
-#define PTRS_PER_PUD	1
-#define PUD_SIZE  	(1UL << PUD_SHIFT)
-#define PUD_MASK  	(~(PUD_SIZE-1))
-
 /*
  * The "pgd_xxx()" functions here are trivial for a folded two-level
  * setup: the pud is never bad, and a pud always exists (as it's folded
@@ -29,6 +29,7 @@ static inline void pgd_clear(pgd_t *pgd)
 #define pud_ERROR(pud)				(pgd_ERROR((pud).pgd))
 
 #define pgd_populate(mm, pgd, pud)		do { } while (0)
+#define pgd_populate_kernel(mm, pgd, pud)	do { } while (0)
 /*
  * (puds are folded into pgds so this doesn't get actually called,
  * but the define is needed for a generic inline function.)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/asm-generic/vmlinux.lds.h linux-3.2.71-pax/include/asm-generic/vmlinux.lds.h
--- linux-3.2.71/include/asm-generic/vmlinux.lds.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/asm-generic/vmlinux.lds.h	2012-07-04 19:24:48.744063008 +0200
@@ -217,6 +217,7 @@
 	.rodata           : AT(ADDR(.rodata) - LOAD_OFFSET) {		\
 		VMLINUX_SYMBOL(__start_rodata) = .;			\
 		*(.rodata) *(.rodata.*)					\
+		*(.data..read_only)					\
 		*(__vermagic)		/* Kernel version magic */	\
 		. = ALIGN(8);						\
 		VMLINUX_SYMBOL(__start___tracepoints_ptrs) = .;		\
@@ -722,17 +723,18 @@
  * section in the linker script will go there too.  @phdr should have
  * a leading colon.
  *
- * Note that this macros defines __per_cpu_load as an absolute symbol.
+ * Note that this macros defines per_cpu_load as an absolute symbol.
  * If there is no need to put the percpu section at a predetermined
  * address, use PERCPU_SECTION.
  */
 #define PERCPU_VADDR(cacheline, vaddr, phdr)				\
-	VMLINUX_SYMBOL(__per_cpu_load) = .;				\
-	.data..percpu vaddr : AT(VMLINUX_SYMBOL(__per_cpu_load)		\
+	per_cpu_load = .;						\
+	.data..percpu vaddr : AT(VMLINUX_SYMBOL(per_cpu_load)		\
 				- LOAD_OFFSET) {			\
+		VMLINUX_SYMBOL(__per_cpu_load) = . + per_cpu_load;	\
 		PERCPU_INPUT(cacheline)					\
 	} phdr								\
-	. = VMLINUX_SYMBOL(__per_cpu_load) + SIZEOF(.data..percpu);
+	. = VMLINUX_SYMBOL(per_cpu_load) + SIZEOF(.data..percpu);
 
 /**
  * PERCPU_SECTION - define output section for percpu area, simple version
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/crypto/algapi.h linux-3.2.71-pax/include/crypto/algapi.h
--- linux-3.2.71/include/crypto/algapi.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/crypto/algapi.h	2013-01-16 21:27:15.878836689 +0100
@@ -34,7 +34,7 @@ struct crypto_type {
 	unsigned int maskclear;
 	unsigned int maskset;
 	unsigned int tfmsize;
-};
+} __do_const;
 
 struct crypto_instance {
 	struct crypto_alg alg;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/drm/drm_crtc_helper.h linux-3.2.71-pax/include/drm/drm_crtc_helper.h
--- linux-3.2.71/include/drm/drm_crtc_helper.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/drm/drm_crtc_helper.h	2013-01-17 00:16:38.450601845 +0100
@@ -95,7 +95,7 @@ struct drm_encoder_helper_funcs {
 					    struct drm_connector *connector);
 	/* disable encoder when not in use - more explicit than dpms off */
 	void (*disable)(struct drm_encoder *encoder);
-};
+} __no_const;
 
 struct drm_connector_helper_funcs {
 	int (*get_modes)(struct drm_connector *connector);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/drm/drmP.h linux-3.2.71-pax/include/drm/drmP.h
--- linux-3.2.71/include/drm/drmP.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/drm/drmP.h	2013-03-28 01:35:23.144427956 +0100
@@ -72,6 +72,7 @@
 #include <linux/workqueue.h>
 #include <linux/poll.h>
 #include <asm/pgalloc.h>
+#include <asm/local.h>
 #include "drm.h"
 
 #include <linux/idr.h>
@@ -284,10 +285,12 @@ do {										\
  * \param cmd command.
  * \param arg argument.
  */
-typedef int drm_ioctl_t(struct drm_device *dev, void *data,
+typedef int (* const drm_ioctl_t)(struct drm_device *dev, void *data,
+			struct drm_file *file_priv);
+typedef int (* drm_ioctl_no_const_t)(struct drm_device *dev, void *data,
 			struct drm_file *file_priv);
 
-typedef int drm_ioctl_compat_t(struct file *filp, unsigned int cmd,
+typedef int (* const drm_ioctl_compat_t)(struct file *filp, unsigned int cmd,
 			       unsigned long arg);
 
 #define DRM_IOCTL_NR(n)                _IOC_NR(n)
@@ -302,9 +305,9 @@ typedef int drm_ioctl_compat_t(struct fi
 struct drm_ioctl_desc {
 	unsigned int cmd;
 	int flags;
-	drm_ioctl_t *func;
+	drm_ioctl_t func;
 	unsigned int cmd_drv;
-};
+} __do_const;
 
 /**
  * Creates a driver or general drm_ioctl_desc array entry for the given
@@ -965,7 +968,7 @@ struct drm_info_list {
 	int (*show)(struct seq_file*, void*); /** show callback */
 	u32 driver_features; /**< Required driver features for this entry */
 	void *data;
-};
+} __do_const;
 
 /**
  * debugfs node structure. This structure represents a debugfs file.
@@ -1038,7 +1041,7 @@ struct drm_device {
 
 	/** \name Usage Counters */
 	/*@{ */
-	int open_count;			/**< Outstanding files open */
+	local_t open_count;		/**< Outstanding files open */
 	atomic_t ioctl_count;		/**< Outstanding IOCTLs pending */
 	atomic_t vma_count;		/**< Outstanding vma areas open */
 	int buf_use;			/**< Buffers in use -- cannot alloc */
@@ -1049,7 +1052,7 @@ struct drm_device {
 	/*@{ */
 	unsigned long counters;
 	enum drm_stat_type types[15];
-	atomic_t counts[15];
+	atomic_unchecked_t counts[15];
 	/*@} */
 
 	struct list_head filelist;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/drm/ttm/ttm_memory.h linux-3.2.71-pax/include/drm/ttm/ttm_memory.h
--- linux-3.2.71/include/drm/ttm/ttm_memory.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/drm/ttm/ttm_memory.h	2012-07-04 19:24:48.744063008 +0200
@@ -47,7 +47,7 @@
 
 struct ttm_mem_shrink {
 	int (*do_shrink) (struct ttm_mem_shrink *);
-};
+} __no_const;
 
 /**
  * struct ttm_mem_global - Global memory accounting structure.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/drm/ttm/ttm_page_alloc.h linux-3.2.71-pax/include/drm/ttm/ttm_page_alloc.h
--- linux-3.2.71/include/drm/ttm/ttm_page_alloc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/drm/ttm/ttm_page_alloc.h	2015-01-05 19:07:59.561797364 +0100
@@ -54,7 +54,7 @@ int ttm_get_pages(struct list_head *page
  * @dma_address: The DMA (bus) address of pages (if TTM_PAGE_FLAG_DMA32 set).
  */
 void ttm_put_pages(struct list_head *pages,
-		   unsigned page_count,
+		   unsigned long page_count,
 		   int flags,
 		   enum ttm_caching_state cstate,
 		   dma_addr_t *dma_address);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/a.out.h linux-3.2.71-pax/include/linux/a.out.h
--- linux-3.2.71/include/linux/a.out.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/a.out.h	2012-07-04 19:24:48.748063008 +0200
@@ -39,6 +39,14 @@ enum machine_type {
   M_MIPS2 = 152		/* MIPS R6000/R4000 binary */
 };
 
+/* Constants for the N_FLAGS field */
+#define F_PAX_PAGEEXEC	1	/* Paging based non-executable pages */
+#define F_PAX_EMUTRAMP	2	/* Emulate trampolines */
+#define F_PAX_MPROTECT	4	/* Restrict mprotect() */
+#define F_PAX_RANDMMAP	8	/* Randomize mmap() base */
+/*#define F_PAX_RANDEXEC	16*/	/* Randomize ET_EXEC base */
+#define F_PAX_SEGMEXEC	32	/* Segmentation based non-executable pages */
+
 #if !defined (N_MAGIC)
 #define N_MAGIC(exec) ((exec).a_info & 0xffff)
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/atmdev.h linux-3.2.71-pax/include/linux/atmdev.h
--- linux-3.2.71/include/linux/atmdev.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/atmdev.h	2013-03-28 01:35:23.148427956 +0100
@@ -237,7 +237,7 @@ struct compat_atm_iobuf {
 #endif
 
 struct k_atm_aal_stats {
-#define __HANDLE_ITEM(i) atomic_t i
+#define __HANDLE_ITEM(i) atomic_unchecked_t i
 	__AAL_STAT_ITEMS
 #undef __HANDLE_ITEM
 };
@@ -406,7 +406,7 @@ struct atmdev_ops { /* only send is requ
 	int (*change_qos)(struct atm_vcc *vcc,struct atm_qos *qos,int flags);
 	int (*proc_read)(struct atm_dev *dev,loff_t *pos,char *page);
 	struct module *owner;
-};
+} __do_const ;
 
 struct atmphy_ops {
 	int (*start)(struct atm_dev *dev);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/binfmts.h linux-3.2.71-pax/include/linux/binfmts.h
--- linux-3.2.71/include/linux/binfmts.h	2014-01-03 15:48:45.052070561 +0100
+++ linux-3.2.71-pax/include/linux/binfmts.h	2014-01-03 15:48:49.592070319 +0100
@@ -86,8 +86,9 @@ struct linux_binfmt {
 	int (*load_binary)(struct linux_binprm *, struct  pt_regs * regs);
 	int (*load_shlib)(struct file *);
 	int (*core_dump)(struct coredump_params *cprm);
+	void (*handle_mprotect)(struct vm_area_struct *vma, unsigned long newflags);
 	unsigned long min_coredump;	/* minimal dump size */
-};
+} __do_const;
 
 extern int __register_binfmt(struct linux_binfmt *fmt, int insert);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/bitops.h linux-3.2.71-pax/include/linux/bitops.h
--- linux-3.2.71/include/linux/bitops.h	2014-04-09 12:13:43.908713384 +0200
+++ linux-3.2.71-pax/include/linux/bitops.h	2014-04-09 12:13:49.048713110 +0200
@@ -74,7 +74,7 @@ static inline __u64 ror64(__u64 word, un
  * @word: value to rotate
  * @shift: bits to roll
  */
-static inline __u32 rol32(__u32 word, unsigned int shift)
+static inline __u32 __intentional_overflow(-1) rol32(__u32 word, unsigned int shift)
 {
 	return (word << shift) | (word >> (32 - shift));
 }
@@ -84,7 +84,7 @@ static inline __u32 rol32(__u32 word, un
  * @word: value to rotate
  * @shift: bits to roll
  */
-static inline __u32 ror32(__u32 word, unsigned int shift)
+static inline __u32 __intentional_overflow(-1) ror32(__u32 word, unsigned int shift)
 {
 	return (word >> shift) | (word << (32 - shift));
 }
@@ -140,7 +140,7 @@ static inline __s32 sign_extend32(__u32
 	return (__s32)(value << shift) >> shift;
 }
 
-static inline unsigned fls_long(unsigned long l)
+static inline unsigned __intentional_overflow(-1) fls_long(unsigned long l)
 {
 	if (sizeof(l) == 4)
 		return fls(l);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/blkdev.h linux-3.2.71-pax/include/linux/blkdev.h
--- linux-3.2.71/include/linux/blkdev.h	2014-12-14 21:13:45.302055266 +0100
+++ linux-3.2.71-pax/include/linux/blkdev.h	2014-12-14 21:13:52.834069337 +0100
@@ -1315,7 +1315,7 @@ struct block_device_operations {
 	/* this callback is with swap_lock and sometimes page table lock held */
 	void (*swap_slot_free_notify) (struct block_device *, unsigned long);
 	struct module *owner;
-};
+} __do_const;
 
 extern int __blkdev_driver_ioctl(struct block_device *, fmode_t, unsigned int,
 				 unsigned long);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/blktrace_api.h linux-3.2.71-pax/include/linux/blktrace_api.h
--- linux-3.2.71/include/linux/blktrace_api.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/blktrace_api.h	2012-07-04 19:24:48.748063008 +0200
@@ -162,7 +162,7 @@ struct blk_trace {
 	struct dentry *dir;
 	struct dentry *dropped_file;
 	struct dentry *msg_file;
-	atomic_t dropped;
+	atomic_unchecked_t dropped;
 };
 
 extern int blk_trace_ioctl(struct block_device *, unsigned, char __user *);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/byteorder/little_endian.h linux-3.2.71-pax/include/linux/byteorder/little_endian.h
--- linux-3.2.71/include/linux/byteorder/little_endian.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/byteorder/little_endian.h	2013-03-27 22:10:09.077085432 +0100
@@ -42,51 +42,51 @@
 
 static inline __le64 __cpu_to_le64p(const __u64 *p)
 {
-	return (__force __le64)*p;
+	return (__force const __le64)*p;
 }
-static inline __u64 __le64_to_cpup(const __le64 *p)
+static inline __u64 __intentional_overflow(-1) __le64_to_cpup(const __le64 *p)
 {
-	return (__force __u64)*p;
+	return (__force const __u64)*p;
 }
 static inline __le32 __cpu_to_le32p(const __u32 *p)
 {
-	return (__force __le32)*p;
+	return (__force const __le32)*p;
 }
 static inline __u32 __le32_to_cpup(const __le32 *p)
 {
-	return (__force __u32)*p;
+	return (__force const __u32)*p;
 }
 static inline __le16 __cpu_to_le16p(const __u16 *p)
 {
-	return (__force __le16)*p;
+	return (__force const __le16)*p;
 }
 static inline __u16 __le16_to_cpup(const __le16 *p)
 {
-	return (__force __u16)*p;
+	return (__force const __u16)*p;
 }
 static inline __be64 __cpu_to_be64p(const __u64 *p)
 {
-	return (__force __be64)__swab64p(p);
+	return (__force const __be64)__swab64p(p);
 }
 static inline __u64 __be64_to_cpup(const __be64 *p)
 {
-	return __swab64p((__u64 *)p);
+	return __swab64p((const __u64 *)p);
 }
 static inline __be32 __cpu_to_be32p(const __u32 *p)
 {
-	return (__force __be32)__swab32p(p);
+	return (__force const __be32)__swab32p(p);
 }
-static inline __u32 __be32_to_cpup(const __be32 *p)
+static inline __u32 __intentional_overflow(-1) __be32_to_cpup(const __be32 *p)
 {
-	return __swab32p((__u32 *)p);
+	return __swab32p((const __u32 *)p);
 }
 static inline __be16 __cpu_to_be16p(const __u16 *p)
 {
-	return (__force __be16)__swab16p(p);
+	return (__force const __be16)__swab16p(p);
 }
 static inline __u16 __be16_to_cpup(const __be16 *p)
 {
-	return __swab16p((__u16 *)p);
+	return __swab16p((const __u16 *)p);
 }
 #define __cpu_to_le64s(x) do { (void)(x); } while (0)
 #define __le64_to_cpus(x) do { (void)(x); } while (0)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/cache.h linux-3.2.71-pax/include/linux/cache.h
--- linux-3.2.71/include/linux/cache.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/cache.h	2013-09-19 00:30:35.721650477 +0200
@@ -16,6 +16,14 @@
 #define __read_mostly
 #endif
 
+#ifndef __read_only
+#ifdef CONFIG_PAX_KERNEXEC
+#error KERNEXEC requires __read_only
+#else
+#define __read_only __read_mostly
+#endif
+#endif
+
 #ifndef ____cacheline_aligned
 #define ____cacheline_aligned __attribute__((__aligned__(SMP_CACHE_BYTES)))
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/cdrom.h linux-3.2.71-pax/include/linux/cdrom.h
--- linux-3.2.71/include/linux/cdrom.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/cdrom.h	2013-01-16 21:27:15.878836689 +0100
@@ -985,7 +985,6 @@ struct cdrom_device_ops {
 
 /* driver specifications */
 	const int capability;   /* capability flags */
-	int n_minors;           /* number of active minor devices */
 	/* handle uniform packets for scsi type devices (scsi,atapi) */
 	int (*generic_packet) (struct cdrom_device_info *,
 			       struct packet_command *);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/cleancache.h linux-3.2.71-pax/include/linux/cleancache.h
--- linux-3.2.71/include/linux/cleancache.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/cleancache.h	2012-07-04 19:24:48.752063008 +0200
@@ -31,7 +31,7 @@ struct cleancache_ops {
 	void (*flush_page)(int, struct cleancache_filekey, pgoff_t);
 	void (*flush_inode)(int, struct cleancache_filekey);
 	void (*flush_fs)(int);
-};
+} __no_const;
 
 extern struct cleancache_ops
 	cleancache_register_ops(struct cleancache_ops *ops);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/compat.h linux-3.2.71-pax/include/linux/compat.h
--- linux-3.2.71/include/linux/compat.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/compat.h	2015-05-05 17:40:21.521927508 +0200
@@ -240,10 +240,10 @@ long compat_sys_msgrcv(int first, int se
 		int version, void __user *uptr);
 long compat_sys_msgctl(int first, int second, void __user *uptr);
 long compat_sys_shmat(int first, int second, compat_uptr_t third, int version,
-		void __user *uptr);
+		void __user *uptr) __intentional_overflow(0);
 long compat_sys_shmctl(int first, int second, void __user *uptr);
 long compat_sys_semtimedop(int semid, struct sembuf __user *tsems,
-		unsigned nsems, const struct compat_timespec __user *timeout);
+		compat_long_t nsems, const struct compat_timespec __user *timeout);
 asmlinkage long compat_sys_keyctl(u32 option,
 			      u32 arg2, u32 arg3, u32 arg4, u32 arg5);
 asmlinkage long compat_sys_ustat(unsigned dev, struct compat_ustat __user *u32);
@@ -334,7 +334,7 @@ extern int compat_ptrace_request(struct
 extern long compat_arch_ptrace(struct task_struct *child, compat_long_t request,
 			       compat_ulong_t addr, compat_ulong_t data);
 asmlinkage long compat_sys_ptrace(compat_long_t request, compat_long_t pid,
-				  compat_long_t addr, compat_long_t data);
+				  compat_ulong_t addr, compat_ulong_t data);
 
 /*
  * epoll (fs/eventpoll.c) compat bits follow ...
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/compiler-gcc4.h linux-3.2.71-pax/include/linux/compiler-gcc4.h
--- linux-3.2.71/include/linux/compiler-gcc4.h	2015-05-10 09:22:38.947493132 +0200
+++ linux-3.2.71-pax/include/linux/compiler-gcc4.h	2015-05-10 09:23:09.483494791 +0200
@@ -44,6 +44,21 @@
 #define asm_volatile_goto(x...)	do { asm goto(x); asm (""); } while (0)
 
 #if __GNUC_MINOR__ >= 5
+
+#ifdef CONSTIFY_PLUGIN
+#define __no_const __attribute__((no_const))
+#define __do_const __attribute__((do_const))
+#endif
+
+#ifdef SIZE_OVERFLOW_PLUGIN
+#define __size_overflow(...) __attribute__((size_overflow(__VA_ARGS__)))
+#define __intentional_overflow(...) __attribute__((intentional_overflow(__VA_ARGS__)))
+#endif
+
+#ifdef LATENT_ENTROPY_PLUGIN
+#define __latent_entropy __attribute__((latent_entropy))
+#endif
+
 /*
  * Mark a position in code as unreachable.  This can be used to
  * suppress control flow warnings after asm blocks that transfer
@@ -59,6 +74,11 @@
 #define __noclone	__attribute__((__noclone__))
 
 #endif
+
+#define __alloc_size(...)	__attribute((alloc_size(__VA_ARGS__)))
+#define __bos(ptr, arg)		__builtin_object_size((ptr), (arg))
+#define __bos0(ptr)		__bos((ptr), 0)
+#define __bos1(ptr)		__bos((ptr), 1)
 #endif
 
 #if __GNUC_MINOR__ > 0
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/compiler-gcc5.h linux-3.2.71-pax/include/linux/compiler-gcc5.h
--- linux-3.2.71/include/linux/compiler-gcc5.h	2014-12-14 21:13:45.302055266 +0100
+++ linux-3.2.71-pax/include/linux/compiler-gcc5.h	2015-04-30 03:07:38.396532395 +0200
@@ -28,6 +28,26 @@
 # define __compiletime_error(message) __attribute__((error(message)))
 #endif /* __CHECKER__ */
 
+#define __alloc_size(...)	__attribute((alloc_size(__VA_ARGS__)))
+#define __bos(ptr, arg)		__builtin_object_size((ptr), (arg))
+#define __bos0(ptr)		__bos((ptr), 0)
+#define __bos1(ptr)		__bos((ptr), 1)
+
+#ifdef CONSTIFY_PLUGIN
+#define __no_const __attribute__((no_const))
+#define __do_const __attribute__((do_const))
+#endif
+
+#ifdef SIZE_OVERFLOW_PLUGIN
+#error not yet
+#define __size_overflow(...) __attribute__((size_overflow(__VA_ARGS__)))
+#define __intentional_overflow(...) __attribute__((intentional_overflow(__VA_ARGS__)))
+#endif
+
+#ifdef LATENT_ENTROPY_PLUGIN
+#define __latent_entropy __attribute__((latent_entropy))
+#endif
+
 /*
  * Mark a position in code as unreachable.  This can be used to
  * suppress control flow warnings after asm blocks that transfer
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/compiler.h linux-3.2.71-pax/include/linux/compiler.h
--- linux-3.2.71/include/linux/compiler.h	2015-05-10 09:22:38.947493132 +0200
+++ linux-3.2.71-pax/include/linux/compiler.h	2015-05-10 09:25:45.299503254 +0200
@@ -5,31 +5,51 @@
 
 #ifdef __CHECKER__
 # define __user		__attribute__((noderef, address_space(1)))
+# define __force_user	__force __user
 # define __kernel	__attribute__((address_space(0)))
+# define __force_kernel	__force __kernel
 # define __safe		__attribute__((safe))
 # define __force	__attribute__((force))
 # define __nocast	__attribute__((nocast))
 # define __iomem	__attribute__((noderef, address_space(2)))
+# define __force_iomem	__force __iomem
 # define __acquires(x)	__attribute__((context(x,0,1)))
 # define __releases(x)	__attribute__((context(x,1,0)))
 # define __acquire(x)	__context__(x,1)
 # define __release(x)	__context__(x,-1)
 # define __cond_lock(x,c)	((c) ? ({ __acquire(x); 1; }) : 0)
 # define __percpu	__attribute__((noderef, address_space(3)))
+# define __force_percpu	__force __percpu
 #ifdef CONFIG_SPARSE_RCU_POINTER
 # define __rcu		__attribute__((noderef, address_space(4)))
+# define __force_rcu	__force __rcu
 #else
 # define __rcu
+# define __force_rcu
 #endif
 extern void __chk_user_ptr(const volatile void __user *);
 extern void __chk_io_ptr(const volatile void __iomem *);
 #else
-# define __user
-# define __kernel
+# ifdef CHECKER_PLUGIN
+//#  define __user
+//#  define __force_user
+//#  define __kernel
+//#  define __force_kernel
+# else
+#  ifdef STRUCTLEAK_PLUGIN
+#   define __user __attribute__((user))
+#  else
+#   define __user
+#  endif
+#  define __force_user
+#  define __kernel
+#  define __force_kernel
+# endif
 # define __safe
 # define __force
 # define __nocast
 # define __iomem
+# define __force_iomem
 # define __chk_user_ptr(x) (void)0
 # define __chk_io_ptr(x) (void)0
 # define __builtin_warning(x, y...) (1)
@@ -39,7 +59,9 @@ extern void __chk_io_ptr(const volatile
 # define __release(x) (void)0
 # define __cond_lock(x,c) (c)
 # define __percpu
+# define __force_percpu
 # define __rcu
+# define __force_rcu
 #endif
 
 #ifdef __KERNEL__
@@ -268,6 +290,22 @@ void ftrace_likely_update(struct ftrace_
 # define __attribute_const__	/* unimplemented */
 #endif
 
+#ifndef __no_const
+# define __no_const
+#endif
+
+#ifndef __do_const
+# define __do_const
+#endif
+
+#ifndef __size_overflow
+# define __size_overflow(...)
+#endif
+
+#ifndef __latent_entropy
+# define __latent_entropy
+#endif
+
 /*
  * Tell gcc if a function is cold. The compiler will assume any path
  * directly leading to the call is unlikely.
@@ -277,6 +315,22 @@ void ftrace_likely_update(struct ftrace_
 #define __cold
 #endif
 
+#ifndef __alloc_size
+#define __alloc_size(...)
+#endif
+
+#ifndef __bos
+#define __bos(ptr, arg)
+#endif
+
+#ifndef __bos0
+#define __bos0(ptr)
+#endif
+
+#ifndef __bos1
+#define __bos1(ptr)
+#endif
+
 /* Simple shorthand for a section definition */
 #ifndef __section
 # define __section(S) __attribute__ ((__section__(#S)))
@@ -287,6 +341,8 @@ void ftrace_likely_update(struct ftrace_
 # define __same_type(a, b) __builtin_types_compatible_p(typeof(a), typeof(b))
 #endif
 
+#define __type_is_unsigned(t) (__same_type((t)0, 0UL) || __same_type((t)0, 0U) || __same_type((t)0, (unsigned short)0) || __same_type((t)0, (unsigned char)0))
+
 /* Compile time object size, -1 for unknown */
 #ifndef __compiletime_object_size
 # define __compiletime_object_size(obj) -1
@@ -297,9 +353,19 @@ void ftrace_likely_update(struct ftrace_
 #ifndef __compiletime_error
 # define __compiletime_error(message)
 #endif
+
 #ifndef __linktime_error
 # define __linktime_error(message)
 #endif
+
+#ifndef __size_overflow
+# define __size_overflow(...)
+#endif
+
+#ifndef __intentional_overflow
+# define __intentional_overflow(...)
+#endif
+
 /*
  * Prevent the compiler from merging or refetching accesses.  The compiler
  * is also forbidden from reordering successive instances of ACCESS_ONCE(),
@@ -312,6 +378,7 @@ void ftrace_likely_update(struct ftrace_
  * use is to mediate communication between process-level code and irq/NMI
  * handlers, all running on the same CPU.
  */
-#define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
+#define ACCESS_ONCE(x) (*(volatile const typeof(x) *)&(x))
+#define ACCESS_ONCE_RW(x) (*(volatile typeof(x) *)&(x))
 
 #endif /* __LINUX_COMPILER_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/completion.h linux-3.2.71-pax/include/linux/completion.h
--- linux-3.2.71/include/linux/completion.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/completion.h	2013-11-23 18:07:03.749937076 +0100
@@ -77,14 +77,14 @@ static inline void init_completion(struc
 }
 
 extern void wait_for_completion(struct completion *);
-extern int wait_for_completion_interruptible(struct completion *x);
-extern int wait_for_completion_killable(struct completion *x);
+extern int wait_for_completion_interruptible(struct completion *x) __intentional_overflow(-1);
+extern int wait_for_completion_killable(struct completion *x) __intentional_overflow(-1);
 extern unsigned long wait_for_completion_timeout(struct completion *x,
-						   unsigned long timeout);
+						   unsigned long timeout) __intentional_overflow(-1);
 extern long wait_for_completion_interruptible_timeout(
-	struct completion *x, unsigned long timeout);
+	struct completion *x, unsigned long timeout) __intentional_overflow(-1);
 extern long wait_for_completion_killable_timeout(
-	struct completion *x, unsigned long timeout);
+	struct completion *x, unsigned long timeout) __intentional_overflow(-1);
 extern bool try_wait_for_completion(struct completion *x);
 extern bool completion_done(struct completion *x);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/configfs.h linux-3.2.71-pax/include/linux/configfs.h
--- linux-3.2.71/include/linux/configfs.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/configfs.h	2013-03-28 01:40:59.408410003 +0100
@@ -125,7 +125,7 @@ struct configfs_attribute {
 	const char		*ca_name;
 	struct module 		*ca_owner;
 	mode_t			ca_mode;
-};
+} __do_const;
 
 /*
  * Users often need to create attribute structures for their configurable
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/cpufreq.h linux-3.2.71-pax/include/linux/cpufreq.h
--- linux-3.2.71/include/linux/cpufreq.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/cpufreq.h	2013-03-28 01:35:23.336427946 +0100
@@ -236,7 +236,7 @@ struct cpufreq_driver {
 	int	(*suspend)	(struct cpufreq_policy *policy);
 	int	(*resume)	(struct cpufreq_policy *policy);
 	struct freq_attr	**attr;
-};
+} __do_const;
 
 /* flags */
 
@@ -295,6 +295,7 @@ struct global_attr {
 	ssize_t (*store)(struct kobject *a, struct attribute *b,
 			 const char *c, size_t count);
 };
+typedef struct global_attr __no_const global_attr_no_const;
 
 #define define_one_global_ro(_name)		\
 static struct global_attr _name =		\
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/cpu.h linux-3.2.71-pax/include/linux/cpu.h
--- linux-3.2.71/include/linux/cpu.h	2013-06-21 21:22:07.698352277 +0200
+++ linux-3.2.71-pax/include/linux/cpu.h	2013-06-21 21:21:57.514352821 +0200
@@ -108,7 +108,7 @@ enum {
 /* Need to know about CPUs going up/down? */
 #if defined(CONFIG_HOTPLUG_CPU) || !defined(MODULE)
 #define cpu_notifier(fn, pri) {					\
-	static struct notifier_block fn##_nb __cpuinitdata =	\
+	static struct notifier_block fn##_nb =			\
 		{ .notifier_call = fn, .priority = pri };	\
 	register_cpu_notifier(&fn##_nb);			\
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/cpuidle.h linux-3.2.71-pax/include/linux/cpuidle.h
--- linux-3.2.71/include/linux/cpuidle.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/cpuidle.h	2013-03-28 01:40:35.088411301 +0100
@@ -49,7 +49,8 @@ struct cpuidle_state {
 	int (*enter)	(struct cpuidle_device *dev,
 			struct cpuidle_driver *drv,
 			int index);
-};
+} __do_const;
+typedef struct cpuidle_state __no_const cpuidle_state_no_const;
 
 /* Idle State Flags */
 #define CPUIDLE_FLAG_TIME_VALID	(0x01) /* is residency time measurable? */
@@ -181,7 +182,7 @@ struct cpuidle_governor {
 	void (*reflect)		(struct cpuidle_device *dev, int index);
 
 	struct module 		*owner;
-};
+} __do_const;
 
 #ifdef CONFIG_CPU_IDLE
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/cpumask.h linux-3.2.71-pax/include/linux/cpumask.h
--- linux-3.2.71/include/linux/cpumask.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/cpumask.h	2013-03-28 04:10:58.187929537 +0100
@@ -117,17 +117,17 @@ static inline unsigned int cpumask_first
 }
 
 /* Valid inputs for n are -1 and 0. */
-static inline unsigned int cpumask_next(int n, const struct cpumask *srcp)
+static inline unsigned int __intentional_overflow(-1) cpumask_next(int n, const struct cpumask *srcp)
 {
 	return n+1;
 }
 
-static inline unsigned int cpumask_next_zero(int n, const struct cpumask *srcp)
+static inline unsigned int __intentional_overflow(-1) cpumask_next_zero(int n, const struct cpumask *srcp)
 {
 	return n+1;
 }
 
-static inline unsigned int cpumask_next_and(int n,
+static inline unsigned int __intentional_overflow(-1) cpumask_next_and(int n,
 					    const struct cpumask *srcp,
 					    const struct cpumask *andp)
 {
@@ -166,7 +166,7 @@ static inline unsigned int cpumask_first
  *
  * Returns >= nr_cpu_ids if no further cpus set.
  */
-static inline unsigned int cpumask_next(int n, const struct cpumask *srcp)
+static inline unsigned int __intentional_overflow(-1) cpumask_next(int n, const struct cpumask *srcp)
 {
 	/* -1 is a legal arg here. */
 	if (n != -1)
@@ -181,7 +181,7 @@ static inline unsigned int cpumask_next(
  *
  * Returns >= nr_cpu_ids if no further cpus unset.
  */
-static inline unsigned int cpumask_next_zero(int n, const struct cpumask *srcp)
+static inline unsigned int __intentional_overflow(-1) cpumask_next_zero(int n, const struct cpumask *srcp)
 {
 	/* -1 is a legal arg here. */
 	if (n != -1)
@@ -189,7 +189,7 @@ static inline unsigned int cpumask_next_
 	return find_next_zero_bit(cpumask_bits(srcp), nr_cpumask_bits, n+1);
 }
 
-int cpumask_next_and(int n, const struct cpumask *, const struct cpumask *);
+int cpumask_next_and(int n, const struct cpumask *, const struct cpumask *) __intentional_overflow(-1);
 int cpumask_any_but(const struct cpumask *mask, unsigned int cpu);
 
 /**
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/crypto.h linux-3.2.71-pax/include/linux/crypto.h
--- linux-3.2.71/include/linux/crypto.h	2015-02-20 12:37:33.229178768 +0100
+++ linux-3.2.71-pax/include/linux/crypto.h	2015-02-20 12:37:41.905178305 +0100
@@ -378,7 +378,7 @@ struct cipher_tfm {
 	                  const u8 *key, unsigned int keylen);
 	void (*cit_encrypt_one)(struct crypto_tfm *tfm, u8 *dst, const u8 *src);
 	void (*cit_decrypt_one)(struct crypto_tfm *tfm, u8 *dst, const u8 *src);
-};
+} __no_const;
 
 struct hash_tfm {
 	int (*init)(struct hash_desc *desc);
@@ -399,13 +399,13 @@ struct compress_tfm {
 	int (*cot_decompress)(struct crypto_tfm *tfm,
 	                      const u8 *src, unsigned int slen,
 	                      u8 *dst, unsigned int *dlen);
-};
+} __no_const;
 
 struct rng_tfm {
 	int (*rng_gen_random)(struct crypto_rng *tfm, u8 *rdata,
 			      unsigned int dlen);
 	int (*rng_reset)(struct crypto_rng *tfm, u8 *seed, unsigned int slen);
-};
+} __no_const;
 
 #define crt_ablkcipher	crt_u.ablkcipher
 #define crt_aead	crt_u.aead
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/ctype.h linux-3.2.71-pax/include/linux/ctype.h
--- linux-3.2.71/include/linux/ctype.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/ctype.h	2013-03-28 04:10:58.187929537 +0100
@@ -56,7 +56,7 @@ static inline unsigned char __toupper(un
  * Fast implementation of tolower() for internal usage. Do not use in your
  * code.
  */
-static inline char _tolower(const char c)
+static inline unsigned char _tolower(const unsigned char c)
 {
 	return c | 0x20;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/decompress/mm.h linux-3.2.71-pax/include/linux/decompress/mm.h
--- linux-3.2.71/include/linux/decompress/mm.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/decompress/mm.h	2012-07-04 19:24:48.752063008 +0200
@@ -77,7 +77,7 @@ static void free(void *where)
  * warnings when not needed (indeed large_malloc / large_free are not
  * needed by inflate */
 
-#define malloc(a) kmalloc(a, GFP_KERNEL)
+#define malloc(a) kmalloc((a), GFP_KERNEL)
 #define free(a) kfree(a)
 
 #define large_malloc(a) vmalloc(a)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/device.h linux-3.2.71-pax/include/linux/device.h
--- linux-3.2.71/include/linux/device.h	2015-02-20 12:37:33.229178768 +0100
+++ linux-3.2.71-pax/include/linux/device.h	2015-02-20 12:37:41.905178305 +0100
@@ -427,7 +427,7 @@ struct device_type {
 	void (*release)(struct device *dev);
 
 	const struct dev_pm_ops *pm;
-};
+} __do_const;
 
 /* interface for exporting device attributes */
 struct device_attribute {
@@ -437,6 +437,7 @@ struct device_attribute {
 	ssize_t (*store)(struct device *dev, struct device_attribute *attr,
 			 const char *buf, size_t count);
 };
+typedef struct device_attribute __no_const device_attribute_no_const;
 
 #define DEVICE_ATTR(_name, _mode, _show, _store) \
 struct device_attribute dev_attr_##_name = __ATTR(_name, _mode, _show, _store)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/dmaengine.h linux-3.2.71-pax/include/linux/dmaengine.h
--- linux-3.2.71/include/linux/dmaengine.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/dmaengine.h	2012-09-11 20:29:10.804017740 +0200
@@ -881,9 +881,9 @@ struct dma_pinned_list {
 struct dma_pinned_list *dma_pin_iovec_pages(struct iovec *iov, size_t len);
 void dma_unpin_iovec_pages(struct dma_pinned_list* pinned_list);
 
-dma_cookie_t dma_memcpy_to_iovec(struct dma_chan *chan, struct iovec *iov,
+dma_cookie_t __intentional_overflow(0) dma_memcpy_to_iovec(struct dma_chan *chan, struct iovec *iov,
 	struct dma_pinned_list *pinned_list, unsigned char *kdata, size_t len);
-dma_cookie_t dma_memcpy_pg_to_iovec(struct dma_chan *chan, struct iovec *iov,
+dma_cookie_t __intentional_overflow(0) dma_memcpy_pg_to_iovec(struct dma_chan *chan, struct iovec *iov,
 	struct dma_pinned_list *pinned_list, struct page *page,
 	unsigned int offset, size_t len);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/dma-mapping.h linux-3.2.71-pax/include/linux/dma-mapping.h
--- linux-3.2.71/include/linux/dma-mapping.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/dma-mapping.h	2012-07-04 19:24:48.756063008 +0200
@@ -46,7 +46,7 @@ struct dma_map_ops {
 	u64 (*get_required_mask)(struct device *dev);
 #endif
 	int is_phys;
-};
+} __do_const;
 
 #define DMA_BIT_MASK(n)	(((n) == 64) ? ~0ULL : ((1ULL<<(n))-1))
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/efi.h linux-3.2.71-pax/include/linux/efi.h
--- linux-3.2.71/include/linux/efi.h	2013-06-09 18:04:43.437591748 +0200
+++ linux-3.2.71-pax/include/linux/efi.h	2013-06-09 18:05:11.437590253 +0200
@@ -486,6 +486,7 @@ struct efivar_operations {
 	efi_set_variable_t *set_variable;
 	efi_query_variable_store_t *query_variable_store;
 };
+typedef struct efivar_operations __no_const efivar_operations_no_const;
 
 struct efivars {
 	/*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/elf.h linux-3.2.71-pax/include/linux/elf.h
--- linux-3.2.71/include/linux/elf.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/elf.h	2012-07-04 19:24:48.756063008 +0200
@@ -49,6 +49,17 @@ typedef __s64	Elf64_Sxword;
 #define PT_GNU_EH_FRAME		0x6474e550
 
 #define PT_GNU_STACK	(PT_LOOS + 0x474e551)
+#define PT_GNU_RELRO	(PT_LOOS + 0x474e552)
+
+#define PT_PAX_FLAGS	(PT_LOOS + 0x5041580)
+
+/* Constants for the e_flags field */
+#define EF_PAX_PAGEEXEC		1	/* Paging based non-executable pages */
+#define EF_PAX_EMUTRAMP		2	/* Emulate trampolines */
+#define EF_PAX_MPROTECT		4	/* Restrict mprotect() */
+#define EF_PAX_RANDMMAP		8	/* Randomize mmap() base */
+/*#define EF_PAX_RANDEXEC		16*/	/* Randomize ET_EXEC base */
+#define EF_PAX_SEGMEXEC		32	/* Segmentation based non-executable pages */
 
 /*
  * Extended Numbering
@@ -106,6 +117,8 @@ typedef __s64	Elf64_Sxword;
 #define DT_DEBUG	21
 #define DT_TEXTREL	22
 #define DT_JMPREL	23
+#define DT_FLAGS	30
+  #define DF_TEXTREL  0x00000004
 #define DT_ENCODING	32
 #define OLD_DT_LOOS	0x60000000
 #define DT_LOOS		0x6000000d
@@ -252,6 +265,19 @@ typedef struct elf64_hdr {
 #define PF_W		0x2
 #define PF_X		0x1
 
+#define PF_PAGEEXEC	(1U << 4)	/* Enable  PAGEEXEC */
+#define PF_NOPAGEEXEC	(1U << 5)	/* Disable PAGEEXEC */
+#define PF_SEGMEXEC	(1U << 6)	/* Enable  SEGMEXEC */
+#define PF_NOSEGMEXEC	(1U << 7)	/* Disable SEGMEXEC */
+#define PF_MPROTECT	(1U << 8)	/* Enable  MPROTECT */
+#define PF_NOMPROTECT	(1U << 9)	/* Disable MPROTECT */
+/*#define PF_RANDEXEC	(1U << 10)*/	/* Enable  RANDEXEC */
+/*#define PF_NORANDEXEC	(1U << 11)*/	/* Disable RANDEXEC */
+#define PF_EMUTRAMP	(1U << 12)	/* Enable  EMUTRAMP */
+#define PF_NOEMUTRAMP	(1U << 13)	/* Disable EMUTRAMP */
+#define PF_RANDMMAP	(1U << 14)	/* Enable  RANDMMAP */
+#define PF_NORANDMMAP	(1U << 15)	/* Disable RANDMMAP */
+
 typedef struct elf32_phdr{
   Elf32_Word	p_type;
   Elf32_Off	p_offset;
@@ -344,6 +370,8 @@ typedef struct elf64_shdr {
 #define	EI_OSABI	7
 #define	EI_PAD		8
 
+#define	EI_PAX		14
+
 #define	ELFMAG0		0x7f		/* EI_MAG */
 #define	ELFMAG1		'E'
 #define	ELFMAG2		'L'
@@ -423,6 +451,7 @@ extern Elf32_Dyn _DYNAMIC [];
 #define elf_note	elf32_note
 #define elf_addr_t	Elf32_Off
 #define Elf_Half	Elf32_Half
+#define elf_dyn		Elf32_Dyn
 
 #else
 
@@ -433,6 +462,7 @@ extern Elf64_Dyn _DYNAMIC [];
 #define elf_note	elf64_note
 #define elf_addr_t	Elf64_Off
 #define Elf_Half	Elf64_Half
+#define elf_dyn		Elf64_Dyn
 
 #endif
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/err.h linux-3.2.71-pax/include/linux/err.h
--- linux-3.2.71/include/linux/err.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/err.h	2013-03-28 04:10:58.191929537 +0100
@@ -19,12 +19,12 @@
 
 #define IS_ERR_VALUE(x) unlikely((x) >= (unsigned long)-MAX_ERRNO)
 
-static inline void * __must_check ERR_PTR(long error)
+static inline void * __must_check __intentional_overflow(-1) ERR_PTR(long error)
 {
 	return (void *) error;
 }
 
-static inline long __must_check PTR_ERR(const void *ptr)
+static inline long __must_check __intentional_overflow(-1) PTR_ERR(const void *ptr)
 {
 	return (long) ptr;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/fb.h linux-3.2.71-pax/include/linux/fb.h
--- linux-3.2.71/include/linux/fb.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/fb.h	2013-03-28 01:35:23.368427944 +0100
@@ -691,7 +691,7 @@ struct fb_ops {
 	/* called at KDB enter and leave time to prepare the console */
 	int (*fb_debug_enter)(struct fb_info *info);
 	int (*fb_debug_leave)(struct fb_info *info);
-};
+} __do_const;
 
 #ifdef CONFIG_FB_TILEBLITTING
 #define FB_TILE_CURSOR_NONE        0
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/fdtable.h linux-3.2.71-pax/include/linux/fdtable.h
--- linux-3.2.71/include/linux/fdtable.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/fdtable.h	2013-12-19 02:34:54.500726568 +0100
@@ -71,7 +71,7 @@ struct file_operations;
 struct vfsmount;
 struct dentry;
 
-extern int expand_files(struct files_struct *, int nr);
+extern int expand_files(struct files_struct *, unsigned int nr);
 extern void free_fdtable_rcu(struct rcu_head *rcu);
 extern void __init files_defer_init(void);
 
@@ -101,7 +101,7 @@ struct files_struct *get_files_struct(st
 void put_files_struct(struct files_struct *fs);
 void reset_files_struct(struct files_struct *);
 int unshare_files(struct files_struct **);
-struct files_struct *dup_fd(struct files_struct *, int *);
+struct files_struct *dup_fd(struct files_struct *, int *) __latent_entropy;
 
 extern struct kmem_cache *files_cachep;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/filter.h linux-3.2.71-pax/include/linux/filter.h
--- linux-3.2.71/include/linux/filter.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/filter.h	2012-07-04 19:24:48.756063008 +0200
@@ -134,6 +134,7 @@ struct sock_fprog {	/* Required for SO_A
 
 struct sk_buff;
 struct sock;
+struct bpf_jit_work;
 
 struct sk_filter
 {
@@ -141,6 +142,9 @@ struct sk_filter
 	unsigned int         	len;	/* Number of filter blocks */
 	unsigned int		(*bpf_func)(const struct sk_buff *skb,
 					    const struct sock_filter *filter);
+#ifdef CONFIG_BPF_JIT
+	struct bpf_jit_work	*work;
+#endif
 	struct rcu_head		rcu;
 	struct sock_filter     	insns[0];
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/fscache-cache.h linux-3.2.71-pax/include/linux/fscache-cache.h
--- linux-3.2.71/include/linux/fscache-cache.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/fscache-cache.h	2012-07-04 19:24:48.756063008 +0200
@@ -102,7 +102,7 @@ struct fscache_operation {
 	fscache_operation_release_t release;
 };
 
-extern atomic_t fscache_op_debug_id;
+extern atomic_unchecked_t fscache_op_debug_id;
 extern void fscache_op_work_func(struct work_struct *work);
 
 extern void fscache_enqueue_operation(struct fscache_operation *);
@@ -122,7 +122,7 @@ static inline void fscache_operation_ini
 {
 	INIT_WORK(&op->work, fscache_op_work_func);
 	atomic_set(&op->usage, 1);
-	op->debug_id = atomic_inc_return(&fscache_op_debug_id);
+	op->debug_id = atomic_inc_return_unchecked(&fscache_op_debug_id);
 	op->processor = processor;
 	op->release = release;
 	INIT_LIST_HEAD(&op->pend_link);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/fscache.h linux-3.2.71-pax/include/linux/fscache.h
--- linux-3.2.71/include/linux/fscache.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/fscache.h	2013-03-28 01:35:23.376427944 +0100
@@ -152,7 +152,7 @@ struct fscache_cookie_def {
 	 * - this is mandatory for any object that may have data
 	 */
 	void (*now_uncached)(void *cookie_netfs_data);
-};
+} __do_const;
 
 /*
  * fscache cached network filesystem type
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/fs.h linux-3.2.71-pax/include/linux/fs.h
--- linux-3.2.71/include/linux/fs.h	2013-11-29 01:58:28.794491623 +0100
+++ linux-3.2.71-pax/include/linux/fs.h	2013-11-29 01:58:37.710491885 +0100
@@ -1624,7 +1624,8 @@ struct file_operations {
 	int (*setlease)(struct file *, long, struct file_lock **);
 	long (*fallocate)(struct file *file, int mode, loff_t offset,
 			  loff_t len);
-};
+} __do_const;
+typedef struct file_operations __no_const file_operations_no_const;
 
 struct inode_operations {
 	struct dentry * (*lookup) (struct inode *,struct dentry *, struct nameidata *);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/fsnotify.h linux-3.2.71-pax/include/linux/fsnotify.h
--- linux-3.2.71/include/linux/fsnotify.h	2015-05-10 09:22:38.963493133 +0200
+++ linux-3.2.71-pax/include/linux/fsnotify.h	2015-05-10 09:23:09.487494791 +0200
@@ -316,7 +316,7 @@ static inline void fsnotify_change(struc
  */
 static inline const unsigned char *fsnotify_oldname_init(const unsigned char *name)
 {
-	return kstrdup(name, GFP_KERNEL);
+	return (const unsigned char *)kstrdup((const char *)name, GFP_KERNEL);
 }
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/fs_struct.h linux-3.2.71-pax/include/linux/fs_struct.h
--- linux-3.2.71/include/linux/fs_struct.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/fs_struct.h	2012-07-04 19:24:48.760063008 +0200
@@ -6,7 +6,7 @@
 #include <linux/seqlock.h>
 
 struct fs_struct {
-	int users;
+	atomic_t users;
 	spinlock_t lock;
 	seqcount_t seq;
 	int umask;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/ftrace_event.h linux-3.2.71-pax/include/linux/ftrace_event.h
--- linux-3.2.71/include/linux/ftrace_event.h	2013-09-10 17:24:55.601739112 +0200
+++ linux-3.2.71-pax/include/linux/ftrace_event.h	2013-09-10 17:24:59.089738926 +0200
@@ -256,7 +256,7 @@ extern int trace_define_field(struct ftr
 extern int trace_add_event_call(struct ftrace_event_call *call);
 extern void trace_remove_event_call(struct ftrace_event_call *call);
 
-#define is_signed_type(type)	(((type)(-1)) < 0)
+#define is_signed_type(type)	(((type)(-1)) < (type)1)
 
 int trace_set_clr_event(const char *system, const char *event, int set);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/genhd.h linux-3.2.71-pax/include/linux/genhd.h
--- linux-3.2.71/include/linux/genhd.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/genhd.h	2013-09-27 19:59:05.828197852 +0200
@@ -185,7 +185,7 @@ struct gendisk {
 	struct kobject *slave_dir;
 
 	struct timer_rand_state *random;
-	atomic_t sync_io;		/* RAID */
+	atomic_unchecked_t sync_io;	/* RAID */
 	struct disk_events *ev;
 #ifdef  CONFIG_BLK_DEV_INTEGRITY
 	struct blk_integrity *integrity;
@@ -420,7 +420,7 @@ extern void disk_flush_events(struct gen
 extern unsigned int disk_clear_events(struct gendisk *disk, unsigned int mask);
 
 /* drivers/char/random.c */
-extern void add_disk_randomness(struct gendisk *disk);
+extern void add_disk_randomness(struct gendisk *disk) __latent_entropy;
 extern void rand_initialize_disk(struct gendisk *disk);
 
 static inline sector_t get_start_sect(struct block_device *bdev)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/gfp.h linux-3.2.71-pax/include/linux/gfp.h
--- linux-3.2.71/include/linux/gfp.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/gfp.h	2012-07-27 21:28:07.474301346 +0200
@@ -37,6 +37,12 @@ struct vm_area_struct;
 #define ___GFP_NO_KSWAPD	0x400000u
 #define ___GFP_OTHER_NODE	0x800000u
 
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+#define ___GFP_USERCOPY		0x1000000u
+#else
+#define ___GFP_USERCOPY		0
+#endif
+
 /*
  * GFP bitmasks..
  *
@@ -85,6 +91,7 @@ struct vm_area_struct;
 
 #define __GFP_NO_KSWAPD	((__force gfp_t)___GFP_NO_KSWAPD)
 #define __GFP_OTHER_NODE ((__force gfp_t)___GFP_OTHER_NODE) /* On behalf of other node */
+#define __GFP_USERCOPY	((__force gfp_t)___GFP_USERCOPY)/* Allocator intends to copy page to/from userland */
 
 /*
  * This may seem redundant, but it's a way of annotating false positives vs.
@@ -92,7 +99,7 @@ struct vm_area_struct;
  */
 #define __GFP_NOTRACK_FALSE_POSITIVE (__GFP_NOTRACK)
 
-#define __GFP_BITS_SHIFT 24	/* Room for N __GFP_FOO bits */
+#define __GFP_BITS_SHIFT 25	/* Room for N __GFP_FOO bits */
 #define __GFP_BITS_MASK ((__force gfp_t)((1 << __GFP_BITS_SHIFT) - 1))
 
 /* This equals 0, but use constants in case they ever change */
@@ -146,6 +153,8 @@ struct vm_area_struct;
 /* 4GB DMA on some platforms */
 #define GFP_DMA32	__GFP_DMA32
 
+#define GFP_USERCOPY	__GFP_USERCOPY
+
 /* Convert GFP flags to their corresponding migrate type */
 static inline int allocflags_to_migratetype(gfp_t gfp_flags)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/highmem.h linux-3.2.71-pax/include/linux/highmem.h
--- linux-3.2.71/include/linux/highmem.h	2013-01-03 19:05:14.764036862 +0100
+++ linux-3.2.71-pax/include/linux/highmem.h	2013-01-03 19:05:22.116037079 +0100
@@ -192,6 +192,18 @@ static inline void clear_highpage(struct
 	kunmap_atomic(kaddr, KM_USER0);
 }
 
+static inline void sanitize_highpage(struct page *page)
+{
+	void *kaddr;
+	unsigned long flags;
+
+	local_irq_save(flags);
+	kaddr = kmap_atomic(page, KM_CLEARPAGE);
+	clear_page(kaddr);
+	kunmap_atomic(kaddr, KM_CLEARPAGE);
+	local_irq_restore(flags);
+}
+
 static inline void zero_user_segments(struct page *page,
 	unsigned start1, unsigned end1,
 	unsigned start2, unsigned end2)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/hwmon-sysfs.h linux-3.2.71-pax/include/linux/hwmon-sysfs.h
--- linux-3.2.71/include/linux/hwmon-sysfs.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/hwmon-sysfs.h	2013-03-28 01:35:23.380427944 +0100
@@ -23,7 +23,8 @@
 struct sensor_device_attribute{
 	struct device_attribute dev_attr;
 	int index;
-};
+} __do_const;
+typedef struct sensor_device_attribute __no_const sensor_device_attribute_no_const;
 #define to_sensor_dev_attr(_dev_attr) \
 	container_of(_dev_attr, struct sensor_device_attribute, dev_attr)
 
@@ -39,7 +40,7 @@ struct sensor_device_attribute_2 {
 	struct device_attribute dev_attr;
 	u8 index;
 	u8 nr;
-};
+} __do_const;
 #define to_sensor_dev_attr_2(_dev_attr) \
 	container_of(_dev_attr, struct sensor_device_attribute_2, dev_attr)
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/i2c.h linux-3.2.71-pax/include/linux/i2c.h
--- linux-3.2.71/include/linux/i2c.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/i2c.h	2012-07-04 19:24:48.764063008 +0200
@@ -364,6 +364,7 @@ struct i2c_algorithm {
 	/* To determine what the adapter supports */
 	u32 (*functionality) (struct i2c_adapter *);
 };
+typedef struct i2c_algorithm __no_const i2c_algorithm_no_const;
 
 /*
  * i2c_adapter is the structure used to identify a physical i2c bus along
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/i2o.h linux-3.2.71-pax/include/linux/i2o.h
--- linux-3.2.71/include/linux/i2o.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/i2o.h	2012-07-04 19:24:48.764063008 +0200
@@ -564,7 +564,7 @@ struct i2o_controller {
 	struct i2o_device *exec;	/* Executive */
 #if BITS_PER_LONG == 64
 	spinlock_t context_list_lock;	/* lock for context_list */
-	atomic_t context_list_counter;	/* needed for unique contexts */
+	atomic_unchecked_t context_list_counter;	/* needed for unique contexts */
 	struct list_head context_list;	/* list of context id's
 					   and pointers */
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/if_pppox.h linux-3.2.71-pax/include/linux/if_pppox.h
--- linux-3.2.71/include/linux/if_pppox.h	2013-08-03 22:17:29.510408839 +0200
+++ linux-3.2.71-pax/include/linux/if_pppox.h	2013-08-03 22:17:33.538408624 +0200
@@ -203,7 +203,7 @@ struct pppox_proto {
 	int		(*ioctl)(struct socket *sock, unsigned int cmd,
 				 unsigned long arg);
 	struct module	*owner;
-};
+} __do_const;
 
 extern int register_pppox_proto(int proto_num, const struct pppox_proto *pp);
 extern void unregister_pppox_proto(int proto_num);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/init.h linux-3.2.71-pax/include/linux/init.h
--- linux-3.2.71/include/linux/init.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/init.h	2013-09-17 02:18:05.729644550 +0200
@@ -38,9 +38,29 @@
  * Also note, that this data cannot be "const".
  */
 
+#define add_init_latent_entropy __latent_entropy
+
+#ifdef CONFIG_HOTPLUG
+#define add_devinit_latent_entropy
+#else
+#define add_devinit_latent_entropy __latent_entropy
+#endif
+
+#ifdef CONFIG_HOTPLUG_CPU
+#define add_cpuinit_latent_entropy
+#else
+#define add_cpuinit_latent_entropy __latent_entropy
+#endif
+
+#ifdef CONFIG_MEMORY_HOTPLUG
+#define add_meminit_latent_entropy
+#else
+#define add_meminit_latent_entropy __latent_entropy
+#endif
+
 /* These are for everybody (although not all archs will actually
    discard it in modules) */
-#define __init		__section(.init.text) __cold notrace
+#define __init		__section(.init.text) __cold notrace add_init_latent_entropy
 #define __initdata	__section(.init.data)
 #define __initconst	__section(.init.rodata)
 #define __exitdata	__section(.exit.data)
@@ -82,7 +102,7 @@
 #define __exit          __section(.exit.text) __exitused __cold notrace
 
 /* Used for HOTPLUG */
-#define __devinit        __section(.devinit.text) __cold notrace
+#define __devinit        __section(.devinit.text) __cold notrace add_devinit_latent_entropy
 #define __devinitdata    __section(.devinit.data)
 #define __devinitconst   __section(.devinit.rodata)
 #define __devexit        __section(.devexit.text) __exitused __cold notrace
@@ -90,7 +110,7 @@
 #define __devexitconst   __section(.devexit.rodata)
 
 /* Used for HOTPLUG_CPU */
-#define __cpuinit        __section(.cpuinit.text) __cold notrace
+#define __cpuinit        __section(.cpuinit.text) __cold notrace add_cpuinit_latent_entropy
 #define __cpuinitdata    __section(.cpuinit.data)
 #define __cpuinitconst   __section(.cpuinit.rodata)
 #define __cpuexit        __section(.cpuexit.text) __exitused __cold notrace
@@ -98,7 +118,7 @@
 #define __cpuexitconst   __section(.cpuexit.rodata)
 
 /* Used for MEMORY_HOTPLUG */
-#define __meminit        __section(.meminit.text) __cold notrace
+#define __meminit        __section(.meminit.text) __cold notrace add_meminit_latent_entropy
 #define __meminitdata    __section(.meminit.data)
 #define __meminitconst   __section(.meminit.rodata)
 #define __memexit        __section(.memexit.text) __exitused __cold notrace
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/init_task.h linux-3.2.71-pax/include/linux/init_task.h
--- linux-3.2.71/include/linux/init_task.h	2012-08-12 12:28:42.609231800 +0200
+++ linux-3.2.71-pax/include/linux/init_task.h	2014-03-13 17:08:12.699852432 +0100
@@ -144,6 +144,12 @@ extern struct task_group root_task_group
 
 #define INIT_TASK_COMM "swapper"
 
+#ifdef CONFIG_X86
+#define INIT_TASK_THREAD_INFO .tinfo = INIT_THREAD_INFO,
+#else
+#define INIT_TASK_THREAD_INFO
+#endif
+
 /*
  *  INIT_TASK is used to set up the first task table, touch at
  * your own risk!. Base=0, limit=0x1fffff (=2MB)
@@ -183,6 +189,7 @@ extern struct task_group root_task_group
 	RCU_INIT_POINTER(.cred, &init_cred),				\
 	.comm		= INIT_TASK_COMM,				\
 	.thread		= INIT_THREAD,					\
+	INIT_TASK_THREAD_INFO						\
 	.fs		= &init_fs,					\
 	.files		= &init_files,					\
 	.signal		= &init_signals,				\
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/interrupt.h linux-3.2.71-pax/include/linux/interrupt.h
--- linux-3.2.71/include/linux/interrupt.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/interrupt.h	2013-02-17 16:28:47.588320185 +0100
@@ -441,7 +441,7 @@ enum
 /* map softirq index to softirq name. update 'softirq_to_name' in
  * kernel/softirq.c when adding a new softirq.
  */
-extern char *softirq_to_name[NR_SOFTIRQS];
+extern const char * const softirq_to_name[NR_SOFTIRQS];
 
 /* softirq mask and active fields moved to irq_cpustat_t in
  * asm/hardirq.h to get better cache usage.  KAO
@@ -449,12 +449,12 @@ extern char *softirq_to_name[NR_SOFTIRQS
 
 struct softirq_action
 {
-	void	(*action)(struct softirq_action *);
-};
+	void	(*action)(void);
+} __no_const;
 
 asmlinkage void do_softirq(void);
 asmlinkage void __do_softirq(void);
-extern void open_softirq(int nr, void (*action)(struct softirq_action *));
+extern void open_softirq(int nr, void (*action)(void));
 extern void softirq_init(void);
 static inline void __raise_softirq_irqoff(unsigned int nr)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/ioport.h linux-3.2.71-pax/include/linux/ioport.h
--- linux-3.2.71/include/linux/ioport.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/ioport.h	2013-04-30 00:31:30.055758236 +0200
@@ -166,7 +166,7 @@ struct resource *lookup_resource(struct
 int adjust_resource(struct resource *res, resource_size_t start,
 		    resource_size_t size);
 resource_size_t resource_alignment(struct resource *res);
-static inline resource_size_t resource_size(const struct resource *res)
+static inline resource_size_t __intentional_overflow(-1) resource_size(const struct resource *res)
 {
 	return res->end - res->start + 1;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/irqdesc.h linux-3.2.71-pax/include/linux/irqdesc.h
--- linux-3.2.71/include/linux/irqdesc.h	2014-07-12 17:42:33.920954215 +0200
+++ linux-3.2.71-pax/include/linux/irqdesc.h	2015-02-27 17:22:44.111965079 +0100
@@ -55,7 +55,7 @@ struct irq_desc {
 	unsigned int		irq_count;	/* For detecting broken IRQs */
 	unsigned long		last_unhandled;	/* Aging timer for unhandled count */
 	unsigned int		irqs_unhandled;
-	atomic_t		threads_handled;
+	atomic_unchecked_t	threads_handled;
 	int			threads_handled_last;
 	raw_spinlock_t		lock;
 	struct cpumask		*percpu_enabled;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/irq.h linux-3.2.71-pax/include/linux/irq.h
--- linux-3.2.71/include/linux/irq.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/irq.h	2013-03-27 23:40:08.004797171 +0100
@@ -328,7 +328,7 @@ struct irq_chip {
 #ifdef CONFIG_IRQ_RELEASE_METHOD
 	void		(*release)(unsigned int irq, void *dev_id);
 #endif
-};
+} __do_const;
 
 /*
  * irq_chip specific flags
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/jiffies.h linux-3.2.71-pax/include/linux/jiffies.h
--- linux-3.2.71/include/linux/jiffies.h	2014-11-05 23:20:30.197389802 +0100
+++ linux-3.2.71-pax/include/linux/jiffies.h	2014-11-05 23:20:50.541398834 +0100
@@ -283,9 +283,9 @@ extern unsigned long preset_lpj;
  */
 extern unsigned int jiffies_to_msecs(const unsigned long j);
 extern unsigned int jiffies_to_usecs(const unsigned long j);
-extern unsigned long msecs_to_jiffies(const unsigned int m);
-extern unsigned long usecs_to_jiffies(const unsigned int u);
-extern unsigned long timespec_to_jiffies(const struct timespec *value);
+extern unsigned long msecs_to_jiffies(const unsigned int m) __intentional_overflow(-1);
+extern unsigned long usecs_to_jiffies(const unsigned int u) __intentional_overflow(-1);
+extern unsigned long timespec_to_jiffies(const struct timespec *value) __intentional_overflow(-1);
 extern void jiffies_to_timespec(const unsigned long jiffies,
 				struct timespec *value);
 extern unsigned long timeval_to_jiffies(const struct timeval *value);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/key-type.h linux-3.2.71-pax/include/linux/key-type.h
--- linux-3.2.71/include/linux/key-type.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/key-type.h	2013-03-28 01:41:51.684407211 +0100
@@ -92,7 +92,7 @@ struct key_type {
 
 	/* internal fields */
 	struct list_head	link;		/* link in types list */
-};
+} __do_const;
 
 extern struct key_type key_type_keyring;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/kgdb.h linux-3.2.71-pax/include/linux/kgdb.h
--- linux-3.2.71/include/linux/kgdb.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/kgdb.h	2012-07-04 19:24:48.768063008 +0200
@@ -53,7 +53,7 @@ extern int kgdb_connected;
 extern int kgdb_io_module_registered;
 
 extern atomic_t			kgdb_setting_breakpoint;
-extern atomic_t			kgdb_cpu_doing_single_step;
+extern atomic_unchecked_t	kgdb_cpu_doing_single_step;
 
 extern struct task_struct	*kgdb_usethread;
 extern struct task_struct	*kgdb_contthread;
@@ -252,7 +252,7 @@ struct kgdb_arch {
 	void	(*disable_hw_break)(struct pt_regs *regs);
 	void	(*remove_all_hw_break)(void);
 	void	(*correct_hw_break)(void);
-};
+} __do_const;
 
 /**
  * struct kgdb_io - Describe the interface for an I/O driver to talk with KGDB.
@@ -277,7 +277,7 @@ struct kgdb_io {
 	void			(*pre_exception) (void);
 	void			(*post_exception) (void);
 	int			is_console;
-};
+} __do_const;
 
 extern struct kgdb_arch		arch_kgdb_ops;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/kobject.h linux-3.2.71-pax/include/linux/kobject.h
--- linux-3.2.71/include/linux/kobject.h	2012-09-20 01:42:17.454672774 +0200
+++ linux-3.2.71-pax/include/linux/kobject.h	2013-03-28 01:35:23.164427955 +0100
@@ -111,7 +111,7 @@ struct kobj_type {
 	struct attribute **default_attrs;
 	const struct kobj_ns_type_operations *(*child_ns_type)(struct kobject *kobj);
 	const void *(*namespace)(struct kobject *kobj);
-};
+} __do_const;
 
 struct kobj_uevent_env {
 	char *envp[UEVENT_NUM_ENVP];
@@ -134,6 +134,7 @@ struct kobj_attribute {
 	ssize_t (*store)(struct kobject *kobj, struct kobj_attribute *attr,
 			 const char *buf, size_t count);
 };
+typedef struct kobj_attribute __no_const kobj_attribute_no_const;
 
 extern const struct sysfs_ops kobj_sysfs_ops;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/kobject_ns.h linux-3.2.71-pax/include/linux/kobject_ns.h
--- linux-3.2.71/include/linux/kobject_ns.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/kobject_ns.h	2013-03-28 01:35:23.412427942 +0100
@@ -43,7 +43,7 @@ struct kobj_ns_type_operations {
 	const void *(*netlink_ns)(struct sock *sk);
 	const void *(*initial_ns)(void);
 	void (*drop_ns)(void *);
-};
+} __do_const;
 
 int kobj_ns_type_register(const struct kobj_ns_type_operations *ops);
 int kobj_ns_type_registered(enum kobj_ns_type type);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/kvm_host.h linux-3.2.71-pax/include/linux/kvm_host.h
--- linux-3.2.71/include/linux/kvm_host.h	2014-06-10 10:59:38.794436242 +0200
+++ linux-3.2.71-pax/include/linux/kvm_host.h	2014-06-10 10:59:44.178435955 +0200
@@ -307,7 +307,7 @@ void kvm_vcpu_uninit(struct kvm_vcpu *vc
 void vcpu_load(struct kvm_vcpu *vcpu);
 void vcpu_put(struct kvm_vcpu *vcpu);
 
-int kvm_init(void *opaque, unsigned vcpu_size, unsigned vcpu_align,
+int kvm_init(const void *opaque, unsigned vcpu_size, unsigned vcpu_align,
 		  struct module *module);
 void kvm_exit(void);
 
@@ -453,7 +453,7 @@ int kvm_arch_vcpu_ioctl_set_guest_debug(
 					struct kvm_guest_debug *dbg);
 int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu, struct kvm_run *kvm_run);
 
-int kvm_arch_init(void *opaque);
+int kvm_arch_init(const void *opaque);
 void kvm_arch_exit(void);
 
 int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/libata.h linux-3.2.71-pax/include/linux/libata.h
--- linux-3.2.71/include/linux/libata.h	2015-08-14 21:48:35.348707911 +0200
+++ linux-3.2.71-pax/include/linux/libata.h	2015-08-14 21:48:45.680707359 +0200
@@ -926,7 +926,7 @@ struct ata_port_operations {
 	 * fields must be pointers.
 	 */
 	const struct ata_port_operations	*inherits;
-};
+} __do_const;
 
 struct ata_port_info {
 	unsigned long		flags;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/linkage.h linux-3.2.71-pax/include/linux/linkage.h
--- linux-3.2.71/include/linux/linkage.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/linkage.h	2015-01-05 18:58:02.377375678 +0100
@@ -15,6 +15,7 @@
 #endif
 
 #define __page_aligned_data	__section(.data..page_aligned) __aligned(PAGE_SIZE)
+#define __page_aligned_rodata	__read_only __aligned(PAGE_SIZE)
 #define __page_aligned_bss	__section(.bss..page_aligned) __aligned(PAGE_SIZE)
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/list.h linux-3.2.71-pax/include/linux/list.h
--- linux-3.2.71/include/linux/list.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/list.h	2013-03-28 01:35:23.164427955 +0100
@@ -112,6 +112,19 @@ extern void __list_del_entry(struct list
 extern void list_del(struct list_head *entry);
 #endif
 
+extern void __pax_list_add(struct list_head *new,
+			      struct list_head *prev,
+			      struct list_head *next);
+static inline void pax_list_add(struct list_head *new, struct list_head *head)
+{
+	__pax_list_add(new, head, head->next);
+}
+static inline void pax_list_add_tail(struct list_head *new, struct list_head *head)
+{
+	__pax_list_add(new, head->prev, head);
+}
+extern void pax_list_del(struct list_head *entry);
+
 /**
  * list_replace - replace old entry by new one
  * @old : the element to be replaced
@@ -145,6 +158,8 @@ static inline void list_del_init(struct
 	INIT_LIST_HEAD(entry);
 }
 
+extern void pax_list_del_init(struct list_head *entry);
+
 /**
  * list_move - delete from one list and add as another's head
  * @list: the entry to move
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/math64.h linux-3.2.71-pax/include/linux/math64.h
--- linux-3.2.71/include/linux/math64.h	2014-08-06 23:17:21.857614202 +0200
+++ linux-3.2.71-pax/include/linux/math64.h	2014-08-06 23:17:55.849614126 +0200
@@ -15,7 +15,7 @@
  * This is commonly provided by 32bit archs to provide an optimized 64bit
  * divide.
  */
-static inline u64 div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)
+static inline u64 __intentional_overflow(-1) div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)
 {
 	*remainder = dividend % divisor;
 	return dividend / divisor;
@@ -33,7 +33,7 @@ static inline s64 div_s64_rem(s64 divide
 /**
  * div64_u64 - unsigned 64bit divide with 64bit divisor
  */
-static inline u64 div64_u64(u64 dividend, u64 divisor)
+static inline u64 __intentional_overflow(-1) div64_u64(u64 dividend, u64 divisor)
 {
 	return dividend / divisor;
 }
@@ -52,7 +52,7 @@ static inline s64 div64_s64(s64 dividend
 #define div64_ul(x, y)   div_u64((x), (y))
 
 #ifndef div_u64_rem
-static inline u64 div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)
+static inline u64 __intentional_overflow(-1) div_u64_rem(u64 dividend, u32 divisor, u32 *remainder)
 {
 	*remainder = do_div(dividend, divisor);
 	return dividend;
@@ -64,7 +64,7 @@ extern s64 div_s64_rem(s64 dividend, s32
 #endif
 
 #ifndef div64_u64
-extern u64 div64_u64(u64 dividend, u64 divisor);
+extern u64 __intentional_overflow(-1) div64_u64(u64 dividend, u64 divisor);
 #endif
 
 #ifndef div64_s64
@@ -81,7 +81,7 @@ extern s64 div64_s64(s64 dividend, s64 d
  * divide.
  */
 #ifndef div_u64
-static inline u64 div_u64(u64 dividend, u32 divisor)
+static inline u64 __intentional_overflow(-1) div_u64(u64 dividend, u32 divisor)
 {
 	u32 remainder;
 	return div_u64_rem(dividend, divisor, &remainder);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/mca.h linux-3.2.71-pax/include/linux/mca.h
--- linux-3.2.71/include/linux/mca.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/mca.h	2012-07-04 19:24:48.768063008 +0200
@@ -80,7 +80,7 @@ struct mca_bus_accessor_functions {
 						  int region);
 	void *		(*mca_transform_memory)(struct mca_device *,
 						void *memory);
-};
+} __no_const;
 
 struct mca_bus {
 	u64			default_dma_mask;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/mmc/core.h linux-3.2.71-pax/include/linux/mmc/core.h
--- linux-3.2.71/include/linux/mmc/core.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/mmc/core.h	2015-04-30 03:07:38.404532395 +0200
@@ -76,7 +76,7 @@ struct mmc_command {
 #define mmc_cmd_type(cmd)	((cmd)->flags & MMC_CMD_MASK)
 
 	unsigned int		retries;	/* max number of retries */
-	unsigned int		error;		/* command error */
+	int			error;		/* command error */
 
 /*
  * Standard errno values are used for errors, but some have specific
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/mm.h linux-3.2.71-pax/include/linux/mm.h
--- linux-3.2.71/include/linux/mm.h	2015-02-20 12:37:33.233178768 +0100
+++ linux-3.2.71-pax/include/linux/mm.h	2015-02-20 12:37:41.905178305 +0100
@@ -115,7 +115,14 @@ extern unsigned int kobjsize(const void
 
 #define VM_CAN_NONLINEAR 0x08000000	/* Has ->fault & does nonlinear pages */
 #define VM_MIXEDMAP	0x10000000	/* Can contain "struct page" and pure PFN pages */
+
+#if defined(CONFIG_PAX_PAGEEXEC) && defined(CONFIG_X86_32)
+#define VM_SAO		0x00000000	/* Strong Access Ordering (powerpc) */
+#define VM_PAGEEXEC	0x20000000	/* vma->vm_page_prot needs special handling */
+#else
 #define VM_SAO		0x20000000	/* Strong Access Ordering (powerpc) */
+#endif
+
 #define VM_PFN_AT_MMAP	0x40000000	/* PFNMAP vma that is fully mapped at mmap time */
 #define VM_MERGEABLE	0x80000000	/* KSM may merge identical pages */
 
@@ -213,8 +220,8 @@ struct vm_operations_struct {
 	/* called by access_process_vm when get_user_pages() fails, typically
 	 * for use by special VMAs that can switch between memory and hardware
 	 */
-	int (*access)(struct vm_area_struct *vma, unsigned long addr,
-		      void *buf, int len, int write);
+	ssize_t (*access)(struct vm_area_struct *vma, unsigned long addr,
+		      void *buf, size_t len, int write);
 #ifdef CONFIG_NUMA
 	/*
 	 * set_policy() op must add a reference to any non-NULL @new mempolicy
@@ -241,6 +248,7 @@ struct vm_operations_struct {
 		const nodemask_t *to, unsigned long flags);
 #endif
 };
+typedef struct vm_operations_struct __no_const vm_operations_struct_no_const;
 
 struct mmu_gather;
 struct inode;
@@ -942,8 +950,8 @@ int follow_pfn(struct vm_area_struct *vm
 	unsigned long *pfn);
 int follow_phys(struct vm_area_struct *vma, unsigned long address,
 		unsigned int flags, unsigned long *prot, resource_size_t *phys);
-int generic_access_phys(struct vm_area_struct *vma, unsigned long addr,
-			void *buf, int len, int write);
+ssize_t generic_access_phys(struct vm_area_struct *vma, unsigned long addr,
+			void *buf, size_t len, int write);
 
 static inline void unmap_shared_mapping_range(struct address_space *mapping,
 		loff_t const holebegin, loff_t const holelen)
@@ -986,10 +994,10 @@ static inline int fixup_user_fault(struc
 }
 #endif
 
-extern int make_pages_present(unsigned long addr, unsigned long end);
-extern int access_process_vm(struct task_struct *tsk, unsigned long addr, void *buf, int len, int write);
-extern int access_remote_vm(struct mm_struct *mm, unsigned long addr,
-		void *buf, int len, int write);
+extern ssize_t make_pages_present(unsigned long addr, unsigned long end);
+extern ssize_t access_process_vm(struct task_struct *tsk, unsigned long addr, void *buf, size_t len, int write);
+extern ssize_t access_remote_vm(struct mm_struct *mm, unsigned long addr,
+		void *buf, size_t len, int write);
 
 int __get_user_pages(struct task_struct *tsk, struct mm_struct *mm,
 		     unsigned long start, int len, unsigned int foll_flags,
@@ -1015,34 +1023,6 @@ int set_page_dirty(struct page *page);
 int set_page_dirty_lock(struct page *page);
 int clear_page_dirty_for_io(struct page *page);
 
-/* Is the vma a continuation of the stack vma above it? */
-static inline int vma_growsdown(struct vm_area_struct *vma, unsigned long addr)
-{
-	return vma && (vma->vm_end == addr) && (vma->vm_flags & VM_GROWSDOWN);
-}
-
-static inline int stack_guard_page_start(struct vm_area_struct *vma,
-					     unsigned long addr)
-{
-	return (vma->vm_flags & VM_GROWSDOWN) &&
-		(vma->vm_start == addr) &&
-		!vma_growsdown(vma->vm_prev, addr);
-}
-
-/* Is the vma a continuation of the stack vma below it? */
-static inline int vma_growsup(struct vm_area_struct *vma, unsigned long addr)
-{
-	return vma && (vma->vm_start == addr) && (vma->vm_flags & VM_GROWSUP);
-}
-
-static inline int stack_guard_page_end(struct vm_area_struct *vma,
-					   unsigned long addr)
-{
-	return (vma->vm_flags & VM_GROWSUP) &&
-		(vma->vm_end == addr) &&
-		!vma_growsup(vma->vm_next, addr);
-}
-
 extern unsigned long move_page_tables(struct vm_area_struct *vma,
 		unsigned long old_addr, struct vm_area_struct *new_vma,
 		unsigned long new_addr, unsigned long len);
@@ -1137,6 +1117,15 @@ static inline void sync_mm_rss(struct ta
 }
 #endif
 
+#ifdef CONFIG_MMU
+pgprot_t vm_get_page_prot(vm_flags_t vm_flags);
+#else
+static inline pgprot_t vm_get_page_prot(vm_flags_t vm_flags)
+{
+	return __pgprot(0);
+}
+#endif
+
 int vma_wants_writenotify(struct vm_area_struct *vma);
 
 extern pte_t *__get_locked_pte(struct mm_struct *mm, unsigned long addr,
@@ -1155,8 +1144,15 @@ static inline int __pud_alloc(struct mm_
 {
 	return 0;
 }
+
+static inline int __pud_alloc_kernel(struct mm_struct *mm, pgd_t *pgd,
+						unsigned long address)
+{
+	return 0;
+}
 #else
 int __pud_alloc(struct mm_struct *mm, pgd_t *pgd, unsigned long address);
+int __pud_alloc_kernel(struct mm_struct *mm, pgd_t *pgd, unsigned long address);
 #endif
 
 #ifdef __PAGETABLE_PMD_FOLDED
@@ -1165,8 +1161,15 @@ static inline int __pmd_alloc(struct mm_
 {
 	return 0;
 }
+
+static inline int __pmd_alloc_kernel(struct mm_struct *mm, pud_t *pud,
+						unsigned long address)
+{
+	return 0;
+}
 #else
 int __pmd_alloc(struct mm_struct *mm, pud_t *pud, unsigned long address);
+int __pmd_alloc_kernel(struct mm_struct *mm, pud_t *pud, unsigned long address);
 #endif
 
 int __pte_alloc(struct mm_struct *mm, struct vm_area_struct *vma,
@@ -1184,11 +1187,23 @@ static inline pud_t *pud_alloc(struct mm
 		NULL: pud_offset(pgd, address);
 }
 
+static inline pud_t *pud_alloc_kernel(struct mm_struct *mm, pgd_t *pgd, unsigned long address)
+{
+	return (unlikely(pgd_none(*pgd)) && __pud_alloc_kernel(mm, pgd, address))?
+		NULL: pud_offset(pgd, address);
+}
+
 static inline pmd_t *pmd_alloc(struct mm_struct *mm, pud_t *pud, unsigned long address)
 {
 	return (unlikely(pud_none(*pud)) && __pmd_alloc(mm, pud, address))?
 		NULL: pmd_offset(pud, address);
 }
+
+static inline pmd_t *pmd_alloc_kernel(struct mm_struct *mm, pud_t *pud, unsigned long address)
+{
+	return (unlikely(pud_none(*pud)) && __pmd_alloc_kernel(mm, pud, address))?
+		NULL: pmd_offset(pud, address);
+}
 #endif /* CONFIG_MMU && !__ARCH_HAS_4LEVEL_HACK */
 
 #if USE_SPLIT_PTLOCKS
@@ -1399,7 +1414,7 @@ extern int install_special_mapping(struc
 				   unsigned long addr, unsigned long len,
 				   unsigned long flags, struct page **pages);
 
-extern unsigned long get_unmapped_area(struct file *, unsigned long, unsigned long, unsigned long, unsigned long);
+extern unsigned long get_unmapped_area(struct file *, unsigned long, unsigned long, unsigned long, unsigned long) __intentional_overflow(-1);
 
 extern unsigned long do_mmap_pgoff(struct file *file, unsigned long addr,
 	unsigned long len, unsigned long prot,
@@ -1422,6 +1437,7 @@ out:
 }
 
 extern int do_munmap(struct mm_struct *, unsigned long, size_t);
+extern int __do_munmap(struct mm_struct *, unsigned long, size_t);
 
 extern unsigned long do_brk(unsigned long, unsigned long);
 
@@ -1479,6 +1495,10 @@ extern struct vm_area_struct * find_vma(
 extern struct vm_area_struct * find_vma_prev(struct mm_struct * mm, unsigned long addr,
 					     struct vm_area_struct **pprev);
 
+extern struct vm_area_struct *pax_find_mirror_vma(struct vm_area_struct *vma);
+extern __must_check long pax_mirror_vma(struct vm_area_struct *vma_m, struct vm_area_struct *vma);
+extern void pax_mirror_file_pte(struct vm_area_struct *vma, unsigned long address, struct page *page_m, spinlock_t *ptl);
+
 /* Look up the first VMA which intersects the interval start_addr..end_addr-1,
    NULL if none.  Assume start_addr < end_addr. */
 static inline struct vm_area_struct * find_vma_intersection(struct mm_struct * mm, unsigned long start_addr, unsigned long end_addr)
@@ -1495,15 +1515,6 @@ static inline unsigned long vma_pages(st
 	return (vma->vm_end - vma->vm_start) >> PAGE_SHIFT;
 }
 
-#ifdef CONFIG_MMU
-pgprot_t vm_get_page_prot(unsigned long vm_flags);
-#else
-static inline pgprot_t vm_get_page_prot(unsigned long vm_flags)
-{
-	return __pgprot(0);
-}
-#endif
-
 struct vm_area_struct *find_extend_vma(struct mm_struct *, unsigned long addr);
 int remap_pfn_range(struct vm_area_struct *, unsigned long addr,
 			unsigned long pfn, unsigned long size, pgprot_t);
@@ -1539,6 +1550,12 @@ void vm_stat_account(struct mm_struct *,
 static inline void vm_stat_account(struct mm_struct *mm,
 			unsigned long flags, struct file *file, long pages)
 {
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP) || (flags & (VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)))
+#endif
+
+	mm->total_vm += pages;
 }
 #endif /* CONFIG_PROC_FS */
 
@@ -1619,7 +1636,7 @@ extern int unpoison_memory(unsigned long
 extern int sysctl_memory_failure_early_kill;
 extern int sysctl_memory_failure_recovery;
 extern void shake_page(struct page *p, int access);
-extern atomic_long_t mce_bad_pages;
+extern atomic_long_unchecked_t mce_bad_pages;
 extern int soft_offline_page(struct page *page, int flags);
 
 extern void dump_page(struct page *page);
@@ -1633,5 +1650,11 @@ extern void copy_user_huge_page(struct p
 				unsigned int pages_per_huge_page);
 #endif /* CONFIG_TRANSPARENT_HUGEPAGE || CONFIG_HUGETLBFS */
 
+#ifdef CONFIG_ARCH_TRACK_EXEC_LIMIT
+extern void track_exec_limit(struct mm_struct *mm, unsigned long start, unsigned long end, unsigned long prot);
+#else
+static inline void track_exec_limit(struct mm_struct *mm, unsigned long start, unsigned long end, unsigned long prot) {}
+#endif
+
 #endif /* __KERNEL__ */
 #endif /* _LINUX_MM_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/mmiotrace.h linux-3.2.71-pax/include/linux/mmiotrace.h
--- linux-3.2.71/include/linux/mmiotrace.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/mmiotrace.h	2013-01-16 21:27:15.898836688 +0100
@@ -46,7 +46,7 @@ extern int kmmio_handler(struct pt_regs
 /* Called from ioremap.c */
 extern void mmiotrace_ioremap(resource_size_t offset, unsigned long size,
 							void __iomem *addr);
-extern void mmiotrace_iounmap(volatile void __iomem *addr);
+extern void mmiotrace_iounmap(const volatile void __iomem *addr);
 
 /* For anyone to insert markers. Remember trailing newline. */
 extern __printf(1, 2) int mmiotrace_printk(const char *fmt, ...);
@@ -66,7 +66,7 @@ static inline void mmiotrace_ioremap(res
 {
 }
 
-static inline void mmiotrace_iounmap(volatile void __iomem *addr)
+static inline void mmiotrace_iounmap(const volatile void __iomem *addr)
 {
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/mm_types.h linux-3.2.71-pax/include/linux/mm_types.h
--- linux-3.2.71/include/linux/mm_types.h	2013-09-10 17:24:55.601739112 +0200
+++ linux-3.2.71-pax/include/linux/mm_types.h	2013-09-10 17:24:59.089738926 +0200
@@ -253,6 +253,8 @@ struct vm_area_struct {
 #ifdef CONFIG_NUMA
 	struct mempolicy *vm_policy;	/* NUMA policy for the VMA */
 #endif
+
+	struct vm_area_struct *vm_mirror;/* PaX: mirror vma or NULL */
 };
 
 struct core_thread {
@@ -390,6 +392,24 @@ struct mm_struct {
 #ifdef CONFIG_CPUMASK_OFFSTACK
 	struct cpumask cpumask_allocation;
 #endif
+
+#if defined(CONFIG_PAX_NOEXEC) || defined(CONFIG_PAX_ASLR)
+	unsigned long pax_flags;
+#endif
+
+#ifdef CONFIG_PAX_DLRESOLVE
+	unsigned long call_dl_resolve;
+#endif
+
+#if defined(CONFIG_PPC32) && defined(CONFIG_PAX_EMUSIGRT)
+	unsigned long call_syscall;
+#endif
+
+#ifdef CONFIG_PAX_ASLR
+	unsigned long delta_mmap;		/* randomized offset */
+	unsigned long delta_stack;		/* randomized offset */
+#endif
+
 };
 
 static inline void mm_init_cpumask(struct mm_struct *mm)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/mmu_notifier.h linux-3.2.71-pax/include/linux/mmu_notifier.h
--- linux-3.2.71/include/linux/mmu_notifier.h	2013-03-29 02:18:30.195676738 +0100
+++ linux-3.2.71-pax/include/linux/mmu_notifier.h	2013-03-29 02:19:02.127675033 +0100
@@ -256,12 +256,12 @@ static inline void mmu_notifier_mm_destr
  */
 #define ptep_clear_flush_notify(__vma, __address, __ptep)		\
 ({									\
-	pte_t __pte;							\
+	pte_t ___pte;							\
 	struct vm_area_struct *___vma = __vma;				\
 	unsigned long ___address = __address;				\
-	__pte = ptep_clear_flush(___vma, ___address, __ptep);		\
+	___pte = ptep_clear_flush(___vma, ___address, __ptep);		\
 	mmu_notifier_invalidate_page(___vma->vm_mm, ___address);	\
-	__pte;								\
+	___pte;								\
 })
 
 #define pmdp_clear_flush_notify(__vma, __address, __pmdp)		\
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/mmzone.h linux-3.2.71-pax/include/linux/mmzone.h
--- linux-3.2.71/include/linux/mmzone.h	2012-08-03 01:53:46.490140481 +0200
+++ linux-3.2.71-pax/include/linux/mmzone.h	2012-08-03 01:53:52.362140170 +0200
@@ -371,7 +371,7 @@ struct zone {
 	unsigned long		flags;		   /* zone flags, see below */
 
 	/* Zone statistics */
-	atomic_long_t		vm_stat[NR_VM_ZONE_STAT_ITEMS];
+	atomic_long_unchecked_t		vm_stat[NR_VM_ZONE_STAT_ITEMS];
 
 	/*
 	 * The target ratio of ACTIVE_ANON to INACTIVE_ANON pages on
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/mod_devicetable.h linux-3.2.71-pax/include/linux/mod_devicetable.h
--- linux-3.2.71/include/linux/mod_devicetable.h	2014-05-20 01:19:02.435997848 +0200
+++ linux-3.2.71-pax/include/linux/mod_devicetable.h	2014-07-01 14:15:15.674906545 +0200
@@ -131,7 +131,7 @@ struct usb_device_id {
 #define USB_DEVICE_ID_MATCH_INT_SUBCLASS	0x0100
 #define USB_DEVICE_ID_MATCH_INT_PROTOCOL	0x0200
 
-#define HID_ANY_ID				(~0)
+#define HID_ANY_ID				(~0U)
 
 struct hid_device_id {
 	__u16 bus;
@@ -480,7 +480,7 @@ struct dmi_system_id {
 	const char *ident;
 	struct dmi_strmatch matches[4];
 	void *driver_data;
-};
+} __do_const;
 /*
  * struct dmi_device_id appears during expansion of
  * "MODULE_DEVICE_TABLE(dmi, x)". Compiler doesn't look inside it
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/module.h linux-3.2.71-pax/include/linux/module.h
--- linux-3.2.71/include/linux/module.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/module.h	2013-03-28 01:35:23.172427955 +0100
@@ -17,9 +17,11 @@
 #include <linux/moduleparam.h>
 #include <linux/tracepoint.h>
 #include <linux/export.h>
+#include <linux/fs.h>
 
 #include <linux/percpu.h>
 #include <asm/module.h>
+#include <asm/pgtable.h>
 
 #include <trace/events/module.h>
 
@@ -53,12 +55,13 @@ struct module_attribute {
 	int (*test)(struct module *);
 	void (*free)(struct module *);
 };
+typedef struct module_attribute __no_const module_attribute_no_const;
 
 struct module_version_attribute {
 	struct module_attribute mattr;
 	const char *module_name;
 	const char *version;
-} __attribute__ ((__aligned__(sizeof(void *))));
+} __do_const __attribute__ ((__aligned__(sizeof(void *))));
 
 extern ssize_t __modver_version_show(struct module_attribute *,
 				     struct module_kobject *, char *);
@@ -217,7 +220,7 @@ struct module
 
 	/* Sysfs stuff. */
 	struct module_kobject mkobj;
-	struct module_attribute *modinfo_attrs;
+	module_attribute_no_const *modinfo_attrs;
 	const char *version;
 	const char *srcversion;
 	struct kobject *holders_dir;
@@ -261,19 +264,16 @@ struct module
 	int (*init)(void);
 
 	/* If this is non-NULL, vfree after init() returns */
-	void *module_init;
+	void *module_init_rx, *module_init_rw;
 
 	/* Here is the actual code + data, vfree'd on unload. */
-	void *module_core;
+	void *module_core_rx, *module_core_rw;
 
 	/* Here are the sizes of the init and core sections */
-	unsigned int init_size, core_size;
+	unsigned int init_size_rw, core_size_rw;
 
 	/* The size of the executable code in each section.  */
-	unsigned int init_text_size, core_text_size;
-
-	/* Size of RO sections of the module (text+rodata) */
-	unsigned int init_ro_size, core_ro_size;
+	unsigned int init_size_rx, core_size_rx;
 
 	/* Arch-specific module values */
 	struct mod_arch_specific arch;
@@ -329,6 +329,10 @@ struct module
 #ifdef CONFIG_EVENT_TRACING
 	struct ftrace_event_call **trace_events;
 	unsigned int num_trace_events;
+	struct file_operations trace_id;
+	struct file_operations trace_enable;
+	struct file_operations trace_format;
+	struct file_operations trace_filter;
 #endif
 #ifdef CONFIG_FTRACE_MCOUNT_RECORD
 	unsigned int num_ftrace_callsites;
@@ -379,16 +383,46 @@ bool is_module_address(unsigned long add
 bool is_module_percpu_address(unsigned long addr);
 bool is_module_text_address(unsigned long addr);
 
+static inline int within_module_range(unsigned long addr, void *start, unsigned long size)
+{
+
+#ifdef CONFIG_PAX_KERNEXEC
+	if (ktla_ktva(addr) >= (unsigned long)start &&
+	    ktla_ktva(addr) < (unsigned long)start + size)
+		return 1;
+#endif
+
+	return ((void *)addr >= start && (void *)addr < start + size);
+}
+
+static inline int within_module_core_rx(unsigned long addr, struct module *mod)
+{
+	return within_module_range(addr, mod->module_core_rx, mod->core_size_rx);
+}
+
+static inline int within_module_core_rw(unsigned long addr, struct module *mod)
+{
+	return within_module_range(addr, mod->module_core_rw, mod->core_size_rw);
+}
+
+static inline int within_module_init_rx(unsigned long addr, struct module *mod)
+{
+	return within_module_range(addr, mod->module_init_rx, mod->init_size_rx);
+}
+
+static inline int within_module_init_rw(unsigned long addr, struct module *mod)
+{
+	return within_module_range(addr, mod->module_init_rw, mod->init_size_rw);
+}
+
 static inline int within_module_core(unsigned long addr, struct module *mod)
 {
-	return (unsigned long)mod->module_core <= addr &&
-	       addr < (unsigned long)mod->module_core + mod->core_size;
+	return within_module_core_rx(addr, mod) || within_module_core_rw(addr, mod);
 }
 
 static inline int within_module_init(unsigned long addr, struct module *mod)
 {
-	return (unsigned long)mod->module_init <= addr &&
-	       addr < (unsigned long)mod->module_init + mod->init_size;
+	return within_module_init_rx(addr, mod) || within_module_init_rw(addr, mod);
 }
 
 /* Search for module by name: must hold module_mutex. */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/moduleloader.h linux-3.2.71-pax/include/linux/moduleloader.h
--- linux-3.2.71/include/linux/moduleloader.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/moduleloader.h	2013-03-30 21:46:26.879040647 +0100
@@ -25,9 +25,21 @@ unsigned int arch_mod_section_prepend(st
    sections.  Returns NULL on failure. */
 void *module_alloc(unsigned long size);
 
+#ifdef CONFIG_PAX_KERNEXEC
+void *module_alloc_exec(unsigned long size);
+#else
+#define module_alloc_exec(x) module_alloc(x)
+#endif
+
 /* Free memory returned from module_alloc. */
 void module_free(struct module *mod, void *module_region);
 
+#ifdef CONFIG_PAX_KERNEXEC
+void module_free_exec(struct module *mod, void *module_region);
+#else
+#define module_free_exec(x, y) module_free((x), (y))
+#endif
+
 /* Apply the given relocation to the (simplified) ELF.  Return -error
    or 0. */
 int apply_relocate(Elf_Shdr *sechdrs,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/moduleparam.h linux-3.2.71-pax/include/linux/moduleparam.h
--- linux-3.2.71/include/linux/moduleparam.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/moduleparam.h	2012-07-04 19:24:48.776063008 +0200
@@ -260,7 +260,7 @@ static inline void __kernel_param_unlock
  * @len is usually just sizeof(string).
  */
 #define module_param_string(name, string, len, perm)			\
-	static const struct kparam_string __param_string_##name		\
+	static const struct kparam_string __param_string_##name __used	\
 		= { len, string };					\
 	__module_param_call(MODULE_PARAM_PREFIX, name,			\
 			    &param_ops_string,				\
@@ -395,7 +395,7 @@ extern int param_get_invbool(char *buffe
  * module_param_named() for why this might be necessary.
  */
 #define module_param_array_named(name, array, type, nump, perm)		\
-	static const struct kparam_array __param_arr_##name		\
+	static const struct kparam_array __param_arr_##name __used	\
 	= { .max = ARRAY_SIZE(array), .num = nump,                      \
 	    .ops = &param_ops_##type,					\
 	    .elemsize = sizeof(array[0]), .elem = array };		\
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/namei.h linux-3.2.71-pax/include/linux/namei.h
--- linux-3.2.71/include/linux/namei.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/namei.h	2012-07-04 19:24:48.776063008 +0200
@@ -24,7 +24,7 @@ struct nameidata {
 	unsigned	seq;
 	int		last_type;
 	unsigned	depth;
-	char *saved_names[MAX_NESTED_LINKS + 1];
+	const char *saved_names[MAX_NESTED_LINKS + 1];
 
 	/* Intent data */
 	union {
@@ -94,12 +94,12 @@ extern int follow_up(struct path *);
 extern struct dentry *lock_rename(struct dentry *, struct dentry *);
 extern void unlock_rename(struct dentry *, struct dentry *);
 
-static inline void nd_set_link(struct nameidata *nd, char *path)
+static inline void nd_set_link(struct nameidata *nd, const char *path)
 {
 	nd->saved_names[nd->depth] = path;
 }
 
-static inline char *nd_get_link(struct nameidata *nd)
+static inline const char *nd_get_link(const struct nameidata *nd)
 {
 	return nd->saved_names[nd->depth];
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/netdevice.h linux-3.2.71-pax/include/linux/netdevice.h
--- linux-3.2.71/include/linux/netdevice.h	2014-02-16 00:01:51.744847714 +0100
+++ linux-3.2.71-pax/include/linux/netdevice.h	2014-02-16 00:01:57.728847394 +0100
@@ -949,6 +949,7 @@ struct net_device_ops {
 	int			(*ndo_set_features)(struct net_device *dev,
 						    u32 features);
 };
+typedef struct net_device_ops __no_const net_device_ops_no_const;
 
 /*
  *	The DEVICE structure.
@@ -1088,7 +1089,7 @@ struct net_device {
 	int			iflink;
 
 	struct net_device_stats	stats;
-	atomic_long_t		rx_dropped; /* dropped packets by core network
+	atomic_long_unchecked_t	rx_dropped; /* dropped packets by core network
 					     * Do not use this in drivers.
 					     */
 
@@ -2594,7 +2595,7 @@ static inline int netif_is_bond_slave(st
 	return dev->flags & IFF_SLAVE && dev->priv_flags & IFF_BONDING;
 }
 
-extern struct pernet_operations __net_initdata loopback_net_ops;
+extern struct pernet_operations __net_initconst loopback_net_ops;
 
 static inline u32 dev_ethtool_get_rx_csum(struct net_device *dev)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/netfilter/nfnetlink.h linux-3.2.71-pax/include/linux/netfilter/nfnetlink.h
--- linux-3.2.71/include/linux/netfilter/nfnetlink.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/netfilter/nfnetlink.h	2013-01-16 21:27:15.898836688 +0100
@@ -65,7 +65,7 @@ struct nfnl_callback {
 		    const struct nlattr * const cda[]);
 	const struct nla_policy *policy;	/* netlink attribute policy */
 	const u_int16_t attr_count;		/* number of nlattr's */
-};
+} __do_const;
 
 struct nfnetlink_subsystem {
 	const char *name;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/netfilter.h linux-3.2.71-pax/include/linux/netfilter.h
--- linux-3.2.71/include/linux/netfilter.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/netfilter.h	2013-03-28 01:35:23.412427942 +0100
@@ -141,7 +141,7 @@ struct nf_sockopt_ops {
 #endif
 	/* Use the module struct to lock set/get code in place */
 	struct module *owner;
-};
+} __do_const;
 
 /* Function to register/unregister hook points. */
 int nf_register_hook(struct nf_hook_ops *reg);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/net.h linux-3.2.71-pax/include/linux/net.h
--- linux-3.2.71/include/linux/net.h	2014-01-03 15:48:45.064070561 +0100
+++ linux-3.2.71-pax/include/linux/net.h	2014-01-03 15:48:49.596070319 +0100
@@ -224,7 +224,7 @@ struct net_proto_family {
 	int		(*create)(struct net *net, struct socket *sock,
 				  int protocol, int kern);
 	struct module	*owner;
-};
+} __do_const;
 
 struct iovec;
 struct kvec;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/nls.h linux-3.2.71-pax/include/linux/nls.h
--- linux-3.2.71/include/linux/nls.h	2013-03-29 02:18:38.735676282 +0100
+++ linux-3.2.71-pax/include/linux/nls.h	2013-03-29 02:20:31.363670268 +0100
@@ -31,7 +31,7 @@ struct nls_table {
 	const unsigned char *charset2upper;
 	struct module *owner;
 	struct nls_table *next;
-};
+} __do_const;
 
 /* this value hold the maximum octet of charset */
 #define NLS_MAX_CHARSET_SIZE 6 /* for UTF-8 */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/notifier.h linux-3.2.71-pax/include/linux/notifier.h
--- linux-3.2.71/include/linux/notifier.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/notifier.h	2013-01-16 21:27:15.898836688 +0100
@@ -51,7 +51,8 @@ struct notifier_block {
 	int (*notifier_call)(struct notifier_block *, unsigned long, void *);
 	struct notifier_block __rcu *next;
 	int priority;
-};
+} __do_const;
+typedef struct notifier_block __no_const notifier_block_no_const;
 
 struct atomic_notifier_head {
 	spinlock_t lock;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/oprofile.h linux-3.2.71-pax/include/linux/oprofile.h
--- linux-3.2.71/include/linux/oprofile.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/oprofile.h	2013-03-30 21:46:53.227041422 +0100
@@ -139,9 +139,9 @@ int oprofilefs_create_ulong(struct super
 int oprofilefs_create_ro_ulong(struct super_block * sb, struct dentry * root,
 	char const * name, ulong * val);
  
-/** Create a file for read-only access to an atomic_t. */
+/** Create a file for read-only access to an atomic_unchecked_t. */
 int oprofilefs_create_ro_atomic(struct super_block * sb, struct dentry * root,
-	char const * name, atomic_t * val);
+	char const * name, atomic_unchecked_t * val);
  
 /** create a directory */
 struct dentry * oprofilefs_mkdir(struct super_block * sb, struct dentry * root,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/padata.h linux-3.2.71-pax/include/linux/padata.h
--- linux-3.2.71/include/linux/padata.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/padata.h	2012-07-04 19:24:48.780063008 +0200
@@ -129,7 +129,7 @@ struct parallel_data {
 	struct padata_instance		*pinst;
 	struct padata_parallel_queue	__percpu *pqueue;
 	struct padata_serial_queue	__percpu *squeue;
-	atomic_t			seq_nr;
+	atomic_unchecked_t		seq_nr;
 	atomic_t			reorder_objects;
 	atomic_t			refcnt;
 	unsigned int			max_seq_nr;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/pci_hotplug.h linux-3.2.71-pax/include/linux/pci_hotplug.h
--- linux-3.2.71/include/linux/pci_hotplug.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/pci_hotplug.h	2013-03-28 01:35:23.428427941 +0100
@@ -80,7 +80,8 @@ struct hotplug_slot_ops {
 	int (*get_attention_status)	(struct hotplug_slot *slot, u8 *value);
 	int (*get_latch_status)		(struct hotplug_slot *slot, u8 *value);
 	int (*get_adapter_status)	(struct hotplug_slot *slot, u8 *value);
-};
+} __do_const;
+typedef struct hotplug_slot_ops __no_const hotplug_slot_ops_no_const;
 
 /**
  * struct hotplug_slot_info - used to notify the hotplug pci core of the state of the slot
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/percpu.h linux-3.2.71-pax/include/linux/percpu.h
--- linux-3.2.71/include/linux/percpu.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/percpu.h	2015-02-20 12:11:36.641261878 +0100
@@ -58,7 +58,7 @@
  * preallocate for this.  Keep PERCPU_DYNAMIC_RESERVE equal to or
  * larger than PERCPU_DYNAMIC_EARLY_SIZE.
  */
-#define PERCPU_DYNAMIC_EARLY_SLOTS	128
+#define PERCPU_DYNAMIC_EARLY_SLOTS	256
 #define PERCPU_DYNAMIC_EARLY_SIZE	(12 << 10)
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/perf_event.h linux-3.2.71-pax/include/linux/perf_event.h
--- linux-3.2.71/include/linux/perf_event.h	2013-11-29 01:58:28.794491623 +0100
+++ linux-3.2.71-pax/include/linux/perf_event.h	2013-11-29 01:58:37.710491885 +0100
@@ -750,8 +750,8 @@ struct perf_event {
 
 	enum perf_event_active_state	state;
 	unsigned int			attach_state;
-	local64_t			count;
-	atomic64_t			child_count;
+	local64_t			count; /* PaX: fix it one day */
+	atomic64_unchecked_t		child_count;
 
 	/*
 	 * These are the total time in nanoseconds that the event
@@ -802,8 +802,8 @@ struct perf_event {
 	 * These accumulate total time (in nanoseconds) that children
 	 * events have been enabled and running, respectively.
 	 */
-	atomic64_t			child_total_time_enabled;
-	atomic64_t			child_total_time_running;
+	atomic64_unchecked_t		child_total_time_enabled;
+	atomic64_unchecked_t		child_total_time_running;
 
 	/*
 	 * Protect attach/detach and child_list:
@@ -1200,7 +1200,7 @@ static inline void perf_restore_debug_st
  */
 #define perf_cpu_notifier(fn)						\
 do {									\
-	static struct notifier_block fn##_nb __cpuinitdata =		\
+	static struct notifier_block fn##_nb =				\
 		{ .notifier_call = fn, .priority = CPU_PRI_PERF };	\
 	fn(&fn##_nb, (unsigned long)CPU_UP_PREPARE,			\
 		(void *)(unsigned long)smp_processor_id());		\
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/phy.h linux-3.2.71-pax/include/linux/phy.h
--- linux-3.2.71/include/linux/phy.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/phy.h	2015-02-20 11:24:32.805412649 +0100
@@ -471,7 +471,7 @@ static inline int phy_write(struct phy_d
 	return mdiobus_write(phydev->bus, phydev->addr, regnum, val);
 }
 
-int get_phy_id(struct mii_bus *bus, int addr, u32 *phy_id);
+int get_phy_id(struct mii_bus *bus, int addr, int *phy_id);
 struct phy_device* get_phy_device(struct mii_bus *bus, int addr);
 int phy_device_register(struct phy_device *phy);
 int phy_init_hw(struct phy_device *phydev);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/pipe_fs_i.h linux-3.2.71-pax/include/linux/pipe_fs_i.h
--- linux-3.2.71/include/linux/pipe_fs_i.h	2014-04-02 03:15:45.315672355 +0200
+++ linux-3.2.71-pax/include/linux/pipe_fs_i.h	2014-04-02 03:15:49.387672138 +0200
@@ -47,9 +47,9 @@ struct pipe_buffer {
 struct pipe_inode_info {
 	wait_queue_head_t wait;
 	unsigned int nrbufs, curbuf, buffers;
-	unsigned int readers;
-	unsigned int writers;
-	unsigned int waiting_writers;
+	atomic_t readers;
+	atomic_t writers;
+	atomic_t waiting_writers;
 	unsigned int r_counter;
 	unsigned int w_counter;
 	struct page *tmp_page;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/pm_runtime.h linux-3.2.71-pax/include/linux/pm_runtime.h
--- linux-3.2.71/include/linux/pm_runtime.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/pm_runtime.h	2012-07-04 19:24:48.780063008 +0200
@@ -95,7 +95,7 @@ static inline bool pm_runtime_callbacks_
 
 static inline void pm_runtime_mark_last_busy(struct device *dev)
 {
-	ACCESS_ONCE(dev->power.last_busy) = jiffies;
+	ACCESS_ONCE_RW(dev->power.last_busy) = jiffies;
 }
 
 #else /* !CONFIG_PM_RUNTIME */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/pnp.h linux-3.2.71-pax/include/linux/pnp.h
--- linux-3.2.71/include/linux/pnp.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/pnp.h	2013-03-28 01:35:23.432427941 +0100
@@ -297,7 +297,7 @@ static inline void pnp_set_drvdata(struc
 struct pnp_fixup {
 	char id[7];
 	void (*quirk_function) (struct pnp_dev * dev);	/* fixup function */
-};
+} __do_const;
 
 /* config parameters */
 #define PNP_CONFIG_NORMAL	0x0001
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/poison.h linux-3.2.71-pax/include/linux/poison.h
--- linux-3.2.71/include/linux/poison.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/poison.h	2012-07-04 19:24:48.784063008 +0200
@@ -19,8 +19,8 @@
  * under normal circumstances, used to verify that nobody uses
  * non-initialized list entries.
  */
-#define LIST_POISON1  ((void *) 0x00100100 + POISON_POINTER_DELTA)
-#define LIST_POISON2  ((void *) 0x00200200 + POISON_POINTER_DELTA)
+#define LIST_POISON1  ((void *) (long)0xFFFFFF01)
+#define LIST_POISON2  ((void *) (long)0xFFFFFF02)
 
 /********** include/linux/timer.h **********/
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/ppp-comp.h linux-3.2.71-pax/include/linux/ppp-comp.h
--- linux-3.2.71/include/linux/ppp-comp.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/ppp-comp.h	2013-03-28 01:35:23.432427941 +0100
@@ -111,7 +111,7 @@ struct compressor {
 	struct module *owner;
 	/* Extra skb space needed by the compressor algorithm */
 	unsigned int comp_extra;
-};
+} __do_const;
 
 /*
  * The return value from decompress routine is the length of the
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/proc_fs.h linux-3.2.71-pax/include/linux/proc_fs.h
--- linux-3.2.71/include/linux/proc_fs.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/proc_fs.h	2013-03-29 02:07:09.871713062 +0100
@@ -247,7 +247,7 @@ struct proc_ns_operations {
 	void *(*get)(struct task_struct *task);
 	void (*put)(void *ns);
 	int (*install)(struct nsproxy *nsproxy, void *ns);
-};
+} __do_const;
 extern const struct proc_ns_operations netns_operations;
 extern const struct proc_ns_operations utsns_operations;
 extern const struct proc_ns_operations ipcns_operations;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/random.h linux-3.2.71-pax/include/linux/random.h
--- linux-3.2.71/include/linux/random.h	2014-01-03 15:48:45.064070561 +0100
+++ linux-3.2.71-pax/include/linux/random.h	2014-01-03 15:48:49.596070319 +0100
@@ -51,9 +51,19 @@ struct rnd_state {
 extern void rand_initialize_irq(int irq);
 
 extern void add_device_randomness(const void *, unsigned int);
+
+static inline void add_latent_entropy(void)
+{
+
+#ifdef LATENT_ENTROPY_PLUGIN
+	add_device_randomness((const void *)&latent_entropy, sizeof(latent_entropy));
+#endif
+
+}
+
 extern void add_input_randomness(unsigned int type, unsigned int code,
-				 unsigned int value);
-extern void add_interrupt_randomness(int irq, int irq_flags);
+				 unsigned int value) __latent_entropy;
+extern void add_interrupt_randomness(int irq, int irq_flags) __latent_entropy;
 
 extern void get_random_bytes(void *buf, int nbytes);
 extern void get_random_bytes_arch(void *buf, int nbytes);
@@ -67,17 +77,22 @@ extern const struct file_operations rand
 unsigned int get_random_int(void);
 unsigned long randomize_range(unsigned long start, unsigned long end, unsigned long len);
 
-u32 random32(void);
+u32 random32(void) __intentional_overflow(-1);
 void srandom32(u32 seed);
 
-u32 prandom32(struct rnd_state *);
+u32 prandom32(struct rnd_state *) __intentional_overflow(-1);
+
+static inline unsigned long __intentional_overflow(-1) pax_get_random_long(void)
+{
+	return random32() + (sizeof(long) > 4 ? (unsigned long)random32() << 32 : 0);
+}
 
 /*
  * Handle minimum values for seeds
  */
 static inline u32 __seed(u32 x, u32 m)
 {
-	return (x < m) ? x + m : x;
+	return (x <= m) ? x + m + 1 : x;
 }
 
 /**
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/rculist.h linux-3.2.71-pax/include/linux/rculist.h
--- linux-3.2.71/include/linux/rculist.h	2013-10-27 17:59:58.276642330 +0100
+++ linux-3.2.71-pax/include/linux/rculist.h	2013-10-27 18:00:09.560641728 +0100
@@ -39,6 +39,9 @@ static inline void __list_add_rcu(struct
 	next->prev = new;
 }
 
+extern void __pax_list_add_rcu(struct list_head *new,
+		struct list_head *prev, struct list_head *next);
+
 /**
  * list_add_rcu - add a new entry to rcu-protected list
  * @new: new entry to be added
@@ -60,6 +63,11 @@ static inline void list_add_rcu(struct l
 	__list_add_rcu(new, head, head->next);
 }
 
+static inline void pax_list_add_rcu(struct list_head *new, struct list_head *head)
+{
+	__pax_list_add_rcu(new, head, head->next);
+}
+
 /**
  * list_add_tail_rcu - add a new entry to rcu-protected list
  * @new: new entry to be added
@@ -82,6 +90,12 @@ static inline void list_add_tail_rcu(str
 	__list_add_rcu(new, head->prev, head);
 }
 
+static inline void pax_list_add_tail_rcu(struct list_head *new,
+					struct list_head *head)
+{
+	__pax_list_add_rcu(new, head->prev, head);
+}
+
 /**
  * list_del_rcu - deletes entry from list without re-initialization
  * @entry: the element to delete from the list.
@@ -112,6 +126,8 @@ static inline void list_del_rcu(struct l
 	entry->prev = LIST_POISON2;
 }
 
+extern void pax_list_del_rcu(struct list_head *entry);
+
 /**
  * hlist_del_init_rcu - deletes entry from hash list with re-initialization
  * @n: the element to delete from the hash list.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/reboot.h linux-3.2.71-pax/include/linux/reboot.h
--- linux-3.2.71/include/linux/reboot.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/reboot.h	2012-07-04 19:24:48.784063008 +0200
@@ -52,9 +52,9 @@ extern int unregister_reboot_notifier(st
  * Architecture-specific implementations of sys_reboot commands.
  */
 
-extern void machine_restart(char *cmd);
-extern void machine_halt(void);
-extern void machine_power_off(void);
+extern void machine_restart(char *cmd) __noreturn;
+extern void machine_halt(void) __noreturn;
+extern void machine_power_off(void) __noreturn;
 
 extern void machine_shutdown(void);
 struct pt_regs;
@@ -65,9 +65,9 @@ extern void machine_crash_shutdown(struc
  */
 
 extern void kernel_restart_prepare(char *cmd);
-extern void kernel_restart(char *cmd);
-extern void kernel_halt(void);
-extern void kernel_power_off(void);
+extern void kernel_restart(char *cmd) __noreturn;
+extern void kernel_halt(void) __noreturn;
+extern void kernel_power_off(void) __noreturn;
 
 extern int C_A_D; /* for sysctl */
 void ctrl_alt_del(void);
@@ -81,7 +81,7 @@ extern int orderly_poweroff(bool force);
  * Emergency restart, callable from an interrupt handler.
  */
 
-extern void emergency_restart(void);
+extern void emergency_restart(void) __noreturn;
 #include <asm/emergency-restart.h>
 
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/regset.h linux-3.2.71-pax/include/linux/regset.h
--- linux-3.2.71/include/linux/regset.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/regset.h	2013-02-17 16:28:47.604320184 +0100
@@ -160,7 +160,8 @@ struct user_regset {
 	unsigned int 			align;
 	unsigned int 			bias;
 	unsigned int 			core_note_type;
-};
+} __do_const;
+typedef struct user_regset __no_const user_regset_no_const;
 
 /**
  * struct user_regset_view - available regsets
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/reiserfs_fs.h linux-3.2.71-pax/include/linux/reiserfs_fs.h
--- linux-3.2.71/include/linux/reiserfs_fs.h	2014-07-12 17:42:33.944954215 +0200
+++ linux-3.2.71-pax/include/linux/reiserfs_fs.h	2014-07-12 17:42:44.764954191 +0200
@@ -1406,7 +1406,7 @@ static inline loff_t max_reiserfs_offset
 #define REISERFS_USER_MEM		1	/* reiserfs user memory mode            */
 
 #define fs_generation(s) (REISERFS_SB(s)->s_generation_counter)
-#define get_generation(s) atomic_read (&fs_generation(s))
+#define get_generation(s) atomic_read_unchecked (&fs_generation(s))
 #define FILESYSTEM_CHANGED_TB(tb)  (get_generation((tb)->tb_sb) != (tb)->fs_gen)
 #define __fs_changed(gen,s) (gen != get_generation (s))
 #define fs_changed(gen,s)		\
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/reiserfs_fs_sb.h linux-3.2.71-pax/include/linux/reiserfs_fs_sb.h
--- linux-3.2.71/include/linux/reiserfs_fs_sb.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/reiserfs_fs_sb.h	2012-07-04 19:24:48.788063008 +0200
@@ -386,7 +386,7 @@ struct reiserfs_sb_info {
 	/* Comment? -Hans */
 	wait_queue_head_t s_wait;
 	/* To be obsoleted soon by per buffer seals.. -Hans */
-	atomic_t s_generation_counter;	// increased by one every time the
+	atomic_unchecked_t s_generation_counter;	// increased by one every time the
 	// tree gets re-balanced
 	unsigned long s_properties;	/* File system properties. Currently holds
 					   on-disk FS format */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/relay.h linux-3.2.71-pax/include/linux/relay.h
--- linux-3.2.71/include/linux/relay.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/relay.h	2012-07-04 19:24:48.788063008 +0200
@@ -159,7 +159,7 @@ struct rchan_callbacks
 	 * The callback should return 0 if successful, negative if not.
 	 */
 	int (*remove_buf_file)(struct dentry *dentry);
-};
+} __no_const;
 
 /*
  * CONFIG_RELAY kernel API, kernel/relay.c
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/rio.h linux-3.2.71-pax/include/linux/rio.h
--- linux-3.2.71/include/linux/rio.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/rio.h	2012-07-04 19:24:48.788063008 +0200
@@ -315,7 +315,7 @@ struct rio_ops {
 				 int mbox, void *buffer, size_t len);
 	int (*add_inb_buffer)(struct rio_mport *mport, int mbox, void *buf);
 	void *(*get_inb_message)(struct rio_mport *mport, int mbox);
-};
+} __no_const;
 
 #define RIO_RESOURCE_MEM	0x00000100
 #define RIO_RESOURCE_DOORBELL	0x00000200
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/rmap.h linux-3.2.71-pax/include/linux/rmap.h
--- linux-3.2.71/include/linux/rmap.h	2015-02-20 12:37:33.233178768 +0100
+++ linux-3.2.71-pax/include/linux/rmap.h	2015-02-20 12:37:41.905178305 +0100
@@ -129,8 +129,8 @@ static inline void anon_vma_unlock(struc
 void anon_vma_init(void);	/* create anon_vma_cachep */
 int  anon_vma_prepare(struct vm_area_struct *);
 void unlink_anon_vmas(struct vm_area_struct *);
-int anon_vma_clone(struct vm_area_struct *, struct vm_area_struct *);
-int anon_vma_fork(struct vm_area_struct *, struct vm_area_struct *);
+int anon_vma_clone(struct vm_area_struct *, const struct vm_area_struct *);
+int anon_vma_fork(struct vm_area_struct *, const struct vm_area_struct *);
 void __anon_vma_link(struct vm_area_struct *);
 
 static inline void anon_vma_merge(struct vm_area_struct *vma,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/sched.h linux-3.2.71-pax/include/linux/sched.h
--- linux-3.2.71/include/linux/sched.h	2015-08-07 11:37:20.719789898 +0200
+++ linux-3.2.71-pax/include/linux/sched.h	2015-08-07 11:37:43.027790554 +0200
@@ -101,6 +101,7 @@ struct bio_list;
 struct fs_struct;
 struct perf_event_context;
 struct blk_plug;
+struct linux_binprm;
 
 /*
  * List of flags we want to share for kernel threads,
@@ -355,7 +356,7 @@ extern char __sched_text_start[], __sche
 extern int in_sched_functions(unsigned long addr);
 
 #define	MAX_SCHEDULE_TIMEOUT	LONG_MAX
-extern signed long schedule_timeout(signed long timeout);
+extern signed long schedule_timeout(signed long timeout) __intentional_overflow(-1);
 extern signed long schedule_timeout_interruptible(signed long timeout);
 extern signed long schedule_timeout_killable(signed long timeout);
 extern signed long schedule_timeout_uninterruptible(signed long timeout);
@@ -381,10 +382,13 @@ struct user_namespace;
 #define DEFAULT_MAX_MAP_COUNT	(USHRT_MAX - MAPCOUNT_ELF_CORE_MARGIN)
 
 extern int sysctl_max_map_count;
+extern unsigned long sysctl_heap_stack_gap;
 
 #include <linux/aio.h>
 
 #ifdef CONFIG_MMU
+extern bool check_heap_stack_gap(const struct vm_area_struct *vma, unsigned long *addr, unsigned long len);
+extern unsigned long skip_heap_stack_gap(const struct vm_area_struct *vma, unsigned long len);
 extern void arch_pick_mmap_layout(struct mm_struct *mm);
 extern unsigned long
 arch_get_unmapped_area(struct file *, unsigned long, unsigned long,
@@ -1129,7 +1133,7 @@ struct sched_class {
 #ifdef CONFIG_FAIR_GROUP_SCHED
 	void (*task_move_group) (struct task_struct *p, int on_rq);
 #endif
-};
+} __do_const;
 
 struct load_weight {
 	unsigned long weight, inv_weight;
@@ -1346,8 +1350,8 @@ struct task_struct {
 	struct list_head thread_group;
 
 	struct completion *vfork_done;		/* for vfork() */
-	int __user *set_child_tid;		/* CLONE_CHILD_SETTID */
-	int __user *clear_child_tid;		/* CLONE_CHILD_CLEARTID */
+	pid_t __user *set_child_tid;		/* CLONE_CHILD_SETTID */
+	pid_t __user *clear_child_tid;		/* CLONE_CHILD_CLEARTID */
 
 	cputime_t utime, stime, utimescaled, stimescaled;
 	cputime_t gtime;
@@ -1386,6 +1390,10 @@ struct task_struct {
 #endif
 /* CPU-specific state of this task */
 	struct thread_struct thread;
+/* thread_info moved to task_struct */
+#ifdef CONFIG_X86
+	struct thread_info tinfo;
+#endif
 /* filesystem information */
 	struct fs_struct *fs;
 /* open file information */
@@ -1560,7 +1568,7 @@ struct task_struct {
 	 * Number of functions that haven't been traced
 	 * because of depth overrun.
 	 */
-	atomic_t trace_overrun;
+	atomic_unchecked_t trace_overrun;
 	/* Pause for the tracing */
 	atomic_t tracing_graph_pause;
 #endif
@@ -1583,6 +1591,53 @@ struct task_struct {
 #endif
 };
 
+#define MF_PAX_PAGEEXEC		0x01000000	/* Paging based non-executable pages */
+#define MF_PAX_EMUTRAMP		0x02000000	/* Emulate trampolines */
+#define MF_PAX_MPROTECT		0x04000000	/* Restrict mprotect() */
+#define MF_PAX_RANDMMAP		0x08000000	/* Randomize mmap() base */
+/*#define MF_PAX_RANDEXEC		0x10000000*/	/* Randomize ET_EXEC base */
+#define MF_PAX_SEGMEXEC		0x20000000	/* Segmentation based non-executable pages */
+
+#ifdef CONFIG_PAX_SOFTMODE
+extern int pax_softmode;
+#endif
+
+extern int pax_check_flags(unsigned long *);
+#define PAX_PARSE_FLAGS_FALLBACK	(~0UL)
+
+/* if tsk != current then task_lock must be held on it */
+#if defined(CONFIG_PAX_NOEXEC) || defined(CONFIG_PAX_ASLR)
+static inline unsigned long pax_get_flags(struct task_struct *tsk)
+{
+	if (likely(tsk->mm))
+		return tsk->mm->pax_flags;
+	else
+		return 0UL;
+}
+
+/* if tsk != current then task_lock must be held on it */
+static inline long pax_set_flags(struct task_struct *tsk, unsigned long flags)
+{
+	if (likely(tsk->mm)) {
+		tsk->mm->pax_flags = flags;
+		return 0;
+	}
+	return -EINVAL;
+}
+#endif
+
+#ifdef CONFIG_PAX_HAVE_ACL_FLAGS
+extern void pax_set_initial_flags(struct linux_binprm *bprm);
+#elif defined(CONFIG_PAX_HOOK_ACL_FLAGS)
+extern void (*pax_set_initial_flags_func)(struct linux_binprm *bprm);
+#endif
+
+struct path;
+extern char *pax_get_path(const struct path *path, char *buf, int buflen);
+extern void pax_report_fault(struct pt_regs *regs, void *pc, void *sp);
+extern void pax_report_insns(struct pt_regs *regs, void *pc, void *sp);
+extern void pax_report_refcount_overflow(struct pt_regs *regs);
+
 /* Future-safe accessor for struct task_struct's cpus_allowed. */
 #define tsk_cpus_allowed(tsk) (&(tsk)->cpus_allowed)
 
@@ -2116,7 +2171,9 @@ void yield(void);
 extern struct exec_domain	default_exec_domain;
 
 union thread_union {
+#ifndef CONFIG_X86
 	struct thread_info thread_info;
+#endif
 	unsigned long stack[THREAD_SIZE/sizeof(long)];
 };
 
@@ -2286,7 +2343,7 @@ extern void __cleanup_sighand(struct sig
 extern void exit_itimers(struct signal_struct *);
 extern void flush_itimer_signals(void);
 
-extern NORET_TYPE void do_group_exit(int);
+extern __noreturn void do_group_exit(int);
 
 extern void daemonize(const char *, ...);
 extern int allow_signal(int);
@@ -2451,9 +2508,9 @@ static inline unsigned long *end_of_stac
 
 #endif
 
-static inline int object_is_on_stack(void *obj)
+static inline int object_starts_on_stack(void *obj)
 {
-	void *stack = task_stack_page(current);
+	const void *stack = task_stack_page(current);
 
 	return (obj >= stack) && (obj < (stack + THREAD_SIZE));
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/screen_info.h linux-3.2.71-pax/include/linux/screen_info.h
--- linux-3.2.71/include/linux/screen_info.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/screen_info.h	2012-07-04 19:24:48.792063008 +0200
@@ -43,7 +43,8 @@ struct screen_info {
 	__u16 pages;		/* 0x32 */
 	__u16 vesa_attributes;	/* 0x34 */
 	__u32 capabilities;     /* 0x36 */
-	__u8  _reserved[6];	/* 0x3a */
+	__u16 vesapm_size;	/* 0x3a */
+	__u8  _reserved[4];	/* 0x3c */
 } __attribute__((packed));
 
 #define VIDEO_TYPE_MDA		0x10	/* Monochrome Text Display	*/
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/security.h linux-3.2.71-pax/include/linux/security.h
--- linux-3.2.71/include/linux/security.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/security.h	2013-09-17 02:14:23.201656431 +0200
@@ -98,8 +98,6 @@ struct seq_file;
 extern int cap_netlink_send(struct sock *sk, struct sk_buff *skb);
 extern int cap_netlink_recv(struct sk_buff *skb, int cap);
 
-void reset_security_ops(void);
-
 #ifdef CONFIG_MMU
 extern unsigned long mmap_min_addr;
 extern unsigned long dac_mmap_min_addr;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/semaphore.h linux-3.2.71-pax/include/linux/semaphore.h
--- linux-3.2.71/include/linux/semaphore.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/semaphore.h	2013-11-23 18:07:03.769937077 +0100
@@ -37,7 +37,7 @@ static inline void sema_init(struct sema
 }
 
 extern void down(struct semaphore *sem);
-extern int __must_check down_interruptible(struct semaphore *sem);
+extern int __must_check down_interruptible(struct semaphore *sem) __intentional_overflow(-1);
 extern int __must_check down_killable(struct semaphore *sem);
 extern int __must_check down_trylock(struct semaphore *sem);
 extern int __must_check down_timeout(struct semaphore *sem, long jiffies);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/seq_file.h linux-3.2.71-pax/include/linux/seq_file.h
--- linux-3.2.71/include/linux/seq_file.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/seq_file.h	2012-07-04 19:24:48.792063008 +0200
@@ -33,6 +33,7 @@ struct seq_operations {
 	void * (*next) (struct seq_file *m, void *v, loff_t *pos);
 	int (*show) (struct seq_file *m, void *v);
 };
+typedef struct seq_operations __no_const seq_operations_no_const;
 
 #define SEQ_SKIP 1
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/skbuff.h linux-3.2.71-pax/include/linux/skbuff.h
--- linux-3.2.71/include/linux/skbuff.h	2014-08-06 23:17:21.869614202 +0200
+++ linux-3.2.71-pax/include/linux/skbuff.h	2014-08-06 23:17:26.565614191 +0200
@@ -538,7 +538,7 @@ extern void consume_skb(struct sk_buff *
 extern void	       __kfree_skb(struct sk_buff *skb);
 extern struct sk_buff *__alloc_skb(unsigned int size,
 				   gfp_t priority, int fclone, int node);
-static inline struct sk_buff *alloc_skb(unsigned int size,
+static inline struct sk_buff * __intentional_overflow(0) alloc_skb(unsigned int size,
 					gfp_t priority)
 {
 	return __alloc_skb(size, priority, 0, NUMA_NO_NODE);
@@ -650,7 +650,7 @@ static inline struct skb_shared_hwtstamp
  */
 static inline int skb_queue_empty(const struct sk_buff_head *list)
 {
-	return list->next == (struct sk_buff *)list;
+	return list->next == (const struct sk_buff *)list;
 }
 
 /**
@@ -663,7 +663,7 @@ static inline int skb_queue_empty(const
 static inline bool skb_queue_is_last(const struct sk_buff_head *list,
 				     const struct sk_buff *skb)
 {
-	return skb->next == (struct sk_buff *)list;
+	return skb->next == (const struct sk_buff *)list;
 }
 
 /**
@@ -676,7 +676,7 @@ static inline bool skb_queue_is_last(con
 static inline bool skb_queue_is_first(const struct sk_buff_head *list,
 				      const struct sk_buff *skb)
 {
-	return skb->prev == (struct sk_buff *)list;
+	return skb->prev == (const struct sk_buff *)list;
 }
 
 /**
@@ -1516,7 +1516,7 @@ static inline u32 skb_network_header_len
 	return skb->transport_header - skb->network_header;
 }
 
-static inline int skb_network_offset(const struct sk_buff *skb)
+static inline int __intentional_overflow(0) skb_network_offset(const struct sk_buff *skb)
 {
 	return skb_network_header(skb) - skb->data;
 }
@@ -1571,7 +1571,7 @@ static inline int pskb_network_may_pull(
  * NET_IP_ALIGN(2) + ethernet_header(14) + IP_header(20/40) + ports(8)
  */
 #ifndef NET_SKB_PAD
-#define NET_SKB_PAD	max(32, L1_CACHE_BYTES)
+#define NET_SKB_PAD	max(_AC(32,UL), L1_CACHE_BYTES)
 #endif
 
 extern int ___pskb_trim(struct sk_buff *skb, unsigned int len);
@@ -2126,7 +2126,7 @@ extern struct sk_buff *skb_recv_datagram
 					 int noblock, int *err);
 extern unsigned int    datagram_poll(struct file *file, struct socket *sock,
 				     struct poll_table_struct *wait);
-extern int	       skb_copy_datagram_iovec(const struct sk_buff *from,
+extern int	       __intentional_overflow(0) skb_copy_datagram_iovec(const struct sk_buff *from,
 					       int offset, struct iovec *to,
 					       int size);
 extern int	       skb_copy_and_csum_datagram_iovec(struct sk_buff *skb,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/slab_def.h linux-3.2.71-pax/include/linux/slab_def.h
--- linux-3.2.71/include/linux/slab_def.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/slab_def.h	2013-11-23 18:07:03.801937078 +0100
@@ -68,10 +68,14 @@ struct kmem_cache {
 	unsigned long node_allocs;
 	unsigned long node_frees;
 	unsigned long node_overflow;
-	atomic_t allochit;
-	atomic_t allocmiss;
-	atomic_t freehit;
-	atomic_t freemiss;
+	atomic_unchecked_t allochit;
+	atomic_unchecked_t allocmiss;
+	atomic_unchecked_t freehit;
+	atomic_unchecked_t freemiss;
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+	atomic_unchecked_t sanitized;
+	atomic_unchecked_t not_sanitized;
+#endif
 
 	/*
 	 * If debugging is enabled, then the allocator can add additional
@@ -105,6 +109,11 @@ struct cache_sizes {
 #ifdef CONFIG_ZONE_DMA
 	struct kmem_cache	*cs_dmacachep;
 #endif
+
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+	struct kmem_cache	*cs_usercopycachep;
+#endif
+
 };
 extern struct cache_sizes malloc_sizes[];
 
@@ -152,6 +161,13 @@ found:
 			cachep = malloc_sizes[i].cs_dmacachep;
 		else
 #endif
+
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+		if (flags & GFP_USERCOPY)
+			cachep = malloc_sizes[i].cs_usercopycachep;
+		else
+#endif
+
 			cachep = malloc_sizes[i].cs_cachep;
 
 		ret = kmem_cache_alloc_trace(size, cachep, flags);
@@ -181,6 +197,7 @@ kmem_cache_alloc_node_trace(size_t size,
 }
 #endif
 
+static __always_inline void *kmalloc_node(size_t size, gfp_t flags, int node) __size_overflow(1);
 static __always_inline void *kmalloc_node(size_t size, gfp_t flags, int node)
 {
 	struct kmem_cache *cachep;
@@ -205,6 +222,13 @@ found:
 			cachep = malloc_sizes[i].cs_dmacachep;
 		else
 #endif
+
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+		if (flags & GFP_USERCOPY)
+			cachep = malloc_sizes[i].cs_usercopycachep;
+		else
+#endif
+
 			cachep = malloc_sizes[i].cs_cachep;
 
 		return kmem_cache_alloc_node_trace(size, cachep, flags, node);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/slab.h linux-3.2.71-pax/include/linux/slab.h
--- linux-3.2.71/include/linux/slab.h	2014-08-06 23:17:21.881614202 +0200
+++ linux-3.2.71-pax/include/linux/slab.h	2014-11-01 00:30:57.915964359 +0100
@@ -11,14 +11,29 @@
 
 #include <linux/gfp.h>
 #include <linux/types.h>
+#include <linux/err.h>
 
 /*
  * Flags to pass to kmem_cache_create().
  * The ones marked DEBUG are only valid if CONFIG_SLAB_DEBUG is set.
  */
 #define SLAB_DEBUG_FREE		0x00000100UL	/* DEBUG: Perform (expensive) checks on free */
+
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+#define SLAB_USERCOPY		0x00000200UL	/* PaX: Allow copying objs to/from userland */
+#else
+#define SLAB_USERCOPY		0x00000000UL
+#endif
+
 #define SLAB_RED_ZONE		0x00000400UL	/* DEBUG: Red zone objs in a cache */
 #define SLAB_POISON		0x00000800UL	/* DEBUG: Poison objects */
+
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+#define SLAB_NO_SANITIZE	0x00001000UL	/* PaX: Do not sanitize objs on free */
+#else
+#define SLAB_NO_SANITIZE	0x00000000UL
+#endif
+
 #define SLAB_HWCACHE_ALIGN	0x00002000UL	/* Align objs on cache lines */
 #define SLAB_CACHE_DMA		0x00004000UL	/* Use GFP_DMA memory */
 #define SLAB_STORE_USER		0x00010000UL	/* DEBUG: Store the last owner for bug hunting */
@@ -87,10 +102,27 @@
  * ZERO_SIZE_PTR can be passed to kfree though in the same way that NULL can.
  * Both make kfree a no-op.
  */
-#define ZERO_SIZE_PTR ((void *)16)
-
-#define ZERO_OR_NULL_PTR(x) ((unsigned long)(x) <= \
-				(unsigned long)ZERO_SIZE_PTR)
+#define ZERO_SIZE_PTR				\
+({						\
+	BUILD_BUG_ON(!(MAX_ERRNO & ~PAGE_MASK));\
+	(void *)(-MAX_ERRNO-1L);		\
+})
+
+#define ZERO_OR_NULL_PTR(x) ((unsigned long)(x) - 1 >= (unsigned long)ZERO_SIZE_PTR - 1)
+
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+#ifdef CONFIG_X86_64
+#define PAX_MEMORY_SANITIZE_VALUE	'\xfe'
+#else
+#define PAX_MEMORY_SANITIZE_VALUE	'\xff'
+#endif
+enum pax_sanitize_mode {
+	PAX_SANITIZE_SLAB_OFF = 0,
+	PAX_SANITIZE_SLAB_FAST,
+	PAX_SANITIZE_SLAB_FULL,
+};
+extern enum pax_sanitize_mode pax_sanitize_slab;
+#endif
 
 /*
  * struct kmem_cache related prototypes
@@ -161,6 +193,8 @@ void * __must_check krealloc(const void
 void kfree(const void *);
 void kzfree(const void *);
 size_t ksize(const void *);
+const char *check_heap_object(const void *ptr, unsigned long n);
+bool is_usercopy_object(const void *ptr);
 
 /*
  * Allocator specific definitions. These are mainly used to establish optimized
@@ -240,8 +274,18 @@ size_t ksize(const void *);
  * for general use, and so are not documented here. For a full list of
  * potential flags, always refer to linux/gfp.h.
  */
+
+extern void kmalloc_array_error(void)
+#if defined(CONFIG_GCOV_KERNEL) && defined(CONFIG_PAX_SIZE_OVERFLOW)
+__compiletime_warning("kmalloc_array called with swapped arguments?");
+#else
+__compiletime_error("kmalloc_array called with swapped arguments?");
+#endif
+
 static inline void *kmalloc_array(size_t n, size_t size, gfp_t flags)
 {
+	if (__builtin_constant_p(n) && !__builtin_constant_p(size))
+		kmalloc_array_error();
 	if (size != 0 && n > SIZE_MAX / size)
 		return NULL;
 	return __kmalloc(n * size, flags);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/slub_def.h linux-3.2.71-pax/include/linux/slub_def.h
--- linux-3.2.71/include/linux/slub_def.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/slub_def.h	2013-11-23 18:07:03.809937078 +0100
@@ -89,7 +89,7 @@ struct kmem_cache {
 	struct kmem_cache_order_objects max;
 	struct kmem_cache_order_objects min;
 	gfp_t allocflags;	/* gfp flags to use on each alloc */
-	int refcount;		/* Refcount for slab cache destroy */
+	atomic_t refcount;	/* Refcount for slab cache destroy */
 	void (*ctor)(void *);
 	int inuse;		/* Offset to metadata */
 	int align;		/* Alignment */
@@ -150,7 +150,7 @@ extern struct kmem_cache *kmalloc_caches
  * Sorry that the following has to be that ugly but some versions of GCC
  * have trouble with constant propagation and loops.
  */
-static __always_inline int kmalloc_index(size_t size)
+static __always_inline __size_overflow(1) int kmalloc_index(size_t size)
 {
 	if (!size)
 		return 0;
@@ -215,9 +215,9 @@ static __always_inline struct kmem_cache
 }
 
 void *kmem_cache_alloc(struct kmem_cache *, gfp_t);
-void *__kmalloc(size_t size, gfp_t flags);
+void *__kmalloc(size_t size, gfp_t flags) __alloc_size(1);
 
-static __always_inline void *
+static __always_inline __size_overflow(1) void *
 kmalloc_order(size_t size, gfp_t flags, unsigned int order)
 {
 	void *ret = (void *) __get_free_pages(flags | __GFP_COMP, order);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/sonet.h linux-3.2.71-pax/include/linux/sonet.h
--- linux-3.2.71/include/linux/sonet.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/sonet.h	2012-07-04 19:24:48.796063008 +0200
@@ -61,7 +61,7 @@ struct sonet_stats {
 #include <linux/atomic.h>
 
 struct k_sonet_stats {
-#define __HANDLE_ITEM(i) atomic_t i
+#define __HANDLE_ITEM(i) atomic_unchecked_t i
 	__SONET_ITEMS
 #undef __HANDLE_ITEM
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/sunrpc/clnt.h linux-3.2.71-pax/include/linux/sunrpc/clnt.h
--- linux-3.2.71/include/linux/sunrpc/clnt.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/sunrpc/clnt.h	2013-03-28 01:40:11.708412549 +0100
@@ -98,7 +98,7 @@ struct rpc_procinfo {
 	unsigned int		p_timer;	/* Which RTT timer to use */
 	u32			p_statidx;	/* Which procedure to account */
 	char *			p_name;		/* name of procedure */
-};
+} __do_const;
 
 #ifdef __KERNEL__
 
@@ -172,9 +172,9 @@ static inline unsigned short rpc_get_por
 {
 	switch (sap->sa_family) {
 	case AF_INET:
-		return ntohs(((struct sockaddr_in *)sap)->sin_port);
+		return ntohs(((const struct sockaddr_in *)sap)->sin_port);
 	case AF_INET6:
-		return ntohs(((struct sockaddr_in6 *)sap)->sin6_port);
+		return ntohs(((const struct sockaddr_in6 *)sap)->sin6_port);
 	}
 	return 0;
 }
@@ -207,7 +207,7 @@ static inline bool __rpc_cmp_addr4(const
 static inline bool __rpc_copy_addr4(struct sockaddr *dst,
 				    const struct sockaddr *src)
 {
-	const struct sockaddr_in *ssin = (struct sockaddr_in *) src;
+	const struct sockaddr_in *ssin = (const struct sockaddr_in *) src;
 	struct sockaddr_in *dsin = (struct sockaddr_in *) dst;
 
 	dsin->sin_family = ssin->sin_family;
@@ -310,7 +310,7 @@ static inline u32 rpc_get_scope_id(const
 	if (sa->sa_family != AF_INET6)
 		return 0;
 
-	return ((struct sockaddr_in6 *) sa)->sin6_scope_id;
+	return ((const struct sockaddr_in6 *) sa)->sin6_scope_id;
 }
 
 #endif /* __KERNEL__ */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/sunrpc/svcauth.h linux-3.2.71-pax/include/linux/sunrpc/svcauth.h
--- linux-3.2.71/include/linux/sunrpc/svcauth.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/sunrpc/svcauth.h	2013-03-28 01:35:23.448427940 +0100
@@ -100,7 +100,7 @@ struct auth_ops {
 	int	(*release)(struct svc_rqst *rq);
 	void	(*domain_release)(struct auth_domain *);
 	int	(*set_client)(struct svc_rqst *rq);
-};
+} __do_const;
 
 #define	SVC_GARBAGE	1
 #define	SVC_SYSERR	2
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/sunrpc/svc.h linux-3.2.71-pax/include/linux/sunrpc/svc.h
--- linux-3.2.71/include/linux/sunrpc/svc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/sunrpc/svc.h	2013-03-28 01:35:23.448427940 +0100
@@ -408,7 +408,7 @@ struct svc_procedure {
 	unsigned int		pc_count;	/* call count */
 	unsigned int		pc_cachetype;	/* cache info (NFS) */
 	unsigned int		pc_xdrressize;	/* maximum size of XDR reply */
-};
+} __do_const;
 
 /*
  * Function prototypes.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/sunrpc/svc_rdma.h linux-3.2.71-pax/include/linux/sunrpc/svc_rdma.h
--- linux-3.2.71/include/linux/sunrpc/svc_rdma.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/sunrpc/svc_rdma.h	2012-07-04 19:24:48.796063008 +0200
@@ -53,15 +53,15 @@ extern unsigned int svcrdma_ord;
 extern unsigned int svcrdma_max_requests;
 extern unsigned int svcrdma_max_req_size;
 
-extern atomic_t rdma_stat_recv;
-extern atomic_t rdma_stat_read;
-extern atomic_t rdma_stat_write;
-extern atomic_t rdma_stat_sq_starve;
-extern atomic_t rdma_stat_rq_starve;
-extern atomic_t rdma_stat_rq_poll;
-extern atomic_t rdma_stat_rq_prod;
-extern atomic_t rdma_stat_sq_poll;
-extern atomic_t rdma_stat_sq_prod;
+extern atomic_unchecked_t rdma_stat_recv;
+extern atomic_unchecked_t rdma_stat_read;
+extern atomic_unchecked_t rdma_stat_write;
+extern atomic_unchecked_t rdma_stat_sq_starve;
+extern atomic_unchecked_t rdma_stat_rq_starve;
+extern atomic_unchecked_t rdma_stat_rq_poll;
+extern atomic_unchecked_t rdma_stat_rq_prod;
+extern atomic_unchecked_t rdma_stat_sq_poll;
+extern atomic_unchecked_t rdma_stat_sq_prod;
 
 #define RPCRDMA_VERSION 1
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/swab.h linux-3.2.71-pax/include/linux/swab.h
--- linux-3.2.71/include/linux/swab.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/swab.h	2013-03-27 22:42:20.880982289 +0100
@@ -43,7 +43,7 @@
  * ___swab16, ___swab32, ___swab64, ___swahw32, ___swahb32
  */
 
-static inline __attribute_const__ __u16 __fswab16(__u16 val)
+static inline __intentional_overflow(-1) __attribute_const__ __u16 __fswab16(__u16 val)
 {
 #ifdef __arch_swab16
 	return __arch_swab16(val);
@@ -52,7 +52,7 @@ static inline __attribute_const__ __u16
 #endif
 }
 
-static inline __attribute_const__ __u32 __fswab32(__u32 val)
+static inline __intentional_overflow(-1) __attribute_const__ __u32 __fswab32(__u32 val)
 {
 #ifdef __arch_swab32
 	return __arch_swab32(val);
@@ -61,7 +61,7 @@ static inline __attribute_const__ __u32
 #endif
 }
 
-static inline __attribute_const__ __u64 __fswab64(__u64 val)
+static inline __intentional_overflow(-1) __attribute_const__ __u64 __fswab64(__u64 val)
 {
 #ifdef __arch_swab64
 	return __arch_swab64(val);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/syscalls.h linux-3.2.71-pax/include/linux/syscalls.h
--- linux-3.2.71/include/linux/syscalls.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/syscalls.h	2015-05-05 17:40:55.649928512 +0200
@@ -83,12 +83,19 @@ struct file_handle;
 #define __SC_DECL5(t5, a5, ...) t5 a5, __SC_DECL4(__VA_ARGS__)
 #define __SC_DECL6(t6, a6, ...) t6 a6, __SC_DECL5(__VA_ARGS__)
 
-#define __SC_LONG1(t1, a1) 	long a1
-#define __SC_LONG2(t2, a2, ...) long a2, __SC_LONG1(__VA_ARGS__)
-#define __SC_LONG3(t3, a3, ...) long a3, __SC_LONG2(__VA_ARGS__)
-#define __SC_LONG4(t4, a4, ...) long a4, __SC_LONG3(__VA_ARGS__)
-#define __SC_LONG5(t5, a5, ...) long a5, __SC_LONG4(__VA_ARGS__)
-#define __SC_LONG6(t6, a6, ...) long a6, __SC_LONG5(__VA_ARGS__)
+#define __SC_TYPE(t, a) __typeof(				\
+	__builtin_choose_expr(					\
+		sizeof(t) > sizeof(int),			\
+		(t) 0,						\
+		__builtin_choose_expr(__type_is_unsigned(t), 0UL, 0L)	\
+	)) a
+
+#define __SC_LONG1(t1, a1) 	__SC_TYPE(t1, a1)
+#define __SC_LONG2(t2, a2, ...) __SC_TYPE(t2, a2), __SC_LONG1(__VA_ARGS__)
+#define __SC_LONG3(t3, a3, ...) __SC_TYPE(t3, a3), __SC_LONG2(__VA_ARGS__)
+#define __SC_LONG4(t4, a4, ...) __SC_TYPE(t4, a4), __SC_LONG3(__VA_ARGS__)
+#define __SC_LONG5(t5, a5, ...) __SC_TYPE(t5, a5), __SC_LONG4(__VA_ARGS__)
+#define __SC_LONG6(t6, a6, ...) __SC_TYPE(t6, a6), __SC_LONG5(__VA_ARGS__)
 
 #define __SC_CAST1(t1, a1)	(t1) a1
 #define __SC_CAST2(t2, a2, ...) (t2) a2, __SC_CAST1(__VA_ARGS__)
@@ -392,11 +399,11 @@ asmlinkage long sys_sync(void);
 asmlinkage long sys_fsync(unsigned int fd);
 asmlinkage long sys_fdatasync(unsigned int fd);
 asmlinkage long sys_bdflush(int func, long data);
-asmlinkage long sys_mount(char __user *dev_name, char __user *dir_name,
-				char __user *type, unsigned long flags,
+asmlinkage long sys_mount(const char __user *dev_name, const char __user *dir_name,
+				const char __user *type, unsigned long flags,
 				void __user *data);
-asmlinkage long sys_umount(char __user *name, int flags);
-asmlinkage long sys_oldumount(char __user *name);
+asmlinkage long sys_umount(const char __user *name, int flags);
+asmlinkage long sys_oldumount(const char __user *name);
 asmlinkage long sys_truncate(const char __user *path, long length);
 asmlinkage long sys_ftruncate(unsigned int fd, unsigned long length);
 asmlinkage long sys_stat(const char __user *filename,
@@ -608,7 +615,7 @@ asmlinkage long sys_getsockname(int, str
 asmlinkage long sys_getpeername(int, struct sockaddr __user *, int __user *);
 asmlinkage long sys_send(int, void __user *, size_t, unsigned);
 asmlinkage long sys_sendto(int, void __user *, size_t, unsigned,
-				struct sockaddr __user *, int);
+				struct sockaddr __user *, int) __intentional_overflow(0);
 asmlinkage long sys_sendmsg(int fd, struct msghdr __user *msg, unsigned flags);
 asmlinkage long sys_sendmmsg(int fd, struct mmsghdr __user *msg,
 			     unsigned int vlen, unsigned flags);
@@ -667,10 +674,10 @@ asmlinkage long sys_msgctl(int msqid, in
 
 asmlinkage long sys_semget(key_t key, int nsems, int semflg);
 asmlinkage long sys_semop(int semid, struct sembuf __user *sops,
-				unsigned nsops);
+				long nsops);
 asmlinkage long sys_semctl(int semid, int semnum, int cmd, union semun arg);
 asmlinkage long sys_semtimedop(int semid, struct sembuf __user *sops,
-				unsigned nsops,
+				long nsops,
 				const struct timespec __user *timeout);
 asmlinkage long sys_shmat(int shmid, char __user *shmaddr, int shmflg);
 asmlinkage long sys_shmget(key_t key, size_t size, int flag);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/syscore_ops.h linux-3.2.71-pax/include/linux/syscore_ops.h
--- linux-3.2.71/include/linux/syscore_ops.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/syscore_ops.h	2013-03-28 01:35:23.460427940 +0100
@@ -16,7 +16,7 @@ struct syscore_ops {
 	int (*suspend)(void);
 	void (*resume)(void);
 	void (*shutdown)(void);
-};
+} __do_const;
 
 extern void register_syscore_ops(struct syscore_ops *ops);
 extern void unregister_syscore_ops(struct syscore_ops *ops);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/sysctl.h linux-3.2.71-pax/include/linux/sysctl.h
--- linux-3.2.71/include/linux/sysctl.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/sysctl.h	2014-01-18 15:12:38.856822067 +0100
@@ -155,8 +155,6 @@ enum
 	KERN_PANIC_ON_NMI=76, /* int: whether we will panic on an unrecovered */
 };
 
-
-
 /* CTL_VM names: */
 enum
 {
@@ -961,8 +959,6 @@ extern void sysctl_head_finish(struct ct
 extern int sysctl_perm(struct ctl_table_root *root,
 		struct ctl_table *table, int op);
 
-typedef struct ctl_table ctl_table;
-
 typedef int proc_handler (struct ctl_table *ctl, int write,
 			  void __user *buffer, size_t *lenp, loff_t *ppos);
 
@@ -1045,7 +1041,9 @@ struct ctl_table
 	struct ctl_table_poll *poll;
 	void *extra1;
 	void *extra2;
-};
+} __do_const;
+typedef struct ctl_table __no_const ctl_table_no_const;
+typedef struct ctl_table ctl_table;
 
 struct ctl_table_root {
 	struct list_head root_list;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/sysdev.h linux-3.2.71-pax/include/linux/sysdev.h
--- linux-3.2.71/include/linux/sysdev.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/sysdev.h	2013-03-28 03:53:41.203984904 +0100
@@ -98,7 +98,7 @@ struct sysdev_attribute {
 	ssize_t (*store)(struct sys_device *, struct sysdev_attribute *,
 			 const char *, size_t);
 };
-
+typedef struct sysdev_attribute __no_const sysdev_attribute_no_const;
 
 #define _SYSDEV_ATTR(_name, _mode, _show, _store)		\
 {								\
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/sysfs.h linux-3.2.71-pax/include/linux/sysfs.h
--- linux-3.2.71/include/linux/sysfs.h	2015-02-20 12:37:33.233178768 +0100
+++ linux-3.2.71-pax/include/linux/sysfs.h	2015-02-20 12:37:41.905178305 +0100
@@ -30,7 +30,8 @@ struct attribute {
 	struct lock_class_key	*key;
 	struct lock_class_key	skey;
 #endif
-};
+} __do_const;
+typedef struct attribute __no_const attribute_no_const;
 
 /**
  *	sysfs_attr_init - initialize a dynamically allocated sysfs attribute
@@ -58,8 +59,8 @@ struct attribute_group {
 	mode_t			(*is_visible)(struct kobject *,
 					      struct attribute *, int);
 	struct attribute	**attrs;
-};
-
+} __do_const;
+typedef struct attribute_group __no_const attribute_group_no_const;
 
 
 /**
@@ -104,7 +105,8 @@ struct bin_attribute {
 			 char *, loff_t, size_t);
 	int (*mmap)(struct file *, struct kobject *, struct bin_attribute *attr,
 		    struct vm_area_struct *vma);
-};
+} __do_const;
+typedef struct bin_attribute __no_const bin_attribute_no_const;
 
 /**
  *	sysfs_bin_attr_init - initialize a dynamically allocated bin_attribute
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/sysrq.h linux-3.2.71-pax/include/linux/sysrq.h
--- linux-3.2.71/include/linux/sysrq.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/sysrq.h	2013-03-28 01:35:23.192427954 +0100
@@ -16,6 +16,7 @@
 
 #include <linux/errno.h>
 #include <linux/types.h>
+#include <linux/compiler.h>
 
 /* Enable/disable SYSRQ support by default (0==no, 1==yes). */
 #define SYSRQ_DEFAULT_ENABLE	1
@@ -36,7 +37,7 @@ struct sysrq_key_op {
 	char *help_msg;
 	char *action_msg;
 	int enable_mask;
-};
+} __do_const;
 
 #ifdef CONFIG_MAGIC_SYSRQ
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/thread_info.h linux-3.2.71-pax/include/linux/thread_info.h
--- linux-3.2.71/include/linux/thread_info.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/thread_info.h	2013-02-09 00:48:56.544740411 +0100
@@ -123,6 +123,13 @@ static inline void set_restore_sigmask(v
 }
 #endif	/* TIF_RESTORE_SIGMASK && !HAVE_SET_RESTORE_SIGMASK */
 
+extern void __check_object_size(const void *ptr, unsigned long n, bool to);
+static inline void check_object_size(const void *ptr, unsigned long n, bool to)
+{
+	if (!__builtin_constant_p(n))
+		__check_object_size(ptr, n, to);
+}
+
 #endif	/* __KERNEL__ */
 
 #endif /* _LINUX_THREAD_INFO_H */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/tty_driver.h linux-3.2.71-pax/include/linux/tty_driver.h
--- linux-3.2.71/include/linux/tty_driver.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/tty_driver.h	2013-01-16 21:29:53.738833041 +0100
@@ -286,7 +286,7 @@ struct tty_operations {
 	void (*poll_put_char)(struct tty_driver *driver, int line, char ch);
 #endif
 	const struct file_operations *proc_fops;
-};
+} __do_const;
 
 struct tty_driver {
 	int	magic;		/* magic number for this structure */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/tty_ldisc.h linux-3.2.71-pax/include/linux/tty_ldisc.h
--- linux-3.2.71/include/linux/tty_ldisc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/tty_ldisc.h	2012-07-04 19:24:48.800063008 +0200
@@ -148,7 +148,7 @@ struct tty_ldisc_ops {
 
 	struct  module *owner;
 	
-	int refcount;
+	atomic_t refcount;
 };
 
 struct tty_ldisc {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/types.h linux-3.2.71-pax/include/linux/types.h
--- linux-3.2.71/include/linux/types.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/types.h	2012-07-04 19:24:48.800063008 +0200
@@ -213,10 +213,26 @@ typedef struct {
 	int counter;
 } atomic_t;
 
+#ifdef CONFIG_PAX_REFCOUNT
+typedef struct {
+	int counter;
+} atomic_unchecked_t;
+#else
+typedef atomic_t atomic_unchecked_t;
+#endif
+
 #ifdef CONFIG_64BIT
 typedef struct {
 	long counter;
 } atomic64_t;
+
+#ifdef CONFIG_PAX_REFCOUNT
+typedef struct {
+	long counter;
+} atomic64_unchecked_t;
+#else
+typedef atomic64_t atomic64_unchecked_t;
+#endif
 #endif
 
 struct list_head {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/uaccess.h linux-3.2.71-pax/include/linux/uaccess.h
--- linux-3.2.71/include/linux/uaccess.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/uaccess.h	2013-11-23 18:07:03.837937079 +0100
@@ -76,11 +76,11 @@ static inline unsigned long __copy_from_
 		long ret;				\
 		mm_segment_t old_fs = get_fs();		\
 							\
-		set_fs(KERNEL_DS);			\
 		pagefault_disable();			\
-		ret = __copy_from_user_inatomic(&(retval), (__force typeof(retval) __user *)(addr), sizeof(retval));		\
-		pagefault_enable();			\
+		set_fs(KERNEL_DS);			\
+		ret = __copy_from_user_inatomic(&(retval), (typeof(retval) __force_user *)(addr), sizeof(retval));		\
 		set_fs(old_fs);				\
+		pagefault_enable();			\
 		ret;					\
 	})
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/unaligned/access_ok.h linux-3.2.71-pax/include/linux/unaligned/access_ok.h
--- linux-3.2.71/include/linux/unaligned/access_ok.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/unaligned/access_ok.h	2013-03-28 04:15:36.223914692 +0100
@@ -4,34 +4,34 @@
 #include <linux/kernel.h>
 #include <asm/byteorder.h>
 
-static inline u16 get_unaligned_le16(const void *p)
+static inline u16 __intentional_overflow(-1) get_unaligned_le16(const void *p)
 {
-	return le16_to_cpup((__le16 *)p);
+	return le16_to_cpup((const __le16 *)p);
 }
 
-static inline u32 get_unaligned_le32(const void *p)
+static inline u32 __intentional_overflow(-1) get_unaligned_le32(const void *p)
 {
-	return le32_to_cpup((__le32 *)p);
+	return le32_to_cpup((const __le32 *)p);
 }
 
-static inline u64 get_unaligned_le64(const void *p)
+static inline u64 __intentional_overflow(-1) get_unaligned_le64(const void *p)
 {
-	return le64_to_cpup((__le64 *)p);
+	return le64_to_cpup((const __le64 *)p);
 }
 
-static inline u16 get_unaligned_be16(const void *p)
+static inline u16 __intentional_overflow(-1) get_unaligned_be16(const void *p)
 {
-	return be16_to_cpup((__be16 *)p);
+	return be16_to_cpup((const __be16 *)p);
 }
 
-static inline u32 get_unaligned_be32(const void *p)
+static inline u32 __intentional_overflow(-1) get_unaligned_be32(const void *p)
 {
-	return be32_to_cpup((__be32 *)p);
+	return be32_to_cpup((const __be32 *)p);
 }
 
-static inline u64 get_unaligned_be64(const void *p)
+static inline u64 __intentional_overflow(-1) get_unaligned_be64(const void *p)
 {
-	return be64_to_cpup((__be64 *)p);
+	return be64_to_cpup((const __be64 *)p);
 }
 
 static inline void put_unaligned_le16(u16 val, void *p)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/usb/renesas_usbhs.h linux-3.2.71-pax/include/linux/usb/renesas_usbhs.h
--- linux-3.2.71/include/linux/usb/renesas_usbhs.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/usb/renesas_usbhs.h	2013-01-16 21:26:55.326837164 +0100
@@ -39,7 +39,7 @@ enum {
  */
 struct renesas_usbhs_driver_callback {
 	int (*notify_hotplug)(struct platform_device *pdev);
-};
+} __no_const;
 
 /*
  * callback functions for platform
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/usb.h linux-3.2.71-pax/include/linux/usb.h
--- linux-3.2.71/include/linux/usb.h	2012-09-12 12:17:18.703311267 +0200
+++ linux-3.2.71-pax/include/linux/usb.h	2013-03-28 04:10:58.219929536 +0100
@@ -497,7 +497,7 @@ struct usb_device {
 	struct usb_device *children[USB_MAXCHILDREN];
 
 	u32 quirks;
-	atomic_t urbnum;
+	atomic_unchecked_t urbnum;
 
 	unsigned long active_duration;
 
@@ -1442,7 +1442,7 @@ void usb_buffer_unmap_sg(const struct us
 
 extern int usb_control_msg(struct usb_device *dev, unsigned int pipe,
 	__u8 request, __u8 requesttype, __u16 value, __u16 index,
-	void *data, __u16 size, int timeout);
+	void *data, __u16 size, int timeout) __intentional_overflow(-1);
 extern int usb_interrupt_msg(struct usb_device *usb_dev, unsigned int pipe,
 	void *data, int len, int *actual_length, int timeout);
 extern int usb_bulk_msg(struct usb_device *usb_dev, unsigned int pipe,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/vermagic.h linux-3.2.71-pax/include/linux/vermagic.h
--- linux-3.2.71/include/linux/vermagic.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/vermagic.h	2012-07-04 19:24:48.800063008 +0200
@@ -25,9 +25,28 @@
 #define MODULE_ARCH_VERMAGIC ""
 #endif
 
+#ifdef CONFIG_PAX_REFCOUNT
+#define MODULE_PAX_REFCOUNT "REFCOUNT "
+#else
+#define MODULE_PAX_REFCOUNT ""
+#endif
+
+#ifdef CONSTIFY_PLUGIN
+#define MODULE_CONSTIFY_PLUGIN "CONSTIFY_PLUGIN "
+#else
+#define MODULE_CONSTIFY_PLUGIN ""
+#endif
+
+#ifdef STACKLEAK_PLUGIN
+#define MODULE_STACKLEAK_PLUGIN "STACKLEAK_PLUGIN "
+#else
+#define MODULE_STACKLEAK_PLUGIN ""
+#endif
+
 #define VERMAGIC_STRING 						\
 	UTS_RELEASE " "							\
 	MODULE_VERMAGIC_SMP MODULE_VERMAGIC_PREEMPT 			\
 	MODULE_VERMAGIC_MODULE_UNLOAD MODULE_VERMAGIC_MODVERSIONS	\
-	MODULE_ARCH_VERMAGIC
+	MODULE_ARCH_VERMAGIC						\
+	MODULE_PAX_REFCOUNT MODULE_CONSTIFY_PLUGIN MODULE_STACKLEAK_PLUGIN
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/videodev2.h linux-3.2.71-pax/include/linux/videodev2.h
--- linux-3.2.71/include/linux/videodev2.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/videodev2.h	2014-01-28 04:21:56.485073843 +0100
@@ -1062,7 +1062,7 @@ struct v4l2_ext_control {
 	union {
 		__s32 value;
 		__s64 value64;
-		char *string;
+		char __user *string;
 	};
 } __attribute__ ((packed));
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/vmalloc.h linux-3.2.71-pax/include/linux/vmalloc.h
--- linux-3.2.71/include/linux/vmalloc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/vmalloc.h	2013-11-23 18:07:03.841937079 +0100
@@ -14,6 +14,11 @@ struct vm_area_struct;		/* vma defining
 #define VM_USERMAP	0x00000008	/* suitable for remap_vmalloc_range */
 #define VM_VPAGES	0x00000010	/* buffer for pages was vmalloc'ed */
 #define VM_UNLIST	0x00000020	/* vm_struct is not listed in vmlist */
+
+#if defined(CONFIG_X86) && defined(CONFIG_PAX_KERNEXEC)
+#define VM_KERNEXEC	0x00000040	/* allocate from executable kernel memory range */
+#endif
+
 /* bits [20..32] reserved for arch specific ioremap internals */
 
 /*
@@ -124,7 +129,7 @@ extern void free_vm_area(struct vm_struc
 
 /* for /dev/kmem */
 extern long vread(char *buf, char *addr, unsigned long count);
-extern long vwrite(char *buf, char *addr, unsigned long count);
+extern long vwrite(char *buf, char *addr, unsigned long count) __size_overflow(3);
 
 /*
  *	Internals.  Dont't use..
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/vmstat.h linux-3.2.71-pax/include/linux/vmstat.h
--- linux-3.2.71/include/linux/vmstat.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/vmstat.h	2013-12-03 02:19:10.982699988 +0100
@@ -87,18 +87,18 @@ static inline void vm_events_fold_cpu(in
 /*
  * Zone based page accounting with per cpu differentials.
  */
-extern atomic_long_t vm_stat[NR_VM_ZONE_STAT_ITEMS];
+extern atomic_long_unchecked_t vm_stat[NR_VM_ZONE_STAT_ITEMS];
 
 static inline void zone_page_state_add(long x, struct zone *zone,
 				 enum zone_stat_item item)
 {
-	atomic_long_add(x, &zone->vm_stat[item]);
-	atomic_long_add(x, &vm_stat[item]);
+	atomic_long_add_unchecked(x, &zone->vm_stat[item]);
+	atomic_long_add_unchecked(x, &vm_stat[item]);
 }
 
-static inline unsigned long global_page_state(enum zone_stat_item item)
+static inline unsigned long __intentional_overflow(-1) global_page_state(enum zone_stat_item item)
 {
-	long x = atomic_long_read(&vm_stat[item]);
+	long x = atomic_long_read_unchecked(&vm_stat[item]);
 #ifdef CONFIG_SMP
 	if (x < 0)
 		x = 0;
@@ -106,10 +106,10 @@ static inline unsigned long global_page_
 	return x;
 }
 
-static inline unsigned long zone_page_state(struct zone *zone,
+static inline unsigned long __intentional_overflow(-1) zone_page_state(struct zone *zone,
 					enum zone_stat_item item)
 {
-	long x = atomic_long_read(&zone->vm_stat[item]);
+	long x = atomic_long_read_unchecked(&zone->vm_stat[item]);
 #ifdef CONFIG_SMP
 	if (x < 0)
 		x = 0;
@@ -126,7 +126,7 @@ static inline unsigned long zone_page_st
 static inline unsigned long zone_page_state_snapshot(struct zone *zone,
 					enum zone_stat_item item)
 {
-	long x = atomic_long_read(&zone->vm_stat[item]);
+	long x = atomic_long_read_unchecked(&zone->vm_stat[item]);
 
 #ifdef CONFIG_SMP
 	int cpu;
@@ -221,8 +221,8 @@ static inline void __mod_zone_page_state
 
 static inline void __inc_zone_state(struct zone *zone, enum zone_stat_item item)
 {
-	atomic_long_inc(&zone->vm_stat[item]);
-	atomic_long_inc(&vm_stat[item]);
+	atomic_long_inc_unchecked(&zone->vm_stat[item]);
+	atomic_long_inc_unchecked(&vm_stat[item]);
 }
 
 static inline void __inc_zone_page_state(struct page *page,
@@ -233,8 +233,8 @@ static inline void __inc_zone_page_state
 
 static inline void __dec_zone_state(struct zone *zone, enum zone_stat_item item)
 {
-	atomic_long_dec(&zone->vm_stat[item]);
-	atomic_long_dec(&vm_stat[item]);
+	atomic_long_dec_unchecked(&zone->vm_stat[item]);
+	atomic_long_dec_unchecked(&vm_stat[item]);
 }
 
 static inline void __dec_zone_page_state(struct page *page,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/xattr.h linux-3.2.71-pax/include/linux/xattr.h
--- linux-3.2.71/include/linux/xattr.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/xattr.h	2013-05-13 13:19:36.639753774 +0200
@@ -57,6 +57,11 @@
 #define XATTR_POSIX_ACL_DEFAULT  "posix_acl_default"
 #define XATTR_NAME_POSIX_ACL_DEFAULT XATTR_SYSTEM_PREFIX XATTR_POSIX_ACL_DEFAULT
 
+/* User namespace */
+#define XATTR_PAX_PREFIX XATTR_USER_PREFIX "pax."
+#define XATTR_PAX_FLAGS_SUFFIX "flags"
+#define XATTR_NAME_PAX_FLAGS XATTR_PAX_PREFIX XATTR_PAX_FLAGS_SUFFIX
+
 #ifdef  __KERNEL__
 
 #include <linux/types.h>
@@ -73,7 +78,7 @@ struct xattr_handler {
 		   size_t size, int handler_flags);
 	int (*set)(struct dentry *dentry, const char *name, const void *buffer,
 		   size_t size, int flags, int handler_flags);
-};
+} __do_const;
 
 struct xattr {
 	char *name;
@@ -82,6 +87,9 @@ struct xattr {
 };
 
 ssize_t xattr_getsecurity(struct inode *, const char *, void *, size_t);
+#ifdef CONFIG_PAX_XATTR_PAX_FLAGS
+ssize_t pax_getxattr(struct dentry *, void *, size_t);
+#endif
 ssize_t vfs_getxattr(struct dentry *, const char *, void *, size_t);
 ssize_t vfs_listxattr(struct dentry *d, char *list, size_t size);
 int __vfs_setxattr_noperm(struct dentry *, const char *, const void *, size_t, int);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/linux/zlib.h linux-3.2.71-pax/include/linux/zlib.h
--- linux-3.2.71/include/linux/zlib.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/linux/zlib.h	2013-03-28 04:10:58.231929535 +0100
@@ -31,6 +31,7 @@
 #define _ZLIB_H
 
 #include <linux/zconf.h>
+#include <linux/compiler.h>
 
 /* zlib deflate based on ZLIB_VERSION "1.1.3" */
 /* zlib inflate based on ZLIB_VERSION "1.2.3" */
@@ -179,7 +180,7 @@ typedef z_stream *z_streamp;
 
                         /* basic functions */
 
-extern int zlib_deflate_workspacesize (int windowBits, int memLevel);
+extern int zlib_deflate_workspacesize (int windowBits, int memLevel) __intentional_overflow(0);
 /*
    Returns the number of bytes that needs to be allocated for a per-
    stream workspace with the specified parameters.  A pointer to this
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/media/v4l2-dev.h linux-3.2.71-pax/include/media/v4l2-dev.h
--- linux-3.2.71/include/media/v4l2-dev.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/media/v4l2-dev.h	2013-01-16 21:38:11.938821528 +0100
@@ -56,7 +56,7 @@ int v4l2_prio_check(struct v4l2_prio_sta
 
 
 struct v4l2_file_operations {
-	struct module *owner;
+	struct module * const owner;
 	ssize_t (*read) (struct file *, char __user *, size_t, loff_t *);
 	ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *);
 	unsigned int (*poll) (struct file *, struct poll_table_struct *);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/media/v4l2-device.h linux-3.2.71-pax/include/media/v4l2-device.h
--- linux-3.2.71/include/media/v4l2-device.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/media/v4l2-device.h	2013-09-01 20:05:21.255827369 +0200
@@ -95,7 +95,7 @@ int __must_check v4l2_device_register(st
    this function returns 0. If the name ends with a digit (e.g. cx18),
    then the name will be set to cx18-0 since cx180 looks really odd. */
 int v4l2_device_set_name(struct v4l2_device *v4l2_dev, const char *basename,
-						atomic_t *instance);
+						atomic_unchecked_t *instance);
 
 /* Set v4l2_dev->dev to NULL. Call when the USB parent disconnects.
    Since the parent disappears this ensures that v4l2_dev doesn't have an
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/media/v4l2-ioctl.h linux-3.2.71-pax/include/media/v4l2-ioctl.h
--- linux-3.2.71/include/media/v4l2-ioctl.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/media/v4l2-ioctl.h	2013-01-16 21:26:55.330837164 +0100
@@ -275,7 +275,6 @@ struct v4l2_ioctl_ops {
 					bool valid_prio, int cmd, void *arg);
 };
 
-
 /* v4l debugging and diagnostics */
 
 /* Debug bitmask flags to be used on V4L2 */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/9p/transport.h linux-3.2.71-pax/include/net/9p/transport.h
--- linux-3.2.71/include/net/9p/transport.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/9p/transport.h	2013-03-28 01:35:23.484427938 +0100
@@ -57,7 +57,7 @@ struct p9_trans_module {
 	int (*cancel) (struct p9_client *, struct p9_req_t *req);
 	int (*zc_request)(struct p9_client *, struct p9_req_t *,
 			  char *, char *, int , int, int, int);
-};
+} __do_const;
 
 void v9fs_register_trans(struct p9_trans_module *m);
 void v9fs_unregister_trans(struct p9_trans_module *m);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/bluetooth/l2cap.h linux-3.2.71-pax/include/net/bluetooth/l2cap.h
--- linux-3.2.71/include/net/bluetooth/l2cap.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/bluetooth/l2cap.h	2013-03-28 01:37:23.200421546 +0100
@@ -387,7 +387,7 @@ struct l2cap_ops {
 	int			(*recv) (void *data, struct sk_buff *skb);
 	void			(*close) (void *data);
 	void			(*state_change) (void *data, int state);
-};
+} __do_const;
 
 struct l2cap_conn {
 	struct hci_conn	*hcon;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/caif/cfctrl.h linux-3.2.71-pax/include/net/caif/cfctrl.h
--- linux-3.2.71/include/net/caif/cfctrl.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/caif/cfctrl.h	2012-07-04 19:24:48.804063008 +0200
@@ -52,7 +52,7 @@ struct cfctrl_rsp {
 	void (*radioset_rsp)(void);
 	void (*reject_rsp)(struct cflayer *layer, u8 linkid,
 				struct cflayer *client_layer);
-};
+} __no_const;
 
 /* Link Setup Parameters for CAIF-Links. */
 struct cfctrl_link_param {
@@ -101,8 +101,8 @@ struct cfctrl_request_info {
 struct cfctrl {
 	struct cfsrvl serv;
 	struct cfctrl_rsp res;
-	atomic_t req_seq_no;
-	atomic_t rsp_seq_no;
+	atomic_unchecked_t req_seq_no;
+	atomic_unchecked_t rsp_seq_no;
 	struct list_head list;
 	/* Protects from simultaneous access to first_req list */
 	spinlock_t info_list_lock;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/flow.h linux-3.2.71-pax/include/net/flow.h
--- linux-3.2.71/include/net/flow.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/flow.h	2012-07-04 19:24:48.804063008 +0200
@@ -218,6 +218,6 @@ extern struct flow_cache_object *flow_ca
 
 extern void flow_cache_flush(void);
 extern void flow_cache_flush_deferred(void);
-extern atomic_t flow_cache_genid;
+extern atomic_unchecked_t flow_cache_genid;
 
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/genetlink.h linux-3.2.71-pax/include/net/genetlink.h
--- linux-3.2.71/include/net/genetlink.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/genetlink.h	2013-03-28 01:35:23.488427938 +0100
@@ -116,7 +116,7 @@ struct genl_ops {
 					 struct netlink_callback *cb);
 	int		       (*done)(struct netlink_callback *cb);
 	struct list_head	ops_list;
-};
+} __do_const;
 
 extern int genl_register_family(struct genl_family *family);
 extern int genl_register_family_with_ops(struct genl_family *family,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/inet_connection_sock.h linux-3.2.71-pax/include/net/inet_connection_sock.h
--- linux-3.2.71/include/net/inet_connection_sock.h	2013-01-16 18:47:48.655057775 +0100
+++ linux-3.2.71-pax/include/net/inet_connection_sock.h	2013-01-16 22:04:58.398784405 +0100
@@ -61,7 +61,7 @@ struct inet_connection_sock_af_ops {
 	void	    (*addr2sockaddr)(struct sock *sk, struct sockaddr *);
 	int	    (*bind_conflict)(const struct sock *sk,
 				     const struct inet_bind_bucket *tb);
-};
+} __do_const;
 
 /** inet_connection_sock - INET connection oriented sock
  *
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/inetpeer.h linux-3.2.71-pax/include/net/inetpeer.h
--- linux-3.2.71/include/net/inetpeer.h	2014-09-14 14:10:59.982118683 +0200
+++ linux-3.2.71-pax/include/net/inetpeer.h	2014-09-14 14:27:28.073853420 +0200
@@ -52,7 +52,7 @@ struct inet_peer {
 	 */
 	union {
 		struct {
-			atomic_t			rid;		/* Frag reception counter */
+			atomic_unchecked_t		rid;		/* Frag reception counter */
 			__u32				tcp_ts;
 			__u32				tcp_ts_stamp;
 		};
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/ip_fib.h linux-3.2.71-pax/include/net/ip_fib.h
--- linux-3.2.71/include/net/ip_fib.h	2015-02-20 12:37:33.233178768 +0100
+++ linux-3.2.71-pax/include/net/ip_fib.h	2015-02-20 12:37:41.909178304 +0100
@@ -144,7 +144,7 @@ extern __be32 fib_info_update_nh_saddr(s
 
 #define FIB_RES_SADDR(net, res)				\
 	((FIB_RES_NH(res).nh_saddr_genid ==		\
-	  atomic_read(&(net)->ipv4.dev_addr_genid)) ?	\
+	  atomic_read_unchecked(&(net)->ipv4.dev_addr_genid)) ?	\
 	 FIB_RES_NH(res).nh_saddr :			\
 	 fib_info_update_nh_saddr((net), &FIB_RES_NH(res)))
 #define FIB_RES_GW(res)			(FIB_RES_NH(res).nh_gw)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/ip.h linux-3.2.71-pax/include/net/ip.h
--- linux-3.2.71/include/net/ip.h	2014-09-14 14:10:59.990118689 +0200
+++ linux-3.2.71-pax/include/net/ip.h	2014-09-14 14:11:26.118138473 +0200
@@ -214,7 +214,7 @@ extern struct local_ports {
 } sysctl_local_ports;
 extern void inet_get_local_port_range(int *low, int *high);
 
-extern unsigned long *sysctl_local_reserved_ports;
+extern unsigned long sysctl_local_reserved_ports[65536 / 8 / sizeof(unsigned long)];
 static inline int inet_is_reserved_local_port(int port)
 {
 	return test_bit(port, sysctl_local_reserved_ports);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/ip_vs.h linux-3.2.71-pax/include/net/ip_vs.h
--- linux-3.2.71/include/net/ip_vs.h	2015-08-07 11:37:20.719789898 +0200
+++ linux-3.2.71-pax/include/net/ip_vs.h	2015-08-07 11:37:43.027790554 +0200
@@ -509,7 +509,7 @@ struct ip_vs_conn {
 	struct ip_vs_conn       *control;       /* Master control connection */
 	atomic_t                n_control;      /* Number of controlled ones */
 	struct ip_vs_dest       *dest;          /* real server */
-	atomic_t                in_pkts;        /* incoming packet counter */
+	atomic_unchecked_t      in_pkts;        /* incoming packet counter */
 
 	/* packet transmitter for different forwarding methods.  If it
 	   mangles the packet, it must return NF_DROP or better NF_STOLEN,
@@ -647,7 +647,7 @@ struct ip_vs_dest {
 	__be16			port;		/* port number of the server */
 	union nf_inet_addr	addr;		/* IP address of the server */
 	volatile unsigned	flags;		/* dest status flags */
-	atomic_t		conn_flags;	/* flags to copy to conn */
+	atomic_unchecked_t	conn_flags;	/* flags to copy to conn */
 	atomic_t		weight;		/* server weight */
 
 	atomic_t		refcnt;		/* reference counter */
@@ -878,11 +878,11 @@ struct netns_ipvs {
 	/* ip_vs_lblc */
 	int			sysctl_lblc_expiration;
 	struct ctl_table_header	*lblc_ctl_header;
-	struct ctl_table	*lblc_ctl_table;
+	ctl_table_no_const	*lblc_ctl_table;
 	/* ip_vs_lblcr */
 	int			sysctl_lblcr_expiration;
 	struct ctl_table_header	*lblcr_ctl_header;
-	struct ctl_table	*lblcr_ctl_table;
+	ctl_table_no_const	*lblcr_ctl_table;
 	/* ip_vs_est */
 	struct list_head	est_list;	/* estimator list */
 	spinlock_t		est_lock;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/irda/ircomm_tty.h linux-3.2.71-pax/include/net/irda/ircomm_tty.h
--- linux-3.2.71/include/net/irda/ircomm_tty.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/irda/ircomm_tty.h	2012-07-04 19:24:48.808063008 +0200
@@ -35,6 +35,7 @@
 #include <linux/termios.h>
 #include <linux/timer.h>
 #include <linux/tty.h>		/* struct tty_struct */
+#include <asm/local.h>
 
 #include <net/irda/irias_object.h>
 #include <net/irda/ircomm_core.h>
@@ -105,8 +106,8 @@ struct ircomm_tty_cb {
         unsigned short    close_delay;
         unsigned short    closing_wait; /* time to wait before closing */
 
-	int  open_count;
-	int  blocked_open;	/* # of blocked opens */
+	local_t open_count;
+	local_t blocked_open;	/* # of blocked opens */
 
 	/* Protect concurent access to :
 	 *	o self->open_count
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/iucv/af_iucv.h linux-3.2.71-pax/include/net/iucv/af_iucv.h
--- linux-3.2.71/include/net/iucv/af_iucv.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/iucv/af_iucv.h	2012-07-04 19:24:48.808063008 +0200
@@ -139,7 +139,7 @@ struct iucv_sock {
 struct iucv_sock_list {
 	struct hlist_head head;
 	rwlock_t	  lock;
-	atomic_t	  autobind_name;
+	atomic_unchecked_t autobind_name;
 };
 
 unsigned int iucv_sock_poll(struct file *file, struct socket *sock,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/llc_c_ac.h linux-3.2.71-pax/include/net/llc_c_ac.h
--- linux-3.2.71/include/net/llc_c_ac.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/llc_c_ac.h	2013-03-28 01:35:23.488427938 +0100
@@ -87,7 +87,7 @@
 #define LLC_CONN_AC_STOP_SENDACK_TMR			70
 #define LLC_CONN_AC_START_SENDACK_TMR_IF_NOT_RUNNING	71
 
-typedef int (*llc_conn_action_t)(struct sock *sk, struct sk_buff *skb);
+typedef int (* const llc_conn_action_t)(struct sock *sk, struct sk_buff *skb);
 
 extern int llc_conn_ac_clear_remote_busy(struct sock *sk, struct sk_buff *skb);
 extern int llc_conn_ac_conn_ind(struct sock *sk, struct sk_buff *skb);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/llc_c_ev.h linux-3.2.71-pax/include/net/llc_c_ev.h
--- linux-3.2.71/include/net/llc_c_ev.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/llc_c_ev.h	2013-03-28 01:35:23.488427938 +0100
@@ -125,8 +125,8 @@ static __inline__ struct llc_conn_state_
 	return (struct llc_conn_state_ev *)skb->cb;
 }
 
-typedef int (*llc_conn_ev_t)(struct sock *sk, struct sk_buff *skb);
-typedef int (*llc_conn_ev_qfyr_t)(struct sock *sk, struct sk_buff *skb);
+typedef int (* const llc_conn_ev_t)(struct sock *sk, struct sk_buff *skb);
+typedef int (* const llc_conn_ev_qfyr_t)(struct sock *sk, struct sk_buff *skb);
 
 extern int llc_conn_ev_conn_req(struct sock *sk, struct sk_buff *skb);
 extern int llc_conn_ev_data_req(struct sock *sk, struct sk_buff *skb);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/llc_c_st.h linux-3.2.71-pax/include/net/llc_c_st.h
--- linux-3.2.71/include/net/llc_c_st.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/llc_c_st.h	2013-03-28 01:35:23.492427938 +0100
@@ -37,7 +37,7 @@ struct llc_conn_state_trans {
 	u8		   next_state;
 	llc_conn_ev_qfyr_t *ev_qualifiers;
 	llc_conn_action_t  *ev_actions;
-};
+} __do_const;
 
 struct llc_conn_state {
 	u8			    current_state;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/llc_s_ac.h linux-3.2.71-pax/include/net/llc_s_ac.h
--- linux-3.2.71/include/net/llc_s_ac.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/llc_s_ac.h	2013-03-28 01:35:23.492427938 +0100
@@ -23,7 +23,7 @@
 #define SAP_ACT_TEST_IND	9
 
 /* All action functions must look like this */
-typedef int (*llc_sap_action_t)(struct llc_sap *sap, struct sk_buff *skb);
+typedef int (* const llc_sap_action_t)(struct llc_sap *sap, struct sk_buff *skb);
 
 extern int llc_sap_action_unitdata_ind(struct llc_sap *sap,
 				       struct sk_buff *skb);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/llc_s_st.h linux-3.2.71-pax/include/net/llc_s_st.h
--- linux-3.2.71/include/net/llc_s_st.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/llc_s_st.h	2013-03-28 01:35:23.492427938 +0100
@@ -20,7 +20,7 @@ struct llc_sap_state_trans {
 	llc_sap_ev_t	  ev;
 	u8		  next_state;
 	llc_sap_action_t *ev_actions;
-};
+} __do_const;
 
 struct llc_sap_state {
 	u8			   curr_state;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/mac80211.h linux-3.2.71-pax/include/net/mac80211.h
--- linux-3.2.71/include/net/mac80211.h	2013-01-16 18:47:48.659057775 +0100
+++ linux-3.2.71-pax/include/net/mac80211.h	2013-03-28 01:35:23.492427938 +0100
@@ -3529,7 +3529,7 @@ struct rate_control_ops {
 	void (*add_sta_debugfs)(void *priv, void *priv_sta,
 				struct dentry *dir);
 	void (*remove_sta_debugfs)(void *priv, void *priv_sta);
-};
+} __do_const;
 
 static inline int rate_supported(struct ieee80211_sta *sta,
 				 enum ieee80211_band band,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/neighbour.h linux-3.2.71-pax/include/net/neighbour.h
--- linux-3.2.71/include/net/neighbour.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/neighbour.h	2012-07-04 19:24:48.808063008 +0200
@@ -122,7 +122,7 @@ struct neigh_ops {
 	void			(*error_report)(struct neighbour *, struct sk_buff *);
 	int			(*output)(struct neighbour *, struct sk_buff *);
 	int			(*connected_output)(struct neighbour *, struct sk_buff *);
-};
+} __do_const;
 
 struct pneigh_entry {
 	struct pneigh_entry	*next;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/netdma.h linux-3.2.71-pax/include/net/netdma.h
--- linux-3.2.71/include/net/netdma.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/netdma.h	2012-09-11 20:29:10.808017741 +0200
@@ -24,7 +24,7 @@
 #include <linux/dmaengine.h>
 #include <linux/skbuff.h>
 
-int dma_skb_copy_datagram_iovec(struct dma_chan* chan,
+int __intentional_overflow(3,5) dma_skb_copy_datagram_iovec(struct dma_chan* chan,
 		struct sk_buff *skb, int offset, struct iovec *to,
 		size_t len, struct dma_pinned_list *pinned_list);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/netfilter/nf_queue.h linux-3.2.71-pax/include/net/netfilter/nf_queue.h
--- linux-3.2.71/include/net/netfilter/nf_queue.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/netfilter/nf_queue.h	2013-01-16 21:29:53.746833041 +0100
@@ -22,7 +22,7 @@ struct nf_queue_handler {
 	int			(*outfn)(struct nf_queue_entry *entry,
 					 unsigned int queuenum);
 	char			*name;
-};
+} __do_const;
 
 extern int nf_register_queue_handler(u_int8_t pf,
 				     const struct nf_queue_handler *qh);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/netlink.h linux-3.2.71-pax/include/net/netlink.h
--- linux-3.2.71/include/net/netlink.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/netlink.h	2015-04-30 03:19:27.756553251 +0200
@@ -135,6 +135,7 @@
  *   nla_get_u16(nla)			get payload for a u16 attribute
  *   nla_get_u32(nla)			get payload for a u32 attribute
  *   nla_get_u64(nla)			get payload for a u64 attribute
+ *   nla_get_s32(nla)			get payload for a s32 attribute
  *   nla_get_flag(nla)			return 1 if flag is true
  *   nla_get_msecs(nla)			get payload for a msecs attribute
  *
@@ -569,7 +570,7 @@ static inline void *nlmsg_get_pos(struct
 static inline void nlmsg_trim(struct sk_buff *skb, const void *mark)
 {
 	if (mark)
-		skb_trim(skb, (unsigned char *) mark - skb->data);
+		skb_trim(skb, (const unsigned char *) mark - skb->data);
 }
 
 /**
@@ -998,6 +999,15 @@ static inline __be64 nla_get_be64(const
 }
 
 /**
+ * nla_get_s32 - return payload of s32 attribute
+ * @nla: s32 netlink attribute
+ */
+static inline s32 nla_get_s32(const struct nlattr *nla)
+{
+	return *(s32 *) nla_data(nla);
+}
+
+/**
  * nla_get_flag - return payload of flag attribute
  * @nla: flag netlink attribute
  */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/net_namespace.h linux-3.2.71-pax/include/net/net_namespace.h
--- linux-3.2.71/include/net/net_namespace.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/net_namespace.h	2013-04-03 01:34:26.676749506 +0200
@@ -240,10 +240,16 @@ static inline struct net *read_pnet(stru
 #define __net_init
 #define __net_exit
 #define __net_initdata
+#define __net_initconst
 #else
 #define __net_init	__init
 #define __net_exit	__exit_refok
 #define __net_initdata	__initdata
+#ifdef CONSTIFY_PLUGIN
+#define __net_initconst	__initconst
+#else
+#define __net_initconst	__initdata
+#endif
 #endif
 
 struct pernet_operations {
@@ -253,7 +259,7 @@ struct pernet_operations {
 	void (*exit_batch)(struct list_head *net_exit_list);
 	int *id;
 	size_t size;
-};
+} __do_const;
 
 /*
  * Use these carefully.  If you implement a network device and it
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/netns/ipv4.h linux-3.2.71-pax/include/net/netns/ipv4.h
--- linux-3.2.71/include/net/netns/ipv4.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/netns/ipv4.h	2012-07-04 19:24:48.812063008 +0200
@@ -56,8 +56,8 @@ struct netns_ipv4 {
 
 	unsigned int sysctl_ping_group_range[2];
 
-	atomic_t rt_genid;
-	atomic_t dev_addr_genid;
+	atomic_unchecked_t rt_genid;
+	atomic_unchecked_t dev_addr_genid;
 
 #ifdef CONFIG_IP_MROUTE
 #ifndef CONFIG_IP_MROUTE_MULTIPLE_TABLES
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/protocol.h linux-3.2.71-pax/include/net/protocol.h
--- linux-3.2.71/include/net/protocol.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/net/protocol.h	2013-01-16 22:05:19.590783915 +0100
@@ -44,7 +44,7 @@ struct net_protocol {
 	int			(*gro_complete)(struct sk_buff *skb);
 	unsigned int		no_policy:1,
 				netns_ok:1;
-};
+} __do_const;
 
 #if defined(CONFIG_IPV6) || defined (CONFIG_IPV6_MODULE)
 struct inet6_protocol {
@@ -63,7 +63,7 @@ struct inet6_protocol {
 	int	(*gro_complete)(struct sk_buff *skb);
 
 	unsigned int	flags;	/* INET6_PROTO_xxx */
-};
+} __do_const;
 
 #define INET6_PROTO_NOPOLICY	0x1
 #define INET6_PROTO_FINAL	0x2
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/rtnetlink.h linux-3.2.71-pax/include/net/rtnetlink.h
--- linux-3.2.71/include/net/rtnetlink.h	2012-11-18 02:43:53.049509622 +0100
+++ linux-3.2.71-pax/include/net/rtnetlink.h	2013-03-28 01:37:46.204420318 +0100
@@ -78,7 +78,7 @@ struct rtnl_link_ops {
 	int			(*get_tx_queues)(struct net *net, struct nlattr *tb[],
 						 unsigned int *tx_queues,
 						 unsigned int *real_tx_queues);
-};
+} __do_const;
 
 extern int	__rtnl_link_register(struct rtnl_link_ops *ops);
 extern void	__rtnl_link_unregister(struct rtnl_link_ops *ops);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/sctp/sctp.h linux-3.2.71-pax/include/net/sctp/sctp.h
--- linux-3.2.71/include/net/sctp/sctp.h	2014-11-05 23:20:30.341389866 +0100
+++ linux-3.2.71-pax/include/net/sctp/sctp.h	2014-11-05 23:20:50.545398835 +0100
@@ -318,9 +318,9 @@ do {									\
 
 #else	/* SCTP_DEBUG */
 
-#define SCTP_DEBUG_PRINTK(whatever...)
-#define SCTP_DEBUG_PRINTK_CONT(fmt, args...)
-#define SCTP_DEBUG_PRINTK_IPADDR(whatever...)
+#define SCTP_DEBUG_PRINTK(whatever...) do {} while (0)
+#define SCTP_DEBUG_PRINTK_CONT(fmt, args...) do {} while (0)
+#define SCTP_DEBUG_PRINTK_IPADDR(whatever...) do {} while (0)
 #define SCTP_ENABLE_DEBUG
 #define SCTP_DISABLE_DEBUG
 #define SCTP_ASSERT(expr, str, func)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/sctp/sm.h linux-3.2.71-pax/include/net/sctp/sm.h
--- linux-3.2.71/include/net/sctp/sm.h	2014-11-05 23:20:30.341389866 +0100
+++ linux-3.2.71-pax/include/net/sctp/sm.h	2014-11-05 23:20:50.545398835 +0100
@@ -86,7 +86,7 @@ typedef void (sctp_timer_event_t) (unsig
 typedef struct {
 	sctp_state_fn_t *fn;
 	const char *name;
-} sctp_sm_table_entry_t;
+} __do_const sctp_sm_table_entry_t;
 
 /* A naming convention of "sctp_sf_xxx" applies to all the state functions
  * currently in use.
@@ -295,7 +295,7 @@ __u32 sctp_generate_tag(const struct sct
 __u32 sctp_generate_tsn(const struct sctp_endpoint *);
 
 /* Extern declarations for major data structures.  */
-extern sctp_timer_event_t *sctp_timer_events[SCTP_NUM_TIMEOUT_TYPES];
+extern sctp_timer_event_t * const sctp_timer_events[SCTP_NUM_TIMEOUT_TYPES];
 
 
 /* Get the size of a DATA chunk payload. */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/sctp/structs.h linux-3.2.71-pax/include/net/sctp/structs.h
--- linux-3.2.71/include/net/sctp/structs.h	2015-08-07 11:37:20.719789898 +0200
+++ linux-3.2.71-pax/include/net/sctp/structs.h	2015-08-07 11:37:43.027790554 +0200
@@ -649,7 +649,7 @@ struct sctp_pf {
 					  struct sctp_association *asoc);
 	void (*addr_v4map) (struct sctp_sock *, union sctp_addr *);
 	struct sctp_af *af;
-};
+} __do_const;
 
 
 /* Structure to track chunk fragments that have been acked, but peer
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/sock.h linux-3.2.71-pax/include/net/sock.h
--- linux-3.2.71/include/net/sock.h	2015-02-20 12:37:33.233178768 +0100
+++ linux-3.2.71-pax/include/net/sock.h	2015-02-20 12:37:41.909178304 +0100
@@ -277,7 +277,7 @@ struct sock {
 #ifdef CONFIG_RPS
 	__u32			sk_rxhash;
 #endif
-	atomic_t		sk_drops;
+	atomic_unchecked_t	sk_drops;
 	int			sk_rcvbuf;
 
 	struct sk_filter __rcu	*sk_filter;
@@ -1414,7 +1414,7 @@ static inline void sk_nocaps_add(struct
 }
 
 static inline int skb_do_copy_data_nocache(struct sock *sk, struct sk_buff *skb,
-					   char __user *from, char *to,
+					   char __user *from, unsigned char *to,
 					   int copy, int offset)
 {
 	if (skb->ip_summed == CHECKSUM_NONE) {
@@ -1676,7 +1676,7 @@ static inline void sk_stream_moderate_sn
 	}
 }
 
-struct sk_buff *sk_stream_alloc_skb(struct sock *sk, int size, gfp_t gfp);
+struct sk_buff * __intentional_overflow(0) sk_stream_alloc_skb(struct sock *sk, int size, gfp_t gfp);
 
 static inline struct page *sk_stream_alloc_page(struct sock *sk)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/tcp.h linux-3.2.71-pax/include/net/tcp.h
--- linux-3.2.71/include/net/tcp.h	2015-01-01 15:15:24.892069635 +0100
+++ linux-3.2.71-pax/include/net/tcp.h	2015-01-01 15:15:30.128069773 +0100
@@ -463,7 +463,7 @@ extern void tcp_retransmit_timer(struct
 extern void tcp_xmit_retransmit_queue(struct sock *);
 extern void tcp_simple_retransmit(struct sock *);
 extern int tcp_trim_head(struct sock *, struct sk_buff *, u32);
-extern int tcp_fragment(struct sock *, struct sk_buff *, u32, unsigned int);
+extern int __intentional_overflow(3) tcp_fragment(struct sock *, struct sk_buff *, u32, unsigned int);
 
 extern void tcp_send_probe0(struct sock *);
 extern void tcp_send_partial(struct sock *);
@@ -626,8 +626,8 @@ struct tcp_skb_cb {
 		struct inet6_skb_parm	h6;
 #endif
 	} header;	/* For incoming frames		*/
-	__u32		seq;		/* Starting sequence number	*/
-	__u32		end_seq;	/* SEQ + FIN + SYN + datalen	*/
+	__u32		seq __intentional_overflow(0);	/* Starting sequence number	*/
+	__u32		end_seq __intentional_overflow(0);	/* SEQ + FIN + SYN + datalen	*/
 	__u32		when;		/* used to compute rtt's	*/
 	__u8		tcp_flags;	/* TCP header flags. (tcp[13])	*/
 	__u8		sacked;		/* State flags for SACK/FACK.	*/
@@ -640,7 +640,7 @@ struct tcp_skb_cb {
 #define TCPCB_EVER_RETRANS	0x80	/* Ever retransmitted frame	*/
 #define TCPCB_RETRANS		(TCPCB_SACKED_RETRANS|TCPCB_EVER_RETRANS)
 
-	__u32		ack_seq;	/* Sequence number ACK'd	*/
+	__u32		ack_seq __intentional_overflow(0);	/* Sequence number ACK'd	*/
 };
 
 #define TCP_SKB_CB(__skb)	((struct tcp_skb_cb *)&((__skb)->cb[0]))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/net/xfrm.h linux-3.2.71-pax/include/net/xfrm.h
--- linux-3.2.71/include/net/xfrm.h	2012-10-10 11:02:19.611865897 +0200
+++ linux-3.2.71-pax/include/net/xfrm.h	2013-09-17 02:23:34.621626989 +0200
@@ -282,7 +282,6 @@ struct xfrm_dst;
 struct xfrm_policy_afinfo {
 	unsigned short		family;
 	struct dst_ops		*dst_ops;
-	void			(*garbage_collect)(struct net *net);
 	struct dst_entry	*(*dst_lookup)(struct net *net, int tos,
 					       const xfrm_address_t *saddr,
 					       const xfrm_address_t *daddr);
@@ -298,7 +297,7 @@ struct xfrm_policy_afinfo {
 					    struct net_device *dev,
 					    const struct flowi *fl);
 	struct dst_entry	*(*blackhole_route)(struct net *net, struct dst_entry *orig);
-};
+} __do_const;
 
 extern int xfrm_policy_register_afinfo(struct xfrm_policy_afinfo *afinfo);
 extern int xfrm_policy_unregister_afinfo(struct xfrm_policy_afinfo *afinfo);
@@ -334,7 +333,7 @@ struct xfrm_state_afinfo {
 						  struct sk_buff *skb);
 	int			(*transport_finish)(struct sk_buff *skb,
 						    int async);
-};
+} __do_const;
 
 extern int xfrm_state_register_afinfo(struct xfrm_state_afinfo *afinfo);
 extern int xfrm_state_unregister_afinfo(struct xfrm_state_afinfo *afinfo);
@@ -417,7 +416,7 @@ struct xfrm_mode {
 	struct module *owner;
 	unsigned int encap;
 	int flags;
-};
+} __do_const;
 
 /* Flags for xfrm_mode. */
 enum {
@@ -508,7 +507,7 @@ struct xfrm_policy {
 	struct timer_list	timer;
 
 	struct flow_cache_object flo;
-	atomic_t		genid;
+	atomic_unchecked_t	genid;
 	u32			priority;
 	u32			index;
 	struct xfrm_mark	mark;
@@ -1141,6 +1140,8 @@ static inline void xfrm_sk_free_policy(s
 	}
 }
 
+extern void xfrm_garbage_collect_deferred(struct net *net);
+
 #else
 
 static inline void xfrm_sk_free_policy(struct sock *sk) {}
@@ -1175,6 +1176,9 @@ static inline int xfrm6_policy_check_rev
 {
 	return 1;
 }
+static inline void xfrm_garbage_collect_deferred(struct net *net)
+{
+}
 #endif
 
 static __inline__
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/rdma/iw_cm.h linux-3.2.71-pax/include/rdma/iw_cm.h
--- linux-3.2.71/include/rdma/iw_cm.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/rdma/iw_cm.h	2012-07-04 19:24:48.816063008 +0200
@@ -122,7 +122,7 @@ struct iw_cm_verbs {
 					 int backlog);
 
 	int		(*destroy_listen)(struct iw_cm_id *cm_id);
-};
+} __no_const;
 
 /**
  * iw_create_cm_id - Create an IW CM identifier.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/scsi/libfc.h linux-3.2.71-pax/include/scsi/libfc.h
--- linux-3.2.71/include/scsi/libfc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/scsi/libfc.h	2012-07-04 19:24:48.816063008 +0200
@@ -748,6 +748,7 @@ struct libfc_function_template {
 	 */
 	void (*disc_stop_final) (struct fc_lport *);
 };
+typedef struct libfc_function_template __no_const libfc_function_template_no_const;
 
 /**
  * struct fc_disc - Discovery context
@@ -851,7 +852,7 @@ struct fc_lport {
 	struct fc_vport		       *vport;
 
 	/* Operational Information */
-	struct libfc_function_template tt;
+	libfc_function_template_no_const tt;
 	u8			       link_up;
 	u8			       qfull;
 	enum fc_lport_state	       state;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/scsi/scsi_device.h linux-3.2.71-pax/include/scsi/scsi_device.h
--- linux-3.2.71/include/scsi/scsi_device.h	2014-08-06 23:17:21.909614202 +0200
+++ linux-3.2.71-pax/include/scsi/scsi_device.h	2014-08-06 23:17:26.585614191 +0200
@@ -162,9 +162,9 @@ struct scsi_device {
 	unsigned int max_device_blocked; /* what device_blocked counts down from  */
 #define SCSI_DEFAULT_DEVICE_BLOCKED	3
 
-	atomic_t iorequest_cnt;
-	atomic_t iodone_cnt;
-	atomic_t ioerr_cnt;
+	atomic_unchecked_t iorequest_cnt;
+	atomic_unchecked_t iodone_cnt;
+	atomic_unchecked_t ioerr_cnt;
 
 	struct device		sdev_gendev,
 				sdev_dev;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/scsi/scsi_driver.h linux-3.2.71-pax/include/scsi/scsi_driver.h
--- linux-3.2.71/include/scsi/scsi_driver.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/scsi/scsi_driver.h	2015-06-26 17:57:00.606478721 +0200
@@ -15,7 +15,7 @@ struct scsi_driver {
 	struct device_driver	gendrv;
 
 	void (*rescan)(struct device *);
-	int (*done)(struct scsi_cmnd *);
+	unsigned int (*done)(struct scsi_cmnd *);
 };
 #define to_scsi_driver(drv) \
 	container_of((drv), struct scsi_driver, gendrv)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/scsi/scsi_transport_fc.h linux-3.2.71-pax/include/scsi/scsi_transport_fc.h
--- linux-3.2.71/include/scsi/scsi_transport_fc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/scsi/scsi_transport_fc.h	2012-07-04 19:24:48.816063008 +0200
@@ -711,7 +711,7 @@ struct fc_function_template {
 	unsigned long	show_host_system_hostname:1;
 
 	unsigned long	disable_target_scan:1;
-};
+} __do_const;
 
 
 /**
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/sound/soc.h linux-3.2.71-pax/include/sound/soc.h
--- linux-3.2.71/include/sound/soc.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/sound/soc.h	2013-01-16 21:26:55.338837163 +0100
@@ -641,7 +641,7 @@ struct snd_soc_codec_driver {
 	/* probe ordering - for components with runtime dependencies */
 	int probe_order;
 	int remove_order;
-};
+} __do_const;
 
 /* SoC platform interface */
 struct snd_soc_platform_driver {
@@ -683,7 +683,7 @@ struct snd_soc_platform_driver {
 	/* platform IO - used for platform DAPM */
 	unsigned int (*read)(struct snd_soc_platform *, unsigned int);
 	int (*write)(struct snd_soc_platform *, unsigned int, unsigned int);
-};
+} __do_const;
 
 struct snd_soc_platform {
 	const char *name;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/sound/ymfpci.h linux-3.2.71-pax/include/sound/ymfpci.h
--- linux-3.2.71/include/sound/ymfpci.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/sound/ymfpci.h	2012-07-04 19:24:48.820063008 +0200
@@ -358,7 +358,7 @@ struct snd_ymfpci {
 	spinlock_t reg_lock;
 	spinlock_t voice_lock;
 	wait_queue_head_t interrupt_sleep;
-	atomic_t interrupt_sleep_count;
+	atomic_unchecked_t interrupt_sleep_count;
 	struct snd_info_entry *proc_entry;
 	const struct firmware *dsp_microcode;
 	const struct firmware *controller_microcode;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/target/target_core_base.h linux-3.2.71-pax/include/target/target_core_base.h
--- linux-3.2.71/include/target/target_core_base.h	2012-08-03 01:53:46.558140480 +0200
+++ linux-3.2.71-pax/include/target/target_core_base.h	2013-01-16 21:26:55.342837163 +0100
@@ -466,8 +466,8 @@ struct se_cmd {
 	atomic_t		t_se_count;
 	atomic_t		t_task_cdbs_left;
 	atomic_t		t_task_cdbs_ex_left;
-	atomic_t		t_task_cdbs_sent;
-	atomic_t		t_transport_aborted;
+	atomic_unchecked_t	t_task_cdbs_sent;
+	atomic_unchecked_t	t_transport_aborted;
 	atomic_t		t_transport_active;
 	atomic_t		t_transport_complete;
 	atomic_t		t_transport_queue_active;
@@ -706,7 +706,7 @@ struct se_device {
 	/* Active commands on this virtual SE device */
 	atomic_t		simple_cmds;
 	atomic_t		depth_left;
-	atomic_t		dev_ordered_id;
+	atomic_unchecked_t	dev_ordered_id;
 	atomic_t		execute_tasks;
 	atomic_t		dev_ordered_sync;
 	atomic_t		dev_qf_count;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/trace/events/irq.h linux-3.2.71-pax/include/trace/events/irq.h
--- linux-3.2.71/include/trace/events/irq.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/trace/events/irq.h	2012-07-04 19:24:48.824063008 +0200
@@ -36,7 +36,7 @@ struct softirq_action;
  */
 TRACE_EVENT(irq_handler_entry,
 
-	TP_PROTO(int irq, struct irqaction *action),
+	TP_PROTO(int irq, const struct irqaction *action),
 
 	TP_ARGS(irq, action),
 
@@ -66,7 +66,7 @@ TRACE_EVENT(irq_handler_entry,
  */
 TRACE_EVENT(irq_handler_exit,
 
-	TP_PROTO(int irq, struct irqaction *action, int ret),
+	TP_PROTO(int irq, const struct irqaction *action, int ret),
 
 	TP_ARGS(irq, action, ret),
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/video/udlfb.h linux-3.2.71-pax/include/video/udlfb.h
--- linux-3.2.71/include/video/udlfb.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/video/udlfb.h	2012-07-04 19:24:48.824063008 +0200
@@ -52,10 +52,10 @@ struct dlfb_data {
 	u32 pseudo_palette[256];
 	int blank_mode; /*one of FB_BLANK_ */
 	/* blit-only rendering path metrics, exposed through sysfs */
-	atomic_t bytes_rendered; /* raw pixel-bytes driver asked to render */
-	atomic_t bytes_identical; /* saved effort with backbuffer comparison */
-	atomic_t bytes_sent; /* to usb, after compression including overhead */
-	atomic_t cpu_kcycles_used; /* transpired during pixel processing */
+	atomic_unchecked_t bytes_rendered; /* raw pixel-bytes driver asked to render */
+	atomic_unchecked_t bytes_identical; /* saved effort with backbuffer comparison */
+	atomic_unchecked_t bytes_sent; /* to usb, after compression including overhead */
+	atomic_unchecked_t cpu_kcycles_used; /* transpired during pixel processing */
 };
 
 #define NR_USB_REQUEST_I2C_SUB_IO 0x02
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/include/video/uvesafb.h linux-3.2.71-pax/include/video/uvesafb.h
--- linux-3.2.71/include/video/uvesafb.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/include/video/uvesafb.h	2012-07-04 19:24:48.824063008 +0200
@@ -177,6 +177,7 @@ struct uvesafb_par {
 	u8 ypan;			/* 0 - nothing, 1 - ypan, 2 - ywrap */
 	u8 pmi_setpal;			/* PMI for palette changes */
 	u16 *pmi_base;			/* protected mode interface location */
+	u8 *pmi_code;			/* protected mode code location */
 	void *pmi_start;
 	void *pmi_pal;
 	u8 *vbe_state_orig;		/*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/init/do_mounts.c linux-3.2.71-pax/init/do_mounts.c
--- linux-3.2.71/init/do_mounts.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/init/do_mounts.c	2012-07-04 19:24:48.824063008 +0200
@@ -325,11 +325,11 @@ static void __init get_fs_names(char *pa
 
 static int __init do_mount_root(char *name, char *fs, int flags, void *data)
 {
-	int err = sys_mount(name, "/root", fs, flags, data);
+	int err = sys_mount((char __force_user *)name, (char __force_user *)"/root", (char __force_user *)fs, flags, (void __force_user *)data);
 	if (err)
 		return err;
 
-	sys_chdir((const char __user __force *)"/root");
+	sys_chdir((const char __force_user*)"/root");
 	ROOT_DEV = current->fs->pwd.mnt->mnt_sb->s_dev;
 	printk(KERN_INFO
 	       "VFS: Mounted root (%s filesystem)%s on device %u:%u.\n",
@@ -448,18 +448,18 @@ void __init change_floppy(char *fmt, ...
 	va_start(args, fmt);
 	vsprintf(buf, fmt, args);
 	va_end(args);
-	fd = sys_open("/dev/root", O_RDWR | O_NDELAY, 0);
+	fd = sys_open((char __user *)"/dev/root", O_RDWR | O_NDELAY, 0);
 	if (fd >= 0) {
 		sys_ioctl(fd, FDEJECT, 0);
 		sys_close(fd);
 	}
 	printk(KERN_NOTICE "VFS: Insert %s and press ENTER\n", buf);
-	fd = sys_open("/dev/console", O_RDWR, 0);
+	fd = sys_open((__force const char __user *)"/dev/console", O_RDWR, 0);
 	if (fd >= 0) {
 		sys_ioctl(fd, TCGETS, (long)&termios);
 		termios.c_lflag &= ~ICANON;
 		sys_ioctl(fd, TCSETSF, (long)&termios);
-		sys_read(fd, &c, 1);
+		sys_read(fd, (char __user *)&c, 1);
 		termios.c_lflag |= ICANON;
 		sys_ioctl(fd, TCSETSF, (long)&termios);
 		sys_close(fd);
@@ -553,6 +553,6 @@ void __init prepare_namespace(void)
 	mount_root();
 out:
 	devtmpfs_mount("dev");
-	sys_mount(".", "/", NULL, MS_MOVE, NULL);
-	sys_chroot((const char __user __force *)".");
+	sys_mount((char __force_user *)".", (char __force_user *)"/", NULL, MS_MOVE, NULL);
+	sys_chroot((const char __force_user *)".");
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/init/do_mounts.h linux-3.2.71-pax/init/do_mounts.h
--- linux-3.2.71/init/do_mounts.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/init/do_mounts.h	2012-07-04 19:24:48.824063008 +0200
@@ -15,15 +15,15 @@ extern int root_mountflags;
 
 static inline int create_dev(char *name, dev_t dev)
 {
-	sys_unlink(name);
-	return sys_mknod(name, S_IFBLK|0600, new_encode_dev(dev));
+	sys_unlink((char __force_user *)name);
+	return sys_mknod((char __force_user *)name, S_IFBLK|0600, new_encode_dev(dev));
 }
 
 #if BITS_PER_LONG == 32
 static inline u32 bstat(char *name)
 {
 	struct stat64 stat;
-	if (sys_stat64(name, &stat) != 0)
+	if (sys_stat64((char __force_user *)name, (struct stat64 __force_user *)&stat) != 0)
 		return 0;
 	if (!S_ISBLK(stat.st_mode))
 		return 0;
@@ -35,7 +35,7 @@ static inline u32 bstat(char *name)
 static inline u32 bstat(char *name)
 {
 	struct stat stat;
-	if (sys_newstat(name, &stat) != 0)
+	if (sys_newstat((const char __force_user *)name, (struct stat __force_user *)&stat) != 0)
 		return 0;
 	if (!S_ISBLK(stat.st_mode))
 		return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/init/do_mounts_initrd.c linux-3.2.71-pax/init/do_mounts_initrd.c
--- linux-3.2.71/init/do_mounts_initrd.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/init/do_mounts_initrd.c	2012-07-04 19:24:48.824063008 +0200
@@ -44,13 +44,13 @@ static void __init handle_initrd(void)
 	create_dev("/dev/root.old", Root_RAM0);
 	/* mount initrd on rootfs' /root */
 	mount_block_root("/dev/root.old", root_mountflags & ~MS_RDONLY);
-	sys_mkdir("/old", 0700);
-	root_fd = sys_open("/", 0, 0);
-	old_fd = sys_open("/old", 0, 0);
+	sys_mkdir((const char __force_user *)"/old", 0700);
+	root_fd = sys_open((const char __force_user *)"/", 0, 0);
+	old_fd = sys_open((const char __force_user *)"/old", 0, 0);
 	/* move initrd over / and chdir/chroot in initrd root */
-	sys_chdir("/root");
-	sys_mount(".", "/", NULL, MS_MOVE, NULL);
-	sys_chroot(".");
+	sys_chdir((const char __force_user *)"/root");
+	sys_mount((char __force_user *)".", (char __force_user *)"/", NULL, MS_MOVE, NULL);
+	sys_chroot((const char __force_user *)".");
 
 	/*
 	 * In case that a resume from disk is carried out by linuxrc or one of
@@ -67,15 +67,15 @@ static void __init handle_initrd(void)
 
 	/* move initrd to rootfs' /old */
 	sys_fchdir(old_fd);
-	sys_mount("/", ".", NULL, MS_MOVE, NULL);
+	sys_mount((char __force_user *)"/", (char __force_user *)".", NULL, MS_MOVE, NULL);
 	/* switch root and cwd back to / of rootfs */
 	sys_fchdir(root_fd);
-	sys_chroot(".");
+	sys_chroot((const char __force_user *)".");
 	sys_close(old_fd);
 	sys_close(root_fd);
 
 	if (new_decode_dev(real_root_dev) == Root_RAM0) {
-		sys_chdir("/old");
+		sys_chdir((const char __force_user *)"/old");
 		return;
 	}
 
@@ -83,17 +83,17 @@ static void __init handle_initrd(void)
 	mount_root();
 
 	printk(KERN_NOTICE "Trying to move old root to /initrd ... ");
-	error = sys_mount("/old", "/root/initrd", NULL, MS_MOVE, NULL);
+	error = sys_mount((char __force_user *)"/old", (char __force_user *)"/root/initrd", NULL, MS_MOVE, NULL);
 	if (!error)
 		printk("okay\n");
 	else {
-		int fd = sys_open("/dev/root.old", O_RDWR, 0);
+		int fd = sys_open((const char __force_user *)"/dev/root.old", O_RDWR, 0);
 		if (error == -ENOENT)
 			printk("/initrd does not exist. Ignored.\n");
 		else
 			printk("failed\n");
 		printk(KERN_NOTICE "Unmounting old root\n");
-		sys_umount("/old", MNT_DETACH);
+		sys_umount((char __force_user *)"/old", MNT_DETACH);
 		printk(KERN_NOTICE "Trying to free ramdisk memory ... ");
 		if (fd < 0) {
 			error = fd;
@@ -116,11 +116,11 @@ int __init initrd_load(void)
 		 * mounted in the normal path.
 		 */
 		if (rd_load_image("/initrd.image") && ROOT_DEV != Root_RAM0) {
-			sys_unlink("/initrd.image");
+			sys_unlink((const char __force_user *)"/initrd.image");
 			handle_initrd();
 			return 1;
 		}
 	}
-	sys_unlink("/initrd.image");
+	sys_unlink((const char __force_user *)"/initrd.image");
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/init/do_mounts_md.c linux-3.2.71-pax/init/do_mounts_md.c
--- linux-3.2.71/init/do_mounts_md.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/init/do_mounts_md.c	2012-07-04 19:24:48.824063008 +0200
@@ -170,7 +170,7 @@ static void __init md_setup_drive(void)
 			partitioned ? "_d" : "", minor,
 			md_setup_args[ent].device_names);
 
-		fd = sys_open(name, 0, 0);
+		fd = sys_open((char __force_user *)name, 0, 0);
 		if (fd < 0) {
 			printk(KERN_ERR "md: open failed - cannot start "
 					"array %s\n", name);
@@ -233,7 +233,7 @@ static void __init md_setup_drive(void)
 			 * array without it
 			 */
 			sys_close(fd);
-			fd = sys_open(name, 0, 0);
+			fd = sys_open((char __force_user *)name, 0, 0);
 			sys_ioctl(fd, BLKRRPART, 0);
 		}
 		sys_close(fd);
@@ -283,7 +283,7 @@ static void __init autodetect_raid(void)
 
 	wait_for_device_probe();
 
-	fd = sys_open((const char __user __force *) "/dev/md0", 0, 0);
+	fd = sys_open((const char __force_user *) "/dev/md0", 0, 0);
 	if (fd >= 0) {
 		sys_ioctl(fd, RAID_AUTORUN, raid_autopart);
 		sys_close(fd);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/init/initramfs.c linux-3.2.71-pax/init/initramfs.c
--- linux-3.2.71/init/initramfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/init/initramfs.c	2013-06-21 20:15:56.162564327 +0200
@@ -74,7 +74,7 @@ static void __init free_hash(void)
 	}
 }
 
-static long __init do_utime(char __user *filename, time_t mtime)
+static long __init do_utime(__force char __user *filename, time_t mtime)
 {
 	struct timespec t[2];
 
@@ -109,7 +109,7 @@ static void __init dir_utime(void)
 	struct dir_entry *de, *tmp;
 	list_for_each_entry_safe(de, tmp, &dir_list, list) {
 		list_del(&de->list);
-		do_utime(de->name, de->mtime);
+		do_utime((char __force_user *)de->name, de->mtime);
 		kfree(de->name);
 		kfree(de);
 	}
@@ -271,7 +271,7 @@ static int __init maybe_link(void)
 	if (nlink >= 2) {
 		char *old = find_link(major, minor, ino, mode, collected);
 		if (old)
-			return (sys_link(old, collected) < 0) ? -1 : 1;
+			return (sys_link((char __force_user *)old, (char __force_user *)collected) < 0) ? -1 : 1;
 	}
 	return 0;
 }
@@ -280,11 +280,11 @@ static void __init clean_path(char *path
 {
 	struct stat st;
 
-	if (!sys_newlstat(path, &st) && (st.st_mode^mode) & S_IFMT) {
+	if (!sys_newlstat((char __force_user *)path, (struct stat __force_user *)&st) && (st.st_mode^mode) & S_IFMT) {
 		if (S_ISDIR(st.st_mode))
-			sys_rmdir(path);
+			sys_rmdir((char __force_user *)path);
 		else
-			sys_unlink(path);
+			sys_unlink((char __force_user *)path);
 	}
 }
 
@@ -305,7 +305,7 @@ static int __init do_name(void)
 			int openflags = O_WRONLY|O_CREAT;
 			if (ml != 1)
 				openflags |= O_TRUNC;
-			wfd = sys_open(collected, openflags, mode);
+			wfd = sys_open((char __force_user *)collected, openflags, mode);
 
 			if (wfd >= 0) {
 				sys_fchown(wfd, uid, gid);
@@ -317,17 +317,17 @@ static int __init do_name(void)
 			}
 		}
 	} else if (S_ISDIR(mode)) {
-		sys_mkdir(collected, mode);
-		sys_chown(collected, uid, gid);
-		sys_chmod(collected, mode);
+		sys_mkdir((char __force_user *)collected, mode);
+		sys_chown((char __force_user *)collected, uid, gid);
+		sys_chmod((char __force_user *)collected, mode);
 		dir_add(collected, mtime);
 	} else if (S_ISBLK(mode) || S_ISCHR(mode) ||
 		   S_ISFIFO(mode) || S_ISSOCK(mode)) {
 		if (maybe_link() == 0) {
-			sys_mknod(collected, mode, rdev);
-			sys_chown(collected, uid, gid);
-			sys_chmod(collected, mode);
-			do_utime(collected, mtime);
+			sys_mknod((char __force_user *)collected, mode, rdev);
+			sys_chown((char __force_user *)collected, uid, gid);
+			sys_chmod((char __force_user *)collected, mode);
+			do_utime((char __force_user *)collected, mtime);
 		}
 	}
 	return 0;
@@ -336,15 +336,15 @@ static int __init do_name(void)
 static int __init do_copy(void)
 {
 	if (count >= body_len) {
-		sys_write(wfd, victim, body_len);
+		sys_write(wfd, (char __force_user *)victim, body_len);
 		sys_close(wfd);
-		do_utime(vcollected, mtime);
+		do_utime((char __force_user *)vcollected, mtime);
 		kfree(vcollected);
 		eat(body_len);
 		state = SkipIt;
 		return 0;
 	} else {
-		sys_write(wfd, victim, count);
+		sys_write(wfd, (char __force_user *)victim, count);
 		body_len -= count;
 		eat(count);
 		return 1;
@@ -355,9 +355,9 @@ static int __init do_symlink(void)
 {
 	collected[N_ALIGN(name_len) + body_len] = '\0';
 	clean_path(collected, 0);
-	sys_symlink(collected + N_ALIGN(name_len), collected);
-	sys_lchown(collected, uid, gid);
-	do_utime(collected, mtime);
+	sys_symlink((char __force_user *)collected + N_ALIGN(name_len), (char __force_user *)collected);
+	sys_lchown((char __force_user *)collected, uid, gid);
+	do_utime((char __force_user *)collected, mtime);
 	state = SkipIt;
 	next_state = Reset;
 	return 0;
@@ -573,7 +573,7 @@ static int __init populate_rootfs(void)
 {
 	char *err = unpack_to_rootfs(__initramfs_start, __initramfs_size);
 	if (err)
-		panic(err);	/* Failed to decompress INTERNAL initramfs */
+		panic("%s", err);	/* Failed to decompress INTERNAL initramfs */
 	if (initrd_start) {
 #ifdef CONFIG_BLK_DEV_RAM
 		int fd;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/init/Kconfig linux-3.2.71-pax/init/Kconfig
--- linux-3.2.71/init/Kconfig	2014-11-05 23:20:30.341389866 +0100
+++ linux-3.2.71-pax/init/Kconfig	2014-11-05 23:20:50.545398835 +0100
@@ -1215,7 +1215,7 @@ config SLUB_DEBUG
 
 config COMPAT_BRK
 	bool "Disable heap randomization"
-	default y
+	default n
 	help
 	  Randomizing heap placement makes heap exploits harder, but it
 	  also breaks ancient binaries (including anything libc5 based).
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/init/main.c linux-3.2.71-pax/init/main.c
--- linux-3.2.71/init/main.c	2014-09-14 14:11:00.058118741 +0200
+++ linux-3.2.71-pax/init/main.c	2014-09-14 14:11:26.118138473 +0200
@@ -150,6 +150,54 @@ static int __init set_reset_devices(char
 
 __setup("reset_devices", set_reset_devices);
 
+#if defined(CONFIG_X86_64) && defined(CONFIG_PAX_MEMORY_UDEREF)
+unsigned long pax_user_shadow_base __read_only = 1UL << TASK_SIZE_MAX_SHIFT;
+EXPORT_SYMBOL(pax_user_shadow_base);
+extern char pax_enter_kernel_user[];
+extern char pax_exit_kernel_user[];
+extern pgdval_t clone_pgd_mask;
+#endif
+
+#if defined(CONFIG_X86) && defined(CONFIG_PAX_MEMORY_UDEREF)
+static int __init setup_pax_nouderef(char *str)
+{
+#ifdef CONFIG_X86_32
+	unsigned int cpu;
+	struct desc_struct *gdt;
+
+	for (cpu = 0; cpu < nr_cpu_ids; cpu++) {
+		gdt = get_cpu_gdt_table(cpu);
+		gdt[GDT_ENTRY_KERNEL_DS].type = 3;
+		gdt[GDT_ENTRY_KERNEL_DS].limit = 0xf;
+		gdt[GDT_ENTRY_DEFAULT_USER_CS].limit = 0xf;
+		gdt[GDT_ENTRY_DEFAULT_USER_DS].limit = 0xf;
+	}
+	loadsegment(ds, __KERNEL_DS);
+	loadsegment(es, __KERNEL_DS);
+	loadsegment(ss, __KERNEL_DS);
+#else
+	memcpy(pax_enter_kernel_user, (unsigned char []){0xc3}, 1);
+	memcpy(pax_exit_kernel_user, (unsigned char []){0xc3}, 1);
+	clone_pgd_mask = ~(pgdval_t)0UL;
+	pax_user_shadow_base = 0UL;
+#endif
+
+	return 0;
+}
+early_param("pax_nouderef", setup_pax_nouderef);
+#endif
+
+#ifdef CONFIG_PAX_SOFTMODE
+int pax_softmode;
+
+static int __init setup_pax_softmode(char *str)
+{
+	get_option(&str, &pax_softmode);
+	return 1;
+}
+__setup("pax_softmode=", setup_pax_softmode);
+#endif
+
 static const char * argv_init[MAX_INIT_ARGS+2] = { "init", NULL, };
 const char * envp_init[MAX_INIT_ENVS+2] = { "HOME=/", "TERM=linux", NULL, };
 static const char *panic_later, *panic_param;
@@ -683,6 +731,7 @@ int __init_or_module do_one_initcall(ini
 {
 	int count = preempt_count();
 	int ret;
+	const char *msg1 = "", *msg2 = "";
 
 	if (initcall_debug)
 		ret = do_one_initcall_debug(fn);
@@ -695,17 +744,18 @@ int __init_or_module do_one_initcall(ini
 		sprintf(msgbuf, "error code %d ", ret);
 
 	if (preempt_count() != count) {
-		strlcat(msgbuf, "preemption imbalance ", sizeof(msgbuf));
+		msg1 = " preemption imbalance";
 		preempt_count() = count;
 	}
 	if (irqs_disabled()) {
-		strlcat(msgbuf, "disabled interrupts ", sizeof(msgbuf));
+		msg2 = " disabled interrupts";
 		local_irq_enable();
 	}
-	if (msgbuf[0]) {
-		printk("initcall %pF returned with %s\n", fn, msgbuf);
+	if (msgbuf[0] || *msg1 || *msg2) {
+		printk("initcall %pF returned with %s%s%s\n", fn, msgbuf, msg1, msg2);
 	}
 
+	add_latent_entropy();
 	return ret;
 }
 
@@ -827,7 +877,7 @@ static int __init kernel_init(void * unu
 	do_basic_setup();
 
 	/* Open the /dev/console on the rootfs, this should never fail */
-	if (sys_open((const char __user *) "/dev/console", O_RDWR, 0) < 0)
+	if (sys_open((const char __force_user *) "/dev/console", O_RDWR, 0) < 0)
 		printk(KERN_WARNING "Warning: unable to open an initial console.\n");
 
 	(void) sys_dup(0);
@@ -840,7 +890,7 @@ static int __init kernel_init(void * unu
 	if (!ramdisk_execute_command)
 		ramdisk_execute_command = "/init";
 
-	if (sys_access((const char __user *) ramdisk_execute_command, 0) != 0) {
+	if (sys_access((const char __force_user *) ramdisk_execute_command, 0) != 0) {
 		ramdisk_execute_command = NULL;
 		prepare_namespace();
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/ipc/compat.c linux-3.2.71-pax/ipc/compat.c
--- linux-3.2.71/ipc/compat.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/ipc/compat.c	2015-05-05 17:41:50.653930129 +0200
@@ -672,7 +672,7 @@ long compat_sys_shmctl(int first, int se
 }
 
 long compat_sys_semtimedop(int semid, struct sembuf __user *tsems,
-		unsigned nsops, const struct compat_timespec __user *timeout)
+		compat_long_t nsops, const struct compat_timespec __user *timeout)
 {
 	struct timespec __user *ts64 = NULL;
 	if (timeout) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/ipc/ipc_sysctl.c linux-3.2.71-pax/ipc/ipc_sysctl.c
--- linux-3.2.71/ipc/ipc_sysctl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/ipc/ipc_sysctl.c	2013-03-28 01:35:23.496427938 +0100
@@ -30,7 +30,7 @@ static void *get_ipc(ctl_table *table)
 static int proc_ipc_dointvec(ctl_table *table, int write,
 	void __user *buffer, size_t *lenp, loff_t *ppos)
 {
-	struct ctl_table ipc_table;
+	ctl_table_no_const ipc_table;
 
 	memcpy(&ipc_table, table, sizeof(ipc_table));
 	ipc_table.data = get_ipc(table);
@@ -41,7 +41,7 @@ static int proc_ipc_dointvec(ctl_table *
 static int proc_ipc_dointvec_minmax(ctl_table *table, int write,
 	void __user *buffer, size_t *lenp, loff_t *ppos)
 {
-	struct ctl_table ipc_table;
+	ctl_table_no_const ipc_table;
 
 	memcpy(&ipc_table, table, sizeof(ipc_table));
 	ipc_table.data = get_ipc(table);
@@ -65,7 +65,7 @@ static int proc_ipc_dointvec_minmax_orph
 static int proc_ipc_callback_dointvec(ctl_table *table, int write,
 	void __user *buffer, size_t *lenp, loff_t *ppos)
 {
-	struct ctl_table ipc_table;
+	ctl_table_no_const ipc_table;
 	size_t lenp_bef = *lenp;
 	int rc;
 
@@ -88,7 +88,7 @@ static int proc_ipc_callback_dointvec(ct
 static int proc_ipc_doulongvec_minmax(ctl_table *table, int write,
 	void __user *buffer, size_t *lenp, loff_t *ppos)
 {
-	struct ctl_table ipc_table;
+	ctl_table_no_const ipc_table;
 	memcpy(&ipc_table, table, sizeof(ipc_table));
 	ipc_table.data = get_ipc(table);
 
@@ -122,7 +122,7 @@ static void ipc_auto_callback(int val)
 static int proc_ipcauto_dointvec_minmax(ctl_table *table, int write,
 	void __user *buffer, size_t *lenp, loff_t *ppos)
 {
-	struct ctl_table ipc_table;
+	ctl_table_no_const ipc_table;
 	size_t lenp_bef = *lenp;
 	int oldval;
 	int rc;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/ipc/mq_sysctl.c linux-3.2.71-pax/ipc/mq_sysctl.c
--- linux-3.2.71/ipc/mq_sysctl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/ipc/mq_sysctl.c	2013-03-28 03:38:37.224033170 +0100
@@ -34,7 +34,7 @@ static void *get_mq(ctl_table *table)
 static int proc_mq_dointvec(ctl_table *table, int write,
 	void __user *buffer, size_t *lenp, loff_t *ppos)
 {
-	struct ctl_table mq_table;
+	ctl_table_no_const mq_table;
 	memcpy(&mq_table, table, sizeof(mq_table));
 	mq_table.data = get_mq(table);
 
@@ -44,7 +44,7 @@ static int proc_mq_dointvec(ctl_table *t
 static int proc_mq_dointvec_minmax(ctl_table *table, int write,
 	void __user *buffer, size_t *lenp, loff_t *ppos)
 {
-	struct ctl_table mq_table;
+	ctl_table_no_const mq_table;
 	memcpy(&mq_table, table, sizeof(mq_table));
 	mq_table.data = get_mq(table);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/ipc/msg.c linux-3.2.71-pax/ipc/msg.c
--- linux-3.2.71/ipc/msg.c	2014-04-09 12:13:43.908713384 +0200
+++ linux-3.2.71-pax/ipc/msg.c	2014-04-09 12:13:49.048713110 +0200
@@ -311,18 +311,19 @@ static inline int msg_security(struct ke
 	return security_msg_queue_associate(msq, msgflg);
 }
 
+static struct ipc_ops msg_ops = {
+	.getnew		= newque,
+	.associate	= msg_security,
+	.more_checks	= NULL
+};
+
 SYSCALL_DEFINE2(msgget, key_t, key, int, msgflg)
 {
 	struct ipc_namespace *ns;
-	struct ipc_ops msg_ops;
 	struct ipc_params msg_params;
 
 	ns = current->nsproxy->ipc_ns;
 
-	msg_ops.getnew = newque;
-	msg_ops.associate = msg_security;
-	msg_ops.more_checks = NULL;
-
 	msg_params.key = key;
 	msg_params.flg = msgflg;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/ipc/sem.c linux-3.2.71-pax/ipc/sem.c
--- linux-3.2.71/ipc/sem.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/ipc/sem.c	2015-05-05 17:42:14.033930816 +0200
@@ -364,10 +364,15 @@ static inline int sem_more_checks(struct
 	return 0;
 }
 
+static struct ipc_ops sem_ops = {
+	.getnew		= newary,
+	.associate	= sem_security,
+	.more_checks	= sem_more_checks
+};
+
 SYSCALL_DEFINE3(semget, key_t, key, int, nsems, int, semflg)
 {
 	struct ipc_namespace *ns;
-	struct ipc_ops sem_ops;
 	struct ipc_params sem_params;
 
 	ns = current->nsproxy->ipc_ns;
@@ -375,10 +380,6 @@ SYSCALL_DEFINE3(semget, key_t, key, int,
 	if (nsems < 0 || nsems > ns->sc_semmsl)
 		return -EINVAL;
 
-	sem_ops.getnew = newary;
-	sem_ops.associate = sem_security;
-	sem_ops.more_checks = sem_more_checks;
-
 	sem_params.key = key;
 	sem_params.flg = semflg;
 	sem_params.u.nsems = nsems;
@@ -1328,7 +1329,7 @@ static int get_queue_result(struct sem_q
 
 
 SYSCALL_DEFINE4(semtimedop, int, semid, struct sembuf __user *, tsops,
-		unsigned, nsops, const struct timespec __user *, timeout)
+		long, nsops, const struct timespec __user *, timeout)
 {
 	int error = -EINVAL;
 	struct sem_array *sma;
@@ -1546,7 +1547,7 @@ out_free:
 }
 
 SYSCALL_DEFINE3(semop, int, semid, struct sembuf __user *, tsops,
-		unsigned, nsops)
+		long, nsops)
 {
 	return sys_semtimedop(semid, tsops, nsops, NULL);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/ipc/shm.c linux-3.2.71-pax/ipc/shm.c
--- linux-3.2.71/ipc/shm.c	2013-05-14 13:33:40.660285670 +0200
+++ linux-3.2.71-pax/ipc/shm.c	2013-05-14 13:33:46.592285354 +0200
@@ -559,18 +559,19 @@ static inline int shm_more_checks(struct
 	return 0;
 }
 
+static struct ipc_ops shm_ops = {
+	.getnew		= newseg,
+	.associate	= shm_security,
+	.more_checks	= shm_more_checks
+};
+
 SYSCALL_DEFINE3(shmget, key_t, key, size_t, size, int, shmflg)
 {
 	struct ipc_namespace *ns;
-	struct ipc_ops shm_ops;
 	struct ipc_params shm_params;
 
 	ns = current->nsproxy->ipc_ns;
 
-	shm_ops.getnew = newseg;
-	shm_ops.associate = shm_security;
-	shm_ops.more_checks = shm_more_checks;
-
 	shm_params.key = key;
 	shm_params.flg = shmflg;
 	shm_params.u.size = size;
@@ -988,6 +989,12 @@ long do_shmat(int shmid, char __user *sh
 		f_mode = FMODE_READ | FMODE_WRITE;
 	}
 	if (shmflg & SHM_EXEC) {
+
+#ifdef CONFIG_PAX_MPROTECT
+		if (current->mm->pax_flags & MF_PAX_MPROTECT)
+			goto out;
+#endif
+
 		prot |= PROT_EXEC;
 		acc_mode |= S_IXUGO;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/acct.c linux-3.2.71-pax/kernel/acct.c
--- linux-3.2.71/kernel/acct.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/acct.c	2012-07-04 19:24:48.832063008 +0200
@@ -570,7 +570,7 @@ static void do_acct_process(struct bsd_a
 	 */
 	flim = current->signal->rlim[RLIMIT_FSIZE].rlim_cur;
 	current->signal->rlim[RLIMIT_FSIZE].rlim_cur = RLIM_INFINITY;
-	file->f_op->write(file, (char *)&ac,
+	file->f_op->write(file, (char __force_user *)&ac,
 			       sizeof(acct_t), &file->f_pos);
 	current->signal->rlim[RLIMIT_FSIZE].rlim_cur = flim;
 	set_fs(fs);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/audit.c linux-3.2.71-pax/kernel/audit.c
--- linux-3.2.71/kernel/audit.c	2014-01-03 15:48:45.096070559 +0100
+++ linux-3.2.71-pax/kernel/audit.c	2014-01-03 15:48:49.600070318 +0100
@@ -115,7 +115,7 @@ u32		audit_sig_sid = 0;
    3) suppressed due to audit_rate_limit
    4) suppressed due to audit_backlog_limit
 */
-static atomic_t    audit_lost = ATOMIC_INIT(0);
+static atomic_unchecked_t    audit_lost = ATOMIC_INIT(0);
 
 /* The netlink socket. */
 static struct sock *audit_sock;
@@ -237,7 +237,7 @@ void audit_log_lost(const char *message)
 	unsigned long		now;
 	int			print;
 
-	atomic_inc(&audit_lost);
+	atomic_inc_unchecked(&audit_lost);
 
 	print = (audit_failure == AUDIT_FAIL_PANIC || !audit_rate_limit);
 
@@ -256,7 +256,7 @@ void audit_log_lost(const char *message)
 			printk(KERN_WARNING
 				"audit: audit_lost=%d audit_rate_limit=%d "
 				"audit_backlog_limit=%d\n",
-				atomic_read(&audit_lost),
+				atomic_read_unchecked(&audit_lost),
 				audit_rate_limit,
 				audit_backlog_limit);
 		audit_panic(message);
@@ -690,7 +690,7 @@ static int audit_receive_msg(struct sk_b
 		status_set.pid		 = audit_pid;
 		status_set.rate_limit	 = audit_rate_limit;
 		status_set.backlog_limit = audit_backlog_limit;
-		status_set.lost		 = atomic_read(&audit_lost);
+		status_set.lost		 = atomic_read_unchecked(&audit_lost);
 		status_set.backlog	 = skb_queue_len(&audit_skb_queue);
 		audit_send_reply(NETLINK_CB(skb).pid, seq, AUDIT_GET, 0, 0,
 				 &status_set, sizeof(status_set));
@@ -1307,7 +1307,7 @@ void audit_log_n_hex(struct audit_buffer
 	int i, avail, new_len;
 	unsigned char *ptr;
 	struct sk_buff *skb;
-	static const unsigned char *hex = "0123456789ABCDEF";
+	static const unsigned char hex[] = "0123456789ABCDEF";
 
 	if (!ab)
 		return;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/auditsc.c linux-3.2.71-pax/kernel/auditsc.c
--- linux-3.2.71/kernel/auditsc.c	2014-07-12 17:42:33.952954215 +0200
+++ linux-3.2.71-pax/kernel/auditsc.c	2014-07-12 17:42:44.768954191 +0200
@@ -2129,7 +2129,7 @@ int auditsc_get_stamp(struct audit_conte
 }
 
 /* global counter which is incremented every time something logs in */
-static atomic_t session_id = ATOMIC_INIT(0);
+static atomic_unchecked_t session_id = ATOMIC_INIT(0);
 
 /**
  * audit_set_loginuid - set a task's audit_context loginuid
@@ -2140,9 +2140,9 @@ static atomic_t session_id = ATOMIC_INIT
  *
  * Called (set) from fs/proc/base.c::proc_loginuid_write().
  */
-int audit_set_loginuid(struct task_struct *task, uid_t loginuid)
+int __intentional_overflow(-1) audit_set_loginuid(struct task_struct *task, uid_t loginuid)
 {
-	unsigned int sessionid = atomic_inc_return(&session_id);
+	unsigned int sessionid = atomic_inc_return_unchecked(&session_id);
 	struct audit_context *context = task->audit_context;
 
 	if (context && context->in_syscall) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/capability.c linux-3.2.71-pax/kernel/capability.c
--- linux-3.2.71/kernel/capability.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/capability.c	2012-07-04 19:24:48.836063008 +0200
@@ -202,6 +202,9 @@ SYSCALL_DEFINE2(capget, cap_user_header_
 		 * before modification is attempted and the application
 		 * fails.
 		 */
+		if (tocopy > ARRAY_SIZE(kdata))
+			return -EFAULT;
+
 		if (copy_to_user(dataptr, kdata, tocopy
 				 * sizeof(struct __user_cap_data_struct))) {
 			return -EFAULT;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/compat.c linux-3.2.71-pax/kernel/compat.c
--- linux-3.2.71/kernel/compat.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/compat.c	2012-07-04 19:24:48.836063008 +0200
@@ -168,7 +168,7 @@ static long compat_nanosleep_restart(str
 	mm_segment_t oldfs;
 	long ret;
 
-	restart->nanosleep.rmtp = (struct timespec __user *) &rmt;
+	restart->nanosleep.rmtp = (struct timespec __force_user *) &rmt;
 	oldfs = get_fs();
 	set_fs(KERNEL_DS);
 	ret = hrtimer_nanosleep_restart(restart);
@@ -200,7 +200,7 @@ asmlinkage long compat_sys_nanosleep(str
 	oldfs = get_fs();
 	set_fs(KERNEL_DS);
 	ret = hrtimer_nanosleep(&tu,
-				rmtp ? (struct timespec __user *)&rmt : NULL,
+				rmtp ? (struct timespec __force_user *)&rmt : NULL,
 				HRTIMER_MODE_REL, CLOCK_MONOTONIC);
 	set_fs(oldfs);
 
@@ -309,7 +309,7 @@ asmlinkage long compat_sys_sigpending(co
 	mm_segment_t old_fs = get_fs();
 
 	set_fs(KERNEL_DS);
-	ret = sys_sigpending((old_sigset_t __user *) &s);
+	ret = sys_sigpending((old_sigset_t __force_user *) &s);
 	set_fs(old_fs);
 	if (ret == 0)
 		ret = put_user(s, set);
@@ -399,7 +399,7 @@ asmlinkage long compat_sys_old_getrlimit
 	mm_segment_t old_fs = get_fs();
 
 	set_fs(KERNEL_DS);
-	ret = sys_old_getrlimit(resource, &r);
+	ret = sys_old_getrlimit(resource, (struct rlimit __force_user *)&r);
 	set_fs(old_fs);
 
 	if (!ret) {
@@ -471,7 +471,7 @@ asmlinkage long compat_sys_getrusage(int
 	mm_segment_t old_fs = get_fs();
 
 	set_fs(KERNEL_DS);
-	ret = sys_getrusage(who, (struct rusage __user *) &r);
+	ret = sys_getrusage(who, (struct rusage __force_user *) &r);
 	set_fs(old_fs);
 
 	if (ret)
@@ -498,8 +498,8 @@ compat_sys_wait4(compat_pid_t pid, compa
 		set_fs (KERNEL_DS);
 		ret = sys_wait4(pid,
 				(stat_addr ?
-				 (unsigned int __user *) &status : NULL),
-				options, (struct rusage __user *) &r);
+				 (unsigned int __force_user *) &status : NULL),
+				options, (struct rusage __force_user *) &r);
 		set_fs (old_fs);
 
 		if (ret > 0) {
@@ -524,8 +524,8 @@ asmlinkage long compat_sys_waitid(int wh
 	memset(&info, 0, sizeof(info));
 
 	set_fs(KERNEL_DS);
-	ret = sys_waitid(which, pid, (siginfo_t __user *)&info, options,
-			 uru ? (struct rusage __user *)&ru : NULL);
+	ret = sys_waitid(which, pid, (siginfo_t __force_user *)&info, options,
+			 uru ? (struct rusage __force_user *)&ru : NULL);
 	set_fs(old_fs);
 
 	if ((ret < 0) || (info.si_signo == 0))
@@ -655,8 +655,8 @@ long compat_sys_timer_settime(timer_t ti
 	oldfs = get_fs();
 	set_fs(KERNEL_DS);
 	err = sys_timer_settime(timer_id, flags,
-				(struct itimerspec __user *) &newts,
-				(struct itimerspec __user *) &oldts);
+				(struct itimerspec __force_user *) &newts,
+				(struct itimerspec __force_user *) &oldts);
 	set_fs(oldfs);
 	if (!err && old && put_compat_itimerspec(old, &oldts))
 		return -EFAULT;
@@ -673,7 +673,7 @@ long compat_sys_timer_gettime(timer_t ti
 	oldfs = get_fs();
 	set_fs(KERNEL_DS);
 	err = sys_timer_gettime(timer_id,
-				(struct itimerspec __user *) &ts);
+				(struct itimerspec __force_user *) &ts);
 	set_fs(oldfs);
 	if (!err && put_compat_itimerspec(setting, &ts))
 		return -EFAULT;
@@ -692,7 +692,7 @@ long compat_sys_clock_settime(clockid_t
 	oldfs = get_fs();
 	set_fs(KERNEL_DS);
 	err = sys_clock_settime(which_clock,
-				(struct timespec __user *) &ts);
+				(struct timespec __force_user *) &ts);
 	set_fs(oldfs);
 	return err;
 }
@@ -707,7 +707,7 @@ long compat_sys_clock_gettime(clockid_t
 	oldfs = get_fs();
 	set_fs(KERNEL_DS);
 	err = sys_clock_gettime(which_clock,
-				(struct timespec __user *) &ts);
+				(struct timespec __force_user *) &ts);
 	set_fs(oldfs);
 	if (!err && put_compat_timespec(&ts, tp))
 		return -EFAULT;
@@ -727,7 +727,7 @@ long compat_sys_clock_adjtime(clockid_t
 
 	oldfs = get_fs();
 	set_fs(KERNEL_DS);
-	ret = sys_clock_adjtime(which_clock, (struct timex __user *) &txc);
+	ret = sys_clock_adjtime(which_clock, (struct timex __force_user *) &txc);
 	set_fs(oldfs);
 
 	err = compat_put_timex(utp, &txc);
@@ -747,7 +747,7 @@ long compat_sys_clock_getres(clockid_t w
 	oldfs = get_fs();
 	set_fs(KERNEL_DS);
 	err = sys_clock_getres(which_clock,
-			       (struct timespec __user *) &ts);
+			       (struct timespec __force_user *) &ts);
 	set_fs(oldfs);
 	if (!err && tp && put_compat_timespec(&ts, tp))
 		return -EFAULT;
@@ -759,9 +759,9 @@ static long compat_clock_nanosleep_resta
 	long err;
 	mm_segment_t oldfs;
 	struct timespec tu;
-	struct compat_timespec *rmtp = restart->nanosleep.compat_rmtp;
+	struct compat_timespec __user *rmtp = restart->nanosleep.compat_rmtp;
 
-	restart->nanosleep.rmtp = (struct timespec __user *) &tu;
+	restart->nanosleep.rmtp = (struct timespec __force_user *) &tu;
 	oldfs = get_fs();
 	set_fs(KERNEL_DS);
 	err = clock_nanosleep_restart(restart);
@@ -793,8 +793,8 @@ long compat_sys_clock_nanosleep(clockid_
 	oldfs = get_fs();
 	set_fs(KERNEL_DS);
 	err = sys_clock_nanosleep(which_clock, flags,
-				  (struct timespec __user *) &in,
-				  (struct timespec __user *) &out);
+				  (struct timespec __force_user *) &in,
+				  (struct timespec __force_user *) &out);
 	set_fs(oldfs);
 
 	if ((err == -ERESTART_RESTARTBLOCK) && rmtp &&
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/debug/debug_core.c linux-3.2.71-pax/kernel/debug/debug_core.c
--- linux-3.2.71/kernel/debug/debug_core.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/debug/debug_core.c	2012-07-04 19:24:48.836063008 +0200
@@ -119,7 +119,7 @@ static DEFINE_RAW_SPINLOCK(dbg_slave_loc
  */
 static atomic_t			masters_in_kgdb;
 static atomic_t			slaves_in_kgdb;
-static atomic_t			kgdb_break_tasklet_var;
+static atomic_unchecked_t	kgdb_break_tasklet_var;
 atomic_t			kgdb_setting_breakpoint;
 
 struct task_struct		*kgdb_usethread;
@@ -129,7 +129,7 @@ int				kgdb_single_step;
 static pid_t			kgdb_sstep_pid;
 
 /* to keep track of the CPU which is doing the single stepping*/
-atomic_t			kgdb_cpu_doing_single_step = ATOMIC_INIT(-1);
+atomic_unchecked_t		kgdb_cpu_doing_single_step = ATOMIC_INIT(-1);
 
 /*
  * If you are debugging a problem where roundup (the collection of
@@ -537,7 +537,7 @@ return_normal:
 	 * kernel will only try for the value of sstep_tries before
 	 * giving up and continuing on.
 	 */
-	if (atomic_read(&kgdb_cpu_doing_single_step) != -1 &&
+	if (atomic_read_unchecked(&kgdb_cpu_doing_single_step) != -1 &&
 	    (kgdb_info[cpu].task &&
 	     kgdb_info[cpu].task->pid != kgdb_sstep_pid) && --sstep_tries) {
 		atomic_set(&kgdb_active, -1);
@@ -631,8 +631,8 @@ cpu_master_loop:
 	}
 
 kgdb_restore:
-	if (atomic_read(&kgdb_cpu_doing_single_step) != -1) {
-		int sstep_cpu = atomic_read(&kgdb_cpu_doing_single_step);
+	if (atomic_read_unchecked(&kgdb_cpu_doing_single_step) != -1) {
+		int sstep_cpu = atomic_read_unchecked(&kgdb_cpu_doing_single_step);
 		if (kgdb_info[sstep_cpu].task)
 			kgdb_sstep_pid = kgdb_info[sstep_cpu].task->pid;
 		else
@@ -829,18 +829,18 @@ static void kgdb_unregister_callbacks(vo
 static void kgdb_tasklet_bpt(unsigned long ing)
 {
 	kgdb_breakpoint();
-	atomic_set(&kgdb_break_tasklet_var, 0);
+	atomic_set_unchecked(&kgdb_break_tasklet_var, 0);
 }
 
 static DECLARE_TASKLET(kgdb_tasklet_breakpoint, kgdb_tasklet_bpt, 0);
 
 void kgdb_schedule_breakpoint(void)
 {
-	if (atomic_read(&kgdb_break_tasklet_var) ||
+	if (atomic_read_unchecked(&kgdb_break_tasklet_var) ||
 		atomic_read(&kgdb_active) != -1 ||
 		atomic_read(&kgdb_setting_breakpoint))
 		return;
-	atomic_inc(&kgdb_break_tasklet_var);
+	atomic_inc_unchecked(&kgdb_break_tasklet_var);
 	tasklet_schedule(&kgdb_tasklet_breakpoint);
 }
 EXPORT_SYMBOL_GPL(kgdb_schedule_breakpoint);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/debug/kdb/kdb_main.c linux-3.2.71-pax/kernel/debug/kdb/kdb_main.c
--- linux-3.2.71/kernel/debug/kdb/kdb_main.c	2015-05-10 09:22:39.051493138 +0200
+++ linux-3.2.71-pax/kernel/debug/kdb/kdb_main.c	2015-05-10 09:23:09.511494792 +0200
@@ -1980,7 +1980,7 @@ static int kdb_lsmod(int argc, const cha
 	list_for_each_entry(mod, kdb_modules, list) {
 
 		kdb_printf("%-20s%8u  0x%p ", mod->name,
-			   mod->core_size, (void *)mod);
+			   mod->core_size_rx + mod->core_size_rw, (void *)mod);
 #ifdef CONFIG_MODULE_UNLOAD
 		kdb_printf("%4d ", module_refcount(mod));
 #endif
@@ -1990,7 +1990,7 @@ static int kdb_lsmod(int argc, const cha
 			kdb_printf(" (Loading)");
 		else
 			kdb_printf(" (Live)");
-		kdb_printf(" 0x%p", mod->module_core);
+		kdb_printf(" 0x%p 0x%p", mod->module_core_rx,  mod->module_core_rw);
 
 #ifdef CONFIG_MODULE_UNLOAD
 		{
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/events/core.c linux-3.2.71-pax/kernel/events/core.c
--- linux-3.2.71/kernel/events/core.c	2015-05-10 09:22:39.095493140 +0200
+++ linux-3.2.71-pax/kernel/events/core.c	2015-05-10 09:23:09.531494793 +0200
@@ -174,7 +174,7 @@ int perf_proc_update_handler(struct ctl_
 	return 0;
 }
 
-static atomic64_t perf_event_id;
+static atomic64_unchecked_t perf_event_id;
 
 static void cpu_ctx_sched_out(struct perf_cpu_context *cpuctx,
 			      enum event_type_t event_type);
@@ -2600,7 +2600,7 @@ static void __perf_event_read(void *info
 
 static inline u64 perf_event_count(struct perf_event *event)
 {
-	return local64_read(&event->count) + atomic64_read(&event->child_count);
+	return local64_read(&event->count) + atomic64_read_unchecked(&event->child_count);
 }
 
 static u64 perf_event_read(struct perf_event *event)
@@ -3143,9 +3143,9 @@ u64 perf_event_read_value(struct perf_ev
 	mutex_lock(&event->child_mutex);
 	total += perf_event_read(event);
 	*enabled += event->total_time_enabled +
-			atomic64_read(&event->child_total_time_enabled);
+			atomic64_read_unchecked(&event->child_total_time_enabled);
 	*running += event->total_time_running +
-			atomic64_read(&event->child_total_time_running);
+			atomic64_read_unchecked(&event->child_total_time_running);
 
 	list_for_each_entry(child, &event->child_list, child_list) {
 		total += perf_event_read(child);
@@ -3556,10 +3556,10 @@ void perf_event_update_userpage(struct p
 		userpg->offset -= local64_read(&event->hw.prev_count);
 
 	userpg->time_enabled = enabled +
-			atomic64_read(&event->child_total_time_enabled);
+			atomic64_read_unchecked(&event->child_total_time_enabled);
 
 	userpg->time_running = running +
-			atomic64_read(&event->child_total_time_running);
+			atomic64_read_unchecked(&event->child_total_time_running);
 
 	barrier();
 	++userpg->lock;
@@ -4077,11 +4077,11 @@ static void perf_output_read_one(struct
 	values[n++] = perf_event_count(event);
 	if (read_format & PERF_FORMAT_TOTAL_TIME_ENABLED) {
 		values[n++] = enabled +
-			atomic64_read(&event->child_total_time_enabled);
+			atomic64_read_unchecked(&event->child_total_time_enabled);
 	}
 	if (read_format & PERF_FORMAT_TOTAL_TIME_RUNNING) {
 		values[n++] = running +
-			atomic64_read(&event->child_total_time_running);
+			atomic64_read_unchecked(&event->child_total_time_running);
 	}
 	if (read_format & PERF_FORMAT_ID)
 		values[n++] = primary_event_id(event);
@@ -4732,12 +4732,12 @@ static void perf_event_mmap_event(struct
 		 * need to add enough zero bytes after the string to handle
 		 * the 64bit alignment we do later.
 		 */
-		buf = kzalloc(PATH_MAX + sizeof(u64), GFP_KERNEL);
+		buf = kzalloc(PATH_MAX, GFP_KERNEL);
 		if (!buf) {
 			name = strncpy(tmp, "//enomem", sizeof(tmp));
 			goto got_name;
 		}
-		name = d_path(&file->f_path, buf, PATH_MAX);
+		name = d_path(&file->f_path, buf, PATH_MAX - sizeof(u64));
 		if (IS_ERR(name)) {
 			name = strncpy(tmp, "//toolong", sizeof(tmp));
 			goto got_name;
@@ -6103,7 +6103,7 @@ perf_event_alloc(struct perf_event_attr
 	event->parent		= parent_event;
 
 	event->ns		= get_pid_ns(current->nsproxy->pid_ns);
-	event->id		= atomic64_inc_return(&perf_event_id);
+	event->id		= atomic64_inc_return_unchecked(&perf_event_id);
 
 	event->state		= PERF_EVENT_STATE_INACTIVE;
 
@@ -6647,10 +6647,10 @@ static void sync_child_event(struct perf
 	/*
 	 * Add back the child's count to the parent's count:
 	 */
-	atomic64_add(child_val, &parent_event->child_count);
-	atomic64_add(child_event->total_time_enabled,
+	atomic64_add_unchecked(child_val, &parent_event->child_count);
+	atomic64_add_unchecked(child_event->total_time_enabled,
 		     &parent_event->child_total_time_enabled);
-	atomic64_add(child_event->total_time_running,
+	atomic64_add_unchecked(child_event->total_time_running,
 		     &parent_event->child_total_time_running);
 
 	/*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/events/internal.h linux-3.2.71-pax/kernel/events/internal.h
--- linux-3.2.71/kernel/events/internal.h	2013-07-27 11:12:22.459992796 +0200
+++ linux-3.2.71-pax/kernel/events/internal.h	2013-09-01 01:49:35.548220656 +0200
@@ -78,7 +78,7 @@ static unsigned long perf_data_size(stru
 
 static inline void
 __output_copy(struct perf_output_handle *handle,
-		   const void *buf, unsigned int len)
+		   const void *buf, unsigned long len)
 {
 	do {
 		unsigned long size = min_t(unsigned long, handle->size, len);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/exit.c linux-3.2.71-pax/kernel/exit.c
--- linux-3.2.71/kernel/exit.c	2014-04-30 18:53:46.172223429 +0200
+++ linux-3.2.71-pax/kernel/exit.c	2014-04-30 18:53:50.664223419 +0200
@@ -380,7 +380,7 @@ int allow_signal(int sig)
 	 * know it'll be handled, so that they don't get converted to
 	 * SIGKILL or just silently dropped.
 	 */
-	current->sighand->action[(sig)-1].sa.sa_handler = (void __user *)2;
+	current->sighand->action[(sig)-1].sa.sa_handler = (__force void __user *)2;
 	recalc_sigpending();
 	spin_unlock_irq(&current->sighand->siglock);
 	return 0;
@@ -1072,7 +1072,7 @@ SYSCALL_DEFINE1(exit, int, error_code)
  * Take down every thread in the group.  This is called by fatal signals
  * as well as by sys_exit_group (below).
  */
-NORET_TYPE void
+__noreturn void
 do_group_exit(int exit_code)
 {
 	struct signal_struct *sig = current->signal;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/fork.c linux-3.2.71-pax/kernel/fork.c
--- linux-3.2.71/kernel/fork.c	2014-11-05 23:20:30.345389868 +0100
+++ linux-3.2.71-pax/kernel/fork.c	2014-11-05 23:20:50.549398837 +0100
@@ -282,7 +282,7 @@ static struct task_struct *dup_task_stru
 	*stackend = STACK_END_MAGIC;	/* for overflow detection */
 
 #ifdef CONFIG_CC_STACKPROTECTOR
-	tsk->stack_canary = get_random_int();
+	tsk->stack_canary = pax_get_random_long();
 #endif
 
 	/*
@@ -306,13 +306,78 @@ out:
 }
 
 #ifdef CONFIG_MMU
-static int dup_mmap(struct mm_struct *mm, struct mm_struct *oldmm)
+static struct vm_area_struct *dup_vma(struct mm_struct *mm, struct vm_area_struct *mpnt)
+{
+	struct vm_area_struct *tmp;
+	unsigned long charge;
+	struct mempolicy *pol;
+	struct file *file;
+
+	charge = 0;
+	if (mpnt->vm_flags & VM_ACCOUNT) {
+		unsigned long len;
+		len = (mpnt->vm_end - mpnt->vm_start) >> PAGE_SHIFT;
+		if (security_vm_enough_memory(len))
+			goto fail_nomem;
+		charge = len;
+	}
+	tmp = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);
+	if (!tmp)
+		goto fail_nomem;
+	*tmp = *mpnt;
+	tmp->vm_mm = mm;
+	INIT_LIST_HEAD(&tmp->anon_vma_chain);
+	pol = mpol_dup(vma_policy(mpnt));
+	if (IS_ERR(pol))
+		goto fail_nomem_policy;
+	vma_set_policy(tmp, pol);
+	if (anon_vma_fork(tmp, mpnt))
+		goto fail_nomem_anon_vma_fork;
+	tmp->vm_flags &= ~VM_LOCKED;
+	tmp->vm_next = tmp->vm_prev = NULL;
+	tmp->vm_mirror = NULL;
+	file = tmp->vm_file;
+	if (file) {
+		struct inode *inode = file->f_path.dentry->d_inode;
+		struct address_space *mapping = file->f_mapping;
+
+		get_file(file);
+		if (tmp->vm_flags & VM_DENYWRITE)
+			atomic_dec(&inode->i_writecount);
+		mutex_lock(&mapping->i_mmap_mutex);
+		if (tmp->vm_flags & VM_SHARED)
+			mapping->i_mmap_writable++;
+		flush_dcache_mmap_lock(mapping);
+		/* insert tmp into the share list, just after mpnt */
+		vma_prio_tree_add(tmp, mpnt);
+		flush_dcache_mmap_unlock(mapping);
+		mutex_unlock(&mapping->i_mmap_mutex);
+	}
+
+	/*
+	 * Clear hugetlb-related page reserves for children. This only
+	 * affects MAP_PRIVATE mappings. Faults generated by the child
+	 * are not guaranteed to succeed, even if read-only
+	 */
+	if (is_vm_hugetlb_page(tmp))
+		reset_vma_resv_huge_pages(tmp);
+
+	return tmp;
+
+fail_nomem_anon_vma_fork:
+	mpol_put(pol);
+fail_nomem_policy:
+	kmem_cache_free(vm_area_cachep, tmp);
+fail_nomem:
+	vm_unacct_memory(charge);
+	return NULL;
+}
+
+static __latent_entropy int dup_mmap(struct mm_struct *mm, struct mm_struct *oldmm)
 {
 	struct vm_area_struct *mpnt, *tmp, *prev, **pprev;
 	struct rb_node **rb_link, *rb_parent;
 	int retval;
-	unsigned long charge;
-	struct mempolicy *pol;
 
 	down_write(&oldmm->mmap_sem);
 	flush_cache_dup_mm(oldmm);
@@ -324,8 +389,8 @@ static int dup_mmap(struct mm_struct *mm
 	mm->locked_vm = 0;
 	mm->mmap = NULL;
 	mm->mmap_cache = NULL;
-	mm->free_area_cache = oldmm->mmap_base;
-	mm->cached_hole_size = ~0UL;
+	mm->free_area_cache = oldmm->free_area_cache;
+	mm->cached_hole_size = oldmm->cached_hole_size;
 	mm->map_count = 0;
 	cpumask_clear(mm_cpumask(mm));
 	mm->mm_rb = RB_ROOT;
@@ -341,65 +406,18 @@ static int dup_mmap(struct mm_struct *mm
 
 	prev = NULL;
 	for (mpnt = oldmm->mmap; mpnt; mpnt = mpnt->vm_next) {
-		struct file *file;
-
 		if (mpnt->vm_flags & VM_DONTCOPY) {
-			long pages = vma_pages(mpnt);
-			mm->total_vm -= pages;
 			vm_stat_account(mm, mpnt->vm_flags, mpnt->vm_file,
-								-pages);
+								-vma_pages(mpnt));
 			continue;
 		}
-		charge = 0;
-		if (mpnt->vm_flags & VM_ACCOUNT) {
-			unsigned long len;
-			len = (mpnt->vm_end - mpnt->vm_start) >> PAGE_SHIFT;
-			if (security_vm_enough_memory(len))
-				goto fail_nomem;
-			charge = len;
-		}
-		tmp = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);
-		if (!tmp)
-			goto fail_nomem;
-		*tmp = *mpnt;
-		INIT_LIST_HEAD(&tmp->anon_vma_chain);
-		pol = mpol_dup(vma_policy(mpnt));
-		retval = PTR_ERR(pol);
-		if (IS_ERR(pol))
-			goto fail_nomem_policy;
-		vma_set_policy(tmp, pol);
-		tmp->vm_mm = mm;
-		if (anon_vma_fork(tmp, mpnt))
-			goto fail_nomem_anon_vma_fork;
-		tmp->vm_flags &= ~VM_LOCKED;
-		tmp->vm_next = tmp->vm_prev = NULL;
-		file = tmp->vm_file;
-		if (file) {
-			struct inode *inode = file->f_path.dentry->d_inode;
-			struct address_space *mapping = file->f_mapping;
-
-			get_file(file);
-			if (tmp->vm_flags & VM_DENYWRITE)
-				atomic_dec(&inode->i_writecount);
-			mutex_lock(&mapping->i_mmap_mutex);
-			if (tmp->vm_flags & VM_SHARED)
-				mapping->i_mmap_writable++;
-			flush_dcache_mmap_lock(mapping);
-			/* insert tmp into the share list, just after mpnt */
-			vma_prio_tree_add(tmp, mpnt);
-			flush_dcache_mmap_unlock(mapping);
-			mutex_unlock(&mapping->i_mmap_mutex);
+		tmp = dup_vma(mm, mpnt);
+		if (!tmp) {
+			retval = -ENOMEM;
+			goto out;
 		}
 
 		/*
-		 * Clear hugetlb-related page reserves for children. This only
-		 * affects MAP_PRIVATE mappings. Faults generated by the child
-		 * are not guaranteed to succeed, even if read-only
-		 */
-		if (is_vm_hugetlb_page(tmp))
-			reset_vma_resv_huge_pages(tmp);
-
-		/*
 		 * Link in the new vma and copy the page table entries.
 		 */
 		*pprev = tmp;
@@ -420,6 +438,31 @@ static int dup_mmap(struct mm_struct *mm
 		if (retval)
 			goto out;
 	}
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (oldmm->pax_flags & MF_PAX_SEGMEXEC) {
+		struct vm_area_struct *mpnt_m;
+
+		for (mpnt = oldmm->mmap, mpnt_m = mm->mmap; mpnt; mpnt = mpnt->vm_next, mpnt_m = mpnt_m->vm_next) {
+			BUG_ON(!mpnt_m || mpnt_m->vm_mirror || mpnt->vm_mm != oldmm || mpnt_m->vm_mm != mm);
+
+			if (!mpnt->vm_mirror)
+				continue;
+
+			if (mpnt->vm_end <= SEGMEXEC_TASK_SIZE) {
+				BUG_ON(mpnt->vm_mirror->vm_mirror != mpnt);
+				mpnt->vm_mirror = mpnt_m;
+			} else {
+				BUG_ON(mpnt->vm_mirror->vm_mirror == mpnt || mpnt->vm_mirror->vm_mirror->vm_mm != mm);
+				mpnt_m->vm_mirror = mpnt->vm_mirror->vm_mirror;
+				mpnt_m->vm_mirror->vm_mirror = mpnt_m;
+				mpnt->vm_mirror->vm_mirror = mpnt;
+			}
+		}
+		BUG_ON(mpnt_m);
+	}
+#endif
+
 	/* a new mm has just been created */
 	arch_dup_mmap(oldmm, mm);
 	retval = 0;
@@ -428,14 +471,6 @@ out:
 	flush_tlb_mm(oldmm);
 	up_write(&oldmm->mmap_sem);
 	return retval;
-fail_nomem_anon_vma_fork:
-	mpol_put(pol);
-fail_nomem_policy:
-	kmem_cache_free(vm_area_cachep, tmp);
-fail_nomem:
-	retval = -ENOMEM;
-	vm_unacct_memory(charge);
-	goto out;
 }
 
 static inline int mm_alloc_pgd(struct mm_struct *mm)
@@ -832,7 +867,7 @@ static int copy_fs(unsigned long clone_f
 			spin_unlock(&fs->lock);
 			return -EAGAIN;
 		}
-		fs->users++;
+		atomic_inc(&fs->users);
 		spin_unlock(&fs->lock);
 		return 0;
 	}
@@ -1047,7 +1082,7 @@ static void posix_cpu_timers_init(struct
  * parts of the process environment (as per the clone
  * flags). The actual kick-off is left to the caller.
  */
-static struct task_struct *copy_process(unsigned long clone_flags,
+static __latent_entropy struct task_struct *copy_process(unsigned long clone_flags,
 					unsigned long stack_start,
 					struct pt_regs *regs,
 					unsigned long stack_size,
@@ -1510,6 +1545,7 @@ long do_fork(unsigned long clone_flags,
 
 	p = copy_process(clone_flags, stack_start, regs, stack_size,
 			 child_tidptr, NULL, trace);
+	add_latent_entropy();
 	/*
 	 * Do this prior waking up the new thread - the thread pointer
 	 * might get invalid after that point, if the thread exits quickly.
@@ -1598,7 +1634,7 @@ void __init proc_caches_init(void)
 	mm_cachep = kmem_cache_create("mm_struct",
 			sizeof(struct mm_struct), ARCH_MIN_MMSTRUCT_ALIGN,
 			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK, NULL);
-	vm_area_cachep = KMEM_CACHE(vm_area_struct, SLAB_PANIC);
+	vm_area_cachep = KMEM_CACHE(vm_area_struct, SLAB_PANIC | SLAB_NO_SANITIZE);
 	mmap_init();
 	nsproxy_cache_init();
 }
@@ -1637,7 +1673,7 @@ static int unshare_fs(unsigned long unsh
 		return 0;
 
 	/* don't need lock here; in the worst case we'll do useless copy */
-	if (fs->users == 1)
+	if (atomic_read(&fs->users) == 1)
 		return 0;
 
 	*new_fsp = copy_fs_struct(fs);
@@ -1726,7 +1762,7 @@ SYSCALL_DEFINE1(unshare, unsigned long,
 			fs = current->fs;
 			spin_lock(&fs->lock);
 			current->fs = new_fs;
-			if (--fs->users)
+			if (atomic_dec_return(&fs->users))
 				new_fs = NULL;
 			else
 				new_fs = fs;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/futex.c linux-3.2.71-pax/kernel/futex.c
--- linux-3.2.71/kernel/futex.c	2014-12-14 21:13:45.322055303 +0100
+++ linux-3.2.71-pax/kernel/futex.c	2014-12-14 21:13:52.838069344 +0100
@@ -240,6 +240,11 @@ get_futex_key(u32 __user *uaddr, int fsh
 	struct page *page, *page_head;
 	int err, ro = 0;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if ((mm->pax_flags & MF_PAX_SEGMEXEC) && address >= SEGMEXEC_TASK_SIZE)
+		return -EFAULT;
+#endif
+
 	/*
 	 * The futex address must be "naturally" aligned.
 	 */
@@ -438,7 +443,7 @@ static int cmpxchg_futex_value_locked(u3
 
 static int get_futex_value_locked(u32 *dest, u32 __user *from)
 {
-	int ret;
+	unsigned long ret;
 
 	pagefault_disable();
 	ret = __copy_from_user_inatomic(dest, from, sizeof(u32));
@@ -2878,6 +2883,7 @@ static int __init futex_init(void)
 {
 	u32 curval;
 	int i;
+	mm_segment_t oldfs;
 
 	/*
 	 * This will fail and we want it. Some arch implementations do
@@ -2889,8 +2895,11 @@ static int __init futex_init(void)
 	 * implementation, the non-functional ones will return
 	 * -ENOSYS.
 	 */
+	oldfs = get_fs();
+	set_fs(USER_DS);
 	if (cmpxchg_futex_value_locked(&curval, NULL, 0, 0) == -EFAULT)
 		futex_cmpxchg_enabled = 1;
+	set_fs(oldfs);
 
 	for (i = 0; i < ARRAY_SIZE(futex_queues); i++) {
 		plist_head_init(&futex_queues[i].chain);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/futex_compat.c linux-3.2.71-pax/kernel/futex_compat.c
--- linux-3.2.71/kernel/futex_compat.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/futex_compat.c	2013-05-13 13:19:36.671753772 +0200
@@ -31,7 +31,7 @@ fetch_robust_entry(compat_uptr_t *uentry
 	return 0;
 }
 
-static void __user *futex_uaddr(struct robust_list __user *entry,
+static void __user __intentional_overflow(-1) *futex_uaddr(struct robust_list __user *entry,
 				compat_long_t futex_offset)
 {
 	compat_uptr_t base = ptr_to_compat(entry);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/gcov/base.c linux-3.2.71-pax/kernel/gcov/base.c
--- linux-3.2.71/kernel/gcov/base.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/gcov/base.c	2012-07-04 19:24:48.844063008 +0200
@@ -102,11 +102,6 @@ void gcov_enable_events(void)
 }
 
 #ifdef CONFIG_MODULES
-static inline int within(void *addr, void *start, unsigned long size)
-{
-	return ((addr >= start) && (addr < start + size));
-}
-
 /* Update list and generate events when modules are unloaded. */
 static int gcov_module_notifier(struct notifier_block *nb, unsigned long event,
 				void *data)
@@ -121,7 +116,7 @@ static int gcov_module_notifier(struct n
 	prev = NULL;
 	/* Remove entries located in module from linked list. */
 	for (info = gcov_info_head; info; info = info->next) {
-		if (within(info, mod->module_core, mod->core_size)) {
+		if (within_module_core_rw((unsigned long)info, mod)) {
 			if (prev)
 				prev->next = info->next;
 			else
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/hrtimer.c linux-3.2.71-pax/kernel/hrtimer.c
--- linux-3.2.71/kernel/hrtimer.c	2015-08-14 21:48:35.360707910 +0200
+++ linux-3.2.71-pax/kernel/hrtimer.c	2015-08-14 21:48:45.680707359 +0200
@@ -1442,7 +1442,7 @@ void hrtimer_peek_ahead_timers(void)
 	local_irq_restore(flags);
 }
 
-static void run_hrtimer_softirq(struct softirq_action *h)
+static __latent_entropy void run_hrtimer_softirq(void)
 {
 	struct hrtimer_cpu_base *cpu_base = &__get_cpu_var(hrtimer_bases);
 
@@ -1784,7 +1784,7 @@ static int __cpuinit hrtimer_cpu_notify(
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata hrtimers_nb = {
+static struct notifier_block hrtimers_nb = {
 	.notifier_call = hrtimer_cpu_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/irq/manage.c linux-3.2.71-pax/kernel/irq/manage.c
--- linux-3.2.71/kernel/irq/manage.c	2014-07-12 17:42:33.956954215 +0200
+++ linux-3.2.71-pax/kernel/irq/manage.c	2015-02-27 17:23:07.435963834 +0100
@@ -814,7 +814,7 @@ static int irq_thread(void *data)
 			raw_spin_unlock_irq(&desc->lock);
 			action_ret = handler_fn(desc, action);
 			if (action_ret == IRQ_HANDLED)
-				atomic_inc(&desc->threads_handled);
+				atomic_inc_unchecked(&desc->threads_handled);
 		}
 
 		wake = atomic_dec_and_test(&desc->threads_active);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/irq/spurious.c linux-3.2.71-pax/kernel/irq/spurious.c
--- linux-3.2.71/kernel/irq/spurious.c	2014-07-12 17:42:33.956954215 +0200
+++ linux-3.2.71-pax/kernel/irq/spurious.c	2015-02-27 17:22:44.267965071 +0100
@@ -331,7 +331,7 @@ void note_interrupt(unsigned int irq, st
 			 * count. We just care about the count being
 			 * different than the one we saw before.
 			 */
-			handled = atomic_read(&desc->threads_handled);
+			handled = atomic_read_unchecked(&desc->threads_handled);
 			handled |= SPURIOUS_DEFERRED;
 			if (handled != desc->threads_handled_last) {
 				action_ret = IRQ_HANDLED;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/jump_label.c linux-3.2.71-pax/kernel/jump_label.c
--- linux-3.2.71/kernel/jump_label.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/jump_label.c	2012-07-04 19:24:48.844063008 +0200
@@ -13,6 +13,7 @@
 #include <linux/sort.h>
 #include <linux/err.h>
 #include <linux/jump_label.h>
+#include <linux/mm.h>
 
 #ifdef HAVE_JUMP_LABEL
 
@@ -55,7 +56,9 @@ jump_label_sort_entries(struct jump_entr
 
 	size = (((unsigned long)stop - (unsigned long)start)
 					/ sizeof(struct jump_entry));
+	pax_open_kernel();
 	sort(start, size, sizeof(struct jump_entry), jump_label_cmp, NULL);
+	pax_close_kernel();
 }
 
 static void jump_label_update(struct jump_label_key *key, int enable);
@@ -303,10 +306,12 @@ static void jump_label_invalidate_module
 	struct jump_entry *iter_stop = iter_start + mod->num_jump_entries;
 	struct jump_entry *iter;
 
+	pax_open_kernel();
 	for (iter = iter_start; iter < iter_stop; iter++) {
 		if (within_module_init(iter->code, mod))
 			iter->code = 0;
 	}
+	pax_close_kernel();
 }
 
 static int
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/kallsyms.c linux-3.2.71-pax/kernel/kallsyms.c
--- linux-3.2.71/kernel/kallsyms.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/kallsyms.c	2012-07-04 19:24:48.844063008 +0200
@@ -53,12 +53,33 @@ extern const unsigned long kallsyms_mark
 
 static inline int is_kernel_inittext(unsigned long addr)
 {
+	if (system_state != SYSTEM_BOOTING)
+		return 0;
+
 	if (addr >= (unsigned long)_sinittext
 	    && addr <= (unsigned long)_einittext)
 		return 1;
 	return 0;
 }
 
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+#ifdef CONFIG_MODULES
+static inline int is_module_text(unsigned long addr)
+{
+	if ((unsigned long)MODULES_EXEC_VADDR <= addr && addr <= (unsigned long)MODULES_EXEC_END)
+		return 1;
+
+	addr = ktla_ktva(addr);
+	return (unsigned long)MODULES_EXEC_VADDR <= addr && addr <= (unsigned long)MODULES_EXEC_END;
+}
+#else
+static inline int is_module_text(unsigned long addr)
+{
+	return 0;
+}
+#endif
+#endif
+
 static inline int is_kernel_text(unsigned long addr)
 {
 	if ((addr >= (unsigned long)_stext && addr <= (unsigned long)_etext) ||
@@ -69,13 +90,28 @@ static inline int is_kernel_text(unsigne
 
 static inline int is_kernel(unsigned long addr)
 {
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+	if (is_kernel_text(addr) || is_kernel_inittext(addr))
+		return 1;
+
+	if (ktla_ktva((unsigned long)_text) <= addr && addr < (unsigned long)_end)
+#else
 	if (addr >= (unsigned long)_stext && addr <= (unsigned long)_end)
+#endif
+
 		return 1;
 	return in_gate_area_no_mm(addr);
 }
 
 static int is_ksym_addr(unsigned long addr)
 {
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+	if (is_module_text(addr))
+		return 0;
+#endif
+
 	if (all_var)
 		return is_kernel(addr);
 
@@ -454,7 +490,6 @@ static unsigned long get_ksymbol_core(st
 
 static void reset_iter(struct kallsym_iter *iter, loff_t new_pos)
 {
-	iter->name[0] = '\0';
 	iter->nameoff = get_symbol_offset(new_pos);
 	iter->pos = new_pos;
 }
@@ -540,7 +575,7 @@ static int kallsyms_open(struct inode *i
 	struct kallsym_iter *iter;
 	int ret;
 
-	iter = kmalloc(sizeof(*iter), GFP_KERNEL);
+	iter = kzalloc(sizeof(*iter), GFP_KERNEL);
 	if (!iter)
 		return -ENOMEM;
 	reset_iter(iter, 0);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/kexec.c linux-3.2.71-pax/kernel/kexec.c
--- linux-3.2.71/kernel/kexec.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/kexec.c	2012-07-04 19:24:48.844063008 +0200
@@ -1048,7 +1048,8 @@ asmlinkage long compat_sys_kexec_load(un
 				unsigned long flags)
 {
 	struct compat_kexec_segment in;
-	struct kexec_segment out, __user *ksegments;
+	struct kexec_segment out;
+	struct kexec_segment __user *ksegments;
 	unsigned long i, result;
 
 	/* Don't allow clients that don't understand the native
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/kmod.c linux-3.2.71-pax/kernel/kmod.c
--- linux-3.2.71/kernel/kmod.c	2013-06-09 18:04:43.457591746 +0200
+++ linux-3.2.71-pax/kernel/kmod.c	2013-06-09 18:04:48.937591454 +0200
@@ -265,7 +265,7 @@ static int wait_for_helper(void *data)
 		 *
 		 * Thus the __user pointer cast is valid here.
 		 */
-		sys_wait4(pid, (int __user *)&ret, 0, NULL);
+		sys_wait4(pid, (int __force_user *)&ret, 0, NULL);
 
 		/*
 		 * If ret is 0, either ____call_usermodehelper failed and the
@@ -512,7 +512,7 @@ EXPORT_SYMBOL(call_usermodehelper_exec);
 static int proc_cap_handler(struct ctl_table *table, int write,
 			 void __user *buffer, size_t *lenp, loff_t *ppos)
 {
-	struct ctl_table t;
+	ctl_table_no_const t;
 	unsigned long cap_array[_KERNEL_CAPABILITY_U32S];
 	kernel_cap_t new_cap;
 	int err, i;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/kprobes.c linux-3.2.71-pax/kernel/kprobes.c
--- linux-3.2.71/kernel/kprobes.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/kprobes.c	2012-09-20 01:26:06.746669719 +0200
@@ -185,7 +185,7 @@ static kprobe_opcode_t __kprobes *__get_
 	 * kernel image and loaded module images reside. This is required
 	 * so x86_64 can correctly handle the %rip-relative fixups.
 	 */
-	kip->insns = module_alloc(PAGE_SIZE);
+	kip->insns = module_alloc_exec(PAGE_SIZE);
 	if (!kip->insns) {
 		kfree(kip);
 		return NULL;
@@ -225,7 +225,7 @@ static int __kprobes collect_one_slot(st
 		 */
 		if (!list_is_singular(&kip->list)) {
 			list_del(&kip->list);
-			module_free(NULL, kip->insns);
+			module_free_exec(NULL, kip->insns);
 			kfree(kip);
 		}
 		return 1;
@@ -1955,7 +1955,7 @@ static int __init init_kprobes(void)
 {
 	int i, err = 0;
 	unsigned long offset = 0, size = 0;
-	char *modname, namebuf[128];
+	char *modname, namebuf[KSYM_NAME_LEN];
 	const char *symbol_name;
 	void *addr;
 	struct kprobe_blackpoint *kb;
@@ -2081,7 +2081,7 @@ static int __kprobes show_kprobe_addr(st
 	const char *sym = NULL;
 	unsigned int i = *(loff_t *) v;
 	unsigned long offset = 0;
-	char *modname, namebuf[128];
+	char *modname, namebuf[KSYM_NAME_LEN];
 
 	head = &kprobe_table[i];
 	preempt_disable();
@@ -2204,7 +2204,7 @@ static ssize_t write_enabled_file_bool(s
 	       const char __user *user_buf, size_t count, loff_t *ppos)
 {
 	char buf[32];
-	int buf_size;
+	size_t buf_size;
 
 	buf_size = min(count, (sizeof(buf)-1));
 	if (copy_from_user(buf, user_buf, buf_size))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/ksysfs.c linux-3.2.71-pax/kernel/ksysfs.c
--- linux-3.2.71/kernel/ksysfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/ksysfs.c	2013-03-28 01:35:23.500427937 +0100
@@ -156,7 +156,7 @@ static ssize_t notes_read(struct file *f
 	return count;
 }
 
-static struct bin_attribute notes_attr = {
+static bin_attribute_no_const notes_attr __read_only = {
 	.attr = {
 		.name = "notes",
 		.mode = S_IRUGO,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/lockdep.c linux-3.2.71-pax/kernel/lockdep.c
--- linux-3.2.71/kernel/lockdep.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/lockdep.c	2012-07-04 19:24:48.856063008 +0200
@@ -592,6 +592,10 @@ static int static_obj(void *obj)
 		      end   = (unsigned long) &_end,
 		      addr  = (unsigned long) obj;
 
+#ifdef CONFIG_PAX_KERNEXEC
+	start = ktla_ktva(start);
+#endif
+
 	/*
 	 * static variable?
 	 */
@@ -731,6 +735,7 @@ register_lock_class(struct lockdep_map *
 	if (!static_obj(lock->key)) {
 		debug_locks_off();
 		printk("INFO: trying to register non-static key.\n");
+		printk("lock:%pS key:%pS.\n", lock, lock->key);
 		printk("the code is fine but needs lockdep annotation.\n");
 		printk("turning off the locking correctness validator.\n");
 		dump_stack();
@@ -3042,7 +3047,7 @@ static int __lock_acquire(struct lockdep
 		if (!class)
 			return 0;
 	}
-	atomic_inc((atomic_t *)&class->ops);
+	atomic_inc_unchecked((atomic_unchecked_t *)&class->ops);
 	if (very_verbose(class)) {
 		printk("\nacquire class [%p] %s", class->key, class->name);
 		if (class->name_version > 1)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/lockdep_proc.c linux-3.2.71-pax/kernel/lockdep_proc.c
--- linux-3.2.71/kernel/lockdep_proc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/lockdep_proc.c	2012-07-04 19:24:48.856063008 +0200
@@ -39,7 +39,7 @@ static void l_stop(struct seq_file *m, v
 
 static void print_name(struct seq_file *m, struct lock_class *class)
 {
-	char str[128];
+	char str[KSYM_NAME_LEN];
 	const char *name = class->name;
 
 	if (!name) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/module.c linux-3.2.71-pax/kernel/module.c
--- linux-3.2.71/kernel/module.c	2014-06-10 10:59:38.802436242 +0200
+++ linux-3.2.71-pax/kernel/module.c	2014-06-10 10:59:44.182435955 +0200
@@ -119,7 +119,8 @@ static BLOCKING_NOTIFIER_HEAD(module_not
 
 /* Bounds of module allocation, for speeding __module_address.
  * Protected by module_mutex. */
-static unsigned long module_addr_min = -1UL, module_addr_max = 0;
+static unsigned long module_addr_min_rw = -1UL, module_addr_max_rw = 0;
+static unsigned long module_addr_min_rx = -1UL, module_addr_max_rx = 0;
 
 int register_module_notifier(struct notifier_block * nb)
 {
@@ -284,7 +285,7 @@ bool each_symbol_section(bool (*fn)(cons
 		return true;
 
 	list_for_each_entry_rcu(mod, &modules, list) {
-		struct symsearch arr[] = {
+		struct symsearch modarr[] = {
 			{ mod->syms, mod->syms + mod->num_syms, mod->crcs,
 			  NOT_GPL_ONLY, false },
 			{ mod->gpl_syms, mod->gpl_syms + mod->num_gpl_syms,
@@ -306,7 +307,7 @@ bool each_symbol_section(bool (*fn)(cons
 #endif
 		};
 
-		if (each_symbol_in_section(arr, ARRAY_SIZE(arr), mod, fn, data))
+		if (each_symbol_in_section(modarr, ARRAY_SIZE(modarr), mod, fn, data))
 			return true;
 	}
 	return false;
@@ -438,7 +439,7 @@ static inline void __percpu *mod_percpu(
 static int percpu_modalloc(struct module *mod,
 			   unsigned long size, unsigned long align)
 {
-	if (align > PAGE_SIZE) {
+	if (align-1 >= PAGE_SIZE) {
 		printk(KERN_WARNING "%s: per-cpu alignment %li > %li\n",
 		       mod->name, align, PAGE_SIZE);
 		align = PAGE_SIZE;
@@ -1323,7 +1324,7 @@ static void add_notes_attrs(struct modul
 {
 	unsigned int notes, loaded, i;
 	struct module_notes_attrs *notes_attrs;
-	struct bin_attribute *nattr;
+	bin_attribute_no_const *nattr;
 
 	/* failed to create section attributes, so can't create notes */
 	if (!mod->sect_attrs)
@@ -1435,7 +1436,7 @@ static void del_usage_links(struct modul
 static int module_add_modinfo_attrs(struct module *mod)
 {
 	struct module_attribute *attr;
-	struct module_attribute *temp_attr;
+	module_attribute_no_const *temp_attr;
 	int error = 0;
 	int i;
 
@@ -1649,21 +1650,21 @@ static void set_section_ro_nx(void *base
 
 static void unset_module_core_ro_nx(struct module *mod)
 {
-	set_page_attributes(mod->module_core + mod->core_text_size,
-		mod->module_core + mod->core_size,
+	set_page_attributes(mod->module_core_rw,
+		mod->module_core_rw + mod->core_size_rw,
 		set_memory_x);
-	set_page_attributes(mod->module_core,
-		mod->module_core + mod->core_ro_size,
+	set_page_attributes(mod->module_core_rx,
+		mod->module_core_rx + mod->core_size_rx,
 		set_memory_rw);
 }
 
 static void unset_module_init_ro_nx(struct module *mod)
 {
-	set_page_attributes(mod->module_init + mod->init_text_size,
-		mod->module_init + mod->init_size,
+	set_page_attributes(mod->module_init_rw,
+		mod->module_init_rw + mod->init_size_rw,
 		set_memory_x);
-	set_page_attributes(mod->module_init,
-		mod->module_init + mod->init_ro_size,
+	set_page_attributes(mod->module_init_rx,
+		mod->module_init_rx + mod->init_size_rx,
 		set_memory_rw);
 }
 
@@ -1674,14 +1675,14 @@ void set_all_modules_text_rw(void)
 
 	mutex_lock(&module_mutex);
 	list_for_each_entry_rcu(mod, &modules, list) {
-		if ((mod->module_core) && (mod->core_text_size)) {
-			set_page_attributes(mod->module_core,
-						mod->module_core + mod->core_text_size,
+		if ((mod->module_core_rx) && (mod->core_size_rx)) {
+			set_page_attributes(mod->module_core_rx,
+						mod->module_core_rx + mod->core_size_rx,
 						set_memory_rw);
 		}
-		if ((mod->module_init) && (mod->init_text_size)) {
-			set_page_attributes(mod->module_init,
-						mod->module_init + mod->init_text_size,
+		if ((mod->module_init_rx) && (mod->init_size_rx)) {
+			set_page_attributes(mod->module_init_rx,
+						mod->module_init_rx + mod->init_size_rx,
 						set_memory_rw);
 		}
 	}
@@ -1695,14 +1696,14 @@ void set_all_modules_text_ro(void)
 
 	mutex_lock(&module_mutex);
 	list_for_each_entry_rcu(mod, &modules, list) {
-		if ((mod->module_core) && (mod->core_text_size)) {
-			set_page_attributes(mod->module_core,
-						mod->module_core + mod->core_text_size,
+		if ((mod->module_core_rx) && (mod->core_size_rx)) {
+			set_page_attributes(mod->module_core_rx,
+						mod->module_core_rx + mod->core_size_rx,
 						set_memory_ro);
 		}
-		if ((mod->module_init) && (mod->init_text_size)) {
-			set_page_attributes(mod->module_init,
-						mod->module_init + mod->init_text_size,
+		if ((mod->module_init_rx) && (mod->init_size_rx)) {
+			set_page_attributes(mod->module_init_rx,
+						mod->module_init_rx + mod->init_size_rx,
 						set_memory_ro);
 		}
 	}
@@ -1748,16 +1749,19 @@ static void free_module(struct module *m
 
 	/* This may be NULL, but that's OK */
 	unset_module_init_ro_nx(mod);
-	module_free(mod, mod->module_init);
+	module_free(mod, mod->module_init_rw);
+	module_free_exec(mod, mod->module_init_rx);
 	kfree(mod->args);
 	percpu_modfree(mod);
 
 	/* Free lock-classes: */
-	lockdep_free_key_range(mod->module_core, mod->core_size);
+	lockdep_free_key_range(mod->module_core_rx, mod->core_size_rx);
+	lockdep_free_key_range(mod->module_core_rw, mod->core_size_rw);
 
 	/* Finally, free the core (containing the module structure) */
 	unset_module_core_ro_nx(mod);
-	module_free(mod, mod->module_core);
+	module_free_exec(mod, mod->module_core_rx);
+	module_free(mod, mod->module_core_rw);
 
 #ifdef CONFIG_MPU
 	update_protections(current->mm);
@@ -1850,7 +1854,9 @@ static int simplify_symbols(struct modul
 			ksym = resolve_symbol_wait(mod, info, name);
 			/* Ok if resolved.  */
 			if (ksym && !IS_ERR(ksym)) {
+				pax_open_kernel();
 				sym[i].st_value = ksym->value;
+				pax_close_kernel();
 				break;
 			}
 
@@ -1869,7 +1875,9 @@ static int simplify_symbols(struct modul
 				secbase = (unsigned long)mod_percpu(mod);
 			else
 				secbase = info->sechdrs[sym[i].st_shndx].sh_addr;
+			pax_open_kernel();
 			sym[i].st_value += secbase;
+			pax_close_kernel();
 			break;
 		}
 	}
@@ -1977,22 +1985,12 @@ static void layout_sections(struct modul
 			    || s->sh_entsize != ~0UL
 			    || strstarts(sname, ".init"))
 				continue;
-			s->sh_entsize = get_offset(mod, &mod->core_size, s, i);
+			if ((s->sh_flags & SHF_WRITE) || !(s->sh_flags & SHF_ALLOC))
+				s->sh_entsize = get_offset(mod, &mod->core_size_rw, s, i);
+			else
+				s->sh_entsize = get_offset(mod, &mod->core_size_rx, s, i);
 			DEBUGP("\t%s\n", name);
 		}
-		switch (m) {
-		case 0: /* executable */
-			mod->core_size = debug_align(mod->core_size);
-			mod->core_text_size = mod->core_size;
-			break;
-		case 1: /* RO: text and ro-data */
-			mod->core_size = debug_align(mod->core_size);
-			mod->core_ro_size = mod->core_size;
-			break;
-		case 3: /* whole core */
-			mod->core_size = debug_align(mod->core_size);
-			break;
-		}
 	}
 
 	DEBUGP("Init section allocation order:\n");
@@ -2006,23 +2004,13 @@ static void layout_sections(struct modul
 			    || s->sh_entsize != ~0UL
 			    || !strstarts(sname, ".init"))
 				continue;
-			s->sh_entsize = (get_offset(mod, &mod->init_size, s, i)
-					 | INIT_OFFSET_MASK);
+			if ((s->sh_flags & SHF_WRITE) || !(s->sh_flags & SHF_ALLOC))
+				s->sh_entsize = get_offset(mod, &mod->init_size_rw, s, i);
+			else
+				s->sh_entsize = get_offset(mod, &mod->init_size_rx, s, i);
+			s->sh_entsize |= INIT_OFFSET_MASK;
 			DEBUGP("\t%s\n", sname);
 		}
-		switch (m) {
-		case 0: /* executable */
-			mod->init_size = debug_align(mod->init_size);
-			mod->init_text_size = mod->init_size;
-			break;
-		case 1: /* RO: text and ro-data */
-			mod->init_size = debug_align(mod->init_size);
-			mod->init_ro_size = mod->init_size;
-			break;
-		case 3: /* whole init */
-			mod->init_size = debug_align(mod->init_size);
-			break;
-		}
 	}
 }
 
@@ -2187,7 +2175,7 @@ static void layout_symtab(struct module
 
 	/* Put symbol section at end of init part of module. */
 	symsect->sh_flags |= SHF_ALLOC;
-	symsect->sh_entsize = get_offset(mod, &mod->init_size, symsect,
+	symsect->sh_entsize = get_offset(mod, &mod->init_size_rx, symsect,
 					 info->index.sym) | INIT_OFFSET_MASK;
 	DEBUGP("\t%s\n", info->secstrings + symsect->sh_name);
 
@@ -2206,19 +2194,19 @@ static void layout_symtab(struct module
 	}
 
 	/* Append room for core symbols at end of core part. */
-	info->symoffs = ALIGN(mod->core_size, symsect->sh_addralign ?: 1);
-	mod->core_size = info->symoffs + ndst * sizeof(Elf_Sym);
+	info->symoffs = ALIGN(mod->core_size_rx, symsect->sh_addralign ?: 1);
+	mod->core_size_rx = info->symoffs + ndst * sizeof(Elf_Sym);
 
 	/* Put string table section at end of init part of module. */
 	strsect->sh_flags |= SHF_ALLOC;
-	strsect->sh_entsize = get_offset(mod, &mod->init_size, strsect,
+	strsect->sh_entsize = get_offset(mod, &mod->init_size_rx, strsect,
 					 info->index.str) | INIT_OFFSET_MASK;
 	DEBUGP("\t%s\n", info->secstrings + strsect->sh_name);
 
 	/* Append room for core symbols' strings at end of core part. */
-	info->stroffs = mod->core_size;
+	info->stroffs = mod->core_size_rx;
 	__set_bit(0, info->strmap);
-	mod->core_size += bitmap_weight(info->strmap, strsect->sh_size);
+	mod->core_size_rx += bitmap_weight(info->strmap, strsect->sh_size);
 }
 
 static void add_kallsyms(struct module *mod, const struct load_info *info)
@@ -2234,11 +2222,13 @@ static void add_kallsyms(struct module *
 	/* Make sure we get permanent strtab: don't use info->strtab. */
 	mod->strtab = (void *)info->sechdrs[info->index.str].sh_addr;
 
+	pax_open_kernel();
+
 	/* Set types up while we still have access to sections. */
 	for (i = 0; i < mod->num_symtab; i++)
 		mod->symtab[i].st_info = elf_type(&mod->symtab[i], info);
 
-	mod->core_symtab = dst = mod->module_core + info->symoffs;
+	mod->core_symtab = dst = mod->module_core_rx + info->symoffs;
 	src = mod->symtab;
 	for (ndst = i = 0; i < mod->num_symtab; i++) {
 		if (i == 0 ||
@@ -2251,10 +2241,12 @@ static void add_kallsyms(struct module *
 	}
 	mod->core_num_syms = ndst;
 
-	mod->core_strtab = s = mod->module_core + info->stroffs;
+	mod->core_strtab = s = mod->module_core_rx + info->stroffs;
 	for (*s = 0, i = 1; i < info->sechdrs[info->index.str].sh_size; ++i)
 		if (test_bit(i, info->strmap))
 			*++s = mod->strtab[i];
+
+	pax_close_kernel();
 }
 #else
 static inline void layout_symtab(struct module *mod, struct load_info *info)
@@ -2288,17 +2280,33 @@ void * __weak module_alloc(unsigned long
 	return size == 0 ? NULL : vmalloc_exec(size);
 }
 
-static void *module_alloc_update_bounds(unsigned long size)
+static void *module_alloc_update_bounds_rw(unsigned long size)
 {
 	void *ret = module_alloc(size);
 
 	if (ret) {
 		mutex_lock(&module_mutex);
 		/* Update module bounds. */
-		if ((unsigned long)ret < module_addr_min)
-			module_addr_min = (unsigned long)ret;
-		if ((unsigned long)ret + size > module_addr_max)
-			module_addr_max = (unsigned long)ret + size;
+		if ((unsigned long)ret < module_addr_min_rw)
+			module_addr_min_rw = (unsigned long)ret;
+		if ((unsigned long)ret + size > module_addr_max_rw)
+			module_addr_max_rw = (unsigned long)ret + size;
+		mutex_unlock(&module_mutex);
+	}
+	return ret;
+}
+
+static void *module_alloc_update_bounds_rx(unsigned long size)
+{
+	void *ret = module_alloc_exec(size);
+
+	if (ret) {
+		mutex_lock(&module_mutex);
+		/* Update module bounds. */
+		if ((unsigned long)ret < module_addr_min_rx)
+			module_addr_min_rx = (unsigned long)ret;
+		if ((unsigned long)ret + size > module_addr_max_rx)
+			module_addr_max_rx = (unsigned long)ret + size;
 		mutex_unlock(&module_mutex);
 	}
 	return ret;
@@ -2475,8 +2483,14 @@ static struct module *setup_load_info(st
 static int check_modinfo(struct module *mod, struct load_info *info)
 {
 	const char *modmagic = get_modinfo(info, "vermagic");
+	const char *license = get_modinfo(info, "license");
 	int err;
 
+#ifdef CONFIG_PAX_KERNEXEC_PLUGIN_METHOD_OR
+	if (!license || !license_is_gpl_compatible(license))
+		return -ENOEXEC;
+#endif
+
 	/* This is allowed: modprobe --force will invalidate it. */
 	if (!modmagic) {
 		err = try_to_force_load(mod, "bad vermagic");
@@ -2499,7 +2513,7 @@ static int check_modinfo(struct module *
 	}
 
 	/* Set up license info based on the info section */
-	set_license(mod, get_modinfo(info, "license"));
+	set_license(mod, license);
 
 	return 0;
 }
@@ -2593,7 +2607,7 @@ static int move_module(struct module *mo
 	void *ptr;
 
 	/* Do the allocs. */
-	ptr = module_alloc_update_bounds(mod->core_size);
+	ptr = module_alloc_update_bounds_rw(mod->core_size_rw);
 	/*
 	 * The pointer to this block is stored in the module structure
 	 * which is inside the block. Just mark it as not being a
@@ -2603,10 +2617,10 @@ static int move_module(struct module *mo
 	if (!ptr)
 		return -ENOMEM;
 
-	memset(ptr, 0, mod->core_size);
-	mod->module_core = ptr;
+	memset(ptr, 0, mod->core_size_rw);
+	mod->module_core_rw = ptr;
 
-	ptr = module_alloc_update_bounds(mod->init_size);
+	ptr = module_alloc_update_bounds_rw(mod->init_size_rw);
 	/*
 	 * The pointer to this block is stored in the module structure
 	 * which is inside the block. This block doesn't need to be
@@ -2614,12 +2628,39 @@ static int move_module(struct module *mo
 	 * after the module is initialized.
 	 */
 	kmemleak_ignore(ptr);
-	if (!ptr && mod->init_size) {
-		module_free(mod, mod->module_core);
+	if (!ptr && mod->init_size_rw) {
+		module_free(mod, mod->module_core_rw);
+		return -ENOMEM;
+	}
+	memset(ptr, 0, mod->init_size_rw);
+	mod->module_init_rw = ptr;
+
+	ptr = module_alloc_update_bounds_rx(mod->core_size_rx);
+	kmemleak_not_leak(ptr);
+	if (!ptr) {
+		module_free(mod, mod->module_init_rw);
+		module_free(mod, mod->module_core_rw);
+		return -ENOMEM;
+	}
+
+	pax_open_kernel();
+	memset(ptr, 0, mod->core_size_rx);
+	pax_close_kernel();
+	mod->module_core_rx = ptr;
+
+	ptr = module_alloc_update_bounds_rx(mod->init_size_rx);
+	kmemleak_ignore(ptr);
+	if (!ptr && mod->init_size_rx) {
+		module_free_exec(mod, mod->module_core_rx);
+		module_free(mod, mod->module_init_rw);
+		module_free(mod, mod->module_core_rw);
 		return -ENOMEM;
 	}
-	memset(ptr, 0, mod->init_size);
-	mod->module_init = ptr;
+
+	pax_open_kernel();
+	memset(ptr, 0, mod->init_size_rx);
+	pax_close_kernel();
+	mod->module_init_rx = ptr;
 
 	/* Transfer each section which specifies SHF_ALLOC */
 	DEBUGP("final section addresses:\n");
@@ -2630,16 +2671,45 @@ static int move_module(struct module *mo
 		if (!(shdr->sh_flags & SHF_ALLOC))
 			continue;
 
-		if (shdr->sh_entsize & INIT_OFFSET_MASK)
-			dest = mod->module_init
-				+ (shdr->sh_entsize & ~INIT_OFFSET_MASK);
-		else
-			dest = mod->module_core + shdr->sh_entsize;
+		if (shdr->sh_entsize & INIT_OFFSET_MASK) {
+			if ((shdr->sh_flags & SHF_WRITE) || !(shdr->sh_flags & SHF_ALLOC))
+				dest = mod->module_init_rw
+					+ (shdr->sh_entsize & ~INIT_OFFSET_MASK);
+			else
+				dest = mod->module_init_rx
+					+ (shdr->sh_entsize & ~INIT_OFFSET_MASK);
+		} else {
+			if ((shdr->sh_flags & SHF_WRITE) || !(shdr->sh_flags & SHF_ALLOC))
+				dest = mod->module_core_rw + shdr->sh_entsize;
+			else
+				dest = mod->module_core_rx + shdr->sh_entsize;
+		}
+
+		if (shdr->sh_type != SHT_NOBITS) {
+
+#ifdef CONFIG_PAX_KERNEXEC
+#ifdef CONFIG_X86_64
+			if ((shdr->sh_flags & SHF_WRITE) && (shdr->sh_flags & SHF_EXECINSTR))
+				set_memory_x((unsigned long)dest, (shdr->sh_size + PAGE_SIZE) >> PAGE_SHIFT);
+#endif
+			if (!(shdr->sh_flags & SHF_WRITE) && (shdr->sh_flags & SHF_ALLOC)) {
+				pax_open_kernel();
+				memcpy(dest, (void *)shdr->sh_addr, shdr->sh_size);
+				pax_close_kernel();
+			} else
+#endif
 
-		if (shdr->sh_type != SHT_NOBITS)
 			memcpy(dest, (void *)shdr->sh_addr, shdr->sh_size);
+		}
 		/* Update sh_addr to point to copy in image. */
-		shdr->sh_addr = (unsigned long)dest;
+
+#ifdef CONFIG_PAX_KERNEXEC
+		if (shdr->sh_flags & SHF_EXECINSTR)
+			shdr->sh_addr = ktva_ktla((unsigned long)dest);
+		else
+#endif
+
+			shdr->sh_addr = (unsigned long)dest;
 		DEBUGP("\t0x%lx %s\n",
 		       shdr->sh_addr, info->secstrings + shdr->sh_name);
 	}
@@ -2694,12 +2764,12 @@ static void flush_module_icache(const st
 	 * Do it before processing of module parameters, so the module
 	 * can provide parameter accessor functions of its own.
 	 */
-	if (mod->module_init)
-		flush_icache_range((unsigned long)mod->module_init,
-				   (unsigned long)mod->module_init
-				   + mod->init_size);
-	flush_icache_range((unsigned long)mod->module_core,
-			   (unsigned long)mod->module_core + mod->core_size);
+	if (mod->module_init_rx)
+		flush_icache_range((unsigned long)mod->module_init_rx,
+				   (unsigned long)mod->module_init_rx
+				   + mod->init_size_rx);
+	flush_icache_range((unsigned long)mod->module_core_rx,
+			   (unsigned long)mod->module_core_rx + mod->core_size_rx);
 
 	set_fs(old_fs);
 }
@@ -2779,8 +2849,10 @@ static void module_deallocate(struct mod
 {
 	kfree(info->strmap);
 	percpu_modfree(mod);
-	module_free(mod, mod->module_init);
-	module_free(mod, mod->module_core);
+	module_free_exec(mod, mod->module_init_rx);
+	module_free_exec(mod, mod->module_core_rx);
+	module_free(mod, mod->module_init_rw);
+	module_free(mod, mod->module_core_rw);
 }
 
 int __weak module_finalize(const Elf_Ehdr *hdr,
@@ -2974,16 +3046,16 @@ SYSCALL_DEFINE3(init_module, void __user
 			MODULE_STATE_COMING, mod);
 
 	/* Set RO and NX regions for core */
-	set_section_ro_nx(mod->module_core,
-				mod->core_text_size,
-				mod->core_ro_size,
-				mod->core_size);
+	set_section_ro_nx(mod->module_core_rx,
+				mod->core_size_rx,
+				mod->core_size_rx,
+				mod->core_size_rx);
 
 	/* Set RO and NX regions for init */
-	set_section_ro_nx(mod->module_init,
-				mod->init_text_size,
-				mod->init_ro_size,
-				mod->init_size);
+	set_section_ro_nx(mod->module_init_rx,
+				mod->init_size_rx,
+				mod->init_size_rx,
+				mod->init_size_rx);
 
 	do_mod_ctors(mod);
 	/* Start the module */
@@ -3029,11 +3101,12 @@ SYSCALL_DEFINE3(init_module, void __user
 	mod->strtab = mod->core_strtab;
 #endif
 	unset_module_init_ro_nx(mod);
-	module_free(mod, mod->module_init);
-	mod->module_init = NULL;
-	mod->init_size = 0;
-	mod->init_ro_size = 0;
-	mod->init_text_size = 0;
+	module_free(mod, mod->module_init_rw);
+	module_free_exec(mod, mod->module_init_rx);
+	mod->module_init_rw = NULL;
+	mod->module_init_rx = NULL;
+	mod->init_size_rw = 0;
+	mod->init_size_rx = 0;
 	mutex_unlock(&module_mutex);
 
 	return 0;
@@ -3064,10 +3137,16 @@ static const char *get_ksymbol(struct mo
 	unsigned long nextval;
 
 	/* At worse, next value is at end of module */
-	if (within_module_init(addr, mod))
-		nextval = (unsigned long)mod->module_init+mod->init_text_size;
+	if (within_module_init_rx(addr, mod))
+		nextval = (unsigned long)mod->module_init_rx+mod->init_size_rx;
+	else if (within_module_init_rw(addr, mod))
+		nextval = (unsigned long)mod->module_init_rw+mod->init_size_rw;
+	else if (within_module_core_rx(addr, mod))
+		nextval = (unsigned long)mod->module_core_rx+mod->core_size_rx;
+	else if (within_module_core_rw(addr, mod))
+		nextval = (unsigned long)mod->module_core_rw+mod->core_size_rw;
 	else
-		nextval = (unsigned long)mod->module_core+mod->core_text_size;
+		return NULL;
 
 	/* Scan for closest preceding symbol, and next symbol. (ELF
 	   starts real symbols at 1). */
@@ -3315,7 +3394,7 @@ static int m_show(struct seq_file *m, vo
 	char buf[8];
 
 	seq_printf(m, "%s %u",
-		   mod->name, mod->init_size + mod->core_size);
+		   mod->name, mod->init_size_rx + mod->init_size_rw + mod->core_size_rx + mod->core_size_rw);
 	print_unload_info(m, mod);
 
 	/* Informative for users. */
@@ -3324,7 +3403,7 @@ static int m_show(struct seq_file *m, vo
 		   mod->state == MODULE_STATE_COMING ? "Loading":
 		   "Live");
 	/* Used by oprofile and other similar tools. */
-	seq_printf(m, " 0x%pK", mod->module_core);
+	seq_printf(m, " 0x%pK 0x%pK", mod->module_core_rx, mod->module_core_rw);
 
 	/* Taints info */
 	if (mod->taints)
@@ -3419,12 +3498,12 @@ struct module *__module_address(unsigned
 {
 	struct module *mod;
 
-	if (addr < module_addr_min || addr > module_addr_max)
+	if ((addr < module_addr_min_rx || addr > module_addr_max_rx) &&
+	    (addr < module_addr_min_rw || addr > module_addr_max_rw))
 		return NULL;
 
 	list_for_each_entry_rcu(mod, &modules, list)
-		if (within_module_core(addr, mod)
-		    || within_module_init(addr, mod))
+		if (within_module_init(addr, mod) || within_module_core(addr, mod))
 			return mod;
 	return NULL;
 }
@@ -3458,11 +3537,20 @@ bool is_module_text_address(unsigned lon
  */
 struct module *__module_text_address(unsigned long addr)
 {
-	struct module *mod = __module_address(addr);
+	struct module *mod;
+
+#ifdef CONFIG_X86_32
+	addr = ktla_ktva(addr);
+#endif
+
+	if (addr < module_addr_min_rx || addr > module_addr_max_rx)
+		return NULL;
+
+	mod = __module_address(addr);
+
 	if (mod) {
 		/* Make sure it's within the text section. */
-		if (!within(addr, mod->module_init, mod->init_text_size)
-		    && !within(addr, mod->module_core, mod->core_text_size))
+		if (!within_module_init_rx(addr, mod) && !within_module_core_rx(addr, mod))
 			mod = NULL;
 	}
 	return mod;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/mutex.c linux-3.2.71-pax/kernel/mutex.c
--- linux-3.2.71/kernel/mutex.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/mutex.c	2012-07-04 19:24:48.860063008 +0200
@@ -198,7 +198,7 @@ __mutex_lock_common(struct mutex *lock,
 	spin_lock_mutex(&lock->wait_lock, flags);
 
 	debug_mutex_lock_common(lock, &waiter);
-	debug_mutex_add_waiter(lock, &waiter, task_thread_info(task));
+	debug_mutex_add_waiter(lock, &waiter, task);
 
 	/* add waiting tasks to the end of the waitqueue (FIFO): */
 	list_add_tail(&waiter.list, &lock->wait_list);
@@ -227,8 +227,7 @@ __mutex_lock_common(struct mutex *lock,
 		 * TASK_UNINTERRUPTIBLE case.)
 		 */
 		if (unlikely(signal_pending_state(state, task))) {
-			mutex_remove_waiter(lock, &waiter,
-					    task_thread_info(task));
+			mutex_remove_waiter(lock, &waiter, task);
 			mutex_release(&lock->dep_map, 1, ip);
 			spin_unlock_mutex(&lock->wait_lock, flags);
 
@@ -249,7 +248,7 @@ __mutex_lock_common(struct mutex *lock,
 done:
 	lock_acquired(&lock->dep_map, ip);
 	/* got the lock - rejoice! */
-	mutex_remove_waiter(lock, &waiter, current_thread_info());
+	mutex_remove_waiter(lock, &waiter, task);
 	mutex_set_owner(lock);
 
 	/* set it to 0 if there are no waiters left: */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/mutex-debug.c linux-3.2.71-pax/kernel/mutex-debug.c
--- linux-3.2.71/kernel/mutex-debug.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/mutex-debug.c	2012-07-04 19:24:48.860063008 +0200
@@ -49,21 +49,21 @@ void debug_mutex_free_waiter(struct mute
 }
 
 void debug_mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,
-			    struct thread_info *ti)
+			    struct task_struct *task)
 {
 	SMP_DEBUG_LOCKS_WARN_ON(!spin_is_locked(&lock->wait_lock));
 
 	/* Mark the current thread as blocked on the lock: */
-	ti->task->blocked_on = waiter;
+	task->blocked_on = waiter;
 }
 
 void mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter,
-			 struct thread_info *ti)
+			 struct task_struct *task)
 {
 	DEBUG_LOCKS_WARN_ON(list_empty(&waiter->list));
-	DEBUG_LOCKS_WARN_ON(waiter->task != ti->task);
-	DEBUG_LOCKS_WARN_ON(ti->task->blocked_on != waiter);
-	ti->task->blocked_on = NULL;
+	DEBUG_LOCKS_WARN_ON(waiter->task != task);
+	DEBUG_LOCKS_WARN_ON(task->blocked_on != waiter);
+	task->blocked_on = NULL;
 
 	list_del_init(&waiter->list);
 	waiter->task = NULL;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/mutex-debug.h linux-3.2.71-pax/kernel/mutex-debug.h
--- linux-3.2.71/kernel/mutex-debug.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/mutex-debug.h	2012-07-04 19:24:48.860063008 +0200
@@ -20,9 +20,9 @@ extern void debug_mutex_wake_waiter(stru
 extern void debug_mutex_free_waiter(struct mutex_waiter *waiter);
 extern void debug_mutex_add_waiter(struct mutex *lock,
 				   struct mutex_waiter *waiter,
-				   struct thread_info *ti);
+				   struct task_struct *task);
 extern void mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter,
-				struct thread_info *ti);
+				struct task_struct *task);
 extern void debug_mutex_unlock(struct mutex *lock);
 extern void debug_mutex_init(struct mutex *lock, const char *name,
 			     struct lock_class_key *key);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/notifier.c linux-3.2.71-pax/kernel/notifier.c
--- linux-3.2.71/kernel/notifier.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/notifier.c	2013-01-16 21:29:53.750833040 +0100
@@ -5,6 +5,7 @@
 #include <linux/rcupdate.h>
 #include <linux/vmalloc.h>
 #include <linux/reboot.h>
+#include <linux/mm.h>
 
 /*
  *	Notifier list for kernel code which wants to be called
@@ -24,10 +25,12 @@ static int notifier_chain_register(struc
 	while ((*nl) != NULL) {
 		if (n->priority > (*nl)->priority)
 			break;
-		nl = &((*nl)->next);
+		nl = (struct notifier_block **)&((*nl)->next);
 	}
-	n->next = *nl;
+	pax_open_kernel();
+	*(const void **)&n->next = *nl;
 	rcu_assign_pointer(*nl, n);
+	pax_close_kernel();
 	return 0;
 }
 
@@ -39,10 +42,12 @@ static int notifier_chain_cond_register(
 			return 0;
 		if (n->priority > (*nl)->priority)
 			break;
-		nl = &((*nl)->next);
+		nl = (struct notifier_block **)&((*nl)->next);
 	}
-	n->next = *nl;
+	pax_open_kernel();
+	*(const void **)&n->next = *nl;
 	rcu_assign_pointer(*nl, n);
+	pax_close_kernel();
 	return 0;
 }
 
@@ -51,10 +56,12 @@ static int notifier_chain_unregister(str
 {
 	while ((*nl) != NULL) {
 		if ((*nl) == n) {
+			pax_open_kernel();
 			rcu_assign_pointer(*nl, n->next);
+			pax_close_kernel();
 			return 0;
 		}
-		nl = &((*nl)->next);
+		nl = (struct notifier_block **)&((*nl)->next);
 	}
 	return -ENOENT;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/padata.c linux-3.2.71-pax/kernel/padata.c
--- linux-3.2.71/kernel/padata.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/padata.c	2012-07-04 19:24:48.860063008 +0200
@@ -132,10 +132,10 @@ int padata_do_parallel(struct padata_ins
 	padata->pd = pd;
 	padata->cb_cpu = cb_cpu;
 
-	if (unlikely(atomic_read(&pd->seq_nr) == pd->max_seq_nr))
-		atomic_set(&pd->seq_nr, -1);
+	if (unlikely(atomic_read_unchecked(&pd->seq_nr) == pd->max_seq_nr))
+		atomic_set_unchecked(&pd->seq_nr, -1);
 
-	padata->seq_nr = atomic_inc_return(&pd->seq_nr);
+	padata->seq_nr = atomic_inc_return_unchecked(&pd->seq_nr);
 
 	target_cpu = padata_cpu_hash(padata);
 	queue = per_cpu_ptr(pd->pqueue, target_cpu);
@@ -444,7 +444,7 @@ static struct parallel_data *padata_allo
 	padata_init_pqueues(pd);
 	padata_init_squeues(pd);
 	setup_timer(&pd->timer, padata_reorder_timer, (unsigned long)pd);
-	atomic_set(&pd->seq_nr, -1);
+	atomic_set_unchecked(&pd->seq_nr, -1);
 	atomic_set(&pd->reorder_objects, 0);
 	atomic_set(&pd->refcnt, 0);
 	pd->pinst = pinst;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/panic.c linux-3.2.71-pax/kernel/panic.c
--- linux-3.2.71/kernel/panic.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/panic.c	2012-07-04 19:24:48.864063008 +0200
@@ -78,7 +78,11 @@ NORET_TYPE void panic(const char * fmt,
 	va_end(args);
 	printk(KERN_EMERG "Kernel panic - not syncing: %s\n",buf);
 #ifdef CONFIG_DEBUG_BUGVERBOSE
-	dump_stack();
+	/*
+	 * Avoid nested stack-dumping if a panic occurs during oops processing
+	 */
+	if (!oops_in_progress)
+		dump_stack();
 #endif
 
 	/*
@@ -437,7 +441,8 @@ EXPORT_SYMBOL(warn_slowpath_null);
  */
 void __stack_chk_fail(void)
 {
-	panic("stack-protector: Kernel stack is corrupted in: %p\n",
+	dump_stack();
+	panic("stack-protector: Kernel stack is corrupted in: %pS\n",
 		__builtin_return_address(0));
 }
 EXPORT_SYMBOL(__stack_chk_fail);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/pid.c linux-3.2.71-pax/kernel/pid.c
--- linux-3.2.71/kernel/pid.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/pid.c	2012-07-04 19:24:48.864063008 +0200
@@ -45,7 +45,7 @@ struct pid init_struct_pid = INIT_STRUCT
 
 int pid_max = PID_MAX_DEFAULT;
 
-#define RESERVED_PIDS		300
+#define RESERVED_PIDS		500
 
 int pid_max_min = RESERVED_PIDS + 1;
 int pid_max_max = PID_MAX_LIMIT;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/posix-cpu-timers.c linux-3.2.71-pax/kernel/posix-cpu-timers.c
--- linux-3.2.71/kernel/posix-cpu-timers.c	2013-03-29 02:18:30.203676737 +0100
+++ linux-3.2.71-pax/kernel/posix-cpu-timers.c	2013-03-29 02:19:02.135675032 +0100
@@ -1625,14 +1625,14 @@ struct k_clock clock_posix_cpu = {
 
 static __init int init_posix_cpu_timers(void)
 {
-	struct k_clock process = {
+	static struct k_clock process = {
 		.clock_getres	= process_cpu_clock_getres,
 		.clock_get	= process_cpu_clock_get,
 		.timer_create	= process_cpu_timer_create,
 		.nsleep		= process_cpu_nsleep,
 		.nsleep_restart	= process_cpu_nsleep_restart,
 	};
-	struct k_clock thread = {
+	static struct k_clock thread = {
 		.clock_getres	= thread_cpu_clock_getres,
 		.clock_get	= thread_cpu_clock_get,
 		.timer_create	= thread_cpu_timer_create,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/posix-timers.c linux-3.2.71-pax/kernel/posix-timers.c
--- linux-3.2.71/kernel/posix-timers.c	2014-12-14 21:13:45.322055303 +0100
+++ linux-3.2.71-pax/kernel/posix-timers.c	2014-12-14 21:13:52.838069344 +0100
@@ -129,7 +129,7 @@ static DEFINE_SPINLOCK(idr_lock);
  *	    which we beg off on and pass to do_sys_settimeofday().
  */
 
-static struct k_clock posix_clocks[MAX_CLOCKS];
+static struct k_clock *posix_clocks[MAX_CLOCKS];
 
 /*
  * These ones are defined below.
@@ -227,7 +227,7 @@ static int posix_get_boottime(const cloc
  */
 static __init int init_posix_timers(void)
 {
-	struct k_clock clock_realtime = {
+	static struct k_clock clock_realtime = {
 		.clock_getres	= hrtimer_get_res,
 		.clock_get	= posix_clock_realtime_get,
 		.clock_set	= posix_clock_realtime_set,
@@ -239,7 +239,7 @@ static __init int init_posix_timers(void
 		.timer_get	= common_timer_get,
 		.timer_del	= common_timer_del,
 	};
-	struct k_clock clock_monotonic = {
+	static struct k_clock clock_monotonic = {
 		.clock_getres	= hrtimer_get_res,
 		.clock_get	= posix_ktime_get_ts,
 		.nsleep		= common_nsleep,
@@ -249,19 +249,19 @@ static __init int init_posix_timers(void
 		.timer_get	= common_timer_get,
 		.timer_del	= common_timer_del,
 	};
-	struct k_clock clock_monotonic_raw = {
+	static struct k_clock clock_monotonic_raw = {
 		.clock_getres	= hrtimer_get_res,
 		.clock_get	= posix_get_monotonic_raw,
 	};
-	struct k_clock clock_realtime_coarse = {
+	static struct k_clock clock_realtime_coarse = {
 		.clock_getres	= posix_get_coarse_res,
 		.clock_get	= posix_get_realtime_coarse,
 	};
-	struct k_clock clock_monotonic_coarse = {
+	static struct k_clock clock_monotonic_coarse = {
 		.clock_getres	= posix_get_coarse_res,
 		.clock_get	= posix_get_monotonic_coarse,
 	};
-	struct k_clock clock_boottime = {
+	static struct k_clock clock_boottime = {
 		.clock_getres	= hrtimer_get_res,
 		.clock_get	= posix_get_boottime,
 		.nsleep		= common_nsleep,
@@ -473,7 +473,7 @@ void posix_timers_register_clock(const c
 		return;
 	}
 
-	posix_clocks[clock_id] = *new_clock;
+	posix_clocks[clock_id] = new_clock;
 }
 EXPORT_SYMBOL_GPL(posix_timers_register_clock);
 
@@ -519,9 +519,9 @@ static struct k_clock *clockid_to_kclock
 		return (id & CLOCKFD_MASK) == CLOCKFD ?
 			&clock_posix_dynamic : &clock_posix_cpu;
 
-	if (id >= MAX_CLOCKS || !posix_clocks[id].clock_getres)
+	if (id >= MAX_CLOCKS || !posix_clocks[id] || !posix_clocks[id]->clock_getres)
 		return NULL;
-	return &posix_clocks[id];
+	return posix_clocks[id];
 }
 
 static int common_timer_create(struct k_itimer *new_timer)
@@ -539,7 +539,7 @@ SYSCALL_DEFINE3(timer_create, const cloc
 	struct k_clock *kc = clockid_to_kclock(which_clock);
 	struct k_itimer *new_timer;
 	int error, new_timer_id;
-	sigevent_t event;
+	sigevent_t event = { };
 	int it_id_set = IT_ID_NOT_SET;
 
 	if (!kc)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/power/poweroff.c linux-3.2.71-pax/kernel/power/poweroff.c
--- linux-3.2.71/kernel/power/poweroff.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/power/poweroff.c	2012-07-04 19:24:48.868063009 +0200
@@ -37,7 +37,7 @@ static struct sysrq_key_op	sysrq_powerof
 	.enable_mask	= SYSRQ_ENABLE_BOOT,
 };
 
-static int pm_sysrq_init(void)
+static int __init pm_sysrq_init(void)
 {
 	register_sysrq_key('o', &sysrq_poweroff_op);
 	return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/power/process.c linux-3.2.71-pax/kernel/power/process.c
--- linux-3.2.71/kernel/power/process.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/power/process.c	2012-07-04 19:24:48.868063009 +0200
@@ -41,6 +41,7 @@ static int try_to_freeze_tasks(bool sig_
 	u64 elapsed_csecs64;
 	unsigned int elapsed_csecs;
 	bool wakeup = false;
+	bool timedout = false;
 
 	do_gettimeofday(&start);
 
@@ -51,6 +52,8 @@ static int try_to_freeze_tasks(bool sig_
 
 	while (true) {
 		todo = 0;
+		if (time_after(jiffies, end_time))
+			timedout = true;
 		read_lock(&tasklist_lock);
 		do_each_thread(g, p) {
 			if (frozen(p) || !freezable(p))
@@ -71,9 +74,13 @@ static int try_to_freeze_tasks(bool sig_
 			 * try_to_stop() after schedule() in ptrace/signal
 			 * stop sees TIF_FREEZE.
 			 */
-			if (!task_is_stopped_or_traced(p) &&
-			    !freezer_should_skip(p))
+			if (!task_is_stopped_or_traced(p) && !freezer_should_skip(p)) {
 				todo++;
+				if (timedout) {
+					printk(KERN_ERR "Task refusing to freeze:\n");
+					sched_show_task(p);
+				}
+			}
 		} while_each_thread(g, p);
 		read_unlock(&tasklist_lock);
 
@@ -82,7 +89,7 @@ static int try_to_freeze_tasks(bool sig_
 			todo += wq_busy;
 		}
 
-		if (!todo || time_after(jiffies, end_time))
+		if (!todo || timedout)
 			break;
 
 		if (pm_wakeup_pending()) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/profile.c linux-3.2.71-pax/kernel/profile.c
--- linux-3.2.71/kernel/profile.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/profile.c	2012-07-04 19:24:48.868063009 +0200
@@ -39,7 +39,7 @@ struct profile_hit {
 /* Oprofile timer tick hook */
 static int (*timer_hook)(struct pt_regs *) __read_mostly;
 
-static atomic_t *prof_buffer;
+static atomic_unchecked_t *prof_buffer;
 static unsigned long prof_len, prof_shift;
 
 int prof_on __read_mostly;
@@ -281,7 +281,7 @@ static void profile_flip_buffers(void)
 					hits[i].pc = 0;
 				continue;
 			}
-			atomic_add(hits[i].hits, &prof_buffer[hits[i].pc]);
+			atomic_add_unchecked(hits[i].hits, &prof_buffer[hits[i].pc]);
 			hits[i].hits = hits[i].pc = 0;
 		}
 	}
@@ -342,9 +342,9 @@ static void do_profile_hits(int type, vo
 	 * Add the current hit(s) and flush the write-queue out
 	 * to the global buffer:
 	 */
-	atomic_add(nr_hits, &prof_buffer[pc]);
+	atomic_add_unchecked(nr_hits, &prof_buffer[pc]);
 	for (i = 0; i < NR_PROFILE_HIT; ++i) {
-		atomic_add(hits[i].hits, &prof_buffer[hits[i].pc]);
+		atomic_add_unchecked(hits[i].hits, &prof_buffer[hits[i].pc]);
 		hits[i].pc = hits[i].hits = 0;
 	}
 out:
@@ -419,7 +419,7 @@ static void do_profile_hits(int type, vo
 {
 	unsigned long pc;
 	pc = ((unsigned long)__pc - (unsigned long)_stext) >> prof_shift;
-	atomic_add(nr_hits, &prof_buffer[min(pc, prof_len - 1)]);
+	atomic_add_unchecked(nr_hits, &prof_buffer[min(pc, prof_len - 1)]);
 }
 #endif /* !CONFIG_SMP */
 
@@ -517,7 +517,7 @@ read_profile(struct file *file, char __u
 			return -EFAULT;
 		buf++; p++; count--; read++;
 	}
-	pnt = (char *)prof_buffer + p - sizeof(atomic_t);
+	pnt = (char *)prof_buffer + p - sizeof(atomic_unchecked_t);
 	if (copy_to_user(buf, (void *)pnt, count))
 		return -EFAULT;
 	read += count;
@@ -548,7 +548,7 @@ static ssize_t write_profile(struct file
 	}
 #endif
 	profile_discard_flip_buffers();
-	memset(prof_buffer, 0, prof_len * sizeof(atomic_t));
+	memset(prof_buffer, 0, prof_len * sizeof(atomic_unchecked_t));
 	return count;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/ptrace.c linux-3.2.71-pax/kernel/ptrace.c
--- linux-3.2.71/kernel/ptrace.c	2015-08-07 11:37:20.739789898 +0200
+++ linux-3.2.71-pax/kernel/ptrace.c	2015-08-07 11:37:43.027790554 +0200
@@ -523,7 +523,7 @@ int ptrace_readdata(struct task_struct *
 				break;
 			return -EIO;
 		}
-		if (copy_to_user(dst, buf, retval))
+		if (retval > sizeof(buf) || copy_to_user(dst, buf, retval))
 			return -EFAULT;
 		copied += retval;
 		src += retval;
@@ -740,7 +740,7 @@ int ptrace_request(struct task_struct *c
 	bool seized = child->ptrace & PT_SEIZED;
 	int ret = -EIO;
 	siginfo_t siginfo, *si;
-	void __user *datavp = (void __user *) data;
+	void __user *datavp = (__force void __user *) data;
 	unsigned long __user *datalp = datavp;
 	unsigned long flags;
 
@@ -977,7 +977,7 @@ int generic_ptrace_peekdata(struct task_
 	copied = access_process_vm(tsk, addr, &tmp, sizeof(tmp), 0);
 	if (copied != sizeof(tmp))
 		return -EIO;
-	return put_user(tmp, (unsigned long __user *)data);
+	return put_user(tmp, (__force unsigned long __user *)data);
 }
 
 int generic_ptrace_pokedata(struct task_struct *tsk, unsigned long addr,
@@ -1071,7 +1071,7 @@ int compat_ptrace_request(struct task_st
 }
 
 asmlinkage long compat_sys_ptrace(compat_long_t request, compat_long_t pid,
-				  compat_long_t addr, compat_long_t data)
+				  compat_ulong_t addr, compat_ulong_t data)
 {
 	struct task_struct *child;
 	long ret;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/rcutiny.c linux-3.2.71-pax/kernel/rcutiny.c
--- linux-3.2.71/kernel/rcutiny.c	2015-08-14 21:48:35.360707910 +0200
+++ linux-3.2.71-pax/kernel/rcutiny.c	2015-08-14 21:48:45.680707359 +0200
@@ -46,7 +46,7 @@
 struct rcu_ctrlblk;
 static void invoke_rcu_callbacks(void);
 static void __rcu_process_callbacks(struct rcu_ctrlblk *rcp);
-static void rcu_process_callbacks(struct softirq_action *unused);
+static void rcu_process_callbacks(void);
 static void __call_rcu(struct rcu_head *head,
 		       void (*func)(struct rcu_head *rcu),
 		       struct rcu_ctrlblk *rcp);
@@ -191,7 +191,7 @@ static void __rcu_process_callbacks(stru
 	RCU_TRACE(trace_rcu_batch_end(rcp->name, cb_count));
 }
 
-static void rcu_process_callbacks(struct softirq_action *unused)
+static __latent_entropy void rcu_process_callbacks(void)
 {
 	__rcu_process_callbacks(&rcu_sched_ctrlblk);
 	__rcu_process_callbacks(&rcu_bh_ctrlblk);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/rcutiny_plugin.h linux-3.2.71-pax/kernel/rcutiny_plugin.h
--- linux-3.2.71/kernel/rcutiny_plugin.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/rcutiny_plugin.h	2012-07-04 19:24:48.872063009 +0200
@@ -907,7 +907,7 @@ static int rcu_kthread(void *arg)
 		have_rcu_kthread_work = morework;
 		local_irq_restore(flags);
 		if (work)
-			rcu_process_callbacks(NULL);
+			rcu_process_callbacks();
 		schedule_timeout_interruptible(1); /* Leave CPU for others. */
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/rcutorture.c linux-3.2.71-pax/kernel/rcutorture.c
--- linux-3.2.71/kernel/rcutorture.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/rcutorture.c	2012-07-04 19:24:48.872063009 +0200
@@ -138,12 +138,12 @@ static DEFINE_PER_CPU(long [RCU_TORTURE_
 	{ 0 };
 static DEFINE_PER_CPU(long [RCU_TORTURE_PIPE_LEN + 1], rcu_torture_batch) =
 	{ 0 };
-static atomic_t rcu_torture_wcount[RCU_TORTURE_PIPE_LEN + 1];
-static atomic_t n_rcu_torture_alloc;
-static atomic_t n_rcu_torture_alloc_fail;
-static atomic_t n_rcu_torture_free;
-static atomic_t n_rcu_torture_mberror;
-static atomic_t n_rcu_torture_error;
+static atomic_unchecked_t rcu_torture_wcount[RCU_TORTURE_PIPE_LEN + 1];
+static atomic_unchecked_t n_rcu_torture_alloc;
+static atomic_unchecked_t n_rcu_torture_alloc_fail;
+static atomic_unchecked_t n_rcu_torture_free;
+static atomic_unchecked_t n_rcu_torture_mberror;
+static atomic_unchecked_t n_rcu_torture_error;
 static long n_rcu_torture_boost_ktrerror;
 static long n_rcu_torture_boost_rterror;
 static long n_rcu_torture_boost_failure;
@@ -223,11 +223,11 @@ rcu_torture_alloc(void)
 
 	spin_lock_bh(&rcu_torture_lock);
 	if (list_empty(&rcu_torture_freelist)) {
-		atomic_inc(&n_rcu_torture_alloc_fail);
+		atomic_inc_unchecked(&n_rcu_torture_alloc_fail);
 		spin_unlock_bh(&rcu_torture_lock);
 		return NULL;
 	}
-	atomic_inc(&n_rcu_torture_alloc);
+	atomic_inc_unchecked(&n_rcu_torture_alloc);
 	p = rcu_torture_freelist.next;
 	list_del_init(p);
 	spin_unlock_bh(&rcu_torture_lock);
@@ -240,7 +240,7 @@ rcu_torture_alloc(void)
 static void
 rcu_torture_free(struct rcu_torture *p)
 {
-	atomic_inc(&n_rcu_torture_free);
+	atomic_inc_unchecked(&n_rcu_torture_free);
 	spin_lock_bh(&rcu_torture_lock);
 	list_add_tail(&p->rtort_free, &rcu_torture_freelist);
 	spin_unlock_bh(&rcu_torture_lock);
@@ -360,7 +360,7 @@ rcu_torture_cb(struct rcu_head *p)
 	i = rp->rtort_pipe_count;
 	if (i > RCU_TORTURE_PIPE_LEN)
 		i = RCU_TORTURE_PIPE_LEN;
-	atomic_inc(&rcu_torture_wcount[i]);
+	atomic_inc_unchecked(&rcu_torture_wcount[i]);
 	if (++rp->rtort_pipe_count >= RCU_TORTURE_PIPE_LEN) {
 		rp->rtort_mbtest = 0;
 		rcu_torture_free(rp);
@@ -407,7 +407,7 @@ static void rcu_sync_torture_deferred_fr
 		i = rp->rtort_pipe_count;
 		if (i > RCU_TORTURE_PIPE_LEN)
 			i = RCU_TORTURE_PIPE_LEN;
-		atomic_inc(&rcu_torture_wcount[i]);
+		atomic_inc_unchecked(&rcu_torture_wcount[i]);
 		if (++rp->rtort_pipe_count >= RCU_TORTURE_PIPE_LEN) {
 			rp->rtort_mbtest = 0;
 			list_del(&rp->rtort_free);
@@ -872,7 +872,7 @@ rcu_torture_writer(void *arg)
 			i = old_rp->rtort_pipe_count;
 			if (i > RCU_TORTURE_PIPE_LEN)
 				i = RCU_TORTURE_PIPE_LEN;
-			atomic_inc(&rcu_torture_wcount[i]);
+			atomic_inc_unchecked(&rcu_torture_wcount[i]);
 			old_rp->rtort_pipe_count++;
 			cur_ops->deferred_free(old_rp);
 		}
@@ -940,7 +940,7 @@ static void rcu_torture_timer(unsigned l
 		return;
 	}
 	if (p->rtort_mbtest == 0)
-		atomic_inc(&n_rcu_torture_mberror);
+		atomic_inc_unchecked(&n_rcu_torture_mberror);
 	spin_lock(&rand_lock);
 	cur_ops->read_delay(&rand);
 	n_rcu_torture_timers++;
@@ -1001,7 +1001,7 @@ rcu_torture_reader(void *arg)
 			continue;
 		}
 		if (p->rtort_mbtest == 0)
-			atomic_inc(&n_rcu_torture_mberror);
+			atomic_inc_unchecked(&n_rcu_torture_mberror);
 		cur_ops->read_delay(&rand);
 		preempt_disable();
 		pipe_count = p->rtort_pipe_count;
@@ -1060,16 +1060,16 @@ rcu_torture_printk(char *page)
 		       rcu_torture_current,
 		       rcu_torture_current_version,
 		       list_empty(&rcu_torture_freelist),
-		       atomic_read(&n_rcu_torture_alloc),
-		       atomic_read(&n_rcu_torture_alloc_fail),
-		       atomic_read(&n_rcu_torture_free),
-		       atomic_read(&n_rcu_torture_mberror),
+		       atomic_read_unchecked(&n_rcu_torture_alloc),
+		       atomic_read_unchecked(&n_rcu_torture_alloc_fail),
+		       atomic_read_unchecked(&n_rcu_torture_free),
+		       atomic_read_unchecked(&n_rcu_torture_mberror),
 		       n_rcu_torture_boost_ktrerror,
 		       n_rcu_torture_boost_rterror,
 		       n_rcu_torture_boost_failure,
 		       n_rcu_torture_boosts,
 		       n_rcu_torture_timers);
-	if (atomic_read(&n_rcu_torture_mberror) != 0 ||
+	if (atomic_read_unchecked(&n_rcu_torture_mberror) != 0 ||
 	    n_rcu_torture_boost_ktrerror != 0 ||
 	    n_rcu_torture_boost_rterror != 0 ||
 	    n_rcu_torture_boost_failure != 0)
@@ -1077,7 +1077,7 @@ rcu_torture_printk(char *page)
 	cnt += sprintf(&page[cnt], "\n%s%s ", torture_type, TORTURE_FLAG);
 	if (i > 1) {
 		cnt += sprintf(&page[cnt], "!!! ");
-		atomic_inc(&n_rcu_torture_error);
+		atomic_inc_unchecked(&n_rcu_torture_error);
 		WARN_ON_ONCE(1);
 	}
 	cnt += sprintf(&page[cnt], "Reader Pipe: ");
@@ -1091,7 +1091,7 @@ rcu_torture_printk(char *page)
 	cnt += sprintf(&page[cnt], "Free-Block Circulation: ");
 	for (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++) {
 		cnt += sprintf(&page[cnt], " %d",
-			       atomic_read(&rcu_torture_wcount[i]));
+			       atomic_read_unchecked(&rcu_torture_wcount[i]));
 	}
 	cnt += sprintf(&page[cnt], "\n");
 	if (cur_ops->stats)
@@ -1401,7 +1401,7 @@ rcu_torture_cleanup(void)
 
 	if (cur_ops->cleanup)
 		cur_ops->cleanup();
-	if (atomic_read(&n_rcu_torture_error))
+	if (atomic_read_unchecked(&n_rcu_torture_error))
 		rcu_torture_print_module_parms(cur_ops, "End of test: FAILURE");
 	else
 		rcu_torture_print_module_parms(cur_ops, "End of test: SUCCESS");
@@ -1465,17 +1465,17 @@ rcu_torture_init(void)
 
 	rcu_torture_current = NULL;
 	rcu_torture_current_version = 0;
-	atomic_set(&n_rcu_torture_alloc, 0);
-	atomic_set(&n_rcu_torture_alloc_fail, 0);
-	atomic_set(&n_rcu_torture_free, 0);
-	atomic_set(&n_rcu_torture_mberror, 0);
-	atomic_set(&n_rcu_torture_error, 0);
+	atomic_set_unchecked(&n_rcu_torture_alloc, 0);
+	atomic_set_unchecked(&n_rcu_torture_alloc_fail, 0);
+	atomic_set_unchecked(&n_rcu_torture_free, 0);
+	atomic_set_unchecked(&n_rcu_torture_mberror, 0);
+	atomic_set_unchecked(&n_rcu_torture_error, 0);
 	n_rcu_torture_boost_ktrerror = 0;
 	n_rcu_torture_boost_rterror = 0;
 	n_rcu_torture_boost_failure = 0;
 	n_rcu_torture_boosts = 0;
 	for (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++)
-		atomic_set(&rcu_torture_wcount[i], 0);
+		atomic_set_unchecked(&rcu_torture_wcount[i], 0);
 	for_each_possible_cpu(cpu) {
 		for (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++) {
 			per_cpu(rcu_torture_count, cpu)[i] = 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/rcutree.c linux-3.2.71-pax/kernel/rcutree.c
--- linux-3.2.71/kernel/rcutree.c	2013-01-03 19:05:14.788036863 +0100
+++ linux-3.2.71-pax/kernel/rcutree.c	2013-09-27 19:55:18.928209966 +0200
@@ -369,9 +369,9 @@ void rcu_enter_nohz(void)
 	trace_rcu_dyntick("Start");
 	/* CPUs seeing atomic_inc() must see prior RCU read-side crit sects */
 	smp_mb__before_atomic_inc();  /* See above. */
-	atomic_inc(&rdtp->dynticks);
+	atomic_inc_unchecked(&rdtp->dynticks);
 	smp_mb__after_atomic_inc();  /* Force ordering with next sojourn. */
-	WARN_ON_ONCE(atomic_read(&rdtp->dynticks) & 0x1);
+	WARN_ON_ONCE(atomic_read_unchecked(&rdtp->dynticks) & 0x1);
 	local_irq_restore(flags);
 }
 
@@ -393,10 +393,10 @@ void rcu_exit_nohz(void)
 		return;
 	}
 	smp_mb__before_atomic_inc();  /* Force ordering w/previous sojourn. */
-	atomic_inc(&rdtp->dynticks);
+	atomic_inc_unchecked(&rdtp->dynticks);
 	/* CPUs seeing atomic_inc() must see later RCU read-side crit sects */
 	smp_mb__after_atomic_inc();  /* See above. */
-	WARN_ON_ONCE(!(atomic_read(&rdtp->dynticks) & 0x1));
+	WARN_ON_ONCE(!(atomic_read_unchecked(&rdtp->dynticks) & 0x1));
 	trace_rcu_dyntick("End");
 	local_irq_restore(flags);
 }
@@ -413,14 +413,14 @@ void rcu_nmi_enter(void)
 	struct rcu_dynticks *rdtp = &__get_cpu_var(rcu_dynticks);
 
 	if (rdtp->dynticks_nmi_nesting == 0 &&
-	    (atomic_read(&rdtp->dynticks) & 0x1))
+	    (atomic_read_unchecked(&rdtp->dynticks) & 0x1))
 		return;
 	rdtp->dynticks_nmi_nesting++;
 	smp_mb__before_atomic_inc();  /* Force delay from prior write. */
-	atomic_inc(&rdtp->dynticks);
+	atomic_inc_unchecked(&rdtp->dynticks);
 	/* CPUs seeing atomic_inc() must see later RCU read-side crit sects */
 	smp_mb__after_atomic_inc();  /* See above. */
-	WARN_ON_ONCE(!(atomic_read(&rdtp->dynticks) & 0x1));
+	WARN_ON_ONCE(!(atomic_read_unchecked(&rdtp->dynticks) & 0x1));
 }
 
 /**
@@ -439,9 +439,9 @@ void rcu_nmi_exit(void)
 		return;
 	/* CPUs seeing atomic_inc() must see prior RCU read-side crit sects */
 	smp_mb__before_atomic_inc();  /* See above. */
-	atomic_inc(&rdtp->dynticks);
+	atomic_inc_unchecked(&rdtp->dynticks);
 	smp_mb__after_atomic_inc();  /* Force delay to next write. */
-	WARN_ON_ONCE(atomic_read(&rdtp->dynticks) & 0x1);
+	WARN_ON_ONCE(atomic_read_unchecked(&rdtp->dynticks) & 0x1);
 }
 
 /**
@@ -476,7 +476,7 @@ void rcu_irq_exit(void)
  */
 static int dyntick_save_progress_counter(struct rcu_data *rdp)
 {
-	rdp->dynticks_snap = atomic_add_return(0, &rdp->dynticks->dynticks);
+	rdp->dynticks_snap = atomic_add_return_unchecked(0, &rdp->dynticks->dynticks);
 	return 0;
 }
 
@@ -491,7 +491,7 @@ static int rcu_implicit_dynticks_qs(stru
 	unsigned int curr;
 	unsigned int snap;
 
-	curr = (unsigned int)atomic_add_return(0, &rdp->dynticks->dynticks);
+	curr = (unsigned int)atomic_add_return_unchecked(0, &rdp->dynticks->dynticks);
 	snap = (unsigned int)rdp->dynticks_snap;
 
 	/*
@@ -1554,7 +1554,7 @@ __rcu_process_callbacks(struct rcu_state
 /*
  * Do RCU core processing for the current CPU.
  */
-static void rcu_process_callbacks(struct softirq_action *unused)
+static __latent_entropy void rcu_process_callbacks(void)
 {
 	trace_rcu_utilization("Start RCU core");
 	__rcu_process_callbacks(&rcu_sched_state,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/rcutree.h linux-3.2.71-pax/kernel/rcutree.h
--- linux-3.2.71/kernel/rcutree.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/rcutree.h	2012-07-04 19:24:48.876063008 +0200
@@ -86,7 +86,7 @@
 struct rcu_dynticks {
 	int dynticks_nesting;	/* Track irq/process nesting level. */
 	int dynticks_nmi_nesting; /* Track NMI nesting level. */
-	atomic_t dynticks;	/* Even value for dynticks-idle, else odd. */
+	atomic_unchecked_t dynticks;	/* Even value for dynticks-idle, else odd. */
 };
 
 /* RCU's kthread states for tracing. */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/rcutree_plugin.h linux-3.2.71-pax/kernel/rcutree_plugin.h
--- linux-3.2.71/kernel/rcutree_plugin.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/rcutree_plugin.h	2012-07-04 19:24:48.876063008 +0200
@@ -842,7 +842,7 @@ void synchronize_rcu_expedited(void)
 
 	/* Clean up and exit. */
 	smp_mb(); /* ensure expedited GP seen before counter increment. */
-	ACCESS_ONCE(sync_rcu_preempt_exp_count)++;
+	ACCESS_ONCE_RW(sync_rcu_preempt_exp_count)++;
 unlock_mb_ret:
 	mutex_unlock(&sync_rcu_preempt_exp_mutex);
 mb_ret:
@@ -1815,8 +1815,8 @@ EXPORT_SYMBOL_GPL(synchronize_sched_expe
 
 #else /* #ifndef CONFIG_SMP */
 
-static atomic_t sync_sched_expedited_started = ATOMIC_INIT(0);
-static atomic_t sync_sched_expedited_done = ATOMIC_INIT(0);
+static atomic_unchecked_t sync_sched_expedited_started = ATOMIC_INIT(0);
+static atomic_unchecked_t sync_sched_expedited_done = ATOMIC_INIT(0);
 
 static int synchronize_sched_expedited_cpu_stop(void *data)
 {
@@ -1871,7 +1871,7 @@ void synchronize_sched_expedited(void)
 	int firstsnap, s, snap, trycount = 0;
 
 	/* Note that atomic_inc_return() implies full memory barrier. */
-	firstsnap = snap = atomic_inc_return(&sync_sched_expedited_started);
+	firstsnap = snap = atomic_inc_return_unchecked(&sync_sched_expedited_started);
 	get_online_cpus();
 
 	/*
@@ -1892,7 +1892,7 @@ void synchronize_sched_expedited(void)
 		}
 
 		/* Check to see if someone else did our work for us. */
-		s = atomic_read(&sync_sched_expedited_done);
+		s = atomic_read_unchecked(&sync_sched_expedited_done);
 		if (UINT_CMP_GE((unsigned)s, (unsigned)firstsnap)) {
 			smp_mb(); /* ensure test happens before caller kfree */
 			return;
@@ -1907,7 +1907,7 @@ void synchronize_sched_expedited(void)
 		 * grace period works for us.
 		 */
 		get_online_cpus();
-		snap = atomic_read(&sync_sched_expedited_started) - 1;
+		snap = atomic_read_unchecked(&sync_sched_expedited_started) - 1;
 		smp_mb(); /* ensure read is before try_stop_cpus(). */
 	}
 
@@ -1918,12 +1918,12 @@ void synchronize_sched_expedited(void)
 	 * than we did beat us to the punch.
 	 */
 	do {
-		s = atomic_read(&sync_sched_expedited_done);
+		s = atomic_read_unchecked(&sync_sched_expedited_done);
 		if (UINT_CMP_GE((unsigned)s, (unsigned)snap)) {
 			smp_mb(); /* ensure test happens before caller kfree */
 			break;
 		}
-	} while (atomic_cmpxchg(&sync_sched_expedited_done, s, snap) != s);
+	} while (atomic_cmpxchg_unchecked(&sync_sched_expedited_done, s, snap) != s);
 
 	put_online_cpus();
 }
@@ -1985,7 +1985,7 @@ int rcu_needs_cpu(int cpu)
 	for_each_online_cpu(thatcpu) {
 		if (thatcpu == cpu)
 			continue;
-		snap = atomic_add_return(0, &per_cpu(rcu_dynticks,
+		snap = atomic_add_return_unchecked(0, &per_cpu(rcu_dynticks,
 						     thatcpu).dynticks);
 		smp_mb(); /* Order sampling of snap with end of grace period. */
 		if ((snap & 0x1) != 0) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/rcutree_trace.c linux-3.2.71-pax/kernel/rcutree_trace.c
--- linux-3.2.71/kernel/rcutree_trace.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/rcutree_trace.c	2012-07-04 19:24:48.876063008 +0200
@@ -69,7 +69,7 @@ static void print_one_rcu_data(struct se
 		   rdp->qs_pending);
 #ifdef CONFIG_NO_HZ
 	seq_printf(m, " dt=%d/%d/%d df=%lu",
-		   atomic_read(&rdp->dynticks->dynticks),
+		   atomic_read_unchecked(&rdp->dynticks->dynticks),
 		   rdp->dynticks->dynticks_nesting,
 		   rdp->dynticks->dynticks_nmi_nesting,
 		   rdp->dynticks_fqs);
@@ -143,7 +143,7 @@ static void print_one_rcu_data_csv(struc
 		   rdp->qs_pending);
 #ifdef CONFIG_NO_HZ
 	seq_printf(m, ",%d,%d,%d,%lu",
-		   atomic_read(&rdp->dynticks->dynticks),
+		   atomic_read_unchecked(&rdp->dynticks->dynticks),
 		   rdp->dynticks->dynticks_nesting,
 		   rdp->dynticks->dynticks_nmi_nesting,
 		   rdp->dynticks_fqs);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/rtmutex-tester.c linux-3.2.71-pax/kernel/rtmutex-tester.c
--- linux-3.2.71/kernel/rtmutex-tester.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/rtmutex-tester.c	2012-07-04 19:24:48.876063008 +0200
@@ -20,7 +20,7 @@
 #define MAX_RT_TEST_MUTEXES	8
 
 static spinlock_t rttest_lock;
-static atomic_t rttest_event;
+static atomic_unchecked_t rttest_event;
 
 struct test_thread_data {
 	int			opcode;
@@ -61,7 +61,7 @@ static int handle_op(struct test_thread_
 
 	case RTTEST_LOCKCONT:
 		td->mutexes[td->opdata] = 1;
-		td->event = atomic_add_return(1, &rttest_event);
+		td->event = atomic_add_return_unchecked(1, &rttest_event);
 		return 0;
 
 	case RTTEST_RESET:
@@ -74,7 +74,7 @@ static int handle_op(struct test_thread_
 		return 0;
 
 	case RTTEST_RESETEVENT:
-		atomic_set(&rttest_event, 0);
+		atomic_set_unchecked(&rttest_event, 0);
 		return 0;
 
 	default:
@@ -91,9 +91,9 @@ static int handle_op(struct test_thread_
 			return ret;
 
 		td->mutexes[id] = 1;
-		td->event = atomic_add_return(1, &rttest_event);
+		td->event = atomic_add_return_unchecked(1, &rttest_event);
 		rt_mutex_lock(&mutexes[id]);
-		td->event = atomic_add_return(1, &rttest_event);
+		td->event = atomic_add_return_unchecked(1, &rttest_event);
 		td->mutexes[id] = 4;
 		return 0;
 
@@ -104,9 +104,9 @@ static int handle_op(struct test_thread_
 			return ret;
 
 		td->mutexes[id] = 1;
-		td->event = atomic_add_return(1, &rttest_event);
+		td->event = atomic_add_return_unchecked(1, &rttest_event);
 		ret = rt_mutex_lock_interruptible(&mutexes[id], 0);
-		td->event = atomic_add_return(1, &rttest_event);
+		td->event = atomic_add_return_unchecked(1, &rttest_event);
 		td->mutexes[id] = ret ? 0 : 4;
 		return ret ? -EINTR : 0;
 
@@ -115,9 +115,9 @@ static int handle_op(struct test_thread_
 		if (id < 0 || id >= MAX_RT_TEST_MUTEXES || td->mutexes[id] != 4)
 			return ret;
 
-		td->event = atomic_add_return(1, &rttest_event);
+		td->event = atomic_add_return_unchecked(1, &rttest_event);
 		rt_mutex_unlock(&mutexes[id]);
-		td->event = atomic_add_return(1, &rttest_event);
+		td->event = atomic_add_return_unchecked(1, &rttest_event);
 		td->mutexes[id] = 0;
 		return 0;
 
@@ -164,7 +164,7 @@ void schedule_rt_mutex_test(struct rt_mu
 			break;
 
 		td->mutexes[dat] = 2;
-		td->event = atomic_add_return(1, &rttest_event);
+		td->event = atomic_add_return_unchecked(1, &rttest_event);
 		break;
 
 	default:
@@ -184,7 +184,7 @@ void schedule_rt_mutex_test(struct rt_mu
 			return;
 
 		td->mutexes[dat] = 3;
-		td->event = atomic_add_return(1, &rttest_event);
+		td->event = atomic_add_return_unchecked(1, &rttest_event);
 		break;
 
 	case RTTEST_LOCKNOWAIT:
@@ -196,7 +196,7 @@ void schedule_rt_mutex_test(struct rt_mu
 			return;
 
 		td->mutexes[dat] = 1;
-		td->event = atomic_add_return(1, &rttest_event);
+		td->event = atomic_add_return_unchecked(1, &rttest_event);
 		return;
 
 	default:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/sched_autogroup.c linux-3.2.71-pax/kernel/sched_autogroup.c
--- linux-3.2.71/kernel/sched_autogroup.c	2015-05-10 09:22:39.135493142 +0200
+++ linux-3.2.71-pax/kernel/sched_autogroup.c	2015-05-10 09:23:09.551494794 +0200
@@ -7,7 +7,7 @@
 
 unsigned int __read_mostly sysctl_sched_autogroup_enabled = 1;
 static struct autogroup autogroup_default;
-static atomic_t autogroup_seq_nr;
+static atomic_unchecked_t autogroup_seq_nr;
 
 static void __init autogroup_init(struct task_struct *init_task)
 {
@@ -78,7 +78,7 @@ static inline struct autogroup *autogrou
 
 	kref_init(&ag->kref);
 	init_rwsem(&ag->lock);
-	ag->id = atomic_inc_return(&autogroup_seq_nr);
+	ag->id = atomic_inc_return_unchecked(&autogroup_seq_nr);
 	ag->tg = tg;
 #ifdef CONFIG_RT_GROUP_SCHED
 	/*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/sched.c linux-3.2.71-pax/kernel/sched.c
--- linux-3.2.71/kernel/sched.c	2015-05-10 09:22:39.135493142 +0200
+++ linux-3.2.71-pax/kernel/sched.c	2015-05-10 09:23:09.551494794 +0200
@@ -5050,7 +5050,7 @@ EXPORT_SYMBOL(wait_for_completion_interr
  * The return value is -ERESTARTSYS if interrupted, 0 if timed out,
  * positive (at least 1, or number of jiffies left till timeout) if completed.
  */
-long __sched
+long __sched __intentional_overflow(-1)
 wait_for_completion_interruptible_timeout(struct completion *x,
 					  unsigned long timeout)
 {
@@ -5067,7 +5067,7 @@ EXPORT_SYMBOL(wait_for_completion_interr
  *
  * The return value is -ERESTARTSYS if interrupted, 0 if completed.
  */
-int __sched wait_for_completion_killable(struct completion *x)
+int __sched __intentional_overflow(-1) wait_for_completion_killable(struct completion *x)
 {
 	long t = wait_for_common(x, MAX_SCHEDULE_TIMEOUT, TASK_KILLABLE);
 	if (t == -ERESTARTSYS)
@@ -5088,7 +5088,7 @@ EXPORT_SYMBOL(wait_for_completion_killab
  * The return value is -ERESTARTSYS if interrupted, 0 if timed out,
  * positive (at least 1, or number of jiffies left till timeout) if completed.
  */
-long __sched
+long __sched __intentional_overflow(-1)
 wait_for_completion_killable_timeout(struct completion *x,
 				     unsigned long timeout)
 {
@@ -6632,7 +6632,7 @@ static void unthrottle_offline_cfs_rqs(s
 
 #if defined(CONFIG_SCHED_DEBUG) && defined(CONFIG_SYSCTL)
 
-static struct ctl_table sd_ctl_dir[] = {
+static ctl_table_no_const sd_ctl_dir[] __read_only = {
 	{
 		.procname	= "sched_domain",
 		.mode		= 0555,
@@ -6649,17 +6649,17 @@ static struct ctl_table sd_ctl_root[] =
 	{}
 };
 
-static struct ctl_table *sd_alloc_ctl_entry(int n)
+static ctl_table_no_const *sd_alloc_ctl_entry(int n)
 {
-	struct ctl_table *entry =
+	ctl_table_no_const *entry =
 		kcalloc(n, sizeof(struct ctl_table), GFP_KERNEL);
 
 	return entry;
 }
 
-static void sd_free_ctl_entry(struct ctl_table **tablep)
+static void sd_free_ctl_entry(ctl_table_no_const *tablep)
 {
-	struct ctl_table *entry;
+	ctl_table_no_const *entry;
 
 	/*
 	 * In the intermediate directories, both the child directory and
@@ -6667,22 +6667,25 @@ static void sd_free_ctl_entry(struct ctl
 	 * will always be set. In the lowest directory the names are
 	 * static strings and all have proc handlers.
 	 */
-	for (entry = *tablep; entry->mode; entry++) {
-		if (entry->child)
-			sd_free_ctl_entry(&entry->child);
+	for (entry = tablep; entry->mode; entry++) {
+		if (entry->child) {
+			sd_free_ctl_entry(entry->child);
+			pax_open_kernel();
+			entry->child = NULL;
+			pax_close_kernel();
+		}
 		if (entry->proc_handler == NULL)
 			kfree(entry->procname);
 	}
 
-	kfree(*tablep);
-	*tablep = NULL;
+	kfree(tablep);
 }
 
 static int min_load_idx = 0;
 static int max_load_idx = CPU_LOAD_IDX_MAX-1;
 
 static void
-set_table_entry(struct ctl_table *entry,
+set_table_entry(ctl_table_no_const *entry,
 		const char *procname, void *data, int maxlen,
 		mode_t mode, proc_handler *proc_handler,
 		bool load_idx)
@@ -6702,7 +6705,7 @@ set_table_entry(struct ctl_table *entry,
 static struct ctl_table *
 sd_alloc_ctl_domain_table(struct sched_domain *sd)
 {
-	struct ctl_table *table = sd_alloc_ctl_entry(13);
+	ctl_table_no_const *table = sd_alloc_ctl_entry(13);
 
 	if (table == NULL)
 		return NULL;
@@ -6737,9 +6740,9 @@ sd_alloc_ctl_domain_table(struct sched_d
 	return table;
 }
 
-static ctl_table *sd_alloc_ctl_cpu_table(int cpu)
+static ctl_table_no_const *sd_alloc_ctl_cpu_table(int cpu)
 {
-	struct ctl_table *entry, *table;
+	ctl_table_no_const *entry, *table;
 	struct sched_domain *sd;
 	int domain_num = 0, i;
 	char buf[32];
@@ -6766,11 +6769,13 @@ static struct ctl_table_header *sd_sysct
 static void register_sched_domain_sysctl(void)
 {
 	int i, cpu_num = num_possible_cpus();
-	struct ctl_table *entry = sd_alloc_ctl_entry(cpu_num + 1);
+	ctl_table_no_const *entry = sd_alloc_ctl_entry(cpu_num + 1);
 	char buf[32];
 
 	WARN_ON(sd_ctl_dir[0].child);
+	pax_open_kernel();
 	sd_ctl_dir[0].child = entry;
+	pax_close_kernel();
 
 	if (entry == NULL)
 		return;
@@ -6793,8 +6798,12 @@ static void unregister_sched_domain_sysc
 	if (sd_sysctl_header)
 		unregister_sysctl_table(sd_sysctl_header);
 	sd_sysctl_header = NULL;
-	if (sd_ctl_dir[0].child)
-		sd_free_ctl_entry(&sd_ctl_dir[0].child);
+	if (sd_ctl_dir[0].child) {
+		sd_free_ctl_entry(sd_ctl_dir[0].child);
+		pax_open_kernel();
+		sd_ctl_dir[0].child = NULL;
+		pax_close_kernel();
+	}
 }
 #else
 static void register_sched_domain_sysctl(void)
@@ -6892,7 +6901,7 @@ migration_call(struct notifier_block *nf
  * happens before everything else.  This has to be lower priority than
  * the notifier in the perf_event subsystem, though.
  */
-static struct notifier_block __cpuinitdata migration_notifier = {
+static struct notifier_block migration_notifier = {
 	.notifier_call = migration_call,
 	.priority = CPU_PRI_MIGRATION,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/sched_fair.c linux-3.2.71-pax/kernel/sched_fair.c
--- linux-3.2.71/kernel/sched_fair.c	2014-04-02 03:15:45.571672341 +0200
+++ linux-3.2.71-pax/kernel/sched_fair.c	2014-04-02 03:15:49.391672138 +0200
@@ -4803,7 +4803,7 @@ static void nohz_idle_balance(int this_c
  * run_rebalance_domains is triggered when needed from the scheduler tick.
  * Also triggered for nohz idle balancing (with nohz_balancing_kick set).
  */
-static void run_rebalance_domains(struct softirq_action *h)
+static __latent_entropy void run_rebalance_domains(void)
 {
 	int this_cpu = smp_processor_id();
 	struct rq *this_rq = cpu_rq(this_cpu);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/signal.c linux-3.2.71-pax/kernel/signal.c
--- linux-3.2.71/kernel/signal.c	2013-04-30 00:45:09.635714477 +0200
+++ linux-3.2.71-pax/kernel/signal.c	2013-04-30 00:31:29.807758250 +0200
@@ -45,12 +45,12 @@ static struct kmem_cache *sigqueue_cache
 
 int print_fatal_signals __read_mostly;
 
-static void __user *sig_handler(struct task_struct *t, int sig)
+static __sighandler_t sig_handler(struct task_struct *t, int sig)
 {
 	return t->sighand->action[sig - 1].sa.sa_handler;
 }
 
-static int sig_handler_ignored(void __user *handler, int sig)
+static int sig_handler_ignored(__sighandler_t handler, int sig)
 {
 	/* Is it explicitly or implicitly ignored? */
 	return handler == SIG_IGN ||
@@ -60,7 +60,7 @@ static int sig_handler_ignored(void __us
 static int sig_task_ignored(struct task_struct *t, int sig,
 		int from_ancestor_ns)
 {
-	void __user *handler;
+	__sighandler_t handler;
 
 	handler = sig_handler(t, sig);
 
@@ -491,7 +491,7 @@ flush_signal_handlers(struct task_struct
 
 int unhandled_signal(struct task_struct *tsk, int sig)
 {
-	void __user *handler = tsk->sighand->action[sig-1].sa.sa_handler;
+	__sighandler_t handler = tsk->sighand->action[sig-1].sa.sa_handler;
 	if (is_global_init(tsk))
 		return 1;
 	if (handler != SIG_IGN && handler != SIG_DFL)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/smp.c linux-3.2.71-pax/kernel/smp.c
--- linux-3.2.71/kernel/smp.c	2013-02-09 01:12:40.780782286 +0100
+++ linux-3.2.71-pax/kernel/smp.c	2013-02-20 01:19:15.966027318 +0100
@@ -75,7 +75,7 @@ hotplug_cfd(struct notifier_block *nfb,
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata hotplug_cfd_notifier = {
+static struct notifier_block hotplug_cfd_notifier = {
 	.notifier_call		= hotplug_cfd,
 };
 
@@ -591,22 +591,22 @@ int smp_call_function(smp_call_func_t fu
 }
 EXPORT_SYMBOL(smp_call_function);
 
-void ipi_call_lock(void)
+void ipi_call_lock(void) __acquires(call_function.lock)
 {
 	raw_spin_lock(&call_function.lock);
 }
 
-void ipi_call_unlock(void)
+void ipi_call_unlock(void) __releases(call_function.lock)
 {
 	raw_spin_unlock(&call_function.lock);
 }
 
-void ipi_call_lock_irq(void)
+void ipi_call_lock_irq(void) __acquires(call_function.lock)
 {
 	raw_spin_lock_irq(&call_function.lock);
 }
 
-void ipi_call_unlock_irq(void)
+void ipi_call_unlock_irq(void) __releases(call_function.lock)
 {
 	raw_spin_unlock_irq(&call_function.lock);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/softirq.c linux-3.2.71-pax/kernel/softirq.c
--- linux-3.2.71/kernel/softirq.c	2015-08-07 11:37:20.739789898 +0200
+++ linux-3.2.71-pax/kernel/softirq.c	2015-08-07 11:37:43.027790554 +0200
@@ -52,11 +52,11 @@ irq_cpustat_t irq_stat[NR_CPUS] ____cach
 EXPORT_SYMBOL(irq_stat);
 #endif
 
-static struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp;
+static struct softirq_action softirq_vec[NR_SOFTIRQS] __read_only __aligned(PAGE_SIZE);
 
 DEFINE_PER_CPU(struct task_struct *, ksoftirqd);
 
-char *softirq_to_name[NR_SOFTIRQS] = {
+const char * const softirq_to_name[NR_SOFTIRQS] = {
 	"HI", "TIMER", "NET_TX", "NET_RX", "BLOCK", "BLOCK_IOPOLL",
 	"TASKLET", "SCHED", "HRTIMER", "RCU"
 };
@@ -241,7 +241,7 @@ restart:
 			kstat_incr_softirqs_this_cpu(vec_nr);
 
 			trace_softirq_entry(vec_nr);
-			h->action(h);
+			h->action();
 			trace_softirq_exit(vec_nr);
 			if (unlikely(prev_count != preempt_count())) {
 				printk(KERN_ERR "huh, entered softirq %u %s %p"
@@ -393,7 +393,7 @@ void raise_softirq(unsigned int nr)
 	local_irq_restore(flags);
 }
 
-void open_softirq(int nr, void (*action)(struct softirq_action *))
+void __init open_softirq(int nr, void (*action)(void))
 {
 	softirq_vec[nr].action = action;
 }
@@ -449,7 +449,7 @@ void __tasklet_hi_schedule_first(struct
 
 EXPORT_SYMBOL(__tasklet_hi_schedule_first);
 
-static void tasklet_action(struct softirq_action *a)
+static __latent_entropy void tasklet_action(void)
 {
 	struct tasklet_struct *list;
 
@@ -484,7 +484,7 @@ static void tasklet_action(struct softir
 	}
 }
 
-static void tasklet_hi_action(struct softirq_action *a)
+static __latent_entropy void tasklet_hi_action(void)
 {
 	struct tasklet_struct *list;
 
@@ -720,7 +720,7 @@ static int __cpuinit remote_softirq_cpu_
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata remote_softirq_cpu_notifier = {
+static struct notifier_block remote_softirq_cpu_notifier = {
 	.notifier_call	= remote_softirq_cpu_notify,
 };
 
@@ -902,7 +902,7 @@ static int __cpuinit cpu_callback(struct
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata cpu_nfb = {
+static struct notifier_block cpu_nfb = {
 	.notifier_call = cpu_callback
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/stop_machine.c linux-3.2.71-pax/kernel/stop_machine.c
--- linux-3.2.71/kernel/stop_machine.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/stop_machine.c	2013-02-20 01:19:15.974027317 +0100
@@ -362,7 +362,7 @@ static int __cpuinit cpu_stop_cpu_callba
  * cpu notifiers.  It currently shares the same priority as sched
  * migration_notifier.
  */
-static struct notifier_block __cpuinitdata cpu_stop_cpu_notifier = {
+static struct notifier_block cpu_stop_cpu_notifier = {
 	.notifier_call	= cpu_stop_cpu_callback,
 	.priority	= 10,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/sys.c linux-3.2.71-pax/kernel/sys.c
--- linux-3.2.71/kernel/sys.c	2013-06-21 21:22:07.702352277 +0200
+++ linux-3.2.71-pax/kernel/sys.c	2013-06-21 21:21:57.526352821 +0200
@@ -1270,19 +1270,19 @@ SYSCALL_DEFINE1(olduname, struct oldold_
 		return -EFAULT;
 
 	down_read(&uts_sem);
-	error = __copy_to_user(&name->sysname, &utsname()->sysname,
+	error = __copy_to_user(name->sysname, &utsname()->sysname,
 			       __OLD_UTS_LEN);
 	error |= __put_user(0, name->sysname + __OLD_UTS_LEN);
-	error |= __copy_to_user(&name->nodename, &utsname()->nodename,
+	error |= __copy_to_user(name->nodename, &utsname()->nodename,
 				__OLD_UTS_LEN);
 	error |= __put_user(0, name->nodename + __OLD_UTS_LEN);
-	error |= __copy_to_user(&name->release, &utsname()->release,
+	error |= __copy_to_user(name->release, &utsname()->release,
 				__OLD_UTS_LEN);
 	error |= __put_user(0, name->release + __OLD_UTS_LEN);
-	error |= __copy_to_user(&name->version, &utsname()->version,
+	error |= __copy_to_user(name->version, &utsname()->version,
 				__OLD_UTS_LEN);
 	error |= __put_user(0, name->version + __OLD_UTS_LEN);
-	error |= __copy_to_user(&name->machine, &utsname()->machine,
+	error |= __copy_to_user(name->machine, &utsname()->machine,
 				__OLD_UTS_LEN);
 	error |= __put_user(0, name->machine + __OLD_UTS_LEN);
 	up_read(&uts_sem);
@@ -1747,7 +1747,7 @@ SYSCALL_DEFINE5(prctl, int, option, unsi
 			error = get_dumpable(me->mm);
 			break;
 		case PR_SET_DUMPABLE:
-			if (arg2 < 0 || arg2 > 1) {
+			if (arg2 > 1) {
 				error = -EINVAL;
 				break;
 			}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/sysctl_binary.c linux-3.2.71-pax/kernel/sysctl_binary.c
--- linux-3.2.71/kernel/sysctl_binary.c	2013-03-29 02:18:30.203676737 +0100
+++ linux-3.2.71-pax/kernel/sysctl_binary.c	2013-03-29 02:19:02.135675032 +0100
@@ -989,7 +989,7 @@ static ssize_t bin_intvec(struct file *f
 		int i;
 
 		set_fs(KERNEL_DS);
-		result = vfs_read(file, buffer, BUFSZ - 1, &pos);
+		result = vfs_read(file, (char __force_user *)buffer, BUFSZ - 1, &pos);
 		set_fs(old_fs);
 		if (result < 0)
 			goto out_kfree;
@@ -1034,7 +1034,7 @@ static ssize_t bin_intvec(struct file *f
 		}
 
 		set_fs(KERNEL_DS);
-		result = vfs_write(file, buffer, str - buffer, &pos);
+		result = vfs_write(file, (const char __force_user *)buffer, str - buffer, &pos);
 		set_fs(old_fs);
 		if (result < 0)
 			goto out_kfree;
@@ -1067,7 +1067,7 @@ static ssize_t bin_ulongvec(struct file
 		int i;
 
 		set_fs(KERNEL_DS);
-		result = vfs_read(file, buffer, BUFSZ - 1, &pos);
+		result = vfs_read(file, (char __force_user *)buffer, BUFSZ - 1, &pos);
 		set_fs(old_fs);
 		if (result < 0)
 			goto out_kfree;
@@ -1112,7 +1112,7 @@ static ssize_t bin_ulongvec(struct file
 		}
 
 		set_fs(KERNEL_DS);
-		result = vfs_write(file, buffer, str - buffer, &pos);
+		result = vfs_write(file, (const char __force_user *)buffer, str - buffer, &pos);
 		set_fs(old_fs);
 		if (result < 0)
 			goto out_kfree;
@@ -1138,7 +1138,7 @@ static ssize_t bin_uuid(struct file *fil
 		int i;
 
 		set_fs(KERNEL_DS);
-		result = vfs_read(file, buf, sizeof(buf) - 1, &pos);
+		result = vfs_read(file, (char __force_user *)buf, sizeof(buf) - 1, &pos);
 		set_fs(old_fs);
 		if (result < 0)
 			goto out;
@@ -1185,7 +1185,7 @@ static ssize_t bin_dn_node_address(struc
 		__le16 dnaddr;
 
 		set_fs(KERNEL_DS);
-		result = vfs_read(file, buf, sizeof(buf) - 1, &pos);
+		result = vfs_read(file, (char __force_user *)buf, sizeof(buf) - 1, &pos);
 		set_fs(old_fs);
 		if (result < 0)
 			goto out;
@@ -1234,7 +1234,7 @@ static ssize_t bin_dn_node_address(struc
 				le16_to_cpu(dnaddr) & 0x3ff);
 
 		set_fs(KERNEL_DS);
-		result = vfs_write(file, buf, len, &pos);
+		result = vfs_write(file, (const char __force_user *)buf, len, &pos);
 		set_fs(old_fs);
 		if (result < 0)
 			goto out;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/sysctl.c linux-3.2.71-pax/kernel/sysctl.c
--- linux-3.2.71/kernel/sysctl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/sysctl.c	2013-03-28 03:49:59.747996728 +0100
@@ -220,6 +220,20 @@ extern struct ctl_table epoll_table[];
 int sysctl_legacy_va_layout;
 #endif
 
+#ifdef CONFIG_PAX_SOFTMODE
+static ctl_table pax_table[] = {
+	{
+		.procname	= "softmode",
+		.data		= &pax_softmode,
+		.maxlen		= sizeof(unsigned int),
+		.mode		= 0600,
+		.proc_handler	= &proc_dointvec,
+	},
+
+	{ }
+};
+#endif
+
 /* The default sysctl tables: */
 
 static struct ctl_table root_table[] = {
@@ -266,6 +280,15 @@ static int max_extfrag_threshold = 1000;
 #endif
 
 static struct ctl_table kern_table[] = {
+
+#ifdef CONFIG_PAX_SOFTMODE
+	{
+		.procname	= "pax",
+		.mode		= 0500,
+		.child		= pax_table,
+	},
+#endif
+
 	{
 		.procname	= "sched_child_runs_first",
 		.data		= &sysctl_sched_child_runs_first,
@@ -1216,6 +1239,13 @@ static struct ctl_table vm_table[] = {
 		.proc_handler	= proc_dointvec_minmax,
 		.extra1		= &zero,
 	},
+	{
+		.procname	= "heap_stack_gap",
+		.data		= &sysctl_heap_stack_gap,
+		.maxlen		= sizeof(sysctl_heap_stack_gap),
+		.mode		= 0644,
+		.proc_handler	= proc_doulongvec_minmax,
+	},
 #else
 	{
 		.procname	= "nr_trim_pages",
@@ -1732,7 +1762,9 @@ int sysctl_perm(struct ctl_table_root *r
 static void sysctl_set_parent(struct ctl_table *parent, struct ctl_table *table)
 {
 	for (; table->procname; table++) {
-		table->parent = parent;
+		pax_open_kernel();
+		*(void **)&table->parent = (ctl_table_no_const *)parent;
+		pax_close_kernel();
 		if (table->child)
 			sysctl_set_parent(table, table->child);
 	}
@@ -1856,7 +1888,8 @@ struct ctl_table_header *__register_sysc
 	const struct ctl_path *path, struct ctl_table *table)
 {
 	struct ctl_table_header *header;
-	struct ctl_table *new, **prevp;
+	struct ctl_table **prevp;
+	ctl_table_no_const *new;
 	unsigned int n, npath;
 	struct ctl_table_set *set;
 
@@ -1877,7 +1910,7 @@ struct ctl_table_header *__register_sysc
 	if (!header)
 		return NULL;
 
-	new = (struct ctl_table *) (header + 1);
+	new = (ctl_table_no_const *) (header + 1);
 
 	/* Now connect the dots */
 	prevp = &header->ctl_table;
@@ -2229,6 +2262,8 @@ static int proc_put_long(void __user **b
 	len = strlen(tmp);
 	if (len > *size)
 		len = *size;
+	if (len > sizeof(tmp))
+		len = sizeof(tmp);
 	if (copy_to_user(*buf, tmp, len))
 		return -EFAULT;
 	*size -= len;
@@ -2393,7 +2428,7 @@ int proc_dointvec(struct ctl_table *tabl
 static int proc_taint(struct ctl_table *table, int write,
 			       void __user *buffer, size_t *lenp, loff_t *ppos)
 {
-	struct ctl_table t;
+	ctl_table_no_const t;
 	unsigned long tmptaint = get_taint();
 	int err;
 
@@ -2545,8 +2580,11 @@ static int __do_proc_doulongvec_minmax(v
 			*i = val;
 		} else {
 			val = convdiv * (*i) / convmul;
-			if (!first)
+			if (!first) {
 				err = proc_put_char(&buffer, &left, '\t');
+				if (err)
+					break;
+			}
 			err = proc_put_long(&buffer, &left, val, false);
 			if (err)
 				break;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/time/alarmtimer.c linux-3.2.71-pax/kernel/time/alarmtimer.c
--- linux-3.2.71/kernel/time/alarmtimer.c	2014-11-05 23:20:30.345389868 +0100
+++ linux-3.2.71-pax/kernel/time/alarmtimer.c	2014-11-05 23:20:50.549398837 +0100
@@ -807,7 +807,7 @@ static int __init alarmtimer_init(void)
 	struct platform_device *pdev;
 	int error = 0;
 	int i;
-	struct k_clock alarm_clock = {
+	static struct k_clock alarm_clock = {
 		.clock_getres	= alarm_clock_getres,
 		.clock_get	= alarm_clock_get,
 		.timer_create	= alarm_timer_create,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/time/tick-broadcast.c linux-3.2.71-pax/kernel/time/tick-broadcast.c
--- linux-3.2.71/kernel/time/tick-broadcast.c	2013-05-14 13:33:40.664285670 +0200
+++ linux-3.2.71-pax/kernel/time/tick-broadcast.c	2013-05-14 13:33:46.596285354 +0200
@@ -120,7 +120,7 @@ int tick_device_uses_broadcast(struct cl
 		 * then clear the broadcast bit.
 		 */
 		if (!(dev->features & CLOCK_EVT_FEAT_C3STOP)) {
-			int cpu = smp_processor_id();
+			cpu = smp_processor_id();
 
 			cpumask_clear_cpu(cpu, tick_get_broadcast_mask());
 			tick_broadcast_clear_oneshot(cpu);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/time/timer_stats.c linux-3.2.71-pax/kernel/time/timer_stats.c
--- linux-3.2.71/kernel/time/timer_stats.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/time/timer_stats.c	2012-07-04 19:24:48.892063008 +0200
@@ -116,7 +116,7 @@ static ktime_t time_start, time_stop;
 static unsigned long nr_entries;
 static struct entry entries[MAX_ENTRIES];
 
-static atomic_t overflow_count;
+static atomic_unchecked_t overflow_count;
 
 /*
  * The entries are in a hash-table, for fast lookup:
@@ -140,7 +140,7 @@ static void reset_entries(void)
 	nr_entries = 0;
 	memset(entries, 0, sizeof(entries));
 	memset(tstat_hash_table, 0, sizeof(tstat_hash_table));
-	atomic_set(&overflow_count, 0);
+	atomic_set_unchecked(&overflow_count, 0);
 }
 
 static struct entry *alloc_entry(void)
@@ -261,7 +261,7 @@ void timer_stats_update_stats(void *time
 	if (likely(entry))
 		entry->count++;
 	else
-		atomic_inc(&overflow_count);
+		atomic_inc_unchecked(&overflow_count);
 
  out_unlock:
 	raw_spin_unlock_irqrestore(lock, flags);
@@ -300,9 +300,9 @@ static int tstats_show(struct seq_file *
 
 	seq_puts(m, "Timer Stats Version: v0.2\n");
 	seq_printf(m, "Sample period: %ld.%03ld s\n", period.tv_sec, ms);
-	if (atomic_read(&overflow_count))
+	if (atomic_read_unchecked(&overflow_count))
 		seq_printf(m, "Overflow: %d entries\n",
-			atomic_read(&overflow_count));
+			atomic_read_unchecked(&overflow_count));
 
 	for (i = 0; i < nr_entries; i++) {
 		entry = entries + i;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/timer.c linux-3.2.71-pax/kernel/timer.c
--- linux-3.2.71/kernel/timer.c	2014-06-10 10:59:38.802436242 +0200
+++ linux-3.2.71-pax/kernel/timer.c	2014-06-10 10:59:44.182435955 +0200
@@ -1308,7 +1308,7 @@ void update_process_times(int user_tick)
 /*
  * This function runs timers and the timer-tq in bottom half context.
  */
-static void run_timer_softirq(struct softirq_action *h)
+static __latent_entropy void run_timer_softirq(void)
 {
 	struct tvec_base *base = __this_cpu_read(tvec_bases);
 
@@ -1435,7 +1435,7 @@ static void process_timeout(unsigned lon
  *
  * In all cases the return value is guaranteed to be non-negative.
  */
-signed long __sched schedule_timeout(signed long timeout)
+signed long __sched __intentional_overflow(-1) schedule_timeout(signed long timeout)
 {
 	struct timer_list timer;
 	unsigned long expire;
@@ -1727,7 +1727,7 @@ static int __cpuinit timer_cpu_notify(st
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata timers_nb = {
+static struct notifier_block timers_nb = {
 	.notifier_call	= timer_cpu_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/trace/blktrace.c linux-3.2.71-pax/kernel/trace/blktrace.c
--- linux-3.2.71/kernel/trace/blktrace.c	2014-04-30 18:53:46.220223429 +0200
+++ linux-3.2.71-pax/kernel/trace/blktrace.c	2014-04-30 18:53:50.664223419 +0200
@@ -324,7 +324,7 @@ static ssize_t blk_dropped_read(struct f
 	struct blk_trace *bt = filp->private_data;
 	char buf[16];
 
-	snprintf(buf, sizeof(buf), "%u\n", atomic_read(&bt->dropped));
+	snprintf(buf, sizeof(buf), "%u\n", atomic_read_unchecked(&bt->dropped));
 
 	return simple_read_from_buffer(buffer, count, ppos, buf, strlen(buf));
 }
@@ -389,7 +389,7 @@ static int blk_subbuf_start_callback(str
 		return 1;
 
 	bt = buf->chan->private_data;
-	atomic_inc(&bt->dropped);
+	atomic_inc_unchecked(&bt->dropped);
 	return 0;
 }
 
@@ -490,7 +490,7 @@ int do_blk_trace_setup(struct request_qu
 
 	bt->dir = dir;
 	bt->dev = dev;
-	atomic_set(&bt->dropped, 0);
+	atomic_set_unchecked(&bt->dropped, 0);
 
 	ret = -EIO;
 	bt->dropped_file = debugfs_create_file("dropped", 0444, dir, bt,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/trace/ftrace.c linux-3.2.71-pax/kernel/trace/ftrace.c
--- linux-3.2.71/kernel/trace/ftrace.c	2015-05-10 09:22:39.155493144 +0200
+++ linux-3.2.71-pax/kernel/trace/ftrace.c	2015-05-10 09:35:13.767534129 +0200
@@ -1616,12 +1616,17 @@ ftrace_code_disable(struct module *mod,
 	if (unlikely(ftrace_disabled))
 		return 0;
 
+	ret = ftrace_arch_code_modify_prepare();
+	FTRACE_WARN_ON(ret);
+	if (ret)
+		return 0;
+
 	ret = ftrace_make_nop(mod, rec, MCOUNT_ADDR);
+	FTRACE_WARN_ON(ftrace_arch_code_modify_post_process());
 	if (ret) {
 		ftrace_bug(ret, ip);
-		return 0;
 	}
-	return 1;
+	return ret ? 0 : 1;
 }
 
 /*
@@ -2713,7 +2718,7 @@ static void ftrace_free_entry_rcu(struct
 
 int
 register_ftrace_function_probe(char *glob, struct ftrace_probe_ops *ops,
-			      void *data)
+				void *data)
 {
 	struct ftrace_func_probe *entry;
 	struct ftrace_page *pg;
@@ -4062,8 +4067,6 @@ ftrace_enable_sysctl(struct ctl_table *t
 
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 
-static struct notifier_block ftrace_suspend_notifier;
-
 int ftrace_graph_entry_stub(struct ftrace_graph_ent *trace)
 {
 	return 0;
@@ -4105,7 +4108,7 @@ static int alloc_retstack_tasklist(struc
 
 		if (t->ret_stack == NULL) {
 			atomic_set(&t->tracing_graph_pause, 0);
-			atomic_set(&t->trace_overrun, 0);
+			atomic_set_unchecked(&t->trace_overrun, 0);
 			t->curr_ret_stack = -1;
 			/* Make sure the tasks see the -1 first: */
 			smp_wmb();
@@ -4208,6 +4211,10 @@ ftrace_suspend_notifier_call(struct noti
 	return NOTIFY_DONE;
 }
 
+static struct notifier_block ftrace_suspend_notifier = {
+	.notifier_call = ftrace_suspend_notifier_call
+};
+
 /* Just a place holder for function graph */
 static struct ftrace_ops fgraph_ops __read_mostly = {
 	.func		= ftrace_stub,
@@ -4251,7 +4258,6 @@ int register_ftrace_graph(trace_func_gra
 		goto out;
 	}
 
-	ftrace_suspend_notifier.notifier_call = ftrace_suspend_notifier_call;
 	register_pm_notifier(&ftrace_suspend_notifier);
 
 	ftrace_graph_active++;
@@ -4305,7 +4311,7 @@ static void
 graph_init_task(struct task_struct *t, struct ftrace_ret_stack *ret_stack)
 {
 	atomic_set(&t->tracing_graph_pause, 0);
-	atomic_set(&t->trace_overrun, 0);
+	atomic_set_unchecked(&t->trace_overrun, 0);
 	t->ftrace_timestamp = 0;
 	/* make curr_ret_stack visible before we add the ret_stack */
 	smp_wmb();
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/trace/ring_buffer.c linux-3.2.71-pax/kernel/trace/ring_buffer.c
--- linux-3.2.71/kernel/trace/ring_buffer.c	2014-11-05 23:20:30.349389870 +0100
+++ linux-3.2.71-pax/kernel/trace/ring_buffer.c	2015-04-03 01:51:28.908414977 +0200
@@ -376,9 +376,9 @@ struct buffer_data_page {
  */
 struct buffer_page {
 	struct list_head list;		/* list of buffer pages */
-	local_t		 write;		/* index for next write */
+	local_unchecked_t	 write;		/* index for next write */
 	unsigned	 read;		/* index for next read */
-	local_t		 entries;	/* entries on this page */
+	local_unchecked_t	 entries;	/* entries on this page */
 	unsigned long	 real_end;	/* real end of data */
 	struct buffer_data_page *page;	/* Actual data page */
 };
@@ -489,11 +489,11 @@ struct ring_buffer_per_cpu {
 	unsigned long			lost_events;
 	unsigned long			last_overrun;
 	local_t				entries_bytes;
-	local_t				commit_overrun;
-	local_t				overrun;
+	local_unchecked_t		commit_overrun;
+	local_unchecked_t		overrun;
 	local_t				entries;
 	local_t				committing;
-	local_t				commits;
+	local_unchecked_t		commits;
 	unsigned long			read;
 	unsigned long			read_bytes;
 	u64				write_stamp;
@@ -884,8 +884,8 @@ static int rb_tail_page_update(struct ri
 	 *
 	 * We add a counter to the write field to denote this.
 	 */
-	old_write = local_add_return(RB_WRITE_INTCNT, &next_page->write);
-	old_entries = local_add_return(RB_WRITE_INTCNT, &next_page->entries);
+	old_write = local_add_return_unchecked(RB_WRITE_INTCNT, &next_page->write);
+	old_entries = local_add_return_unchecked(RB_WRITE_INTCNT, &next_page->entries);
 
 	/*
 	 * Just make sure we have seen our old_write and synchronize
@@ -913,8 +913,8 @@ static int rb_tail_page_update(struct ri
 		 * cmpxchg to only update if an interrupt did not already
 		 * do it for us. If the cmpxchg fails, we don't care.
 		 */
-		(void)local_cmpxchg(&next_page->write, old_write, val);
-		(void)local_cmpxchg(&next_page->entries, old_entries, eval);
+		(void)local_cmpxchg_unchecked(&next_page->write, old_write, val);
+		(void)local_cmpxchg_unchecked(&next_page->entries, old_entries, eval);
 
 		/*
 		 * No need to worry about races with clearing out the commit.
@@ -1481,7 +1481,7 @@ rb_iter_head_event(struct ring_buffer_it
 
 static inline unsigned long rb_page_write(struct buffer_page *bpage)
 {
-	return local_read(&bpage->write) & RB_WRITE_MASK;
+	return local_read_unchecked(&bpage->write) & RB_WRITE_MASK;
 }
 
 static inline unsigned rb_page_commit(struct buffer_page *bpage)
@@ -1491,7 +1491,7 @@ static inline unsigned rb_page_commit(st
 
 static inline unsigned long rb_page_entries(struct buffer_page *bpage)
 {
-	return local_read(&bpage->entries) & RB_WRITE_MASK;
+	return local_read_unchecked(&bpage->entries) & RB_WRITE_MASK;
 }
 
 /* Size is determined by what has been committed */
@@ -1709,7 +1709,7 @@ rb_handle_head_page(struct ring_buffer_p
 		 * it is our responsibility to update
 		 * the counters.
 		 */
-		local_add(entries, &cpu_buffer->overrun);
+		local_add_unchecked(entries, &cpu_buffer->overrun);
 		local_sub(BUF_PAGE_SIZE, &cpu_buffer->entries_bytes);
 
 		/*
@@ -1859,7 +1859,7 @@ rb_reset_tail(struct ring_buffer_per_cpu
 		if (tail == BUF_PAGE_SIZE)
 			tail_page->real_end = 0;
 
-		local_sub(length, &tail_page->write);
+		local_sub_unchecked(length, &tail_page->write);
 		return;
 	}
 
@@ -1894,7 +1894,7 @@ rb_reset_tail(struct ring_buffer_per_cpu
 		rb_event_set_padding(event);
 
 		/* Set the write back to the previous setting */
-		local_sub(length, &tail_page->write);
+		local_sub_unchecked(length, &tail_page->write);
 		return;
 	}
 
@@ -1906,7 +1906,7 @@ rb_reset_tail(struct ring_buffer_per_cpu
 
 	/* Set write to end of buffer */
 	length = (tail + length) - BUF_PAGE_SIZE;
-	local_sub(length, &tail_page->write);
+	local_sub_unchecked(length, &tail_page->write);
 }
 
 /*
@@ -1932,7 +1932,7 @@ rb_move_tail(struct ring_buffer_per_cpu
 	 * about it.
 	 */
 	if (unlikely(next_page == commit_page)) {
-		local_inc(&cpu_buffer->commit_overrun);
+		local_inc_unchecked(&cpu_buffer->commit_overrun);
 		goto out_reset;
 	}
 
@@ -1986,7 +1986,7 @@ rb_move_tail(struct ring_buffer_per_cpu
 				      cpu_buffer->tail_page) &&
 				     (cpu_buffer->commit_page ==
 				      cpu_buffer->reader_page))) {
-				local_inc(&cpu_buffer->commit_overrun);
+				local_inc_unchecked(&cpu_buffer->commit_overrun);
 				goto out_reset;
 			}
 		}
@@ -2034,7 +2034,7 @@ __rb_reserve_next(struct ring_buffer_per
 		length += RB_LEN_TIME_EXTEND;
 
 	tail_page = cpu_buffer->tail_page;
-	write = local_add_return(length, &tail_page->write);
+	write = local_add_return_unchecked(length, &tail_page->write);
 
 	/* set write to only the index of the write */
 	write &= RB_WRITE_MASK;
@@ -2058,7 +2058,7 @@ __rb_reserve_next(struct ring_buffer_per
 	kmemcheck_annotate_bitfield(event, bitfield);
 	rb_update_event(cpu_buffer, event, length, add_timestamp, delta);
 
-	local_inc(&tail_page->entries);
+	local_inc_unchecked(&tail_page->entries);
 
 	/*
 	 * If this is the first commit on the page, then update
@@ -2091,7 +2091,7 @@ rb_try_to_discard(struct ring_buffer_per
 
 	if (bpage->page == (void *)addr && rb_page_write(bpage) == old_index) {
 		unsigned long write_mask =
-			local_read(&bpage->write) & ~RB_WRITE_MASK;
+			local_read_unchecked(&bpage->write) & ~RB_WRITE_MASK;
 		unsigned long event_length = rb_event_length(event);
 		/*
 		 * This is on the tail page. It is possible that
@@ -2101,7 +2101,7 @@ rb_try_to_discard(struct ring_buffer_per
 		 */
 		old_index += write_mask;
 		new_index += write_mask;
-		index = local_cmpxchg(&bpage->write, old_index, new_index);
+		index = local_cmpxchg_unchecked(&bpage->write, old_index, new_index);
 		if (index == old_index) {
 			/* update counters */
 			local_sub(event_length, &cpu_buffer->entries_bytes);
@@ -2116,7 +2116,7 @@ rb_try_to_discard(struct ring_buffer_per
 static void rb_start_commit(struct ring_buffer_per_cpu *cpu_buffer)
 {
 	local_inc(&cpu_buffer->committing);
-	local_inc(&cpu_buffer->commits);
+	local_inc_unchecked(&cpu_buffer->commits);
 }
 
 static inline void rb_end_commit(struct ring_buffer_per_cpu *cpu_buffer)
@@ -2128,7 +2128,7 @@ static inline void rb_end_commit(struct
 		return;
 
  again:
-	commits = local_read(&cpu_buffer->commits);
+	commits = local_read_unchecked(&cpu_buffer->commits);
 	/* synchronize with interrupts */
 	barrier();
 	if (local_read(&cpu_buffer->committing) == 1)
@@ -2144,7 +2144,7 @@ static inline void rb_end_commit(struct
 	 * updating of the commit page and the clearing of the
 	 * committing counter.
 	 */
-	if (unlikely(local_read(&cpu_buffer->commits) != commits) &&
+	if (unlikely(local_read_unchecked(&cpu_buffer->commits) != commits) &&
 	    !local_read(&cpu_buffer->committing)) {
 		local_inc(&cpu_buffer->committing);
 		goto again;
@@ -2174,7 +2174,7 @@ rb_reserve_next_event(struct ring_buffer
 	barrier();
 	if (unlikely(ACCESS_ONCE(cpu_buffer->buffer) != buffer)) {
 		local_dec(&cpu_buffer->committing);
-		local_dec(&cpu_buffer->commits);
+		local_dec_unchecked(&cpu_buffer->commits);
 		return NULL;
 	}
 #endif
@@ -2440,7 +2440,7 @@ rb_decrement_entry(struct ring_buffer_pe
 
 	/* Do the likely case first */
 	if (likely(bpage->page == (void *)addr)) {
-		local_dec(&bpage->entries);
+		local_dec_unchecked(&bpage->entries);
 		return;
 	}
 
@@ -2452,7 +2452,7 @@ rb_decrement_entry(struct ring_buffer_pe
 	start = bpage;
 	do {
 		if (bpage->page == (void *)addr) {
-			local_dec(&bpage->entries);
+			local_dec_unchecked(&bpage->entries);
 			return;
 		}
 		rb_inc_page(cpu_buffer, &bpage);
@@ -2677,7 +2677,7 @@ static inline unsigned long
 rb_num_of_entries(struct ring_buffer_per_cpu *cpu_buffer)
 {
 	return local_read(&cpu_buffer->entries) -
-		(local_read(&cpu_buffer->overrun) + cpu_buffer->read);
+		(local_read_unchecked(&cpu_buffer->overrun) + cpu_buffer->read);
 }
 
 /**
@@ -2765,7 +2765,7 @@ unsigned long ring_buffer_overrun_cpu(st
 		return 0;
 
 	cpu_buffer = buffer->buffers[cpu];
-	ret = local_read(&cpu_buffer->overrun);
+	ret = local_read_unchecked(&cpu_buffer->overrun);
 
 	return ret;
 }
@@ -2786,7 +2786,7 @@ ring_buffer_commit_overrun_cpu(struct ri
 		return 0;
 
 	cpu_buffer = buffer->buffers[cpu];
-	ret = local_read(&cpu_buffer->commit_overrun);
+	ret = local_read_unchecked(&cpu_buffer->commit_overrun);
 
 	return ret;
 }
@@ -2831,7 +2831,7 @@ unsigned long ring_buffer_overruns(struc
 	/* if you care about this being correct, lock the buffer */
 	for_each_buffer_cpu(buffer, cpu) {
 		cpu_buffer = buffer->buffers[cpu];
-		overruns += local_read(&cpu_buffer->overrun);
+		overruns += local_read_unchecked(&cpu_buffer->overrun);
 	}
 
 	return overruns;
@@ -2998,8 +2998,8 @@ rb_get_reader_page(struct ring_buffer_pe
 	/*
 	 * Reset the reader page to size zero.
 	 */
-	local_set(&cpu_buffer->reader_page->write, 0);
-	local_set(&cpu_buffer->reader_page->entries, 0);
+	local_set_unchecked(&cpu_buffer->reader_page->write, 0);
+	local_set_unchecked(&cpu_buffer->reader_page->entries, 0);
 	local_set(&cpu_buffer->reader_page->page->commit, 0);
 	cpu_buffer->reader_page->real_end = 0;
 
@@ -3033,7 +3033,7 @@ rb_get_reader_page(struct ring_buffer_pe
 	 * want to compare with the last_overrun.
 	 */
 	smp_mb();
-	overwrite = local_read(&(cpu_buffer->overrun));
+	overwrite = local_read_unchecked(&(cpu_buffer->overrun));
 
 	/*
 	 * Here's the tricky part.
@@ -3583,8 +3583,8 @@ rb_reset_cpu(struct ring_buffer_per_cpu
 
 	cpu_buffer->head_page
 		= list_entry(cpu_buffer->pages, struct buffer_page, list);
-	local_set(&cpu_buffer->head_page->write, 0);
-	local_set(&cpu_buffer->head_page->entries, 0);
+	local_set_unchecked(&cpu_buffer->head_page->write, 0);
+	local_set_unchecked(&cpu_buffer->head_page->entries, 0);
 	local_set(&cpu_buffer->head_page->page->commit, 0);
 
 	cpu_buffer->head_page->read = 0;
@@ -3593,17 +3593,17 @@ rb_reset_cpu(struct ring_buffer_per_cpu
 	cpu_buffer->commit_page = cpu_buffer->head_page;
 
 	INIT_LIST_HEAD(&cpu_buffer->reader_page->list);
-	local_set(&cpu_buffer->reader_page->write, 0);
-	local_set(&cpu_buffer->reader_page->entries, 0);
+	local_set_unchecked(&cpu_buffer->reader_page->write, 0);
+	local_set_unchecked(&cpu_buffer->reader_page->entries, 0);
 	local_set(&cpu_buffer->reader_page->page->commit, 0);
 	cpu_buffer->reader_page->read = 0;
 
-	local_set(&cpu_buffer->commit_overrun, 0);
+	local_set_unchecked(&cpu_buffer->commit_overrun, 0);
 	local_set(&cpu_buffer->entries_bytes, 0);
-	local_set(&cpu_buffer->overrun, 0);
+	local_set_unchecked(&cpu_buffer->overrun, 0);
 	local_set(&cpu_buffer->entries, 0);
 	local_set(&cpu_buffer->committing, 0);
-	local_set(&cpu_buffer->commits, 0);
+	local_set_unchecked(&cpu_buffer->commits, 0);
 	cpu_buffer->read = 0;
 	cpu_buffer->read_bytes = 0;
 
@@ -3998,8 +3998,8 @@ int ring_buffer_read_page(struct ring_bu
 		rb_init_page(bpage);
 		bpage = reader->page;
 		reader->page = *data_page;
-		local_set(&reader->write, 0);
-		local_set(&reader->entries, 0);
+		local_set_unchecked(&reader->write, 0);
+		local_set_unchecked(&reader->entries, 0);
 		reader->read = 0;
 		*data_page = bpage;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/trace/trace.c linux-3.2.71-pax/kernel/trace/trace.c
--- linux-3.2.71/kernel/trace/trace.c	2014-08-06 23:17:21.997614201 +0200
+++ linux-3.2.71-pax/kernel/trace/trace.c	2014-08-06 23:17:26.665614191 +0200
@@ -2656,7 +2656,7 @@ int trace_keep_overwrite(struct tracer *
 	return 0;
 }
 
-int set_tracer_flag(unsigned int mask, int enabled)
+int set_tracer_flag(unsigned long mask, int enabled)
 {
 	/* do nothing if flag is already set */
 	if (!!(trace_flags & mask) == !!enabled)
@@ -4246,10 +4246,9 @@ static const struct file_operations trac
 };
 #endif
 
-static struct dentry *d_tracer;
-
 struct dentry *tracing_init_dentry(void)
 {
+	static struct dentry *d_tracer;
 	static int once;
 
 	if (d_tracer)
@@ -4269,10 +4268,9 @@ struct dentry *tracing_init_dentry(void)
 	return d_tracer;
 }
 
-static struct dentry *d_percpu;
-
 struct dentry *tracing_dentry_percpu(void)
 {
+	static struct dentry *d_percpu;
 	static int once;
 	struct dentry *d_tracer;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/trace/trace_clock.c linux-3.2.71-pax/kernel/trace/trace_clock.c
--- linux-3.2.71/kernel/trace/trace_clock.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/trace/trace_clock.c	2013-09-01 20:23:25.911769456 +0200
@@ -114,7 +114,7 @@ u64 notrace trace_clock_global(void)
 	return now;
 }
 
-static atomic64_t trace_counter;
+static atomic64_unchecked_t trace_counter;
 
 /*
  * trace_clock_counter(): simply an atomic counter.
@@ -123,5 +123,5 @@ static atomic64_t trace_counter;
  */
 u64 notrace trace_clock_counter(void)
 {
-	return atomic64_add_return(1, &trace_counter);
+	return atomic64_add_return_unchecked(1, &trace_counter);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/trace/trace_events.c linux-3.2.71-pax/kernel/trace/trace_events.c
--- linux-3.2.71/kernel/trace/trace_events.c	2014-04-02 03:15:45.611672339 +0200
+++ linux-3.2.71-pax/kernel/trace/trace_events.c	2014-04-02 03:15:49.395672137 +0200
@@ -1299,10 +1299,6 @@ static LIST_HEAD(ftrace_module_file_list
 struct ftrace_module_file_ops {
 	struct list_head		list;
 	struct module			*mod;
-	struct file_operations		id;
-	struct file_operations		enable;
-	struct file_operations		format;
-	struct file_operations		filter;
 };
 
 static struct ftrace_module_file_ops *
@@ -1323,17 +1319,12 @@ trace_create_file_ops(struct module *mod
 
 	file_ops->mod = mod;
 
-	file_ops->id = ftrace_event_id_fops;
-	file_ops->id.owner = mod;
-
-	file_ops->enable = ftrace_enable_fops;
-	file_ops->enable.owner = mod;
-
-	file_ops->filter = ftrace_event_filter_fops;
-	file_ops->filter.owner = mod;
-
-	file_ops->format = ftrace_event_format_fops;
-	file_ops->format.owner = mod;
+	pax_open_kernel();
+	mod->trace_id.owner = mod;
+	mod->trace_enable.owner = mod;
+	mod->trace_filter.owner = mod;
+	mod->trace_format.owner = mod;
+	pax_close_kernel();
 
 	list_add(&file_ops->list, &ftrace_module_file_list);
 
@@ -1367,8 +1358,8 @@ static void trace_module_add_events(stru
 
 	for_each_event(call, start, end) {
 		__trace_add_event_call(*call, mod,
-				       &file_ops->id, &file_ops->enable,
-				       &file_ops->filter, &file_ops->format);
+				       &mod->trace_id, &mod->trace_enable,
+				       &mod->trace_filter, &mod->trace_format);
 	}
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/trace/trace_functions_graph.c linux-3.2.71-pax/kernel/trace/trace_functions_graph.c
--- linux-3.2.71/kernel/trace/trace_functions_graph.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/trace/trace_functions_graph.c	2015-01-05 18:29:52.739803454 +0100
@@ -108,7 +108,7 @@ ftrace_push_return_trace(unsigned long r
 
 	/* The return trace stack is full */
 	if (current->curr_ret_stack == FTRACE_RETFUNC_DEPTH - 1) {
-		atomic_inc(&current->trace_overrun);
+		atomic_inc_unchecked(&current->trace_overrun);
 		return -EBUSY;
 	}
 
@@ -171,7 +171,7 @@ ftrace_pop_return_trace(struct ftrace_gr
 	*ret = current->ret_stack[index].ret;
 	trace->func = current->ret_stack[index].func;
 	trace->calltime = current->ret_stack[index].calltime;
-	trace->overrun = atomic_read(&current->trace_overrun);
+	trace->overrun = atomic_read_unchecked(&current->trace_overrun);
 	trace->depth = index;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/trace/trace.h linux-3.2.71-pax/kernel/trace/trace.h
--- linux-3.2.71/kernel/trace/trace.h	2013-03-29 02:18:43.451676030 +0100
+++ linux-3.2.71-pax/kernel/trace/trace.h	2013-04-30 00:38:55.459734455 +0200
@@ -820,7 +820,7 @@ extern const char *__start___trace_bprin
 extern const char *__stop___trace_bprintk_fmt[];
 
 int trace_keep_overwrite(struct tracer *tracer, u32 mask, int set);
-int set_tracer_flag(unsigned int mask, int enabled);
+int set_tracer_flag(unsigned long mask, int enabled);
 
 #undef FTRACE_ENTRY
 #define FTRACE_ENTRY(call, struct_name, id, tstruct, print)		\
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/trace/trace_kprobe.c linux-3.2.71-pax/kernel/trace/trace_kprobe.c
--- linux-3.2.71/kernel/trace/trace_kprobe.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/trace/trace_kprobe.c	2012-07-04 19:24:48.900063009 +0200
@@ -217,7 +217,7 @@ static __kprobes void FETCH_FUNC_NAME(me
 	long ret;
 	int maxlen = get_rloc_len(*(u32 *)dest);
 	u8 *dst = get_rloc_data(dest);
-	u8 *src = addr;
+	const u8 __user *src = (const u8 __force_user *)addr;
 	mm_segment_t old_fs = get_fs();
 	if (!maxlen)
 		return;
@@ -229,7 +229,7 @@ static __kprobes void FETCH_FUNC_NAME(me
 	pagefault_disable();
 	do
 		ret = __copy_from_user_inatomic(dst++, src++, 1);
-	while (dst[-1] && ret == 0 && src - (u8 *)addr < maxlen);
+	while (dst[-1] && ret == 0 && src - (const u8 __force_user *)addr < maxlen);
 	dst[-1] = '\0';
 	pagefault_enable();
 	set_fs(old_fs);
@@ -238,7 +238,7 @@ static __kprobes void FETCH_FUNC_NAME(me
 		((u8 *)get_rloc_data(dest))[0] = '\0';
 		*(u32 *)dest = make_data_rloc(0, get_rloc_offs(*(u32 *)dest));
 	} else
-		*(u32 *)dest = make_data_rloc(src - (u8 *)addr,
+		*(u32 *)dest = make_data_rloc(src - (const u8 __force_user *)addr,
 					      get_rloc_offs(*(u32 *)dest));
 }
 /* Return the length of string -- including null terminal byte */
@@ -252,7 +252,7 @@ static __kprobes void FETCH_FUNC_NAME(me
 	set_fs(KERNEL_DS);
 	pagefault_disable();
 	do {
-		ret = __copy_from_user_inatomic(&c, (u8 *)addr + len, 1);
+		ret = __copy_from_user_inatomic(&c, (const u8 __force_user *)addr + len, 1);
 		len++;
 	} while (c && ret == 0 && len < MAX_STRING_SIZE);
 	pagefault_enable();
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/trace/trace_mmiotrace.c linux-3.2.71-pax/kernel/trace/trace_mmiotrace.c
--- linux-3.2.71/kernel/trace/trace_mmiotrace.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/trace/trace_mmiotrace.c	2012-07-04 19:24:48.904063009 +0200
@@ -24,7 +24,7 @@ struct header_iter {
 static struct trace_array *mmio_trace_array;
 static bool overrun_detected;
 static unsigned long prev_overruns;
-static atomic_t dropped_count;
+static atomic_unchecked_t dropped_count;
 
 static void mmio_reset_data(struct trace_array *tr)
 {
@@ -127,7 +127,7 @@ static void mmio_close(struct trace_iter
 
 static unsigned long count_overruns(struct trace_iterator *iter)
 {
-	unsigned long cnt = atomic_xchg(&dropped_count, 0);
+	unsigned long cnt = atomic_xchg_unchecked(&dropped_count, 0);
 	unsigned long over = ring_buffer_overruns(iter->tr->buffer);
 
 	if (over > prev_overruns)
@@ -317,7 +317,7 @@ static void __trace_mmiotrace_rw(struct
 	event = trace_buffer_lock_reserve(buffer, TRACE_MMIO_RW,
 					  sizeof(*entry), 0, pc);
 	if (!event) {
-		atomic_inc(&dropped_count);
+		atomic_inc_unchecked(&dropped_count);
 		return;
 	}
 	entry	= ring_buffer_event_data(event);
@@ -347,7 +347,7 @@ static void __trace_mmiotrace_map(struct
 	event = trace_buffer_lock_reserve(buffer, TRACE_MMIO_MAP,
 					  sizeof(*entry), 0, pc);
 	if (!event) {
-		atomic_inc(&dropped_count);
+		atomic_inc_unchecked(&dropped_count);
 		return;
 	}
 	entry	= ring_buffer_event_data(event);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/trace/trace_output.c linux-3.2.71-pax/kernel/trace/trace_output.c
--- linux-3.2.71/kernel/trace/trace_output.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/trace/trace_output.c	2013-01-22 12:36:20.269511269 +0100
@@ -278,7 +278,7 @@ int trace_seq_path(struct trace_seq *s,
 
 	p = d_path(path, s->buffer + s->len, PAGE_SIZE - s->len);
 	if (!IS_ERR(p)) {
-		p = mangle_path(s->buffer + s->len, p, "\n");
+		p = mangle_path(s->buffer + s->len, p, "\n\\");
 		if (p) {
 			s->len = p - s->buffer;
 			return 1;
@@ -810,14 +810,16 @@ int register_ftrace_event(struct trace_e
 			goto out;
 	}
 
+	pax_open_kernel();
 	if (event->funcs->trace == NULL)
-		event->funcs->trace = trace_nop_print;
+		*(void **)&event->funcs->trace = trace_nop_print;
 	if (event->funcs->raw == NULL)
-		event->funcs->raw = trace_nop_print;
+		*(void **)&event->funcs->raw = trace_nop_print;
 	if (event->funcs->hex == NULL)
-		event->funcs->hex = trace_nop_print;
+		*(void **)&event->funcs->hex = trace_nop_print;
 	if (event->funcs->binary == NULL)
-		event->funcs->binary = trace_nop_print;
+		*(void **)&event->funcs->binary = trace_nop_print;
+	pax_close_kernel();
 
 	key = event->type & (EVENT_HASHSIZE - 1);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/trace/trace_stack.c linux-3.2.71-pax/kernel/trace/trace_stack.c
--- linux-3.2.71/kernel/trace/trace_stack.c	2013-05-14 13:33:40.680285669 +0200
+++ linux-3.2.71-pax/kernel/trace/trace_stack.c	2013-05-14 13:36:00.764278190 +0200
@@ -66,7 +66,7 @@ check_stack(unsigned long ip, unsigned l
 		return;
 
 	/* we do not handle interrupt stacks yet */
-	if (!object_is_on_stack(stack))
+	if (!object_starts_on_stack(stack))
 		return;
 
 	local_irq_save(flags);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/trace/trace_workqueue.c linux-3.2.71-pax/kernel/trace/trace_workqueue.c
--- linux-3.2.71/kernel/trace/trace_workqueue.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/trace/trace_workqueue.c	2012-07-04 19:24:48.908063008 +0200
@@ -22,7 +22,7 @@ struct cpu_workqueue_stats {
 	int		            cpu;
 	pid_t			    pid;
 /* Can be inserted from interrupt or user context, need to be atomic */
-	atomic_t	            inserted;
+	atomic_unchecked_t          inserted;
 /*
  *  Don't need to be atomic, works are serialized in a single workqueue thread
  *  on a single CPU.
@@ -60,7 +60,7 @@ probe_workqueue_insertion(void *ignore,
 	spin_lock_irqsave(&workqueue_cpu_stat(cpu)->lock, flags);
 	list_for_each_entry(node, &workqueue_cpu_stat(cpu)->list, list) {
 		if (node->pid == wq_thread->pid) {
-			atomic_inc(&node->inserted);
+			atomic_inc_unchecked(&node->inserted);
 			goto found;
 		}
 	}
@@ -210,7 +210,7 @@ static int workqueue_stat_show(struct se
 		tsk = get_pid_task(pid, PIDTYPE_PID);
 		if (tsk) {
 			seq_printf(s, "%3d %6d     %6u       %s\n", cws->cpu,
-				   atomic_read(&cws->inserted), cws->executed,
+				   atomic_read_unchecked(&cws->inserted), cws->executed,
 				   tsk->comm);
 			put_task_struct(tsk);
 		}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/utsname_sysctl.c linux-3.2.71-pax/kernel/utsname_sysctl.c
--- linux-3.2.71/kernel/utsname_sysctl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/kernel/utsname_sysctl.c	2013-03-28 01:35:23.504427937 +0100
@@ -46,7 +46,7 @@ static void put_uts(ctl_table *table, in
 static int proc_do_uts_string(ctl_table *table, int write,
 		  void __user *buffer, size_t *lenp, loff_t *ppos)
 {
-	struct ctl_table uts_table;
+	ctl_table_no_const uts_table;
 	int r;
 	memcpy(&uts_table, table, sizeof(uts_table));
 	uts_table.data = get_uts(table, write);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/watchdog.c linux-3.2.71-pax/kernel/watchdog.c
--- linux-3.2.71/kernel/watchdog.c	2012-12-06 19:03:21.427211696 +0100
+++ linux-3.2.71-pax/kernel/watchdog.c	2013-02-20 01:23:18.322014378 +0100
@@ -574,7 +574,7 @@ cpu_callback(struct notifier_block *nfb,
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata cpu_nfb = {
+static struct notifier_block cpu_nfb = {
 	.notifier_call = cpu_callback
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/kernel/workqueue.c linux-3.2.71-pax/kernel/workqueue.c
--- linux-3.2.71/kernel/workqueue.c	2014-04-02 03:15:45.619672339 +0200
+++ linux-3.2.71-pax/kernel/workqueue.c	2014-04-02 03:15:49.395672137 +0200
@@ -3506,7 +3506,7 @@ static int __cpuinit trustee_thread(void
 		 */
 		worker_flags |= WORKER_REBIND;
 		worker_flags &= ~WORKER_ROGUE;
-		ACCESS_ONCE(worker->flags) = worker_flags;
+		ACCESS_ONCE_RW(worker->flags) = worker_flags;
 
 		/* queue rebind_work, wq doesn't matter, use the default one */
 		if (test_and_set_bit(WORK_STRUCT_PENDING_BIT,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/bitmap.c linux-3.2.71-pax/lib/bitmap.c
--- linux-3.2.71/lib/bitmap.c	2015-08-14 21:48:35.360707910 +0200
+++ linux-3.2.71-pax/lib/bitmap.c	2015-08-14 21:49:39.484704486 +0200
@@ -423,7 +423,7 @@ int __bitmap_parse(const char *buf, unsi
 {
 	int c, old_c, totaldigits, ndigits, nchunks, nbits;
 	u32 chunk;
-	const char __user __force *ubuf = (const char __user __force *)buf;
+	const char __user *ubuf = (const char __force_user *)buf;
 
 	bitmap_zero(maskp, nmaskbits);
 
@@ -508,7 +508,7 @@ int bitmap_parse_user(const char __user
 {
 	if (!access_ok(VERIFY_READ, ubuf, ulen))
 		return -EFAULT;
-	return __bitmap_parse((const char __force *)ubuf,
+	return __bitmap_parse((const char __force_kernel *)ubuf,
 				ulen, 1, maskp, nmaskbits);
 
 }
@@ -600,7 +600,7 @@ static int __bitmap_parselist(const char
 {
 	unsigned a, b;
 	int c, old_c, totaldigits;
-	const char __user __force *ubuf = (const char __user __force *)buf;
+	const char __user *ubuf = (const char __force_user *)buf;
 	int at_start, in_range;
 
 	totaldigits = c = 0;
@@ -701,7 +701,7 @@ int bitmap_parselist_user(const char __u
 {
 	if (!access_ok(VERIFY_READ, ubuf, ulen))
 		return -EFAULT;
-	return __bitmap_parselist((const char __force *)ubuf,
+	return __bitmap_parselist((const char __force_kernel *)ubuf,
 					ulen, 1, maskp, nmaskbits);
 }
 EXPORT_SYMBOL(bitmap_parselist_user);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/bug.c linux-3.2.71-pax/lib/bug.c
--- linux-3.2.71/lib/bug.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/bug.c	2012-07-04 19:24:48.908063008 +0200
@@ -133,6 +133,8 @@ enum bug_trap_type report_bug(unsigned l
 		return BUG_TRAP_TYPE_NONE;
 
 	bug = find_bug(bugaddr);
+	if (!bug)
+		return BUG_TRAP_TYPE_NONE;
 
 	file = NULL;
 	line = 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/cpu-notifier-error-inject.c linux-3.2.71-pax/lib/cpu-notifier-error-inject.c
--- linux-3.2.71/lib/cpu-notifier-error-inject.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/cpu-notifier-error-inject.c	2013-01-17 00:07:42.178614237 +0100
@@ -45,7 +45,9 @@ static struct notifier_block err_inject_
 
 static int err_inject_init(void)
 {
-	err_inject_cpu_notifier.priority = priority;
+	pax_open_kernel();
+	*(int *)&err_inject_cpu_notifier.priority = priority;
+	pax_close_kernel();
 
 	return register_hotcpu_notifier(&err_inject_cpu_notifier);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/debugobjects.c linux-3.2.71-pax/lib/debugobjects.c
--- linux-3.2.71/lib/debugobjects.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/debugobjects.c	2012-07-04 19:24:48.908063008 +0200
@@ -284,7 +284,7 @@ static void debug_object_is_on_stack(voi
 	if (limit > 4)
 		return;
 
-	is_on_stack = object_is_on_stack(addr);
+	is_on_stack = object_starts_on_stack(addr);
 	if (is_on_stack == onstack)
 		return;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/decompress_bunzip2.c linux-3.2.71-pax/lib/decompress_bunzip2.c
--- linux-3.2.71/lib/decompress_bunzip2.c	2015-02-20 12:37:33.233178768 +0100
+++ linux-3.2.71-pax/lib/decompress_bunzip2.c	2015-05-06 23:55:17.524026742 +0200
@@ -666,7 +666,8 @@ static int INIT start_bunzip(struct bunz
 
 	/* Fourth byte (ascii '1'-'9'), indicates block size in units of 100k of
 	   uncompressed data.  Allocate intermediate buffer for block. */
-	bd->dbufSize = 100000*(i-BZh0);
+	i -= BZh0;
+	bd->dbufSize = 100000 * i;
 
 	bd->dbuf = large_malloc(bd->dbufSize * sizeof(int));
 	if (!bd->dbuf)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/decompress_unlzma.c linux-3.2.71-pax/lib/decompress_unlzma.c
--- linux-3.2.71/lib/decompress_unlzma.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/decompress_unlzma.c	2015-06-26 17:49:16.286479755 +0200
@@ -39,10 +39,10 @@
 
 #define	MIN(a, b) (((a) < (b)) ? (a) : (b))
 
-static long long INIT read_int(unsigned char *ptr, int size)
+static unsigned long long INIT read_int(unsigned char *ptr, int size)
 {
 	int i;
-	long long ret = 0;
+	unsigned long long ret = 0;
 
 	for (i = 0; i < size; i++)
 		ret = (ret << 8) | ptr[size-i-1];
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/devres.c linux-3.2.71-pax/lib/devres.c
--- linux-3.2.71/lib/devres.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/devres.c	2012-07-04 19:24:48.908063008 +0200
@@ -80,7 +80,7 @@ EXPORT_SYMBOL(devm_ioremap_nocache);
 void devm_iounmap(struct device *dev, void __iomem *addr)
 {
 	WARN_ON(devres_destroy(dev, devm_ioremap_release, devm_ioremap_match,
-			       (void *)addr));
+			       (void __force *)addr));
 	iounmap(addr);
 }
 EXPORT_SYMBOL(devm_iounmap);
@@ -141,7 +141,7 @@ void devm_ioport_unmap(struct device *de
 {
 	ioport_unmap(addr);
 	WARN_ON(devres_destroy(dev, devm_ioport_map_release,
-			       devm_ioport_map_match, (void *)addr));
+			       devm_ioport_map_match, (void __force *)addr));
 }
 EXPORT_SYMBOL(devm_ioport_unmap);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/div64.c linux-3.2.71-pax/lib/div64.c
--- linux-3.2.71/lib/div64.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/div64.c	2013-03-28 04:10:58.227929535 +0100
@@ -58,7 +58,7 @@ uint32_t __attribute__((weak)) __div64_3
 EXPORT_SYMBOL(__div64_32);
 
 #ifndef div_s64_rem
-s64 div_s64_rem(s64 dividend, s32 divisor, s32 *remainder)
+s64 __intentional_overflow(-1) div_s64_rem(s64 dividend, s32 divisor, s32 *remainder)
 {
 	u64 quotient;
 
@@ -89,7 +89,7 @@ EXPORT_SYMBOL(div_s64_rem);
  * 'http://www.hackersdelight.org/HDcode/newCode/divDouble.c'
  */
 #ifndef div64_u64
-u64 div64_u64(u64 dividend, u64 divisor)
+u64 __intentional_overflow(-1) div64_u64(u64 dividend, u64 divisor)
 {
 	u32 high = divisor >> 32;
 	u64 quot;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/dma-debug.c linux-3.2.71-pax/lib/dma-debug.c
--- linux-3.2.71/lib/dma-debug.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/dma-debug.c	2013-01-16 21:26:55.346837163 +0100
@@ -760,7 +760,7 @@ static int dma_debug_device_change(struc
 
 void dma_debug_add_bus(struct bus_type *bus)
 {
-	struct notifier_block *nb;
+	notifier_block_no_const *nb;
 
 	if (global_disable)
 		return;
@@ -925,7 +925,7 @@ out:
 
 static void check_for_stack(struct device *dev, void *addr)
 {
-	if (object_is_on_stack(addr))
+	if (object_starts_on_stack(addr))
 		err_printk(dev, NULL, "DMA-API: device driver maps memory from"
 				"stack [addr=%p]\n", addr);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/extable.c linux-3.2.71-pax/lib/extable.c
--- linux-3.2.71/lib/extable.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/extable.c	2012-09-09 23:04:43.829095130 +0200
@@ -13,6 +13,7 @@
 #include <linux/init.h>
 #include <linux/sort.h>
 #include <asm/uaccess.h>
+#include <asm/pgtable.h>
 
 #ifndef ARCH_HAS_SORT_EXTABLE
 /*
@@ -36,8 +37,10 @@ static int cmp_ex(const void *a, const v
 void sort_extable(struct exception_table_entry *start,
 		  struct exception_table_entry *finish)
 {
+	pax_open_kernel();
 	sort(start, finish - start, sizeof(struct exception_table_entry),
 	     cmp_ex, NULL);
+	pax_close_kernel();
 }
 
 #ifdef CONFIG_MODULES
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/inflate.c linux-3.2.71-pax/lib/inflate.c
--- linux-3.2.71/lib/inflate.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/inflate.c	2012-07-04 19:24:48.912063008 +0200
@@ -269,7 +269,7 @@ static void free(void *where)
 		malloc_ptr = free_mem_ptr;
 }
 #else
-#define malloc(a) kmalloc(a, GFP_KERNEL)
+#define malloc(a) kmalloc((a), GFP_KERNEL)
 #define free(a) kfree(a)
 #endif
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/ioremap.c linux-3.2.71-pax/lib/ioremap.c
--- linux-3.2.71/lib/ioremap.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/ioremap.c	2012-07-04 19:24:48.912063008 +0200
@@ -38,7 +38,7 @@ static inline int ioremap_pmd_range(pud_
 	unsigned long next;
 
 	phys_addr -= addr;
-	pmd = pmd_alloc(&init_mm, pud, addr);
+	pmd = pmd_alloc_kernel(&init_mm, pud, addr);
 	if (!pmd)
 		return -ENOMEM;
 	do {
@@ -56,7 +56,7 @@ static inline int ioremap_pud_range(pgd_
 	unsigned long next;
 
 	phys_addr -= addr;
-	pud = pud_alloc(&init_mm, pgd, addr);
+	pud = pud_alloc_kernel(&init_mm, pgd, addr);
 	if (!pud)
 		return -ENOMEM;
 	do {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/Kconfig.debug linux-3.2.71-pax/lib/Kconfig.debug
--- linux-3.2.71/lib/Kconfig.debug	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/Kconfig.debug	2013-03-28 04:34:45.215853345 +0100
@@ -510,7 +510,7 @@ config DEBUG_MUTEXES
 
 config DEBUG_LOCK_ALLOC
 	bool "Lock debugging: detect incorrect freeing of live locks"
-	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT
+	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT && !PAX_CONSTIFY_PLUGIN
 	select DEBUG_SPINLOCK
 	select DEBUG_MUTEXES
 	select LOCKDEP
@@ -524,7 +524,7 @@ config DEBUG_LOCK_ALLOC
 
 config PROVE_LOCKING
 	bool "Lock debugging: prove locking correctness"
-	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT
+	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT && !PAX_CONSTIFY_PLUGIN
 	select LOCKDEP
 	select DEBUG_SPINLOCK
 	select DEBUG_MUTEXES
@@ -616,7 +616,7 @@ config LOCKDEP
 
 config LOCK_STAT
 	bool "Lock usage statistics"
-	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT
+	depends on DEBUG_KERNEL && TRACE_IRQFLAGS_SUPPORT && STACKTRACE_SUPPORT && LOCKDEP_SUPPORT && !PAX_CONSTIFY_PLUGIN
 	select LOCKDEP
 	select DEBUG_SPINLOCK
 	select DEBUG_MUTEXES
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/kobject.c linux-3.2.71-pax/lib/kobject.c
--- linux-3.2.71/lib/kobject.c	2013-04-30 00:45:09.635714477 +0200
+++ linux-3.2.71-pax/lib/kobject.c	2013-06-21 20:15:56.162564327 +0200
@@ -844,7 +844,7 @@ static struct kset *kset_create(const ch
 	kset = kzalloc(sizeof(*kset), GFP_KERNEL);
 	if (!kset)
 		return NULL;
-	retval = kobject_set_name(&kset->kobj, name);
+	retval = kobject_set_name(&kset->kobj, "%s", name);
 	if (retval) {
 		kfree(kset);
 		return NULL;
@@ -898,9 +898,9 @@ EXPORT_SYMBOL_GPL(kset_create_and_add);
 
 
 static DEFINE_SPINLOCK(kobj_ns_type_lock);
-static const struct kobj_ns_type_operations *kobj_ns_ops_tbl[KOBJ_NS_TYPES];
+static const struct kobj_ns_type_operations *kobj_ns_ops_tbl[KOBJ_NS_TYPES] __read_only;
 
-int kobj_ns_type_register(const struct kobj_ns_type_operations *ops)
+int __init kobj_ns_type_register(const struct kobj_ns_type_operations *ops)
 {
 	enum kobj_ns_type type = ops->type;
 	int error;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/kref.c linux-3.2.71-pax/lib/kref.c
--- linux-3.2.71/lib/kref.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/kref.c	2012-07-04 19:24:48.912063008 +0200
@@ -52,7 +52,7 @@ void kref_get(struct kref *kref)
  */
 int kref_put(struct kref *kref, void (*release)(struct kref *kref))
 {
-	WARN_ON(release == NULL);
+	BUG_ON(release == NULL);
 	WARN_ON(release == (void (*)(struct kref *))kfree);
 
 	if (atomic_dec_and_test(&kref->refcount)) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/list_debug.c linux-3.2.71-pax/lib/list_debug.c
--- linux-3.2.71/lib/list_debug.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/list_debug.c	2013-03-28 02:34:34.020238367 +0100
@@ -8,7 +8,9 @@
 
 #include <linux/module.h>
 #include <linux/list.h>
+#include <linux/mm.h>
 
+#ifdef CONFIG_DEBUG_LIST
 /*
  * Insert a new entry between two known consecutive entries.
  *
@@ -16,18 +18,32 @@
  * the prev/next entries already!
  */
 
-void __list_add(struct list_head *new,
-			      struct list_head *prev,
-			      struct list_head *next)
+static bool __list_add_debug(struct list_head *new,
+			     struct list_head *prev,
+			     struct list_head *next)
 {
-	WARN(next->prev != prev,
+	if (WARN(next->prev != prev,
 		"list_add corruption. next->prev should be "
 		"prev (%p), but was %p. (next=%p).\n",
-		prev, next->prev, next);
-	WARN(prev->next != next,
+		prev, next->prev, next) ||
+	    WARN(prev->next != next,
 		"list_add corruption. prev->next should be "
 		"next (%p), but was %p. (prev=%p).\n",
-		next, prev->next, prev);
+		next, prev->next, prev) ||
+	    WARN(new == prev || new == next,
+		"list_add double add: new=%p, prev=%p, next=%p.\n",
+		new, prev, next))
+		return false;
+	return true;
+}
+
+void __list_add(struct list_head *new,
+		struct list_head *prev,
+		struct list_head *next)
+{
+	if (!__list_add_debug(new, prev, next))
+		return;
+
 	next->prev = new;
 	new->next = next;
 	new->prev = prev;
@@ -35,7 +51,7 @@ void __list_add(struct list_head *new,
 }
 EXPORT_SYMBOL(__list_add);
 
-void __list_del_entry(struct list_head *entry)
+static bool __list_del_entry_debug(struct list_head *entry)
 {
 	struct list_head *prev, *next;
 
@@ -54,9 +70,16 @@ void __list_del_entry(struct list_head *
 	    WARN(next->prev != entry,
 		"list_del corruption. next->prev should be %p, "
 		"but was %p\n", entry, next->prev))
+		return false;
+	return true;
+}
+
+void __list_del_entry(struct list_head *entry)
+{
+	if (!__list_del_entry_debug(entry))
 		return;
 
-	__list_del(prev, next);
+	__list_del(entry->prev, entry->next);
 }
 EXPORT_SYMBOL(__list_del_entry);
 
@@ -73,3 +96,76 @@ void list_del(struct list_head *entry)
 	entry->prev = LIST_POISON2;
 }
 EXPORT_SYMBOL(list_del);
+#endif
+
+void __pax_list_add(struct list_head *new, struct list_head *prev, struct list_head *next)
+{
+#ifdef CONFIG_DEBUG_LIST
+	if (!__list_add_debug(new, prev, next))
+		return;
+#endif
+
+	pax_open_kernel();
+	next->prev = new;
+	new->next = next;
+	new->prev = prev;
+	prev->next = new;
+	pax_close_kernel();
+}
+EXPORT_SYMBOL(__pax_list_add);
+
+void pax_list_del(struct list_head *entry)
+{
+#ifdef CONFIG_DEBUG_LIST
+	if (!__list_del_entry_debug(entry))
+		return;
+#endif
+
+	pax_open_kernel();
+	__list_del(entry->prev, entry->next);
+	entry->next = LIST_POISON1;
+	entry->prev = LIST_POISON2;
+	pax_close_kernel();
+}
+EXPORT_SYMBOL(pax_list_del);
+
+void pax_list_del_init(struct list_head *entry)
+{
+	pax_open_kernel();
+	__list_del(entry->prev, entry->next);
+	INIT_LIST_HEAD(entry);
+	pax_close_kernel();
+}
+EXPORT_SYMBOL(pax_list_del_init);
+
+void __pax_list_add_rcu(struct list_head *new,
+			struct list_head *prev, struct list_head *next)
+{
+#ifdef CONFIG_DEBUG_LIST
+	if (!__list_add_debug(new, prev, next))
+		return;
+#endif
+
+	pax_open_kernel();
+	new->next = next;
+	new->prev = prev;
+	rcu_assign_pointer(list_next_rcu(prev), new);
+	next->prev = new;
+	pax_close_kernel();
+}
+EXPORT_SYMBOL(__pax_list_add_rcu);
+
+void pax_list_del_rcu(struct list_head *entry)
+{
+#ifdef CONFIG_DEBUG_LIST
+	if (!__list_del_entry_debug(entry))
+		return;
+#endif
+
+	pax_open_kernel();
+	__list_del(entry->prev, entry->next);
+	entry->next = LIST_POISON1;
+	entry->prev = LIST_POISON2;
+	pax_close_kernel();
+}
+EXPORT_SYMBOL(pax_list_del_rcu);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/Makefile linux-3.2.71-pax/lib/Makefile
--- linux-3.2.71/lib/Makefile	2014-04-02 03:15:45.631672338 +0200
+++ linux-3.2.71-pax/lib/Makefile	2014-04-02 03:15:49.411672136 +0200
@@ -46,7 +46,7 @@ obj-$(CONFIG_GENERIC_HWEIGHT) += hweight
 
 obj-$(CONFIG_BTREE) += btree.o
 obj-$(CONFIG_DEBUG_PREEMPT) += smp_processor_id.o
-obj-$(CONFIG_DEBUG_LIST) += list_debug.o
+obj-y += list_debug.o
 obj-$(CONFIG_DEBUG_OBJECTS) += debugobjects.o
 
 ifneq ($(CONFIG_HAVE_DEC_LOCK),y)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/radix-tree.c linux-3.2.71-pax/lib/radix-tree.c
--- linux-3.2.71/lib/radix-tree.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/lib/radix-tree.c	2014-04-18 13:53:31.536555436 +0200
@@ -80,7 +80,7 @@ struct radix_tree_preload {
 	int nr;
 	struct radix_tree_node *nodes[RADIX_TREE_MAX_PATH];
 };
-static DEFINE_PER_CPU(struct radix_tree_preload, radix_tree_preloads) = { 0, };
+static DEFINE_PER_CPU(struct radix_tree_preload, radix_tree_preloads);
 
 static inline void *ptr_to_indirect(void *ptr)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/random32.c linux-3.2.71-pax/lib/random32.c
--- linux-3.2.71/lib/random32.c	2014-01-03 15:48:45.124070557 +0100
+++ linux-3.2.71-pax/lib/random32.c	2014-02-24 23:15:57.051848426 +0100
@@ -39,7 +39,7 @@
 #include <linux/jiffies.h>
 #include <linux/random.h>
 
-static DEFINE_PER_CPU(struct rnd_state, net_rand_state);
+static DEFINE_PER_CPU(struct rnd_state, net_rand_state) __latent_entropy;
 
 /**
  *	prandom32 - seeded pseudo-random number generator.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/lib/vsprintf.c linux-3.2.71-pax/lib/vsprintf.c
--- linux-3.2.71/lib/vsprintf.c	2014-01-03 15:48:45.124070557 +0100
+++ linux-3.2.71-pax/lib/vsprintf.c	2014-01-03 15:48:49.612070318 +0100
@@ -836,12 +836,12 @@ char *pointer(const char *fmt, char *buf
 {
 	if (!ptr && *fmt != 'K') {
 		/*
-		 * Print (null) with the same width as a pointer so it makes
+		 * Print (nil) with the same width as a pointer so it makes
 		 * tabular output look nice.
 		 */
 		if (spec.field_width == -1)
 			spec.field_width = 2 * sizeof(void *);
-		return string(buf, end, "(null)", spec);
+		return string(buf, end, "(nil)", spec);
 	}
 
 	switch (*fmt) {
@@ -1635,11 +1635,11 @@ int bstr_printf(char *buf, size_t size,
 	typeof(type) value;						\
 	if (sizeof(type) == 8) {					\
 		args = PTR_ALIGN(args, sizeof(u32));			\
-		*(u32 *)&value = *(u32 *)args;				\
-		*((u32 *)&value + 1) = *(u32 *)(args + 4);		\
+		*(u32 *)&value = *(const u32 *)args;			\
+		*((u32 *)&value + 1) = *(const u32 *)(args + 4);	\
 	} else {							\
 		args = PTR_ALIGN(args, sizeof(type));			\
-		value = *(typeof(type) *)args;				\
+		value = *(const typeof(type) *)args;			\
 	}								\
 	args += sizeof(type);						\
 	value;								\
@@ -1702,7 +1702,7 @@ int bstr_printf(char *buf, size_t size,
 		case FORMAT_TYPE_STR: {
 			const char *str_arg = args;
 			args += strlen(str_arg) + 1;
-			str = string(str, end, (char *)str_arg, spec);
+			str = string(str, end, str_arg, spec);
 			break;
 		}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/Makefile linux-3.2.71-pax/Makefile
--- linux-3.2.71/Makefile	2015-08-14 21:48:35.020707928 +0200
+++ linux-3.2.71-pax/Makefile	2015-08-14 21:48:45.548707366 +0200
@@ -245,8 +245,9 @@ CONFIG_SHELL := $(shell if [ -x "$$BASH"
 
 HOSTCC       = gcc
 HOSTCXX      = g++
-HOSTCFLAGS   = -Wall -Wmissing-prototypes -Wstrict-prototypes -O2 -fomit-frame-pointer
-HOSTCXXFLAGS = -O2
+HOSTCFLAGS   = -Wall -W -Wmissing-prototypes -Wstrict-prototypes -Wno-unused-parameter -Wno-missing-field-initializers -O2 -fomit-frame-pointer -fno-delete-null-pointer-checks
+HOSTCFLAGS  += $(call cc-option, -Wno-empty-body)
+HOSTCXXFLAGS = -O2 -Wall -W -Wno-array-bounds
 
 # Decide whether to build built-in, modular, or both.
 # Normally, just do built-in.
@@ -312,9 +313,15 @@ endif
 # If the user is running make -s (silent mode), suppress echoing of
 # commands
 
+ifneq ($(filter 4.%,$(MAKE_VERSION)),)	# make-4
+ifneq ($(filter %s ,$(firstword x$(MAKEFLAGS))),)
+ quiet=silent_
+endif
+else					# make-3.8x
 ifneq ($(findstring s,$(MAKEFLAGS)),)
   quiet=silent_
 endif
+endif
 
 export quiet Q KBUILD_VERBOSE
 
@@ -407,8 +414,8 @@ export RCS_TAR_IGNORE := --exclude SCCS
 # Rules shared between *config targets and build targets
 
 # Basic helpers built in scripts/
-PHONY += scripts_basic
-scripts_basic:
+PHONY += scripts_basic gcc-plugins
+scripts_basic: gcc-plugins
 	$(Q)$(MAKE) $(build)=scripts/basic
 	$(Q)rm -f .tmp_quiet_recordmcount
 
@@ -564,6 +571,63 @@ else
 KBUILD_CFLAGS	+= -O2
 endif
 
+ifeq ($(call cc-ifversion, -ge, 0408, y), y)
+PLUGINCC := $(shell $(CONFIG_SHELL) $(srctree)/scripts/gcc-plugin.sh "$(HOSTCXX)" "$(HOSTCXX)" "$(CC)")
+else
+PLUGINCC := $(shell $(CONFIG_SHELL) $(srctree)/scripts/gcc-plugin.sh "$(HOSTCC)" "$(HOSTCXX)" "$(CC)")
+endif
+ifneq ($(PLUGINCC),)
+ifdef CONFIG_PAX_CONSTIFY_PLUGIN
+CONSTIFY_PLUGIN_CFLAGS := -fplugin=$(objtree)/tools/gcc/constify_plugin.so -DCONSTIFY_PLUGIN
+endif
+ifdef CONFIG_PAX_MEMORY_STACKLEAK
+STACKLEAK_PLUGIN_CFLAGS := -fplugin=$(objtree)/tools/gcc/stackleak_plugin.so -DSTACKLEAK_PLUGIN
+STACKLEAK_PLUGIN_CFLAGS += -fplugin-arg-stackleak_plugin-track-lowest-sp=100
+endif
+ifdef CONFIG_KALLOCSTAT_PLUGIN
+KALLOCSTAT_PLUGIN_CFLAGS := -fplugin=$(objtree)/tools/gcc/kallocstat_plugin.so
+endif
+ifdef CONFIG_PAX_KERNEXEC_PLUGIN
+KERNEXEC_PLUGIN_CFLAGS := -fplugin=$(objtree)/tools/gcc/kernexec_plugin.so
+KERNEXEC_PLUGIN_CFLAGS += -fplugin-arg-kernexec_plugin-method=$(CONFIG_PAX_KERNEXEC_PLUGIN_METHOD) -DKERNEXEC_PLUGIN
+KERNEXEC_PLUGIN_AFLAGS := -DKERNEXEC_PLUGIN
+endif
+ifdef CONFIG_CHECKER_PLUGIN
+ifeq ($(call cc-ifversion, -ge, 0406, y), y)
+CHECKER_PLUGIN_CFLAGS := -fplugin=$(objtree)/tools/gcc/checker_plugin.so -DCHECKER_PLUGIN
+endif
+endif
+COLORIZE_PLUGIN_CFLAGS := -fplugin=$(objtree)/tools/gcc/colorize_plugin.so
+ifdef CONFIG_PAX_SIZE_OVERFLOW
+SIZE_OVERFLOW_PLUGIN_CFLAGS := -fplugin=$(objtree)/tools/gcc/size_overflow_plugin/size_overflow_plugin.so -DSIZE_OVERFLOW_PLUGIN
+endif
+ifdef CONFIG_PAX_LATENT_ENTROPY
+LATENT_ENTROPY_PLUGIN_CFLAGS := -fplugin=$(objtree)/tools/gcc/latent_entropy_plugin.so -DLATENT_ENTROPY_PLUGIN
+endif
+ifdef CONFIG_PAX_MEMORY_STRUCTLEAK
+STRUCTLEAK_PLUGIN_CFLAGS := -fplugin=$(objtree)/tools/gcc/structleak_plugin.so -DSTRUCTLEAK_PLUGIN
+endif
+GCC_PLUGINS_CFLAGS := $(CONSTIFY_PLUGIN_CFLAGS) $(STACKLEAK_PLUGIN_CFLAGS) $(KALLOCSTAT_PLUGIN_CFLAGS)
+GCC_PLUGINS_CFLAGS += $(KERNEXEC_PLUGIN_CFLAGS) $(CHECKER_PLUGIN_CFLAGS) $(COLORIZE_PLUGIN_CFLAGS)
+GCC_PLUGINS_CFLAGS += $(SIZE_OVERFLOW_PLUGIN_CFLAGS) $(LATENT_ENTROPY_PLUGIN_CFLAGS) $(STRUCTLEAK_PLUGIN_CFLAGS)
+GCC_PLUGINS_AFLAGS := $(KERNEXEC_PLUGIN_AFLAGS)
+export PLUGINCC CONSTIFY_PLUGIN LATENT_ENTROPY_PLUGIN_CFLAGS
+ifeq ($(KBUILD_EXTMOD),)
+gcc-plugins:
+	$(Q)$(MAKE) $(build)=tools/gcc
+else
+gcc-plugins: ;
+endif
+else
+gcc-plugins:
+ifeq ($(call cc-ifversion, -ge, 0405, y), y)
+	$(Q)echo "warning, your gcc installation does not support plugins, perhaps the necessary headers are missing?"
+else
+	$(Q)echo "warning, your gcc version does not support plugins, you should upgrade it to gcc 4.5 at least"
+endif
+	$(Q)echo "PAX_MEMORY_STACKLEAK and other features will be less secure"
+endif
+
 include $(srctree)/arch/$(SRCARCH)/Makefile
 
 ifneq ($(CONFIG_FRAME_WARN),0)
@@ -596,7 +660,7 @@ KBUILD_CFLAGS   += $(call cc-option, -fn
 
 ifdef CONFIG_DEBUG_INFO
 KBUILD_CFLAGS	+= -g
-KBUILD_AFLAGS	+= -gdwarf-2
+KBUILD_AFLAGS	+= -Wa,--gdwarf-2
 endif
 
 ifdef CONFIG_DEBUG_INFO_REDUCED
@@ -934,6 +998,8 @@ vmlinux.o: $(modpost-init) $(vmlinux-mai
 
 # The actual objects are generated when descending, 
 # make sure no implicit rule kicks in
+$(sort $(vmlinux-init) $(vmlinux-main)) $(vmlinux-lds): KBUILD_CFLAGS += $(GCC_PLUGINS_CFLAGS)
+$(sort $(vmlinux-init) $(vmlinux-main)) $(vmlinux-lds): KBUILD_AFLAGS += $(GCC_PLUGINS_AFLAGS)
 $(sort $(vmlinux-init) $(vmlinux-main)) $(vmlinux-lds): $(vmlinux-dirs) ;
 
 # Handle descending into subdirectories listed in $(vmlinux-dirs)
@@ -943,7 +1009,7 @@ $(sort $(vmlinux-init) $(vmlinux-main))
 # Error messages still appears in the original language
 
 PHONY += $(vmlinux-dirs)
-$(vmlinux-dirs): prepare scripts
+$(vmlinux-dirs): gcc-plugins prepare scripts
 	$(Q)$(MAKE) $(build)=$@
 
 # Store (new) KERNELRELASE string in include/config/kernel.release
@@ -983,10 +1049,13 @@ prepare1: prepare2 include/linux/version
 
 archprepare: archscripts prepare1 scripts_basic
 
+prepare0: KBUILD_CFLAGS += $(GCC_PLUGINS_CFLAGS)
+prepare0: KBUILD_AFLAGS += $(GCC_PLUGINS_AFLAGS)
 prepare0: archprepare FORCE
 	$(Q)$(MAKE) $(build)=.
 
 # All the preparing..
+prepare: KBUILD_CFLAGS := $(filter-out $(GCC_PLUGINS_CFLAGS),$(KBUILD_CFLAGS))
 prepare: prepare0
 
 # Generate some files
@@ -1091,6 +1160,8 @@ all: modules
 #	using awk while concatenating to the final file.
 
 PHONY += modules
+modules: KBUILD_CFLAGS += $(GCC_PLUGINS_CFLAGS)
+modules: KBUILD_AFLAGS += $(GCC_PLUGINS_AFLAGS)
 modules: $(vmlinux-dirs) $(if $(KBUILD_BUILTIN),vmlinux) modules.builtin
 	$(Q)$(AWK) '!x[$$0]++' $(vmlinux-dirs:%=$(objtree)/%/modules.order) > $(objtree)/modules.order
 	@$(kecho) '  Building modules, stage 2.';
@@ -1106,7 +1177,7 @@ modules.builtin: $(vmlinux-dirs:%=%/modu
 
 # Target to prepare building external modules
 PHONY += modules_prepare
-modules_prepare: prepare scripts
+modules_prepare: gcc-plugins prepare scripts
 
 # Target to install modules
 PHONY += modules_install
@@ -1166,6 +1237,8 @@ MRPROPER_DIRS  += include/config usr/inc
                   arch/*/include/generated
 MRPROPER_FILES += .config .config.old .version .old_version             \
                   include/linux/version.h                               \
+                  tools/gcc/size_overflow_plugin/size_overflow_hash_aux.h \
+                  tools/gcc/size_overflow_plugin/size_overflow_hash.h   \
 		  Module.symvers tags TAGS cscope* GPATH GTAGS GRTAGS GSYMS
 
 # clean - Delete most, but leave enough to build external modules
@@ -1202,7 +1275,7 @@ distclean: mrproper
 	@find $(srctree) $(RCS_FIND_IGNORE) \
 		\( -name '*.orig' -o -name '*.rej' -o -name '*~' \
 		-o -name '*.bak' -o -name '#*#' -o -name '.*.orig' \
-		-o -name '.*.rej' \
+		-o -name '.*.rej' -o -name '*.so' \
 		-o -name '*%' -o -name '.*.cmd' -o -name 'core' \) \
 		-type f -print | xargs rm -f
 
@@ -1363,6 +1436,8 @@ PHONY += $(module-dirs) modules
 $(module-dirs): crmodverdir $(objtree)/Module.symvers
 	$(Q)$(MAKE) $(build)=$(patsubst _module_%,%,$@)
 
+modules: KBUILD_CFLAGS += $(GCC_PLUGINS_CFLAGS)
+modules: KBUILD_AFLAGS += $(GCC_PLUGINS_AFLAGS)
 modules: $(module-dirs)
 	@$(kecho) '  Building modules, stage 2.';
 	$(Q)$(MAKE) -f $(srctree)/scripts/Makefile.modpost
@@ -1489,17 +1564,21 @@ else
         target-dir = $(if $(KBUILD_EXTMOD),$(dir $<),$(dir $@))
 endif
 
-%.s: %.c prepare scripts FORCE
+%.s: KBUILD_CFLAGS += $(GCC_PLUGINS_CFLAGS)
+%.s: KBUILD_AFLAGS += $(GCC_PLUGINS_AFLAGS)
+%.s: %.c gcc-plugins prepare scripts FORCE
 	$(Q)$(MAKE) $(build)=$(build-dir) $(target-dir)$(notdir $@)
 %.i: %.c prepare scripts FORCE
 	$(Q)$(MAKE) $(build)=$(build-dir) $(target-dir)$(notdir $@)
-%.o: %.c prepare scripts FORCE
+%.o: KBUILD_CFLAGS += $(GCC_PLUGINS_CFLAGS)
+%.o: KBUILD_AFLAGS += $(GCC_PLUGINS_AFLAGS)
+%.o: %.c gcc-plugins prepare scripts FORCE
 	$(Q)$(MAKE) $(build)=$(build-dir) $(target-dir)$(notdir $@)
 %.lst: %.c prepare scripts FORCE
 	$(Q)$(MAKE) $(build)=$(build-dir) $(target-dir)$(notdir $@)
-%.s: %.S prepare scripts FORCE
+%.s: %.S gcc-plugins prepare scripts FORCE
 	$(Q)$(MAKE) $(build)=$(build-dir) $(target-dir)$(notdir $@)
-%.o: %.S prepare scripts FORCE
+%.o: %.S gcc-plugins prepare scripts FORCE
 	$(Q)$(MAKE) $(build)=$(build-dir) $(target-dir)$(notdir $@)
 %.symtypes: %.c prepare scripts FORCE
 	$(Q)$(MAKE) $(build)=$(build-dir) $(target-dir)$(notdir $@)
@@ -1509,11 +1588,15 @@ endif
 	$(cmd_crmodverdir)
 	$(Q)$(MAKE) KBUILD_MODULES=$(if $(CONFIG_MODULES),1) \
 	$(build)=$(build-dir)
-%/: prepare scripts FORCE
+%/: KBUILD_CFLAGS += $(GCC_PLUGINS_CFLAGS)
+%/: KBUILD_AFLAGS += $(GCC_PLUGINS_AFLAGS)
+%/: gcc-plugins prepare scripts FORCE
 	$(cmd_crmodverdir)
 	$(Q)$(MAKE) KBUILD_MODULES=$(if $(CONFIG_MODULES),1) \
 	$(build)=$(build-dir)
-%.ko: prepare scripts FORCE
+%.ko: KBUILD_CFLAGS += $(GCC_PLUGINS_CFLAGS)
+%.ko: KBUILD_AFLAGS += $(GCC_PLUGINS_AFLAGS)
+%.ko: gcc-plugins prepare scripts FORCE
 	$(cmd_crmodverdir)
 	$(Q)$(MAKE) KBUILD_MODULES=$(if $(CONFIG_MODULES),1)   \
 	$(build)=$(build-dir) $(@:.ko=.o)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/backing-dev.c linux-3.2.71-pax/mm/backing-dev.c
--- linux-3.2.71/mm/backing-dev.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/mm/backing-dev.c	2013-08-19 00:45:51.659807699 +0200
@@ -12,7 +12,7 @@
 #include <linux/device.h>
 #include <trace/events/writeback.h>
 
-static atomic_long_t bdi_seq = ATOMIC_LONG_INIT(0);
+static atomic_long_unchecked_t bdi_seq = ATOMIC_LONG_INIT(0);
 
 struct backing_dev_info default_backing_dev_info = {
 	.name		= "default",
@@ -759,7 +759,6 @@ EXPORT_SYMBOL(bdi_destroy);
 int bdi_setup_and_register(struct backing_dev_info *bdi, char *name,
 			   unsigned int cap)
 {
-	char tmp[32];
 	int err;
 
 	bdi->name = name;
@@ -768,8 +767,7 @@ int bdi_setup_and_register(struct backin
 	if (err)
 		return err;
 
-	sprintf(tmp, "%.28s%s", name, "-%d");
-	err = bdi_register(bdi, NULL, tmp, atomic_long_inc_return(&bdi_seq));
+	err = bdi_register(bdi, NULL, "%.28s-%ld", name, atomic_long_inc_return_unchecked(&bdi_seq));
 	if (err) {
 		bdi_destroy(bdi);
 		return err;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/filemap.c linux-3.2.71-pax/mm/filemap.c
--- linux-3.2.71/mm/filemap.c	2015-08-14 21:48:35.380707909 +0200
+++ linux-3.2.71-pax/mm/filemap.c	2015-08-14 21:48:45.680707359 +0200
@@ -1773,7 +1773,7 @@ int generic_file_mmap(struct file * file
 	struct address_space *mapping = file->f_mapping;
 
 	if (!mapping->a_ops->readpage)
-		return -ENOEXEC;
+		return -ENODEV;
 	file_accessed(file);
 	vma->vm_ops = &generic_file_vm_ops;
 	vma->vm_flags |= VM_CAN_NONLINEAR;
@@ -2021,7 +2021,7 @@ static size_t __iovec_copy_from_user_ina
 
 	while (bytes) {
 		char __user *buf = iov->iov_base + base;
-		int copy = min(bytes, iov->iov_len - base);
+		size_t copy = min(bytes, iov->iov_len - base);
 
 		base = 0;
 		left = __copy_from_user_inatomic(vaddr, buf, copy);
@@ -2050,7 +2050,7 @@ size_t iov_iter_copy_from_user_atomic(st
 	BUG_ON(!in_atomic());
 	kaddr = kmap_atomic(page, KM_USER0);
 	if (likely(i->nr_segs == 1)) {
-		int left;
+		size_t left;
 		char __user *buf = i->iov->iov_base + i->iov_offset;
 		left = __copy_from_user_inatomic(kaddr + offset, buf, bytes);
 		copied = bytes - left;
@@ -2078,7 +2078,7 @@ size_t iov_iter_copy_from_user(struct pa
 
 	kaddr = kmap(page);
 	if (likely(i->nr_segs == 1)) {
-		int left;
+		size_t left;
 		char __user *buf = i->iov->iov_base + i->iov_offset;
 		left = __copy_from_user(kaddr + offset, buf, bytes);
 		copied = bytes - left;
@@ -2108,7 +2108,7 @@ void iov_iter_advance(struct iov_iter *i
 		 * zero-length segments (without overruning the iovec).
 		 */
 		while (bytes || unlikely(i->count && !iov->iov_len)) {
-			int copy;
+			size_t copy;
 
 			copy = min(bytes, iov->iov_len - base);
 			BUG_ON(!i->count || i->count < copy);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/fremap.c linux-3.2.71-pax/mm/fremap.c
--- linux-3.2.71/mm/fremap.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/mm/fremap.c	2012-07-04 19:24:48.920063009 +0200
@@ -155,6 +155,11 @@ SYSCALL_DEFINE5(remap_file_pages, unsign
  retry:
 	vma = find_vma(mm, start);
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (vma && (mm->pax_flags & MF_PAX_SEGMEXEC) && (vma->vm_flags & VM_MAYEXEC))
+		goto out;
+#endif
+
 	/*
 	 * Make sure the vma is shared, that it supports prefaulting,
 	 * and that the remapped range is valid and fully within
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/highmem.c linux-3.2.71-pax/mm/highmem.c
--- linux-3.2.71/mm/highmem.c	2014-07-12 17:42:34.000954215 +0200
+++ linux-3.2.71-pax/mm/highmem.c	2014-07-12 17:42:44.772954191 +0200
@@ -138,9 +138,10 @@ static void flush_all_zero_pkmaps(void)
 		 * So no dangers, even with speculative execution.
 		 */
 		page = pte_page(pkmap_page_table[i]);
+		pax_open_kernel();
 		pte_clear(&init_mm, (unsigned long)page_address(page),
 			  &pkmap_page_table[i]);
-
+		pax_close_kernel();
 		set_page_address(page, NULL);
 		need_flush = 1;
 	}
@@ -199,9 +200,11 @@ start:
 		}
 	}
 	vaddr = PKMAP_ADDR(last_pkmap_nr);
+
+	pax_open_kernel();
 	set_pte_at(&init_mm, vaddr,
 		   &(pkmap_page_table[last_pkmap_nr]), mk_pte(page, kmap_prot));
-
+	pax_close_kernel();
 	pkmap_count[last_pkmap_nr] = 1;
 	set_page_address(page, (void *)vaddr);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/huge_memory.c linux-3.2.71-pax/mm/huge_memory.c
--- linux-3.2.71/mm/huge_memory.c	2014-12-14 21:13:45.330055318 +0100
+++ linux-3.2.71-pax/mm/huge_memory.c	2014-12-14 21:13:52.842069352 +0100
@@ -704,7 +704,7 @@ out:
 	 * run pte_offset_map on the pmd, if an huge pmd could
 	 * materialize from under us from a different thread.
 	 */
-	if (unlikely(__pte_alloc(mm, vma, pmd, address)))
+	if (unlikely(pmd_none(*pmd) && __pte_alloc(mm, vma, pmd, address)))
 		return VM_FAULT_OOM;
 	/* if an huge pmd materialized from under us just retry later */
 	if (unlikely(pmd_trans_huge(*pmd)))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/hugetlb.c linux-3.2.71-pax/mm/hugetlb.c
--- linux-3.2.71/mm/hugetlb.c	2015-05-10 09:22:39.183493145 +0200
+++ linux-3.2.71-pax/mm/hugetlb.c	2015-05-10 09:24:34.571499412 +0200
@@ -2009,15 +2009,17 @@ static int hugetlb_sysctl_handler_common
 	struct hstate *h = &default_hstate;
 	unsigned long tmp;
 	int ret;
+	ctl_table_no_const hugetlb_table;
 
 	tmp = h->max_huge_pages;
 
 	if (write && h->order >= MAX_ORDER)
 		return -EINVAL;
 
-	table->data = &tmp;
-	table->maxlen = sizeof(unsigned long);
-	ret = proc_doulongvec_minmax(table, write, buffer, length, ppos);
+	hugetlb_table = *table;
+	hugetlb_table.data = &tmp;
+	hugetlb_table.maxlen = sizeof(unsigned long);
+	ret = proc_doulongvec_minmax(&hugetlb_table, write, buffer, length, ppos);
 	if (ret)
 		goto out;
 
@@ -2074,15 +2076,17 @@ int hugetlb_overcommit_handler(struct ct
 	struct hstate *h = &default_hstate;
 	unsigned long tmp;
 	int ret;
+	ctl_table_no_const hugetlb_table;
 
 	tmp = h->nr_overcommit_huge_pages;
 
 	if (write && h->order >= MAX_ORDER)
 		return -EINVAL;
 
-	table->data = &tmp;
-	table->maxlen = sizeof(unsigned long);
-	ret = proc_doulongvec_minmax(table, write, buffer, length, ppos);
+	hugetlb_table = *table;
+	hugetlb_table.data = &tmp;
+	hugetlb_table.maxlen = sizeof(unsigned long);
+	ret = proc_doulongvec_minmax(&hugetlb_table, write, buffer, length, ppos);
 	if (ret)
 		goto out;
 
@@ -2518,6 +2522,27 @@ static int unmap_ref_private(struct mm_s
 	return 1;
 }
 
+#ifdef CONFIG_PAX_SEGMEXEC
+static void pax_mirror_huge_pte(struct vm_area_struct *vma, unsigned long address, struct page *page_m)
+{
+	struct mm_struct *mm = vma->vm_mm;
+	struct vm_area_struct *vma_m;
+	unsigned long address_m;
+	pte_t *ptep_m;
+
+	vma_m = pax_find_mirror_vma(vma);
+	if (!vma_m)
+		return;
+
+	BUG_ON(address >= SEGMEXEC_TASK_SIZE);
+	address_m = address + SEGMEXEC_TASK_SIZE;
+	ptep_m = huge_pte_offset(mm, address_m & HPAGE_MASK);
+	get_page(page_m);
+	hugepage_add_anon_rmap(page_m, vma_m, address_m);
+	set_huge_pte_at(mm, address_m, ptep_m, make_huge_pte(vma_m, page_m, 0));
+}
+#endif
+
 /*
  * Hugetlb_cow() should be called with page lock of the original hugepage held.
  */
@@ -2620,6 +2645,11 @@ retry_avoidcopy:
 				make_huge_pte(vma, new_page, 1));
 		page_remove_rmap(old_page);
 		hugepage_add_new_anon_rmap(new_page, vma, address);
+
+#ifdef CONFIG_PAX_SEGMEXEC
+		pax_mirror_huge_pte(vma, address, new_page);
+#endif
+
 		/* Make the old page be freed below */
 		new_page = old_page;
 		mmu_notifier_invalidate_range_end(mm,
@@ -2771,6 +2801,10 @@ retry:
 				&& (vma->vm_flags & VM_SHARED)));
 	set_huge_pte_at(mm, address, ptep, new_pte);
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	pax_mirror_huge_pte(vma, address, page);
+#endif
+
 	if ((flags & FAULT_FLAG_WRITE) && !(vma->vm_flags & VM_SHARED)) {
 		/* Optimization, do the COW without a second fault */
 		ret = hugetlb_cow(mm, vma, address, ptep, new_pte, page);
@@ -2801,6 +2835,10 @@ int hugetlb_fault(struct mm_struct *mm,
 	struct hstate *h = hstate_vma(vma);
 	int need_wait_lock = 0;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	struct vm_area_struct *vma_m;
+#endif
+
 	ptep = huge_pte_offset(mm, address);
 	if (ptep) {
 		entry = huge_ptep_get(ptep);
@@ -2812,6 +2850,26 @@ int hugetlb_fault(struct mm_struct *mm,
 			       VM_FAULT_SET_HINDEX(h - hstates);
 	}
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	vma_m = pax_find_mirror_vma(vma);
+	if (vma_m) {
+		unsigned long address_m;
+
+		if (vma->vm_start > vma_m->vm_start) {
+			address_m = address;
+			address -= SEGMEXEC_TASK_SIZE;
+			vma = vma_m;
+			h = hstate_vma(vma);
+		} else
+			address_m = address + SEGMEXEC_TASK_SIZE;
+
+		if (!huge_pte_alloc(mm, address_m, huge_page_size(h)))
+			return VM_FAULT_OOM;
+		address_m &= HPAGE_MASK;
+		unmap_hugepage_range(vma, address_m, address_m + HPAGE_SIZE, NULL);
+	}
+#endif
+
 	ptep = huge_pte_alloc(mm, address, huge_page_size(h));
 	if (!ptep)
 		return VM_FAULT_OOM;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/internal.h linux-3.2.71-pax/mm/internal.h
--- linux-3.2.71/mm/internal.h	2012-08-12 12:28:43.045231782 +0200
+++ linux-3.2.71-pax/mm/internal.h	2012-08-12 12:28:56.933231851 +0200
@@ -95,6 +95,7 @@ extern void putback_lru_page(struct page
  * in mm/page_alloc.c
  */
 extern void __free_pages_bootmem(struct page *page, unsigned int order);
+extern void free_compound_page(struct page *page);
 extern void prep_compound_page(struct page *page, unsigned long order);
 #ifdef CONFIG_MEMORY_FAILURE
 extern bool is_free_buddy_page(struct page *page);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/Kconfig linux-3.2.71-pax/mm/Kconfig
--- linux-3.2.71/mm/Kconfig	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/mm/Kconfig	2012-07-04 19:24:48.924063008 +0200
@@ -241,10 +241,10 @@ config KSM
 	  root has set /sys/kernel/mm/ksm/run to 1 (if CONFIG_SYSFS is set).
 
 config DEFAULT_MMAP_MIN_ADDR
-        int "Low address space to protect from user allocation"
+	int "Low address space to protect from user allocation"
 	depends on MMU
-        default 4096
-        help
+	default 32768
+	help
 	  This is the portion of low virtual memory which should be protected
 	  from userspace allocation.  Keeping a user from writing to low pages
 	  can help reduce the impact of kernel NULL pointer bugs.
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/maccess.c linux-3.2.71-pax/mm/maccess.c
--- linux-3.2.71/mm/maccess.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/mm/maccess.c	2012-07-04 19:24:48.928063008 +0200
@@ -26,7 +26,7 @@ long __probe_kernel_read(void *dst, cons
 	set_fs(KERNEL_DS);
 	pagefault_disable();
 	ret = __copy_from_user_inatomic(dst,
-			(__force const void __user *)src, size);
+			(const void __force_user *)src, size);
 	pagefault_enable();
 	set_fs(old_fs);
 
@@ -53,7 +53,7 @@ long __probe_kernel_write(void *dst, con
 
 	set_fs(KERNEL_DS);
 	pagefault_disable();
-	ret = __copy_to_user_inatomic((__force void __user *)dst, src, size);
+	ret = __copy_to_user_inatomic((void __force_user *)dst, src, size);
 	pagefault_enable();
 	set_fs(old_fs);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/madvise.c linux-3.2.71-pax/mm/madvise.c
--- linux-3.2.71/mm/madvise.c	2012-07-12 18:23:34.921071950 +0200
+++ linux-3.2.71-pax/mm/madvise.c	2015-04-30 02:44:51.224492198 +0200
@@ -46,6 +46,10 @@ static long madvise_behavior(struct vm_a
 	pgoff_t pgoff;
 	unsigned long new_flags = vma->vm_flags;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	struct vm_area_struct *vma_m;
+#endif
+
 	switch (behavior) {
 	case MADV_NORMAL:
 		new_flags = new_flags & ~VM_RAND_READ & ~VM_SEQ_READ;
@@ -111,6 +115,13 @@ success:
 	/*
 	 * vm_flags is protected by the mmap_sem held in write mode.
 	 */
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	vma_m = pax_find_mirror_vma(vma);
+	if (vma_m)
+		vma_m->vm_flags = new_flags & ~(VM_WRITE | VM_MAYWRITE | VM_ACCOUNT);
+#endif
+
 	vma->vm_flags = new_flags;
 
 out:
@@ -169,6 +180,11 @@ static long madvise_dontneed(struct vm_a
 			     struct vm_area_struct ** prev,
 			     unsigned long start, unsigned long end)
 {
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	struct vm_area_struct *vma_m;
+#endif
+
 	*prev = vma;
 	if (vma->vm_flags & (VM_LOCKED|VM_HUGETLB|VM_PFNMAP))
 		return -EINVAL;
@@ -181,6 +197,21 @@ static long madvise_dontneed(struct vm_a
 		zap_page_range(vma, start, end - start, &details);
 	} else
 		zap_page_range(vma, start, end - start, NULL);
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	vma_m = pax_find_mirror_vma(vma);
+	if (vma_m) {
+		if (unlikely(vma->vm_flags & VM_NONLINEAR)) {
+			struct zap_details details = {
+				.nonlinear_vma = vma_m,
+				.last_index = ULONG_MAX,
+			};
+			zap_page_range(vma_m, start + SEGMEXEC_TASK_SIZE, end - start, &details);
+		} else
+			zap_page_range(vma_m, start + SEGMEXEC_TASK_SIZE, end - start, NULL);
+	}
+#endif
+
 	return 0;
 }
 
@@ -386,6 +417,16 @@ SYSCALL_DEFINE3(madvise, unsigned long,
 	if (end < start)
 		goto out;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (current->mm->pax_flags & MF_PAX_SEGMEXEC) {
+		if (end > SEGMEXEC_TASK_SIZE)
+			goto out;
+	} else
+#endif
+
+	if (end > TASK_SIZE)
+		goto out;
+
 	error = 0;
 	if (end == start)
 		goto out;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/memory.c linux-3.2.71-pax/mm/memory.c
--- linux-3.2.71/mm/memory.c	2015-08-14 21:48:35.380707909 +0200
+++ linux-3.2.71-pax/mm/memory.c	2015-08-20 15:12:35.253248835 +0200
@@ -462,8 +462,12 @@ static inline void free_pmd_range(struct
 		return;
 
 	pmd = pmd_offset(pud, start);
+
+#if !defined(CONFIG_X86_32) || !defined(CONFIG_PAX_PER_CPU_PGD)
 	pud_clear(pud);
 	pmd_free_tlb(tlb, pmd, start);
+#endif
+
 }
 
 static inline void free_pud_range(struct mmu_gather *tlb, pgd_t *pgd,
@@ -494,9 +498,12 @@ static inline void free_pud_range(struct
 	if (end - 1 > ceiling - 1)
 		return;
 
+#if !defined(CONFIG_X86_64) || !defined(CONFIG_PAX_PER_CPU_PGD)
 	pud = pud_offset(pgd, start);
 	pgd_clear(pgd);
 	pud_free_tlb(tlb, pud, start);
+#endif
+
 }
 
 /*
@@ -1584,12 +1591,6 @@ no_page_table:
 	return page;
 }
 
-static inline int stack_guard_page(struct vm_area_struct *vma, unsigned long addr)
-{
-	return stack_guard_page_start(vma, addr) ||
-	       stack_guard_page_end(vma, addr+PAGE_SIZE);
-}
-
 /**
  * __get_user_pages() - pin user pages in memory
  * @tsk:	task_struct of target task
@@ -1662,10 +1663,10 @@ int __get_user_pages(struct task_struct
 			(VM_MAYREAD | VM_MAYWRITE) : (VM_READ | VM_WRITE);
 	i = 0;
 
-	do {
+	while (nr_pages) {
 		struct vm_area_struct *vma;
 
-		vma = find_extend_vma(mm, start);
+		vma = find_vma(mm, start);
 		if (!vma && in_gate_area(mm, start)) {
 			unsigned long pg = start & PAGE_MASK;
 			pgd_t *pgd;
@@ -1713,7 +1714,7 @@ int __get_user_pages(struct task_struct
 			goto next_page;
 		}
 
-		if (!vma ||
+		if (!vma || start < vma->vm_start ||
 		    (vma->vm_flags & (VM_IO | VM_PFNMAP)) ||
 		    !(vm_flags & vma->vm_flags))
 			return i ? : -EFAULT;
@@ -1740,11 +1741,6 @@ int __get_user_pages(struct task_struct
 				int ret;
 				unsigned int fault_flags = 0;
 
-				/* For mlock, just skip the stack guard page. */
-				if (foll_flags & FOLL_MLOCK) {
-					if (stack_guard_page(vma, start))
-						goto next_page;
-				}
 				if (foll_flags & FOLL_WRITE)
 					fault_flags |= FAULT_FLAG_WRITE;
 				if (nonblocking)
@@ -1818,7 +1814,7 @@ next_page:
 			start += PAGE_SIZE;
 			nr_pages--;
 		} while (nr_pages && start < vma->vm_end);
-	} while (nr_pages);
+	}
 	return i;
 }
 EXPORT_SYMBOL(__get_user_pages);
@@ -2030,6 +2026,10 @@ static int insert_page(struct vm_area_st
 	page_add_file_rmap(page);
 	set_pte_at(mm, addr, pte, mk_pte(page, prot));
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	pax_mirror_file_pte(vma, addr, page, ptl);
+#endif
+
 	retval = 0;
 	pte_unmap_unlock(pte, ptl);
 	return retval;
@@ -2064,10 +2064,22 @@ out:
 int vm_insert_page(struct vm_area_struct *vma, unsigned long addr,
 			struct page *page)
 {
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	struct vm_area_struct *vma_m;
+#endif
+
 	if (addr < vma->vm_start || addr >= vma->vm_end)
 		return -EFAULT;
 	if (!page_count(page))
 		return -EINVAL;
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	vma_m = pax_find_mirror_vma(vma);
+	if (vma_m)
+		vma_m->vm_flags |= VM_INSERTPAGE;
+#endif
+
 	vma->vm_flags |= VM_INSERTPAGE;
 	return insert_page(vma, addr, page, vma->vm_page_prot);
 }
@@ -2153,6 +2165,7 @@ int vm_insert_mixed(struct vm_area_struc
 			unsigned long pfn)
 {
 	BUG_ON(!(vma->vm_flags & VM_MIXEDMAP));
+	BUG_ON(vma->vm_mirror);
 
 	if (addr < vma->vm_start || addr >= vma->vm_end)
 		return -EFAULT;
@@ -2407,7 +2420,9 @@ static int apply_to_pmd_range(struct mm_
 
 	BUG_ON(pud_huge(*pud));
 
-	pmd = pmd_alloc(mm, pud, addr);
+	pmd = (mm == &init_mm) ?
+		pmd_alloc_kernel(mm, pud, addr) :
+		pmd_alloc(mm, pud, addr);
 	if (!pmd)
 		return -ENOMEM;
 	do {
@@ -2427,7 +2442,9 @@ static int apply_to_pud_range(struct mm_
 	unsigned long next;
 	int err;
 
-	pud = pud_alloc(mm, pgd, addr);
+	pud = (mm == &init_mm) ?
+		pud_alloc_kernel(mm, pgd, addr) :
+		pud_alloc(mm, pgd, addr);
 	if (!pud)
 		return -ENOMEM;
 	do {
@@ -2515,6 +2532,192 @@ static inline void cow_user_page(struct
 		copy_user_highpage(dst, src, va, vma);
 }
 
+#ifdef CONFIG_PAX_SEGMEXEC
+static void pax_unmap_mirror_pte(struct vm_area_struct *vma, unsigned long address, pmd_t *pmd)
+{
+	struct mm_struct *mm = vma->vm_mm;
+	spinlock_t *ptl;
+	pte_t *pte, entry;
+
+	pte = pte_offset_map_lock(mm, pmd, address, &ptl);
+	entry = *pte;
+	if (pte_none(entry))
+		;
+	else if (!pte_present(entry)) {
+		swp_entry_t swapentry;
+
+		BUG_ON(pte_file(entry));
+
+		swapentry = pte_to_swp_entry(entry);
+		if (!non_swap_entry(swapentry))
+			dec_mm_counter_fast(mm, MM_SWAPENTS);
+		free_swap_and_cache(swapentry);
+		pte_clear_not_present_full(mm, address, pte, 0);
+	} else {
+		struct page *page;
+
+		flush_cache_page(vma, address, pte_pfn(entry));
+		entry = ptep_clear_flush(vma, address, pte);
+		BUG_ON(pte_dirty(entry));
+		page = vm_normal_page(vma, address, entry);
+		if (page) {
+			update_hiwater_rss(mm);
+			if (PageAnon(page))
+				dec_mm_counter_fast(mm, MM_ANONPAGES);
+			else
+				dec_mm_counter_fast(mm, MM_FILEPAGES);
+			page_remove_rmap(page);
+			page_cache_release(page);
+		}
+	}
+	pte_unmap_unlock(pte, ptl);
+}
+
+/* PaX: if vma is mirrored, synchronize the mirror's PTE
+ *
+ * the ptl of the lower mapped page is held on entry and is not released on exit
+ * or inside to ensure atomic changes to the PTE states (swapout, mremap, munmap, etc)
+ */
+static void pax_mirror_anon_pte(struct vm_area_struct *vma, unsigned long address, struct page *page_m, spinlock_t *ptl)
+{
+	struct mm_struct *mm = vma->vm_mm;
+	unsigned long address_m;
+	spinlock_t *ptl_m;
+	struct vm_area_struct *vma_m;
+	pmd_t *pmd_m;
+	pte_t *pte_m, entry_m;
+
+	BUG_ON(!page_m || !PageAnon(page_m));
+
+	vma_m = pax_find_mirror_vma(vma);
+	if (!vma_m)
+		return;
+
+	BUG_ON(!PageLocked(page_m));
+	BUG_ON(address >= SEGMEXEC_TASK_SIZE);
+	address_m = address + SEGMEXEC_TASK_SIZE;
+	pmd_m = pmd_offset(pud_offset(pgd_offset(mm, address_m), address_m), address_m);
+	pte_m = pte_offset_map(pmd_m, address_m);
+	ptl_m = pte_lockptr(mm, pmd_m);
+	if (ptl != ptl_m) {
+		spin_lock_nested(ptl_m, SINGLE_DEPTH_NESTING);
+		if (!pte_none(*pte_m))
+			goto out;
+	}
+
+	entry_m = pfn_pte(page_to_pfn(page_m), vma_m->vm_page_prot);
+	page_cache_get(page_m);
+	page_add_anon_rmap(page_m, vma_m, address_m);
+	inc_mm_counter_fast(mm, MM_ANONPAGES);
+	set_pte_at(mm, address_m, pte_m, entry_m);
+	update_mmu_cache(vma_m, address_m, entry_m);
+out:
+	if (ptl != ptl_m)
+		spin_unlock(ptl_m);
+	pte_unmap(pte_m);
+	unlock_page(page_m);
+}
+
+void pax_mirror_file_pte(struct vm_area_struct *vma, unsigned long address, struct page *page_m, spinlock_t *ptl)
+{
+	struct mm_struct *mm = vma->vm_mm;
+	unsigned long address_m;
+	spinlock_t *ptl_m;
+	struct vm_area_struct *vma_m;
+	pmd_t *pmd_m;
+	pte_t *pte_m, entry_m;
+
+	BUG_ON(!page_m || PageAnon(page_m));
+
+	vma_m = pax_find_mirror_vma(vma);
+	if (!vma_m)
+		return;
+
+	BUG_ON(address >= SEGMEXEC_TASK_SIZE);
+	address_m = address + SEGMEXEC_TASK_SIZE;
+	pmd_m = pmd_offset(pud_offset(pgd_offset(mm, address_m), address_m), address_m);
+	pte_m = pte_offset_map(pmd_m, address_m);
+	ptl_m = pte_lockptr(mm, pmd_m);
+	if (ptl != ptl_m) {
+		spin_lock_nested(ptl_m, SINGLE_DEPTH_NESTING);
+		if (!pte_none(*pte_m))
+			goto out;
+	}
+
+	entry_m = pfn_pte(page_to_pfn(page_m), vma_m->vm_page_prot);
+	page_cache_get(page_m);
+	page_add_file_rmap(page_m);
+	inc_mm_counter_fast(mm, MM_FILEPAGES);
+	set_pte_at(mm, address_m, pte_m, entry_m);
+	update_mmu_cache(vma_m, address_m, entry_m);
+out:
+	if (ptl != ptl_m)
+		spin_unlock(ptl_m);
+	pte_unmap(pte_m);
+}
+
+static void pax_mirror_pfn_pte(struct vm_area_struct *vma, unsigned long address, unsigned long pfn_m, spinlock_t *ptl)
+{
+	struct mm_struct *mm = vma->vm_mm;
+	unsigned long address_m;
+	spinlock_t *ptl_m;
+	struct vm_area_struct *vma_m;
+	pmd_t *pmd_m;
+	pte_t *pte_m, entry_m;
+
+	vma_m = pax_find_mirror_vma(vma);
+	if (!vma_m)
+		return;
+
+	BUG_ON(address >= SEGMEXEC_TASK_SIZE);
+	address_m = address + SEGMEXEC_TASK_SIZE;
+	pmd_m = pmd_offset(pud_offset(pgd_offset(mm, address_m), address_m), address_m);
+	pte_m = pte_offset_map(pmd_m, address_m);
+	ptl_m = pte_lockptr(mm, pmd_m);
+	if (ptl != ptl_m) {
+		spin_lock_nested(ptl_m, SINGLE_DEPTH_NESTING);
+		if (!pte_none(*pte_m))
+			goto out;
+	}
+
+	entry_m = pfn_pte(pfn_m, vma_m->vm_page_prot);
+	set_pte_at(mm, address_m, pte_m, entry_m);
+out:
+	if (ptl != ptl_m)
+		spin_unlock(ptl_m);
+	pte_unmap(pte_m);
+}
+
+static void pax_mirror_pte(struct vm_area_struct *vma, unsigned long address, pte_t *pte, pmd_t *pmd, spinlock_t *ptl)
+{
+	struct page *page_m;
+	pte_t entry;
+
+	if (!(vma->vm_mm->pax_flags & MF_PAX_SEGMEXEC))
+		goto out;
+
+	entry = *pte;
+	page_m  = vm_normal_page(vma, address, entry);
+	if (!page_m)
+		pax_mirror_pfn_pte(vma, address, pte_pfn(entry), ptl);
+	else if (PageAnon(page_m)) {
+		if (pax_find_mirror_vma(vma)) {
+			pte_unmap_unlock(pte, ptl);
+			lock_page(page_m);
+			pte = pte_offset_map_lock(vma->vm_mm, pmd, address, &ptl);
+			if (pte_same(entry, *pte))
+				pax_mirror_anon_pte(vma, address, page_m, ptl);
+			else
+				unlock_page(page_m);
+		}
+	} else
+		pax_mirror_file_pte(vma, address, page_m, ptl);
+
+out:
+	pte_unmap_unlock(pte, ptl);
+}
+#endif
+
 /*
  * This routine handles present pages, when users try to write
  * to a shared page. It is done by copying the page to a new address
@@ -2733,6 +2936,12 @@ gotten:
 	 */
 	page_table = pte_offset_map_lock(mm, pmd, address, &ptl);
 	if (likely(pte_same(*page_table, orig_pte))) {
+
+#ifdef CONFIG_PAX_SEGMEXEC
+		if (pax_find_mirror_vma(vma))
+			BUG_ON(!trylock_page(new_page));
+#endif
+
 		if (old_page) {
 			if (!PageAnon(old_page)) {
 				dec_mm_counter_fast(mm, MM_FILEPAGES);
@@ -2784,6 +2993,10 @@ gotten:
 			page_remove_rmap(old_page);
 		}
 
+#ifdef CONFIG_PAX_SEGMEXEC
+		pax_mirror_anon_pte(vma, address, new_page, ptl);
+#endif
+
 		/* Free the old page.. */
 		new_page = old_page;
 		ret |= VM_FAULT_WRITE;
@@ -3063,6 +3276,11 @@ static int do_swap_page(struct mm_struct
 	swap_free(entry);
 	if (vm_swap_full() || (vma->vm_flags & VM_LOCKED) || PageMlocked(page))
 		try_to_free_swap(page);
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if ((flags & FAULT_FLAG_WRITE) || !pax_find_mirror_vma(vma))
+#endif
+
 	unlock_page(page);
 	if (swapcache) {
 		/*
@@ -3086,6 +3304,11 @@ static int do_swap_page(struct mm_struct
 
 	/* No need to invalidate - it was non-present before */
 	update_mmu_cache(vma, address, page_table);
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	pax_mirror_anon_pte(vma, address, page, ptl);
+#endif
+
 unlock:
 	pte_unmap_unlock(page_table, ptl);
 out:
@@ -3105,40 +3328,6 @@ out_release:
 }
 
 /*
- * This is like a special single-page "expand_{down|up}wards()",
- * except we must first make sure that 'address{-|+}PAGE_SIZE'
- * doesn't hit another vma.
- */
-static inline int check_stack_guard_page(struct vm_area_struct *vma, unsigned long address)
-{
-	address &= PAGE_MASK;
-	if ((vma->vm_flags & VM_GROWSDOWN) && address == vma->vm_start) {
-		struct vm_area_struct *prev = vma->vm_prev;
-
-		/*
-		 * Is there a mapping abutting this one below?
-		 *
-		 * That's only ok if it's the same stack mapping
-		 * that has gotten split..
-		 */
-		if (prev && prev->vm_end == address)
-			return prev->vm_flags & VM_GROWSDOWN ? 0 : -ENOMEM;
-
-		return expand_downwards(vma, address - PAGE_SIZE);
-	}
-	if ((vma->vm_flags & VM_GROWSUP) && address + PAGE_SIZE == vma->vm_end) {
-		struct vm_area_struct *next = vma->vm_next;
-
-		/* As VM_GROWSDOWN but s/below/above/ */
-		if (next && next->vm_start == address + PAGE_SIZE)
-			return next->vm_flags & VM_GROWSUP ? 0 : -ENOMEM;
-
-		return expand_upwards(vma, address + PAGE_SIZE);
-	}
-	return 0;
-}
-
-/*
  * We enter with non-exclusive mmap_sem (to exclude vma changes,
  * but allow concurrent faults), and pte mapped but not yet locked.
  * We return with mmap_sem still held, but pte unmapped and unlocked.
@@ -3147,31 +3336,29 @@ static int do_anonymous_page(struct mm_s
 		unsigned long address, pte_t *page_table, pmd_t *pmd,
 		unsigned int flags)
 {
-	struct page *page;
+	struct page *page = NULL;
 	spinlock_t *ptl;
 	pte_t entry;
 
-	pte_unmap(page_table);
-
 	/* File mapping without ->vm_ops ? */
-	if (vma->vm_flags & VM_SHARED)
+	if (vma->vm_flags & VM_SHARED) {
+		pte_unmap(page_table);
 		return VM_FAULT_SIGBUS;
+	}
 
-	/* Check if we need to add a guard page to the stack */
-	if (check_stack_guard_page(vma, address) < 0)
-		return VM_FAULT_SIGSEGV;
-
-	/* Use the zero-page for reads */
 	if (!(flags & FAULT_FLAG_WRITE)) {
 		entry = pte_mkspecial(pfn_pte(my_zero_pfn(address),
 						vma->vm_page_prot));
-		page_table = pte_offset_map_lock(mm, pmd, address, &ptl);
+		ptl = pte_lockptr(mm, pmd);
+		spin_lock(ptl);
 		if (!pte_none(*page_table))
 			goto unlock;
 		goto setpte;
 	}
 
 	/* Allocate our own private page. */
+	pte_unmap(page_table);
+
 	if (unlikely(anon_vma_prepare(vma)))
 		goto oom;
 	page = alloc_zeroed_user_highpage_movable(vma, address);
@@ -3190,6 +3377,11 @@ static int do_anonymous_page(struct mm_s
 	if (!pte_none(*page_table))
 		goto release;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (pax_find_mirror_vma(vma))
+		BUG_ON(!trylock_page(page));
+#endif
+
 	inc_mm_counter_fast(mm, MM_ANONPAGES);
 	page_add_new_anon_rmap(page, vma, address);
 setpte:
@@ -3197,6 +3389,12 @@ setpte:
 
 	/* No need to invalidate - it was non-present before */
 	update_mmu_cache(vma, address, page_table);
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (page)
+		pax_mirror_anon_pte(vma, address, page, ptl);
+#endif
+
 unlock:
 	pte_unmap_unlock(page_table, ptl);
 	return 0;
@@ -3340,6 +3538,12 @@ static int __do_fault(struct mm_struct *
 	 */
 	/* Only go through if we didn't race with anybody else... */
 	if (likely(pte_same(*page_table, orig_pte))) {
+
+#ifdef CONFIG_PAX_SEGMEXEC
+		if (anon && pax_find_mirror_vma(vma))
+			BUG_ON(!trylock_page(page));
+#endif
+
 		flush_icache_page(vma, page);
 		entry = mk_pte(page, vma->vm_page_prot);
 		if (flags & FAULT_FLAG_WRITE)
@@ -3359,6 +3563,14 @@ static int __do_fault(struct mm_struct *
 
 		/* no need to invalidate: a not-present page won't be cached */
 		update_mmu_cache(vma, address, page_table);
+
+#ifdef CONFIG_PAX_SEGMEXEC
+		if (anon)
+			pax_mirror_anon_pte(vma, address, page, ptl);
+		else
+			pax_mirror_file_pte(vma, address, page, ptl);
+#endif
+
 	} else {
 		if (cow_page)
 			mem_cgroup_uncharge_page(cow_page);
@@ -3513,6 +3725,12 @@ int handle_pte_fault(struct mm_struct *m
 		if (flags & FAULT_FLAG_WRITE)
 			flush_tlb_fix_spurious_fault(vma, address);
 	}
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	pax_mirror_pte(vma, address, pte, pmd, ptl);
+	return 0;
+#endif
+
 unlock:
 	pte_unmap_unlock(pte, ptl);
 	return 0;
@@ -3529,6 +3747,10 @@ int handle_mm_fault(struct mm_struct *mm
 	pmd_t *pmd;
 	pte_t *pte;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	struct vm_area_struct *vma_m;
+#endif
+
 	__set_current_state(TASK_RUNNING);
 
 	count_vm_event(PGFAULT);
@@ -3540,6 +3762,34 @@ int handle_mm_fault(struct mm_struct *mm
 	if (unlikely(is_vm_hugetlb_page(vma)))
 		return hugetlb_fault(mm, vma, address, flags);
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	vma_m = pax_find_mirror_vma(vma);
+	if (vma_m) {
+		unsigned long address_m;
+		pgd_t *pgd_m;
+		pud_t *pud_m;
+		pmd_t *pmd_m;
+
+		if (vma->vm_start > vma_m->vm_start) {
+			address_m = address;
+			address -= SEGMEXEC_TASK_SIZE;
+			vma = vma_m;
+		} else
+			address_m = address + SEGMEXEC_TASK_SIZE;
+
+		pgd_m = pgd_offset(mm, address_m);
+		pud_m = pud_alloc(mm, pgd_m, address_m);
+		if (!pud_m)
+			return VM_FAULT_OOM;
+		pmd_m = pmd_alloc(mm, pud_m, address_m);
+		if (!pmd_m)
+			return VM_FAULT_OOM;
+		if (!pmd_present(*pmd_m) && __pte_alloc(mm, vma_m, pmd_m, address_m))
+			return VM_FAULT_OOM;
+		pax_unmap_mirror_pte(vma_m, address_m, pmd_m);
+	}
+#endif
+
 retry:
 	pgd = pgd_offset(mm, address);
 	pud = pud_alloc(mm, pgd, address);
@@ -3581,7 +3831,7 @@ retry:
 	 * run pte_offset_map on the pmd, if an huge pmd could
 	 * materialize from under us from a different thread.
 	 */
-	if (unlikely(pmd_none(*pmd)) && __pte_alloc(mm, vma, pmd, address))
+	if (unlikely(pmd_none(*pmd) && __pte_alloc(mm, vma, pmd, address)))
 		return VM_FAULT_OOM;
 	/* if an huge pmd materialized from under us just retry later */
 	if (unlikely(pmd_trans_huge(*pmd)))
@@ -3618,6 +3868,23 @@ int __pud_alloc(struct mm_struct *mm, pg
 	spin_unlock(&mm->page_table_lock);
 	return 0;
 }
+
+int __pud_alloc_kernel(struct mm_struct *mm, pgd_t *pgd, unsigned long address)
+{
+	pud_t *new = pud_alloc_one(mm, address);
+	if (!new)
+		return -ENOMEM;
+
+	smp_wmb(); /* See comment in __pte_alloc */
+
+	spin_lock(&mm->page_table_lock);
+	if (pgd_present(*pgd))		/* Another has populated it */
+		pud_free(mm, new);
+	else
+		pgd_populate_kernel(mm, pgd, new);
+	spin_unlock(&mm->page_table_lock);
+	return 0;
+}
 #endif /* __PAGETABLE_PUD_FOLDED */
 
 #ifndef __PAGETABLE_PMD_FOLDED
@@ -3648,11 +3915,35 @@ int __pmd_alloc(struct mm_struct *mm, pu
 	spin_unlock(&mm->page_table_lock);
 	return 0;
 }
+
+int __pmd_alloc_kernel(struct mm_struct *mm, pud_t *pud, unsigned long address)
+{
+	pmd_t *new = pmd_alloc_one(mm, address);
+	if (!new)
+		return -ENOMEM;
+
+	smp_wmb(); /* See comment in __pte_alloc */
+
+	spin_lock(&mm->page_table_lock);
+#ifndef __ARCH_HAS_4LEVEL_HACK
+	if (pud_present(*pud))		/* Another has populated it */
+		pmd_free(mm, new);
+	else
+		pud_populate_kernel(mm, pud, new);
+#else
+	if (pgd_present(*pud))		/* Another has populated it */
+		pmd_free(mm, new);
+	else
+		pgd_populate_kernel(mm, pud, new);
+#endif /* __ARCH_HAS_4LEVEL_HACK */
+	spin_unlock(&mm->page_table_lock);
+	return 0;
+}
 #endif /* __PAGETABLE_PMD_FOLDED */
 
-int make_pages_present(unsigned long addr, unsigned long end)
+ssize_t make_pages_present(unsigned long addr, unsigned long end)
 {
-	int ret, len, write;
+	ssize_t ret, len, write;
 	struct vm_area_struct * vma;
 
 	vma = find_vma(current->mm, addr);
@@ -3685,7 +3976,7 @@ static int __init gate_vma_init(void)
 	gate_vma.vm_start = FIXADDR_USER_START;
 	gate_vma.vm_end = FIXADDR_USER_END;
 	gate_vma.vm_flags = VM_READ | VM_MAYREAD | VM_EXEC | VM_MAYEXEC;
-	gate_vma.vm_page_prot = __P101;
+	gate_vma.vm_page_prot = vm_get_page_prot(gate_vma.vm_flags);
 	/*
 	 * Make sure the vDSO gets into every core dump.
 	 * Dumping its contents makes post-mortem fully interpretable later
@@ -3825,8 +4116,8 @@ out:
 	return ret;
 }
 
-int generic_access_phys(struct vm_area_struct *vma, unsigned long addr,
-			void *buf, int len, int write)
+ssize_t generic_access_phys(struct vm_area_struct *vma, unsigned long addr,
+			void *buf, size_t len, int write)
 {
 	resource_size_t phys_addr;
 	unsigned long prot = 0;
@@ -3851,8 +4142,8 @@ int generic_access_phys(struct vm_area_s
  * Access another process' address space as given in mm.  If non-NULL, use the
  * given task for page fault accounting.
  */
-static int __access_remote_vm(struct task_struct *tsk, struct mm_struct *mm,
-		unsigned long addr, void *buf, int len, int write)
+static ssize_t __access_remote_vm(struct task_struct *tsk, struct mm_struct *mm,
+		unsigned long addr, void *buf, size_t len, int write)
 {
 	struct vm_area_struct *vma;
 	void *old_buf = buf;
@@ -3860,7 +4151,7 @@ static int __access_remote_vm(struct tas
 	down_read(&mm->mmap_sem);
 	/* ignore errors, just check how much was successfully transferred */
 	while (len) {
-		int bytes, ret, offset;
+		ssize_t bytes, ret, offset;
 		void *maddr;
 		struct page *page = NULL;
 
@@ -3919,8 +4210,8 @@ static int __access_remote_vm(struct tas
  *
  * The caller must hold a reference on @mm.
  */
-int access_remote_vm(struct mm_struct *mm, unsigned long addr,
-		void *buf, int len, int write)
+ssize_t access_remote_vm(struct mm_struct *mm, unsigned long addr,
+		void *buf, size_t len, int write)
 {
 	return __access_remote_vm(NULL, mm, addr, buf, len, write);
 }
@@ -3930,11 +4221,11 @@ int access_remote_vm(struct mm_struct *m
  * Source/target buffer must be kernel space,
  * Do not walk the page table directly, use get_user_pages
  */
-int access_process_vm(struct task_struct *tsk, unsigned long addr,
-		void *buf, int len, int write)
+ssize_t access_process_vm(struct task_struct *tsk, unsigned long addr,
+		void *buf, size_t len, int write)
 {
 	struct mm_struct *mm;
-	int ret;
+	ssize_t ret;
 
 	mm = get_task_mm(tsk);
 	if (!mm)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/memory-failure.c linux-3.2.71-pax/mm/memory-failure.c
--- linux-3.2.71/mm/memory-failure.c	2014-06-10 10:59:38.802436242 +0200
+++ linux-3.2.71-pax/mm/memory-failure.c	2014-06-10 11:01:02.866431754 +0200
@@ -61,7 +61,7 @@ int sysctl_memory_failure_early_kill __r
 
 int sysctl_memory_failure_recovery __read_mostly = 1;
 
-atomic_long_t mce_bad_pages __read_mostly = ATOMIC_LONG_INIT(0);
+atomic_long_unchecked_t mce_bad_pages __read_mostly = ATOMIC_LONG_INIT(0);
 
 #if defined(CONFIG_HWPOISON_INJECT) || defined(CONFIG_HWPOISON_INJECT_MODULE)
 
@@ -202,7 +202,7 @@ static int kill_proc_ao(struct task_stru
 	si.si_signo = SIGBUS;
 	si.si_errno = 0;
 	si.si_code = BUS_MCEERR_AO;
-	si.si_addr = (void *)addr;
+	si.si_addr = (void __user *)addr;
 #ifdef __ARCH_SI_TRAPNO
 	si.si_trapno = trapno;
 #endif
@@ -750,7 +750,7 @@ static struct page_state {
 	unsigned long res;
 	char *msg;
 	int (*action)(struct page *p, unsigned long pfn);
-} error_states[] = {
+} __do_const error_states[] = {
 	{ reserved,	reserved,	"reserved kernel",	me_kernel },
 	/*
 	 * free pages are specially detected outside this table:
@@ -1010,7 +1010,7 @@ int __memory_failure(unsigned long pfn,
 	}
 
 	nr_pages = 1 << compound_trans_order(hpage);
-	atomic_long_add(nr_pages, &mce_bad_pages);
+	atomic_long_add_unchecked(nr_pages, &mce_bad_pages);
 
 	/*
 	 * We need/can do nothing about count=0 pages.
@@ -1039,7 +1039,7 @@ int __memory_failure(unsigned long pfn,
 			if (PageHWPoison(hpage)) {
 				if ((hwpoison_filter(p) && TestClearPageHWPoison(p))
 				    || (p != hpage && TestSetPageHWPoison(hpage))) {
-					atomic_long_sub(nr_pages, &mce_bad_pages);
+					atomic_long_sub_unchecked(nr_pages, &mce_bad_pages);
 					unlock_page(hpage);
 					return 0;
 				}
@@ -1094,14 +1094,14 @@ int __memory_failure(unsigned long pfn,
 	 */
 	if (!PageHWPoison(p)) {
 		printk(KERN_ERR "MCE %#lx: just unpoisoned\n", pfn);
-		atomic_long_sub(nr_pages, &mce_bad_pages);
+		atomic_long_sub_unchecked(nr_pages, &mce_bad_pages);
 		put_page(hpage);
 		res = 0;
 		goto out;
 	}
 	if (hwpoison_filter(p)) {
 		if (TestClearPageHWPoison(p))
-			atomic_long_sub(nr_pages, &mce_bad_pages);
+			atomic_long_sub_unchecked(nr_pages, &mce_bad_pages);
 		unlock_page(hpage);
 		put_page(hpage);
 		return 0;
@@ -1318,7 +1318,7 @@ int unpoison_memory(unsigned long pfn)
 			return 0;
 		}
 		if (TestClearPageHWPoison(p))
-			atomic_long_sub(nr_pages, &mce_bad_pages);
+			atomic_long_sub_unchecked(nr_pages, &mce_bad_pages);
 		pr_info("MCE: Software-unpoisoned free page %#lx\n", pfn);
 		return 0;
 	}
@@ -1332,7 +1332,7 @@ int unpoison_memory(unsigned long pfn)
 	 */
 	if (TestClearPageHWPoison(page)) {
 		pr_info("MCE: Software-unpoisoned page %#lx\n", pfn);
-		atomic_long_sub(nr_pages, &mce_bad_pages);
+		atomic_long_sub_unchecked(nr_pages, &mce_bad_pages);
 		freeit = 1;
 		if (PageHuge(page))
 			clear_page_hwpoison_huge_page(page);
@@ -1447,13 +1447,13 @@ done:
 	/* overcommit hugetlb page will be freed to buddy */
 	if (PageHuge(hpage)) {
 		if (!PageHWPoison(hpage))
-			atomic_long_add(1 << compound_trans_order(hpage),
+			atomic_long_add_unchecked(1 << compound_trans_order(hpage),
 					&mce_bad_pages);
 		set_page_hwpoison_huge_page(hpage);
 		dequeue_hwpoisoned_huge_page(hpage);
 	} else {
 		SetPageHWPoison(page);
-		atomic_long_inc(&mce_bad_pages);
+		atomic_long_inc_unchecked(&mce_bad_pages);
 	}
 
 	/* keep elevated page count for bad page */
@@ -1592,7 +1592,7 @@ int soft_offline_page(struct page *page,
 		return ret;
 
 done:
-	atomic_long_add(1, &mce_bad_pages);
+	atomic_long_add_unchecked(1, &mce_bad_pages);
 	SetPageHWPoison(page);
 	/* keep elevated page count for bad page */
 	return ret;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/mempolicy.c linux-3.2.71-pax/mm/mempolicy.c
--- linux-3.2.71/mm/mempolicy.c	2014-09-14 14:11:00.106118777 +0200
+++ linux-3.2.71-pax/mm/mempolicy.c	2014-09-14 14:11:26.122138476 +0200
@@ -652,6 +652,10 @@ static int mbind_range(struct mm_struct
 	unsigned long vmstart;
 	unsigned long vmend;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	struct vm_area_struct *vma_m;
+#endif
+
 	vma = find_vma_prev(mm, start, &prev);
 	if (!vma || vma->vm_start > start)
 		return -EFAULT;
@@ -690,6 +694,16 @@ static int mbind_range(struct mm_struct
 		err = vma_replace_policy(vma, new_pol);
 		if (err)
 			goto out;
+
+#ifdef CONFIG_PAX_SEGMEXEC
+		vma_m = pax_find_mirror_vma(vma);
+		if (vma_m) {
+			err = vma_replace_policy(vma_m, new_pol);
+			if (err)
+				goto out;
+		}
+#endif
+
 	}
 
  out:
@@ -1126,6 +1140,17 @@ static long do_mbind(unsigned long start
 
 	if (end < start)
 		return -EINVAL;
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (mm->pax_flags & MF_PAX_SEGMEXEC) {
+		if (end > SEGMEXEC_TASK_SIZE)
+			return -EINVAL;
+	} else
+#endif
+
+	if (end > TASK_SIZE)
+		return -EINVAL;
+
 	if (end == start)
 		return 0;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/mlock.c linux-3.2.71-pax/mm/mlock.c
--- linux-3.2.71/mm/mlock.c	2014-04-30 18:53:46.252223429 +0200
+++ linux-3.2.71-pax/mm/mlock.c	2014-04-30 18:53:50.672223419 +0200
@@ -378,7 +378,7 @@ static int do_mlock(unsigned long start,
 {
 	unsigned long nstart, end, tmp;
 	struct vm_area_struct * vma, * prev;
-	int error;
+	int error = 0;
 
 	VM_BUG_ON(start & ~PAGE_MASK);
 	VM_BUG_ON(len != PAGE_ALIGN(len));
@@ -387,6 +387,9 @@ static int do_mlock(unsigned long start,
 		return -EINVAL;
 	if (end == start)
 		return 0;
+	if (end > TASK_SIZE)
+		return -EINVAL;
+
 	vma = find_vma_prev(current->mm, start, &prev);
 	if (!vma || vma->vm_start > start)
 		return -ENOMEM;
@@ -397,6 +400,11 @@ static int do_mlock(unsigned long start,
 	for (nstart = start ; ; ) {
 		vm_flags_t newflags;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+		if ((current->mm->pax_flags & MF_PAX_SEGMEXEC) && (vma->vm_start >= SEGMEXEC_TASK_SIZE))
+			break;
+#endif
+
 		/* Here we know that  vma->vm_start <= nstart < vma->vm_end. */
 
 		newflags = vma->vm_flags | VM_LOCKED;
@@ -525,17 +533,22 @@ SYSCALL_DEFINE2(munlock, unsigned long,
 static int do_mlockall(int flags)
 {
 	struct vm_area_struct * vma, * prev = NULL;
-	unsigned int def_flags = 0;
 
 	if (flags & MCL_FUTURE)
-		def_flags = VM_LOCKED;
-	current->mm->def_flags = def_flags;
+		current->mm->def_flags |= VM_LOCKED;
+	else
+		current->mm->def_flags &= ~VM_LOCKED;
 	if (flags == MCL_FUTURE)
 		goto out;
 
 	for (vma = current->mm->mmap; vma ; vma = prev->vm_next) {
 		vm_flags_t newflags;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+		if ((current->mm->pax_flags & MF_PAX_SEGMEXEC) && (vma->vm_start >= SEGMEXEC_TASK_SIZE))
+			break;
+#endif
+
 		newflags = vma->vm_flags | VM_LOCKED;
 		if (!(flags & MCL_CURRENT))
 			newflags &= ~VM_LOCKED;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/mmap.c linux-3.2.71-pax/mm/mmap.c
--- linux-3.2.71/mm/mmap.c	2015-05-10 09:22:39.191493146 +0200
+++ linux-3.2.71-pax/mm/mmap.c	2015-05-10 09:23:09.555494795 +0200
@@ -46,6 +46,16 @@
 #define arch_rebalance_pgtables(addr, len)		(addr)
 #endif
 
+static inline void verify_mm_writelocked(struct mm_struct *mm)
+{
+#if defined(CONFIG_DEBUG_VM) || defined(CONFIG_PAX)
+	if (unlikely(down_read_trylock(&mm->mmap_sem))) {
+		up_read(&mm->mmap_sem);
+		BUG();
+	}
+#endif
+}
+
 static void unmap_region(struct mm_struct *mm,
 		struct vm_area_struct *vma, struct vm_area_struct *prev,
 		unsigned long start, unsigned long end);
@@ -71,22 +81,32 @@ static void unmap_region(struct mm_struc
  *		x: (no) no	x: (no) yes	x: (no) yes	x: (yes) yes
  *
  */
-pgprot_t protection_map[16] = {
+pgprot_t protection_map[16] __read_only = {
 	__P000, __P001, __P010, __P011, __P100, __P101, __P110, __P111,
 	__S000, __S001, __S010, __S011, __S100, __S101, __S110, __S111
 };
 
-pgprot_t vm_get_page_prot(unsigned long vm_flags)
+pgprot_t vm_get_page_prot(vm_flags_t vm_flags)
 {
-	return __pgprot(pgprot_val(protection_map[vm_flags &
+	pgprot_t prot = __pgprot(pgprot_val(protection_map[vm_flags &
 				(VM_READ|VM_WRITE|VM_EXEC|VM_SHARED)]) |
 			pgprot_val(arch_vm_get_page_prot(vm_flags)));
+
+#if defined(CONFIG_PAX_PAGEEXEC) && defined(CONFIG_X86_32)
+	if (!(__supported_pte_mask & _PAGE_NX) &&
+	    (vm_flags & (VM_PAGEEXEC | VM_EXEC)) == VM_PAGEEXEC &&
+	    (vm_flags & (VM_READ | VM_WRITE)))
+		prot = __pgprot(pte_val(pte_exprotect(__pte(pgprot_val(prot)))));
+#endif
+
+	return prot;
 }
 EXPORT_SYMBOL(vm_get_page_prot);
 
 int sysctl_overcommit_memory __read_mostly = OVERCOMMIT_GUESS;  /* heuristic overcommit */
 int sysctl_overcommit_ratio __read_mostly = 50;	/* default is 50% */
 int sysctl_max_map_count __read_mostly = DEFAULT_MAX_MAP_COUNT;
+unsigned long sysctl_heap_stack_gap __read_mostly = 64*1024;
 /*
  * Make sure vm_committed_as in one cacheline and not cacheline shared with
  * other variables. It can be updated by several CPUs frequently.
@@ -228,6 +248,7 @@ static struct vm_area_struct *remove_vma
 	struct vm_area_struct *next = vma->vm_next;
 
 	might_sleep();
+	BUG_ON(vma->vm_mirror);
 	if (vma->vm_ops && vma->vm_ops->close)
 		vma->vm_ops->close(vma);
 	if (vma->vm_file) {
@@ -692,6 +713,12 @@ static int
 can_vma_merge_before(struct vm_area_struct *vma, unsigned long vm_flags,
 	struct anon_vma *anon_vma, struct file *file, pgoff_t vm_pgoff)
 {
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if ((vma->vm_mm->pax_flags & MF_PAX_SEGMEXEC) && vma->vm_start == SEGMEXEC_TASK_SIZE)
+		return 0;
+#endif
+
 	if (is_mergeable_vma(vma, file, vm_flags) &&
 	    is_mergeable_anon_vma(anon_vma, vma->anon_vma, vma)) {
 		if (vma->vm_pgoff == vm_pgoff)
@@ -711,6 +738,12 @@ static int
 can_vma_merge_after(struct vm_area_struct *vma, unsigned long vm_flags,
 	struct anon_vma *anon_vma, struct file *file, pgoff_t vm_pgoff)
 {
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if ((vma->vm_mm->pax_flags & MF_PAX_SEGMEXEC) && vma->vm_end == SEGMEXEC_TASK_SIZE)
+		return 0;
+#endif
+
 	if (is_mergeable_vma(vma, file, vm_flags) &&
 	    is_mergeable_anon_vma(anon_vma, vma->anon_vma, vma)) {
 		pgoff_t vm_pglen;
@@ -753,13 +786,20 @@ can_vma_merge_after(struct vm_area_struc
 struct vm_area_struct *vma_merge(struct mm_struct *mm,
 			struct vm_area_struct *prev, unsigned long addr,
 			unsigned long end, unsigned long vm_flags,
-		     	struct anon_vma *anon_vma, struct file *file,
+			struct anon_vma *anon_vma, struct file *file,
 			pgoff_t pgoff, struct mempolicy *policy)
 {
 	pgoff_t pglen = (end - addr) >> PAGE_SHIFT;
 	struct vm_area_struct *area, *next;
 	int err;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	unsigned long addr_m = addr + SEGMEXEC_TASK_SIZE, end_m = end + SEGMEXEC_TASK_SIZE;
+	struct vm_area_struct *area_m = NULL, *next_m = NULL, *prev_m = NULL;
+
+	BUG_ON((mm->pax_flags & MF_PAX_SEGMEXEC) && SEGMEXEC_TASK_SIZE < end);
+#endif
+
 	/*
 	 * We later require that vma->vm_flags == vm_flags,
 	 * so this tests vma->vm_flags & VM_SPECIAL, too.
@@ -775,6 +815,15 @@ struct vm_area_struct *vma_merge(struct
 	if (next && next->vm_end == end)		/* cases 6, 7, 8 */
 		next = next->vm_next;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (prev)
+		prev_m = pax_find_mirror_vma(prev);
+	if (area)
+		area_m = pax_find_mirror_vma(area);
+	if (next)
+		next_m = pax_find_mirror_vma(next);
+#endif
+
 	/*
 	 * Can it merge with the predecessor?
 	 */
@@ -794,9 +843,24 @@ struct vm_area_struct *vma_merge(struct
 							/* cases 1, 6 */
 			err = vma_adjust(prev, prev->vm_start,
 				next->vm_end, prev->vm_pgoff, NULL);
-		} else					/* cases 2, 5, 7 */
+
+#ifdef CONFIG_PAX_SEGMEXEC
+			if (!err && prev_m)
+				err = vma_adjust(prev_m, prev_m->vm_start,
+					next_m->vm_end, prev_m->vm_pgoff, NULL);
+#endif
+
+		} else {				/* cases 2, 5, 7 */
 			err = vma_adjust(prev, prev->vm_start,
 				end, prev->vm_pgoff, NULL);
+
+#ifdef CONFIG_PAX_SEGMEXEC
+			if (!err && prev_m)
+				err = vma_adjust(prev_m, prev_m->vm_start,
+						end_m, prev_m->vm_pgoff, NULL);
+#endif
+
+		}
 		if (err)
 			return NULL;
 		khugepaged_enter_vma_merge(prev, vm_flags);
@@ -810,12 +874,27 @@ struct vm_area_struct *vma_merge(struct
  			mpol_equal(policy, vma_policy(next)) &&
 			can_vma_merge_before(next, vm_flags,
 					anon_vma, file, pgoff+pglen)) {
-		if (prev && addr < prev->vm_end)	/* case 4 */
+		if (prev && addr < prev->vm_end) {	/* case 4 */
 			err = vma_adjust(prev, prev->vm_start,
 				addr, prev->vm_pgoff, NULL);
-		else					/* cases 3, 8 */
+
+#ifdef CONFIG_PAX_SEGMEXEC
+			if (!err && prev_m)
+				err = vma_adjust(prev_m, prev_m->vm_start,
+						addr_m, prev_m->vm_pgoff, NULL);
+#endif
+
+		} else {				/* cases 3, 8 */
 			err = vma_adjust(area, addr, next->vm_end,
 				next->vm_pgoff - pglen, NULL);
+
+#ifdef CONFIG_PAX_SEGMEXEC
+			if (!err && area_m)
+				err = vma_adjust(area_m, addr_m, next_m->vm_end,
+						next_m->vm_pgoff - pglen, NULL);
+#endif
+
+		}
 		if (err)
 			return NULL;
 		khugepaged_enter_vma_merge(area, vm_flags);
@@ -924,14 +1003,18 @@ none:
 void vm_stat_account(struct mm_struct *mm, unsigned long flags,
 						struct file *file, long pages)
 {
-	const unsigned long stack_flags
-		= VM_STACK_FLAGS & (VM_GROWSUP|VM_GROWSDOWN);
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP) || (flags & (VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)))
+#endif
+
+	mm->total_vm += pages;
 
 	if (file) {
 		mm->shared_vm += pages;
 		if ((flags & (VM_EXEC|VM_WRITE)) == VM_EXEC)
 			mm->exec_vm += pages;
-	} else if (flags & stack_flags)
+	} else if (flags & (VM_GROWSUP|VM_GROWSDOWN))
 		mm->stack_vm += pages;
 	if (flags & (VM_RESERVED|VM_IO))
 		mm->reserved_vm += pages;
@@ -958,7 +1041,7 @@ unsigned long do_mmap_pgoff(struct file
 	 * (the exception is when the underlying filesystem is noexec
 	 *  mounted, in which case we dont add PROT_EXEC.)
 	 */
-	if ((prot & PROT_READ) && (current->personality & READ_IMPLIES_EXEC))
+	if ((prot & (PROT_READ | PROT_WRITE)) && (current->personality & READ_IMPLIES_EXEC))
 		if (!(file && (file->f_path.mnt->mnt_flags & MNT_NOEXEC)))
 			prot |= PROT_EXEC;
 
@@ -984,7 +1067,7 @@ unsigned long do_mmap_pgoff(struct file
 	/* Obtain the address to map to. we verify (or select) it and ensure
 	 * that it represents a valid section of the address space.
 	 */
-	addr = get_unmapped_area(file, addr, len, pgoff, flags);
+	addr = get_unmapped_area(file, addr, len, pgoff, flags | ((prot & PROT_EXEC) ? MAP_EXECUTABLE : 0));
 	if (addr & ~PAGE_MASK)
 		return addr;
 
@@ -995,6 +1078,28 @@ unsigned long do_mmap_pgoff(struct file
 	vm_flags = calc_vm_prot_bits(prot) | calc_vm_flag_bits(flags) |
 			mm->def_flags | VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC;
 
+#ifdef CONFIG_PAX_MPROTECT
+	if (mm->pax_flags & MF_PAX_MPROTECT) {
+		if ((vm_flags & (VM_WRITE | VM_EXEC)) == (VM_WRITE | VM_EXEC))
+
+#ifdef CONFIG_PAX_EMUPLT
+			vm_flags &= ~VM_EXEC;
+#else
+			return -EPERM;
+#endif
+
+		if (!(vm_flags & VM_EXEC))
+			vm_flags &= ~VM_MAYEXEC;
+		else
+			vm_flags &= ~VM_MAYWRITE;
+	}
+#endif
+
+#if defined(CONFIG_PAX_PAGEEXEC) && defined(CONFIG_X86_32)
+	if ((mm->pax_flags & MF_PAX_PAGEEXEC) && file)
+		vm_flags &= ~VM_PAGEEXEC;
+#endif
+
 	if (flags & MAP_LOCKED)
 		if (!can_do_mlock())
 			return -EPERM;
@@ -1156,7 +1261,7 @@ int vma_wants_writenotify(struct vm_area
 	vm_flags_t vm_flags = vma->vm_flags;
 
 	/* If it was private or non-writable, the write bit is already clear */
-	if ((vm_flags & (VM_WRITE|VM_SHARED)) != ((VM_WRITE|VM_SHARED)))
+	if ((vm_flags & (VM_WRITE|VM_SHARED)) != (VM_WRITE|VM_SHARED))
 		return 0;
 
 	/* The backer wishes to know when pages are first written to? */
@@ -1205,17 +1310,32 @@ unsigned long mmap_region(struct file *f
 	unsigned long charged = 0;
 	struct inode *inode =  file ? file->f_path.dentry->d_inode : NULL;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	struct vm_area_struct *vma_m = NULL;
+#endif
+
+	/*
+	 * mm->mmap_sem is required to protect against another thread
+	 * changing the mappings in case we sleep.
+	 */
+	verify_mm_writelocked(mm);
+
 	/* Clear old maps */
 	error = -ENOMEM;
-munmap_back:
 	vma = find_vma_prepare(mm, addr, &prev, &rb_link, &rb_parent);
 	if (vma && vma->vm_start < addr + len) {
 		if (do_munmap(mm, addr, len))
 			return -ENOMEM;
-		goto munmap_back;
+		vma = find_vma_prepare(mm, addr, &prev, &rb_link, &rb_parent);
+		BUG_ON(vma && vma->vm_start < addr + len);
 	}
 
 	/* Check against address space limit. */
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP) || (vm_flags & (VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)))
+#endif
+
 	if (!may_expand_vm(mm, len >> PAGE_SHIFT))
 		return -ENOMEM;
 
@@ -1261,6 +1381,16 @@ munmap_back:
 		goto unacct_error;
 	}
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if ((mm->pax_flags & MF_PAX_SEGMEXEC) && (vm_flags & VM_EXEC)) {
+		vma_m = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+		if (!vma_m) {
+			error = -ENOMEM;
+			goto free_vma;
+		}
+	}
+#endif
+
 	vma->vm_mm = mm;
 	vma->vm_start = addr;
 	vma->vm_end = addr + len;
@@ -1284,6 +1414,19 @@ munmap_back:
 		error = file->f_op->mmap(file, vma);
 		if (error)
 			goto unmap_and_free_vma;
+
+#ifdef CONFIG_PAX_SEGMEXEC
+		if (vma_m && (vm_flags & VM_EXECUTABLE))
+			added_exe_file_vma(mm);
+#endif
+
+#if defined(CONFIG_PAX_PAGEEXEC) && defined(CONFIG_X86_32)
+		if ((mm->pax_flags & MF_PAX_PAGEEXEC) && !(vma->vm_flags & VM_SPECIAL)) {
+			vma->vm_flags |= VM_PAGEEXEC;
+			vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
+		}
+#endif
+
 		if (vm_flags & VM_EXECUTABLE)
 			added_exe_file_vma(mm);
 
@@ -1319,14 +1462,19 @@ munmap_back:
 	vma_link(mm, vma, prev, rb_link, rb_parent);
 	file = vma->vm_file;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (vma_m)
+		BUG_ON(pax_mirror_vma(vma_m, vma));
+#endif
+
 	/* Once vma denies write, undo our temporary denial count */
 	if (correct_wcount)
 		atomic_inc(&inode->i_writecount);
 out:
 	perf_event_mmap(vma);
 
-	mm->total_vm += len >> PAGE_SHIFT;
 	vm_stat_account(mm, vm_flags, file, len >> PAGE_SHIFT);
+	track_exec_limit(mm, addr, addr + len, vm_flags);
 	if (vm_flags & VM_LOCKED) {
 		if (!mlock_vma_pages_range(vma, addr, addr + len))
 			mm->locked_vm += (len >> PAGE_SHIFT);
@@ -1344,6 +1492,12 @@ unmap_and_free_vma:
 	unmap_region(mm, vma, prev, vma->vm_start, vma->vm_end);
 	charged = 0;
 free_vma:
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (vma_m)
+		kmem_cache_free(vm_area_cachep, vma_m);
+#endif
+
 	kmem_cache_free(vm_area_cachep, vma);
 unacct_error:
 	if (charged)
@@ -1351,6 +1505,51 @@ unacct_error:
 	return error;
 }
 
+bool check_heap_stack_gap(const struct vm_area_struct *vma, unsigned long *addr, unsigned long len)
+{
+	if (!vma) {
+#ifdef CONFIG_STACK_GROWSUP
+		if (*addr > sysctl_heap_stack_gap)
+			vma = find_vma(current->mm, *addr - sysctl_heap_stack_gap);
+		else
+			vma = find_vma(current->mm, 0);
+		if (vma && (vma->vm_flags & VM_GROWSUP))
+			return false;
+#endif
+		return true;
+	}
+
+	if (*addr + len > vma->vm_start)
+		return false;
+
+	if (vma->vm_flags & VM_GROWSDOWN)
+		return sysctl_heap_stack_gap <= vma->vm_start - *addr - len;
+#ifdef CONFIG_STACK_GROWSUP
+	else if (vma->vm_prev && (vma->vm_prev->vm_flags & VM_GROWSUP)) {
+		if (*addr - vma->vm_prev->vm_end >= sysctl_heap_stack_gap)
+			return true;
+		if (vma->vm_start - len - vma->vm_prev->vm_end >= sysctl_heap_stack_gap) {
+			*addr = vma->vm_start - len;
+			return true;
+		}
+		return false;
+	}
+#endif
+
+	return true;
+}
+
+unsigned long skip_heap_stack_gap(const struct vm_area_struct *vma, unsigned long len)
+{
+	if (vma->vm_start < len)
+		return -ENOMEM;
+	if (!(vma->vm_flags & VM_GROWSDOWN))
+		return vma->vm_start - len;
+	if (sysctl_heap_stack_gap <= vma->vm_start - len)
+		return vma->vm_start - len - sysctl_heap_stack_gap;
+	return -ENOMEM;
+}
+
 /* Get an address range which is currently unmapped.
  * For shmat() with addr=0.
  *
@@ -1377,18 +1576,23 @@ arch_get_unmapped_area(struct file *filp
 	if (flags & MAP_FIXED)
 		return addr;
 
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	if (addr) {
 		addr = PAGE_ALIGN(addr);
-		vma = find_vma(mm, addr);
-		if (TASK_SIZE - len >= addr && addr >= mmap_min_addr &&
-		    (!vma || addr + len <= vma->vm_start))
-			return addr;
+		if (TASK_SIZE - len >= addr) {
+			vma = find_vma(mm, addr);
+			if (addr >= mmap_min_addr && check_heap_stack_gap(vma, &addr, len))
+				return addr;
+		}
 	}
 	if (len > mm->cached_hole_size) {
-	        start_addr = addr = mm->free_area_cache;
+		start_addr = addr = mm->free_area_cache;
 	} else {
-	        start_addr = addr = TASK_UNMAPPED_BASE;
-	        mm->cached_hole_size = 0;
+		start_addr = addr = mm->mmap_base;
+		mm->cached_hole_size = 0;
 	}
 
 full_search:
@@ -1399,34 +1603,40 @@ full_search:
 			 * Start a new search - just in case we missed
 			 * some holes.
 			 */
-			if (start_addr != TASK_UNMAPPED_BASE) {
-				addr = TASK_UNMAPPED_BASE;
-			        start_addr = addr;
+			if (start_addr != mm->mmap_base) {
+				start_addr = addr = mm->mmap_base;
 				mm->cached_hole_size = 0;
 				goto full_search;
 			}
 			return -ENOMEM;
 		}
-		if (!vma || addr + len <= vma->vm_start) {
-			/*
-			 * Remember the place where we stopped the search:
-			 */
-			mm->free_area_cache = addr + len;
-			return addr;
-		}
+		if (check_heap_stack_gap(vma, &addr, len))
+			break;
 		if (addr + mm->cached_hole_size < vma->vm_start)
 		        mm->cached_hole_size = vma->vm_start - addr;
 		addr = vma->vm_end;
 	}
+
+	/*
+	 * Remember the place where we stopped the search:
+	 */
+	mm->free_area_cache = addr + len;
+	return addr;
 }
 #endif	
 
 void arch_unmap_area(struct mm_struct *mm, unsigned long addr)
 {
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if ((mm->pax_flags & MF_PAX_SEGMEXEC) && SEGMEXEC_TASK_SIZE <= addr)
+		return;
+#endif
+
 	/*
 	 * Is this a new hole at the lowest possible address?
 	 */
-	if (addr >= TASK_UNMAPPED_BASE && addr < mm->free_area_cache) {
+	if (addr >= mm->mmap_base && addr < mm->free_area_cache) {
 		mm->free_area_cache = addr;
 		mm->cached_hole_size = ~0UL;
 	}
@@ -1444,7 +1654,7 @@ arch_get_unmapped_area_topdown(struct fi
 {
 	struct vm_area_struct *vma;
 	struct mm_struct *mm = current->mm;
-	unsigned long addr = addr0;
+	unsigned long base = mm->mmap_base, addr = addr0;
 	unsigned long low_limit = max(PAGE_SIZE, mmap_min_addr);
 
 	/* requested length too big for entire address space */
@@ -1454,13 +1664,18 @@ arch_get_unmapped_area_topdown(struct fi
 	if (flags & MAP_FIXED)
 		return addr;
 
+#ifdef CONFIG_PAX_RANDMMAP
+	if (!(mm->pax_flags & MF_PAX_RANDMMAP))
+#endif
+
 	/* requesting a specific address */
 	if (addr) {
 		addr = PAGE_ALIGN(addr);
-		vma = find_vma(mm, addr);
-		if (TASK_SIZE - len >= addr && addr >= mmap_min_addr &&
-				(!vma || addr + len <= vma->vm_start))
-			return addr;
+		if (TASK_SIZE - len >= addr && addr >= mmap_min_addr) {
+			vma = find_vma(mm, addr);
+			if (check_heap_stack_gap(vma, &addr, len))
+				return addr;
+		}
 	}
 
 	/* check if free_area_cache is useful for us */
@@ -1474,10 +1689,11 @@ arch_get_unmapped_area_topdown(struct fi
 
 	/* make sure it can fit in the remaining address space */
 	if (addr >= low_limit + len) {
-		vma = find_vma(mm, addr-len);
-		if (!vma || addr <= vma->vm_start)
+		addr -= len;
+		vma = find_vma(mm, addr);
+		if (check_heap_stack_gap(vma, &addr, len))
 			/* remember the address as a hint for next time */
-			return (mm->free_area_cache = addr-len);
+			return (mm->free_area_cache = addr);
 	}
 
 	if (mm->mmap_base < low_limit + len)
@@ -1492,7 +1708,7 @@ arch_get_unmapped_area_topdown(struct fi
 		 * return with success:
 		 */
 		vma = find_vma(mm, addr);
-		if (!vma || addr+len <= vma->vm_start)
+		if (check_heap_stack_gap(vma, &addr, len))
 			/* remember the address as a hint for next time */
 			return (mm->free_area_cache = addr);
 
@@ -1501,8 +1717,8 @@ arch_get_unmapped_area_topdown(struct fi
  		        mm->cached_hole_size = vma->vm_start - addr;
 
 		/* try just below the current vma->vm_start */
-		addr = vma->vm_start-len;
-	} while (vma->vm_start >= low_limit + len);
+		addr = skip_heap_stack_gap(vma, len);
+	} while (!IS_ERR_VALUE(addr) && addr >= low_limit);
 
 bottomup:
 	/*
@@ -1511,13 +1727,21 @@ bottomup:
 	 * can happen with large stack limits and large mmap()
 	 * allocations.
 	 */
+	mm->mmap_base = TASK_UNMAPPED_BASE;
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (mm->pax_flags & MF_PAX_RANDMMAP)
+		mm->mmap_base += mm->delta_mmap;
+#endif
+
+	mm->free_area_cache = mm->mmap_base;
 	mm->cached_hole_size = ~0UL;
-  	mm->free_area_cache = TASK_UNMAPPED_BASE;
 	addr = arch_get_unmapped_area(filp, addr0, len, pgoff, flags);
 	/*
 	 * Restore the topdown base:
 	 */
-	mm->free_area_cache = mm->mmap_base;
+	mm->mmap_base = base;
+	mm->free_area_cache = base;
 	mm->cached_hole_size = ~0UL;
 
 	return addr;
@@ -1526,6 +1750,12 @@ bottomup:
 
 void arch_unmap_area_topdown(struct mm_struct *mm, unsigned long addr)
 {
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if ((mm->pax_flags & MF_PAX_SEGMEXEC) && SEGMEXEC_TASK_SIZE <= addr)
+		return;
+#endif
+
 	/*
 	 * Is this a new hole at the highest possible address?
 	 */
@@ -1533,8 +1763,10 @@ void arch_unmap_area_topdown(struct mm_s
 		mm->free_area_cache = addr;
 
 	/* dont allow allocations above current base */
-	if (mm->free_area_cache > mm->mmap_base)
+	if (mm->free_area_cache > mm->mmap_base) {
 		mm->free_area_cache = mm->mmap_base;
+		mm->cached_hole_size = ~0UL;
+	}
 }
 
 unsigned long
@@ -1607,40 +1839,51 @@ struct vm_area_struct *find_vma(struct m
 
 EXPORT_SYMBOL(find_vma);
 
-/* Same as find_vma, but also return a pointer to the previous VMA in *pprev. */
+/*
+ * Same as find_vma, but also return a pointer to the previous VMA in *pprev.
+ * Note: pprev is set to NULL when return value is NULL.
+ */
 struct vm_area_struct *
 find_vma_prev(struct mm_struct *mm, unsigned long addr,
 			struct vm_area_struct **pprev)
 {
-	struct vm_area_struct *vma = NULL, *prev = NULL;
-	struct rb_node *rb_node;
-	if (!mm)
-		goto out;
-
-	/* Guard against addr being lower than the first VMA */
-	vma = mm->mmap;
-
-	/* Go through the RB tree quickly. */
-	rb_node = mm->mm_rb.rb_node;
-
-	while (rb_node) {
-		struct vm_area_struct *vma_tmp;
-		vma_tmp = rb_entry(rb_node, struct vm_area_struct, vm_rb);
+	struct vm_area_struct *vma;
 
-		if (addr < vma_tmp->vm_end) {
-			rb_node = rb_node->rb_left;
-		} else {
-			prev = vma_tmp;
-			if (!prev->vm_next || (addr < prev->vm_next->vm_end))
-				break;
+	vma = find_vma(mm, addr);
+	if (vma) {
+		*pprev = vma->vm_prev;
+	} else {
+		struct rb_node *rb_node = mm->mm_rb.rb_node;
+		*pprev = NULL;
+		while (rb_node) {
+			*pprev = rb_entry(rb_node, struct vm_area_struct, vm_rb);
 			rb_node = rb_node->rb_right;
 		}
 	}
+	return vma;
+}
 
-out:
-	*pprev = prev;
-	return prev ? prev->vm_next : vma;
+#ifdef CONFIG_PAX_SEGMEXEC
+struct vm_area_struct *pax_find_mirror_vma(struct vm_area_struct *vma)
+{
+	struct vm_area_struct *vma_m;
+
+	BUG_ON(!vma || vma->vm_start >= vma->vm_end);
+	if (!(vma->vm_mm->pax_flags & MF_PAX_SEGMEXEC) || !(vma->vm_flags & VM_EXEC)) {
+		BUG_ON(vma->vm_mirror);
+		return NULL;
+	}
+	BUG_ON(vma->vm_start < SEGMEXEC_TASK_SIZE && SEGMEXEC_TASK_SIZE < vma->vm_end);
+	vma_m = vma->vm_mirror;
+	BUG_ON(!vma_m || vma_m->vm_mirror != vma);
+	BUG_ON(vma->vm_file != vma_m->vm_file);
+	BUG_ON(vma->vm_end - vma->vm_start != vma_m->vm_end - vma_m->vm_start);
+	BUG_ON(vma->vm_pgoff != vma_m->vm_pgoff);
+	BUG_ON(vma->anon_vma != vma_m->anon_vma && vma->anon_vma->root != vma_m->anon_vma->root);
+	BUG_ON((vma->vm_flags ^ vma_m->vm_flags) & ~(VM_WRITE | VM_MAYWRITE | VM_ACCOUNT | VM_LOCKED | VM_RESERVED));
+	return vma_m;
 }
+#endif
 
 /*
  * Verify that the stack growth is acceptable and
@@ -1659,8 +1902,6 @@ static int acct_stack_growth(struct vm_a
 
 	/* Stack limit test */
 	actual_size = size;
-	if (size && (vma->vm_flags & (VM_GROWSUP | VM_GROWSDOWN)))
-		actual_size -= PAGE_SIZE;
 	if (actual_size > ACCESS_ONCE(rlim[RLIMIT_STACK].rlim_cur))
 		return -ENOMEM;
 
@@ -1689,7 +1930,6 @@ static int acct_stack_growth(struct vm_a
 		return -ENOMEM;
 
 	/* Ok, everything looks good - let it rip */
-	mm->total_vm += grow;
 	if (vma->vm_flags & VM_LOCKED)
 		mm->locked_vm += grow;
 	vm_stat_account(mm, vma->vm_flags, vma->vm_file, grow);
@@ -1704,34 +1944,42 @@ static int acct_stack_growth(struct vm_a
 int expand_upwards(struct vm_area_struct *vma, unsigned long address)
 {
 	int error;
+	bool locknext;
 
 	if (!(vma->vm_flags & VM_GROWSUP))
 		return -EFAULT;
 
+	/* Also guard against wrapping around to address 0. */
+	if (address < PAGE_ALIGN(address+1))
+		address = PAGE_ALIGN(address+1);
+	else
+		return -ENOMEM;
+
 	/*
 	 * We must make sure the anon_vma is allocated
 	 * so that the anon_vma locking is not a noop.
 	 */
 	if (unlikely(anon_vma_prepare(vma)))
 		return -ENOMEM;
+	locknext = vma->vm_next && (vma->vm_next->vm_flags & VM_GROWSDOWN);
+	if (locknext && anon_vma_prepare(vma->vm_next))
+		return -ENOMEM;
 	vma_lock_anon_vma(vma);
+	if (locknext)
+		vma_lock_anon_vma(vma->vm_next);
 
 	/*
 	 * vma->vm_start/vm_end cannot change under us because the caller
 	 * is required to hold the mmap_sem in read mode.  We need the
-	 * anon_vma lock to serialize against concurrent expand_stacks.
-	 * Also guard against wrapping around to address 0.
+	 * anon_vma locks to serialize against concurrent expand_stacks
+	 * and expand_upwards.
 	 */
-	if (address < PAGE_ALIGN(address+4))
-		address = PAGE_ALIGN(address+4);
-	else {
-		vma_unlock_anon_vma(vma);
-		return -ENOMEM;
-	}
 	error = 0;
 
 	/* Somebody else might have raced and expanded it already */
-	if (address > vma->vm_end) {
+	if (vma->vm_next && (vma->vm_next->vm_flags & (VM_READ | VM_WRITE | VM_EXEC)) && vma->vm_next->vm_start - address < sysctl_heap_stack_gap)
+		error = -ENOMEM;
+	else if (address > vma->vm_end && (!locknext || vma->vm_next->vm_start >= address)) {
 		unsigned long size, grow;
 
 		size = address - vma->vm_start;
@@ -1746,6 +1994,8 @@ int expand_upwards(struct vm_area_struct
 			}
 		}
 	}
+	if (locknext)
+		vma_unlock_anon_vma(vma->vm_next);
 	vma_unlock_anon_vma(vma);
 	khugepaged_enter_vma_merge(vma, vma->vm_flags);
 	return error;
@@ -1759,6 +2009,8 @@ int expand_downwards(struct vm_area_stru
 				   unsigned long address)
 {
 	int error;
+	bool lockprev = false;
+	struct vm_area_struct *prev;
 
 	/*
 	 * We must make sure the anon_vma is allocated
@@ -1772,6 +2024,15 @@ int expand_downwards(struct vm_area_stru
 	if (error)
 		return error;
 
+	prev = vma->vm_prev;
+#if defined(CONFIG_STACK_GROWSUP) || defined(CONFIG_IA64)
+	lockprev = prev && (prev->vm_flags & VM_GROWSUP);
+#endif
+	if (lockprev && anon_vma_prepare(prev))
+		return -ENOMEM;
+	if (lockprev)
+		vma_lock_anon_vma(prev);
+
 	vma_lock_anon_vma(vma);
 
 	/*
@@ -1781,9 +2042,17 @@ int expand_downwards(struct vm_area_stru
 	 */
 
 	/* Somebody else might have raced and expanded it already */
-	if (address < vma->vm_start) {
+	if (prev && (prev->vm_flags & (VM_READ | VM_WRITE | VM_EXEC)) && address - prev->vm_end < sysctl_heap_stack_gap)
+		error = -ENOMEM;
+	else if (address < vma->vm_start && (!lockprev || prev->vm_end <= address)) {
 		unsigned long size, grow;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+		struct vm_area_struct *vma_m;
+
+		vma_m = pax_find_mirror_vma(vma);
+#endif
+
 		size = vma->vm_end - address;
 		grow = (vma->vm_start - address) >> PAGE_SHIFT;
 
@@ -1793,11 +2062,22 @@ int expand_downwards(struct vm_area_stru
 			if (!error) {
 				vma->vm_start = address;
 				vma->vm_pgoff -= grow;
+				track_exec_limit(vma->vm_mm, vma->vm_start, vma->vm_end, vma->vm_flags);
+
+#ifdef CONFIG_PAX_SEGMEXEC
+				if (vma_m) {
+					vma_m->vm_start -= grow << PAGE_SHIFT;
+					vma_m->vm_pgoff -= grow;
+				}
+#endif
+
 				perf_event_mmap(vma);
 			}
 		}
 	}
 	vma_unlock_anon_vma(vma);
+	if (lockprev)
+		vma_unlock_anon_vma(prev);
 	khugepaged_enter_vma_merge(vma, vma->vm_flags);
 	return error;
 }
@@ -1867,7 +2147,13 @@ static void remove_vma_list(struct mm_st
 	do {
 		long nrpages = vma_pages(vma);
 
-		mm->total_vm -= nrpages;
+#ifdef CONFIG_PAX_SEGMEXEC
+		if ((mm->pax_flags & MF_PAX_SEGMEXEC) && (vma->vm_start >= SEGMEXEC_TASK_SIZE)) {
+			vma = remove_vma(vma);
+			continue;
+		}
+#endif
+
 		vm_stat_account(mm, vma->vm_flags, vma->vm_file, -nrpages);
 		vma = remove_vma(vma);
 	} while (vma);
@@ -1912,6 +2198,16 @@ detach_vmas_to_be_unmapped(struct mm_str
 	insertion_point = (prev ? &prev->vm_next : &mm->mmap);
 	vma->vm_prev = NULL;
 	do {
+
+#ifdef CONFIG_PAX_SEGMEXEC
+		if (vma->vm_mirror) {
+			BUG_ON(!vma->vm_mirror->vm_mirror || vma->vm_mirror->vm_mirror != vma);
+			vma->vm_mirror->vm_mirror = NULL;
+			vma->vm_mirror->vm_flags &= ~VM_EXEC;
+			vma->vm_mirror = NULL;
+		}
+#endif
+
 		rb_erase(&vma->vm_rb, &mm->mm_rb);
 		mm->map_count--;
 		tail_vma = vma;
@@ -1940,14 +2236,33 @@ static int __split_vma(struct mm_struct
 	struct vm_area_struct *new;
 	int err = -ENOMEM;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	struct vm_area_struct *vma_m, *new_m = NULL;
+	unsigned long addr_m = addr + SEGMEXEC_TASK_SIZE;
+#endif
+
 	if (is_vm_hugetlb_page(vma) && (addr &
 					~(huge_page_mask(hstate_vma(vma)))))
 		return -EINVAL;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	vma_m = pax_find_mirror_vma(vma);
+#endif
+
 	new = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);
 	if (!new)
 		goto out_err;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (vma_m) {
+		new_m = kmem_cache_alloc(vm_area_cachep, GFP_KERNEL);
+		if (!new_m) {
+			kmem_cache_free(vm_area_cachep, new);
+			goto out_err;
+		}
+	}
+#endif
+
 	/* most fields are the same, copy all, and then fixup */
 	*new = *vma;
 
@@ -1960,6 +2275,22 @@ static int __split_vma(struct mm_struct
 		new->vm_pgoff += ((addr - vma->vm_start) >> PAGE_SHIFT);
 	}
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (vma_m) {
+		*new_m = *vma_m;
+		INIT_LIST_HEAD(&new_m->anon_vma_chain);
+		new_m->vm_mirror = new;
+		new->vm_mirror = new_m;
+
+		if (new_below)
+			new_m->vm_end = addr_m;
+		else {
+			new_m->vm_start = addr_m;
+			new_m->vm_pgoff += ((addr_m - vma_m->vm_start) >> PAGE_SHIFT);
+		}
+	}
+#endif
+
 	pol = mpol_dup(vma_policy(vma));
 	if (IS_ERR(pol)) {
 		err = PTR_ERR(pol);
@@ -1985,6 +2316,42 @@ static int __split_vma(struct mm_struct
 	else
 		err = vma_adjust(vma, vma->vm_start, addr, vma->vm_pgoff, new);
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (!err && vma_m) {
+		if (anon_vma_clone(new_m, vma_m))
+			goto out_free_mpol;
+
+		mpol_get(pol);
+		vma_set_policy(new_m, pol);
+
+		if (new_m->vm_file) {
+			get_file(new_m->vm_file);
+			if (vma_m->vm_flags & VM_EXECUTABLE)
+				added_exe_file_vma(mm);
+		}
+
+		if (new_m->vm_ops && new_m->vm_ops->open)
+			new_m->vm_ops->open(new_m);
+
+		if (new_below)
+			err = vma_adjust(vma_m, addr_m, vma_m->vm_end, vma_m->vm_pgoff +
+				((addr_m - new_m->vm_start) >> PAGE_SHIFT), new_m);
+		else
+			err = vma_adjust(vma_m, vma_m->vm_start, addr_m, vma_m->vm_pgoff, new_m);
+
+		if (err) {
+			if (new_m->vm_ops && new_m->vm_ops->close)
+				new_m->vm_ops->close(new_m);
+			if (new_m->vm_file) {
+				if (vma_m->vm_flags & VM_EXECUTABLE)
+					removed_exe_file_vma(mm);
+				fput(new_m->vm_file);
+			}
+			mpol_put(pol);
+		}
+	}
+#endif
+
 	/* Success. */
 	if (!err)
 		return 0;
@@ -1997,10 +2364,18 @@ static int __split_vma(struct mm_struct
 			removed_exe_file_vma(mm);
 		fput(new->vm_file);
 	}
-	unlink_anon_vmas(new);
  out_free_mpol:
 	mpol_put(pol);
  out_free_vma:
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (new_m) {
+		unlink_anon_vmas(new_m);
+		kmem_cache_free(vm_area_cachep, new_m);
+	}
+#endif
+
+	unlink_anon_vmas(new);
 	kmem_cache_free(vm_area_cachep, new);
  out_err:
 	return err;
@@ -2013,6 +2388,15 @@ static int __split_vma(struct mm_struct
 int split_vma(struct mm_struct *mm, struct vm_area_struct *vma,
 	      unsigned long addr, int new_below)
 {
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (mm->pax_flags & MF_PAX_SEGMEXEC) {
+		BUG_ON(vma->vm_end > SEGMEXEC_TASK_SIZE);
+		if (mm->map_count >= sysctl_max_map_count-1)
+			return -ENOMEM;
+	} else
+#endif
+
 	if (mm->map_count >= sysctl_max_map_count)
 		return -ENOMEM;
 
@@ -2024,11 +2408,30 @@ int split_vma(struct mm_struct *mm, stru
  * work.  This now handles partial unmappings.
  * Jeremy Fitzhardinge <jeremy@goop.org>
  */
+#ifdef CONFIG_PAX_SEGMEXEC
+int do_munmap(struct mm_struct *mm, unsigned long start, size_t len)
+{
+	int ret = __do_munmap(mm, start, len);
+	if (ret || !(mm->pax_flags & MF_PAX_SEGMEXEC))
+		return ret;
+
+	return __do_munmap(mm, start + SEGMEXEC_TASK_SIZE, len);
+}
+
+int __do_munmap(struct mm_struct *mm, unsigned long start, size_t len)
+#else
 int do_munmap(struct mm_struct *mm, unsigned long start, size_t len)
+#endif
 {
 	unsigned long end;
 	struct vm_area_struct *vma, *prev, *last;
 
+	/*
+	 * mm->mmap_sem is required to protect against another thread
+	 * changing the mappings in case we sleep.
+	 */
+	verify_mm_writelocked(mm);
+
 	if ((start & ~PAGE_MASK) || start > TASK_SIZE || len > TASK_SIZE-start)
 		return -EINVAL;
 
@@ -2103,6 +2506,8 @@ int do_munmap(struct mm_struct *mm, unsi
 	/* Fix up all other VM information */
 	remove_vma_list(mm, vma);
 
+	track_exec_limit(mm, start, end, 0UL);
+
 	return 0;
 }
 
@@ -2115,22 +2520,18 @@ SYSCALL_DEFINE2(munmap, unsigned long, a
 
 	profile_munmap(addr);
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if ((mm->pax_flags & MF_PAX_SEGMEXEC) &&
+	    (len > SEGMEXEC_TASK_SIZE || addr > SEGMEXEC_TASK_SIZE-len))
+		return -EINVAL;
+#endif
+
 	down_write(&mm->mmap_sem);
 	ret = do_munmap(mm, addr, len);
 	up_write(&mm->mmap_sem);
 	return ret;
 }
 
-static inline void verify_mm_writelocked(struct mm_struct *mm)
-{
-#ifdef CONFIG_DEBUG_VM
-	if (unlikely(down_read_trylock(&mm->mmap_sem))) {
-		WARN_ON(1);
-		up_read(&mm->mmap_sem);
-	}
-#endif
-}
-
 /*
  *  this is really a simplified "do_mmap".  it only handles
  *  anonymous maps.  eventually we may be able to do some
@@ -2144,6 +2545,7 @@ unsigned long do_brk(unsigned long addr,
 	struct rb_node ** rb_link, * rb_parent;
 	pgoff_t pgoff = addr >> PAGE_SHIFT;
 	int error;
+	unsigned long charged;
 
 	len = PAGE_ALIGN(len);
 	if (!len)
@@ -2155,16 +2557,30 @@ unsigned long do_brk(unsigned long addr,
 
 	flags = VM_DATA_DEFAULT_FLAGS | VM_ACCOUNT | mm->def_flags;
 
+#if defined(CONFIG_PAX_PAGEEXEC) || defined(CONFIG_PAX_SEGMEXEC)
+	if (mm->pax_flags & (MF_PAX_PAGEEXEC | MF_PAX_SEGMEXEC)) {
+		flags &= ~VM_EXEC;
+
+#ifdef CONFIG_PAX_MPROTECT
+		if (mm->pax_flags & MF_PAX_MPROTECT)
+			flags &= ~VM_MAYEXEC;
+#endif
+
+	}
+#endif
+
 	error = get_unmapped_area(NULL, addr, len, 0, MAP_FIXED);
 	if (error & ~PAGE_MASK)
 		return error;
 
+	charged = len >> PAGE_SHIFT;
+
 	/*
 	 * mlock MCL_FUTURE?
 	 */
 	if (mm->def_flags & VM_LOCKED) {
 		unsigned long locked, lock_limit;
-		locked = len >> PAGE_SHIFT;
+		locked = charged;
 		locked += mm->locked_vm;
 		lock_limit = rlimit(RLIMIT_MEMLOCK);
 		lock_limit >>= PAGE_SHIFT;
@@ -2181,22 +2597,22 @@ unsigned long do_brk(unsigned long addr,
 	/*
 	 * Clear old maps.  this also does some error checking for us
 	 */
- munmap_back:
 	vma = find_vma_prepare(mm, addr, &prev, &rb_link, &rb_parent);
 	if (vma && vma->vm_start < addr + len) {
 		if (do_munmap(mm, addr, len))
 			return -ENOMEM;
-		goto munmap_back;
+		vma = find_vma_prepare(mm, addr, &prev, &rb_link, &rb_parent);
+		BUG_ON(vma && vma->vm_start < addr + len);
 	}
 
 	/* Check against address space limits *after* clearing old maps... */
-	if (!may_expand_vm(mm, len >> PAGE_SHIFT))
+	if (!may_expand_vm(mm, charged))
 		return -ENOMEM;
 
 	if (mm->map_count > sysctl_max_map_count)
 		return -ENOMEM;
 
-	if (security_vm_enough_memory(len >> PAGE_SHIFT))
+	if (security_vm_enough_memory(charged))
 		return -ENOMEM;
 
 	/* Can we just expand an old private anonymous mapping? */
@@ -2210,7 +2626,7 @@ unsigned long do_brk(unsigned long addr,
 	 */
 	vma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
 	if (!vma) {
-		vm_unacct_memory(len >> PAGE_SHIFT);
+		vm_unacct_memory(charged);
 		return -ENOMEM;
 	}
 
@@ -2224,11 +2640,12 @@ unsigned long do_brk(unsigned long addr,
 	vma_link(mm, vma, prev, rb_link, rb_parent);
 out:
 	perf_event_mmap(vma);
-	mm->total_vm += len >> PAGE_SHIFT;
+	mm->total_vm += charged;
 	if (flags & VM_LOCKED) {
 		if (!mlock_vma_pages_range(vma, addr, addr + len))
-			mm->locked_vm += (len >> PAGE_SHIFT);
+			mm->locked_vm += charged;
 	}
+	track_exec_limit(mm, addr, addr + len, flags);
 	return addr;
 }
 
@@ -2275,8 +2692,10 @@ void exit_mmap(struct mm_struct *mm)
 	 * Walk the list again, actually closing and freeing it,
 	 * with preemption enabled, without holding any MM locks.
 	 */
-	while (vma)
+	while (vma) {
+		vma->vm_mirror = NULL;
 		vma = remove_vma(vma);
+	}
 
 	BUG_ON(mm->nr_ptes > (FIRST_USER_ADDRESS+PMD_SIZE-1)>>PMD_SHIFT);
 }
@@ -2290,6 +2709,10 @@ int insert_vm_struct(struct mm_struct *
 	struct vm_area_struct * __vma, * prev;
 	struct rb_node ** rb_link, * rb_parent;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	struct vm_area_struct *vma_m = NULL;
+#endif
+
 	/*
 	 * The vm_pgoff of a purely anonymous vma should be irrelevant
 	 * until its first write fault, when page's anon_vma and index
@@ -2312,7 +2735,22 @@ int insert_vm_struct(struct mm_struct *
 	if ((vma->vm_flags & VM_ACCOUNT) &&
 	     security_vm_enough_memory_mm(mm, vma_pages(vma)))
 		return -ENOMEM;
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if ((mm->pax_flags & MF_PAX_SEGMEXEC) && (vma->vm_flags & VM_EXEC)) {
+		vma_m = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+		if (!vma_m)
+			return -ENOMEM;
+	}
+#endif
+
 	vma_link(mm, vma, prev, rb_link, rb_parent);
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (vma_m)
+		BUG_ON(pax_mirror_vma(vma_m, vma));
+#endif
+
 	return 0;
 }
 
@@ -2330,6 +2768,8 @@ struct vm_area_struct *copy_vma(struct v
 	struct rb_node **rb_link, *rb_parent;
 	struct mempolicy *pol;
 
+	BUG_ON(vma->vm_mirror);
+
 	/*
 	 * If anonymous vma has not yet been faulted, update new pgoff
 	 * to match new location, to increase its chance of merging.
@@ -2380,6 +2820,39 @@ struct vm_area_struct *copy_vma(struct v
 	return NULL;
 }
 
+#ifdef CONFIG_PAX_SEGMEXEC
+long pax_mirror_vma(struct vm_area_struct *vma_m, struct vm_area_struct *vma)
+{
+	struct vm_area_struct *prev_m;
+	struct rb_node **rb_link_m, *rb_parent_m;
+	struct mempolicy *pol_m;
+
+	BUG_ON(!(vma->vm_mm->pax_flags & MF_PAX_SEGMEXEC) || !(vma->vm_flags & VM_EXEC));
+	BUG_ON(vma->vm_mirror || vma_m->vm_mirror);
+	BUG_ON(!mpol_equal(vma_policy(vma), vma_policy(vma_m)));
+	*vma_m = *vma;
+	INIT_LIST_HEAD(&vma_m->anon_vma_chain);
+	if (anon_vma_clone(vma_m, vma))
+		return -ENOMEM;
+	pol_m = vma_policy(vma_m);
+	mpol_get(pol_m);
+	vma_set_policy(vma_m, pol_m);
+	vma_m->vm_start += SEGMEXEC_TASK_SIZE;
+	vma_m->vm_end += SEGMEXEC_TASK_SIZE;
+	vma_m->vm_flags &= ~(VM_WRITE | VM_MAYWRITE | VM_ACCOUNT | VM_LOCKED);
+	vma_m->vm_page_prot = vm_get_page_prot(vma_m->vm_flags);
+	if (vma_m->vm_file)
+		get_file(vma_m->vm_file);
+	if (vma_m->vm_ops && vma_m->vm_ops->open)
+		vma_m->vm_ops->open(vma_m);
+	find_vma_prepare(vma->vm_mm, vma_m->vm_start, &prev_m, &rb_link_m, &rb_parent_m);
+	vma_link(vma->vm_mm, vma_m, prev_m, rb_link_m, rb_parent_m);
+	vma_m->vm_mirror = vma;
+	vma->vm_mirror = vma_m;
+	return 0;
+}
+#endif
+
 /*
  * Return true if the calling process may expand its vm space by the passed
  * number of pages
@@ -2461,6 +2934,17 @@ int install_special_mapping(struct mm_st
 	vma->vm_start = addr;
 	vma->vm_end = addr + len;
 
+#ifdef CONFIG_PAX_MPROTECT
+	if (mm->pax_flags & MF_PAX_MPROTECT) {
+		if ((vm_flags & (VM_WRITE | VM_EXEC)) == (VM_WRITE | VM_EXEC))
+			return -EPERM;
+		if (!(vm_flags & VM_EXEC))
+			vm_flags &= ~VM_MAYEXEC;
+		else
+			vm_flags &= ~VM_MAYWRITE;
+	}
+#endif
+
 	vma->vm_flags = vm_flags | mm->def_flags | VM_DONTEXPAND;
 	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/mm_init.c linux-3.2.71-pax/mm/mm_init.c
--- linux-3.2.71/mm/mm_init.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/mm/mm_init.c	2014-11-01 00:49:17.900422186 +0100
@@ -9,8 +9,33 @@
 #include <linux/init.h>
 #include <linux/kobject.h>
 #include <linux/export.h>
+#include <linux/slab.h>
 #include "internal.h"
 
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+enum pax_sanitize_mode pax_sanitize_slab __read_only = PAX_SANITIZE_SLAB_FAST;
+static int __init pax_sanitize_slab_setup(char *str)
+{
+	if (!str)
+		return 0;
+
+	if (!strcmp(str, "0") || !strcmp(str, "off")) {
+		pr_info("PaX slab sanitization: %s\n", "disabled");
+		pax_sanitize_slab = PAX_SANITIZE_SLAB_OFF;
+	} else if (!strcmp(str, "1") || !strcmp(str, "fast")) {
+		pr_info("PaX slab sanitization: %s\n", "fast");
+		pax_sanitize_slab = PAX_SANITIZE_SLAB_FAST;
+	} else if (!strcmp(str, "full")) {
+		pr_info("PaX slab sanitization: %s\n", "full");
+		pax_sanitize_slab = PAX_SANITIZE_SLAB_FULL;
+	} else
+		pr_err("PaX slab sanitization: unsupported option '%s'\n", str);
+
+	return 0;
+}
+early_param("pax_sanitize_slab", pax_sanitize_slab_setup);
+#endif
+
 #ifdef CONFIG_DEBUG_MEMORY_INIT
 int mminit_loglevel;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/mprotect.c linux-3.2.71-pax/mm/mprotect.c
--- linux-3.2.71/mm/mprotect.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/mm/mprotect.c	2015-06-28 00:17:44.314444512 +0200
@@ -23,10 +23,16 @@
 #include <linux/mmu_notifier.h>
 #include <linux/migrate.h>
 #include <linux/perf_event.h>
+
+#ifdef CONFIG_PAX_MPROTECT
+#include <linux/elf.h>
+#endif
+
 #include <asm/uaccess.h>
 #include <asm/pgtable.h>
 #include <asm/cacheflush.h>
 #include <asm/tlbflush.h>
+#include <asm/mmu_context.h>
 
 #ifndef pgprot_modify
 static inline pgprot_t pgprot_modify(pgprot_t oldprot, pgprot_t newprot)
@@ -141,6 +147,48 @@ static void change_protection(struct vm_
 	flush_tlb_range(vma, start, end);
 }
 
+#ifdef CONFIG_ARCH_TRACK_EXEC_LIMIT
+/* called while holding the mmap semaphor for writing except stack expansion */
+void track_exec_limit(struct mm_struct *mm, unsigned long start, unsigned long end, unsigned long prot)
+{
+	unsigned long oldlimit, newlimit = 0UL;
+
+	if (!(mm->pax_flags & MF_PAX_PAGEEXEC) || (__supported_pte_mask & _PAGE_NX))
+		return;
+
+	spin_lock(&mm->page_table_lock);
+	oldlimit = mm->context.user_cs_limit;
+	if ((prot & VM_EXEC) && oldlimit < end)
+		/* USER_CS limit moved up */
+		newlimit = end;
+	else if (!(prot & VM_EXEC) && start < oldlimit && oldlimit <= end)
+		/* USER_CS limit moved down */
+		newlimit = start;
+
+	if (newlimit) {
+		mm->context.user_cs_limit = newlimit;
+
+#ifdef CONFIG_SMP
+		wmb();
+		cpumask_clear(&mm->context.cpu_user_cs_mask);
+		cpumask_set_cpu(smp_processor_id(), &mm->context.cpu_user_cs_mask);
+#endif
+
+		set_user_cs(mm->context.user_cs_base, mm->context.user_cs_limit, smp_processor_id());
+	}
+	spin_unlock(&mm->page_table_lock);
+	if (newlimit == end) {
+		struct vm_area_struct *vma = find_vma(mm, oldlimit);
+
+		for (; vma && vma->vm_start < end; vma = vma->vm_next)
+			if (is_vm_hugetlb_page(vma))
+				hugetlb_change_protection(vma, vma->vm_start, vma->vm_end, vma->vm_page_prot);
+			else
+				change_protection(vma, vma->vm_start, vma->vm_end, vma->vm_page_prot, vma_wants_writenotify(vma));
+	}
+}
+#endif
+
 int
 mprotect_fixup(struct vm_area_struct *vma, struct vm_area_struct **pprev,
 	unsigned long start, unsigned long end, unsigned long newflags)
@@ -153,11 +201,29 @@ mprotect_fixup(struct vm_area_struct *vm
 	int error;
 	int dirty_accountable = 0;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	struct vm_area_struct *vma_m = NULL;
+	unsigned long start_m, end_m;
+
+	start_m = start + SEGMEXEC_TASK_SIZE;
+	end_m = end + SEGMEXEC_TASK_SIZE;
+#endif
+
 	if (newflags == oldflags) {
 		*pprev = vma;
 		return 0;
 	}
 
+	if (newflags & (VM_READ | VM_WRITE | VM_EXEC)) {
+		struct vm_area_struct *prev = vma->vm_prev, *next = vma->vm_next;
+
+		if (next && (next->vm_flags & VM_GROWSDOWN) && sysctl_heap_stack_gap > next->vm_start - end)
+			return -ENOMEM;
+
+		if (prev && (prev->vm_flags & VM_GROWSUP) && sysctl_heap_stack_gap > start - prev->vm_end)
+			return -ENOMEM;
+	}
+
 	/*
 	 * If we make a private mapping writable we increase our commit;
 	 * but (without finer accounting) cannot reduce our commit if we
@@ -174,6 +240,42 @@ mprotect_fixup(struct vm_area_struct *vm
 		}
 	}
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if ((mm->pax_flags & MF_PAX_SEGMEXEC) && ((oldflags ^ newflags) & VM_EXEC)) {
+		if (start != vma->vm_start) {
+			error = split_vma(mm, vma, start, 1);
+			if (error)
+				goto fail;
+			BUG_ON(!*pprev || (*pprev)->vm_next == vma);
+			*pprev = (*pprev)->vm_next;
+		}
+
+		if (end != vma->vm_end) {
+			error = split_vma(mm, vma, end, 0);
+			if (error)
+				goto fail;
+		}
+
+		if (pax_find_mirror_vma(vma)) {
+			error = __do_munmap(mm, start_m, end_m - start_m);
+			if (error)
+				goto fail;
+		} else {
+			vma_m = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);
+			if (!vma_m) {
+				error = -ENOMEM;
+				goto fail;
+			}
+			vma->vm_flags = newflags;
+			error = pax_mirror_vma(vma_m, vma);
+			if (error) {
+				vma->vm_flags = oldflags;
+				goto fail;
+			}
+		}
+	}
+#endif
+
 	/*
 	 * First try to merge with previous and/or next vma.
 	 */
@@ -204,9 +306,21 @@ success:
 	 * vm_flags and vm_page_prot are protected by the mmap_sem
 	 * held in write mode.
 	 */
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if ((mm->pax_flags & MF_PAX_SEGMEXEC) && (newflags & VM_EXEC) && ((vma->vm_flags ^ newflags) & VM_READ))
+		pax_find_mirror_vma(vma)->vm_flags ^= VM_READ;
+#endif
+
 	vma->vm_flags = newflags;
+
+#ifdef CONFIG_PAX_MPROTECT
+	if (mm->binfmt && mm->binfmt->handle_mprotect)
+		mm->binfmt->handle_mprotect(vma, newflags);
+#endif
+
 	vma->vm_page_prot = pgprot_modify(vma->vm_page_prot,
-					  vm_get_page_prot(newflags));
+					  vm_get_page_prot(vma->vm_flags));
 
 	if (vma_wants_writenotify(vma)) {
 		vma->vm_page_prot = vm_get_page_prot(newflags & ~VM_SHARED);
@@ -248,6 +362,17 @@ SYSCALL_DEFINE3(mprotect, unsigned long,
 	end = start + len;
 	if (end <= start)
 		return -ENOMEM;
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (current->mm->pax_flags & MF_PAX_SEGMEXEC) {
+		if (end > SEGMEXEC_TASK_SIZE)
+			return -EINVAL;
+	} else
+#endif
+
+	if (end > TASK_SIZE)
+		return -EINVAL;
+
 	if (!arch_validate_prot(prot))
 		return -EINVAL;
 
@@ -255,7 +380,7 @@ SYSCALL_DEFINE3(mprotect, unsigned long,
 	/*
 	 * Does the application expect PROT_READ to imply PROT_EXEC:
 	 */
-	if ((prot & PROT_READ) && (current->personality & READ_IMPLIES_EXEC))
+	if ((prot & (PROT_READ | PROT_WRITE)) && (current->personality & READ_IMPLIES_EXEC))
 		prot |= PROT_EXEC;
 
 	vm_flags = calc_vm_prot_bits(prot);
@@ -287,6 +412,11 @@ SYSCALL_DEFINE3(mprotect, unsigned long,
 	if (start > vma->vm_start)
 		prev = vma;
 
+#ifdef CONFIG_PAX_MPROTECT
+	if (current->mm->binfmt && current->mm->binfmt->handle_mprotect)
+		current->mm->binfmt->handle_mprotect(vma, vm_flags);
+#endif
+
 	for (nstart = start ; ; ) {
 		unsigned long newflags;
 
@@ -310,6 +440,9 @@ SYSCALL_DEFINE3(mprotect, unsigned long,
 		error = mprotect_fixup(vma, &prev, nstart, tmp, newflags);
 		if (error)
 			goto out;
+
+		track_exec_limit(current->mm, nstart, tmp, vm_flags);
+
 		nstart = tmp;
 
 		if (nstart < prev->vm_end)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/mremap.c linux-3.2.71-pax/mm/mremap.c
--- linux-3.2.71/mm/mremap.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/mm/mremap.c	2013-10-28 11:26:48.449772687 +0100
@@ -106,6 +106,12 @@ static void move_ptes(struct vm_area_str
 			continue;
 		pte = ptep_get_and_clear(mm, old_addr, old_pte);
 		pte = move_pte(pte, new_vma->vm_page_prot, old_addr, new_addr);
+
+#ifdef CONFIG_ARCH_TRACK_EXEC_LIMIT
+		if (!(__supported_pte_mask & _PAGE_NX) && (new_vma->vm_flags & (VM_PAGEEXEC | VM_EXEC)) == VM_PAGEEXEC)
+			pte = pte_exprotect(pte);
+#endif
+
 		set_pte_at(mm, new_addr, new_pte, pte);
 	}
 
@@ -251,7 +257,6 @@ static unsigned long move_vma(struct vm_
 	 * If this were a serious issue, we'd add a flag to do_munmap().
 	 */
 	hiwater_vm = mm->hiwater_vm;
-	mm->total_vm += new_len >> PAGE_SHIFT;
 	vm_stat_account(mm, vma->vm_flags, vma->vm_file, new_len>>PAGE_SHIFT);
 
 	if (do_munmap(mm, old_addr, old_len) < 0) {
@@ -290,6 +295,11 @@ static struct vm_area_struct *vma_to_res
 	if (is_vm_hugetlb_page(vma))
 		goto Einval;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (pax_find_mirror_vma(vma))
+		goto Einval;
+#endif
+
 	/* We can't remap across vm area boundaries */
 	if (old_len > vma->vm_end - addr)
 		goto Efault;
@@ -346,20 +356,25 @@ static unsigned long mremap_to(unsigned
 	unsigned long ret = -EINVAL;
 	unsigned long charged = 0;
 	unsigned long map_flags;
+	unsigned long pax_task_size = TASK_SIZE;
 
 	if (new_addr & ~PAGE_MASK)
 		goto out;
 
-	if (new_len > TASK_SIZE || new_addr > TASK_SIZE - new_len)
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (mm->pax_flags & MF_PAX_SEGMEXEC)
+		pax_task_size = SEGMEXEC_TASK_SIZE;
+#endif
+
+	pax_task_size -= PAGE_SIZE;
+
+	if (new_len > TASK_SIZE || new_addr > pax_task_size - new_len)
 		goto out;
 
 	/* Check if the location we're moving into overlaps the
 	 * old location at all, and fail if it does.
 	 */
-	if ((new_addr <= addr) && (new_addr+new_len) > addr)
-		goto out;
-
-	if ((addr <= new_addr) && (addr+old_len) > new_addr)
+	if (addr + old_len > new_addr && new_addr + new_len > addr)
 		goto out;
 
 	ret = security_file_mmap(NULL, 0, 0, 0, new_addr, 1);
@@ -431,6 +446,7 @@ unsigned long do_mremap(unsigned long ad
 	struct vm_area_struct *vma;
 	unsigned long ret = -EINVAL;
 	unsigned long charged = 0;
+	unsigned long pax_task_size = TASK_SIZE;
 
 	if (flags & ~(MREMAP_FIXED | MREMAP_MAYMOVE))
 		goto out;
@@ -449,6 +465,17 @@ unsigned long do_mremap(unsigned long ad
 	if (!new_len)
 		goto out;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (mm->pax_flags & MF_PAX_SEGMEXEC)
+		pax_task_size = SEGMEXEC_TASK_SIZE;
+#endif
+
+	pax_task_size -= PAGE_SIZE;
+
+	if (new_len > pax_task_size || addr > pax_task_size-new_len ||
+	    old_len > pax_task_size || addr > pax_task_size-old_len)
+		goto out;
+
 	if (flags & MREMAP_FIXED) {
 		if (flags & MREMAP_MAYMOVE)
 			ret = mremap_to(addr, old_len, new_addr, new_len);
@@ -490,7 +517,6 @@ unsigned long do_mremap(unsigned long ad
 				goto out;
 			}
 
-			mm->total_vm += pages;
 			vm_stat_account(mm, vma->vm_flags, vma->vm_file, pages);
 			if (vma->vm_flags & VM_LOCKED) {
 				mm->locked_vm += pages;
@@ -498,6 +524,7 @@ unsigned long do_mremap(unsigned long ad
 						   addr + new_len);
 			}
 			ret = addr;
+			track_exec_limit(vma->vm_mm, vma->vm_start, addr + new_len, vma->vm_flags);
 			goto out;
 		}
 	}
@@ -524,7 +551,13 @@ unsigned long do_mremap(unsigned long ad
 		ret = security_file_mmap(NULL, 0, 0, 0, new_addr, 1);
 		if (ret)
 			goto out;
+
+		map_flags = vma->vm_flags;
 		ret = move_vma(vma, addr, old_len, new_len, new_addr);
+		if (!(ret & ~PAGE_MASK)) {
+			track_exec_limit(current->mm, addr, addr + old_len, 0UL);
+			track_exec_limit(current->mm, new_addr, new_addr + new_len, map_flags);
+		}
 	}
 out:
 	if (ret & ~PAGE_MASK)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/nobootmem.c linux-3.2.71-pax/mm/nobootmem.c
--- linux-3.2.71/mm/nobootmem.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/mm/nobootmem.c	2012-07-04 19:24:48.936063009 +0200
@@ -109,19 +109,30 @@ static void __init __free_pages_memory(u
 unsigned long __init free_all_memory_core_early(int nodeid)
 {
 	int i;
-	u64 start, end;
+	u64 start, end, startrange, endrange;
 	unsigned long count = 0;
-	struct range *range = NULL;
+	struct range *range = NULL, rangerange = { 0, 0 };
 	int nr_range;
 
 	nr_range = get_free_all_memory_range(&range, nodeid);
+	startrange = __pa(range) >> PAGE_SHIFT;
+	endrange = (__pa(range + nr_range) - 1) >> PAGE_SHIFT;
 
 	for (i = 0; i < nr_range; i++) {
 		start = range[i].start;
 		end = range[i].end;
+		if (start <= endrange && startrange < end) {
+			BUG_ON(rangerange.start | rangerange.end);
+			rangerange = range[i];
+			continue;
+		}
 		count += end - start;
 		__free_pages_memory(start, end);
 	}
+	start = rangerange.start;
+	end = rangerange.end;
+	count += end - start;
+	__free_pages_memory(start, end);
 
 	return count;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/nommu.c linux-3.2.71-pax/mm/nommu.c
--- linux-3.2.71/mm/nommu.c	2015-05-10 09:22:39.191493146 +0200
+++ linux-3.2.71-pax/mm/nommu.c	2015-05-10 09:23:09.555494795 +0200
@@ -62,7 +62,6 @@ int sysctl_overcommit_memory = OVERCOMMI
 int sysctl_overcommit_ratio = 50; /* default is 50% */
 int sysctl_max_map_count = DEFAULT_MAX_MAP_COUNT;
 int sysctl_nr_trim_pages = CONFIG_NOMMU_INITIAL_TRIM_EXCESS;
-int heap_stack_gap = 0;
 
 atomic_long_t mmap_pages_allocated;
 
@@ -827,15 +826,6 @@ struct vm_area_struct *find_vma(struct m
 EXPORT_SYMBOL(find_vma);
 
 /*
- * find a VMA
- * - we don't extend stack VMAs under NOMMU conditions
- */
-struct vm_area_struct *find_extend_vma(struct mm_struct *mm, unsigned long addr)
-{
-	return find_vma(mm, addr);
-}
-
-/*
  * expand a stack to a given address
  * - not supported under NOMMU conditions
  */
@@ -1555,6 +1545,7 @@ int split_vma(struct mm_struct *mm, stru
 
 	/* most fields are the same, copy all, and then fixup */
 	*new = *vma;
+	INIT_LIST_HEAD(&new->anon_vma_chain);
 	*region = *vma->vm_region;
 	new->vm_region = region;
 
@@ -1971,8 +1962,8 @@ int filemap_fault(struct vm_area_struct
 }
 EXPORT_SYMBOL(filemap_fault);
 
-static int __access_remote_vm(struct task_struct *tsk, struct mm_struct *mm,
-		unsigned long addr, void *buf, int len, int write)
+static ssize_t __access_remote_vm(struct task_struct *tsk, struct mm_struct *mm,
+		unsigned long addr, void *buf, size_t len, int write)
 {
 	struct vm_area_struct *vma;
 
@@ -2013,8 +2004,8 @@ static int __access_remote_vm(struct tas
  *
  * The caller must hold a reference on @mm.
  */
-int access_remote_vm(struct mm_struct *mm, unsigned long addr,
-		void *buf, int len, int write)
+ssize_t access_remote_vm(struct mm_struct *mm, unsigned long addr,
+		void *buf, size_t len, int write)
 {
 	return __access_remote_vm(NULL, mm, addr, buf, len, write);
 }
@@ -2023,7 +2014,7 @@ int access_remote_vm(struct mm_struct *m
  * Access another process' address space.
  * - source/target buffer must be kernel space
  */
-int access_process_vm(struct task_struct *tsk, unsigned long addr, void *buf, int len, int write)
+ssize_t access_process_vm(struct task_struct *tsk, unsigned long addr, void *buf, size_t len, int write)
 {
 	struct mm_struct *mm;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/page_alloc.c linux-3.2.71-pax/mm/page_alloc.c
--- linux-3.2.71/mm/page_alloc.c	2014-09-14 14:11:00.118118786 +0200
+++ linux-3.2.71-pax/mm/page_alloc.c	2014-09-14 14:11:26.122138476 +0200
@@ -57,6 +57,7 @@
 #include <linux/ftrace_event.h>
 #include <linux/memcontrol.h>
 #include <linux/prefetch.h>
+#include <linux/random.h>
 
 #include <asm/tlbflush.h>
 #include <asm/div64.h>
@@ -341,7 +342,7 @@ out:
  * This usage means that zero-order pages may not be compound.
  */
 
-static void free_compound_page(struct page *page)
+void free_compound_page(struct page *page)
 {
 	__free_pages_ok(page, compound_order(page));
 }
@@ -654,6 +655,10 @@ static bool free_pages_prepare(struct pa
 	int i;
 	int bad = 0;
 
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+	unsigned long index = 1UL << order;
+#endif
+
 	trace_mm_page_free_direct(page, order);
 	kmemcheck_free_shadow(page, order);
 
@@ -669,6 +674,12 @@ static bool free_pages_prepare(struct pa
 		debug_check_no_obj_freed(page_address(page),
 					   PAGE_SIZE << order);
 	}
+
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+	for (; index; --index)
+		sanitize_highpage(page + index - 1);
+#endif
+
 	arch_free_page(page, order);
 	kernel_map_pages(page, 1 << order, 0);
 
@@ -692,6 +703,20 @@ static void __free_pages_ok(struct page
 	local_irq_restore(flags);
 }
 
+#ifdef CONFIG_PAX_LATENT_ENTROPY
+bool __meminitdata extra_latent_entropy;
+
+static int __init setup_pax_extra_latent_entropy(char *str)
+{
+	extra_latent_entropy = true;
+	return 0;
+}
+early_param("pax_extra_latent_entropy", setup_pax_extra_latent_entropy);
+
+volatile u64 latent_entropy __latent_entropy;
+EXPORT_SYMBOL(latent_entropy);
+#endif
+
 /*
  * permit the bootmem allocator to evade page validation on high-order frees
  */
@@ -715,6 +740,19 @@ void __meminit __free_pages_bootmem(stru
 			set_page_count(p, 0);
 		}
 
+#ifdef CONFIG_PAX_LATENT_ENTROPY
+		if (extra_latent_entropy && !PageHighMem(page) && page_to_pfn(page) < 0x100000) {
+			u64 hash = 0;
+			size_t index, end = PAGE_SIZE * (1UL << order) / sizeof hash;
+			const u64 *data = lowmem_page_address(page);
+
+			for (index = 0; index < end; index++)
+				hash ^= hash + data[index];
+			latent_entropy ^= hash;
+			add_device_randomness((const void *)&latent_entropy, sizeof(latent_entropy));
+		}
+#endif
+
 		set_page_refcounted(page);
 		__free_pages(page, order);
 	}
@@ -784,8 +822,10 @@ static int prep_new_page(struct page *pa
 	arch_alloc_page(page, order);
 	kernel_map_pages(page, 1 << order, 1);
 
+#ifndef CONFIG_PAX_MEMORY_SANITIZE
 	if (gfp_flags & __GFP_ZERO)
 		prep_zero_page(page, order, gfp_flags);
+#endif
 
 	if (order && (gfp_flags & __GFP_COMP))
 		prep_compound_page(page, order);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/page-writeback.c linux-3.2.71-pax/mm/page-writeback.c
--- linux-3.2.71/mm/page-writeback.c	2015-08-07 11:37:20.755789899 +0200
+++ linux-3.2.71-pax/mm/page-writeback.c	2015-08-07 11:37:43.031790554 +0200
@@ -522,7 +522,7 @@ unsigned long bdi_dirty_limit(struct bac
  *   card's bdi_dirty may rush to many times higher than bdi_setpoint.
  * - the bdi dirty thresh drops quickly due to change of JBOD workload
  */
-static unsigned long bdi_position_ratio(struct backing_dev_info *bdi,
+static unsigned long __intentional_overflow(-1) bdi_position_ratio(struct backing_dev_info *bdi,
 					unsigned long thresh,
 					unsigned long bg_thresh,
 					unsigned long dirty,
@@ -1373,7 +1373,7 @@ ratelimit_handler(struct notifier_block
 	return NOTIFY_DONE;
 }
 
-static struct notifier_block __cpuinitdata ratelimit_nb = {
+static struct notifier_block ratelimit_nb = {
 	.notifier_call	= ratelimit_handler,
 	.next		= NULL,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/percpu.c linux-3.2.71-pax/mm/percpu.c
--- linux-3.2.71/mm/percpu.c	2014-11-05 23:20:30.373389880 +0100
+++ linux-3.2.71-pax/mm/percpu.c	2014-11-05 23:20:50.553398838 +0100
@@ -121,7 +121,7 @@ static unsigned int pcpu_low_unit_cpu __
 static unsigned int pcpu_high_unit_cpu __read_mostly;
 
 /* the address of the first chunk which starts with the kernel static area */
-void *pcpu_base_addr __read_mostly;
+void *pcpu_base_addr __read_only;
 EXPORT_SYMBOL_GPL(pcpu_base_addr);
 
 static const int *pcpu_unit_map __read_mostly;		/* cpu -> unit */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/process_vm_access.c linux-3.2.71-pax/mm/process_vm_access.c
--- linux-3.2.71/mm/process_vm_access.c	2013-03-29 02:18:38.747676281 +0100
+++ linux-3.2.71-pax/mm/process_vm_access.c	2013-03-29 02:20:31.367670268 +0100
@@ -258,19 +258,19 @@ static ssize_t process_vm_rw_core(pid_t
 	size_t iov_l_curr_offset = 0;
 	ssize_t iov_len;
 
+	return -ENOSYS; // PaX: until properly audited
+
 	/*
 	 * Work out how many pages of struct pages we're going to need
 	 * when eventually calling get_user_pages
 	 */
 	for (i = 0; i < riovcnt; i++) {
 		iov_len = rvec[i].iov_len;
-		if (iov_len > 0) {
-			nr_pages_iov = ((unsigned long)rvec[i].iov_base
-					+ iov_len)
-				/ PAGE_SIZE - (unsigned long)rvec[i].iov_base
-				/ PAGE_SIZE + 1;
-			nr_pages = max(nr_pages, nr_pages_iov);
-		}
+		if (iov_len <= 0)
+			continue;
+		nr_pages_iov = ((unsigned long)rvec[i].iov_base + iov_len) / PAGE_SIZE -
+				(unsigned long)rvec[i].iov_base / PAGE_SIZE + 1;
+		nr_pages = max(nr_pages, nr_pages_iov);
 	}
 
 	if (nr_pages == 0)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/readahead.c linux-3.2.71-pax/mm/readahead.c
--- linux-3.2.71/mm/readahead.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/mm/readahead.c	2013-11-29 01:15:17.698415440 +0100
@@ -342,7 +342,7 @@ static unsigned long get_next_ra_size(st
  * 	- length of the sequential read sequence, or
  * 	- thrashing threshold in memory tight systems
  */
-static pgoff_t count_history_pages(struct address_space *mapping,
+static pgoff_t __intentional_overflow(-1) count_history_pages(struct address_space *mapping,
 				   struct file_ra_state *ra,
 				   pgoff_t offset, unsigned long max)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/rmap.c linux-3.2.71-pax/mm/rmap.c
--- linux-3.2.71/mm/rmap.c	2015-05-10 09:22:39.195493146 +0200
+++ linux-3.2.71-pax/mm/rmap.c	2015-05-10 09:23:09.559494795 +0200
@@ -156,6 +156,10 @@ int anon_vma_prepare(struct vm_area_stru
 	struct anon_vma *anon_vma = vma->anon_vma;
 	struct anon_vma_chain *avc;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+	struct anon_vma_chain *avc_m = NULL;
+#endif
+
 	might_sleep();
 	if (unlikely(!anon_vma)) {
 		struct mm_struct *mm = vma->vm_mm;
@@ -165,6 +169,12 @@ int anon_vma_prepare(struct vm_area_stru
 		if (!avc)
 			goto out_enomem;
 
+#ifdef CONFIG_PAX_SEGMEXEC
+		avc_m = anon_vma_chain_alloc(GFP_KERNEL);
+		if (!avc_m)
+			goto out_enomem_free_avc;
+#endif
+
 		anon_vma = find_mergeable_anon_vma(vma);
 		allocated = NULL;
 		if (!anon_vma) {
@@ -178,6 +188,21 @@ int anon_vma_prepare(struct vm_area_stru
 		/* page_table_lock to protect against threads */
 		spin_lock(&mm->page_table_lock);
 		if (likely(!vma->anon_vma)) {
+
+#ifdef CONFIG_PAX_SEGMEXEC
+			struct vm_area_struct *vma_m = pax_find_mirror_vma(vma);
+
+			if (vma_m) {
+				BUG_ON(vma_m->anon_vma);
+				vma_m->anon_vma = anon_vma;
+				avc_m->anon_vma = anon_vma;
+				avc_m->vma = vma;
+				list_add(&avc_m->same_vma, &vma_m->anon_vma_chain);
+				list_add(&avc_m->same_anon_vma, &anon_vma->head);
+				avc_m = NULL;
+			}
+#endif
+
 			vma->anon_vma = anon_vma;
 			avc->anon_vma = anon_vma;
 			avc->vma = vma;
@@ -193,12 +218,24 @@ int anon_vma_prepare(struct vm_area_stru
 
 		if (unlikely(allocated))
 			put_anon_vma(allocated);
+
+#ifdef CONFIG_PAX_SEGMEXEC
+		if (unlikely(avc_m))
+			anon_vma_chain_free(avc_m);
+#endif
+
 		if (unlikely(avc))
 			anon_vma_chain_free(avc);
 	}
 	return 0;
 
  out_enomem_free_avc:
+
+#ifdef CONFIG_PAX_SEGMEXEC
+	if (avc_m)
+		anon_vma_chain_free(avc_m);
+#endif
+
 	anon_vma_chain_free(avc);
  out_enomem:
 	return -ENOMEM;
@@ -257,7 +294,7 @@ static void anon_vma_chain_link(struct v
  * good chance of avoiding scanning the whole hierarchy when it searches where
  * page is mapped.
  */
-int anon_vma_clone(struct vm_area_struct *dst, struct vm_area_struct *src)
+int anon_vma_clone(struct vm_area_struct *dst, const struct vm_area_struct *src)
 {
 	struct anon_vma_chain *avc, *pavc;
 	struct anon_vma *root = NULL;
@@ -311,7 +348,7 @@ int anon_vma_clone(struct vm_area_struct
  * the corresponding VMA in the parent process is attached to.
  * Returns 0 on success, non-zero on failure.
  */
-int anon_vma_fork(struct vm_area_struct *vma, struct vm_area_struct *pvma)
+int anon_vma_fork(struct vm_area_struct *vma, const struct vm_area_struct *pvma)
 {
 	struct anon_vma_chain *avc;
 	struct anon_vma *anon_vma;
@@ -429,8 +466,10 @@ static void anon_vma_ctor(void *data)
 void __init anon_vma_init(void)
 {
 	anon_vma_cachep = kmem_cache_create("anon_vma", sizeof(struct anon_vma),
-			0, SLAB_DESTROY_BY_RCU|SLAB_PANIC, anon_vma_ctor);
-	anon_vma_chain_cachep = KMEM_CACHE(anon_vma_chain, SLAB_PANIC);
+			0, SLAB_DESTROY_BY_RCU|SLAB_PANIC|SLAB_NO_SANITIZE,
+			anon_vma_ctor);
+	anon_vma_chain_cachep = KMEM_CACHE(anon_vma_chain,
+			SLAB_PANIC|SLAB_NO_SANITIZE);
 }
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/shmem.c linux-3.2.71-pax/mm/shmem.c
--- linux-3.2.71/mm/shmem.c	2014-11-05 23:20:30.373389880 +0100
+++ linux-3.2.71-pax/mm/shmem.c	2014-11-05 23:20:50.553398838 +0100
@@ -74,7 +74,7 @@ static struct vfsmount *shm_mnt;
 #define BOGO_DIRENT_SIZE 20
 
 /* Symlink up to this size is kmalloc'ed instead of using a swappable page */
-#define SHORT_SYMLINK_LEN 128
+#define SHORT_SYMLINK_LEN 64
 
 /*
  * vmtruncate_range() communicates with shmem_fault via
@@ -1926,6 +1926,11 @@ static const struct xattr_handler *shmem
 static int shmem_xattr_validate(const char *name)
 {
 	struct { const char *prefix; size_t len; } arr[] = {
+
+#ifdef CONFIG_PAX_XATTR_PAX_FLAGS
+		{ XATTR_USER_PREFIX, XATTR_USER_PREFIX_LEN},
+#endif
+
 		{ XATTR_SECURITY_PREFIX, XATTR_SECURITY_PREFIX_LEN },
 		{ XATTR_TRUSTED_PREFIX, XATTR_TRUSTED_PREFIX_LEN }
 	};
@@ -1979,6 +1984,15 @@ static int shmem_setxattr(struct dentry
 	if (err)
 		return err;
 
+#ifdef CONFIG_PAX_XATTR_PAX_FLAGS
+	if (!strncmp(name, XATTR_USER_PREFIX, XATTR_USER_PREFIX_LEN)) {
+		if (strcmp(name, XATTR_NAME_PAX_FLAGS))
+			return -EOPNOTSUPP;
+		if (size > 8)
+			return -EINVAL;
+	}
+#endif
+
 	if (size == 0)
 		value = "";  /* empty EA, do not remove */
 
@@ -2312,8 +2326,7 @@ int shmem_fill_super(struct super_block
 	int err = -ENOMEM;
 
 	/* Round up to L1_CACHE_BYTES to resist false sharing */
-	sbinfo = kzalloc(max((int)sizeof(struct shmem_sb_info),
-				L1_CACHE_BYTES), GFP_KERNEL);
+	sbinfo = kzalloc(max(sizeof(struct shmem_sb_info), L1_CACHE_BYTES), GFP_KERNEL);
 	if (!sbinfo)
 		return -ENOMEM;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/slab.c linux-3.2.71-pax/mm/slab.c
--- linux-3.2.71/mm/slab.c	2014-09-14 14:11:00.134118798 +0200
+++ linux-3.2.71-pax/mm/slab.c	2014-11-01 00:28:04.259885953 +0100
@@ -151,7 +151,7 @@
 
 /* Legal flag mask for kmem_cache_create(). */
 #if DEBUG
-# define CREATE_MASK	(SLAB_RED_ZONE | \
+# define CREATE_MASK	(SLAB_USERCOPY | SLAB_NO_SANITIZE | SLAB_RED_ZONE | \
 			 SLAB_POISON | SLAB_HWCACHE_ALIGN | \
 			 SLAB_CACHE_DMA | \
 			 SLAB_STORE_USER | \
@@ -159,8 +159,8 @@
 			 SLAB_DESTROY_BY_RCU | SLAB_MEM_SPREAD | \
 			 SLAB_DEBUG_OBJECTS | SLAB_NOLEAKTRACE | SLAB_NOTRACK)
 #else
-# define CREATE_MASK	(SLAB_HWCACHE_ALIGN | \
-			 SLAB_CACHE_DMA | \
+# define CREATE_MASK	(SLAB_USERCOPY | SLAB_NO_SANITIZE | \
+			 SLAB_HWCACHE_ALIGN | SLAB_CACHE_DMA | \
 			 SLAB_RECLAIM_ACCOUNT | SLAB_PANIC | \
 			 SLAB_DESTROY_BY_RCU | SLAB_MEM_SPREAD | \
 			 SLAB_DEBUG_OBJECTS | SLAB_NOLEAKTRACE | SLAB_NOTRACK)
@@ -288,7 +288,7 @@ struct kmem_list3 {
  * Need this for bootstrapping a per node allocator.
  */
 #define NUM_INIT_LISTS (3 * MAX_NUMNODES)
-static struct kmem_list3 __initdata initkmem_list3[NUM_INIT_LISTS];
+static struct kmem_list3 initkmem_list3[NUM_INIT_LISTS];
 #define	CACHE_CACHE 0
 #define	SIZE_AC MAX_NUMNODES
 #define	SIZE_L3 (2 * MAX_NUMNODES)
@@ -389,10 +389,12 @@ static void kmem_list3_init(struct kmem_
 		if ((x)->max_freeable < i)				\
 			(x)->max_freeable = i;				\
 	} while (0)
-#define STATS_INC_ALLOCHIT(x)	atomic_inc(&(x)->allochit)
-#define STATS_INC_ALLOCMISS(x)	atomic_inc(&(x)->allocmiss)
-#define STATS_INC_FREEHIT(x)	atomic_inc(&(x)->freehit)
-#define STATS_INC_FREEMISS(x)	atomic_inc(&(x)->freemiss)
+#define STATS_INC_ALLOCHIT(x)	atomic_inc_unchecked(&(x)->allochit)
+#define STATS_INC_ALLOCMISS(x)	atomic_inc_unchecked(&(x)->allocmiss)
+#define STATS_INC_FREEHIT(x)	atomic_inc_unchecked(&(x)->freehit)
+#define STATS_INC_FREEMISS(x)	atomic_inc_unchecked(&(x)->freemiss)
+#define STATS_INC_SANITIZED(x)	atomic_inc_unchecked(&(x)->sanitized)
+#define STATS_INC_NOT_SANITIZED(x) atomic_inc_unchecked(&(x)->not_sanitized)
 #else
 #define	STATS_INC_ACTIVE(x)	do { } while (0)
 #define	STATS_DEC_ACTIVE(x)	do { } while (0)
@@ -409,6 +411,8 @@ static void kmem_list3_init(struct kmem_
 #define STATS_INC_ALLOCMISS(x)	do { } while (0)
 #define STATS_INC_FREEHIT(x)	do { } while (0)
 #define STATS_INC_FREEMISS(x)	do { } while (0)
+#define STATS_INC_SANITIZED(x)	do { } while (0)
+#define STATS_INC_NOT_SANITIZED(x) do { } while (0)
 #endif
 
 #if DEBUG
@@ -538,7 +542,7 @@ static inline void *index_to_obj(struct
  *   reciprocal_divide(offset, cache->reciprocal_buffer_size)
  */
 static inline unsigned int obj_to_index(const struct kmem_cache *cache,
-					const struct slab *slab, void *obj)
+					const struct slab *slab, const void *obj)
 {
 	u32 offset = (obj - slab->s_mem);
 	return reciprocal_divide(offset, cache->reciprocal_buffer_size);
@@ -559,12 +563,13 @@ EXPORT_SYMBOL(malloc_sizes);
 struct cache_names {
 	char *name;
 	char *name_dma;
+	char *name_usercopy;
 };
 
 static struct cache_names __initdata cache_names[] = {
-#define CACHE(x) { .name = "size-" #x, .name_dma = "size-" #x "(DMA)" },
+#define CACHE(x) { .name = "size-" #x, .name_dma = "size-" #x "(DMA)", .name_usercopy = "size-" #x "(USERCOPY)" },
 #include <linux/kmalloc_sizes.h>
-	{NULL,}
+	{NULL}
 #undef CACHE
 };
 
@@ -752,6 +757,12 @@ static inline struct kmem_cache *__find_
 	if (unlikely(gfpflags & GFP_DMA))
 		return csizep->cs_dmacachep;
 #endif
+
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+	if (unlikely(gfpflags & GFP_USERCOPY))
+		return csizep->cs_usercopycachep;
+#endif
+
 	return csizep->cs_cachep;
 }
 
@@ -1370,7 +1381,7 @@ static int __cpuinit cpuup_callback(stru
 	return notifier_from_errno(err);
 }
 
-static struct notifier_block __cpuinitdata cpucache_notifier = {
+static struct notifier_block cpucache_notifier = {
 	&cpuup_callback, NULL, 0
 };
 
@@ -1572,7 +1583,7 @@ void __init kmem_cache_init(void)
 	sizes[INDEX_AC].cs_cachep = kmem_cache_create(names[INDEX_AC].name,
 					sizes[INDEX_AC].cs_size,
 					ARCH_KMALLOC_MINALIGN,
-					ARCH_KMALLOC_FLAGS|SLAB_PANIC,
+					ARCH_KMALLOC_FLAGS|SLAB_PANIC|SLAB_USERCOPY,
 					NULL);
 
 	if (INDEX_AC != INDEX_L3) {
@@ -1580,7 +1591,7 @@ void __init kmem_cache_init(void)
 			kmem_cache_create(names[INDEX_L3].name,
 				sizes[INDEX_L3].cs_size,
 				ARCH_KMALLOC_MINALIGN,
-				ARCH_KMALLOC_FLAGS|SLAB_PANIC,
+				ARCH_KMALLOC_FLAGS|SLAB_PANIC|SLAB_USERCOPY,
 				NULL);
 	}
 
@@ -1598,7 +1609,7 @@ void __init kmem_cache_init(void)
 			sizes->cs_cachep = kmem_cache_create(names->name,
 					sizes->cs_size,
 					ARCH_KMALLOC_MINALIGN,
-					ARCH_KMALLOC_FLAGS|SLAB_PANIC,
+					ARCH_KMALLOC_FLAGS|SLAB_PANIC|SLAB_USERCOPY,
 					NULL);
 		}
 #ifdef CONFIG_ZONE_DMA
@@ -1610,6 +1621,16 @@ void __init kmem_cache_init(void)
 						SLAB_PANIC,
 					NULL);
 #endif
+
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+		sizes->cs_usercopycachep = kmem_cache_create(
+					names->name_usercopy,
+					sizes->cs_size,
+					ARCH_KMALLOC_MINALIGN,
+					ARCH_KMALLOC_FLAGS|SLAB_PANIC|SLAB_USERCOPY,
+					NULL);
+#endif
+
 		sizes++;
 		names++;
 	}
@@ -2284,6 +2305,13 @@ kmem_cache_create (const char *name, siz
 	 */
 	BUG_ON(flags & ~CREATE_MASK);
 
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+	if (pax_sanitize_slab == PAX_SANITIZE_SLAB_OFF || (flags & SLAB_DESTROY_BY_RCU))
+		flags |= SLAB_NO_SANITIZE;
+	else if (pax_sanitize_slab == PAX_SANITIZE_SLAB_FULL)
+		flags &= ~SLAB_NO_SANITIZE;
+#endif
+
 	/*
 	 * Check that size is in terms of words.  This is needed to avoid
 	 * unaligned accesses for some archs when redzoning is used, and makes
@@ -3662,6 +3690,20 @@ static inline void __cache_free(struct k
 	struct array_cache *ac = cpu_cache_get(cachep);
 
 	check_irq_off();
+
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+	if (cachep->flags & (SLAB_POISON | SLAB_NO_SANITIZE))
+		STATS_INC_NOT_SANITIZED(cachep);
+	else {
+		memset(objp, PAX_MEMORY_SANITIZE_VALUE, obj_size(cachep));
+
+		if (cachep->ctor)
+			cachep->ctor(objp);
+
+		STATS_INC_SANITIZED(cachep);
+	}
+#endif
+
 	kmemleak_free_recursive(objp, cachep->flags);
 	objp = cache_free_debugcheck(cachep, objp, caller);
 
@@ -3879,6 +3921,7 @@ void kfree(const void *objp)
 
 	if (unlikely(ZERO_OR_NULL_PTR(objp)))
 		return;
+	VM_BUG_ON(!virt_addr_valid(objp));
 	local_irq_save(flags);
 	kfree_debugcheck(objp);
 	c = virt_to_cache(objp);
@@ -4216,6 +4259,9 @@ static void print_slabinfo_header(struct
 	seq_puts(m, " : globalstat <listallocs> <maxobjs> <grown> <reaped> "
 		 "<error> <maxfreeable> <nodeallocs> <remotefrees> <alienoverflow>");
 	seq_puts(m, " : cpustat <allochit> <allocmiss> <freehit> <freemiss>");
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+	seq_puts(m, " : pax <sanitized> <not_sanitized>");
+#endif
 #endif
 	seq_putc(m, '\n');
 }
@@ -4325,14 +4371,22 @@ static int s_show(struct seq_file *m, vo
 	}
 	/* cpu stats */
 	{
-		unsigned long allochit = atomic_read(&cachep->allochit);
-		unsigned long allocmiss = atomic_read(&cachep->allocmiss);
-		unsigned long freehit = atomic_read(&cachep->freehit);
-		unsigned long freemiss = atomic_read(&cachep->freemiss);
+		unsigned long allochit = atomic_read_unchecked(&cachep->allochit);
+		unsigned long allocmiss = atomic_read_unchecked(&cachep->allocmiss);
+		unsigned long freehit = atomic_read_unchecked(&cachep->freehit);
+		unsigned long freemiss = atomic_read_unchecked(&cachep->freemiss);
 
 		seq_printf(m, " : cpustat %6lu %6lu %6lu %6lu",
 			   allochit, allocmiss, freehit, freemiss);
 	}
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+	{
+		unsigned long sanitized = atomic_read_unchecked(&cachep->sanitized);
+		unsigned long not_sanitized = atomic_read_unchecked(&cachep->not_sanitized);
+
+		seq_printf(m, " : pax %6lu %6lu", sanitized, not_sanitized);
+	}
+#endif
 #endif
 	seq_putc(m, '\n');
 	return 0;
@@ -4594,6 +4648,64 @@ static int __init slab_proc_init(void)
 module_init(slab_proc_init);
 #endif
 
+bool is_usercopy_object(const void *ptr)
+{
+	struct page *page;
+	struct kmem_cache *cachep;
+
+	if (ZERO_OR_NULL_PTR(ptr))
+		return false;
+
+	if (!slab_is_available())
+		return false;
+
+	if (!virt_addr_valid(ptr))
+		return false;
+
+	page = virt_to_head_page(ptr);
+
+	if (!PageSlab(page))
+		return false;
+
+	cachep = page_get_cache(page);
+	return cachep->flags & SLAB_USERCOPY;
+}
+
+#ifdef CONFIG_PAX_USERCOPY
+const char *check_heap_object(const void *ptr, unsigned long n)
+{
+	struct page *page;
+	struct kmem_cache *cachep;
+	struct slab *slabp;
+	unsigned int objnr;
+	unsigned long offset;
+
+	if (ZERO_OR_NULL_PTR(ptr))
+		return "<null>";
+
+	if (!virt_addr_valid(ptr))
+		return NULL;
+
+	page = virt_to_head_page(ptr);
+
+	if (!PageSlab(page))
+		return NULL;
+
+	cachep = page_get_cache(page);
+	if (!(cachep->flags & SLAB_USERCOPY))
+		return cachep->name;
+
+	slabp = page_get_slab(page);
+	objnr = obj_to_index(cachep, slabp, ptr);
+	BUG_ON(objnr >= cachep->num);
+	offset = ptr - index_to_obj(cachep, slabp, objnr) - obj_offset(cachep);
+	if (offset <= obj_size(cachep) && n <= obj_size(cachep) - offset)
+		return NULL;
+
+	return cachep->name;
+}
+#endif
+
 /**
  * ksize - get the actual amount of memory allocated for a given object
  * @objp: Pointer to the object
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/slob.c linux-3.2.71-pax/mm/slob.c
--- linux-3.2.71/mm/slob.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/mm/slob.c	2014-11-01 00:52:16.096493316 +0100
@@ -29,7 +29,7 @@
  * If kmalloc is asked for objects of PAGE_SIZE or larger, it calls
  * alloc_pages() directly, allocating compound pages so the page order
  * does not have to be separately tracked, and also stores the exact
- * allocation size in page->private so that it can be used to accurately
+ * allocation size in slob_page->size so that it can be used to accurately
  * provide ksize(). These objects are detected in kfree() because slob_page()
  * is false for them.
  *
@@ -58,6 +58,7 @@
  */
 
 #include <linux/kernel.h>
+#include <linux/sched.h>
 #include <linux/slab.h>
 #include <linux/mm.h>
 #include <linux/swap.h> /* struct reclaim_state */
@@ -91,6 +92,13 @@ struct slob_block {
 };
 typedef struct slob_block slob_t;
 
+struct kmem_cache {
+	unsigned int size, align;
+	unsigned long flags;
+	const char *name;
+	void (*ctor)(void *);
+};
+
 /*
  * We use struct page fields to manage some slob allocation aspects,
  * however to avoid the horrible mess in include/linux/mm_types.h, we'll
@@ -100,9 +108,8 @@ struct slob_page {
 	union {
 		struct {
 			unsigned long flags;	/* mandatory */
-			atomic_t _count;	/* mandatory */
 			slobidx_t units;	/* free units left in page */
-			unsigned long pad[2];
+			unsigned long size;	/* size when >=PAGE_SIZE */
 			slob_t *free;		/* first free slob_t in page */
 			struct list_head list;	/* linked list of free pages */
 		};
@@ -135,7 +142,7 @@ static LIST_HEAD(free_slob_large);
  */
 static inline int is_slob_page(struct slob_page *sp)
 {
-	return PageSlab((struct page *)sp);
+	return PageSlab((struct page *)sp) && !sp->size;
 }
 
 static inline void set_slob_page(struct slob_page *sp)
@@ -150,7 +157,7 @@ static inline void clear_slob_page(struc
 
 static inline struct slob_page *slob_page(const void *addr)
 {
-	return (struct slob_page *)virt_to_page(addr);
+	return (struct slob_page *)virt_to_head_page(addr);
 }
 
 /*
@@ -210,7 +217,7 @@ static void set_slob(slob_t *s, slobidx_
 /*
  * Return the size of a slob block.
  */
-static slobidx_t slob_units(slob_t *s)
+static slobidx_t slob_units(const slob_t *s)
 {
 	if (s->units > 0)
 		return s->units;
@@ -220,7 +227,7 @@ static slobidx_t slob_units(slob_t *s)
 /*
  * Return the next free slob block pointer after this one.
  */
-static slob_t *slob_next(slob_t *s)
+static slob_t *slob_next(const slob_t *s)
 {
 	slob_t *base = (slob_t *)((unsigned long)s & PAGE_MASK);
 	slobidx_t next;
@@ -235,7 +242,7 @@ static slob_t *slob_next(slob_t *s)
 /*
  * Returns true if s is the last free block in its page.
  */
-static int slob_last(slob_t *s)
+static int slob_last(const slob_t *s)
 {
 	return !((unsigned long)slob_next(s) & ~PAGE_MASK);
 }
@@ -254,6 +261,7 @@ static void *slob_new_pages(gfp_t gfp, i
 	if (!page)
 		return NULL;
 
+	set_slob_page(page);
 	return page_address(page);
 }
 
@@ -370,11 +378,11 @@ static void *slob_alloc(size_t size, gfp
 		if (!b)
 			return NULL;
 		sp = slob_page(b);
-		set_slob_page(sp);
 
 		spin_lock_irqsave(&slob_lock, flags);
 		sp->units = SLOB_UNITS(PAGE_SIZE);
 		sp->free = b;
+		sp->size = 0;
 		INIT_LIST_HEAD(&sp->list);
 		set_slob(b, SLOB_UNITS(PAGE_SIZE), b + SLOB_UNITS(PAGE_SIZE));
 		set_slob_page_free(sp, slob_list);
@@ -390,7 +398,7 @@ static void *slob_alloc(size_t size, gfp
 /*
  * slob_free: entry point into the slob allocator.
  */
-static void slob_free(void *block, int size)
+static void slob_free(struct kmem_cache *c, void *block, int size)
 {
 	struct slob_page *sp;
 	slob_t *prev, *next, *b = (slob_t *)block;
@@ -418,6 +426,11 @@ static void slob_free(void *block, int s
 		return;
 	}
 
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+	if (pax_sanitize_slab && !(c && (c->flags & SLAB_NO_SANITIZE)))
+		memset(block, PAX_MEMORY_SANITIZE_VALUE, size);
+#endif
+
 	if (!slob_page_free(sp)) {
 		/* This slob page is about to become partially free. Easy! */
 		sp->units = units;
@@ -476,10 +489,9 @@ out:
  * End of slob allocator proper. Begin kmem_cache_alloc and kmalloc frontend.
  */
 
-void *__kmalloc_node(size_t size, gfp_t gfp, int node)
+static void *__kmalloc_node_align(size_t size, gfp_t gfp, int node, int align)
 {
-	unsigned int *m;
-	int align = max(ARCH_KMALLOC_MINALIGN, ARCH_SLAB_MINALIGN);
+	slob_t *m;
 	void *ret;
 
 	gfp &= gfp_allowed_mask;
@@ -494,7 +506,10 @@ void *__kmalloc_node(size_t size, gfp_t
 
 		if (!m)
 			return NULL;
-		*m = size;
+		BUILD_BUG_ON(ARCH_KMALLOC_MINALIGN < 2 * SLOB_UNIT);
+		BUILD_BUG_ON(ARCH_SLAB_MINALIGN < 2 * SLOB_UNIT);
+		m[0].units = size;
+		m[1].units = align;
 		ret = (void *)m + align;
 
 		trace_kmalloc_node(_RET_IP_, ret,
@@ -506,16 +521,25 @@ void *__kmalloc_node(size_t size, gfp_t
 			gfp |= __GFP_COMP;
 		ret = slob_new_pages(gfp, order, node);
 		if (ret) {
-			struct page *page;
-			page = virt_to_page(ret);
-			page->private = size;
+			struct slob_page *sp;
+			sp = slob_page(ret);
+			sp->size = size;
 		}
 
 		trace_kmalloc_node(_RET_IP_, ret,
 				   size, PAGE_SIZE << order, gfp, node);
 	}
 
-	kmemleak_alloc(ret, size, 1, gfp);
+	return ret;
+}
+
+void *__kmalloc_node(size_t size, gfp_t gfp, int node)
+{
+	int align = max(ARCH_KMALLOC_MINALIGN, ARCH_SLAB_MINALIGN);
+	void *ret = __kmalloc_node_align(size, gfp, node, align);
+
+	if (!ZERO_OR_NULL_PTR(ret))
+		kmemleak_alloc(ret, size, 1, gfp);
 	return ret;
 }
 EXPORT_SYMBOL(__kmalloc_node);
@@ -530,16 +554,92 @@ void kfree(const void *block)
 		return;
 	kmemleak_free(block);
 
+	VM_BUG_ON(!virt_addr_valid(block));
 	sp = slob_page(block);
 	if (is_slob_page(sp)) {
 		int align = max(ARCH_KMALLOC_MINALIGN, ARCH_SLAB_MINALIGN);
-		unsigned int *m = (unsigned int *)(block - align);
-		slob_free(m, *m + align);
-	} else
+		slob_t *m = (slob_t *)(block - align);
+		slob_free(NULL, m, m[0].units + align);
+	} else {
+		clear_slob_page(sp);
+		free_slob_page(sp);
+		sp->size = 0;
 		put_page(&sp->page);
+	}
 }
 EXPORT_SYMBOL(kfree);
 
+bool is_usercopy_object(const void *ptr)
+{
+	if (!slab_is_available())
+		return false;
+
+	// PAX: TODO
+
+	return false;
+}
+
+#ifdef CONFIG_PAX_USERCOPY
+const char *check_heap_object(const void *ptr, unsigned long n)
+{
+	struct slob_page *sp;
+	const slob_t *free;
+	const void *base;
+	unsigned long flags;
+
+	if (ZERO_OR_NULL_PTR(ptr))
+		return "<null>";
+
+	if (!virt_addr_valid(ptr))
+		return NULL;
+
+	sp = slob_page(ptr);
+	if (!PageSlab((struct page *)sp))
+		return NULL;
+
+	if (sp->size) {
+		base = page_address(&sp->page);
+		if (base <= ptr && n <= sp->size - (ptr - base))
+			return NULL;
+		return "<slob>";
+	}
+
+	/* some tricky double walking to find the chunk */
+	spin_lock_irqsave(&slob_lock, flags);
+	base = (void *)((unsigned long)ptr & PAGE_MASK);
+	free = sp->free;
+
+	while ((void *)free <= ptr) {
+		base = free + slob_units(free);
+		free = slob_next(free);
+	}
+
+	while (base < (void *)free) {
+		slobidx_t m = ((slob_t *)base)[0].units, align = ((slob_t *)base)[1].units;
+		int size = SLOB_UNIT * SLOB_UNITS(m + align);
+		int offset;
+
+		if (ptr < base + align)
+			break;
+
+		offset = ptr - base - align;
+		if (offset >= m) {
+			base += size;
+			continue;
+		}
+
+		if (n > m - offset)
+			break;
+
+		spin_unlock_irqrestore(&slob_lock, flags);
+		return NULL;
+	}
+
+	spin_unlock_irqrestore(&slob_lock, flags);
+	return "<slob>";
+}
+#endif
+
 /* can't use ksize for kmem_cache_alloc memory, only kmalloc */
 size_t ksize(const void *block)
 {
@@ -552,27 +652,32 @@ size_t ksize(const void *block)
 	sp = slob_page(block);
 	if (is_slob_page(sp)) {
 		int align = max(ARCH_KMALLOC_MINALIGN, ARCH_SLAB_MINALIGN);
-		unsigned int *m = (unsigned int *)(block - align);
-		return SLOB_UNITS(*m) * SLOB_UNIT;
+		slob_t *m = (slob_t *)(block - align);
+		return SLOB_UNITS(m[0].units) * SLOB_UNIT;
 	} else
-		return sp->page.private;
+		return sp->size;
 }
 EXPORT_SYMBOL(ksize);
 
-struct kmem_cache {
-	unsigned int size, align;
-	unsigned long flags;
-	const char *name;
-	void (*ctor)(void *);
-};
-
 struct kmem_cache *kmem_cache_create(const char *name, size_t size,
 	size_t align, unsigned long flags, void (*ctor)(void *))
 {
 	struct kmem_cache *c;
 
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+	c = __kmalloc_node_align(sizeof(struct kmem_cache),
+		GFP_KERNEL, -1, ARCH_KMALLOC_MINALIGN);
+#else
 	c = slob_alloc(sizeof(struct kmem_cache),
 		GFP_KERNEL, ARCH_KMALLOC_MINALIGN, -1);
+#endif
+
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+	if (pax_sanitize_slab == PAX_SANITIZE_SLAB_OFF || (flags & SLAB_DESTROY_BY_RCU))
+		flags |= SLAB_NO_SANITIZE;
+	else if (pax_sanitize_slab == PAX_SANITIZE_SLAB_FULL)
+		flags &= ~SLAB_NO_SANITIZE;
+#endif
 
 	if (c) {
 		c->name = name;
@@ -602,7 +707,7 @@ void kmem_cache_destroy(struct kmem_cach
 	kmemleak_free(c);
 	if (c->flags & SLAB_DESTROY_BY_RCU)
 		rcu_barrier();
-	slob_free(c, sizeof(struct kmem_cache));
+	slob_free(NULL, c, sizeof(struct kmem_cache));
 }
 EXPORT_SYMBOL(kmem_cache_destroy);
 
@@ -614,17 +719,25 @@ void *kmem_cache_alloc_node(struct kmem_
 
 	lockdep_trace_alloc(flags);
 
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+	b = __kmalloc_node_align(c->size, flags, node, c->align);
+#else
 	if (c->size < PAGE_SIZE) {
 		b = slob_alloc(c->size, flags, c->align, node);
 		trace_kmem_cache_alloc_node(_RET_IP_, b, c->size,
 					    SLOB_UNITS(c->size) * SLOB_UNIT,
 					    flags, node);
 	} else {
+		struct slob_page *sp;
+
 		b = slob_new_pages(flags, get_order(c->size), node);
+		sp = slob_page(b);
+		sp->size = c->size;
 		trace_kmem_cache_alloc_node(_RET_IP_, b, c->size,
 					    PAGE_SIZE << get_order(c->size),
 					    flags, node);
 	}
+#endif
 
 	if (c->ctor)
 		c->ctor(b);
@@ -634,12 +747,18 @@ void *kmem_cache_alloc_node(struct kmem_
 }
 EXPORT_SYMBOL(kmem_cache_alloc_node);
 
-static void __kmem_cache_free(void *b, int size)
+static void __kmem_cache_free(struct kmem_cache *c, void *b, int size)
 {
-	if (size < PAGE_SIZE)
-		slob_free(b, size);
-	else
+	struct slob_page *sp = slob_page(b);
+
+	if (is_slob_page(sp))
+		slob_free(c, b, size);
+	else {
+		clear_slob_page(sp);
+		free_slob_page(sp);
+		sp->size = 0;
 		slob_free_pages(b, get_order(size));
+	}
 }
 
 static void kmem_rcu_free(struct rcu_head *head)
@@ -647,22 +766,36 @@ static void kmem_rcu_free(struct rcu_hea
 	struct slob_rcu *slob_rcu = (struct slob_rcu *)head;
 	void *b = (void *)slob_rcu - (slob_rcu->size - sizeof(struct slob_rcu));
 
-	__kmem_cache_free(b, slob_rcu->size);
+	__kmem_cache_free(NULL, b, slob_rcu->size);
 }
 
 void kmem_cache_free(struct kmem_cache *c, void *b)
 {
+	int size = c->size;
+
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+	if (size + c->align < PAGE_SIZE) {
+		size += c->align;
+		b -= c->align;
+	}
+#endif
+
 	kmemleak_free_recursive(b, c->flags);
 	if (unlikely(c->flags & SLAB_DESTROY_BY_RCU)) {
 		struct slob_rcu *slob_rcu;
-		slob_rcu = b + (c->size - sizeof(struct slob_rcu));
-		slob_rcu->size = c->size;
+		slob_rcu = b + (size - sizeof(struct slob_rcu));
+		slob_rcu->size = size;
 		call_rcu(&slob_rcu->head, kmem_rcu_free);
 	} else {
-		__kmem_cache_free(b, c->size);
+		__kmem_cache_free(c, b, size);
 	}
 
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+	trace_kfree(_RET_IP_, b);
+#else
 	trace_kmem_cache_free(_RET_IP_, b);
+#endif
+
 }
 EXPORT_SYMBOL(kmem_cache_free);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/slub.c linux-3.2.71-pax/mm/slub.c
--- linux-3.2.71/mm/slub.c	2015-08-07 11:37:20.755789899 +0200
+++ linux-3.2.71-pax/mm/slub.c	2015-08-07 11:37:43.031790554 +0200
@@ -186,7 +186,7 @@ static enum {
 	PARTIAL,	/* Kmem_cache_node works */
 	UP,		/* Everything works but does not show up in sysfs */
 	SYSFS		/* Sysfs up */
-} slab_state = DOWN;
+} slab_state __read_only = DOWN;
 
 /* A list of all slab caches on the system */
 static DECLARE_RWSEM(slub_lock);
@@ -2520,6 +2520,14 @@ static __always_inline void slab_free(st
 
 	slab_free_hook(s, x);
 
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+	if (!(s->flags & SLAB_NO_SANITIZE)) {
+		memset(x, PAX_MEMORY_SANITIZE_VALUE, s->objsize);
+		if (s->ctor)
+			s->ctor(x);
+	}
+#endif
+
 redo:
 	/*
 	 * Determine the currently cpus per cpu slab.
@@ -2555,6 +2563,8 @@ void kmem_cache_free(struct kmem_cache *
 
 	page = virt_to_head_page(x);
 
+	BUG_ON(!PageSlab(page));
+
 	slab_free(s, page, x, _RET_IP_);
 
 	trace_kmem_cache_free(_RET_IP_, x);
@@ -2588,7 +2598,7 @@ static int slub_min_objects;
  * Merge control. If this is set then no merging of slab caches will occur.
  * (Could be removed. This was introduced to pacify the merge skeptics.)
  */
-static int slub_nomerge;
+static int slub_nomerge = 1;
 
 /*
  * Calculate the order of allocation given an slab object size.
@@ -2892,6 +2902,9 @@ static int calculate_sizes(struct kmem_c
 	s->inuse = size;
 
 	if (((flags & (SLAB_DESTROY_BY_RCU | SLAB_POISON)) ||
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+		(!(flags & SLAB_NO_SANITIZE)) ||
+#endif
 		s->ctor)) {
 		/*
 		 * Relocate free pointer after the object if it is not
@@ -3038,7 +3051,7 @@ static int kmem_cache_open(struct kmem_c
 	else
 		s->cpu_partial = 30;
 
-	s->refcount = 1;
+	atomic_set(&s->refcount, 1);
 #ifdef CONFIG_NUMA
 	s->remote_node_defrag_ratio = 1000;
 #endif
@@ -3142,8 +3155,7 @@ static inline int kmem_cache_close(struc
 void kmem_cache_destroy(struct kmem_cache *s)
 {
 	down_write(&slub_lock);
-	s->refcount--;
-	if (!s->refcount) {
+	if (atomic_dec_and_test(&s->refcount)) {
 		list_del(&s->list);
 		up_write(&slub_lock);
 		if (kmem_cache_close(s)) {
@@ -3172,6 +3184,10 @@ static struct kmem_cache *kmem_cache;
 static struct kmem_cache *kmalloc_dma_caches[SLUB_PAGE_SHIFT];
 #endif
 
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+static struct kmem_cache *kmalloc_usercopy_caches[SLUB_PAGE_SHIFT];
+#endif
+
 static int __init setup_slub_min_order(char *str)
 {
 	get_option(&str, &slub_min_order);
@@ -3286,6 +3302,13 @@ static struct kmem_cache *get_slab(size_
 		return kmalloc_dma_caches[index];
 
 #endif
+
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+	if (flags & SLAB_USERCOPY)
+		return kmalloc_usercopy_caches[index];
+
+#endif
+
 	return kmalloc_caches[index];
 }
 
@@ -3354,6 +3377,59 @@ void *__kmalloc_node(size_t size, gfp_t
 EXPORT_SYMBOL(__kmalloc_node);
 #endif
 
+bool is_usercopy_object(const void *ptr)
+{
+	struct page *page;
+	struct kmem_cache *s;
+
+	if (ZERO_OR_NULL_PTR(ptr))
+		return false;
+
+	if (!slab_is_available())
+		return false;
+
+	if (!virt_addr_valid(ptr))
+		return false;
+
+	page = virt_to_head_page(ptr);
+
+	if (!PageSlab(page))
+		return false;
+
+	s = page->slab;
+	return s->flags & SLAB_USERCOPY;
+}
+
+#ifdef CONFIG_PAX_USERCOPY
+const char *check_heap_object(const void *ptr, unsigned long n)
+{
+	struct page *page;
+	struct kmem_cache *s;
+	unsigned long offset;
+
+	if (ZERO_OR_NULL_PTR(ptr))
+		return "<null>";
+
+	if (!virt_addr_valid(ptr))
+		return NULL;
+
+	page = virt_to_head_page(ptr);
+
+	if (!PageSlab(page))
+		return NULL;
+
+	s = page->slab;
+	if (!(s->flags & SLAB_USERCOPY))
+		return s->name;
+
+	offset = (ptr - page_address(page)) % s->size;
+	if (offset <= s->objsize && n <= s->objsize - offset)
+		return NULL;
+
+	return s->name;
+}
+#endif
+
 size_t ksize(const void *object)
 {
 	struct page *page;
@@ -3418,6 +3494,7 @@ void kfree(const void *x)
 	if (unlikely(ZERO_OR_NULL_PTR(x)))
 		return;
 
+	VM_BUG_ON(!virt_addr_valid(x));
 	page = virt_to_head_page(x);
 	if (unlikely(!PageSlab(page))) {
 		BUG_ON(!PageCompound(page));
@@ -3628,7 +3705,7 @@ static void __init kmem_cache_bootstrap_
 	int node;
 
 	list_add(&s->list, &slab_caches);
-	s->refcount = -1;
+	atomic_set(&s->refcount, -1);
 
 	for_each_node_state(node, N_NORMAL_MEMORY) {
 		struct kmem_cache_node *n = get_node(s, node);
@@ -3745,17 +3822,17 @@ void __init kmem_cache_init(void)
 
 	/* Caches that are not of the two-to-the-power-of size */
 	if (KMALLOC_MIN_SIZE <= 32) {
-		kmalloc_caches[1] = create_kmalloc_cache("kmalloc-96", 96, 0);
+		kmalloc_caches[1] = create_kmalloc_cache("kmalloc-96", 96, SLAB_USERCOPY);
 		caches++;
 	}
 
 	if (KMALLOC_MIN_SIZE <= 64) {
-		kmalloc_caches[2] = create_kmalloc_cache("kmalloc-192", 192, 0);
+		kmalloc_caches[2] = create_kmalloc_cache("kmalloc-192", 192, SLAB_USERCOPY);
 		caches++;
 	}
 
 	for (i = KMALLOC_SHIFT_LOW; i < SLUB_PAGE_SHIFT; i++) {
-		kmalloc_caches[i] = create_kmalloc_cache("kmalloc", 1 << i, 0);
+		kmalloc_caches[i] = create_kmalloc_cache("kmalloc", 1 << i, SLAB_USERCOPY);
 		caches++;
 	}
 
@@ -3797,6 +3874,22 @@ void __init kmem_cache_init(void)
 		}
 	}
 #endif
+
+#ifdef CONFIG_PAX_USERCOPY_SLABS
+	for (i = 0; i < SLUB_PAGE_SHIFT; i++) {
+		struct kmem_cache *s = kmalloc_caches[i];
+
+		if (s && s->size) {
+			char *name = kasprintf(GFP_NOWAIT,
+				 "usercopy-kmalloc-%d", s->objsize);
+
+			BUG_ON(!name);
+			kmalloc_usercopy_caches[i] = create_kmalloc_cache(name,
+				s->objsize, SLAB_USERCOPY);
+		}
+	}
+#endif
+
 	printk(KERN_INFO
 		"SLUB: Genslabs=%d, HWalign=%d, Order=%d-%d, MinObjects=%d,"
 		" CPUs=%d, Nodes=%d\n",
@@ -3823,7 +3916,7 @@ static int slab_unmergeable(struct kmem_
 	/*
 	 * We may have set a slab to be unmergeable during bootstrap.
 	 */
-	if (s->refcount < 0)
+	if (atomic_read(&s->refcount) < 0)
 		return 1;
 
 	return 0;
@@ -3880,9 +3973,17 @@ struct kmem_cache *kmem_cache_create(con
 		return NULL;
 
 	down_write(&slub_lock);
+
+#ifdef CONFIG_PAX_MEMORY_SANITIZE
+	if (pax_sanitize_slab == PAX_SANITIZE_SLAB_OFF || (flags & SLAB_DESTROY_BY_RCU))
+		flags |= SLAB_NO_SANITIZE;
+	else if (pax_sanitize_slab == PAX_SANITIZE_SLAB_FULL)
+		flags &= ~SLAB_NO_SANITIZE;
+#endif
+
 	s = find_mergeable(size, align, flags, name, ctor);
 	if (s) {
-		s->refcount++;
+		atomic_inc(&s->refcount);
 		/*
 		 * Adjust the object sizes so that we clear
 		 * the complete object on kzalloc.
@@ -3891,7 +3992,7 @@ struct kmem_cache *kmem_cache_create(con
 		s->inuse = max_t(int, s->inuse, ALIGN(size, sizeof(void *)));
 
 		if (sysfs_slab_alias(s, name)) {
-			s->refcount--;
+			atomic_dec(&s->refcount);
 			goto err;
 		}
 		up_write(&slub_lock);
@@ -3962,7 +4063,7 @@ static int __cpuinit slab_cpuup_callback
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata slab_notifier = {
+static struct notifier_block slab_notifier = {
 	.notifier_call = slab_cpuup_callback
 };
 
@@ -4659,7 +4760,7 @@ SLAB_ATTR_RO(ctor);
 
 static ssize_t aliases_show(struct kmem_cache *s, char *buf)
 {
-	return sprintf(buf, "%d\n", s->refcount - 1);
+	return sprintf(buf, "%d\n", atomic_read(&s->refcount) - 1);
 }
 SLAB_ATTR_RO(aliases);
 
@@ -5254,7 +5355,7 @@ static int sysfs_slab_add(struct kmem_ca
 	}
 
 	s->kobj.kset = slab_kset;
-	err = kobject_init_and_add(&s->kobj, &slab_ktype, NULL, name);
+	err = kobject_init_and_add(&s->kobj, &slab_ktype, NULL, "%s", name);
 	if (err) {
 		kobject_put(&s->kobj);
 		return err;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/sparse-vmemmap.c linux-3.2.71-pax/mm/sparse-vmemmap.c
--- linux-3.2.71/mm/sparse-vmemmap.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/mm/sparse-vmemmap.c	2012-07-04 19:24:48.948063009 +0200
@@ -128,7 +128,7 @@ pud_t * __meminit vmemmap_pud_populate(p
 		void *p = vmemmap_alloc_block(PAGE_SIZE, node);
 		if (!p)
 			return NULL;
-		pud_populate(&init_mm, pud, p);
+		pud_populate_kernel(&init_mm, pud, p);
 	}
 	return pud;
 }
@@ -140,7 +140,7 @@ pgd_t * __meminit vmemmap_pgd_populate(u
 		void *p = vmemmap_alloc_block(PAGE_SIZE, node);
 		if (!p)
 			return NULL;
-		pgd_populate(&init_mm, pgd, p);
+		pgd_populate_kernel(&init_mm, pgd, p);
 	}
 	return pgd;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/swap.c linux-3.2.71-pax/mm/swap.c
--- linux-3.2.71/mm/swap.c	2014-02-16 00:01:51.752847713 +0100
+++ linux-3.2.71-pax/mm/swap.c	2014-02-16 00:09:06.392824507 +0100
@@ -70,9 +70,11 @@ static void __put_compound_page(struct p
 {
 	compound_page_dtor *dtor;
 
-	if (!PageHuge(page))
-		__page_cache_release(page);
 	dtor = get_compound_page_dtor(page);
+	if (!PageHuge(page)) {
+		BUG_ON(dtor != free_compound_page);
+		__page_cache_release(page);
+	}
 	(*dtor)(page);
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/swapfile.c linux-3.2.71-pax/mm/swapfile.c
--- linux-3.2.71/mm/swapfile.c	2014-04-02 03:15:45.683672336 +0200
+++ linux-3.2.71-pax/mm/swapfile.c	2014-04-02 03:16:21.119670443 +0200
@@ -61,7 +61,7 @@ static DEFINE_MUTEX(swapon_mutex);
 
 static DECLARE_WAIT_QUEUE_HEAD(proc_poll_wait);
 /* Activity counter to indicate that a swapon or swapoff has occurred */
-static atomic_t proc_poll_event = ATOMIC_INIT(0);
+static atomic_unchecked_t proc_poll_event = ATOMIC_INIT(0);
 
 static inline unsigned char swap_count(unsigned char ent)
 {
@@ -1677,7 +1677,7 @@ SYSCALL_DEFINE1(swapoff, const char __us
 	spin_unlock(&swap_lock);
 
 	err = 0;
-	atomic_inc(&proc_poll_event);
+	atomic_inc_unchecked(&proc_poll_event);
 	wake_up_interruptible(&proc_poll_wait);
 
 out_dput:
@@ -1693,8 +1693,8 @@ static unsigned swaps_poll(struct file *
 
 	poll_wait(file, &proc_poll_wait, wait);
 
-	if (seq->poll_event != atomic_read(&proc_poll_event)) {
-		seq->poll_event = atomic_read(&proc_poll_event);
+	if (seq->poll_event != atomic_read_unchecked(&proc_poll_event)) {
+		seq->poll_event = atomic_read_unchecked(&proc_poll_event);
 		return POLLIN | POLLRDNORM | POLLERR | POLLPRI;
 	}
 
@@ -1792,7 +1792,7 @@ static int swaps_open(struct inode *inod
 		return ret;
 
 	seq = file->private_data;
-	seq->poll_event = atomic_read(&proc_poll_event);
+	seq->poll_event = atomic_read_unchecked(&proc_poll_event);
 	return 0;
 }
 
@@ -2126,7 +2126,7 @@ SYSCALL_DEFINE2(swapon, const char __use
 		(p->flags & SWP_DISCARDABLE) ? "D" : "");
 
 	mutex_unlock(&swapon_mutex);
-	atomic_inc(&proc_poll_event);
+	atomic_inc_unchecked(&proc_poll_event);
 	wake_up_interruptible(&proc_poll_wait);
 
 	if (S_ISREG(inode->i_mode))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/util.c linux-3.2.71-pax/mm/util.c
--- linux-3.2.71/mm/util.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/mm/util.c	2012-07-04 19:24:48.948063009 +0200
@@ -243,6 +243,12 @@ void __vma_link_list(struct mm_struct *m
 void arch_pick_mmap_layout(struct mm_struct *mm)
 {
 	mm->mmap_base = TASK_UNMAPPED_BASE;
+
+#ifdef CONFIG_PAX_RANDMMAP
+	if (mm->pax_flags & MF_PAX_RANDMMAP)
+		mm->mmap_base += mm->delta_mmap;
+#endif
+
 	mm->get_unmapped_area = arch_get_unmapped_area;
 	mm->unmap_area = arch_unmap_area;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/vmalloc.c linux-3.2.71-pax/mm/vmalloc.c
--- linux-3.2.71/mm/vmalloc.c	2014-08-06 23:17:22.109614201 +0200
+++ linux-3.2.71-pax/mm/vmalloc.c	2014-08-06 23:17:26.725614191 +0200
@@ -39,8 +39,19 @@ static void vunmap_pte_range(pmd_t *pmd,
 
 	pte = pte_offset_kernel(pmd, addr);
 	do {
-		pte_t ptent = ptep_get_and_clear(&init_mm, addr, pte);
-		WARN_ON(!pte_none(ptent) && !pte_present(ptent));
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+		if ((unsigned long)MODULES_EXEC_VADDR <= addr && addr < (unsigned long)MODULES_EXEC_END) {
+			BUG_ON(!pte_exec(*pte));
+			set_pte_at(&init_mm, addr, pte, pfn_pte(__pa(addr) >> PAGE_SHIFT, PAGE_KERNEL_EXEC));
+			continue;
+		}
+#endif
+
+		{
+			pte_t ptent = ptep_get_and_clear(&init_mm, addr, pte);
+			WARN_ON(!pte_none(ptent) && !pte_present(ptent));
+		}
 	} while (pte++, addr += PAGE_SIZE, addr != end);
 }
 
@@ -100,16 +111,29 @@ static int vmap_pte_range(pmd_t *pmd, un
 	pte = pte_alloc_kernel(pmd, addr);
 	if (!pte)
 		return -ENOMEM;
+
+	pax_open_kernel();
 	do {
 		struct page *page = pages[*nr];
 
-		if (WARN_ON(!pte_none(*pte)))
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+		if (pgprot_val(prot) & _PAGE_NX)
+#endif
+
+		if (!pte_none(*pte)) {
+			pax_close_kernel();
+			WARN_ON(1);
 			return -EBUSY;
-		if (WARN_ON(!page))
+		}
+		if (!page) {
+			pax_close_kernel();
+			WARN_ON(1);
 			return -ENOMEM;
+		}
 		set_pte_at(&init_mm, addr, pte, mk_pte(page, prot));
 		(*nr)++;
 	} while (pte++, addr += PAGE_SIZE, addr != end);
+	pax_close_kernel();
 	return 0;
 }
 
@@ -119,7 +143,7 @@ static int vmap_pmd_range(pud_t *pud, un
 	pmd_t *pmd;
 	unsigned long next;
 
-	pmd = pmd_alloc(&init_mm, pud, addr);
+	pmd = pmd_alloc_kernel(&init_mm, pud, addr);
 	if (!pmd)
 		return -ENOMEM;
 	do {
@@ -136,7 +160,7 @@ static int vmap_pud_range(pgd_t *pgd, un
 	pud_t *pud;
 	unsigned long next;
 
-	pud = pud_alloc(&init_mm, pgd, addr);
+	pud = pud_alloc_kernel(&init_mm, pgd, addr);
 	if (!pud)
 		return -ENOMEM;
 	do {
@@ -196,6 +220,12 @@ int is_vmalloc_or_module_addr(const void
 	if (addr >= MODULES_VADDR && addr < MODULES_END)
 		return 1;
 #endif
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+	if (x >= (const void *)MODULES_EXEC_VADDR && x < (const void *)MODULES_EXEC_END)
+		return 1;
+#endif
+
 	return is_vmalloc_addr(x);
 }
 
@@ -216,8 +246,14 @@ struct page *vmalloc_to_page(const void
 
 	if (!pgd_none(*pgd)) {
 		pud_t *pud = pud_offset(pgd, addr);
+#ifdef CONFIG_X86
+		if (!pud_large(*pud))
+#endif
 		if (!pud_none(*pud)) {
 			pmd_t *pmd = pmd_offset(pud, addr);
+#ifdef CONFIG_X86
+			if (!pmd_large(*pmd))
+#endif
 			if (!pmd_none(*pmd)) {
 				pte_t *ptep, pte;
 
@@ -1301,6 +1337,16 @@ static struct vm_struct *__get_vm_area_n
 	struct vm_struct *area;
 
 	BUG_ON(in_interrupt());
+
+#if defined(CONFIG_X86) && defined(CONFIG_PAX_KERNEXEC)
+	if (flags & VM_KERNEXEC) {
+		if (start != VMALLOC_START || end != VMALLOC_END)
+			return NULL;
+		start = (unsigned long)MODULES_EXEC_VADDR;
+		end = (unsigned long)MODULES_EXEC_END;
+	}
+#endif
+
 	if (flags & VM_IOREMAP) {
 		int bit = fls(size);
 
@@ -1533,6 +1579,11 @@ void *vmap(struct page **pages, unsigned
 	if (count > totalram_pages)
 		return NULL;
 
+#if defined(CONFIG_X86) && defined(CONFIG_PAX_KERNEXEC)
+	if (!(pgprot_val(prot) & _PAGE_NX))
+		flags |= VM_KERNEXEC;
+#endif
+
 	area = get_vm_area_caller((count << PAGE_SHIFT), flags,
 					__builtin_return_address(0));
 	if (!area)
@@ -1634,6 +1685,13 @@ void *__vmalloc_node_range(unsigned long
 	if (!size || (size >> PAGE_SHIFT) > totalram_pages)
 		goto fail;
 
+#if defined(CONFIG_X86) && defined(CONFIG_PAX_KERNEXEC)
+	if (!(pgprot_val(prot) & _PAGE_NX))
+		area = __get_vm_area_node(size, align, VM_ALLOC | VM_UNLIST | VM_KERNEXEC,
+					  VMALLOC_START, VMALLOC_END, node, gfp_mask, caller);
+	else
+#endif
+
 	area = __get_vm_area_node(size, align, VM_ALLOC | VM_UNLIST,
 				  start, end, node, gfp_mask, caller);
 	if (!area)
@@ -1807,10 +1865,9 @@ EXPORT_SYMBOL(vzalloc_node);
  *	For tight control over page level allocator and protection flags
  *	use __vmalloc() instead.
  */
-
 void *vmalloc_exec(unsigned long size)
 {
-	return __vmalloc_node(size, 1, GFP_KERNEL | __GFP_HIGHMEM, PAGE_KERNEL_EXEC,
+	return __vmalloc_node(size, 1, GFP_KERNEL | __GFP_HIGHMEM | __GFP_ZERO, PAGE_KERNEL_EXEC,
 			      -1, __builtin_return_address(0));
 }
 
@@ -2105,6 +2162,8 @@ int remap_vmalloc_range(struct vm_area_s
 	unsigned long uaddr = vma->vm_start;
 	unsigned long usize = vma->vm_end - vma->vm_start;
 
+	BUG_ON(vma->vm_mirror);
+
 	if ((PAGE_SIZE-1) & (unsigned long)addr)
 		return -EINVAL;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/mm/vmstat.c linux-3.2.71-pax/mm/vmstat.c
--- linux-3.2.71/mm/vmstat.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/mm/vmstat.c	2013-02-20 01:19:12.190027519 +0100
@@ -78,7 +78,7 @@ void vm_events_fold_cpu(int cpu)
  *
  * vm_stat contains the global counters
  */
-atomic_long_t vm_stat[NR_VM_ZONE_STAT_ITEMS] __cacheline_aligned_in_smp;
+atomic_long_unchecked_t vm_stat[NR_VM_ZONE_STAT_ITEMS] __cacheline_aligned_in_smp;
 EXPORT_SYMBOL(vm_stat);
 
 #ifdef CONFIG_SMP
@@ -454,7 +454,7 @@ void refresh_cpu_vm_stats(int cpu)
 				v = p->vm_stat_diff[i];
 				p->vm_stat_diff[i] = 0;
 				local_irq_restore(flags);
-				atomic_long_add(v, &zone->vm_stat[i]);
+				atomic_long_add_unchecked(v, &zone->vm_stat[i]);
 				global_diff[i] += v;
 #ifdef CONFIG_NUMA
 				/* 3 seconds idle till flush */
@@ -492,7 +492,7 @@ void refresh_cpu_vm_stats(int cpu)
 
 	for (i = 0; i < NR_VM_ZONE_STAT_ITEMS; i++)
 		if (global_diff[i])
-			atomic_long_add(global_diff[i], &vm_stat[i]);
+			atomic_long_add_unchecked(global_diff[i], &vm_stat[i]);
 }
 
 #endif
@@ -1193,7 +1193,7 @@ static int __cpuinit vmstat_cpuup_callba
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata vmstat_notifier =
+static struct notifier_block vmstat_notifier =
 	{ &vmstat_cpuup_callback, NULL, 0 };
 #endif
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/8021q/vlan.c linux-3.2.71-pax/net/8021q/vlan.c
--- linux-3.2.71/net/8021q/vlan.c	2013-04-10 12:38:44.598744751 +0200
+++ linux-3.2.71-pax/net/8021q/vlan.c	2013-04-10 12:38:51.906744360 +0200
@@ -513,7 +513,7 @@ out:
 	return NOTIFY_DONE;
 }
 
-static struct notifier_block vlan_notifier_block __read_mostly = {
+static struct notifier_block vlan_notifier_block = {
 	.notifier_call = vlan_device_event,
 };
 
@@ -588,8 +588,7 @@ static int vlan_ioctl_handler(struct net
 		err = -EPERM;
 		if (!capable(CAP_NET_ADMIN))
 			break;
-		if ((args.u.name_type >= 0) &&
-		    (args.u.name_type < VLAN_NAME_TYPE_HIGHEST)) {
+		if (args.u.name_type < VLAN_NAME_TYPE_HIGHEST) {
 			struct vlan_net *vn;
 
 			vn = net_generic(net, vlan_net_id);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/8021q/vlan_netlink.c linux-3.2.71-pax/net/8021q/vlan_netlink.c
--- linux-3.2.71/net/8021q/vlan_netlink.c	2013-11-29 01:58:28.818491623 +0100
+++ linux-3.2.71-pax/net/8021q/vlan_netlink.c	2015-01-05 18:26:58.859716856 +0100
@@ -214,7 +214,7 @@ nla_put_failure:
 	return -EMSGSIZE;
 }
 
-struct rtnl_link_ops vlan_link_ops __read_mostly = {
+struct rtnl_link_ops vlan_link_ops = {
 	.kind		= "vlan",
 	.maxtype	= IFLA_VLAN_MAX,
 	.policy		= vlan_policy,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/9p/client.c linux-3.2.71-pax/net/9p/client.c
--- linux-3.2.71/net/9p/client.c	2015-08-14 21:48:35.380707909 +0200
+++ linux-3.2.71-pax/net/9p/client.c	2015-08-14 21:48:45.684707359 +0200
@@ -582,7 +582,7 @@ static int p9_check_zc_errors(struct p9_
 				       len - inline_len);
 			} else {
 				err = copy_from_user(ename + inline_len,
-						     uidata, len - inline_len);
+						     (char __force_user *)uidata, len - inline_len);
 				if (err) {
 					err = -EFAULT;
 					goto out_free;
@@ -1529,7 +1529,7 @@ p9_client_read(struct p9_fid *fid, char
 			kernel_buf = 1;
 			indata = data;
 		} else
-			indata = (char *)udata;
+			indata = (__force_kernel char *)udata;
 		/*
 		 * response header len is 11
 		 * PDU Header(7) + IO Size (4)
@@ -1604,7 +1604,7 @@ p9_client_write(struct p9_fid *fid, char
 			kernel_buf = 1;
 			odata = data;
 		} else
-			odata = (char *)udata;
+			odata = (char __force_kernel *)udata;
 		req = p9_client_zc_rpc(clnt, P9_TWRITE, NULL, odata, 0, rsize,
 				       P9_ZC_HDR_SZ, kernel_buf, "dqd",
 				       fid->fid, offset, rsize);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/9p/mod.c linux-3.2.71-pax/net/9p/mod.c
--- linux-3.2.71/net/9p/mod.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/9p/mod.c	2013-03-28 01:35:23.512427937 +0100
@@ -57,7 +57,7 @@ static LIST_HEAD(v9fs_trans_list);
 void v9fs_register_trans(struct p9_trans_module *m)
 {
 	spin_lock(&v9fs_trans_lock);
-	list_add_tail(&m->list, &v9fs_trans_list);
+	pax_list_add_tail((struct list_head *)&m->list, &v9fs_trans_list);
 	spin_unlock(&v9fs_trans_lock);
 }
 EXPORT_SYMBOL(v9fs_register_trans);
@@ -70,7 +70,7 @@ EXPORT_SYMBOL(v9fs_register_trans);
 void v9fs_unregister_trans(struct p9_trans_module *m)
 {
 	spin_lock(&v9fs_trans_lock);
-	list_del_init(&m->list);
+	pax_list_del_init((struct list_head *)&m->list);
 	spin_unlock(&v9fs_trans_lock);
 }
 EXPORT_SYMBOL(v9fs_unregister_trans);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/9p/trans_fd.c linux-3.2.71-pax/net/9p/trans_fd.c
--- linux-3.2.71/net/9p/trans_fd.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/9p/trans_fd.c	2012-07-04 19:24:48.952063009 +0200
@@ -423,7 +423,7 @@ static int p9_fd_write(struct p9_client
 	oldfs = get_fs();
 	set_fs(get_ds());
 	/* The cast to a user pointer is valid due to the set_fs() */
-	ret = vfs_write(ts->wr, (__force void __user *)v, len, &ts->wr->f_pos);
+	ret = vfs_write(ts->wr, (void __force_user *)v, len, &ts->wr->f_pos);
 	set_fs(oldfs);
 
 	if (ret <= 0 && ret != -ERESTARTSYS && ret != -EAGAIN)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/atm/atm_misc.c linux-3.2.71-pax/net/atm/atm_misc.c
--- linux-3.2.71/net/atm/atm_misc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/atm/atm_misc.c	2012-07-04 19:24:48.952063009 +0200
@@ -17,7 +17,7 @@ int atm_charge(struct atm_vcc *vcc, int
 	if (atomic_read(&sk_atm(vcc)->sk_rmem_alloc) <= sk_atm(vcc)->sk_rcvbuf)
 		return 1;
 	atm_return(vcc, truesize);
-	atomic_inc(&vcc->stats->rx_drop);
+	atomic_inc_unchecked(&vcc->stats->rx_drop);
 	return 0;
 }
 EXPORT_SYMBOL(atm_charge);
@@ -39,7 +39,7 @@ struct sk_buff *atm_alloc_charge(struct
 		}
 	}
 	atm_return(vcc, guess);
-	atomic_inc(&vcc->stats->rx_drop);
+	atomic_inc_unchecked(&vcc->stats->rx_drop);
 	return NULL;
 }
 EXPORT_SYMBOL(atm_alloc_charge);
@@ -86,7 +86,7 @@ EXPORT_SYMBOL(atm_pcr_goal);
 
 void sonet_copy_stats(struct k_sonet_stats *from, struct sonet_stats *to)
 {
-#define __HANDLE_ITEM(i) to->i = atomic_read(&from->i)
+#define __HANDLE_ITEM(i) to->i = atomic_read_unchecked(&from->i)
 	__SONET_ITEMS
 #undef __HANDLE_ITEM
 }
@@ -94,7 +94,7 @@ EXPORT_SYMBOL(sonet_copy_stats);
 
 void sonet_subtract_stats(struct k_sonet_stats *from, struct sonet_stats *to)
 {
-#define __HANDLE_ITEM(i) atomic_sub(to->i, &from->i)
+#define __HANDLE_ITEM(i) atomic_sub_unchecked(to->i,&from->i)
 	__SONET_ITEMS
 #undef __HANDLE_ITEM
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/atm/lec.h linux-3.2.71-pax/net/atm/lec.h
--- linux-3.2.71/net/atm/lec.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/atm/lec.h	2012-07-04 19:24:48.956063008 +0200
@@ -48,7 +48,7 @@ struct lane2_ops {
 			      const u8 *tlvs, u32 sizeoftlvs);
 	void (*associate_indicator) (struct net_device *dev, const u8 *mac_addr,
 				     const u8 *tlvs, u32 sizeoftlvs);
-};
+} __no_const;
 
 /*
  * ATM LAN Emulation supports both LLC & Dix Ethernet EtherType
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/atm/proc.c linux-3.2.71-pax/net/atm/proc.c
--- linux-3.2.71/net/atm/proc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/atm/proc.c	2012-07-04 19:24:48.956063008 +0200
@@ -45,9 +45,9 @@ static void add_stats(struct seq_file *s
   const struct k_atm_aal_stats *stats)
 {
 	seq_printf(seq, "%s ( %d %d %d %d %d )", aal,
-		   atomic_read(&stats->tx), atomic_read(&stats->tx_err),
-		   atomic_read(&stats->rx), atomic_read(&stats->rx_err),
-		   atomic_read(&stats->rx_drop));
+		   atomic_read_unchecked(&stats->tx),atomic_read_unchecked(&stats->tx_err),
+		   atomic_read_unchecked(&stats->rx),atomic_read_unchecked(&stats->rx_err),
+		   atomic_read_unchecked(&stats->rx_drop));
 }
 
 static void atm_dev_info(struct seq_file *seq, const struct atm_dev *dev)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/atm/resources.c linux-3.2.71-pax/net/atm/resources.c
--- linux-3.2.71/net/atm/resources.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/atm/resources.c	2012-07-04 19:24:48.956063008 +0200
@@ -160,7 +160,7 @@ EXPORT_SYMBOL(atm_dev_deregister);
 static void copy_aal_stats(struct k_atm_aal_stats *from,
     struct atm_aal_stats *to)
 {
-#define __HANDLE_ITEM(i) to->i = atomic_read(&from->i)
+#define __HANDLE_ITEM(i) to->i = atomic_read_unchecked(&from->i)
 	__AAL_STAT_ITEMS
 #undef __HANDLE_ITEM
 }
@@ -168,7 +168,7 @@ static void copy_aal_stats(struct k_atm_
 static void subtract_aal_stats(struct k_atm_aal_stats *from,
     struct atm_aal_stats *to)
 {
-#define __HANDLE_ITEM(i) atomic_sub(to->i, &from->i)
+#define __HANDLE_ITEM(i) atomic_sub_unchecked(to->i, &from->i)
 	__AAL_STAT_ITEMS
 #undef __HANDLE_ITEM
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ax25/sysctl_net_ax25.c linux-3.2.71-pax/net/ax25/sysctl_net_ax25.c
--- linux-3.2.71/net/ax25/sysctl_net_ax25.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/ax25/sysctl_net_ax25.c	2013-03-28 13:59:14.766044974 +0100
@@ -31,7 +31,7 @@ static int min_ds_timeout[1],		max_ds_ti
 
 static struct ctl_table_header *ax25_table_header;
 
-static ctl_table *ax25_table;
+static ctl_table_no_const *ax25_table;
 static int ax25_table_size;
 
 static struct ctl_path ax25_path[] = {
@@ -174,7 +174,7 @@ void ax25_register_sysctl(void)
 	}
 
 	for (n = 0, ax25_dev = ax25_dev_list; ax25_dev != NULL; ax25_dev = ax25_dev->next) {
-		struct ctl_table *child = kmemdup(ax25_param_table,
+		ctl_table_no_const *child = kmemdup(ax25_param_table,
 						  sizeof(ax25_param_table),
 						  GFP_ATOMIC);
 		if (!child) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/batman-adv/bat_iv_ogm.c linux-3.2.71-pax/net/batman-adv/bat_iv_ogm.c
--- linux-3.2.71/net/batman-adv/bat_iv_ogm.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/batman-adv/bat_iv_ogm.c	2012-07-04 19:24:48.956063008 +0200
@@ -541,7 +541,7 @@ void bat_ogm_schedule(struct hard_iface
 
 	/* change sequence number to network order */
 	batman_ogm_packet->seqno =
-			htonl((uint32_t)atomic_read(&hard_iface->seqno));
+			htonl((uint32_t)atomic_read_unchecked(&hard_iface->seqno));
 
 	batman_ogm_packet->ttvn = atomic_read(&bat_priv->ttvn);
 	batman_ogm_packet->tt_crc = htons((uint16_t)
@@ -561,7 +561,7 @@ void bat_ogm_schedule(struct hard_iface
 	else
 		batman_ogm_packet->gw_flags = NO_FLAGS;
 
-	atomic_inc(&hard_iface->seqno);
+	atomic_inc_unchecked(&hard_iface->seqno);
 
 	slide_own_bcast_window(hard_iface);
 	bat_ogm_queue_add(bat_priv, hard_iface->packet_buff,
@@ -922,7 +922,7 @@ static void bat_ogm_process(const struct
 		return;
 
 	/* could be changed by schedule_own_packet() */
-	if_incoming_seqno = atomic_read(&if_incoming->seqno);
+	if_incoming_seqno = atomic_read_unchecked(&if_incoming->seqno);
 
 	has_directlink_flag = (batman_ogm_packet->flags & DIRECTLINK ? 1 : 0);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/batman-adv/hard-interface.c linux-3.2.71-pax/net/batman-adv/hard-interface.c
--- linux-3.2.71/net/batman-adv/hard-interface.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/batman-adv/hard-interface.c	2012-07-04 19:24:48.956063008 +0200
@@ -326,8 +326,8 @@ int hardif_enable_interface(struct hard_
 	hard_iface->batman_adv_ptype.dev = hard_iface->net_dev;
 	dev_add_pack(&hard_iface->batman_adv_ptype);
 
-	atomic_set(&hard_iface->seqno, 1);
-	atomic_set(&hard_iface->frag_seqno, 1);
+	atomic_set_unchecked(&hard_iface->seqno, 1);
+	atomic_set_unchecked(&hard_iface->frag_seqno, 1);
 	bat_info(hard_iface->soft_iface, "Adding interface: %s\n",
 		 hard_iface->net_dev->name);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/batman-adv/soft-interface.c linux-3.2.71-pax/net/batman-adv/soft-interface.c
--- linux-3.2.71/net/batman-adv/soft-interface.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/batman-adv/soft-interface.c	2012-07-04 19:24:48.960063008 +0200
@@ -634,7 +634,7 @@ static int interface_tx(struct sk_buff *
 
 		/* set broadcast sequence number */
 		bcast_packet->seqno =
-			htonl(atomic_inc_return(&bat_priv->bcast_seqno));
+			htonl(atomic_inc_return_unchecked(&bat_priv->bcast_seqno));
 
 		add_bcast_packet_to_list(bat_priv, skb, 1);
 
@@ -828,7 +828,7 @@ struct net_device *softif_create(const c
 	atomic_set(&bat_priv->batman_queue_left, BATMAN_QUEUE_LEN);
 
 	atomic_set(&bat_priv->mesh_state, MESH_INACTIVE);
-	atomic_set(&bat_priv->bcast_seqno, 1);
+	atomic_set_unchecked(&bat_priv->bcast_seqno, 1);
 	atomic_set(&bat_priv->ttvn, 0);
 	atomic_set(&bat_priv->tt_local_changes, 0);
 	atomic_set(&bat_priv->tt_ogm_append_cnt, 0);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/batman-adv/types.h linux-3.2.71-pax/net/batman-adv/types.h
--- linux-3.2.71/net/batman-adv/types.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/batman-adv/types.h	2012-07-04 19:24:48.960063008 +0200
@@ -38,8 +38,8 @@ struct hard_iface {
 	int16_t if_num;
 	char if_status;
 	struct net_device *net_dev;
-	atomic_t seqno;
-	atomic_t frag_seqno;
+	atomic_unchecked_t seqno;
+	atomic_unchecked_t frag_seqno;
 	unsigned char *packet_buff;
 	int packet_len;
 	struct kobject *hardif_obj;
@@ -154,7 +154,7 @@ struct bat_priv {
 	atomic_t orig_interval;		/* uint */
 	atomic_t hop_penalty;		/* uint */
 	atomic_t log_level;		/* uint */
-	atomic_t bcast_seqno;
+	atomic_unchecked_t bcast_seqno;
 	atomic_t bcast_queue_left;
 	atomic_t batman_queue_left;
 	atomic_t ttvn; /* translation table version number */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/batman-adv/unicast.c linux-3.2.71-pax/net/batman-adv/unicast.c
--- linux-3.2.71/net/batman-adv/unicast.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/batman-adv/unicast.c	2012-07-04 19:24:48.960063008 +0200
@@ -264,7 +264,7 @@ int frag_send_skb(struct sk_buff *skb, s
 	frag1->flags = UNI_FRAG_HEAD | large_tail;
 	frag2->flags = large_tail;
 
-	seqno = atomic_add_return(2, &hard_iface->frag_seqno);
+	seqno = atomic_add_return_unchecked(2, &hard_iface->frag_seqno);
 	frag1->seqno = htons(seqno - 1);
 	frag2->seqno = htons(seqno);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/bluetooth/hci_conn.c linux-3.2.71-pax/net/bluetooth/hci_conn.c
--- linux-3.2.71/net/bluetooth/hci_conn.c	2014-07-12 17:42:34.004954215 +0200
+++ linux-3.2.71-pax/net/bluetooth/hci_conn.c	2014-07-12 17:42:44.776954191 +0200
@@ -235,7 +235,7 @@ void hci_le_ltk_reply(struct hci_conn *c
 	memset(&cp, 0, sizeof(cp));
 
 	cp.handle = cpu_to_le16(conn->handle);
-	memcpy(cp.ltk, ltk, sizeof(ltk));
+	memcpy(cp.ltk, ltk, sizeof(cp.ltk));
 
 	hci_send_cmd(hdev, HCI_OP_LE_LTK_REPLY, sizeof(cp), &cp);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/bluetooth/hci_sock.c linux-3.2.71-pax/net/bluetooth/hci_sock.c
--- linux-3.2.71/net/bluetooth/hci_sock.c	2014-01-03 15:48:45.136070557 +0100
+++ linux-3.2.71-pax/net/bluetooth/hci_sock.c	2014-01-03 15:48:49.616070318 +0100
@@ -605,7 +605,7 @@ static int hci_sock_setsockopt(struct so
 			uf.event_mask[1] = *((u32 *) f->event_mask + 1);
 		}
 
-		len = min_t(unsigned int, len, sizeof(uf));
+		len = min((size_t)len, sizeof(uf));
 		if (copy_from_user(&uf, optval, len)) {
 			err = -EFAULT;
 			break;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/bluetooth/l2cap_core.c linux-3.2.71-pax/net/bluetooth/l2cap_core.c
--- linux-3.2.71/net/bluetooth/l2cap_core.c	2013-07-27 11:12:22.463992796 +0200
+++ linux-3.2.71-pax/net/bluetooth/l2cap_core.c	2013-07-27 11:12:26.619992574 +0200
@@ -2181,8 +2181,10 @@ static int l2cap_parse_conf_rsp(struct l
 			break;
 
 		case L2CAP_CONF_RFC:
-			if (olen == sizeof(rfc))
-				memcpy(&rfc, (void *)val, olen);
+			if (olen != sizeof(rfc))
+				break;
+
+			memcpy(&rfc, (void *)val, olen);
 
 			if (test_bit(CONF_STATE2_DEVICE, &chan->conf_state) &&
 							rfc.mode != chan->mode)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/bluetooth/l2cap_sock.c linux-3.2.71-pax/net/bluetooth/l2cap_sock.c
--- linux-3.2.71/net/bluetooth/l2cap_sock.c	2014-09-14 14:11:00.162118819 +0200
+++ linux-3.2.71-pax/net/bluetooth/l2cap_sock.c	2014-09-14 14:11:26.126138479 +0200
@@ -484,7 +484,8 @@ static int l2cap_sock_setsockopt_old(str
 	struct sock *sk = sock->sk;
 	struct l2cap_chan *chan = l2cap_pi(sk)->chan;
 	struct l2cap_options opts;
-	int len, err = 0;
+	int err = 0;
+	size_t len = optlen;
 	u32 opt;
 
 	BT_DBG("sk %p", sk);
@@ -506,7 +507,7 @@ static int l2cap_sock_setsockopt_old(str
 		opts.max_tx   = chan->max_tx;
 		opts.txwin_size = (__u16)chan->tx_win;
 
-		len = min_t(unsigned int, sizeof(opts), optlen);
+		len = min(sizeof(opts), len);
 		if (copy_from_user((char *) &opts, optval, len)) {
 			err = -EFAULT;
 			break;
@@ -572,7 +573,8 @@ static int l2cap_sock_setsockopt(struct
 	struct bt_security sec;
 	struct bt_power pwr;
 	struct l2cap_conn *conn;
-	int len, err = 0;
+	int err = 0;
+	size_t len = optlen;
 	u32 opt;
 
 	BT_DBG("sk %p", sk);
@@ -595,7 +597,7 @@ static int l2cap_sock_setsockopt(struct
 
 		sec.level = BT_SECURITY_LOW;
 
-		len = min_t(unsigned int, sizeof(sec), optlen);
+		len = min(sizeof(sec), len);
 		if (copy_from_user((char *) &sec, optval, len)) {
 			err = -EFAULT;
 			break;
@@ -671,7 +673,7 @@ static int l2cap_sock_setsockopt(struct
 
 		pwr.force_active = BT_POWER_FORCE_ACTIVE_ON;
 
-		len = min_t(unsigned int, sizeof(pwr), optlen);
+		len = min(sizeof(pwr), len);
 		if (copy_from_user((char *) &pwr, optval, len)) {
 			err = -EFAULT;
 			break;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/bluetooth/Makefile linux-3.2.71-pax/net/bluetooth/Makefile
--- linux-3.2.71/net/bluetooth/Makefile	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/bluetooth/Makefile	2012-10-10 12:05:03.200122562 +0200
@@ -8,6 +8,6 @@ obj-$(CONFIG_BT_BNEP)	+= bnep/
 obj-$(CONFIG_BT_CMTP)	+= cmtp/
 obj-$(CONFIG_BT_HIDP)	+= hidp/
 
-bluetooth-y := af_bluetooth.o hci_core.o hci_conn.o hci_event.o mgmt.o hci_sock.o hci_sysfs.o lib.o
-bluetooth-$(CONFIG_BT_L2CAP)	+= l2cap_core.o l2cap_sock.o smp.o
+bluetooth-y := af_bluetooth.o hci_core.o hci_conn.o hci_event.o mgmt.o hci_sock.o hci_sysfs.o lib.o smp.o
+bluetooth-$(CONFIG_BT_L2CAP)	+= l2cap_core.o l2cap_sock.o
 bluetooth-$(CONFIG_BT_SCO)	+= sco.o
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/bluetooth/rfcomm/sock.c linux-3.2.71-pax/net/bluetooth/rfcomm/sock.c
--- linux-3.2.71/net/bluetooth/rfcomm/sock.c	2014-09-14 14:11:00.166118823 +0200
+++ linux-3.2.71-pax/net/bluetooth/rfcomm/sock.c	2014-09-14 14:11:26.126138479 +0200
@@ -684,7 +684,7 @@ static int rfcomm_sock_setsockopt(struct
 	struct sock *sk = sock->sk;
 	struct bt_security sec;
 	int err = 0;
-	size_t len;
+	size_t len = optlen;
 	u32 opt;
 
 	BT_DBG("sk %p", sk);
@@ -706,7 +706,7 @@ static int rfcomm_sock_setsockopt(struct
 
 		sec.level = BT_SECURITY_LOW;
 
-		len = min_t(unsigned int, sizeof(sec), optlen);
+		len = min(sizeof(sec), len);
 		if (copy_from_user((char *) &sec, optval, len)) {
 			err = -EFAULT;
 			break;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/bridge/br_multicast.c linux-3.2.71-pax/net/bridge/br_multicast.c
--- linux-3.2.71/net/bridge/br_multicast.c	2015-08-14 21:48:35.380707909 +0200
+++ linux-3.2.71-pax/net/bridge/br_multicast.c	2015-08-14 21:48:45.684707359 +0200
@@ -1420,7 +1420,7 @@ static int br_multicast_ipv6_rcv(struct
 	nexthdr = ip6h->nexthdr;
 	offset = ipv6_skip_exthdr(skb, sizeof(*ip6h), &nexthdr);
 
-	if (offset < 0 || nexthdr != IPPROTO_ICMPV6)
+	if (nexthdr != IPPROTO_ICMPV6)
 		return 0;
 
 	/* Okay, we found ICMPv6 header */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/bridge/br_netlink.c linux-3.2.71-pax/net/bridge/br_netlink.c
--- linux-3.2.71/net/bridge/br_netlink.c	2014-06-10 10:59:38.802436242 +0200
+++ linux-3.2.71-pax/net/bridge/br_netlink.c	2015-01-05 18:27:43.235738883 +0100
@@ -225,7 +225,7 @@ static int br_dev_newlink(struct net *sr
 	return register_netdevice(dev);
 }
 
-struct rtnl_link_ops br_link_ops __read_mostly = {
+struct rtnl_link_ops br_link_ops = {
 	.kind		= "bridge",
 	.priv_size	= sizeof(struct net_bridge),
 	.setup		= br_dev_setup,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/bridge/netfilter/ebtables.c linux-3.2.71-pax/net/bridge/netfilter/ebtables.c
--- linux-3.2.71/net/bridge/netfilter/ebtables.c	2014-06-10 10:59:38.806436242 +0200
+++ linux-3.2.71-pax/net/bridge/netfilter/ebtables.c	2014-06-10 10:59:44.186435955 +0200
@@ -1512,7 +1512,7 @@ static int do_ebt_get_ctl(struct sock *s
 			tmp.valid_hooks = t->table->valid_hooks;
 		}
 		mutex_unlock(&ebt_mutex);
-		if (copy_to_user(user, &tmp, *len) != 0){
+		if (*len > sizeof(tmp) || copy_to_user(user, &tmp, *len) != 0){
 			BUGPRINT("c2u Didn't work\n");
 			ret = -EFAULT;
 			break;
@@ -2322,7 +2322,7 @@ static int compat_do_ebt_get_ctl(struct
 			goto out;
 		tmp.valid_hooks = t->valid_hooks;
 
-		if (copy_to_user(user, &tmp, *len) != 0) {
+		if (*len > sizeof(tmp) || copy_to_user(user, &tmp, *len) != 0) {
 			ret = -EFAULT;
 			break;
 		}
@@ -2333,7 +2333,7 @@ static int compat_do_ebt_get_ctl(struct
 		tmp.entries_size = t->table->entries_size;
 		tmp.valid_hooks = t->table->valid_hooks;
 
-		if (copy_to_user(user, &tmp, *len) != 0) {
+		if (*len > sizeof(tmp) || copy_to_user(user, &tmp, *len) != 0) {
 			ret = -EFAULT;
 			break;
 		}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/caif/caif_socket.c linux-3.2.71-pax/net/caif/caif_socket.c
--- linux-3.2.71/net/caif/caif_socket.c	2015-08-07 11:37:20.771789899 +0200
+++ linux-3.2.71-pax/net/caif/caif_socket.c	2015-08-07 11:37:43.031790554 +0200
@@ -48,19 +48,20 @@ static struct dentry *debugfsdir;
 #ifdef CONFIG_DEBUG_FS
 struct debug_fs_counter {
 	atomic_t caif_nr_socks;
-	atomic_t caif_sock_create;
-	atomic_t num_connect_req;
-	atomic_t num_connect_resp;
-	atomic_t num_connect_fail_resp;
-	atomic_t num_disconnect;
-	atomic_t num_remote_shutdown_ind;
-	atomic_t num_tx_flow_off_ind;
-	atomic_t num_tx_flow_on_ind;
-	atomic_t num_rx_flow_off;
-	atomic_t num_rx_flow_on;
+	atomic_unchecked_t caif_sock_create;
+	atomic_unchecked_t num_connect_req;
+	atomic_unchecked_t num_connect_resp;
+	atomic_unchecked_t num_connect_fail_resp;
+	atomic_unchecked_t num_disconnect;
+	atomic_unchecked_t num_remote_shutdown_ind;
+	atomic_unchecked_t num_tx_flow_off_ind;
+	atomic_unchecked_t num_tx_flow_on_ind;
+	atomic_unchecked_t num_rx_flow_off;
+	atomic_unchecked_t num_rx_flow_on;
 };
 static struct debug_fs_counter cnt;
 #define	dbfs_atomic_inc(v) atomic_inc_return(v)
+#define	dbfs_atomic_inc_unchecked(v) atomic_inc_return_unchecked(v)
 #define	dbfs_atomic_dec(v) atomic_dec_return(v)
 #else
 #define	dbfs_atomic_inc(v) 0
@@ -161,7 +162,7 @@ static int caif_queue_rcv_skb(struct soc
 					atomic_read(&cf_sk->sk.sk_rmem_alloc),
 					sk_rcvbuf_lowwater(cf_sk));
 		set_rx_flow_off(cf_sk);
-		dbfs_atomic_inc(&cnt.num_rx_flow_off);
+		dbfs_atomic_inc_unchecked(&cnt.num_rx_flow_off);
 		caif_flow_ctrl(sk, CAIF_MODEMCMD_FLOW_OFF_REQ);
 	}
 
@@ -172,7 +173,7 @@ static int caif_queue_rcv_skb(struct soc
 		set_rx_flow_off(cf_sk);
 		if (net_ratelimit())
 			pr_debug("sending flow OFF due to rmem_schedule\n");
-		dbfs_atomic_inc(&cnt.num_rx_flow_off);
+		dbfs_atomic_inc_unchecked(&cnt.num_rx_flow_off);
 		caif_flow_ctrl(sk, CAIF_MODEMCMD_FLOW_OFF_REQ);
 	}
 	skb->dev = NULL;
@@ -233,14 +234,14 @@ static void caif_ctrl_cb(struct cflayer
 	switch (flow) {
 	case CAIF_CTRLCMD_FLOW_ON_IND:
 		/* OK from modem to start sending again */
-		dbfs_atomic_inc(&cnt.num_tx_flow_on_ind);
+		dbfs_atomic_inc_unchecked(&cnt.num_tx_flow_on_ind);
 		set_tx_flow_on(cf_sk);
 		cf_sk->sk.sk_state_change(&cf_sk->sk);
 		break;
 
 	case CAIF_CTRLCMD_FLOW_OFF_IND:
 		/* Modem asks us to shut up */
-		dbfs_atomic_inc(&cnt.num_tx_flow_off_ind);
+		dbfs_atomic_inc_unchecked(&cnt.num_tx_flow_off_ind);
 		set_tx_flow_off(cf_sk);
 		cf_sk->sk.sk_state_change(&cf_sk->sk);
 		break;
@@ -249,7 +250,7 @@ static void caif_ctrl_cb(struct cflayer
 		/* We're now connected */
 		caif_client_register_refcnt(&cf_sk->layer,
 						cfsk_hold, cfsk_put);
-		dbfs_atomic_inc(&cnt.num_connect_resp);
+		dbfs_atomic_inc_unchecked(&cnt.num_connect_resp);
 		cf_sk->sk.sk_state = CAIF_CONNECTED;
 		set_tx_flow_on(cf_sk);
 		cf_sk->sk.sk_state_change(&cf_sk->sk);
@@ -263,7 +264,7 @@ static void caif_ctrl_cb(struct cflayer
 
 	case CAIF_CTRLCMD_INIT_FAIL_RSP:
 		/* Connect request failed */
-		dbfs_atomic_inc(&cnt.num_connect_fail_resp);
+		dbfs_atomic_inc_unchecked(&cnt.num_connect_fail_resp);
 		cf_sk->sk.sk_err = ECONNREFUSED;
 		cf_sk->sk.sk_state = CAIF_DISCONNECTED;
 		cf_sk->sk.sk_shutdown = SHUTDOWN_MASK;
@@ -277,7 +278,7 @@ static void caif_ctrl_cb(struct cflayer
 
 	case CAIF_CTRLCMD_REMOTE_SHUTDOWN_IND:
 		/* Modem has closed this connection, or device is down. */
-		dbfs_atomic_inc(&cnt.num_remote_shutdown_ind);
+		dbfs_atomic_inc_unchecked(&cnt.num_remote_shutdown_ind);
 		cf_sk->sk.sk_shutdown = SHUTDOWN_MASK;
 		cf_sk->sk.sk_err = ECONNRESET;
 		set_rx_flow_on(cf_sk);
@@ -297,7 +298,7 @@ static void caif_check_flow_release(stru
 		return;
 
 	if (atomic_read(&sk->sk_rmem_alloc) <= sk_rcvbuf_lowwater(cf_sk)) {
-			dbfs_atomic_inc(&cnt.num_rx_flow_on);
+			dbfs_atomic_inc_unchecked(&cnt.num_rx_flow_on);
 			set_rx_flow_on(cf_sk);
 			caif_flow_ctrl(sk, CAIF_MODEMCMD_FLOW_ON_REQ);
 	}
@@ -860,7 +861,7 @@ static int caif_connect(struct socket *s
 	/*ifindex = id of the interface.*/
 	cf_sk->conn_req.ifindex = cf_sk->sk.sk_bound_dev_if;
 
-	dbfs_atomic_inc(&cnt.num_connect_req);
+	dbfs_atomic_inc_unchecked(&cnt.num_connect_req);
 	cf_sk->layer.receive = caif_sktrecv_cb;
 
 	err = caif_connect_client(sock_net(sk), &cf_sk->conn_req,
@@ -949,7 +950,7 @@ static int caif_release(struct socket *s
 	spin_unlock_bh(&sk->sk_receive_queue.lock);
 	sock->sk = NULL;
 
-	dbfs_atomic_inc(&cnt.num_disconnect);
+	dbfs_atomic_inc_unchecked(&cnt.num_disconnect);
 
 	WARN_ON(IS_ERR(cf_sk->debugfs_socket_dir));
 	if (cf_sk->debugfs_socket_dir != NULL)
@@ -1128,7 +1129,7 @@ static int caif_create(struct net *net,
 	cf_sk->conn_req.protocol = protocol;
 	/* Increase the number of sockets created. */
 	dbfs_atomic_inc(&cnt.caif_nr_socks);
-	num = dbfs_atomic_inc(&cnt.caif_sock_create);
+	num = dbfs_atomic_inc_unchecked(&cnt.caif_sock_create);
 #ifdef CONFIG_DEBUG_FS
 	if (!IS_ERR(debugfsdir)) {
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/caif/cfctrl.c linux-3.2.71-pax/net/caif/cfctrl.c
--- linux-3.2.71/net/caif/cfctrl.c	2013-10-27 17:59:58.536642316 +0100
+++ linux-3.2.71-pax/net/caif/cfctrl.c	2013-10-27 18:00:09.584641726 +0100
@@ -9,6 +9,7 @@
 #include <linux/stddef.h>
 #include <linux/spinlock.h>
 #include <linux/slab.h>
+#include <linux/sched.h>
 #include <net/caif/caif_layer.h>
 #include <net/caif/cfpkt.h>
 #include <net/caif/cfctrl.h>
@@ -42,8 +43,8 @@ struct cflayer *cfctrl_create(void)
 	memset(&dev_info, 0, sizeof(dev_info));
 	dev_info.id = 0xff;
 	cfsrvl_init(&this->serv, 0, &dev_info, false);
-	atomic_set(&this->req_seq_no, 1);
-	atomic_set(&this->rsp_seq_no, 1);
+	atomic_set_unchecked(&this->req_seq_no, 1);
+	atomic_set_unchecked(&this->rsp_seq_no, 1);
 	this->serv.layer.receive = cfctrl_recv;
 	sprintf(this->serv.layer.name, "ctrl");
 	this->serv.layer.ctrlcmd = cfctrl_ctrlcmd;
@@ -129,8 +130,8 @@ static void cfctrl_insert_req(struct cfc
 			      struct cfctrl_request_info *req)
 {
 	spin_lock_bh(&ctrl->info_list_lock);
-	atomic_inc(&ctrl->req_seq_no);
-	req->sequence_no = atomic_read(&ctrl->req_seq_no);
+	atomic_inc_unchecked(&ctrl->req_seq_no);
+	req->sequence_no = atomic_read_unchecked(&ctrl->req_seq_no);
 	list_add_tail(&req->list, &ctrl->list);
 	spin_unlock_bh(&ctrl->info_list_lock);
 }
@@ -148,7 +149,7 @@ static struct cfctrl_request_info *cfctr
 			if (p != first)
 				pr_warn("Requests are not received in order\n");
 
-			atomic_set(&ctrl->rsp_seq_no,
+			atomic_set_unchecked(&ctrl->rsp_seq_no,
 					 p->sequence_no);
 			list_del(&p->list);
 			goto out;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/caif/chnl_net.c linux-3.2.71-pax/net/caif/chnl_net.c
--- linux-3.2.71/net/caif/chnl_net.c	2015-03-06 19:43:09.736464841 +0100
+++ linux-3.2.71-pax/net/caif/chnl_net.c	2015-03-06 19:43:13.340464648 +0100
@@ -507,7 +507,7 @@ static const struct nla_policy ipcaif_po
 };
 
 
-static struct rtnl_link_ops ipcaif_link_ops __read_mostly = {
+static struct rtnl_link_ops ipcaif_link_ops = {
 	.kind		= "caif",
 	.priv_size	= sizeof(struct chnl_net),
 	.setup		= ipcaif_net_setup,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/can/af_can.c linux-3.2.71-pax/net/can/af_can.c
--- linux-3.2.71/net/can/af_can.c	2015-05-10 09:22:39.255493149 +0200
+++ linux-3.2.71-pax/net/can/af_can.c	2015-05-10 09:23:09.583494796 +0200
@@ -821,7 +821,7 @@ static const struct net_proto_family can
 };
 
 /* notifier block for netdevice event */
-static struct notifier_block can_netdev_notifier __read_mostly = {
+static struct notifier_block can_netdev_notifier = {
 	.notifier_call = can_notifier,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/can/gw.c linux-3.2.71-pax/net/can/gw.c
--- linux-3.2.71/net/can/gw.c	2013-04-30 00:45:09.639714477 +0200
+++ linux-3.2.71-pax/net/can/gw.c	2013-04-30 00:45:13.191714287 +0200
@@ -67,7 +67,6 @@ MODULE_AUTHOR("Oliver Hartkopp <oliver.h
 MODULE_ALIAS("can-gw");
 
 HLIST_HEAD(cgw_list);
-static struct notifier_block notifier;
 
 static struct kmem_cache *cgw_cache __read_mostly;
 
@@ -911,6 +910,10 @@ static int cgw_remove_job(struct sk_buff
 	return err;
 }
 
+static struct notifier_block notifier = {
+	.notifier_call = cgw_notifier
+};
+
 static __init int cgw_module_init(void)
 {
 	printk(banner);
@@ -922,7 +925,6 @@ static __init int cgw_module_init(void)
 		return -ENOMEM;
 
 	/* set notifier */
-	notifier.notifier_call = cgw_notifier;
 	register_netdevice_notifier(&notifier);
 
 	if (__rtnl_register(PF_CAN, RTM_GETROUTE, NULL, cgw_dump_jobs, NULL)) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/compat.c linux-3.2.71-pax/net/compat.c
--- linux-3.2.71/net/compat.c	2015-05-10 09:22:39.283493151 +0200
+++ linux-3.2.71-pax/net/compat.c	2015-05-10 09:25:11.903501440 +0200
@@ -80,9 +80,9 @@ int get_compat_msghdr(struct msghdr *kms
 
 	if (kmsg->msg_namelen > sizeof(struct sockaddr_storage))
 		kmsg->msg_namelen = sizeof(struct sockaddr_storage);
-	kmsg->msg_name = compat_ptr(tmp1);
-	kmsg->msg_iov = compat_ptr(tmp2);
-	kmsg->msg_control = compat_ptr(tmp3);
+	kmsg->msg_name = (void __force_kernel *)compat_ptr(tmp1);
+	kmsg->msg_iov = (void __force_kernel *)compat_ptr(tmp2);
+	kmsg->msg_control = (void __force_kernel *)compat_ptr(tmp3);
 	return 0;
 }
 
@@ -94,7 +94,7 @@ int verify_compat_iovec(struct msghdr *k
 
 	if (kern_msg->msg_name && kern_msg->msg_namelen) {
 		if (mode == VERIFY_READ) {
-			int err = move_addr_to_kernel(kern_msg->msg_name,
+			int err = move_addr_to_kernel((void __force_user *)kern_msg->msg_name,
 						      kern_msg->msg_namelen,
 						      kern_address);
 			if (err < 0)
@@ -107,7 +107,7 @@ int verify_compat_iovec(struct msghdr *k
 	}
 
 	tot_len = iov_from_user_compat_to_kern(kern_iov,
-					  (struct compat_iovec __user *)kern_msg->msg_iov,
+					  (struct compat_iovec __force_user *)kern_msg->msg_iov,
 					  kern_msg->msg_iovlen);
 	if (tot_len >= 0)
 		kern_msg->msg_iov = kern_iov;
@@ -127,20 +127,20 @@ int verify_compat_iovec(struct msghdr *k
 
 #define CMSG_COMPAT_FIRSTHDR(msg)			\
 	(((msg)->msg_controllen) >= sizeof(struct compat_cmsghdr) ?	\
-	 (struct compat_cmsghdr __user *)((msg)->msg_control) :		\
+	 (struct compat_cmsghdr __force_user *)((msg)->msg_control) :		\
 	 (struct compat_cmsghdr __user *)NULL)
 
 #define CMSG_COMPAT_OK(ucmlen, ucmsg, mhdr) \
 	((ucmlen) >= sizeof(struct compat_cmsghdr) && \
 	 (ucmlen) <= (unsigned long) \
 	 ((mhdr)->msg_controllen - \
-	  ((char *)(ucmsg) - (char *)(mhdr)->msg_control)))
+	  ((char __force_kernel *)(ucmsg) - (char *)(mhdr)->msg_control)))
 
 static inline struct compat_cmsghdr __user *cmsg_compat_nxthdr(struct msghdr *msg,
 		struct compat_cmsghdr __user *cmsg, int cmsg_len)
 {
 	char __user *ptr = (char __user *)cmsg + CMSG_COMPAT_ALIGN(cmsg_len);
-	if ((unsigned long)(ptr + 1 - (char __user *)msg->msg_control) >
+	if ((unsigned long)(ptr + 1 - (char __force_user *)msg->msg_control) >
 			msg->msg_controllen)
 		return NULL;
 	return (struct compat_cmsghdr __user *)ptr;
@@ -232,7 +232,7 @@ int put_cmsg_compat(struct msghdr *kmsg,
 {
 	struct compat_timeval ctv;
 	struct compat_timespec cts[3];
-	struct compat_cmsghdr __user *cm = (struct compat_cmsghdr __user *) kmsg->msg_control;
+	struct compat_cmsghdr __user *cm = (struct compat_cmsghdr __force_user *) kmsg->msg_control;
 	struct compat_cmsghdr cmhdr;
 	int cmlen;
 
@@ -284,7 +284,7 @@ int put_cmsg_compat(struct msghdr *kmsg,
 
 void scm_detach_fds_compat(struct msghdr *kmsg, struct scm_cookie *scm)
 {
-	struct compat_cmsghdr __user *cm = (struct compat_cmsghdr __user *) kmsg->msg_control;
+	struct compat_cmsghdr __user *cm = (struct compat_cmsghdr __force_user *) kmsg->msg_control;
 	int fdmax = (kmsg->msg_controllen - sizeof(struct compat_cmsghdr)) / sizeof(int);
 	int fdnum = scm->fp->count;
 	struct file **fp = scm->fp->fp;
@@ -381,7 +381,7 @@ static int do_set_sock_timeout(struct so
 		return -EFAULT;
 	old_fs = get_fs();
 	set_fs(KERNEL_DS);
-	err = sock_setsockopt(sock, level, optname, (char *)&ktime, sizeof(ktime));
+	err = sock_setsockopt(sock, level, optname, (char __force_user *)&ktime, sizeof(ktime));
 	set_fs(old_fs);
 
 	return err;
@@ -442,7 +442,7 @@ static int do_get_sock_timeout(struct so
 	len = sizeof(ktime);
 	old_fs = get_fs();
 	set_fs(KERNEL_DS);
-	err = sock_getsockopt(sock, level, optname, (char *) &ktime, &len);
+	err = sock_getsockopt(sock, level, optname, (char __force_user *) &ktime, (int __force_user *)&len);
 	set_fs(old_fs);
 
 	if (!err) {
@@ -577,7 +577,7 @@ int compat_mc_setsockopt(struct sock *so
 	case MCAST_JOIN_GROUP:
 	case MCAST_LEAVE_GROUP:
 	{
-		struct compat_group_req __user *gr32 = (void *)optval;
+		struct compat_group_req __user *gr32 = (void __user *)optval;
 		struct group_req __user *kgr =
 			compat_alloc_user_space(sizeof(struct group_req));
 		u32 interface;
@@ -598,7 +598,7 @@ int compat_mc_setsockopt(struct sock *so
 	case MCAST_BLOCK_SOURCE:
 	case MCAST_UNBLOCK_SOURCE:
 	{
-		struct compat_group_source_req __user *gsr32 = (void *)optval;
+		struct compat_group_source_req __user *gsr32 = (void __user *)optval;
 		struct group_source_req __user *kgsr = compat_alloc_user_space(
 			sizeof(struct group_source_req));
 		u32 interface;
@@ -619,7 +619,7 @@ int compat_mc_setsockopt(struct sock *so
 	}
 	case MCAST_MSFILTER:
 	{
-		struct compat_group_filter __user *gf32 = (void *)optval;
+		struct compat_group_filter __user *gf32 = (void __user *)optval;
 		struct group_filter __user *kgf;
 		u32 interface, fmode, numsrc;
 
@@ -657,7 +657,7 @@ int compat_mc_getsockopt(struct sock *so
 	char __user *optval, int __user *optlen,
 	int (*getsockopt)(struct sock *, int, int, char __user *, int __user *))
 {
-	struct compat_group_filter __user *gf32 = (void *)optval;
+	struct compat_group_filter __user *gf32 = (void __user *)optval;
 	struct group_filter __user *kgf;
 	int __user	*koptlen;
 	u32 interface, fmode, numsrc;
@@ -801,7 +801,7 @@ asmlinkage long compat_sys_socketcall(in
 
 	if (call < SYS_SOCKET || call > SYS_SENDMMSG)
 		return -EINVAL;
-	if (copy_from_user(a, args, nas[call]))
+	if (nas[call] > sizeof a || copy_from_user(a, args, nas[call]))
 		return -EFAULT;
 	a0 = a[0];
 	a1 = a[1];
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/core/datagram.c linux-3.2.71-pax/net/core/datagram.c
--- linux-3.2.71/net/core/datagram.c	2015-08-14 21:48:35.408707907 +0200
+++ linux-3.2.71-pax/net/core/datagram.c	2015-08-14 21:48:45.684707359 +0200
@@ -286,7 +286,7 @@ int skb_kill_datagram(struct sock *sk, s
 	}
 
 	kfree_skb(skb);
-	atomic_inc(&sk->sk_drops);
+	atomic_inc_unchecked(&sk->sk_drops);
 	sk_mem_reclaim_partial(sk);
 
 	return err;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/core/dev_addr_lists.c linux-3.2.71-pax/net/core/dev_addr_lists.c
--- linux-3.2.71/net/core/dev_addr_lists.c	2013-05-14 13:33:40.696285669 +0200
+++ linux-3.2.71-pax/net/core/dev_addr_lists.c	2013-05-14 13:33:46.608285353 +0200
@@ -723,7 +723,7 @@ static void __net_exit dev_mc_net_exit(s
 	proc_net_remove(net, "dev_mcast");
 }
 
-static struct pernet_operations __net_initdata dev_mc_net_ops = {
+static struct pernet_operations __net_initconst dev_mc_net_ops = {
 	.init = dev_mc_net_init,
 	.exit = dev_mc_net_exit,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/core/dev.c linux-3.2.71-pax/net/core/dev.c
--- linux-3.2.71/net/core/dev.c	2015-08-14 21:48:35.412707907 +0200
+++ linux-3.2.71-pax/net/core/dev.c	2015-08-14 21:48:45.688707358 +0200
@@ -1597,7 +1597,7 @@ int dev_forward_skb(struct net_device *d
 {
 	if (skb_shinfo(skb)->tx_flags & SKBTX_DEV_ZEROCOPY) {
 		if (skb_copy_ubufs(skb, GFP_ATOMIC)) {
-			atomic_long_inc(&dev->rx_dropped);
+			atomic_long_inc_unchecked(&dev->rx_dropped);
 			kfree_skb(skb);
 			return NET_RX_DROP;
 		}
@@ -1607,7 +1607,7 @@ int dev_forward_skb(struct net_device *d
 	nf_reset(skb);
 
 	if (unlikely(!is_skb_forwardable(dev, skb))) {
-		atomic_long_inc(&dev->rx_dropped);
+		atomic_long_inc_unchecked(&dev->rx_dropped);
 		kfree_skb(skb);
 		return NET_RX_DROP;
 	}
@@ -2048,7 +2048,7 @@ static int illegal_highdma(struct net_de
 
 struct dev_gso_cb {
 	void (*destructor)(struct sk_buff *skb);
-};
+} __no_const;
 
 #define DEV_GSO_CB(skb) ((struct dev_gso_cb *)(skb)->cb)
 
@@ -2975,7 +2975,7 @@ drop:
 
 	local_irq_restore(flags);
 
-	atomic_long_inc(&skb->dev->rx_dropped);
+	atomic_long_inc_unchecked(&skb->dev->rx_dropped);
 	kfree_skb(skb);
 	return NET_RX_DROP;
 }
@@ -3049,7 +3049,7 @@ int netif_rx_ni(struct sk_buff *skb)
 }
 EXPORT_SYMBOL(netif_rx_ni);
 
-static void net_tx_action(struct softirq_action *h)
+static __latent_entropy void net_tx_action(void)
 {
 	struct softnet_data *sd = &__get_cpu_var(softnet_data);
 
@@ -3346,7 +3346,7 @@ ncls:
 	if (pt_prev) {
 		ret = pt_prev->func(skb, skb->dev, pt_prev, orig_dev);
 	} else {
-		atomic_long_inc(&skb->dev->rx_dropped);
+		atomic_long_inc_unchecked(&skb->dev->rx_dropped);
 		kfree_skb(skb);
 		/* Jamal, now you will not able to escape explaining
 		 * me how you were going to use this. :-)
@@ -3910,7 +3910,7 @@ void netif_napi_del(struct napi_struct *
 }
 EXPORT_SYMBOL(netif_napi_del);
 
-static void net_rx_action(struct softirq_action *h)
+static __latent_entropy void net_rx_action(void)
 {
 	struct softnet_data *sd = &__get_cpu_var(softnet_data);
 	unsigned long time_limit = jiffies + 2;
@@ -4443,7 +4443,7 @@ static void __net_exit dev_proc_net_exit
 	proc_net_remove(net, "dev");
 }
 
-static struct pernet_operations __net_initdata dev_proc_ops = {
+static struct pernet_operations __net_initconst dev_proc_ops = {
 	.init = dev_proc_net_init,
 	.exit = dev_proc_net_exit,
 };
@@ -5937,7 +5937,7 @@ struct rtnl_link_stats64 *dev_get_stats(
 	} else {
 		netdev_stats_to_stats64(storage, &dev->stats);
 	}
-	storage->rx_dropped += atomic_long_read(&dev->rx_dropped);
+	storage->rx_dropped += atomic_long_read_unchecked(&dev->rx_dropped);
 	return storage;
 }
 EXPORT_SYMBOL(dev_get_stats);
@@ -6526,7 +6526,7 @@ static void __net_exit netdev_exit(struc
 	kfree(net->dev_index_head);
 }
 
-static struct pernet_operations __net_initdata netdev_net_ops = {
+static struct pernet_operations __net_initconst netdev_net_ops = {
 	.init = netdev_init,
 	.exit = netdev_exit,
 };
@@ -6588,7 +6588,7 @@ static void __net_exit default_device_ex
 	rtnl_unlock();
 }
 
-static struct pernet_operations __net_initdata default_device_ops = {
+static struct pernet_operations __net_initconst default_device_ops = {
 	.exit = default_device_exit,
 	.exit_batch = default_device_exit_batch,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/core/flow.c linux-3.2.71-pax/net/core/flow.c
--- linux-3.2.71/net/core/flow.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/core/flow.c	2012-07-04 19:24:48.972063008 +0200
@@ -61,7 +61,7 @@ struct flow_cache {
 	struct timer_list		rnd_timer;
 };
 
-atomic_t flow_cache_genid = ATOMIC_INIT(0);
+atomic_unchecked_t flow_cache_genid = ATOMIC_INIT(0);
 EXPORT_SYMBOL(flow_cache_genid);
 static struct flow_cache flow_cache_global;
 static struct kmem_cache *flow_cachep __read_mostly;
@@ -86,7 +86,7 @@ static void flow_cache_new_hashrnd(unsig
 
 static int flow_entry_valid(struct flow_cache_entry *fle)
 {
-	if (atomic_read(&flow_cache_genid) != fle->genid)
+	if (atomic_read_unchecked(&flow_cache_genid) != fle->genid)
 		return 0;
 	if (fle->object && !fle->object->ops->check(fle->object))
 		return 0;
@@ -259,7 +259,7 @@ flow_cache_lookup(struct net *net, const
 			hlist_add_head(&fle->u.hlist, &fcp->hash_table[hash]);
 			fcp->hash_count++;
 		}
-	} else if (likely(fle->genid == atomic_read(&flow_cache_genid))) {
+	} else if (likely(fle->genid == atomic_read_unchecked(&flow_cache_genid))) {
 		flo = fle->object;
 		if (!flo)
 			goto ret_object;
@@ -280,7 +280,7 @@ nocache:
 	}
 	flo = resolver(net, key, family, dir, flo, ctx);
 	if (fle) {
-		fle->genid = atomic_read(&flow_cache_genid);
+		fle->genid = atomic_read_unchecked(&flow_cache_genid);
 		if (!IS_ERR(flo))
 			fle->object = flo;
 		else
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/core/iovec.c linux-3.2.71-pax/net/core/iovec.c
--- linux-3.2.71/net/core/iovec.c	2014-09-14 14:11:00.214118859 +0200
+++ linux-3.2.71-pax/net/core/iovec.c	2014-09-14 14:16:19.001980120 +0200
@@ -42,7 +42,7 @@ int verify_iovec(struct msghdr *m, struc
 	if (m->msg_name && m->msg_namelen) {
 		if (mode == VERIFY_READ) {
 			void __user *namep;
-			namep = (void __user __force *) m->msg_name;
+			namep = (void __force_user *) m->msg_name;
 			err = move_addr_to_kernel(namep, m->msg_namelen,
 						  address);
 			if (err < 0)
@@ -55,7 +55,7 @@ int verify_iovec(struct msghdr *m, struc
 	}
 
 	size = m->msg_iovlen * sizeof(struct iovec);
-	if (copy_from_user(iov, (void __user __force *) m->msg_iov, size))
+	if (copy_from_user(iov, (void __force_user *) m->msg_iov, size))
 		return -EFAULT;
 
 	m->msg_iov = iov;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/core/net_namespace.c linux-3.2.71-pax/net/core/net_namespace.c
--- linux-3.2.71/net/core/net_namespace.c	2012-10-10 11:02:19.619865899 +0200
+++ linux-3.2.71-pax/net/core/net_namespace.c	2013-03-28 01:35:23.516427937 +0100
@@ -422,7 +422,7 @@ static int __register_pernet_operations(
 	int error;
 	LIST_HEAD(net_exit_list);
 
-	list_add_tail(&ops->list, list);
+	pax_list_add_tail((struct list_head *)&ops->list, list);
 	if (ops->init || (ops->id && ops->size)) {
 		for_each_net(net) {
 			error = ops_init(ops, net);
@@ -435,7 +435,7 @@ static int __register_pernet_operations(
 
 out_undo:
 	/* If I have an error cleanup all namespaces I initialized */
-	list_del(&ops->list);
+	pax_list_del((struct list_head *)&ops->list);
 	ops_exit_list(ops, &net_exit_list);
 	ops_free_list(ops, &net_exit_list);
 	return error;
@@ -446,7 +446,7 @@ static void __unregister_pernet_operatio
 	struct net *net;
 	LIST_HEAD(net_exit_list);
 
-	list_del(&ops->list);
+	pax_list_del((struct list_head *)&ops->list);
 	for_each_net(net)
 		list_add_tail(&net->exit_list, &net_exit_list);
 	ops_exit_list(ops, &net_exit_list);
@@ -580,7 +580,7 @@ int register_pernet_device(struct pernet
 	mutex_lock(&net_mutex);
 	error = register_pernet_operations(&pernet_list, ops);
 	if (!error && (first_device == &pernet_list))
-		first_device = &ops->list;
+		first_device = (struct list_head *)&ops->list;
 	mutex_unlock(&net_mutex);
 	return error;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/core/net-sysfs.c linux-3.2.71-pax/net/core/net-sysfs.c
--- linux-3.2.71/net/core/net-sysfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/core/net-sysfs.c	2013-03-28 01:35:23.516427937 +0100
@@ -1334,7 +1334,7 @@ void netdev_class_remove_file(struct cla
 }
 EXPORT_SYMBOL(netdev_class_remove_file);
 
-int netdev_kobject_init(void)
+int __init netdev_kobject_init(void)
 {
 	kobj_ns_type_register(&net_ns_type_operations);
 	return class_register(&net_class);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/core/rtnetlink.c linux-3.2.71-pax/net/core/rtnetlink.c
--- linux-3.2.71/net/core/rtnetlink.c	2015-08-14 21:48:35.412707907 +0200
+++ linux-3.2.71-pax/net/core/rtnetlink.c	2015-08-14 21:48:45.688707358 +0200
@@ -57,7 +57,7 @@ struct rtnl_link {
 	rtnl_doit_func		doit;
 	rtnl_dumpit_func	dumpit;
 	rtnl_calcit_func 	calcit;
-};
+} __no_const;
 
 static DEFINE_MUTEX(rtnl_mutex);
 
@@ -284,10 +284,13 @@ static LIST_HEAD(link_ops);
  */
 int __rtnl_link_register(struct rtnl_link_ops *ops)
 {
-	if (!ops->dellink)
-		ops->dellink = unregister_netdevice_queue;
+	if (!ops->dellink) {
+		pax_open_kernel();
+		*(void **)&ops->dellink = unregister_netdevice_queue;
+		pax_close_kernel();
+	}
 
-	list_add_tail(&ops->list, &link_ops);
+	pax_list_add_tail((struct list_head *)&ops->list, &link_ops);
 	return 0;
 }
 EXPORT_SYMBOL_GPL(__rtnl_link_register);
@@ -334,7 +337,7 @@ void __rtnl_link_unregister(struct rtnl_
 	for_each_net(net) {
 		__rtnl_kill_links(net, ops);
 	}
-	list_del(&ops->list);
+	pax_list_del((struct list_head *)&ops->list);
 }
 EXPORT_SYMBOL_GPL(__rtnl_link_unregister);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/core/scm.c linux-3.2.71-pax/net/core/scm.c
--- linux-3.2.71/net/core/scm.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/core/scm.c	2012-07-04 19:24:48.972063008 +0200
@@ -220,7 +220,7 @@ EXPORT_SYMBOL(__scm_send);
 int put_cmsg(struct msghdr * msg, int level, int type, int len, void *data)
 {
 	struct cmsghdr __user *cm
-		= (__force struct cmsghdr __user *)msg->msg_control;
+		= (struct cmsghdr __force_user *)msg->msg_control;
 	struct cmsghdr cmhdr;
 	int cmlen = CMSG_LEN(len);
 	int err;
@@ -243,7 +243,7 @@ int put_cmsg(struct msghdr * msg, int le
 	err = -EFAULT;
 	if (copy_to_user(cm, &cmhdr, sizeof cmhdr))
 		goto out;
-	if (copy_to_user(CMSG_DATA(cm), data, cmlen - sizeof(struct cmsghdr)))
+	if (copy_to_user((void __force_user *)CMSG_DATA((void __force_kernel *)cm), data, cmlen - sizeof(struct cmsghdr)))
 		goto out;
 	cmlen = CMSG_SPACE(len);
 	if (msg->msg_controllen < cmlen)
@@ -259,7 +259,7 @@ EXPORT_SYMBOL(put_cmsg);
 void scm_detach_fds(struct msghdr *msg, struct scm_cookie *scm)
 {
 	struct cmsghdr __user *cm
-		= (__force struct cmsghdr __user*)msg->msg_control;
+		= (struct cmsghdr __force_user *)msg->msg_control;
 
 	int fdmax = 0;
 	int fdnum = scm->fp->count;
@@ -279,7 +279,7 @@ void scm_detach_fds(struct msghdr *msg,
 	if (fdnum < fdmax)
 		fdmax = fdnum;
 
-	for (i=0, cmfptr=(__force int __user *)CMSG_DATA(cm); i<fdmax;
+	for (i=0, cmfptr=(int __force_user *)CMSG_DATA((void __force_kernel *)cm); i<fdmax;
 	     i++, cmfptr++)
 	{
 		int new_fd;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/core/skbuff.c linux-3.2.71-pax/net/core/skbuff.c
--- linux-3.2.71/net/core/skbuff.c	2014-07-12 17:42:34.004954215 +0200
+++ linux-3.2.71-pax/net/core/skbuff.c	2014-07-12 17:42:44.776954191 +0200
@@ -2876,13 +2876,15 @@ void __init skb_init(void)
 	skbuff_head_cache = kmem_cache_create("skbuff_head_cache",
 					      sizeof(struct sk_buff),
 					      0,
-					      SLAB_HWCACHE_ALIGN|SLAB_PANIC,
+					      SLAB_HWCACHE_ALIGN|SLAB_PANIC|
+					      SLAB_NO_SANITIZE,
 					      NULL);
 	skbuff_fclone_cache = kmem_cache_create("skbuff_fclone_cache",
 						(2*sizeof(struct sk_buff)) +
 						sizeof(atomic_t),
 						0,
-						SLAB_HWCACHE_ALIGN|SLAB_PANIC,
+						SLAB_HWCACHE_ALIGN|SLAB_PANIC|
+						SLAB_NO_SANITIZE,
 						NULL);
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/core/sock.c linux-3.2.71-pax/net/core/sock.c
--- linux-3.2.71/net/core/sock.c	2015-02-20 12:37:33.237178767 +0100
+++ linux-3.2.71-pax/net/core/sock.c	2015-02-20 12:37:41.917178304 +0100
@@ -289,7 +289,7 @@ int sock_queue_rcv_skb(struct sock *sk,
 	struct sk_buff_head *list = &sk->sk_receive_queue;
 
 	if (atomic_read(&sk->sk_rmem_alloc) >= sk->sk_rcvbuf) {
-		atomic_inc(&sk->sk_drops);
+		atomic_inc_unchecked(&sk->sk_drops);
 		trace_sock_rcvqueue_full(sk, skb);
 		return -ENOMEM;
 	}
@@ -299,7 +299,7 @@ int sock_queue_rcv_skb(struct sock *sk,
 		return err;
 
 	if (!sk_rmem_schedule(sk, skb->truesize)) {
-		atomic_inc(&sk->sk_drops);
+		atomic_inc_unchecked(&sk->sk_drops);
 		return -ENOBUFS;
 	}
 
@@ -319,7 +319,7 @@ int sock_queue_rcv_skb(struct sock *sk,
 	skb_dst_force(skb);
 
 	spin_lock_irqsave(&list->lock, flags);
-	skb->dropcount = atomic_read(&sk->sk_drops);
+	skb->dropcount = atomic_read_unchecked(&sk->sk_drops);
 	__skb_queue_tail(list, skb);
 	spin_unlock_irqrestore(&list->lock, flags);
 
@@ -339,7 +339,7 @@ int sk_receive_skb(struct sock *sk, stru
 	skb->dev = NULL;
 
 	if (sk_rcvqueues_full(sk, skb)) {
-		atomic_inc(&sk->sk_drops);
+		atomic_inc_unchecked(&sk->sk_drops);
 		goto discard_and_relse;
 	}
 	if (nested)
@@ -357,7 +357,7 @@ int sk_receive_skb(struct sock *sk, stru
 		mutex_release(&sk->sk_lock.dep_map, 1, _RET_IP_);
 	} else if (sk_add_backlog(sk, skb)) {
 		bh_unlock_sock(sk);
-		atomic_inc(&sk->sk_drops);
+		atomic_inc_unchecked(&sk->sk_drops);
 		goto discard_and_relse;
 	}
 
@@ -406,7 +406,7 @@ struct dst_entry *sk_dst_check(struct so
 }
 EXPORT_SYMBOL(sk_dst_check);
 
-static int sock_bindtodevice(struct sock *sk, char __user *optval, int optlen)
+static int sock_bindtodevice(struct sock *sk, char __user *optval, unsigned int optlen)
 {
 	int ret = -ENOPROTOOPT;
 #ifdef CONFIG_NETDEVICES
@@ -420,7 +420,7 @@ static int sock_bindtodevice(struct sock
 		goto out;
 
 	ret = -EINVAL;
-	if (optlen < 0)
+	if (optlen > INT_MAX)
 		goto out;
 
 	/* Bind this socket to a particular device like "eth0",
@@ -786,12 +786,12 @@ int sock_getsockopt(struct socket *sock,
 		struct timeval tm;
 	} v;
 
-	int lv = sizeof(int);
-	int len;
+	unsigned int lv = sizeof(int);
+	unsigned int len;
 
 	if (get_user(len, optlen))
 		return -EFAULT;
-	if (len < 0)
+	if (len > INT_MAX)
 		return -EINVAL;
 
 	memset(&v, 0, sizeof(v));
@@ -939,11 +939,11 @@ int sock_getsockopt(struct socket *sock,
 
 	case SO_PEERNAME:
 	{
-		char address[128];
+		char address[_K_SS_MAXSIZE];
 
 		if (sock->ops->getname(sock, (struct sockaddr *)address, &lv, 2))
 			return -ENOTCONN;
-		if (lv < len)
+		if (lv < len || sizeof address < len)
 			return -EINVAL;
 		if (copy_to_user(optval, address, len))
 			return -EFAULT;
@@ -978,7 +978,7 @@ int sock_getsockopt(struct socket *sock,
 
 	if (len > lv)
 		len = lv;
-	if (copy_to_user(optval, &v, len))
+	if (len > sizeof(v) || copy_to_user(optval, &v, len))
 		return -EFAULT;
 lenout:
 	if (put_user(len, optlen))
@@ -2026,7 +2026,7 @@ void sock_init_data(struct socket *sock,
 	 */
 	smp_wmb();
 	atomic_set(&sk->sk_refcnt, 1);
-	atomic_set(&sk->sk_drops, 0);
+	atomic_set_unchecked(&sk->sk_drops, 0);
 }
 EXPORT_SYMBOL(sock_init_data);
 
@@ -2563,7 +2563,7 @@ static __net_exit void proto_exit_net(st
 }
 
 
-static __net_initdata struct pernet_operations proto_net_ops = {
+static __net_initconst struct pernet_operations proto_net_ops = {
 	.init = proto_init_net,
 	.exit = proto_exit_net,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/core/sysctl_net_core.c linux-3.2.71-pax/net/core/sysctl_net_core.c
--- linux-3.2.71/net/core/sysctl_net_core.c	2015-05-10 09:22:39.339493154 +0200
+++ linux-3.2.71-pax/net/core/sysctl_net_core.c	2015-05-10 09:23:09.587494796 +0200
@@ -30,7 +30,7 @@ static int rps_sock_flow_sysctl(ctl_tabl
 {
 	unsigned int orig_size, size;
 	int ret, i;
-	ctl_table tmp = {
+	ctl_table_no_const tmp = {
 		.data = &size,
 		.maxlen = sizeof(size),
 		.mode = table->mode
@@ -216,29 +216,27 @@ __net_initdata struct ctl_path net_core_
 
 static __net_init int sysctl_core_net_init(struct net *net)
 {
-	struct ctl_table *tbl;
+	ctl_table_no_const *tbl = NULL;
 
 	net->core.sysctl_somaxconn = SOMAXCONN;
 
-	tbl = netns_core_table;
 	if (!net_eq(net, &init_net)) {
-		tbl = kmemdup(tbl, sizeof(netns_core_table), GFP_KERNEL);
+		tbl = kmemdup(netns_core_table, sizeof(netns_core_table), GFP_KERNEL);
 		if (tbl == NULL)
 			goto err_dup;
 
 		tbl[0].data = &net->core.sysctl_somaxconn;
-	}
+		net->core.sysctl_hdr = register_net_sysctl_table(net, net_core_path, tbl);
+	} else
+		net->core.sysctl_hdr = register_net_sysctl_table(net, net_core_path, netns_core_table);
 
-	net->core.sysctl_hdr = register_net_sysctl_table(net,
-			net_core_path, tbl);
 	if (net->core.sysctl_hdr == NULL)
 		goto err_reg;
 
 	return 0;
 
 err_reg:
-	if (tbl != netns_core_table)
-		kfree(tbl);
+	kfree(tbl);
 err_dup:
 	return -ENOMEM;
 }
@@ -253,7 +251,7 @@ static __net_exit void sysctl_core_net_e
 	kfree(tbl);
 }
 
-static __net_initdata struct pernet_operations sysctl_core_ops = {
+static __net_initconst struct pernet_operations sysctl_core_ops = {
 	.init = sysctl_core_net_init,
 	.exit = sysctl_core_net_exit,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/decnet/af_decnet.c linux-3.2.71-pax/net/decnet/af_decnet.c
--- linux-3.2.71/net/decnet/af_decnet.c	2013-03-29 02:18:38.747676281 +0100
+++ linux-3.2.71-pax/net/decnet/af_decnet.c	2013-03-29 02:20:31.367670268 +0100
@@ -469,6 +469,7 @@ static struct proto dn_proto = {
 	.sysctl_rmem		= sysctl_decnet_rmem,
 	.max_header		= DN_MAX_NSP_DATA_HEADER + 64,
 	.obj_size		= sizeof(struct dn_sock),
+	.slab_flags		= SLAB_USERCOPY,
 };
 
 static struct sock *dn_alloc_sock(struct net *net, struct socket *sock, gfp_t gfp)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/decnet/sysctl_net_decnet.c linux-3.2.71-pax/net/decnet/sysctl_net_decnet.c
--- linux-3.2.71/net/decnet/sysctl_net_decnet.c	2013-03-29 02:18:38.747676281 +0100
+++ linux-3.2.71-pax/net/decnet/sysctl_net_decnet.c	2013-03-29 02:20:31.367670268 +0100
@@ -175,7 +175,7 @@ static int dn_node_address_handler(ctl_t
 
 	if (len > *lenp) len = *lenp;
 
-	if (copy_to_user(buffer, addr, len))
+	if (len > sizeof addr || copy_to_user(buffer, addr, len))
 		return -EFAULT;
 
 	*lenp = len;
@@ -238,7 +238,7 @@ static int dn_def_dev_handler(ctl_table
 
 	if (len > *lenp) len = *lenp;
 
-	if (copy_to_user(buffer, devname, len))
+	if (len > sizeof devname || copy_to_user(buffer, devname, len))
 		return -EFAULT;
 
 	*lenp = len;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ieee802154/6lowpan.c linux-3.2.71-pax/net/ieee802154/6lowpan.c
--- linux-3.2.71/net/ieee802154/6lowpan.c	2014-01-03 15:48:45.156070556 +0100
+++ linux-3.2.71-pax/net/ieee802154/6lowpan.c	2015-01-05 18:28:35.199764725 +0100
@@ -329,7 +329,7 @@ static int lowpan_header_create(struct s
 			hc06_ptr += 3;
 		} else {
 			/* compress nothing */
-			memcpy(hc06_ptr, &hdr, 4);
+			memcpy(hc06_ptr, hdr, 4);
 			/* replace the top byte with new ECN | DSCP format */
 			*hc06_ptr = tmp;
 			hc06_ptr += 4;
@@ -837,7 +837,7 @@ static void lowpan_dellink(struct net_de
 	dev_put(real_dev);
 }
 
-static struct rtnl_link_ops lowpan_link_ops __read_mostly = {
+static struct rtnl_link_ops lowpan_link_ops = {
 	.kind		= "lowpan",
 	.priv_size	= sizeof(struct lowpan_dev_info),
 	.setup		= lowpan_setup,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/af_inet.c linux-3.2.71-pax/net/ipv4/af_inet.c
--- linux-3.2.71/net/ipv4/af_inet.c	2013-03-29 02:18:30.207676737 +0100
+++ linux-3.2.71-pax/net/ipv4/af_inet.c	2013-03-29 04:00:53.151348751 +0100
@@ -1612,7 +1612,7 @@ static __net_exit void ipv4_mib_exit_net
 	snmp_mib_free((void __percpu **)net->mib.tcp_statistics);
 }
 
-static __net_initdata struct pernet_operations ipv4_mib_ops = {
+static __net_initconst struct pernet_operations ipv4_mib_ops = {
 	.init = ipv4_mib_init_net,
 	.exit = ipv4_mib_exit_net,
 };
@@ -1646,13 +1646,9 @@ static int __init inet_init(void)
 
 	BUILD_BUG_ON(sizeof(struct inet_skb_parm) > sizeof(dummy_skb->cb));
 
-	sysctl_local_reserved_ports = kzalloc(65536 / 8, GFP_KERNEL);
-	if (!sysctl_local_reserved_ports)
-		goto out;
-
 	rc = proto_register(&tcp_prot, 1);
 	if (rc)
-		goto out_free_reserved_ports;
+		goto out;
 
 	rc = proto_register(&udp_prot, 1);
 	if (rc)
@@ -1759,8 +1755,6 @@ out_unregister_udp_proto:
 	proto_unregister(&udp_prot);
 out_unregister_tcp_proto:
 	proto_unregister(&tcp_prot);
-out_free_reserved_ports:
-	kfree(sysctl_local_reserved_ports);
 	goto out;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/devinet.c linux-3.2.71-pax/net/ipv4/devinet.c
--- linux-3.2.71/net/ipv4/devinet.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/ipv4/devinet.c	2013-03-29 03:54:49.235368182 +0100
@@ -1584,7 +1584,7 @@ static int ipv4_doint_and_flush(ctl_tabl
 #define DEVINET_SYSCTL_FLUSHING_ENTRY(attr, name) \
 	DEVINET_SYSCTL_COMPLEX_ENTRY(attr, name, ipv4_doint_and_flush)
 
-static struct devinet_sysctl_table {
+static const struct devinet_sysctl_table {
 	struct ctl_table_header *sysctl_header;
 	struct ctl_table devinet_vars[__IPV4_DEVCONF_MAX];
 	char *dev_name;
@@ -1729,7 +1729,7 @@ static __net_init int devinet_init_net(s
 	int err;
 	struct ipv4_devconf *all, *dflt;
 #ifdef CONFIG_SYSCTL
-	struct ctl_table *tbl = ctl_forward_entry;
+	ctl_table_no_const *tbl = NULL;
 	struct ctl_table_header *forw_hdr;
 #endif
 
@@ -1747,7 +1747,7 @@ static __net_init int devinet_init_net(s
 			goto err_alloc_dflt;
 
 #ifdef CONFIG_SYSCTL
-		tbl = kmemdup(tbl, sizeof(ctl_forward_entry), GFP_KERNEL);
+		tbl = kmemdup(ctl_forward_entry, sizeof(ctl_forward_entry), GFP_KERNEL);
 		if (tbl == NULL)
 			goto err_alloc_ctl;
 
@@ -1767,7 +1767,10 @@ static __net_init int devinet_init_net(s
 		goto err_reg_dflt;
 
 	err = -ENOMEM;
-	forw_hdr = register_net_sysctl_table(net, net_ipv4_path, tbl);
+	if (!net_eq(net, &init_net))
+		forw_hdr = register_net_sysctl_table(net, net_ipv4_path, tbl);
+	else
+		forw_hdr = register_net_sysctl_table(net, net_ipv4_path, ctl_forward_entry);
 	if (forw_hdr == NULL)
 		goto err_reg_ctl;
 	net->ipv4.forw_hdr = forw_hdr;
@@ -1783,8 +1786,7 @@ err_reg_ctl:
 err_reg_dflt:
 	__devinet_sysctl_unregister(all);
 err_reg_all:
-	if (tbl != ctl_forward_entry)
-		kfree(tbl);
+	kfree(tbl);
 err_alloc_ctl:
 #endif
 	if (dflt != &ipv4_devconf_dflt)
@@ -1811,7 +1813,7 @@ static __net_exit void devinet_exit_net(
 	kfree(net->ipv4.devconf_all);
 }
 
-static __net_initdata struct pernet_operations devinet_ops = {
+static __net_initconst struct pernet_operations devinet_ops = {
 	.init = devinet_init_net,
 	.exit = devinet_exit_net,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/fib_frontend.c linux-3.2.71-pax/net/ipv4/fib_frontend.c
--- linux-3.2.71/net/ipv4/fib_frontend.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/ipv4/fib_frontend.c	2012-07-04 19:24:48.976063008 +0200
@@ -970,12 +970,12 @@ static int fib_inetaddr_event(struct not
 #ifdef CONFIG_IP_ROUTE_MULTIPATH
 		fib_sync_up(dev);
 #endif
-		atomic_inc(&net->ipv4.dev_addr_genid);
+		atomic_inc_unchecked(&net->ipv4.dev_addr_genid);
 		rt_cache_flush(dev_net(dev), -1);
 		break;
 	case NETDEV_DOWN:
 		fib_del_ifaddr(ifa, NULL);
-		atomic_inc(&net->ipv4.dev_addr_genid);
+		atomic_inc_unchecked(&net->ipv4.dev_addr_genid);
 		if (ifa->ifa_dev->ifa_list == NULL) {
 			/* Last address was deleted from this interface.
 			 * Disable IP.
@@ -1011,7 +1011,7 @@ static int fib_netdev_event(struct notif
 #ifdef CONFIG_IP_ROUTE_MULTIPATH
 		fib_sync_up(dev);
 #endif
-		atomic_inc(&net->ipv4.dev_addr_genid);
+		atomic_inc_unchecked(&net->ipv4.dev_addr_genid);
 		rt_cache_flush(dev_net(dev), -1);
 		break;
 	case NETDEV_DOWN:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/fib_semantics.c linux-3.2.71-pax/net/ipv4/fib_semantics.c
--- linux-3.2.71/net/ipv4/fib_semantics.c	2015-01-01 15:15:24.984069638 +0100
+++ linux-3.2.71-pax/net/ipv4/fib_semantics.c	2015-01-01 15:15:30.268069777 +0100
@@ -699,7 +699,7 @@ __be32 fib_info_update_nh_saddr(struct n
 	nh->nh_saddr = inet_select_addr(nh->nh_dev,
 					nh->nh_gw,
 					nh->nh_parent->fib_scope);
-	nh->nh_saddr_genid = atomic_read(&net->ipv4.dev_addr_genid);
+	nh->nh_saddr_genid = atomic_read_unchecked(&net->ipv4.dev_addr_genid);
 
 	return nh->nh_saddr;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/icmp.c linux-3.2.71-pax/net/ipv4/icmp.c
--- linux-3.2.71/net/ipv4/icmp.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/ipv4/icmp.c	2013-03-29 04:01:00.975348334 +0100
@@ -1195,7 +1195,7 @@ fail:
 	return err;
 }
 
-static struct pernet_operations __net_initdata icmp_sk_ops = {
+static struct pernet_operations __net_initconst icmp_sk_ops = {
        .init = icmp_sk_init,
        .exit = icmp_sk_exit,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/inet_connection_sock.c linux-3.2.71-pax/net/ipv4/inet_connection_sock.c
--- linux-3.2.71/net/ipv4/inet_connection_sock.c	2013-01-16 18:47:48.659057775 +0100
+++ linux-3.2.71-pax/net/ipv4/inet_connection_sock.c	2013-03-28 01:35:23.524427936 +0100
@@ -37,7 +37,7 @@ struct local_ports sysctl_local_ports __
 	.range = { 32768, 61000 },
 };
 
-unsigned long *sysctl_local_reserved_ports;
+unsigned long sysctl_local_reserved_ports[65536 / 8 / sizeof(unsigned long)];
 EXPORT_SYMBOL(sysctl_local_reserved_ports);
 
 void inet_get_local_port_range(int *low, int *high)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/inetpeer.c linux-3.2.71-pax/net/ipv4/inetpeer.c
--- linux-3.2.71/net/ipv4/inetpeer.c	2014-09-14 14:11:00.290118916 +0200
+++ linux-3.2.71-pax/net/ipv4/inetpeer.c	2014-09-14 14:17:30.213935678 +0200
@@ -473,7 +473,7 @@ relookup:
 	if (p) {
 		p->daddr = *daddr;
 		atomic_set(&p->refcnt, 1);
-		atomic_set(&p->rid, 0);
+		atomic_set_unchecked(&p->rid, 0);
 		p->tcp_ts_stamp = 0;
 		p->metrics[RTAX_LOCK-1] = INETPEER_METRICS_NEW;
 		p->rate_tokens = 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/ipconfig.c linux-3.2.71-pax/net/ipv4/ipconfig.c
--- linux-3.2.71/net/ipv4/ipconfig.c	2015-02-20 12:37:33.241178767 +0100
+++ linux-3.2.71-pax/net/ipv4/ipconfig.c	2015-02-20 12:37:41.917178304 +0100
@@ -318,7 +318,7 @@ static int __init ic_devinet_ioctl(unsig
 
 	mm_segment_t oldfs = get_fs();
 	set_fs(get_ds());
-	res = devinet_ioctl(&init_net, cmd, (struct ifreq __user *) arg);
+	res = devinet_ioctl(&init_net, cmd, (struct ifreq __force_user *) arg);
 	set_fs(oldfs);
 	return res;
 }
@@ -329,7 +329,7 @@ static int __init ic_dev_ioctl(unsigned
 
 	mm_segment_t oldfs = get_fs();
 	set_fs(get_ds());
-	res = dev_ioctl(&init_net, cmd, (struct ifreq __user *) arg);
+	res = dev_ioctl(&init_net, cmd, (struct ifreq __force_user *) arg);
 	set_fs(oldfs);
 	return res;
 }
@@ -340,7 +340,7 @@ static int __init ic_route_ioctl(unsigne
 
 	mm_segment_t oldfs = get_fs();
 	set_fs(get_ds());
-	res = ip_rt_ioctl(&init_net, cmd, (void __user *) arg);
+	res = ip_rt_ioctl(&init_net, cmd, (void __force_user *) arg);
 	set_fs(oldfs);
 	return res;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/ip_fragment.c linux-3.2.71-pax/net/ipv4/ip_fragment.c
--- linux-3.2.71/net/ipv4/ip_fragment.c	2015-08-14 21:48:35.412707907 +0200
+++ linux-3.2.71-pax/net/ipv4/ip_fragment.c	2015-08-14 21:48:45.688707358 +0200
@@ -315,7 +315,7 @@ static inline int ip_frag_too_far(struct
 		return 0;
 
 	start = qp->rid;
-	end = atomic_inc_return(&peer->rid);
+	end = atomic_inc_return_unchecked(&peer->rid);
 	qp->rid = end;
 
 	rc = qp->q.fragments && (end - start) > max;
@@ -778,21 +778,21 @@ static struct ctl_table ip4_frags_ctl_ta
 
 static int __net_init ip4_frags_ns_ctl_register(struct net *net)
 {
-	struct ctl_table *table;
+	ctl_table_no_const *table = NULL;
 	struct ctl_table_header *hdr;
 
-	table = ip4_frags_ns_ctl_table;
 	if (!net_eq(net, &init_net)) {
-		table = kmemdup(table, sizeof(ip4_frags_ns_ctl_table), GFP_KERNEL);
+		table = kmemdup(ip4_frags_ns_ctl_table, sizeof(ip4_frags_ns_ctl_table), GFP_KERNEL);
 		if (table == NULL)
 			goto err_alloc;
 
 		table[0].data = &net->ipv4.frags.high_thresh;
 		table[1].data = &net->ipv4.frags.low_thresh;
 		table[2].data = &net->ipv4.frags.timeout;
-	}
+		hdr = register_net_sysctl_table(net, net_ipv4_ctl_path, table);
+	} else
+		hdr = register_net_sysctl_table(net, net_ipv4_ctl_path, ip4_frags_ns_ctl_table);
 
-	hdr = register_net_sysctl_table(net, net_ipv4_ctl_path, table);
 	if (hdr == NULL)
 		goto err_reg;
 
@@ -800,8 +800,7 @@ static int __net_init ip4_frags_ns_ctl_r
 	return 0;
 
 err_reg:
-	if (!net_eq(net, &init_net))
-		kfree(table);
+	kfree(table);
 err_alloc:
 	return -ENOMEM;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/ip_gre.c linux-3.2.71-pax/net/ipv4/ip_gre.c
--- linux-3.2.71/net/ipv4/ip_gre.c	2013-07-27 01:12:45.979994715 +0200
+++ linux-3.2.71-pax/net/ipv4/ip_gre.c	2013-07-27 01:12:52.727994354 +0200
@@ -118,7 +118,7 @@
    Alexey Kuznetsov.
  */
 
-static struct rtnl_link_ops ipgre_link_ops __read_mostly;
+static struct rtnl_link_ops ipgre_link_ops;
 static int ipgre_tunnel_init(struct net_device *dev);
 static void ipgre_tunnel_setup(struct net_device *dev);
 static int ipgre_tunnel_bind_dev(struct net_device *dev);
@@ -1669,7 +1669,7 @@ static const struct nla_policy ipgre_pol
 	[IFLA_GRE_PMTUDISC]	= { .type = NLA_U8 },
 };
 
-static struct rtnl_link_ops ipgre_link_ops __read_mostly = {
+static struct rtnl_link_ops ipgre_link_ops = {
 	.kind		= "gre",
 	.maxtype	= IFLA_GRE_MAX,
 	.policy		= ipgre_policy,
@@ -1682,7 +1682,7 @@ static struct rtnl_link_ops ipgre_link_o
 	.fill_info	= ipgre_fill_info,
 };
 
-static struct rtnl_link_ops ipgre_tap_ops __read_mostly = {
+static struct rtnl_link_ops ipgre_tap_ops = {
 	.kind		= "gretap",
 	.maxtype	= IFLA_GRE_MAX,
 	.policy		= ipgre_policy,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/ip_sockglue.c linux-3.2.71-pax/net/ipv4/ip_sockglue.c
--- linux-3.2.71/net/ipv4/ip_sockglue.c	2015-05-10 09:22:39.375493156 +0200
+++ linux-3.2.71-pax/net/ipv4/ip_sockglue.c	2015-05-10 09:23:09.587494796 +0200
@@ -1245,7 +1245,7 @@ static int do_ip_getsockopt(struct sock
 		if (sk->sk_type != SOCK_STREAM)
 			return -ENOPROTOOPT;
 
-		msg.msg_control = optval;
+		msg.msg_control = (void __force_kernel *)optval;
 		msg.msg_controllen = len;
 		msg.msg_flags = flags;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/netfilter/arp_tables.c linux-3.2.71-pax/net/ipv4/netfilter/arp_tables.c
--- linux-3.2.71/net/ipv4/netfilter/arp_tables.c	2014-06-10 10:59:38.810436242 +0200
+++ linux-3.2.71-pax/net/ipv4/netfilter/arp_tables.c	2014-06-10 10:59:44.190435954 +0200
@@ -880,14 +880,14 @@ static int compat_table_info(const struc
 #endif
 
 static int get_info(struct net *net, void __user *user,
-                    const int *len, int compat)
+                    int len, int compat)
 {
 	char name[XT_TABLE_MAXNAMELEN];
 	struct xt_table *t;
 	int ret;
 
-	if (*len != sizeof(struct arpt_getinfo)) {
-		duprintf("length %u != %Zu\n", *len,
+	if (len != sizeof(struct arpt_getinfo)) {
+		duprintf("length %u != %Zu\n", len,
 			 sizeof(struct arpt_getinfo));
 		return -EINVAL;
 	}
@@ -924,7 +924,7 @@ static int get_info(struct net *net, voi
 		info.size = private->size;
 		strcpy(info.name, name);
 
-		if (copy_to_user(user, &info, *len) != 0)
+		if (copy_to_user(user, &info, len) != 0)
 			ret = -EFAULT;
 		else
 			ret = 0;
@@ -1685,7 +1685,7 @@ static int compat_do_arpt_get_ctl(struct
 
 	switch (cmd) {
 	case ARPT_SO_GET_INFO:
-		ret = get_info(sock_net(sk), user, len, 1);
+		ret = get_info(sock_net(sk), user, *len, 1);
 		break;
 	case ARPT_SO_GET_ENTRIES:
 		ret = compat_get_entries(sock_net(sk), user, len);
@@ -1730,7 +1730,7 @@ static int do_arpt_get_ctl(struct sock *
 
 	switch (cmd) {
 	case ARPT_SO_GET_INFO:
-		ret = get_info(sock_net(sk), user, len, 0);
+		ret = get_info(sock_net(sk), user, *len, 0);
 		break;
 
 	case ARPT_SO_GET_ENTRIES:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/netfilter/ip_tables.c linux-3.2.71-pax/net/ipv4/netfilter/ip_tables.c
--- linux-3.2.71/net/ipv4/netfilter/ip_tables.c	2014-06-10 10:59:38.810436242 +0200
+++ linux-3.2.71-pax/net/ipv4/netfilter/ip_tables.c	2014-06-10 10:59:44.194435954 +0200
@@ -1069,14 +1069,14 @@ static int compat_table_info(const struc
 #endif
 
 static int get_info(struct net *net, void __user *user,
-                    const int *len, int compat)
+                    int len, int compat)
 {
 	char name[XT_TABLE_MAXNAMELEN];
 	struct xt_table *t;
 	int ret;
 
-	if (*len != sizeof(struct ipt_getinfo)) {
-		duprintf("length %u != %zu\n", *len,
+	if (len != sizeof(struct ipt_getinfo)) {
+		duprintf("length %u != %zu\n", len,
 			 sizeof(struct ipt_getinfo));
 		return -EINVAL;
 	}
@@ -1113,7 +1113,7 @@ static int get_info(struct net *net, voi
 		info.size = private->size;
 		strcpy(info.name, name);
 
-		if (copy_to_user(user, &info, *len) != 0)
+		if (copy_to_user(user, &info, len) != 0)
 			ret = -EFAULT;
 		else
 			ret = 0;
@@ -1969,7 +1969,7 @@ compat_do_ipt_get_ctl(struct sock *sk, i
 
 	switch (cmd) {
 	case IPT_SO_GET_INFO:
-		ret = get_info(sock_net(sk), user, len, 1);
+		ret = get_info(sock_net(sk), user, *len, 1);
 		break;
 	case IPT_SO_GET_ENTRIES:
 		ret = compat_get_entries(sock_net(sk), user, len);
@@ -2016,7 +2016,7 @@ do_ipt_get_ctl(struct sock *sk, int cmd,
 
 	switch (cmd) {
 	case IPT_SO_GET_INFO:
-		ret = get_info(sock_net(sk), user, len, 0);
+		ret = get_info(sock_net(sk), user, *len, 0);
 		break;
 
 	case IPT_SO_GET_ENTRIES:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/ping.c linux-3.2.71-pax/net/ipv4/ping.c
--- linux-3.2.71/net/ipv4/ping.c	2015-05-10 09:22:39.375493156 +0200
+++ linux-3.2.71-pax/net/ipv4/ping.c	2015-05-10 09:23:09.587494796 +0200
@@ -851,7 +851,7 @@ static void ping_format_sock(struct sock
 		sk_rmem_alloc_get(sp),
 		0, 0L, 0, sock_i_uid(sp), 0, sock_i_ino(sp),
 		atomic_read(&sp->sk_refcnt), sp,
-		atomic_read(&sp->sk_drops), len);
+		atomic_read_unchecked(&sp->sk_drops), len);
 }
 
 static int ping_seq_show(struct seq_file *seq, void *v)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/proc.c linux-3.2.71-pax/net/ipv4/proc.c
--- linux-3.2.71/net/ipv4/proc.c	2013-01-16 18:47:48.659057775 +0100
+++ linux-3.2.71-pax/net/ipv4/proc.c	2013-03-29 04:00:44.299349224 +0100
@@ -487,7 +487,7 @@ static __net_exit void ip_proc_exit_net(
 	proc_net_remove(net, "sockstat");
 }
 
-static __net_initdata struct pernet_operations ip_proc_ops = {
+static __net_initconst struct pernet_operations ip_proc_ops = {
 	.init = ip_proc_init_net,
 	.exit = ip_proc_exit_net,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/raw.c linux-3.2.71-pax/net/ipv4/raw.c
--- linux-3.2.71/net/ipv4/raw.c	2015-02-20 12:37:33.241178767 +0100
+++ linux-3.2.71-pax/net/ipv4/raw.c	2015-02-20 12:37:41.917178304 +0100
@@ -305,7 +305,7 @@ static int raw_rcv_skb(struct sock * sk,
 int raw_rcv(struct sock *sk, struct sk_buff *skb)
 {
 	if (!xfrm4_policy_check(sk, XFRM_POLICY_IN, skb)) {
-		atomic_inc(&sk->sk_drops);
+		atomic_inc_unchecked(&sk->sk_drops);
 		kfree_skb(skb);
 		return NET_RX_DROP;
 	}
@@ -741,16 +741,20 @@ static int raw_init(struct sock *sk)
 
 static int raw_seticmpfilter(struct sock *sk, char __user *optval, int optlen)
 {
+	struct icmp_filter filter;
+
 	if (optlen > sizeof(struct icmp_filter))
 		optlen = sizeof(struct icmp_filter);
-	if (copy_from_user(&raw_sk(sk)->filter, optval, optlen))
+	if (copy_from_user(&filter, optval, optlen))
 		return -EFAULT;
+	raw_sk(sk)->filter = filter;
 	return 0;
 }
 
 static int raw_geticmpfilter(struct sock *sk, char __user *optval, int __user *optlen)
 {
 	int len, ret = -EFAULT;
+	struct icmp_filter filter;
 
 	if (get_user(len, optlen))
 		goto out;
@@ -760,8 +764,8 @@ static int raw_geticmpfilter(struct sock
 	if (len > sizeof(struct icmp_filter))
 		len = sizeof(struct icmp_filter);
 	ret = -EFAULT;
-	if (put_user(len, optlen) ||
-	    copy_to_user(optval, &raw_sk(sk)->filter, len))
+	filter = raw_sk(sk)->filter;
+	if (put_user(len, optlen) || len > sizeof filter || copy_to_user(optval, &filter, len))
 		goto out;
 	ret = 0;
 out:	return ret;
@@ -989,7 +993,7 @@ static void raw_sock_seq_show(struct seq
 		sk_wmem_alloc_get(sp),
 		sk_rmem_alloc_get(sp),
 		0, 0L, 0, sock_i_uid(sp), 0, sock_i_ino(sp),
-		atomic_read(&sp->sk_refcnt), sp, atomic_read(&sp->sk_drops));
+		atomic_read(&sp->sk_refcnt), sp, atomic_read_unchecked(&sp->sk_drops));
 }
 
 static int raw_seq_show(struct seq_file *seq, void *v)
@@ -1052,7 +1056,7 @@ static __net_exit void raw_exit_net(stru
 	proc_net_remove(net, "raw");
 }
 
-static __net_initdata struct pernet_operations raw_net_ops = {
+static __net_initconst struct pernet_operations raw_net_ops = {
 	.init = raw_init_net,
 	.exit = raw_exit_net,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/route.c linux-3.2.71-pax/net/ipv4/route.c
--- linux-3.2.71/net/ipv4/route.c	2014-11-05 23:20:30.781390061 +0100
+++ linux-3.2.71-pax/net/ipv4/route.c	2014-11-05 23:20:50.557398840 +0100
@@ -316,7 +316,7 @@ static inline unsigned int rt_hash(__be3
 
 static inline int rt_genid(struct net *net)
 {
-	return atomic_read(&net->ipv4.rt_genid);
+	return atomic_read_unchecked(&net->ipv4.rt_genid);
 }
 
 #ifdef CONFIG_PROC_FS
@@ -644,7 +644,7 @@ static void __net_exit ip_rt_do_proc_exi
 #endif
 }
 
-static struct pernet_operations ip_rt_proc_ops __net_initdata =  {
+static struct pernet_operations ip_rt_proc_ops __net_initconst =  {
 	.init = ip_rt_do_proc_init,
 	.exit = ip_rt_do_proc_exit,
 };
@@ -940,7 +940,7 @@ static void rt_cache_invalidate(struct n
 	unsigned char shuffle;
 
 	get_random_bytes(&shuffle, sizeof(shuffle));
-	atomic_add(shuffle + 1U, &net->ipv4.rt_genid);
+	atomic_add_unchecked(shuffle + 1U, &net->ipv4.rt_genid);
 	redirect_genid++;
 	inetpeer_invalidate_tree(AF_INET);
 }
@@ -1372,11 +1372,11 @@ void rt_bind_peer(struct rtable *rt, __b
 
 #define IP_IDENTS_SZ 2048u
 struct ip_ident_bucket {
-	atomic_t	id;
+	atomic_unchecked_t	id;
 	u32		stamp32;
 };
 
-static struct ip_ident_bucket *ip_idents __read_mostly;
+static struct ip_ident_bucket ip_idents[IP_IDENTS_SZ] __read_mostly;
 
 /* In order to protect privacy, we add a perturbation to identifiers
  * if one generator is seldom used. This makes hard for an attacker
@@ -1396,7 +1396,7 @@ u32 ip_idents_reserve(u32 hash, int segs
 		delta = (u32)(x >> 32);
 	}
 
-	return atomic_add_return(segs + delta, &bucket->id) - segs;
+	return atomic_add_return_unchecked(segs + delta, &bucket->id) - segs;
 }
 EXPORT_SYMBOL(ip_idents_reserve);
 
@@ -3254,7 +3254,7 @@ static int ipv4_sysctl_rtcache_flush(ctl
 {
 	if (write) {
 		int flush_delay;
-		ctl_table ctl;
+		ctl_table_no_const ctl;
 		struct net *net;
 
 		memcpy(&ctl, __ctl, sizeof(ctl));
@@ -3403,6 +3403,7 @@ static struct ctl_table ipv4_route_flush
 		.maxlen		= sizeof(int),
 		.mode		= 0200,
 		.proc_handler	= ipv4_sysctl_rtcache_flush,
+		.extra1		= &init_net,
 	},
 	{ },
 };
@@ -3416,25 +3417,23 @@ static __net_initdata struct ctl_path ip
 
 static __net_init int sysctl_route_net_init(struct net *net)
 {
-	struct ctl_table *tbl;
+	ctl_table_no_const *tbl = NULL;
 
-	tbl = ipv4_route_flush_table;
 	if (!net_eq(net, &init_net)) {
-		tbl = kmemdup(tbl, sizeof(ipv4_route_flush_table), GFP_KERNEL);
+		tbl = kmemdup(ipv4_route_flush_table, sizeof(ipv4_route_flush_table), GFP_KERNEL);
 		if (tbl == NULL)
 			goto err_dup;
-	}
-	tbl[0].extra1 = net;
 
-	net->ipv4.route_hdr =
-		register_net_sysctl_table(net, ipv4_route_path, tbl);
+		net->ipv4.route_hdr = register_net_sysctl_table(net, ipv4_route_path, tbl);
+	} else
+		net->ipv4.route_hdr = register_net_sysctl_table(net, ipv4_route_path, ipv4_route_flush_table);
+
 	if (net->ipv4.route_hdr == NULL)
 		goto err_reg;
 	return 0;
 
 err_reg:
-	if (tbl != ipv4_route_flush_table)
-		kfree(tbl);
+	kfree(tbl);
 err_dup:
 	return -ENOMEM;
 }
@@ -3449,7 +3448,7 @@ static __net_exit void sysctl_route_net_
 	kfree(tbl);
 }
 
-static __net_initdata struct pernet_operations sysctl_route_ops = {
+static __net_initconst struct pernet_operations sysctl_route_ops = {
 	.init = sysctl_route_net_init,
 	.exit = sysctl_route_net_exit,
 };
@@ -3464,7 +3463,7 @@ static __net_init int rt_genid_init(stru
 	return 0;
 }
 
-static __net_initdata struct pernet_operations rt_genid_ops = {
+static __net_initconst struct pernet_operations rt_genid_ops = {
 	.init = rt_genid_init,
 };
 
@@ -3487,11 +3486,7 @@ int __init ip_rt_init(void)
 {
 	int rc = 0;
 
-	ip_idents = kmalloc(IP_IDENTS_SZ * sizeof(*ip_idents), GFP_KERNEL);
-	if (!ip_idents)
-		panic("IP: failed to allocate ip_idents\n");
-
-	get_random_bytes(ip_idents, IP_IDENTS_SZ * sizeof(*ip_idents));
+	get_random_bytes(ip_idents, sizeof(ip_idents));
 
 #ifdef CONFIG_IP_ROUTE_CLASSID
 	ip_rt_acct = __alloc_percpu(256 * sizeof(struct ip_rt_acct), __alignof__(struct ip_rt_acct));
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/sysctl_net_ipv4.c linux-3.2.71-pax/net/ipv4/sysctl_net_ipv4.c
--- linux-3.2.71/net/ipv4/sysctl_net_ipv4.c	2015-05-10 09:22:39.383493156 +0200
+++ linux-3.2.71-pax/net/ipv4/sysctl_net_ipv4.c	2015-05-10 09:23:09.591494797 +0200
@@ -53,7 +53,7 @@ static int ipv4_local_port_range(ctl_tab
 {
 	int ret;
 	int range[2];
-	ctl_table tmp = {
+	ctl_table_no_const tmp = {
 		.data = &range,
 		.maxlen = sizeof(range),
 		.mode = table->mode,
@@ -104,7 +104,7 @@ static int ipv4_ping_group_range(ctl_tab
 {
 	int ret;
 	gid_t range[2];
-	ctl_table tmp = {
+	ctl_table_no_const tmp = {
 		.data = &range,
 		.maxlen = sizeof(range),
 		.mode = table->mode,
@@ -125,7 +125,7 @@ static int proc_tcp_congestion_control(c
 				       void __user *buffer, size_t *lenp, loff_t *ppos)
 {
 	char val[TCP_CA_NAME_MAX];
-	ctl_table tbl = {
+	ctl_table_no_const tbl = {
 		.data = val,
 		.maxlen = TCP_CA_NAME_MAX,
 	};
@@ -144,7 +144,7 @@ static int proc_tcp_available_congestion
 						 void __user *buffer, size_t *lenp,
 						 loff_t *ppos)
 {
-	ctl_table tbl = { .maxlen = TCP_CA_BUF_MAX, };
+	ctl_table_no_const tbl = { .maxlen = TCP_CA_BUF_MAX, };
 	int ret;
 
 	tbl.data = kmalloc(tbl.maxlen, GFP_USER);
@@ -161,7 +161,7 @@ static int proc_allowed_congestion_contr
 					   void __user *buffer, size_t *lenp,
 					   loff_t *ppos)
 {
-	ctl_table tbl = { .maxlen = TCP_CA_BUF_MAX };
+	ctl_table_no_const tbl = { .maxlen = TCP_CA_BUF_MAX };
 	int ret;
 
 	tbl.data = kmalloc(tbl.maxlen, GFP_USER);
@@ -361,7 +361,7 @@ static struct ctl_table ipv4_table[] = {
 	},
 	{
 		.procname	= "ip_local_reserved_ports",
-		.data		= NULL, /* initialized in sysctl_ipv4_init */
+		.data		= sysctl_local_reserved_ports,
 		.maxlen		= 65536,
 		.mode		= 0644,
 		.proc_handler	= proc_do_large_bitmap,
@@ -746,11 +746,10 @@ EXPORT_SYMBOL_GPL(net_ipv4_ctl_path);
 
 static __net_init int ipv4_sysctl_init_net(struct net *net)
 {
-	struct ctl_table *table;
+	ctl_table_no_const *table = NULL;
 
-	table = ipv4_net_table;
 	if (!net_eq(net, &init_net)) {
-		table = kmemdup(table, sizeof(ipv4_net_table), GFP_KERNEL);
+		table = kmemdup(ipv4_net_table, sizeof(ipv4_net_table), GFP_KERNEL);
 		if (table == NULL)
 			goto err_alloc;
 
@@ -782,16 +781,17 @@ static __net_init int ipv4_sysctl_init_n
 
 	net->ipv4.sysctl_rt_cache_rebuild_count = 4;
 
-	net->ipv4.ipv4_hdr = register_net_sysctl_table(net,
-			net_ipv4_ctl_path, table);
+	if (!net_eq(net, &init_net))
+		net->ipv4.ipv4_hdr = register_net_sysctl_table(net, net_ipv4_ctl_path, table);
+	else
+		net->ipv4.ipv4_hdr = register_net_sysctl_table(net, net_ipv4_ctl_path, ipv4_net_table);
 	if (net->ipv4.ipv4_hdr == NULL)
 		goto err_reg;
 
 	return 0;
 
 err_reg:
-	if (!net_eq(net, &init_net))
-		kfree(table);
+	kfree(table);
 err_alloc:
 	return -ENOMEM;
 }
@@ -805,7 +805,7 @@ static __net_exit void ipv4_sysctl_exit_
 	kfree(table);
 }
 
-static __net_initdata struct pernet_operations ipv4_sysctl_ops = {
+static __net_initconst struct pernet_operations ipv4_sysctl_ops = {
 	.init = ipv4_sysctl_init_net,
 	.exit = ipv4_sysctl_exit_net,
 };
@@ -813,16 +813,6 @@ static __net_initdata struct pernet_oper
 static __init int sysctl_ipv4_init(void)
 {
 	struct ctl_table_header *hdr;
-	struct ctl_table *i;
-
-	for (i = ipv4_table; i->procname; i++) {
-		if (strcmp(i->procname, "ip_local_reserved_ports") == 0) {
-			i->data = sysctl_local_reserved_ports;
-			break;
-		}
-	}
-	if (!i->procname)
-		return -EINVAL;
 
 	hdr = register_sysctl_paths(net_ipv4_ctl_path, ipv4_table);
 	if (hdr == NULL)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/tcp_input.c linux-3.2.71-pax/net/ipv4/tcp_input.c
--- linux-3.2.71/net/ipv4/tcp_input.c	2014-08-06 23:17:22.205614201 +0200
+++ linux-3.2.71-pax/net/ipv4/tcp_input.c	2014-08-06 23:17:26.801614191 +0200
@@ -4739,7 +4739,7 @@ static struct sk_buff *tcp_collapse_one(
  * simplifies code)
  */
 static void
-tcp_collapse(struct sock *sk, struct sk_buff_head *list,
+__intentional_overflow(5,6) tcp_collapse(struct sock *sk, struct sk_buff_head *list,
 	     struct sk_buff *head, struct sk_buff *tail,
 	     u32 start, u32 end)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/tcp_ipv4.c linux-3.2.71-pax/net/ipv4/tcp_ipv4.c
--- linux-3.2.71/net/ipv4/tcp_ipv4.c	2015-01-01 15:15:25.008069638 +0100
+++ linux-3.2.71-pax/net/ipv4/tcp_ipv4.c	2015-01-01 15:15:30.336069777 +0100
@@ -2657,7 +2657,7 @@ static void __net_exit tcp_sk_exit_batch
 	inet_twsk_purge(&tcp_hashinfo, &tcp_death_row, AF_INET);
 }
 
-static struct pernet_operations __net_initdata tcp_sk_ops = {
+static struct pernet_operations __net_initconst tcp_sk_ops = {
        .init	   = tcp_sk_init,
        .exit	   = tcp_sk_exit,
        .exit_batch = tcp_sk_exit_batch,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/tcp_output.c linux-3.2.71-pax/net/ipv4/tcp_output.c
--- linux-3.2.71/net/ipv4/tcp_output.c	2015-05-10 09:22:39.391493156 +0200
+++ linux-3.2.71-pax/net/ipv4/tcp_output.c	2015-05-10 09:23:09.591494797 +0200
@@ -1319,7 +1319,7 @@ static void tcp_cwnd_validate(struct soc
  * modulo only when the receiver window alone is the limiting factor or
  * when we would be allowed to send the split-due-to-Nagle skb fully.
  */
-static unsigned int tcp_mss_split_point(const struct sock *sk, const struct sk_buff *skb,
+static unsigned int __intentional_overflow(0) tcp_mss_split_point(const struct sock *sk, const struct sk_buff *skb,
 					unsigned int mss_now, unsigned int cwnd)
 {
 	const struct tcp_sock *tp = tcp_sk(sk);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/tcp_probe.c linux-3.2.71-pax/net/ipv4/tcp_probe.c
--- linux-3.2.71/net/ipv4/tcp_probe.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/ipv4/tcp_probe.c	2012-07-04 19:24:48.984063009 +0200
@@ -202,7 +202,7 @@ static ssize_t tcpprobe_read(struct file
 		if (cnt + width >= len)
 			break;
 
-		if (copy_to_user(buf + cnt, tbuf, width))
+		if (width > sizeof tbuf || copy_to_user(buf + cnt, tbuf, width))
 			return -EFAULT;
 		cnt += width;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/udp.c linux-3.2.71-pax/net/ipv4/udp.c
--- linux-3.2.71/net/ipv4/udp.c	2015-08-07 11:37:20.771789899 +0200
+++ linux-3.2.71-pax/net/ipv4/udp.c	2015-08-07 11:37:43.031790554 +0200
@@ -1103,7 +1103,7 @@ static unsigned int first_packet_length(
 		udp_lib_checksum_complete(skb)) {
 		UDP_INC_STATS_BH(sock_net(sk), UDP_MIB_INERRORS,
 				 IS_UDPLITE(sk));
-		atomic_inc(&sk->sk_drops);
+		atomic_inc_unchecked(&sk->sk_drops);
 		__skb_unlink(skb, rcvq);
 		__skb_queue_tail(&list_kill, skb);
 	}
@@ -1484,7 +1484,7 @@ int udp_queue_rcv_skb(struct sock *sk, s
 
 drop:
 	UDP_INC_STATS_BH(sock_net(sk), UDP_MIB_INERRORS, is_udplite);
-	atomic_inc(&sk->sk_drops);
+	atomic_inc_unchecked(&sk->sk_drops);
 	kfree_skb(skb);
 	return -1;
 }
@@ -1503,7 +1503,7 @@ static void flush_stack(struct sock **st
 			skb1 = (i == final) ? skb : skb_clone(skb, GFP_ATOMIC);
 
 		if (!skb1) {
-			atomic_inc(&sk->sk_drops);
+			atomic_inc_unchecked(&sk->sk_drops);
 			UDP_INC_STATS_BH(sock_net(sk), UDP_MIB_RCVBUFERRORS,
 					 IS_UDPLITE(sk));
 			UDP_INC_STATS_BH(sock_net(sk), UDP_MIB_INERRORS,
@@ -2096,7 +2096,7 @@ static void udp4_format_sock(struct sock
 		sk_rmem_alloc_get(sp),
 		0, 0L, 0, sock_i_uid(sp), 0, sock_i_ino(sp),
 		atomic_read(&sp->sk_refcnt), sp,
-		atomic_read(&sp->sk_drops), len);
+		atomic_read_unchecked(&sp->sk_drops), len);
 }
 
 int udp4_seq_show(struct seq_file *seq, void *v)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv4/xfrm4_policy.c linux-3.2.71-pax/net/ipv4/xfrm4_policy.c
--- linux-3.2.71/net/ipv4/xfrm4_policy.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/ipv4/xfrm4_policy.c	2013-09-17 02:25:20.029621361 +0200
@@ -190,11 +190,11 @@ _decode_session4(struct sk_buff *skb, st
 	fl4->flowi4_tos = iph->tos;
 }
 
-static inline int xfrm4_garbage_collect(struct dst_ops *ops)
+static int xfrm4_garbage_collect(struct dst_ops *ops)
 {
 	struct net *net = container_of(ops, struct net, xfrm.xfrm4_dst_ops);
 
-	xfrm4_policy_afinfo.garbage_collect(net);
+	xfrm_garbage_collect_deferred(net);
 	return (dst_entries_get_slow(ops) > ops->gc_thresh * 2);
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv6/addrconf.c linux-3.2.71-pax/net/ipv6/addrconf.c
--- linux-3.2.71/net/ipv6/addrconf.c	2014-11-05 23:20:30.781390061 +0100
+++ linux-3.2.71-pax/net/ipv6/addrconf.c	2014-11-05 23:20:50.557398840 +0100
@@ -2160,7 +2160,7 @@ int addrconf_set_dstaddr(struct net *net
 		p.iph.ihl = 5;
 		p.iph.protocol = IPPROTO_IPV6;
 		p.iph.ttl = 64;
-		ifr.ifr_ifru.ifru_data = (__force void __user *)&p;
+		ifr.ifr_ifru.ifru_data = (void __force_user *)&p;
 
 		if (ops->ndo_do_ioctl) {
 			mm_segment_t oldfs = get_fs();
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv6/icmp.c linux-3.2.71-pax/net/ipv6/icmp.c
--- linux-3.2.71/net/ipv6/icmp.c	2014-04-30 18:53:46.356223429 +0200
+++ linux-3.2.71-pax/net/ipv6/icmp.c	2014-04-30 18:53:50.684223419 +0200
@@ -969,7 +969,7 @@ ctl_table ipv6_icmp_table_template[] = {
 
 struct ctl_table * __net_init ipv6_icmp_sysctl_init(struct net *net)
 {
-	struct ctl_table *table;
+	ctl_table_no_const *table;
 
 	table = kmemdup(ipv6_icmp_table_template,
 			sizeof(ipv6_icmp_table_template),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv6/inet6_connection_sock.c linux-3.2.71-pax/net/ipv6/inet6_connection_sock.c
--- linux-3.2.71/net/ipv6/inet6_connection_sock.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/ipv6/inet6_connection_sock.c	2012-07-04 19:24:48.984063009 +0200
@@ -178,7 +178,7 @@ void __inet6_csk_dst_store(struct sock *
 #ifdef CONFIG_XFRM
 	{
 		struct rt6_info *rt = (struct rt6_info  *)dst;
-		rt->rt6i_flow_cache_genid = atomic_read(&flow_cache_genid);
+		rt->rt6i_flow_cache_genid = atomic_read_unchecked(&flow_cache_genid);
 	}
 #endif
 }
@@ -193,7 +193,7 @@ struct dst_entry *__inet6_csk_dst_check(
 #ifdef CONFIG_XFRM
 	if (dst) {
 		struct rt6_info *rt = (struct rt6_info *)dst;
-		if (rt->rt6i_flow_cache_genid != atomic_read(&flow_cache_genid)) {
+		if (rt->rt6i_flow_cache_genid != atomic_read_unchecked(&flow_cache_genid)) {
 			__sk_dst_reset(sk);
 			dst = NULL;
 		}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv6/ipv6_sockglue.c linux-3.2.71-pax/net/ipv6/ipv6_sockglue.c
--- linux-3.2.71/net/ipv6/ipv6_sockglue.c	2012-12-06 19:03:21.435211770 +0100
+++ linux-3.2.71-pax/net/ipv6/ipv6_sockglue.c	2012-12-06 19:03:25.783213078 +0100
@@ -961,7 +961,7 @@ static int do_ipv6_getsockopt(struct soc
 		if (sk->sk_type != SOCK_STREAM)
 			return -ENOPROTOOPT;
 
-		msg.msg_control = optval;
+		msg.msg_control = (void __force_kernel *)optval;
 		msg.msg_controllen = len;
 		msg.msg_flags = flags;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv6/netfilter/ip6_tables.c linux-3.2.71-pax/net/ipv6/netfilter/ip6_tables.c
--- linux-3.2.71/net/ipv6/netfilter/ip6_tables.c	2014-06-10 10:59:38.810436242 +0200
+++ linux-3.2.71-pax/net/ipv6/netfilter/ip6_tables.c	2014-06-10 10:59:44.194435954 +0200
@@ -1091,14 +1091,14 @@ static int compat_table_info(const struc
 #endif
 
 static int get_info(struct net *net, void __user *user,
-                    const int *len, int compat)
+                    int len, int compat)
 {
 	char name[XT_TABLE_MAXNAMELEN];
 	struct xt_table *t;
 	int ret;
 
-	if (*len != sizeof(struct ip6t_getinfo)) {
-		duprintf("length %u != %zu\n", *len,
+	if (len != sizeof(struct ip6t_getinfo)) {
+		duprintf("length %u != %zu\n", len,
 			 sizeof(struct ip6t_getinfo));
 		return -EINVAL;
 	}
@@ -1135,7 +1135,7 @@ static int get_info(struct net *net, voi
 		info.size = private->size;
 		strcpy(info.name, name);
 
-		if (copy_to_user(user, &info, *len) != 0)
+		if (copy_to_user(user, &info, len) != 0)
 			ret = -EFAULT;
 		else
 			ret = 0;
@@ -1991,7 +1991,7 @@ compat_do_ip6t_get_ctl(struct sock *sk,
 
 	switch (cmd) {
 	case IP6T_SO_GET_INFO:
-		ret = get_info(sock_net(sk), user, len, 1);
+		ret = get_info(sock_net(sk), user, *len, 1);
 		break;
 	case IP6T_SO_GET_ENTRIES:
 		ret = compat_get_entries(sock_net(sk), user, len);
@@ -2038,7 +2038,7 @@ do_ip6t_get_ctl(struct sock *sk, int cmd
 
 	switch (cmd) {
 	case IP6T_SO_GET_INFO:
-		ret = get_info(sock_net(sk), user, len, 0);
+		ret = get_info(sock_net(sk), user, *len, 0);
 		break;
 
 	case IP6T_SO_GET_ENTRIES:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv6/raw.c linux-3.2.71-pax/net/ipv6/raw.c
--- linux-3.2.71/net/ipv6/raw.c	2015-02-20 12:37:33.245178767 +0100
+++ linux-3.2.71-pax/net/ipv6/raw.c	2015-02-20 12:37:41.921178304 +0100
@@ -109,7 +109,7 @@ found:
  */
 static int icmpv6_filter(const struct sock *sk, const struct sk_buff *skb)
 {
-	struct icmp6hdr *_hdr;
+	struct icmp6hdr _hdr;
 	const struct icmp6hdr *hdr;
 
 	hdr = skb_header_pointer(skb, skb_transport_offset(skb),
@@ -376,7 +376,7 @@ static inline int rawv6_rcv_skb(struct s
 {
 	if ((raw6_sk(sk)->checksum || rcu_access_pointer(sk->sk_filter)) &&
 	    skb_checksum_complete(skb)) {
-		atomic_inc(&sk->sk_drops);
+		atomic_inc_unchecked(&sk->sk_drops);
 		kfree_skb(skb);
 		return NET_RX_DROP;
 	}
@@ -403,7 +403,7 @@ int rawv6_rcv(struct sock *sk, struct sk
 	struct raw6_sock *rp = raw6_sk(sk);
 
 	if (!xfrm6_policy_check(sk, XFRM_POLICY_IN, skb)) {
-		atomic_inc(&sk->sk_drops);
+		atomic_inc_unchecked(&sk->sk_drops);
 		kfree_skb(skb);
 		return NET_RX_DROP;
 	}
@@ -427,7 +427,7 @@ int rawv6_rcv(struct sock *sk, struct sk
 
 	if (inet->hdrincl) {
 		if (skb_checksum_complete(skb)) {
-			atomic_inc(&sk->sk_drops);
+			atomic_inc_unchecked(&sk->sk_drops);
 			kfree_skb(skb);
 			return NET_RX_DROP;
 		}
@@ -598,7 +598,7 @@ out:
 	return err;
 }
 
-static int rawv6_send_hdrinc(struct sock *sk, void *from, int length,
+static int rawv6_send_hdrinc(struct sock *sk, void *from, unsigned int length,
 			struct flowi6 *fl6, struct dst_entry **dstp,
 			unsigned int flags)
 {
@@ -908,12 +908,15 @@ do_confirm:
 static int rawv6_seticmpfilter(struct sock *sk, int level, int optname,
 			       char __user *optval, int optlen)
 {
+	struct icmp6_filter filter;
+
 	switch (optname) {
 	case ICMPV6_FILTER:
 		if (optlen > sizeof(struct icmp6_filter))
 			optlen = sizeof(struct icmp6_filter);
-		if (copy_from_user(&raw6_sk(sk)->filter, optval, optlen))
+		if (copy_from_user(&filter, optval, optlen))
 			return -EFAULT;
+		raw6_sk(sk)->filter = filter;
 		return 0;
 	default:
 		return -ENOPROTOOPT;
@@ -926,6 +929,7 @@ static int rawv6_geticmpfilter(struct so
 			       char __user *optval, int __user *optlen)
 {
 	int len;
+	struct icmp6_filter filter;
 
 	switch (optname) {
 	case ICMPV6_FILTER:
@@ -937,7 +941,8 @@ static int rawv6_geticmpfilter(struct so
 			len = sizeof(struct icmp6_filter);
 		if (put_user(len, optlen))
 			return -EFAULT;
-		if (copy_to_user(optval, &raw6_sk(sk)->filter, len))
+		filter = raw6_sk(sk)->filter;
+		if (len > sizeof filter || copy_to_user(optval, &filter, len))
 			return -EFAULT;
 		return 0;
 	default:
@@ -1244,7 +1249,7 @@ static void raw6_sock_seq_show(struct se
 		   0, 0L, 0,
 		   sock_i_uid(sp), 0,
 		   sock_i_ino(sp),
-		   atomic_read(&sp->sk_refcnt), sp, atomic_read(&sp->sk_drops));
+		   atomic_read(&sp->sk_refcnt), sp, atomic_read_unchecked(&sp->sk_drops));
 }
 
 static int raw6_seq_show(struct seq_file *seq, void *v)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv6/reassembly.c linux-3.2.71-pax/net/ipv6/reassembly.c
--- linux-3.2.71/net/ipv6/reassembly.c	2013-10-27 17:59:58.736642306 +0100
+++ linux-3.2.71-pax/net/ipv6/reassembly.c	2013-10-27 18:00:09.604641725 +0100
@@ -651,21 +651,21 @@ static struct ctl_table ip6_frags_ctl_ta
 
 static int __net_init ip6_frags_ns_sysctl_register(struct net *net)
 {
-	struct ctl_table *table;
+	ctl_table_no_const *table = NULL;
 	struct ctl_table_header *hdr;
 
-	table = ip6_frags_ns_ctl_table;
 	if (!net_eq(net, &init_net)) {
-		table = kmemdup(table, sizeof(ip6_frags_ns_ctl_table), GFP_KERNEL);
+		table = kmemdup(ip6_frags_ns_ctl_table, sizeof(ip6_frags_ns_ctl_table), GFP_KERNEL);
 		if (table == NULL)
 			goto err_alloc;
 
 		table[0].data = &net->ipv6.frags.high_thresh;
 		table[1].data = &net->ipv6.frags.low_thresh;
 		table[2].data = &net->ipv6.frags.timeout;
-	}
+		hdr = register_net_sysctl_table(net, net_ipv6_ctl_path, table);
+	} else
+		hdr = register_net_sysctl_table(net, net_ipv6_ctl_path, ip6_frags_ns_ctl_table);
 
-	hdr = register_net_sysctl_table(net, net_ipv6_ctl_path, table);
 	if (hdr == NULL)
 		goto err_reg;
 
@@ -673,8 +673,7 @@ static int __net_init ip6_frags_ns_sysct
 	return 0;
 
 err_reg:
-	if (!net_eq(net, &init_net))
-		kfree(table);
+	kfree(table);
 err_alloc:
 	return -ENOMEM;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv6/route.c linux-3.2.71-pax/net/ipv6/route.c
--- linux-3.2.71/net/ipv6/route.c	2015-05-10 09:22:39.419493158 +0200
+++ linux-3.2.71-pax/net/ipv6/route.c	2015-05-10 09:23:09.591494797 +0200
@@ -2806,7 +2806,7 @@ ctl_table ipv6_route_table_template[] =
 
 struct ctl_table * __net_init ipv6_route_sysctl_init(struct net *net)
 {
-	struct ctl_table *table;
+	ctl_table_no_const *table;
 
 	table = kmemdup(ipv6_route_table_template,
 			sizeof(ipv6_route_table_template),
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv6/sysctl_net_ipv6.c linux-3.2.71-pax/net/ipv6/sysctl_net_ipv6.c
--- linux-3.2.71/net/ipv6/sysctl_net_ipv6.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/ipv6/sysctl_net_ipv6.c	2013-03-28 01:35:23.540427935 +0100
@@ -71,7 +71,7 @@ EXPORT_SYMBOL_GPL(net_ipv6_ctl_path);
 
 static int __net_init ipv6_sysctl_net_init(struct net *net)
 {
-	struct ctl_table *ipv6_table;
+	ctl_table_no_const *ipv6_table;
 	struct ctl_table *ipv6_route_table;
 	struct ctl_table *ipv6_icmp_table;
 	int err;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv6/udp.c linux-3.2.71-pax/net/ipv6/udp.c
--- linux-3.2.71/net/ipv6/udp.c	2015-08-07 11:37:20.775789900 +0200
+++ linux-3.2.71-pax/net/ipv6/udp.c	2015-08-07 11:37:43.031790554 +0200
@@ -544,7 +544,7 @@ int udpv6_queue_rcv_skb(struct sock * sk
 
 	return 0;
 drop:
-	atomic_inc(&sk->sk_drops);
+	atomic_inc_unchecked(&sk->sk_drops);
 drop_no_sk_drops_inc:
 	UDP6_INC_STATS_BH(sock_net(sk), UDP_MIB_INERRORS, is_udplite);
 	kfree_skb(skb);
@@ -620,7 +620,7 @@ static void flush_stack(struct sock **st
 			continue;
 		}
 drop:
-		atomic_inc(&sk->sk_drops);
+		atomic_inc_unchecked(&sk->sk_drops);
 		UDP6_INC_STATS_BH(sock_net(sk),
 				UDP_MIB_RCVBUFERRORS, IS_UDPLITE(sk));
 		UDP6_INC_STATS_BH(sock_net(sk),
@@ -791,7 +791,7 @@ int __udp6_lib_rcv(struct sk_buff *skb,
 	if (!sock_owned_by_user(sk))
 		udpv6_queue_rcv_skb(sk, skb);
 	else if (sk_add_backlog(sk, skb)) {
-		atomic_inc(&sk->sk_drops);
+		atomic_inc_unchecked(&sk->sk_drops);
 		bh_unlock_sock(sk);
 		sock_put(sk);
 		goto discard;
@@ -1408,7 +1408,7 @@ static void udp6_sock_seq_show(struct se
 		   sock_i_uid(sp), 0,
 		   sock_i_ino(sp),
 		   atomic_read(&sp->sk_refcnt), sp,
-		   atomic_read(&sp->sk_drops));
+		   atomic_read_unchecked(&sp->sk_drops));
 }
 
 int udp6_seq_show(struct seq_file *seq, void *v)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/ipv6/xfrm6_policy.c linux-3.2.71-pax/net/ipv6/xfrm6_policy.c
--- linux-3.2.71/net/ipv6/xfrm6_policy.c	2013-06-09 18:04:43.501591744 +0200
+++ linux-3.2.71-pax/net/ipv6/xfrm6_policy.c	2015-01-05 18:19:52.747510193 +0100
@@ -125,8 +125,8 @@ _decode_session6(struct sk_buff *skb, st
 {
 	struct flowi6 *fl6 = &fl->u.ip6;
 	int onlyproto = 0;
-	u16 offset = skb_network_header_len(skb);
 	const struct ipv6hdr *hdr = ipv6_hdr(skb);
+	u16 offset = sizeof(*hdr);
 	struct ipv6_opt_hdr *exthdr;
 	const unsigned char *nh = skb_network_header(skb);
 	u8 nexthdr = nh[IP6CB(skb)->nhoff];
@@ -202,11 +202,11 @@ _decode_session6(struct sk_buff *skb, st
 	}
 }
 
-static inline int xfrm6_garbage_collect(struct dst_ops *ops)
+static int xfrm6_garbage_collect(struct dst_ops *ops)
 {
 	struct net *net = container_of(ops, struct net, xfrm.xfrm6_dst_ops);
 
-	xfrm6_policy_afinfo.garbage_collect(net);
+	xfrm_garbage_collect_deferred(net);
 	return dst_entries_get_fast(ops) > ops->gc_thresh * 2;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/irda/ircomm/ircomm_tty.c linux-3.2.71-pax/net/irda/ircomm/ircomm_tty.c
--- linux-3.2.71/net/irda/ircomm/ircomm_tty.c	2015-05-10 09:22:39.471493161 +0200
+++ linux-3.2.71-pax/net/irda/ircomm/ircomm_tty.c	2015-05-10 09:23:09.591494797 +0200
@@ -282,16 +282,16 @@ static int ircomm_tty_block_til_ready(st
 	add_wait_queue(&self->open_wait, &wait);
 
 	IRDA_DEBUG(2, "%s(%d):block_til_ready before block on %s open_count=%d\n",
-	      __FILE__,__LINE__, tty->driver->name, self->open_count );
+	      __FILE__,__LINE__, tty->driver->name, local_read(&self->open_count) );
 
 	/* As far as I can see, we protect open_count - Jean II */
 	spin_lock_irqsave(&self->spinlock, flags);
 	if (!tty_hung_up_p(filp)) {
 		extra_count = 1;
-		self->open_count--;
+		local_dec(&self->open_count);
 	}
 	spin_unlock_irqrestore(&self->spinlock, flags);
-	self->blocked_open++;
+	local_inc(&self->blocked_open);
 
 	while (1) {
 		if (tty->termios->c_cflag & CBAUD) {
@@ -331,7 +331,7 @@ static int ircomm_tty_block_til_ready(st
 		}
 
 		IRDA_DEBUG(1, "%s(%d):block_til_ready blocking on %s open_count=%d\n",
-		      __FILE__,__LINE__, tty->driver->name, self->open_count );
+		      __FILE__,__LINE__, tty->driver->name, local_read(&self->open_count) );
 
 		schedule();
 	}
@@ -342,13 +342,13 @@ static int ircomm_tty_block_til_ready(st
 	if (extra_count) {
 		/* ++ is not atomic, so this should be protected - Jean II */
 		spin_lock_irqsave(&self->spinlock, flags);
-		self->open_count++;
+		local_inc(&self->open_count);
 		spin_unlock_irqrestore(&self->spinlock, flags);
 	}
-	self->blocked_open--;
+	local_dec(&self->blocked_open);
 
 	IRDA_DEBUG(1, "%s(%d):block_til_ready after blocking on %s open_count=%d\n",
-	      __FILE__,__LINE__, tty->driver->name, self->open_count);
+	      __FILE__,__LINE__, tty->driver->name, local_read(&self->open_count));
 
 	if (!retval)
 		self->flags |= ASYNC_NORMAL_ACTIVE;
@@ -417,14 +417,14 @@ static int ircomm_tty_open(struct tty_st
 	}
 	/* ++ is not atomic, so this should be protected - Jean II */
 	spin_lock_irqsave(&self->spinlock, flags);
-	self->open_count++;
+	local_inc(&self->open_count);
 
 	tty->driver_data = self;
 	self->tty = tty;
 	spin_unlock_irqrestore(&self->spinlock, flags);
 
 	IRDA_DEBUG(1, "%s(), %s%d, count = %d\n", __func__ , tty->driver->name,
-		   self->line, self->open_count);
+		   self->line, local_read(&self->open_count));
 
 	/* Not really used by us, but lets do it anyway */
 	self->tty->low_latency = (self->flags & ASYNC_LOW_LATENCY) ? 1 : 0;
@@ -510,7 +510,7 @@ static void ircomm_tty_close(struct tty_
 		return;
 	}
 
-	if ((tty->count == 1) && (self->open_count != 1)) {
+	if ((tty->count == 1) && (local_read(&self->open_count) != 1)) {
 		/*
 		 * Uh, oh.  tty->count is 1, which means that the tty
 		 * structure will be freed.  state->count should always
@@ -520,16 +520,16 @@ static void ircomm_tty_close(struct tty_
 		 */
 		IRDA_DEBUG(0, "%s(), bad serial port count; "
 			   "tty->count is 1, state->count is %d\n", __func__ ,
-			   self->open_count);
-		self->open_count = 1;
+			   local_read(&self->open_count));
+		local_set(&self->open_count, 1);
 	}
 
-	if (--self->open_count < 0) {
+	if (local_dec_return(&self->open_count) < 0) {
 		IRDA_ERROR("%s(), bad serial port count for ttys%d: %d\n",
-			   __func__, self->line, self->open_count);
-		self->open_count = 0;
+			   __func__, self->line, local_read(&self->open_count));
+		local_set(&self->open_count, 0);
 	}
-	if (self->open_count) {
+	if (local_read(&self->open_count)) {
 		spin_unlock_irqrestore(&self->spinlock, flags);
 
 		IRDA_DEBUG(0, "%s(), open count > 0\n", __func__ );
@@ -561,7 +561,7 @@ static void ircomm_tty_close(struct tty_
 	tty->closing = 0;
 	self->tty = NULL;
 
-	if (self->blocked_open) {
+	if (local_read(&self->blocked_open)) {
 		if (self->close_delay)
 			schedule_timeout_interruptible(self->close_delay);
 		wake_up_interruptible(&self->open_wait);
@@ -1015,7 +1015,7 @@ static void ircomm_tty_hangup(struct tty
 	spin_lock_irqsave(&self->spinlock, flags);
 	self->flags &= ~ASYNC_NORMAL_ACTIVE;
 	self->tty = NULL;
-	self->open_count = 0;
+	local_set(&self->open_count, 0);
 	spin_unlock_irqrestore(&self->spinlock, flags);
 
 	wake_up_interruptible(&self->open_wait);
@@ -1362,7 +1362,7 @@ static void ircomm_tty_line_info(struct
 	seq_putc(m, '\n');
 
 	seq_printf(m, "Role: %s\n", self->client ? "client" : "server");
-	seq_printf(m, "Open count: %d\n", self->open_count);
+	seq_printf(m, "Open count: %d\n", local_read(&self->open_count));
 	seq_printf(m, "Max data size: %d\n", self->max_data_size);
 	seq_printf(m, "Max header size: %d\n", self->max_header_size);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/iucv/af_iucv.c linux-3.2.71-pax/net/iucv/af_iucv.c
--- linux-3.2.71/net/iucv/af_iucv.c	2014-01-03 15:48:45.180070554 +0100
+++ linux-3.2.71-pax/net/iucv/af_iucv.c	2014-01-03 15:48:49.636070316 +0100
@@ -786,10 +786,10 @@ static int iucv_sock_autobind(struct soc
 
 	write_lock_bh(&iucv_sk_list.lock);
 
-	sprintf(name, "%08x", atomic_inc_return(&iucv_sk_list.autobind_name));
+	sprintf(name, "%08x", atomic_inc_return_unchecked(&iucv_sk_list.autobind_name));
 	while (__iucv_get_sock_by_name(name)) {
 		sprintf(name, "%08x",
-			atomic_inc_return(&iucv_sk_list.autobind_name));
+			atomic_inc_return_unchecked(&iucv_sk_list.autobind_name));
 	}
 
 	write_unlock_bh(&iucv_sk_list.lock);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/iucv/iucv.c linux-3.2.71-pax/net/iucv/iucv.c
--- linux-3.2.71/net/iucv/iucv.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/iucv/iucv.c	2013-02-20 01:19:15.974027317 +0100
@@ -690,7 +690,7 @@ static int __cpuinit iucv_cpu_notify(str
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __refdata iucv_cpu_notifier = {
+static struct notifier_block iucv_cpu_notifier = {
 	.notifier_call = iucv_cpu_notify,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/key/af_key.c linux-3.2.71-pax/net/key/af_key.c
--- linux-3.2.71/net/key/af_key.c	2014-01-03 15:48:45.180070554 +0100
+++ linux-3.2.71-pax/net/key/af_key.c	2014-01-03 15:48:49.640070316 +0100
@@ -3020,10 +3020,10 @@ static int pfkey_send_policy_notify(stru
 static u32 get_acqseq(void)
 {
 	u32 res;
-	static atomic_t acqseq;
+	static atomic_unchecked_t acqseq;
 
 	do {
-		res = atomic_inc_return(&acqseq);
+		res = atomic_inc_return_unchecked(&acqseq);
 	} while (!res);
 	return res;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/l2tp/l2tp_ip.c linux-3.2.71-pax/net/l2tp/l2tp_ip.c
--- linux-3.2.71/net/l2tp/l2tp_ip.c	2014-01-03 15:48:45.180070554 +0100
+++ linux-3.2.71-pax/net/l2tp/l2tp_ip.c	2015-04-30 03:10:50.192538034 +0200
@@ -667,7 +667,7 @@ static struct inet_protosw l2tp_ip_proto
 	.no_check	= 0,
 };
 
-static struct net_protocol l2tp_ip_protocol __read_mostly = {
+static const struct net_protocol l2tp_ip_protocol = {
 	.handler	= l2tp_ip_recv,
 };
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/mac80211/ieee80211_i.h linux-3.2.71-pax/net/mac80211/ieee80211_i.h
--- linux-3.2.71/net/mac80211/ieee80211_i.h	2015-05-10 09:22:39.547493165 +0200
+++ linux-3.2.71-pax/net/mac80211/ieee80211_i.h	2015-05-10 09:23:09.595494797 +0200
@@ -27,6 +27,7 @@
 #include <net/ieee80211_radiotap.h>
 #include <net/cfg80211.h>
 #include <net/mac80211.h>
+#include <asm/local.h>
 #include "key.h"
 #include "sta_info.h"
 
@@ -781,7 +782,7 @@ struct ieee80211_local {
 	/* also used to protect ampdu_ac_queue and amdpu_ac_stop_refcnt */
 	spinlock_t queue_stop_reason_lock;
 
-	int open_count;
+	local_t open_count;
 	int monitors, cooked_mntrs;
 	/* number of interfaces with corresponding FIF_ flags */
 	int fif_fcsfail, fif_plcpfail, fif_control, fif_other_bss, fif_pspoll,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/mac80211/iface.c linux-3.2.71-pax/net/mac80211/iface.c
--- linux-3.2.71/net/mac80211/iface.c	2014-12-14 21:13:45.346055348 +0100
+++ linux-3.2.71-pax/net/mac80211/iface.c	2014-12-14 21:41:00.833805780 +0100
@@ -211,7 +211,7 @@ static int ieee80211_do_open(struct net_
 		break;
 	}
 
-	if (local->open_count == 0) {
+	if (local_read(&local->open_count) == 0) {
 		res = drv_start(local);
 		if (res)
 			goto err_del_bss;
@@ -235,7 +235,7 @@ static int ieee80211_do_open(struct net_
 		memcpy(dev->perm_addr, dev->dev_addr, ETH_ALEN);
 
 		if (!is_valid_ether_addr(dev->dev_addr)) {
-			if (!local->open_count)
+			if (!local_read(&local->open_count))
 				drv_stop(local);
 			return -EADDRNOTAVAIL;
 		}
@@ -327,7 +327,7 @@ static int ieee80211_do_open(struct net_
 	mutex_unlock(&local->mtx);
 
 	if (coming_up)
-		local->open_count++;
+		local_inc(&local->open_count);
 
 	if (hw_reconf_flags) {
 		ieee80211_hw_config(local, hw_reconf_flags);
@@ -347,7 +347,7 @@ static int ieee80211_do_open(struct net_
  err_del_interface:
 	drv_remove_interface(local, &sdata->vif);
  err_stop:
-	if (!local->open_count)
+	if (!local_read(&local->open_count))
 		drv_stop(local);
  err_del_bss:
 	sdata->bss = NULL;
@@ -474,7 +474,7 @@ static void ieee80211_do_stop(struct iee
 	}
 
 	if (going_down)
-		local->open_count--;
+		local_dec(&local->open_count);
 
 	switch (sdata->vif.type) {
 	case NL80211_IFTYPE_AP_VLAN:
@@ -548,7 +548,7 @@ static void ieee80211_do_stop(struct iee
 	if (cancel_scan)
 		flush_delayed_work(&local->scan_work);
 
-	if (local->open_count == 0) {
+	if (local_read(&local->open_count) == 0) {
 		if (local->ops->napi_poll)
 			napi_disable(&local->napi);
 		ieee80211_clear_tx_pending(local);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/mac80211/main.c linux-3.2.71-pax/net/mac80211/main.c
--- linux-3.2.71/net/mac80211/main.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/mac80211/main.c	2012-07-04 19:24:48.992063008 +0200
@@ -163,7 +163,7 @@ int ieee80211_hw_config(struct ieee80211
 		local->hw.conf.power_level = power;
 	}
 
-	if (changed && local->open_count) {
+	if (changed && local_read(&local->open_count)) {
 		ret = drv_config(local, changed);
 		/*
 		 * Goal:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/mac80211/pm.c linux-3.2.71-pax/net/mac80211/pm.c
--- linux-3.2.71/net/mac80211/pm.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/mac80211/pm.c	2012-07-04 19:24:48.992063008 +0200
@@ -34,7 +34,7 @@ int __ieee80211_suspend(struct ieee80211
 	struct ieee80211_sub_if_data *sdata;
 	struct sta_info *sta;
 
-	if (!local->open_count)
+	if (!local_read(&local->open_count))
 		goto suspend;
 
 	ieee80211_scan_cancel(local);
@@ -72,7 +72,7 @@ int __ieee80211_suspend(struct ieee80211
 	cancel_work_sync(&local->dynamic_ps_enable_work);
 	del_timer_sync(&local->dynamic_ps_timer);
 
-	local->wowlan = wowlan && local->open_count;
+	local->wowlan = wowlan && local_read(&local->open_count);
 	if (local->wowlan) {
 		int err = drv_suspend(local, wowlan);
 		if (err < 0) {
@@ -129,7 +129,7 @@ int __ieee80211_suspend(struct ieee80211
 	}
 
 	/* stop hardware - this must stop RX */
-	if (local->open_count)
+	if (local_read(&local->open_count))
 		ieee80211_stop_device(local);
 
  suspend:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/mac80211/rate.c linux-3.2.71-pax/net/mac80211/rate.c
--- linux-3.2.71/net/mac80211/rate.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/mac80211/rate.c	2012-07-04 19:24:48.996063009 +0200
@@ -401,7 +401,7 @@ int ieee80211_init_rate_ctrl_alg(struct
 
 	ASSERT_RTNL();
 
-	if (local->open_count)
+	if (local_read(&local->open_count))
 		return -EBUSY;
 
 	if (local->hw.flags & IEEE80211_HW_HAS_RATE_CONTROL) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/mac80211/rc80211_pid_debugfs.c linux-3.2.71-pax/net/mac80211/rc80211_pid_debugfs.c
--- linux-3.2.71/net/mac80211/rc80211_pid_debugfs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/mac80211/rc80211_pid_debugfs.c	2012-07-04 19:24:48.996063009 +0200
@@ -193,7 +193,7 @@ static ssize_t rate_control_pid_events_r
 
 	spin_unlock_irqrestore(&events->lock, status);
 
-	if (copy_to_user(buf, pb, p))
+	if (p > sizeof(pb) || copy_to_user(buf, pb, p))
 		return -EFAULT;
 
 	return p;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/mac80211/util.c linux-3.2.71-pax/net/mac80211/util.c
--- linux-3.2.71/net/mac80211/util.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/mac80211/util.c	2012-07-04 19:24:48.996063009 +0200
@@ -1000,7 +1000,7 @@ int ieee80211_reconfig(struct ieee80211_
 	drv_set_coverage_class(local, hw->wiphy->coverage_class);
 
 	/* everything else happens only if HW was up & running */
-	if (!local->open_count)
+	if (!local_read(&local->open_count))
 		goto wake_up;
 
 	/*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/ipset/ip_set_core.c linux-3.2.71-pax/net/netfilter/ipset/ip_set_core.c
--- linux-3.2.71/net/netfilter/ipset/ip_set_core.c	2015-02-20 12:37:33.245178767 +0100
+++ linux-3.2.71-pax/net/netfilter/ipset/ip_set_core.c	2015-02-20 12:37:41.921178304 +0100
@@ -1685,7 +1685,7 @@ done:
 	return ret;
 }
 
-static struct nf_sockopt_ops so_set __read_mostly = {
+static struct nf_sockopt_ops so_set = {
 	.pf		= PF_INET,
 	.get_optmin	= SO_IP_SET,
 	.get_optmax	= SO_IP_SET + 1,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/ipvs/ip_vs_conn.c linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_conn.c
--- linux-3.2.71/net/netfilter/ipvs/ip_vs_conn.c	2014-11-05 23:20:30.781390061 +0100
+++ linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_conn.c	2014-11-05 23:20:50.557398840 +0100
@@ -556,7 +556,7 @@ ip_vs_bind_dest(struct ip_vs_conn *cp, s
 	/* Increase the refcnt counter of the dest */
 	atomic_inc(&dest->refcnt);
 
-	conn_flags = atomic_read(&dest->conn_flags);
+	conn_flags = atomic_read_unchecked(&dest->conn_flags);
 	if (cp->protocol != IPPROTO_UDP)
 		conn_flags &= ~IP_VS_CONN_F_ONE_PACKET;
 	/* Bind with the destination and its corresponding transmitter */
@@ -868,7 +868,7 @@ ip_vs_conn_new(const struct ip_vs_conn_p
 	atomic_set(&cp->refcnt, 1);
 
 	atomic_set(&cp->n_control, 0);
-	atomic_set(&cp->in_pkts, 0);
+	atomic_set_unchecked(&cp->in_pkts, 0);
 
 	atomic_inc(&ipvs->conn_count);
 	if (flags & IP_VS_CONN_F_NO_CPORT)
@@ -1148,7 +1148,7 @@ static inline int todrop_entry(struct ip
 
 	/* Don't drop the entry if its number of incoming packets is not
 	   located in [0, 8] */
-	i = atomic_read(&cp->in_pkts);
+	i = atomic_read_unchecked(&cp->in_pkts);
 	if (i > 8 || i < 0) return 0;
 
 	if (!todrop_rate[i]) return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/ipvs/ip_vs_core.c linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_core.c
--- linux-3.2.71/net/netfilter/ipvs/ip_vs_core.c	2015-08-07 11:37:20.783789900 +0200
+++ linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_core.c	2015-08-07 11:37:43.035790554 +0200
@@ -562,7 +562,7 @@ int ip_vs_leave(struct ip_vs_service *sv
 		ret = cp->packet_xmit(skb, cp, pd->pp);
 		/* do not touch skb anymore */
 
-		atomic_inc(&cp->in_pkts);
+		atomic_inc_unchecked(&cp->in_pkts);
 		ip_vs_conn_put(cp);
 		return ret;
 	}
@@ -1621,7 +1621,7 @@ ip_vs_in(unsigned int hooknum, struct sk
 	if (cp->flags & IP_VS_CONN_F_ONE_PACKET)
 		pkts = sysctl_sync_threshold(ipvs);
 	else
-		pkts = atomic_add_return(1, &cp->in_pkts);
+		pkts = atomic_add_return_unchecked(1, &cp->in_pkts);
 
 	if ((ipvs->sync_state & IP_VS_STATE_MASTER) &&
 	    cp->protocol == IPPROTO_SCTP) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/ipvs/ip_vs_ctl.c linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_ctl.c
--- linux-3.2.71/net/netfilter/ipvs/ip_vs_ctl.c	2015-08-07 11:37:20.783789900 +0200
+++ linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_ctl.c	2015-08-07 11:37:43.035790554 +0200
@@ -788,7 +788,7 @@ __ip_vs_update_dest(struct ip_vs_service
 		ip_vs_rs_hash(ipvs, dest);
 		write_unlock_bh(&ipvs->rs_lock);
 	}
-	atomic_set(&dest->conn_flags, conn_flags);
+	atomic_set_unchecked(&dest->conn_flags, conn_flags);
 
 	/* bind the service */
 	if (!dest->svc) {
@@ -1666,7 +1666,7 @@ proc_do_sync_mode(ctl_table *table, int
  *	align with netns init in ip_vs_control_net_init()
  */
 
-static struct ctl_table vs_vars[] = {
+static ctl_table_no_const vs_vars[] __read_only = {
 	{
 		.procname	= "amemthresh",
 		.maxlen		= sizeof(int),
@@ -2028,7 +2028,7 @@ static int ip_vs_info_seq_show(struct se
 					   "      %-7s %-6d %-10d %-10d\n",
 					   &dest->addr.in6,
 					   ntohs(dest->port),
-					   ip_vs_fwd_name(atomic_read(&dest->conn_flags)),
+					   ip_vs_fwd_name(atomic_read_unchecked(&dest->conn_flags)),
 					   atomic_read(&dest->weight),
 					   atomic_read(&dest->activeconns),
 					   atomic_read(&dest->inactconns));
@@ -2039,7 +2039,7 @@ static int ip_vs_info_seq_show(struct se
 					   "%-7s %-6d %-10d %-10d\n",
 					   ntohl(dest->addr.ip),
 					   ntohs(dest->port),
-					   ip_vs_fwd_name(atomic_read(&dest->conn_flags)),
+					   ip_vs_fwd_name(atomic_read_unchecked(&dest->conn_flags)),
 					   atomic_read(&dest->weight),
 					   atomic_read(&dest->activeconns),
 					   atomic_read(&dest->inactconns));
@@ -2509,7 +2509,7 @@ __ip_vs_get_dest_entries(struct net *net
 
 			entry.addr = dest->addr.ip;
 			entry.port = dest->port;
-			entry.conn_flags = atomic_read(&dest->conn_flags);
+			entry.conn_flags = atomic_read_unchecked(&dest->conn_flags);
 			entry.weight = atomic_read(&dest->weight);
 			entry.u_threshold = dest->u_threshold;
 			entry.l_threshold = dest->l_threshold;
@@ -3043,7 +3043,7 @@ static int ip_vs_genl_fill_dest(struct s
 	NLA_PUT_U16(skb, IPVS_DEST_ATTR_PORT, dest->port);
 
 	NLA_PUT_U32(skb, IPVS_DEST_ATTR_FWD_METHOD,
-		    atomic_read(&dest->conn_flags) & IP_VS_CONN_F_FWD_MASK);
+		    atomic_read_unchecked(&dest->conn_flags) & IP_VS_CONN_F_FWD_MASK);
 	NLA_PUT_U32(skb, IPVS_DEST_ATTR_WEIGHT, atomic_read(&dest->weight));
 	NLA_PUT_U32(skb, IPVS_DEST_ATTR_U_THRESH, dest->u_threshold);
 	NLA_PUT_U32(skb, IPVS_DEST_ATTR_L_THRESH, dest->l_threshold);
@@ -3626,7 +3626,7 @@ int __net_init ip_vs_control_net_init_sy
 {
 	int idx;
 	struct netns_ipvs *ipvs = net_ipvs(net);
-	struct ctl_table *tbl;
+	ctl_table_no_const *tbl;
 
 	atomic_set(&ipvs->dropentry, 0);
 	spin_lock_init(&ipvs->dropentry_lock);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/ipvs/ip_vs_lblc.c linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_lblc.c
--- linux-3.2.71/net/netfilter/ipvs/ip_vs_lblc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_lblc.c	2013-03-28 01:35:23.540427935 +0100
@@ -115,7 +115,7 @@ struct ip_vs_lblc_table {
  *      IPVS LBLC sysctl table
  */
 #ifdef CONFIG_SYSCTL
-static ctl_table vs_vars_table[] = {
+static ctl_table_no_const vs_vars_table[] __read_only = {
 	{
 		.procname	= "lblc_expiration",
 		.data		= NULL,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/ipvs/ip_vs_lblcr.c linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_lblcr.c
--- linux-3.2.71/net/netfilter/ipvs/ip_vs_lblcr.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_lblcr.c	2013-03-28 01:35:23.544427935 +0100
@@ -288,7 +288,7 @@ struct ip_vs_lblcr_table {
  *      IPVS LBLCR sysctl table
  */
 
-static ctl_table vs_vars_table[] = {
+static ctl_table_no_const vs_vars_table[] __read_only = {
 	{
 		.procname	= "lblcr_expiration",
 		.data		= NULL,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/ipvs/ip_vs_sync.c linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_sync.c
--- linux-3.2.71/net/netfilter/ipvs/ip_vs_sync.c	2015-05-10 09:22:39.619493169 +0200
+++ linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_sync.c	2015-05-10 09:23:09.611494798 +0200
@@ -649,7 +649,7 @@ control:
 	 * i.e only increment in_pkts for Templates.
 	 */
 	if (cp->flags & IP_VS_CONN_F_TEMPLATE) {
-		int pkts = atomic_add_return(1, &cp->in_pkts);
+		int pkts = atomic_add_return_unchecked(1, &cp->in_pkts);
 
 		if (pkts % sysctl_sync_period(ipvs) != 1)
 			return;
@@ -797,7 +797,7 @@ static void ip_vs_proc_conn(struct net *
 
 	if (opt)
 		memcpy(&cp->in_seq, opt, sizeof(*opt));
-	atomic_set(&cp->in_pkts, sysctl_sync_threshold(ipvs));
+	atomic_set_unchecked(&cp->in_pkts, sysctl_sync_threshold(ipvs));
 	cp->state = state;
 	cp->old_state = cp->state;
 	/*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/ipvs/ip_vs_xmit.c linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_xmit.c
--- linux-3.2.71/net/netfilter/ipvs/ip_vs_xmit.c	2014-09-14 14:11:00.374118980 +0200
+++ linux-3.2.71-pax/net/netfilter/ipvs/ip_vs_xmit.c	2014-09-14 14:11:26.134138486 +0200
@@ -1151,7 +1151,7 @@ ip_vs_icmp_xmit(struct sk_buff *skb, str
 		else
 			rc = NF_ACCEPT;
 		/* do not touch skb anymore */
-		atomic_inc(&cp->in_pkts);
+		atomic_inc_unchecked(&cp->in_pkts);
 		goto out;
 	}
 
@@ -1272,7 +1272,7 @@ ip_vs_icmp_xmit_v6(struct sk_buff *skb,
 		else
 			rc = NF_ACCEPT;
 		/* do not touch skb anymore */
-		atomic_inc(&cp->in_pkts);
+		atomic_inc_unchecked(&cp->in_pkts);
 		goto out;
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/nf_conntrack_acct.c linux-3.2.71-pax/net/netfilter/nf_conntrack_acct.c
--- linux-3.2.71/net/netfilter/nf_conntrack_acct.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/netfilter/nf_conntrack_acct.c	2013-03-28 01:35:23.544427935 +0100
@@ -60,7 +60,7 @@ static struct nf_ct_ext_type acct_extend
 #ifdef CONFIG_SYSCTL
 static int nf_conntrack_acct_init_sysctl(struct net *net)
 {
-	struct ctl_table *table;
+	ctl_table_no_const *table;
 
 	table = kmemdup(acct_sysctl_table, sizeof(acct_sysctl_table),
 			GFP_KERNEL);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/nf_conntrack_ecache.c linux-3.2.71-pax/net/netfilter/nf_conntrack_ecache.c
--- linux-3.2.71/net/netfilter/nf_conntrack_ecache.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/netfilter/nf_conntrack_ecache.c	2013-03-28 01:35:23.544427935 +0100
@@ -185,7 +185,7 @@ static struct nf_ct_ext_type event_exten
 #ifdef CONFIG_SYSCTL
 static int nf_conntrack_event_init_sysctl(struct net *net)
 {
-	struct ctl_table *table;
+	ctl_table_no_const *table;
 
 	table = kmemdup(event_sysctl_table, sizeof(event_sysctl_table),
 			GFP_KERNEL);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/nf_conntrack_proto_dccp.c linux-3.2.71-pax/net/netfilter/nf_conntrack_proto_dccp.c
--- linux-3.2.71/net/netfilter/nf_conntrack_proto_dccp.c	2014-04-09 12:13:43.924713383 +0200
+++ linux-3.2.71-pax/net/netfilter/nf_conntrack_proto_dccp.c	2013-08-31 15:31:27.346200879 +0200
@@ -391,7 +391,7 @@ struct dccp_net {
 	unsigned int dccp_timeout[CT_DCCP_MAX + 1];
 #ifdef CONFIG_SYSCTL
 	struct ctl_table_header *sysctl_header;
-	struct ctl_table *sysctl_table;
+	ctl_table_no_const *sysctl_table;
 #endif
 };
 
@@ -459,7 +459,7 @@ static bool dccp_new(struct nf_conn *ct,
 
 out_invalid:
 	if (LOG_INVALID(net, IPPROTO_DCCP))
-		nf_log_packet(nf_ct_l3num(ct), 0, skb, NULL, NULL, NULL, msg);
+		nf_log_packet(nf_ct_l3num(ct), 0, skb, NULL, NULL, NULL, "%s", msg);
 	return false;
 }
 
@@ -612,7 +612,7 @@ static int dccp_error(struct net *net, s
 
 out_invalid:
 	if (LOG_INVALID(net, IPPROTO_DCCP))
-		nf_log_packet(pf, 0, skb, NULL, NULL, NULL, msg);
+		nf_log_packet(pf, 0, skb, NULL, NULL, NULL, "%s", msg);
 	return -NF_ACCEPT;
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/nf_conntrack_standalone.c linux-3.2.71-pax/net/netfilter/nf_conntrack_standalone.c
--- linux-3.2.71/net/netfilter/nf_conntrack_standalone.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/netfilter/nf_conntrack_standalone.c	2013-03-28 01:35:23.548427935 +0100
@@ -475,7 +475,7 @@ static struct ctl_path nf_ct_path[] = {
 
 static int nf_conntrack_standalone_init_sysctl(struct net *net)
 {
-	struct ctl_table *table;
+	ctl_table_no_const *table;
 
 	if (net_eq(net, &init_net)) {
 		nf_ct_netfilter_header =
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/nf_conntrack_timestamp.c linux-3.2.71-pax/net/netfilter/nf_conntrack_timestamp.c
--- linux-3.2.71/net/netfilter/nf_conntrack_timestamp.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/netfilter/nf_conntrack_timestamp.c	2013-03-28 01:35:23.552427935 +0100
@@ -42,7 +42,7 @@ static struct nf_ct_ext_type tstamp_exte
 #ifdef CONFIG_SYSCTL
 static int nf_conntrack_tstamp_init_sysctl(struct net *net)
 {
-	struct ctl_table *table;
+	ctl_table_no_const *table;
 
 	table = kmemdup(tstamp_sysctl_table, sizeof(tstamp_sysctl_table),
 			GFP_KERNEL);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/nf_log.c linux-3.2.71-pax/net/netfilter/nf_log.c
--- linux-3.2.71/net/netfilter/nf_log.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/netfilter/nf_log.c	2013-03-28 02:38:49.620224720 +0100
@@ -222,7 +222,7 @@ static struct ctl_path nf_log_sysctl_pat
 };
 
 static char nf_log_sysctl_fnames[NFPROTO_NUMPROTO-NFPROTO_UNSPEC][3];
-static struct ctl_table nf_log_sysctl_table[NFPROTO_NUMPROTO+1];
+static ctl_table_no_const nf_log_sysctl_table[NFPROTO_NUMPROTO+1] __read_only;
 static struct ctl_table_header *nf_log_dir_header;
 
 static int nf_log_proc_dostring(ctl_table *table, int write,
@@ -253,14 +253,16 @@ static int nf_log_proc_dostring(ctl_tabl
 		rcu_assign_pointer(nf_loggers[tindex], logger);
 		mutex_unlock(&nf_log_mutex);
 	} else {
+		ctl_table_no_const nf_log_table = *table;
+
 		mutex_lock(&nf_log_mutex);
 		logger = rcu_dereference_protected(nf_loggers[tindex],
 						   lockdep_is_held(&nf_log_mutex));
 		if (!logger)
-			table->data = "NONE";
+			nf_log_table.data = "NONE";
 		else
-			table->data = logger->name;
-		r = proc_dostring(table, write, buffer, lenp, ppos);
+			nf_log_table.data = logger->name;
+		r = proc_dostring(&nf_log_table, write, buffer, lenp, ppos);
 		mutex_unlock(&nf_log_mutex);
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/nfnetlink_log.c linux-3.2.71-pax/net/netfilter/nfnetlink_log.c
--- linux-3.2.71/net/netfilter/nfnetlink_log.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/netfilter/nfnetlink_log.c	2012-07-04 19:24:49.000063009 +0200
@@ -70,7 +70,7 @@ struct nfulnl_instance {
 };
 
 static DEFINE_SPINLOCK(instances_lock);
-static atomic_t global_seq;
+static atomic_unchecked_t global_seq;
 
 #define INSTANCE_BUCKETS	16
 static struct hlist_head instance_table[INSTANCE_BUCKETS];
@@ -502,7 +502,7 @@ __build_packet_message(struct nfulnl_ins
 	/* global sequence number */
 	if (inst->flags & NFULNL_CFG_F_SEQ_GLOBAL)
 		NLA_PUT_BE32(inst->skb, NFULA_SEQ_GLOBAL,
-			     htonl(atomic_inc_return(&global_seq)));
+			     htonl(atomic_inc_return_unchecked(&global_seq)));
 
 	if (data_len) {
 		struct nlattr *nla;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/nf_sockopt.c linux-3.2.71-pax/net/netfilter/nf_sockopt.c
--- linux-3.2.71/net/netfilter/nf_sockopt.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/netfilter/nf_sockopt.c	2013-03-28 01:35:23.552427935 +0100
@@ -45,7 +45,7 @@ int nf_register_sockopt(struct nf_sockop
 		}
 	}
 
-	list_add(&reg->list, &nf_sockopts);
+	pax_list_add((struct list_head *)&reg->list, &nf_sockopts);
 out:
 	mutex_unlock(&nf_sockopt_mutex);
 	return ret;
@@ -55,7 +55,7 @@ EXPORT_SYMBOL(nf_register_sockopt);
 void nf_unregister_sockopt(struct nf_sockopt_ops *reg)
 {
 	mutex_lock(&nf_sockopt_mutex);
-	list_del(&reg->list);
+	pax_list_del((struct list_head *)&reg->list);
 	mutex_unlock(&nf_sockopt_mutex);
 }
 EXPORT_SYMBOL(nf_unregister_sockopt);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netfilter/xt_statistic.c linux-3.2.71-pax/net/netfilter/xt_statistic.c
--- linux-3.2.71/net/netfilter/xt_statistic.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/netfilter/xt_statistic.c	2012-07-04 19:24:49.004063008 +0200
@@ -19,7 +19,7 @@
 #include <linux/module.h>
 
 struct xt_statistic_priv {
-	atomic_t count;
+	atomic_unchecked_t count;
 } ____cacheline_aligned_in_smp;
 
 MODULE_LICENSE("GPL");
@@ -42,9 +42,9 @@ statistic_mt(const struct sk_buff *skb,
 		break;
 	case XT_STATISTIC_MODE_NTH:
 		do {
-			oval = atomic_read(&info->master->count);
+			oval = atomic_read_unchecked(&info->master->count);
 			nval = (oval == info->u.nth.every) ? 0 : oval + 1;
-		} while (atomic_cmpxchg(&info->master->count, oval, nval) != oval);
+		} while (atomic_cmpxchg_unchecked(&info->master->count, oval, nval) != oval);
 		if (nval == 0)
 			ret = !ret;
 		break;
@@ -64,7 +64,7 @@ static int statistic_mt_check(const stru
 	info->master = kzalloc(sizeof(*info->master), GFP_KERNEL);
 	if (info->master == NULL)
 		return -ENOMEM;
-	atomic_set(&info->master->count, info->u.nth.count);
+	atomic_set_unchecked(&info->master->count, info->u.nth.count);
 
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netlink/af_netlink.c linux-3.2.71-pax/net/netlink/af_netlink.c
--- linux-3.2.71/net/netlink/af_netlink.c	2014-01-03 15:48:45.184070554 +0100
+++ linux-3.2.71-pax/net/netlink/af_netlink.c	2014-01-03 15:48:49.644070316 +0100
@@ -753,7 +753,7 @@ static void netlink_overrun(struct sock
 			sk->sk_error_report(sk);
 		}
 	}
-	atomic_inc(&sk->sk_drops);
+	atomic_inc_unchecked(&sk->sk_drops);
 }
 
 static struct sock *netlink_getsockbypid(struct sock *ssk, u32 pid)
@@ -2011,7 +2011,7 @@ static int netlink_seq_show(struct seq_f
 			   sk_wmem_alloc_get(s),
 			   nlk->cb,
 			   atomic_read(&s->sk_refcnt),
-			   atomic_read(&s->sk_drops),
+			   atomic_read_unchecked(&s->sk_drops),
 			   sock_i_ino(s)
 			);
 
@@ -2118,7 +2118,7 @@ static void __init netlink_add_usersock_
 	netlink_table_ungrab();
 }
 
-static struct pernet_operations __net_initdata netlink_net_ops = {
+static struct pernet_operations __net_initconst netlink_net_ops = {
 	.init = netlink_net_init,
 	.exit = netlink_net_exit,
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/netlink/genetlink.c linux-3.2.71-pax/net/netlink/genetlink.c
--- linux-3.2.71/net/netlink/genetlink.c	2013-04-10 12:38:44.614744750 +0200
+++ linux-3.2.71-pax/net/netlink/genetlink.c	2013-04-10 12:38:51.914744360 +0200
@@ -288,18 +288,20 @@ int genl_register_ops(struct genl_family
 		goto errout;
 	}
 
+	pax_open_kernel();
 	if (ops->dumpit)
-		ops->flags |= GENL_CMD_CAP_DUMP;
+		*(unsigned int *)&ops->flags |= GENL_CMD_CAP_DUMP;
 	if (ops->doit)
-		ops->flags |= GENL_CMD_CAP_DO;
+		*(unsigned int *)&ops->flags |= GENL_CMD_CAP_DO;
 	if (ops->policy)
-		ops->flags |= GENL_CMD_CAP_HASPOL;
+		*(unsigned int *)&ops->flags |= GENL_CMD_CAP_HASPOL;
+	pax_close_kernel();
 
 	genl_lock();
-	list_add_tail(&ops->ops_list, &family->ops_list);
+	pax_list_add_tail((struct list_head *)&ops->ops_list, &family->ops_list);
 	genl_unlock();
 
-	genl_ctrl_event(CTRL_CMD_NEWOPS, ops);
+	genl_ctrl_event(CTRL_CMD_NEWOPS, (void *)ops);
 	err = 0;
 errout:
 	return err;
@@ -329,9 +331,9 @@ int genl_unregister_ops(struct genl_fami
 	genl_lock();
 	list_for_each_entry(rc, &family->ops_list, ops_list) {
 		if (rc == ops) {
-			list_del(&ops->ops_list);
+			pax_list_del((struct list_head *)&ops->ops_list);
 			genl_unlock();
-			genl_ctrl_event(CTRL_CMD_DELOPS, ops);
+			genl_ctrl_event(CTRL_CMD_DELOPS, (void *)ops);
 			return 0;
 		}
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/packet/af_packet.c linux-3.2.71-pax/net/packet/af_packet.c
--- linux-3.2.71/net/packet/af_packet.c	2015-08-07 11:37:20.783789900 +0200
+++ linux-3.2.71-pax/net/packet/af_packet.c	2015-08-07 11:37:43.035790554 +0200
@@ -1664,7 +1664,7 @@ static int packet_rcv(struct sk_buff *sk
 
 	spin_lock(&sk->sk_receive_queue.lock);
 	po->stats.tp_packets++;
-	skb->dropcount = atomic_read(&sk->sk_drops);
+	skb->dropcount = atomic_read_unchecked(&sk->sk_drops);
 	__skb_queue_tail(&sk->sk_receive_queue, skb);
 	spin_unlock(&sk->sk_receive_queue.lock);
 	sk->sk_data_ready(sk, skb->len);
@@ -1673,7 +1673,7 @@ static int packet_rcv(struct sk_buff *sk
 drop_n_acct:
 	spin_lock(&sk->sk_receive_queue.lock);
 	po->stats.tp_drops++;
-	atomic_inc(&sk->sk_drops);
+	atomic_inc_unchecked(&sk->sk_drops);
 	spin_unlock(&sk->sk_receive_queue.lock);
 
 drop_n_restore:
@@ -2609,6 +2609,7 @@ out:
 
 static int packet_recv_error(struct sock *sk, struct msghdr *msg, int len)
 {
+	struct sock_extended_err ee;
 	struct sock_exterr_skb *serr;
 	struct sk_buff *skb, *skb2;
 	int copied, err;
@@ -2630,8 +2631,9 @@ static int packet_recv_error(struct sock
 	sock_recv_timestamp(msg, sk, skb);
 
 	serr = SKB_EXT_ERR(skb);
+	ee = serr->ee;
 	put_cmsg(msg, SOL_PACKET, PACKET_TX_TIMESTAMP,
-		 sizeof(serr->ee), &serr->ee);
+		 sizeof ee, &ee);
 
 	msg->msg_flags |= MSG_ERRQUEUE;
 	err = copied;
@@ -3259,7 +3261,7 @@ static int packet_getsockopt(struct sock
 	case PACKET_HDRLEN:
 		if (len > sizeof(int))
 			len = sizeof(int);
-		if (copy_from_user(&val, optval, len))
+		if (len > sizeof(val) || copy_from_user(&val, optval, len))
 			return -EFAULT;
 		switch (val) {
 		case TPACKET_V1:
@@ -3309,7 +3311,7 @@ static int packet_getsockopt(struct sock
 
 	if (put_user(len, optlen))
 		return -EFAULT;
-	if (copy_to_user(optval, data, len))
+	if (len > sizeof(st) || copy_to_user(optval, data, len))
 		return -EFAULT;
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/phonet/pep.c linux-3.2.71-pax/net/phonet/pep.c
--- linux-3.2.71/net/phonet/pep.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/phonet/pep.c	2012-07-04 19:24:49.004063008 +0200
@@ -388,7 +388,7 @@ static int pipe_do_rcv(struct sock *sk,
 
 	case PNS_PEP_CTRL_REQ:
 		if (skb_queue_len(&pn->ctrlreq_queue) >= PNPIPE_CTRLREQ_MAX) {
-			atomic_inc(&sk->sk_drops);
+			atomic_inc_unchecked(&sk->sk_drops);
 			break;
 		}
 		__skb_pull(skb, 4);
@@ -409,7 +409,7 @@ static int pipe_do_rcv(struct sock *sk,
 		}
 
 		if (pn->rx_credits == 0) {
-			atomic_inc(&sk->sk_drops);
+			atomic_inc_unchecked(&sk->sk_drops);
 			err = -ENOBUFS;
 			break;
 		}
@@ -557,7 +557,7 @@ static int pipe_handler_do_rcv(struct so
 		}
 
 		if (pn->rx_credits == 0) {
-			atomic_inc(&sk->sk_drops);
+			atomic_inc_unchecked(&sk->sk_drops);
 			err = NET_RX_DROP;
 			break;
 		}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/phonet/socket.c linux-3.2.71-pax/net/phonet/socket.c
--- linux-3.2.71/net/phonet/socket.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/phonet/socket.c	2012-07-04 19:24:49.008063008 +0200
@@ -614,7 +614,7 @@ static int pn_sock_seq_show(struct seq_f
 			sk_wmem_alloc_get(sk), sk_rmem_alloc_get(sk),
 			sock_i_uid(sk), sock_i_ino(sk),
 			atomic_read(&sk->sk_refcnt), sk,
-			atomic_read(&sk->sk_drops), &len);
+			atomic_read_unchecked(&sk->sk_drops), &len);
 	}
 	seq_printf(seq, "%*s\n", 127 - len, "");
 	return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/phonet/sysctl.c linux-3.2.71-pax/net/phonet/sysctl.c
--- linux-3.2.71/net/phonet/sysctl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/phonet/sysctl.c	2013-03-28 01:35:23.556427934 +0100
@@ -62,7 +62,7 @@ static int proc_local_port_range(ctl_tab
 {
 	int ret;
 	int range[2] = {local_port_range[0], local_port_range[1]};
-	ctl_table tmp = {
+	ctl_table_no_const tmp = {
 		.data = &range,
 		.maxlen = sizeof(range),
 		.mode = table->mode,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rds/cong.c linux-3.2.71-pax/net/rds/cong.c
--- linux-3.2.71/net/rds/cong.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rds/cong.c	2012-07-04 19:24:49.008063008 +0200
@@ -78,7 +78,7 @@
  * finds that the saved generation number is smaller than the global generation
  * number, it wakes up the process.
  */
-static atomic_t		rds_cong_generation = ATOMIC_INIT(0);
+static atomic_unchecked_t		rds_cong_generation = ATOMIC_INIT(0);
 
 /*
  * Congestion monitoring
@@ -233,7 +233,7 @@ void rds_cong_map_updated(struct rds_con
 	rdsdebug("waking map %p for %pI4\n",
 	  map, &map->m_addr);
 	rds_stats_inc(s_cong_update_received);
-	atomic_inc(&rds_cong_generation);
+	atomic_inc_unchecked(&rds_cong_generation);
 	if (waitqueue_active(&map->m_waitq))
 		wake_up(&map->m_waitq);
 	if (waitqueue_active(&rds_poll_waitq))
@@ -259,7 +259,7 @@ EXPORT_SYMBOL_GPL(rds_cong_map_updated);
 
 int rds_cong_updated_since(unsigned long *recent)
 {
-	unsigned long gen = atomic_read(&rds_cong_generation);
+	unsigned long gen = atomic_read_unchecked(&rds_cong_generation);
 
 	if (likely(*recent == gen))
 		return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rds/ib_cm.c linux-3.2.71-pax/net/rds/ib_cm.c
--- linux-3.2.71/net/rds/ib_cm.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rds/ib_cm.c	2012-07-04 19:24:49.008063008 +0200
@@ -718,7 +718,7 @@ void rds_ib_conn_shutdown(struct rds_con
 	/* Clear the ACK state */
 	clear_bit(IB_ACK_IN_FLIGHT, &ic->i_ack_flags);
 #ifdef KERNEL_HAS_ATOMIC64
-	atomic64_set(&ic->i_ack_next, 0);
+	atomic64_set_unchecked(&ic->i_ack_next, 0);
 #else
 	ic->i_ack_next = 0;
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rds/ib.h linux-3.2.71-pax/net/rds/ib.h
--- linux-3.2.71/net/rds/ib.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rds/ib.h	2012-07-04 19:24:49.008063008 +0200
@@ -128,7 +128,7 @@ struct rds_ib_connection {
 	/* sending acks */
 	unsigned long		i_ack_flags;
 #ifdef KERNEL_HAS_ATOMIC64
-	atomic64_t		i_ack_next;	/* next ACK to send */
+	atomic64_unchecked_t	i_ack_next;	/* next ACK to send */
 #else
 	spinlock_t		i_ack_lock;	/* protect i_ack_next */
 	u64			i_ack_next;	/* next ACK to send */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rds/ib_recv.c linux-3.2.71-pax/net/rds/ib_recv.c
--- linux-3.2.71/net/rds/ib_recv.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rds/ib_recv.c	2012-07-04 19:24:49.008063008 +0200
@@ -592,7 +592,7 @@ static u64 rds_ib_get_ack(struct rds_ib_
 static void rds_ib_set_ack(struct rds_ib_connection *ic, u64 seq,
 				int ack_required)
 {
-	atomic64_set(&ic->i_ack_next, seq);
+	atomic64_set_unchecked(&ic->i_ack_next, seq);
 	if (ack_required) {
 		smp_mb__before_clear_bit();
 		set_bit(IB_ACK_REQUESTED, &ic->i_ack_flags);
@@ -604,7 +604,7 @@ static u64 rds_ib_get_ack(struct rds_ib_
 	clear_bit(IB_ACK_REQUESTED, &ic->i_ack_flags);
 	smp_mb__after_clear_bit();
 
-	return atomic64_read(&ic->i_ack_next);
+	return atomic64_read_unchecked(&ic->i_ack_next);
 }
 #endif
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rds/iw_cm.c linux-3.2.71-pax/net/rds/iw_cm.c
--- linux-3.2.71/net/rds/iw_cm.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rds/iw_cm.c	2012-07-04 19:24:49.012063009 +0200
@@ -663,7 +663,7 @@ void rds_iw_conn_shutdown(struct rds_con
 	/* Clear the ACK state */
 	clear_bit(IB_ACK_IN_FLIGHT, &ic->i_ack_flags);
 #ifdef KERNEL_HAS_ATOMIC64
-	atomic64_set(&ic->i_ack_next, 0);
+	atomic64_set_unchecked(&ic->i_ack_next, 0);
 #else
 	ic->i_ack_next = 0;
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rds/iw.h linux-3.2.71-pax/net/rds/iw.h
--- linux-3.2.71/net/rds/iw.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rds/iw.h	2012-07-04 19:24:49.012063009 +0200
@@ -134,7 +134,7 @@ struct rds_iw_connection {
 	/* sending acks */
 	unsigned long		i_ack_flags;
 #ifdef KERNEL_HAS_ATOMIC64
-	atomic64_t		i_ack_next;	/* next ACK to send */
+	atomic64_unchecked_t	i_ack_next;	/* next ACK to send */
 #else
 	spinlock_t		i_ack_lock;	/* protect i_ack_next */
 	u64			i_ack_next;	/* next ACK to send */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rds/iw_recv.c linux-3.2.71-pax/net/rds/iw_recv.c
--- linux-3.2.71/net/rds/iw_recv.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rds/iw_recv.c	2012-07-04 19:24:49.012063009 +0200
@@ -427,7 +427,7 @@ static u64 rds_iw_get_ack(struct rds_iw_
 static void rds_iw_set_ack(struct rds_iw_connection *ic, u64 seq,
 				int ack_required)
 {
-	atomic64_set(&ic->i_ack_next, seq);
+	atomic64_set_unchecked(&ic->i_ack_next, seq);
 	if (ack_required) {
 		smp_mb__before_clear_bit();
 		set_bit(IB_ACK_REQUESTED, &ic->i_ack_flags);
@@ -439,7 +439,7 @@ static u64 rds_iw_get_ack(struct rds_iw_
 	clear_bit(IB_ACK_REQUESTED, &ic->i_ack_flags);
 	smp_mb__after_clear_bit();
 
-	return atomic64_read(&ic->i_ack_next);
+	return atomic64_read_unchecked(&ic->i_ack_next);
 }
 #endif
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rds/rds.h linux-3.2.71-pax/net/rds/rds.h
--- linux-3.2.71/net/rds/rds.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rds/rds.h	2013-03-28 01:35:23.556427934 +0100
@@ -449,7 +449,7 @@ struct rds_transport {
 	void (*sync_mr)(void *trans_private, int direction);
 	void (*free_mr)(void *trans_private, int invalidate);
 	void (*flush_mrs)(void);
-};
+} __do_const;
 
 struct rds_sock {
 	struct sock		rs_sk;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rds/tcp.c linux-3.2.71-pax/net/rds/tcp.c
--- linux-3.2.71/net/rds/tcp.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rds/tcp.c	2012-07-04 19:24:49.016063009 +0200
@@ -59,7 +59,7 @@ void rds_tcp_nonagle(struct socket *sock
 	int val = 1;
 
 	set_fs(KERNEL_DS);
-	sock->ops->setsockopt(sock, SOL_TCP, TCP_NODELAY, (char __user *)&val,
+	sock->ops->setsockopt(sock, SOL_TCP, TCP_NODELAY, (char __force_user *)&val,
 			      sizeof(val));
 	set_fs(oldfs);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rds/tcp_send.c linux-3.2.71-pax/net/rds/tcp_send.c
--- linux-3.2.71/net/rds/tcp_send.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rds/tcp_send.c	2012-07-04 19:24:49.016063009 +0200
@@ -43,7 +43,7 @@ static void rds_tcp_cork(struct socket *
 
 	oldfs = get_fs();
 	set_fs(KERNEL_DS);
-	sock->ops->setsockopt(sock, SOL_TCP, TCP_CORK, (char __user *)&val,
+	sock->ops->setsockopt(sock, SOL_TCP, TCP_CORK, (char __force_user *)&val,
 			      sizeof(val));
 	set_fs(oldfs);
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/af_rxrpc.c linux-3.2.71-pax/net/rxrpc/af_rxrpc.c
--- linux-3.2.71/net/rxrpc/af_rxrpc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/af_rxrpc.c	2012-07-04 19:24:49.016063009 +0200
@@ -39,7 +39,7 @@ static const struct proto_ops rxrpc_rpc_
 __be32 rxrpc_epoch;
 
 /* current debugging ID */
-atomic_t rxrpc_debug_id;
+atomic_unchecked_t rxrpc_debug_id;
 
 /* count of skbs currently in use */
 atomic_t rxrpc_n_skbs;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/ar-ack.c linux-3.2.71-pax/net/rxrpc/ar-ack.c
--- linux-3.2.71/net/rxrpc/ar-ack.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/ar-ack.c	2012-07-04 19:24:49.016063009 +0200
@@ -175,7 +175,7 @@ static void rxrpc_resend(struct rxrpc_ca
 
 	_enter("{%d,%d,%d,%d},",
 	       call->acks_hard, call->acks_unacked,
-	       atomic_read(&call->sequence),
+	       atomic_read_unchecked(&call->sequence),
 	       CIRC_CNT(call->acks_head, call->acks_tail, call->acks_winsz));
 
 	stop = 0;
@@ -199,7 +199,7 @@ static void rxrpc_resend(struct rxrpc_ca
 
 			/* each Tx packet has a new serial number */
 			sp->hdr.serial =
-				htonl(atomic_inc_return(&call->conn->serial));
+				htonl(atomic_inc_return_unchecked(&call->conn->serial));
 
 			hdr = (struct rxrpc_header *) txb->head;
 			hdr->serial = sp->hdr.serial;
@@ -403,7 +403,7 @@ static void rxrpc_rotate_tx_window(struc
  */
 static void rxrpc_clear_tx_window(struct rxrpc_call *call)
 {
-	rxrpc_rotate_tx_window(call, atomic_read(&call->sequence));
+	rxrpc_rotate_tx_window(call, atomic_read_unchecked(&call->sequence));
 }
 
 /*
@@ -629,7 +629,7 @@ process_further:
 
 		latest = ntohl(sp->hdr.serial);
 		hard = ntohl(ack.firstPacket);
-		tx = atomic_read(&call->sequence);
+		tx = atomic_read_unchecked(&call->sequence);
 
 		_proto("Rx ACK %%%u { m=%hu f=#%u p=#%u s=%%%u r=%s n=%u }",
 		       latest,
@@ -1161,7 +1161,7 @@ void rxrpc_process_call(struct work_stru
 	goto maybe_reschedule;
 
 send_ACK_with_skew:
-	ack.maxSkew = htons(atomic_read(&call->conn->hi_serial) -
+	ack.maxSkew = htons(atomic_read_unchecked(&call->conn->hi_serial) -
 			    ntohl(ack.serial));
 send_ACK:
 	mtu = call->conn->trans->peer->if_mtu;
@@ -1173,7 +1173,7 @@ send_ACK:
 	ackinfo.rxMTU	= htonl(5692);
 	ackinfo.jumbo_max = htonl(4);
 
-	hdr.serial = htonl(atomic_inc_return(&call->conn->serial));
+	hdr.serial = htonl(atomic_inc_return_unchecked(&call->conn->serial));
 	_proto("Tx ACK %%%u { m=%hu f=#%u p=#%u s=%%%u r=%s n=%u }",
 	       ntohl(hdr.serial),
 	       ntohs(ack.maxSkew),
@@ -1191,7 +1191,7 @@ send_ACK:
 send_message:
 	_debug("send message");
 
-	hdr.serial = htonl(atomic_inc_return(&call->conn->serial));
+	hdr.serial = htonl(atomic_inc_return_unchecked(&call->conn->serial));
 	_proto("Tx %s %%%u", rxrpc_pkts[hdr.type], ntohl(hdr.serial));
 send_message_2:
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/ar-call.c linux-3.2.71-pax/net/rxrpc/ar-call.c
--- linux-3.2.71/net/rxrpc/ar-call.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/ar-call.c	2012-07-04 19:24:49.016063009 +0200
@@ -83,7 +83,7 @@ static struct rxrpc_call *rxrpc_alloc_ca
 	spin_lock_init(&call->lock);
 	rwlock_init(&call->state_lock);
 	atomic_set(&call->usage, 1);
-	call->debug_id = atomic_inc_return(&rxrpc_debug_id);
+	call->debug_id = atomic_inc_return_unchecked(&rxrpc_debug_id);
 	call->state = RXRPC_CALL_CLIENT_SEND_REQUEST;
 
 	memset(&call->sock_node, 0xed, sizeof(call->sock_node));
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/ar-connection.c linux-3.2.71-pax/net/rxrpc/ar-connection.c
--- linux-3.2.71/net/rxrpc/ar-connection.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/ar-connection.c	2012-07-04 19:24:49.016063009 +0200
@@ -206,7 +206,7 @@ static struct rxrpc_connection *rxrpc_al
 		rwlock_init(&conn->lock);
 		spin_lock_init(&conn->state_lock);
 		atomic_set(&conn->usage, 1);
-		conn->debug_id = atomic_inc_return(&rxrpc_debug_id);
+		conn->debug_id = atomic_inc_return_unchecked(&rxrpc_debug_id);
 		conn->avail_calls = RXRPC_MAXCALLS;
 		conn->size_align = 4;
 		conn->header_size = sizeof(struct rxrpc_header);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/ar-connevent.c linux-3.2.71-pax/net/rxrpc/ar-connevent.c
--- linux-3.2.71/net/rxrpc/ar-connevent.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/ar-connevent.c	2012-07-04 19:24:49.020063009 +0200
@@ -109,7 +109,7 @@ static int rxrpc_abort_connection(struct
 
 	len = iov[0].iov_len + iov[1].iov_len;
 
-	hdr.serial = htonl(atomic_inc_return(&conn->serial));
+	hdr.serial = htonl(atomic_inc_return_unchecked(&conn->serial));
 	_proto("Tx CONN ABORT %%%u { %d }", ntohl(hdr.serial), abort_code);
 
 	ret = kernel_sendmsg(conn->trans->local->socket, &msg, iov, 2, len);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/ar-input.c linux-3.2.71-pax/net/rxrpc/ar-input.c
--- linux-3.2.71/net/rxrpc/ar-input.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/ar-input.c	2012-07-04 19:24:49.020063009 +0200
@@ -340,9 +340,9 @@ void rxrpc_fast_process_packet(struct rx
 	/* track the latest serial number on this connection for ACK packet
 	 * information */
 	serial = ntohl(sp->hdr.serial);
-	hi_serial = atomic_read(&call->conn->hi_serial);
+	hi_serial = atomic_read_unchecked(&call->conn->hi_serial);
 	while (serial > hi_serial)
-		hi_serial = atomic_cmpxchg(&call->conn->hi_serial, hi_serial,
+		hi_serial = atomic_cmpxchg_unchecked(&call->conn->hi_serial, hi_serial,
 					   serial);
 
 	/* request ACK generation for any ACK or DATA packet that requests
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/ar-internal.h linux-3.2.71-pax/net/rxrpc/ar-internal.h
--- linux-3.2.71/net/rxrpc/ar-internal.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/ar-internal.h	2012-07-04 19:24:49.020063009 +0200
@@ -272,8 +272,8 @@ struct rxrpc_connection {
 	int			error;		/* error code for local abort */
 	int			debug_id;	/* debug ID for printks */
 	unsigned		call_counter;	/* call ID counter */
-	atomic_t		serial;		/* packet serial number counter */
-	atomic_t		hi_serial;	/* highest serial number received */
+	atomic_unchecked_t	serial;		/* packet serial number counter */
+	atomic_unchecked_t	hi_serial;	/* highest serial number received */
 	u8			avail_calls;	/* number of calls available */
 	u8			size_align;	/* data size alignment (for security) */
 	u8			header_size;	/* rxrpc + security header size */
@@ -346,7 +346,7 @@ struct rxrpc_call {
 	spinlock_t		lock;
 	rwlock_t		state_lock;	/* lock for state transition */
 	atomic_t		usage;
-	atomic_t		sequence;	/* Tx data packet sequence counter */
+	atomic_unchecked_t	sequence;	/* Tx data packet sequence counter */
 	u32			abort_code;	/* local/remote abort code */
 	enum {					/* current state of call */
 		RXRPC_CALL_CLIENT_SEND_REQUEST,	/* - client sending request phase */
@@ -420,7 +420,7 @@ static inline void rxrpc_abort_call(stru
  */
 extern atomic_t rxrpc_n_skbs;
 extern __be32 rxrpc_epoch;
-extern atomic_t rxrpc_debug_id;
+extern atomic_unchecked_t rxrpc_debug_id;
 extern struct workqueue_struct *rxrpc_workqueue;
 
 /*
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/ar-key.c linux-3.2.71-pax/net/rxrpc/ar-key.c
--- linux-3.2.71/net/rxrpc/ar-key.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/ar-key.c	2013-11-24 12:06:53.669189856 +0100
@@ -232,7 +232,7 @@ static int rxrpc_krb5_decode_principal(s
 	if (toklen <= (n_parts + 1) * 4)
 		return -EINVAL;
 
-	princ->name_parts = kcalloc(sizeof(char *), n_parts, GFP_KERNEL);
+	princ->name_parts = kcalloc(n_parts, sizeof(char *), GFP_KERNEL);
 	if (!princ->name_parts)
 		return -ENOMEM;
 
@@ -356,7 +356,7 @@ static int rxrpc_krb5_decode_tagged_arra
 
 		_debug("n_elem %d", n_elem);
 
-		td = kcalloc(sizeof(struct krb5_tagged_data), n_elem,
+		td = kcalloc(n_elem, sizeof(struct krb5_tagged_data),
 			     GFP_KERNEL);
 		if (!td)
 			return -ENOMEM;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/ar-local.c linux-3.2.71-pax/net/rxrpc/ar-local.c
--- linux-3.2.71/net/rxrpc/ar-local.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/ar-local.c	2012-07-04 19:24:49.020063009 +0200
@@ -45,7 +45,7 @@ struct rxrpc_local *rxrpc_alloc_local(st
 		spin_lock_init(&local->lock);
 		rwlock_init(&local->services_lock);
 		atomic_set(&local->usage, 1);
-		local->debug_id = atomic_inc_return(&rxrpc_debug_id);
+		local->debug_id = atomic_inc_return_unchecked(&rxrpc_debug_id);
 		memcpy(&local->srx, srx, sizeof(*srx));
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/ar-output.c linux-3.2.71-pax/net/rxrpc/ar-output.c
--- linux-3.2.71/net/rxrpc/ar-output.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/ar-output.c	2012-07-04 19:24:49.020063009 +0200
@@ -682,9 +682,9 @@ static int rxrpc_send_data(struct kiocb
 			sp->hdr.cid = call->cid;
 			sp->hdr.callNumber = call->call_id;
 			sp->hdr.seq =
-				htonl(atomic_inc_return(&call->sequence));
+				htonl(atomic_inc_return_unchecked(&call->sequence));
 			sp->hdr.serial =
-				htonl(atomic_inc_return(&conn->serial));
+				htonl(atomic_inc_return_unchecked(&conn->serial));
 			sp->hdr.type = RXRPC_PACKET_TYPE_DATA;
 			sp->hdr.userStatus = 0;
 			sp->hdr.securityIndex = conn->security_ix;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/ar-peer.c linux-3.2.71-pax/net/rxrpc/ar-peer.c
--- linux-3.2.71/net/rxrpc/ar-peer.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/ar-peer.c	2012-07-04 19:24:49.020063009 +0200
@@ -72,7 +72,7 @@ static struct rxrpc_peer *rxrpc_alloc_pe
 		INIT_LIST_HEAD(&peer->error_targets);
 		spin_lock_init(&peer->lock);
 		atomic_set(&peer->usage, 1);
-		peer->debug_id = atomic_inc_return(&rxrpc_debug_id);
+		peer->debug_id = atomic_inc_return_unchecked(&rxrpc_debug_id);
 		memcpy(&peer->srx, srx, sizeof(*srx));
 
 		rxrpc_assess_MTU_size(peer);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/ar-proc.c linux-3.2.71-pax/net/rxrpc/ar-proc.c
--- linux-3.2.71/net/rxrpc/ar-proc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/ar-proc.c	2012-07-04 19:24:49.024063009 +0200
@@ -164,8 +164,8 @@ static int rxrpc_connection_seq_show(str
 		   atomic_read(&conn->usage),
 		   rxrpc_conn_states[conn->state],
 		   key_serial(conn->key),
-		   atomic_read(&conn->serial),
-		   atomic_read(&conn->hi_serial));
+		   atomic_read_unchecked(&conn->serial),
+		   atomic_read_unchecked(&conn->hi_serial));
 
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/ar-transport.c linux-3.2.71-pax/net/rxrpc/ar-transport.c
--- linux-3.2.71/net/rxrpc/ar-transport.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/ar-transport.c	2012-07-04 19:24:49.024063009 +0200
@@ -47,7 +47,7 @@ static struct rxrpc_transport *rxrpc_all
 		spin_lock_init(&trans->client_lock);
 		rwlock_init(&trans->conn_lock);
 		atomic_set(&trans->usage, 1);
-		trans->debug_id = atomic_inc_return(&rxrpc_debug_id);
+		trans->debug_id = atomic_inc_return_unchecked(&rxrpc_debug_id);
 
 		if (peer->srx.transport.family == AF_INET) {
 			switch (peer->srx.transport_type) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/rxrpc/rxkad.c linux-3.2.71-pax/net/rxrpc/rxkad.c
--- linux-3.2.71/net/rxrpc/rxkad.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/rxrpc/rxkad.c	2012-07-04 19:24:49.024063009 +0200
@@ -610,7 +610,7 @@ static int rxkad_issue_challenge(struct
 
 	len = iov[0].iov_len + iov[1].iov_len;
 
-	hdr.serial = htonl(atomic_inc_return(&conn->serial));
+	hdr.serial = htonl(atomic_inc_return_unchecked(&conn->serial));
 	_proto("Tx CHALLENGE %%%u", ntohl(hdr.serial));
 
 	ret = kernel_sendmsg(conn->trans->local->socket, &msg, iov, 2, len);
@@ -660,7 +660,7 @@ static int rxkad_send_response(struct rx
 
 	len = iov[0].iov_len + iov[1].iov_len + iov[2].iov_len;
 
-	hdr->serial = htonl(atomic_inc_return(&conn->serial));
+	hdr->serial = htonl(atomic_inc_return_unchecked(&conn->serial));
 	_proto("Tx RESPONSE %%%u", ntohl(hdr->serial));
 
 	ret = kernel_sendmsg(conn->trans->local->socket, &msg, iov, 3, len);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/sctp/ipv6.c linux-3.2.71-pax/net/sctp/ipv6.c
--- linux-3.2.71/net/sctp/ipv6.c	2013-10-27 17:59:58.784642303 +0100
+++ linux-3.2.71-pax/net/sctp/ipv6.c	2013-10-27 18:00:09.608641725 +0100
@@ -961,7 +961,7 @@ static const struct inet6_protocol sctpv
 	.flags        = INET6_PROTO_NOPOLICY | INET6_PROTO_FINAL,
 };
 
-static struct sctp_af sctp_af_inet6 = {
+static struct sctp_af sctp_af_inet6 __read_only = {
 	.sa_family	   = AF_INET6,
 	.sctp_xmit	   = sctp_v6_xmit,
 	.setsockopt	   = ipv6_setsockopt,
@@ -993,7 +993,7 @@ static struct sctp_af sctp_af_inet6 = {
 #endif
 };
 
-static struct sctp_pf sctp_pf_inet6 = {
+static struct sctp_pf sctp_pf_inet6 __read_only = {
 	.event_msgname = sctp_inet6_event_msgname,
 	.skb_msgname   = sctp_inet6_skb_msgname,
 	.af_supported  = sctp_inet6_af_supported,
@@ -1018,7 +1018,7 @@ void sctp_v6_pf_init(void)
 
 void sctp_v6_pf_exit(void)
 {
-	list_del(&sctp_af_inet6.list);
+	pax_list_del(&sctp_af_inet6.list);
 }
 
 /* Initialize IPv6 support and register with socket layer.  */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/sctp/protocol.c linux-3.2.71-pax/net/sctp/protocol.c
--- linux-3.2.71/net/sctp/protocol.c	2014-06-10 10:59:38.814436241 +0200
+++ linux-3.2.71-pax/net/sctp/protocol.c	2014-06-10 10:59:44.194435954 +0200
@@ -867,8 +867,10 @@ int sctp_register_af(struct sctp_af *af)
 		return 0;
 	}
 
+	pax_open_kernel();
 	INIT_LIST_HEAD(&af->list);
-	list_add_tail(&af->list, &sctp_address_families);
+	pax_close_kernel();
+	pax_list_add_tail(&af->list, &sctp_address_families);
 	return 1;
 }
 
@@ -999,7 +1001,7 @@ static inline int sctp_v4_xmit(struct sk
 
 static struct sctp_af sctp_af_inet;
 
-static struct sctp_pf sctp_pf_inet = {
+static struct sctp_pf sctp_pf_inet __read_only = {
 	.event_msgname = sctp_inet_event_msgname,
 	.skb_msgname   = sctp_inet_skb_msgname,
 	.af_supported  = sctp_inet_af_supported,
@@ -1069,7 +1071,7 @@ static const struct net_protocol sctp_pr
 };
 
 /* IPv4 address related functions.  */
-static struct sctp_af sctp_af_inet = {
+static struct sctp_af sctp_af_inet __read_only = {
 	.sa_family	   = AF_INET,
 	.sctp_xmit	   = sctp_v4_xmit,
 	.setsockopt	   = ip_setsockopt,
@@ -1154,7 +1156,7 @@ static void sctp_v4_pf_init(void)
 
 static void sctp_v4_pf_exit(void)
 {
-	list_del(&sctp_af_inet.list);
+	pax_list_del(&sctp_af_inet.list);
 }
 
 static int sctp_v4_protosw_init(void)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/sctp/sm_sideeffect.c linux-3.2.71-pax/net/sctp/sm_sideeffect.c
--- linux-3.2.71/net/sctp/sm_sideeffect.c	2013-10-27 17:59:58.792642303 +0100
+++ linux-3.2.71-pax/net/sctp/sm_sideeffect.c	2013-10-27 18:00:09.608641725 +0100
@@ -441,7 +441,7 @@ static void sctp_generate_sack_event(uns
 	sctp_generate_timeout_event(asoc, SCTP_EVENT_TIMEOUT_SACK);
 }
 
-sctp_timer_event_t *sctp_timer_events[SCTP_NUM_TIMEOUT_TYPES] = {
+sctp_timer_event_t * const sctp_timer_events[SCTP_NUM_TIMEOUT_TYPES] = {
 	NULL,
 	sctp_generate_t1_cookie_event,
 	sctp_generate_t1_init_event,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/sctp/socket.c linux-3.2.71-pax/net/sctp/socket.c
--- linux-3.2.71/net/sctp/socket.c	2015-08-07 11:37:20.783789900 +0200
+++ linux-3.2.71-pax/net/sctp/socket.c	2015-08-07 11:37:43.035790554 +0200
@@ -2192,11 +2192,13 @@ static int sctp_setsockopt_events(struct
 {
 	struct sctp_association *asoc;
 	struct sctp_ulpevent *event;
+	struct sctp_event_subscribe subscribe;
 
 	if (optlen > sizeof(struct sctp_event_subscribe))
 		return -EINVAL;
-	if (copy_from_user(&sctp_sk(sk)->subscribe, optval, optlen))
+	if (copy_from_user(&subscribe, optval, optlen))
 		return -EFAULT;
+	sctp_sk(sk)->subscribe = subscribe;
 
 	/*
 	 * At the time when a user app subscribes to SCTP_SENDER_DRY_EVENT,
@@ -4194,13 +4196,16 @@ static int sctp_getsockopt_disable_fragm
 static int sctp_getsockopt_events(struct sock *sk, int len, char __user *optval,
 				  int __user *optlen)
 {
+	struct sctp_event_subscribe subscribe;
+
 	if (len <= 0)
 		return -EINVAL;
 	if (len > sizeof(struct sctp_event_subscribe))
 		len = sizeof(struct sctp_event_subscribe);
 	if (put_user(len, optlen))
 		return -EFAULT;
-	if (copy_to_user(optval, &sctp_sk(sk)->subscribe, len))
+	subscribe = sctp_sk(sk)->subscribe;
+	if (copy_to_user(optval, &subscribe, len))
 		return -EFAULT;
 	return 0;
 }
@@ -4218,6 +4223,8 @@ static int sctp_getsockopt_events(struct
  */
 static int sctp_getsockopt_autoclose(struct sock *sk, int len, char __user *optval, int __user *optlen)
 {
+	__u32 autoclose;
+
 	/* Applicable to UDP-style socket only */
 	if (sctp_style(sk, TCP))
 		return -EOPNOTSUPP;
@@ -4226,7 +4233,8 @@ static int sctp_getsockopt_autoclose(str
 	len = sizeof(int);
 	if (put_user(len, optlen))
 		return -EFAULT;
-	if (copy_to_user(optval, &sctp_sk(sk)->autoclose, sizeof(int)))
+	autoclose = sctp_sk(sk)->autoclose;
+	if (copy_to_user(optval, &autoclose, sizeof(int)))
 		return -EFAULT;
 	return 0;
 }
@@ -4590,12 +4598,15 @@ static int sctp_getsockopt_delayed_ack(s
  */
 static int sctp_getsockopt_initmsg(struct sock *sk, int len, char __user *optval, int __user *optlen)
 {
+	struct sctp_initmsg initmsg;
+
 	if (len < sizeof(struct sctp_initmsg))
 		return -EINVAL;
 	len = sizeof(struct sctp_initmsg);
 	if (put_user(len, optlen))
 		return -EFAULT;
-	if (copy_to_user(optval, &sctp_sk(sk)->initmsg, len))
+	initmsg = sctp_sk(sk)->initmsg;
+	if (copy_to_user(optval, &initmsg, len))
 		return -EFAULT;
 	return 0;
 }
@@ -4636,6 +4647,8 @@ static int sctp_getsockopt_peer_addrs(st
 		addrlen = sctp_get_af_specific(temp.sa.sa_family)->sockaddr_len;
 		if (space_left < addrlen)
 			return -ENOMEM;
+		if (addrlen > sizeof(temp) || addrlen < 0)
+			return -EFAULT;
 		if (copy_to_user(to, &temp, addrlen))
 			return -EFAULT;
 		to += addrlen;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/socket.c linux-3.2.71-pax/net/socket.c
--- linux-3.2.71/net/socket.c	2015-08-07 11:37:20.783789900 +0200
+++ linux-3.2.71-pax/net/socket.c	2015-08-07 11:37:43.035790554 +0200
@@ -1671,6 +1671,8 @@ SYSCALL_DEFINE3(getpeername, int, fd, st
  *	the protocol.
  */
 
+asmlinkage long sys_sendto(int, void __user *, size_t, unsigned, struct sockaddr __user *, int);
+
 SYSCALL_DEFINE6(sendto, int, fd, void __user *, buff, size_t, len,
 		unsigned, flags, struct sockaddr __user *, addr,
 		int, addr_len)
@@ -1971,7 +1973,7 @@ static int ___sys_sendmsg(struct socket
 		 * checking falls down on this.
 		 */
 		if (copy_from_user(ctl_buf,
-				   (void __user __force *)msg_sys->msg_control,
+				   (void __force_user *)msg_sys->msg_control,
 				   ctl_len))
 			goto out_freectl;
 		msg_sys->msg_control = ctl_buf;
@@ -2151,7 +2153,8 @@ static int ___sys_recvmsg(struct socket
 	/* Save the user-mode address (verify_iovec will change the
 	 * kernel msghdr to use the kernel address space)
 	 */
-	uaddr = (__force void __user *)msg_sys->msg_name;
+
+	uaddr = (void __force_user *)msg_sys->msg_name;
 	uaddr_len = COMPAT_NAMELEN(msg);
 	if (MSG_CMSG_COMPAT & flags)
 		err = verify_compat_iovec(msg_sys, iov,
@@ -2795,9 +2798,9 @@ static int ethtool_ioctl(struct net *net
 	}
 
 	ifr = compat_alloc_user_space(buf_size);
-	rxnfc = (void *)ifr + ALIGN(sizeof(struct ifreq), 8);
+	rxnfc = (void __user *)ifr + ALIGN(sizeof(struct ifreq), 8);
 
-	if (copy_in_user(&ifr->ifr_name, &ifr32->ifr_name, IFNAMSIZ))
+	if (copy_in_user(ifr->ifr_name, ifr32->ifr_name, IFNAMSIZ))
 		return -EFAULT;
 
 	if (put_user(convert_in ? rxnfc : compat_ptr(data),
@@ -2819,12 +2822,12 @@ static int ethtool_ioctl(struct net *net
 			offsetof(struct ethtool_rxnfc, fs.ring_cookie));
 
 		if (copy_in_user(rxnfc, compat_rxnfc,
-				 (void *)(&rxnfc->fs.m_ext + 1) -
-				 (void *)rxnfc) ||
+				 (void __user *)(&rxnfc->fs.m_ext + 1) -
+				 (void __user *)rxnfc) ||
 		    copy_in_user(&rxnfc->fs.ring_cookie,
 				 &compat_rxnfc->fs.ring_cookie,
-				 (void *)(&rxnfc->fs.location + 1) -
-				 (void *)&rxnfc->fs.ring_cookie) ||
+				 (void __user *)(&rxnfc->fs.location + 1) -
+				 (void __user *)&rxnfc->fs.ring_cookie) ||
 		    copy_in_user(&rxnfc->rule_cnt, &compat_rxnfc->rule_cnt,
 				 sizeof(rxnfc->rule_cnt)))
 			return -EFAULT;
@@ -2836,12 +2839,12 @@ static int ethtool_ioctl(struct net *net
 
 	if (convert_out) {
 		if (copy_in_user(compat_rxnfc, rxnfc,
-				 (const void *)(&rxnfc->fs.m_ext + 1) -
-				 (const void *)rxnfc) ||
+				 (const void __user *)(&rxnfc->fs.m_ext + 1) -
+				 (const void __user *)rxnfc) ||
 		    copy_in_user(&compat_rxnfc->fs.ring_cookie,
 				 &rxnfc->fs.ring_cookie,
-				 (const void *)(&rxnfc->fs.location + 1) -
-				 (const void *)&rxnfc->fs.ring_cookie) ||
+				 (const void __user *)(&rxnfc->fs.location + 1) -
+				 (const void __user *)&rxnfc->fs.ring_cookie) ||
 		    copy_in_user(&compat_rxnfc->rule_cnt, &rxnfc->rule_cnt,
 				 sizeof(rxnfc->rule_cnt)))
 			return -EFAULT;
@@ -2911,14 +2914,14 @@ static int bond_ioctl(struct net *net, u
 		old_fs = get_fs();
 		set_fs(KERNEL_DS);
 		err = dev_ioctl(net, cmd,
-				(struct ifreq __user __force *) &kifr);
+				(struct ifreq __force_user *) &kifr);
 		set_fs(old_fs);
 
 		return err;
 	case SIOCBONDSLAVEINFOQUERY:
 	case SIOCBONDINFOQUERY:
 		uifr = compat_alloc_user_space(sizeof(*uifr));
-		if (copy_in_user(&uifr->ifr_name, &ifr32->ifr_name, IFNAMSIZ))
+		if (copy_in_user(uifr->ifr_name, ifr32->ifr_name, IFNAMSIZ))
 			return -EFAULT;
 
 		if (get_user(data, &ifr32->ifr_ifru.ifru_data))
@@ -3020,7 +3023,7 @@ static int compat_sioc_ifmap(struct net
 
 	old_fs = get_fs();
 	set_fs(KERNEL_DS);
-	err = dev_ioctl(net, cmd, (void  __user __force *)&ifr);
+	err = dev_ioctl(net, cmd, (void  __force_user *)&ifr);
 	set_fs(old_fs);
 
 	if (cmd == SIOCGIFMAP && !err) {
@@ -3125,7 +3128,7 @@ static int routing_ioctl(struct net *net
 		ret |= __get_user(rtdev, &(ur4->rt_dev));
 		if (rtdev) {
 			ret |= copy_from_user(devname, compat_ptr(rtdev), 15);
-			r4.rt_dev = (char __user __force *)devname;
+			r4.rt_dev = (char __force_user *)devname;
 			devname[15] = 0;
 		} else
 			r4.rt_dev = NULL;
@@ -3365,8 +3368,8 @@ int kernel_getsockopt(struct socket *soc
 	int __user *uoptlen;
 	int err;
 
-	uoptval = (char __user __force *) optval;
-	uoptlen = (int __user __force *) optlen;
+	uoptval = (char __force_user *) optval;
+	uoptlen = (int __force_user *) optlen;
 
 	set_fs(KERNEL_DS);
 	if (level == SOL_SOCKET)
@@ -3386,7 +3389,7 @@ int kernel_setsockopt(struct socket *soc
 	char __user *uoptval;
 	int err;
 
-	uoptval = (char __user __force *) optval;
+	uoptval = (char __force_user *) optval;
 
 	set_fs(KERNEL_DS);
 	if (level == SOL_SOCKET)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/sunrpc/clnt.c linux-3.2.71-pax/net/sunrpc/clnt.c
--- linux-3.2.71/net/sunrpc/clnt.c	2014-04-02 03:15:45.855672326 +0200
+++ linux-3.2.71-pax/net/sunrpc/clnt.c	2014-04-02 03:15:49.419672136 +0200
@@ -903,7 +903,9 @@ call_start(struct rpc_task *task)
 			(RPC_IS_ASYNC(task) ? "async" : "sync"));
 
 	/* Increment call count */
-	task->tk_msg.rpc_proc->p_count++;
+	pax_open_kernel();
+	(*(unsigned int *)&task->tk_msg.rpc_proc->p_count)++;
+	pax_close_kernel();
 	clnt->cl_stats->rpccnt++;
 	task->tk_action = call_reserve;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/sunrpc/sched.c linux-3.2.71-pax/net/sunrpc/sched.c
--- linux-3.2.71/net/sunrpc/sched.c	2013-06-09 18:04:43.509591744 +0200
+++ linux-3.2.71-pax/net/sunrpc/sched.c	2013-06-09 18:04:48.949591453 +0200
@@ -240,9 +240,9 @@ static int rpc_wait_bit_killable(void *w
 #ifdef RPC_DEBUG
 static void rpc_task_set_debuginfo(struct rpc_task *task)
 {
-	static atomic_t rpc_pid;
+	static atomic_unchecked_t rpc_pid;
 
-	task->tk_pid = atomic_inc_return(&rpc_pid);
+	task->tk_pid = atomic_inc_return_unchecked(&rpc_pid);
 }
 #else
 static inline void rpc_task_set_debuginfo(struct rpc_task *task)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/sunrpc/svcauth_unix.c linux-3.2.71-pax/net/sunrpc/svcauth_unix.c
--- linux-3.2.71/net/sunrpc/svcauth_unix.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/sunrpc/svcauth_unix.c	2013-11-23 18:07:03.941937082 +0100
@@ -602,7 +602,7 @@ struct cache_detail unix_gid_cache = {
 	.alloc		= unix_gid_alloc,
 };
 
-static struct unix_gid *unix_gid_lookup(uid_t uid)
+static struct unix_gid * __intentional_overflow(-1) unix_gid_lookup(uid_t uid)
 {
 	struct unix_gid ug;
 	struct cache_head *ch;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/sunrpc/svc.c linux-3.2.71-pax/net/sunrpc/svc.c
--- linux-3.2.71/net/sunrpc/svc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/sunrpc/svc.c	2013-06-21 20:15:56.166564326 +0200
@@ -732,7 +732,7 @@ svc_set_num_threads(struct svc_serv *ser
 
 		__module_get(serv->sv_module);
 		task = kthread_create_on_node(serv->sv_function, rqstp,
-					      node, serv->sv_name);
+					      node, "%s", serv->sv_name);
 		if (IS_ERR(task)) {
 			error = PTR_ERR(task);
 			module_put(serv->sv_module);
@@ -1145,7 +1145,9 @@ svc_process_common(struct svc_rqst *rqst
 	svc_putnl(resv, RPC_SUCCESS);
 
 	/* Bump per-procedure stats counter */
-	procp->pc_count++;
+	pax_open_kernel();
+	(*(unsigned int *)&procp->pc_count)++;
+	pax_close_kernel();
 
 	/* Initialize storage for argp and resp */
 	memset(rqstp->rq_argp, 0, procp->pc_argsize);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/sunrpc/svcsock.c linux-3.2.71-pax/net/sunrpc/svcsock.c
--- linux-3.2.71/net/sunrpc/svcsock.c	2014-12-14 21:13:45.346055348 +0100
+++ linux-3.2.71-pax/net/sunrpc/svcsock.c	2014-12-14 21:13:52.850069367 +0100
@@ -396,7 +396,7 @@ static int svc_partial_recvfrom(struct s
 				int buflen, unsigned int base)
 {
 	size_t save_iovlen;
-	void __user *save_iovbase;
+	void *save_iovbase;
 	unsigned int i;
 	int ret;
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/sunrpc/xprtrdma/svc_rdma.c linux-3.2.71-pax/net/sunrpc/xprtrdma/svc_rdma.c
--- linux-3.2.71/net/sunrpc/xprtrdma/svc_rdma.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/sunrpc/xprtrdma/svc_rdma.c	2012-07-04 19:24:49.028063009 +0200
@@ -61,15 +61,15 @@ unsigned int svcrdma_max_req_size = RPCR
 static unsigned int min_max_inline = 4096;
 static unsigned int max_max_inline = 65536;
 
-atomic_t rdma_stat_recv;
-atomic_t rdma_stat_read;
-atomic_t rdma_stat_write;
-atomic_t rdma_stat_sq_starve;
-atomic_t rdma_stat_rq_starve;
-atomic_t rdma_stat_rq_poll;
-atomic_t rdma_stat_rq_prod;
-atomic_t rdma_stat_sq_poll;
-atomic_t rdma_stat_sq_prod;
+atomic_unchecked_t rdma_stat_recv;
+atomic_unchecked_t rdma_stat_read;
+atomic_unchecked_t rdma_stat_write;
+atomic_unchecked_t rdma_stat_sq_starve;
+atomic_unchecked_t rdma_stat_rq_starve;
+atomic_unchecked_t rdma_stat_rq_poll;
+atomic_unchecked_t rdma_stat_rq_prod;
+atomic_unchecked_t rdma_stat_sq_poll;
+atomic_unchecked_t rdma_stat_sq_prod;
 
 /* Temporary NFS request map and context caches */
 struct kmem_cache *svc_rdma_map_cachep;
@@ -109,7 +109,7 @@ static int read_reset_stat(ctl_table *ta
 		len -= *ppos;
 		if (len > *lenp)
 			len = *lenp;
-		if (len && copy_to_user(buffer, str_buf, len))
+		if (len > sizeof str_buf || (len && copy_to_user(buffer, str_buf, len)))
 			return -EFAULT;
 		*lenp = len;
 		*ppos += len;
@@ -150,63 +150,63 @@ static ctl_table svcrdma_parm_table[] =
 	{
 		.procname	= "rdma_stat_read",
 		.data		= &rdma_stat_read,
-		.maxlen		= sizeof(atomic_t),
+		.maxlen		= sizeof(atomic_unchecked_t),
 		.mode		= 0644,
 		.proc_handler	= read_reset_stat,
 	},
 	{
 		.procname	= "rdma_stat_recv",
 		.data		= &rdma_stat_recv,
-		.maxlen		= sizeof(atomic_t),
+		.maxlen		= sizeof(atomic_unchecked_t),
 		.mode		= 0644,
 		.proc_handler	= read_reset_stat,
 	},
 	{
 		.procname	= "rdma_stat_write",
 		.data		= &rdma_stat_write,
-		.maxlen		= sizeof(atomic_t),
+		.maxlen		= sizeof(atomic_unchecked_t),
 		.mode		= 0644,
 		.proc_handler	= read_reset_stat,
 	},
 	{
 		.procname	= "rdma_stat_sq_starve",
 		.data		= &rdma_stat_sq_starve,
-		.maxlen		= sizeof(atomic_t),
+		.maxlen		= sizeof(atomic_unchecked_t),
 		.mode		= 0644,
 		.proc_handler	= read_reset_stat,
 	},
 	{
 		.procname	= "rdma_stat_rq_starve",
 		.data		= &rdma_stat_rq_starve,
-		.maxlen		= sizeof(atomic_t),
+		.maxlen		= sizeof(atomic_unchecked_t),
 		.mode		= 0644,
 		.proc_handler	= read_reset_stat,
 	},
 	{
 		.procname	= "rdma_stat_rq_poll",
 		.data		= &rdma_stat_rq_poll,
-		.maxlen		= sizeof(atomic_t),
+		.maxlen		= sizeof(atomic_unchecked_t),
 		.mode		= 0644,
 		.proc_handler	= read_reset_stat,
 	},
 	{
 		.procname	= "rdma_stat_rq_prod",
 		.data		= &rdma_stat_rq_prod,
-		.maxlen		= sizeof(atomic_t),
+		.maxlen		= sizeof(atomic_unchecked_t),
 		.mode		= 0644,
 		.proc_handler	= read_reset_stat,
 	},
 	{
 		.procname	= "rdma_stat_sq_poll",
 		.data		= &rdma_stat_sq_poll,
-		.maxlen		= sizeof(atomic_t),
+		.maxlen		= sizeof(atomic_unchecked_t),
 		.mode		= 0644,
 		.proc_handler	= read_reset_stat,
 	},
 	{
 		.procname	= "rdma_stat_sq_prod",
 		.data		= &rdma_stat_sq_prod,
-		.maxlen		= sizeof(atomic_t),
+		.maxlen		= sizeof(atomic_unchecked_t),
 		.mode		= 0644,
 		.proc_handler	= read_reset_stat,
 	},
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/sunrpc/xprtrdma/svc_rdma_recvfrom.c linux-3.2.71-pax/net/sunrpc/xprtrdma/svc_rdma_recvfrom.c
--- linux-3.2.71/net/sunrpc/xprtrdma/svc_rdma_recvfrom.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/sunrpc/xprtrdma/svc_rdma_recvfrom.c	2012-07-04 19:24:49.032063009 +0200
@@ -499,7 +499,7 @@ next_sge:
 			svc_rdma_put_context(ctxt, 0);
 			goto out;
 		}
-		atomic_inc(&rdma_stat_read);
+		atomic_inc_unchecked(&rdma_stat_read);
 
 		if (read_wr.num_sge < chl_map->ch[ch_no].count) {
 			chl_map->ch[ch_no].count -= read_wr.num_sge;
@@ -609,7 +609,7 @@ int svc_rdma_recvfrom(struct svc_rqst *r
 				  dto_q);
 		list_del_init(&ctxt->dto_q);
 	} else {
-		atomic_inc(&rdma_stat_rq_starve);
+		atomic_inc_unchecked(&rdma_stat_rq_starve);
 		clear_bit(XPT_DATA, &xprt->xpt_flags);
 		ctxt = NULL;
 	}
@@ -629,7 +629,7 @@ int svc_rdma_recvfrom(struct svc_rqst *r
 	dprintk("svcrdma: processing ctxt=%p on xprt=%p, rqstp=%p, status=%d\n",
 		ctxt, rdma_xprt, rqstp, ctxt->wc_status);
 	BUG_ON(ctxt->wc_status != IB_WC_SUCCESS);
-	atomic_inc(&rdma_stat_recv);
+	atomic_inc_unchecked(&rdma_stat_recv);
 
 	/* Build up the XDR from the receive buffers. */
 	rdma_build_arg_xdr(rqstp, ctxt, ctxt->byte_len);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/sunrpc/xprtrdma/svc_rdma_sendto.c linux-3.2.71-pax/net/sunrpc/xprtrdma/svc_rdma_sendto.c
--- linux-3.2.71/net/sunrpc/xprtrdma/svc_rdma_sendto.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/sunrpc/xprtrdma/svc_rdma_sendto.c	2012-07-04 19:24:49.032063009 +0200
@@ -362,7 +362,7 @@ static int send_write(struct svcxprt_rdm
 	write_wr.wr.rdma.remote_addr = to;
 
 	/* Post It */
-	atomic_inc(&rdma_stat_write);
+	atomic_inc_unchecked(&rdma_stat_write);
 	if (svc_rdma_send(xprt, &write_wr))
 		goto err;
 	return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/sunrpc/xprtrdma/svc_rdma_transport.c linux-3.2.71-pax/net/sunrpc/xprtrdma/svc_rdma_transport.c
--- linux-3.2.71/net/sunrpc/xprtrdma/svc_rdma_transport.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/sunrpc/xprtrdma/svc_rdma_transport.c	2012-07-04 19:24:49.032063009 +0200
@@ -300,7 +300,7 @@ static void rq_cq_reap(struct svcxprt_rd
 		return;
 
 	ib_req_notify_cq(xprt->sc_rq_cq, IB_CQ_NEXT_COMP);
-	atomic_inc(&rdma_stat_rq_poll);
+	atomic_inc_unchecked(&rdma_stat_rq_poll);
 
 	while ((ret = ib_poll_cq(xprt->sc_rq_cq, 1, &wc)) > 0) {
 		ctxt = (struct svc_rdma_op_ctxt *)(unsigned long)wc.wr_id;
@@ -322,7 +322,7 @@ static void rq_cq_reap(struct svcxprt_rd
 	}
 
 	if (ctxt)
-		atomic_inc(&rdma_stat_rq_prod);
+		atomic_inc_unchecked(&rdma_stat_rq_prod);
 
 	set_bit(XPT_DATA, &xprt->sc_xprt.xpt_flags);
 	/*
@@ -394,7 +394,7 @@ static void sq_cq_reap(struct svcxprt_rd
 		return;
 
 	ib_req_notify_cq(xprt->sc_sq_cq, IB_CQ_NEXT_COMP);
-	atomic_inc(&rdma_stat_sq_poll);
+	atomic_inc_unchecked(&rdma_stat_sq_poll);
 	while ((ret = ib_poll_cq(cq, 1, &wc)) > 0) {
 		if (wc.status != IB_WC_SUCCESS)
 			/* Close the transport */
@@ -412,7 +412,7 @@ static void sq_cq_reap(struct svcxprt_rd
 	}
 
 	if (ctxt)
-		atomic_inc(&rdma_stat_sq_prod);
+		atomic_inc_unchecked(&rdma_stat_sq_prod);
 }
 
 static void sq_comp_handler(struct ib_cq *cq, void *cq_context)
@@ -1274,7 +1274,7 @@ int svc_rdma_send(struct svcxprt_rdma *x
 		spin_lock_bh(&xprt->sc_lock);
 		if (xprt->sc_sq_depth < atomic_read(&xprt->sc_sq_count) + wr_count) {
 			spin_unlock_bh(&xprt->sc_lock);
-			atomic_inc(&rdma_stat_sq_starve);
+			atomic_inc_unchecked(&rdma_stat_sq_starve);
 
 			/* See if we can opportunistically reap SQ WR to make room */
 			sq_cq_reap(xprt);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/tipc/eth_media.c linux-3.2.71-pax/net/tipc/eth_media.c
--- linux-3.2.71/net/tipc/eth_media.c	2013-10-27 17:59:58.836642300 +0100
+++ linux-3.2.71-pax/net/tipc/eth_media.c	2013-10-27 18:00:09.612641725 +0100
@@ -58,7 +58,6 @@ struct eth_bearer {
 
 static struct eth_bearer eth_bearers[MAX_ETH_BEARERS];
 static int eth_started;
-static struct notifier_block notifier;
 
 /**
  * send_msg - send a TIPC message out over an Ethernet interface
@@ -277,6 +276,11 @@ static char *eth_addr2str(struct tipc_me
  * with OS for notifications about device state changes.
  */
 
+static struct notifier_block notifier = {
+	.notifier_call = &recv_notification,
+	.priority = 0,
+};
+
 int tipc_eth_media_start(void)
 {
 	struct tipc_media_addr bcast_addr;
@@ -297,8 +301,6 @@ int tipc_eth_media_start(void)
 	if (res)
 		return res;
 
-	notifier.notifier_call = &recv_notification;
-	notifier.priority = 0;
 	res = register_netdevice_notifier(&notifier);
 	if (!res)
 		eth_started = 1;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/tipc/link.c linux-3.2.71-pax/net/tipc/link.c
--- linux-3.2.71/net/tipc/link.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/tipc/link.c	2012-07-04 19:24:49.032063009 +0200
@@ -1203,7 +1203,7 @@ static int link_send_sections_long(struc
 	struct tipc_msg fragm_hdr;
 	struct sk_buff *buf, *buf_chain, *prev;
 	u32 fragm_crs, fragm_rest, hsz, sect_rest;
-	const unchar *sect_crs;
+	const unchar __user *sect_crs;
 	int curr_sect;
 	u32 fragm_no;
 
@@ -1247,7 +1247,7 @@ again:
 
 		if (!sect_rest) {
 			sect_rest = msg_sect[++curr_sect].iov_len;
-			sect_crs = (const unchar *)msg_sect[curr_sect].iov_base;
+			sect_crs = (const unchar __user *)msg_sect[curr_sect].iov_base;
 		}
 
 		if (sect_rest < fragm_rest)
@@ -1266,7 +1266,7 @@ error:
 			}
 		} else
 			skb_copy_to_linear_data_offset(buf, fragm_crs,
-						       sect_crs, sz);
+						       (const void __force_kernel *)sect_crs, sz);
 		sect_crs += sz;
 		sect_rest -= sz;
 		fragm_crs += sz;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/tipc/msg.c linux-3.2.71-pax/net/tipc/msg.c
--- linux-3.2.71/net/tipc/msg.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/tipc/msg.c	2012-07-04 19:24:49.032063009 +0200
@@ -99,7 +99,7 @@ int tipc_msg_build(struct tipc_msg *hdr,
 					      msg_sect[cnt].iov_len);
 		else
 			skb_copy_to_linear_data_offset(*buf, pos,
-						       msg_sect[cnt].iov_base,
+						       (const void __force_kernel *)msg_sect[cnt].iov_base,
 						       msg_sect[cnt].iov_len);
 		pos += msg_sect[cnt].iov_len;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/tipc/subscr.c linux-3.2.71-pax/net/tipc/subscr.c
--- linux-3.2.71/net/tipc/subscr.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/tipc/subscr.c	2012-07-04 19:24:49.036063009 +0200
@@ -101,7 +101,7 @@ static void subscr_send_event(struct sub
 {
 	struct iovec msg_sect;
 
-	msg_sect.iov_base = (void *)&sub->evt;
+	msg_sect.iov_base = (void __force_user *)&sub->evt;
 	msg_sect.iov_len = sizeof(struct tipc_event);
 
 	sub->evt.event = htohl(event, sub->swap);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/unix/af_unix.c linux-3.2.71-pax/net/unix/af_unix.c
--- linux-3.2.71/net/unix/af_unix.c	2015-08-07 11:37:20.783789900 +0200
+++ linux-3.2.71-pax/net/unix/af_unix.c	2015-08-07 11:37:43.035790554 +0200
@@ -2188,11 +2188,14 @@ static unsigned int unix_dgram_poll(stru
 	writable = unix_writable(sk);
 	other = unix_peer_get(sk);
 	if (other) {
-		if (unix_peer(other) != sk) {
+		unix_state_lock(other);
+		if (!sock_flag(other, SOCK_DEAD) && unix_peer(other) != sk) {
+			unix_state_unlock(other);
 			sock_poll_wait(file, &unix_sk(other)->peer_wait, wait);
 			if (unix_recvq_full(other))
 				writable = 0;
-		}
+		} else
+			unix_state_unlock(other);
 		sock_put(other);
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/unix/sysctl_net_unix.c linux-3.2.71-pax/net/unix/sysctl_net_unix.c
--- linux-3.2.71/net/unix/sysctl_net_unix.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/unix/sysctl_net_unix.c	2013-03-28 01:35:23.568427934 +0100
@@ -34,7 +34,7 @@ static struct ctl_path unix_path[] = {
 
 int __net_init unix_sysctl_register(struct net *net)
 {
-	struct ctl_table *table;
+	ctl_table_no_const *table;
 
 	table = kmemdup(unix_table, sizeof(unix_table), GFP_KERNEL);
 	if (table == NULL)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/wireless/wext-core.c linux-3.2.71-pax/net/wireless/wext-core.c
--- linux-3.2.71/net/wireless/wext-core.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/wireless/wext-core.c	2012-07-04 19:24:49.036063009 +0200
@@ -747,8 +747,7 @@ static int ioctl_standard_iw_point(struc
 		 */
 
 		/* Support for very large requests */
-		if ((descr->flags & IW_DESCR_FLAG_NOMAX) &&
-		    (user_length > descr->max_tokens)) {
+		if (user_length > descr->max_tokens) {
 			/* Allow userspace to GET more than max so
 			 * we can support any size GET requests.
 			 * There is still a limit : -ENOMEM.
@@ -785,22 +784,6 @@ static int ioctl_standard_iw_point(struc
 		}
 	}
 
-	if (IW_IS_GET(cmd) && !(descr->flags & IW_DESCR_FLAG_NOMAX)) {
-		/*
-		 * If this is a GET, but not NOMAX, it means that the extra
-		 * data is not bounded by userspace, but by max_tokens. Thus
-		 * set the length to max_tokens. This matches the extra data
-		 * allocation.
-		 * The driver should fill it with the number of tokens it
-		 * provided, and it may check iwp->length rather than having
-		 * knowledge of max_tokens. If the driver doesn't change the
-		 * iwp->length, this ioctl just copies back max_token tokens
-		 * filled with zeroes. Hopefully the driver isn't claiming
-		 * them to be valid data.
-		 */
-		iwp->length = descr->max_tokens;
-	}
-
 	err = handler(dev, info, (union iwreq_data *) iwp, extra);
 
 	iwp->length += essid_compat;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/xfrm/xfrm_policy.c linux-3.2.71-pax/net/xfrm/xfrm_policy.c
--- linux-3.2.71/net/xfrm/xfrm_policy.c	2012-10-10 11:02:19.627865901 +0200
+++ linux-3.2.71-pax/net/xfrm/xfrm_policy.c	2013-09-17 02:26:47.153616710 +0200
@@ -299,7 +299,7 @@ static void xfrm_policy_kill(struct xfrm
 {
 	policy->walk.dead = 1;
 
-	atomic_inc(&policy->genid);
+	atomic_inc_unchecked(&policy->genid);
 
 	if (del_timer(&policy->timer))
 		xfrm_pol_put(policy);
@@ -583,7 +583,7 @@ int xfrm_policy_insert(int dir, struct x
 		hlist_add_head(&policy->bydst, chain);
 	xfrm_pol_hold(policy);
 	net->xfrm.policy_count[dir]++;
-	atomic_inc(&flow_cache_genid);
+	atomic_inc_unchecked(&flow_cache_genid);
 	if (delpol)
 		__xfrm_policy_unlink(delpol, dir);
 	policy->index = delpol ? delpol->index : xfrm_gen_index(net, dir);
@@ -1530,7 +1530,7 @@ free_dst:
 	goto out;
 }
 
-static int inline
+static inline int
 xfrm_dst_alloc_copy(void **target, const void *src, int size)
 {
 	if (!*target) {
@@ -1542,7 +1542,7 @@ xfrm_dst_alloc_copy(void **target, const
 	return 0;
 }
 
-static int inline
+static inline int
 xfrm_dst_update_parent(struct dst_entry *dst, const struct xfrm_selector *sel)
 {
 #ifdef CONFIG_XFRM_SUB_POLICY
@@ -1554,7 +1554,7 @@ xfrm_dst_update_parent(struct dst_entry
 #endif
 }
 
-static int inline
+static inline int
 xfrm_dst_update_origin(struct dst_entry *dst, const struct flowi *fl)
 {
 #ifdef CONFIG_XFRM_SUB_POLICY
@@ -1648,7 +1648,7 @@ xfrm_resolve_and_create_bundle(struct xf
 
 	xdst->num_pols = num_pols;
 	memcpy(xdst->pols, pols, sizeof(struct xfrm_policy*) * num_pols);
-	xdst->policy_genid = atomic_read(&pols[0]->genid);
+	xdst->policy_genid = atomic_read_unchecked(&pols[0]->genid);
 
 	return xdst;
 }
@@ -2297,11 +2297,12 @@ static void xfrm_garbage_collect(struct
 	__xfrm_garbage_collect(net);
 }
 
-static void xfrm_garbage_collect_deferred(struct net *net)
+void xfrm_garbage_collect_deferred(struct net *net)
 {
 	flow_cache_flush_deferred();
 	__xfrm_garbage_collect(net);
 }
+EXPORT_SYMBOL(xfrm_garbage_collect_deferred);
 
 static void xfrm_init_pmtu(struct dst_entry *dst)
 {
@@ -2348,7 +2349,7 @@ static int xfrm_bundle_ok(struct xfrm_ds
 		if (xdst->xfrm_genid != dst->xfrm->genid)
 			return 0;
 		if (xdst->num_pols > 0 &&
-		    xdst->policy_genid != atomic_read(&xdst->pols[0]->genid))
+		    xdst->policy_genid != atomic_read_unchecked(&xdst->pols[0]->genid))
 			return 0;
 
 		mtu = dst_mtu(dst->child);
@@ -2434,8 +2435,6 @@ int xfrm_policy_register_afinfo(struct x
 			dst_ops->link_failure = xfrm_link_failure;
 		if (likely(dst_ops->neigh_lookup == NULL))
 			dst_ops->neigh_lookup = xfrm_neigh_lookup;
-		if (likely(afinfo->garbage_collect == NULL))
-			afinfo->garbage_collect = xfrm_garbage_collect_deferred;
 		xfrm_policy_afinfo[afinfo->family] = afinfo;
 	}
 	write_unlock_bh(&xfrm_policy_afinfo_lock);
@@ -2482,7 +2481,6 @@ int xfrm_policy_unregister_afinfo(struct
 			dst_ops->check = NULL;
 			dst_ops->negative_advice = NULL;
 			dst_ops->link_failure = NULL;
-			afinfo->garbage_collect = NULL;
 		}
 	}
 	write_unlock_bh(&xfrm_policy_afinfo_lock);
@@ -2692,7 +2690,7 @@ static void __net_exit xfrm_net_exit(str
 	xfrm_statistics_fini(net);
 }
 
-static struct pernet_operations __net_initdata xfrm_net_ops = {
+static struct pernet_operations __net_initconst xfrm_net_ops = {
 	.init = xfrm_net_init,
 	.exit = xfrm_net_exit,
 };
@@ -2885,7 +2883,7 @@ static int xfrm_policy_migrate(struct xf
 			       sizeof(pol->xfrm_vec[i].saddr));
 			pol->xfrm_vec[i].encap_family = mp->new_family;
 			/* flush bundles */
-			atomic_inc(&pol->genid);
+			atomic_inc_unchecked(&pol->genid);
 		}
 	}
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/xfrm/xfrm_state.c linux-3.2.71-pax/net/xfrm/xfrm_state.c
--- linux-3.2.71/net/xfrm/xfrm_state.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/xfrm/xfrm_state.c	2013-09-01 19:51:01.567873269 +0200
@@ -194,11 +194,13 @@ int xfrm_register_type(const struct xfrm
 
 	if (unlikely(afinfo == NULL))
 		return -EAFNOSUPPORT;
-	typemap = afinfo->type_map;
+	typemap = (const struct xfrm_type **)afinfo->type_map;
 
-	if (likely(typemap[type->proto] == NULL))
+	if (likely(typemap[type->proto] == NULL)) {
+		pax_open_kernel();
 		typemap[type->proto] = type;
-	else
+		pax_close_kernel();
+	} else
 		err = -EEXIST;
 	xfrm_state_unlock_afinfo(afinfo);
 	return err;
@@ -213,12 +215,15 @@ int xfrm_unregister_type(const struct xf
 
 	if (unlikely(afinfo == NULL))
 		return -EAFNOSUPPORT;
-	typemap = afinfo->type_map;
+	typemap = (const struct xfrm_type **)afinfo->type_map;
 
 	if (unlikely(typemap[type->proto] != type))
 		err = -ENOENT;
-	else
+	else {
+		pax_open_kernel();
 		typemap[type->proto] = NULL;
+		pax_close_kernel();
+	}
 	xfrm_state_unlock_afinfo(afinfo);
 	return err;
 }
@@ -227,7 +232,6 @@ EXPORT_SYMBOL(xfrm_unregister_type);
 static const struct xfrm_type *xfrm_get_type(u8 proto, unsigned short family)
 {
 	struct xfrm_state_afinfo *afinfo;
-	const struct xfrm_type **typemap;
 	const struct xfrm_type *type;
 	int modload_attempted = 0;
 
@@ -235,9 +239,8 @@ retry:
 	afinfo = xfrm_state_get_afinfo(family);
 	if (unlikely(afinfo == NULL))
 		return NULL;
-	typemap = afinfo->type_map;
 
-	type = typemap[proto];
+	type = afinfo->type_map[proto];
 	if (unlikely(type && !try_module_get(type->owner)))
 		type = NULL;
 	if (!type && !modload_attempted) {
@@ -270,7 +273,7 @@ int xfrm_register_mode(struct xfrm_mode
 		return -EAFNOSUPPORT;
 
 	err = -EEXIST;
-	modemap = afinfo->mode_map;
+	modemap = (struct xfrm_mode **)afinfo->mode_map;
 	if (modemap[mode->encap])
 		goto out;
 
@@ -278,8 +281,10 @@ int xfrm_register_mode(struct xfrm_mode
 	if (!try_module_get(afinfo->owner))
 		goto out;
 
-	mode->afinfo = afinfo;
+	pax_open_kernel();
+	*(const void **)&mode->afinfo = afinfo;
 	modemap[mode->encap] = mode;
+	pax_close_kernel();
 	err = 0;
 
 out:
@@ -302,9 +307,11 @@ int xfrm_unregister_mode(struct xfrm_mod
 		return -EAFNOSUPPORT;
 
 	err = -ENOENT;
-	modemap = afinfo->mode_map;
+	modemap = (struct xfrm_mode **)afinfo->mode_map;
 	if (likely(modemap[mode->encap] == mode)) {
+		pax_open_kernel();
 		modemap[mode->encap] = NULL;
+		pax_close_kernel();
 		module_put(mode->afinfo->owner);
 		err = 0;
 	}
@@ -1497,10 +1504,10 @@ EXPORT_SYMBOL(xfrm_find_acq_byseq);
 u32 xfrm_get_acqseq(void)
 {
 	u32 res;
-	static atomic_t acqseq;
+	static atomic_unchecked_t acqseq;
 
 	do {
-		res = atomic_inc_return(&acqseq);
+		res = atomic_inc_return_unchecked(&acqseq);
 	} while (!res);
 
 	return res;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/net/xfrm/xfrm_sysctl.c linux-3.2.71-pax/net/xfrm/xfrm_sysctl.c
--- linux-3.2.71/net/xfrm/xfrm_sysctl.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/net/xfrm/xfrm_sysctl.c	2013-03-28 01:35:23.568427934 +0100
@@ -42,7 +42,7 @@ static struct ctl_table xfrm_table[] = {
 
 int __net_init xfrm_sysctl_init(struct net *net)
 {
-	struct ctl_table *table;
+	ctl_table_no_const *table;
 
 	__xfrm_sysctl_init(net);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/basic/fixdep.c linux-3.2.71-pax/scripts/basic/fixdep.c
--- linux-3.2.71/scripts/basic/fixdep.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/scripts/basic/fixdep.c	2012-07-04 19:24:49.036063009 +0200
@@ -161,7 +161,7 @@ static unsigned int strhash(const char *
 /*
  * Lookup a value in the configuration string.
  */
-static int is_defined_config(const char *name, int len, unsigned int hash)
+static int is_defined_config(const char *name, unsigned int len, unsigned int hash)
 {
 	struct item *aux;
 
@@ -211,10 +211,10 @@ static void clear_config(void)
 /*
  * Record the use of a CONFIG_* word.
  */
-static void use_config(const char *m, int slen)
+static void use_config(const char *m, unsigned int slen)
 {
 	unsigned int hash = strhash(m, slen);
-	int c, i;
+	unsigned int c, i;
 
 	if (is_defined_config(m, slen, hash))
 	    return;
@@ -235,9 +235,9 @@ static void use_config(const char *m, in
 
 static void parse_config_file(const char *map, size_t len)
 {
-	const int *end = (const int *) (map + len);
+	const unsigned int *end = (const unsigned int *) (map + len);
 	/* start at +1, so that p can never be < map */
-	const int *m   = (const int *) map + 1;
+	const unsigned int *m   = (const unsigned int *) map + 1;
 	const char *p, *q;
 
 	for (; m < end; m++) {
@@ -406,7 +406,7 @@ static void print_deps(void)
 static void traps(void)
 {
 	static char test[] __attribute__((aligned(sizeof(int)))) = "CONF";
-	int *p = (int *)test;
+	unsigned int *p = (unsigned int *)test;
 
 	if (*p != INT_CONF) {
 		fprintf(stderr, "fixdep: sizeof(int) != 4 or wrong endianess? %#x\n",
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/gcc-plugin.sh linux-3.2.71-pax/scripts/gcc-plugin.sh
--- linux-3.2.71/scripts/gcc-plugin.sh	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/scripts/gcc-plugin.sh	2015-04-03 00:33:14.672160020 +0200
@@ -0,0 +1,51 @@
+#!/bin/sh
+srctree=$(dirname "$0")
+gccplugins_dir=$($3 -print-file-name=plugin)
+plugincc=$($1 -E -x c++ - -o /dev/null -I"${srctree}"/../tools/gcc -I"${gccplugins_dir}"/include 2>&1 <<EOF
+#include "gcc-common.h"
+#if BUILDING_GCC_VERSION >= 4008 || defined(ENABLE_BUILD_WITH_CXX)
+#warning $2 CXX
+#else
+#warning $1 CC
+#endif
+EOF
+)
+
+if [ $? -ne 0 ]
+then
+	exit 1
+fi
+
+case "$plugincc" in
+	*"$1 CC"*)
+		echo "$1"
+		exit 0
+		;;
+
+	*"$2 CXX"*)
+		# the c++ compiler needs another test, see below
+		;;
+
+	*)
+		exit 1
+		;;
+esac
+
+# we need a c++ compiler that supports the designated initializer GNU extension
+plugincc=$($2 -c -x c++ -std=gnu++98 - -fsyntax-only -I"${srctree}"/../tools/gcc -I"${gccplugins_dir}"/include 2>&1 <<EOF
+#include "gcc-common.h"
+class test {
+public:
+	int test;
+} test = {
+	.test = 1
+};
+EOF
+)
+
+if [ $? -eq 0 ]
+then
+	echo "$2"
+	exit 0
+fi
+exit 1
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/headers_install.pl linux-3.2.71-pax/scripts/headers_install.pl
--- linux-3.2.71/scripts/headers_install.pl	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/scripts/headers_install.pl	2013-04-05 19:58:05.772903585 +0200
@@ -33,6 +33,7 @@ foreach my $file (@files) {
 		$line =~ s/([\s(])__user\s/$1/g;
 		$line =~ s/([\s(])__force\s/$1/g;
 		$line =~ s/([\s(])__iomem\s/$1/g;
+		$line =~ s/(\s?)__intentional_overflow\([-\d\s,]*\)\s?/$1/g;
 		$line =~ s/\s__attribute_const__\s/ /g;
 		$line =~ s/\s__attribute_const__$//g;
 		$line =~ s/\b__packed\b/__attribute__((packed))/g;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/Kbuild.include linux-3.2.71-pax/scripts/Kbuild.include
--- linux-3.2.71/scripts/Kbuild.include	2012-10-24 01:05:57.440814655 +0200
+++ linux-3.2.71-pax/scripts/Kbuild.include	2015-02-05 15:39:49.672067919 +0100
@@ -143,7 +143,7 @@ cc-ifversion = $(shell [ $(call cc-versi
 # cc-ldoption
 # Usage: ldflags += $(call cc-ldoption, -Wl$(comma)--hash-style=both)
 cc-ldoption = $(call try-run,\
-	$(CC) $(1) -nostdlib -x c /dev/null -o "$$TMP",$(1),$(2))
+	$(CC) $(1) -Wl,-r -nostdlib -x c /dev/null -o "$$TMP",$(1),$(2))
 
 # ld-option
 # Usage: LDFLAGS += $(call ld-option, -X)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/Makefile.build linux-3.2.71-pax/scripts/Makefile.build
--- linux-3.2.71/scripts/Makefile.build	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/scripts/Makefile.build	2012-09-11 20:41:05.476019995 +0200
@@ -109,7 +109,7 @@ endif
 endif
 
 # Do not include host rules unless needed
-ifneq ($(hostprogs-y)$(hostprogs-m),)
+ifneq ($(hostprogs-y)$(hostprogs-m)$(hostlibs-y)$(hostlibs-m)$(hostcxxlibs-y)$(hostcxxlibs-m),)
 include scripts/Makefile.host
 endif
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/Makefile.clean linux-3.2.71-pax/scripts/Makefile.clean
--- linux-3.2.71/scripts/Makefile.clean	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/scripts/Makefile.clean	2012-07-04 19:24:49.040063009 +0200
@@ -43,7 +43,8 @@ subdir-ymn	:= $(addprefix $(obj)/,$(subd
 __clean-files	:= $(extra-y) $(always)                  \
 		   $(targets) $(clean-files)             \
 		   $(host-progs)                         \
-		   $(hostprogs-y) $(hostprogs-m) $(hostprogs-)
+		   $(hostprogs-y) $(hostprogs-m) $(hostprogs-) \
+		   $(hostlibs-y) $(hostlibs-m) $(hostlibs-)
 
 __clean-files   := $(filter-out $(no-clean-files), $(__clean-files))
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/Makefile.headersinst linux-3.2.71-pax/scripts/Makefile.headersinst
--- linux-3.2.71/scripts/Makefile.headersinst	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/scripts/Makefile.headersinst	2012-07-04 19:24:49.040063009 +0200
@@ -4,12 +4,16 @@
 # header-y  - list files to be installed. They are preprocessed
 #             to remove __KERNEL__ section of the file
 # objhdr-y  - Same as header-y but for generated files
+# genhdr-y  - Same as objhdr-y but in a generated/ directory
 #
 # ==========================================================================
 
 # called may set destination dir (when installing to asm/)
 _dst := $(if $(dst),$(dst),$(obj))
 
+# generated header directory
+gen := $(if $(gen),$(gen),$(subst include/,include/generated/,$(obj)))
+
 kbuild-file := $(srctree)/$(obj)/Kbuild
 include $(kbuild-file)
 
@@ -33,9 +37,10 @@ wrapper-files := $(filter $(header-y), $
 
 # all headers files for this dir
 header-y      := $(filter-out $(generic-y), $(header-y))
-all-files     := $(header-y) $(objhdr-y) $(wrapper-files)
+all-files     := $(header-y) $(objhdr-y) $(genhdr-y) $(wrapper-files)
 input-files   := $(addprefix $(srctree)/$(obj)/,$(header-y)) \
-                 $(addprefix $(objtree)/$(obj)/,$(objhdr-y))
+                 $(addprefix $(objtree)/$(obj)/,$(objhdr-y)) \
+                 $(addprefix $(objtree)/$(gen)/,$(genhdr-y))
 output-files  := $(addprefix $(install)/, $(all-files))
 
 # Work out what needs to be removed
@@ -52,6 +57,7 @@ quiet_cmd_install = INSTALL $(printdir)
       cmd_install = \
         $(PERL) $< $(srctree)/$(obj) $(install) $(SRCARCH) $(header-y); \
         $(PERL) $< $(objtree)/$(obj) $(install) $(SRCARCH) $(objhdr-y); \
+        $(PERL) $< $(objtree)/$(gen) $(install) $(SRCARCH) $(genhdr-y); \
         for F in $(wrapper-files); do                                   \
                 echo "\#include <asm-generic/$$F>" > $(install)/$$F;    \
         done;                                                           \
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/Makefile.host linux-3.2.71-pax/scripts/Makefile.host
--- linux-3.2.71/scripts/Makefile.host	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/scripts/Makefile.host	2012-07-04 19:24:49.040063009 +0200
@@ -31,6 +31,8 @@
 # Note: Shared libraries consisting of C++ files are not supported
 
 __hostprogs := $(sort $(hostprogs-y) $(hostprogs-m))
+__hostlibs := $(sort $(hostlibs-y) $(hostlibs-m))
+__hostcxxlibs := $(sort $(hostcxxlibs-y) $(hostcxxlibs-m))
 
 # C code
 # Executables compiled from a single .c file
@@ -54,11 +56,15 @@ host-cxxobjs	:= $(sort $(foreach m,$(hos
 # Shared libaries (only .c supported)
 # Shared libraries (.so) - all .so files referenced in "xxx-objs"
 host-cshlib	:= $(sort $(filter %.so, $(host-cobjs)))
+host-cshlib	+= $(sort $(filter %.so, $(__hostlibs)))
+host-cxxshlib	:= $(sort $(filter %.so, $(__hostcxxlibs)))
 # Remove .so files from "xxx-objs"
 host-cobjs	:= $(filter-out %.so,$(host-cobjs))
+host-cxxobjs	:= $(filter-out %.so,$(host-cxxobjs))
 
-#Object (.o) files used by the shared libaries
+# Object (.o) files used by the shared libaries
 host-cshobjs	:= $(sort $(foreach m,$(host-cshlib),$($(m:.so=-objs))))
+host-cxxshobjs	:= $(sort $(foreach m,$(host-cxxshlib),$($(m:.so=-objs))))
 
 # output directory for programs/.o files
 # hostprogs-y := tools/build may have been specified. Retrieve directory
@@ -82,7 +88,9 @@ host-cobjs	:= $(addprefix $(obj)/,$(host
 host-cxxmulti	:= $(addprefix $(obj)/,$(host-cxxmulti))
 host-cxxobjs	:= $(addprefix $(obj)/,$(host-cxxobjs))
 host-cshlib	:= $(addprefix $(obj)/,$(host-cshlib))
+host-cxxshlib	:= $(addprefix $(obj)/,$(host-cxxshlib))
 host-cshobjs	:= $(addprefix $(obj)/,$(host-cshobjs))
+host-cxxshobjs	:= $(addprefix $(obj)/,$(host-cxxshobjs))
 host-objdirs    := $(addprefix $(obj)/,$(host-objdirs))
 
 obj-dirs += $(host-objdirs)
@@ -156,6 +164,13 @@ quiet_cmd_host-cshobjs	= HOSTCC  -fPIC $
 $(host-cshobjs): $(obj)/%.o: $(src)/%.c FORCE
 	$(call if_changed_dep,host-cshobjs)
 
+# Compile .c file, create position independent .o file
+# host-cxxshobjs -> .o
+quiet_cmd_host-cxxshobjs	= HOSTCXX -fPIC $@
+      cmd_host-cxxshobjs	= $(HOSTCXX) $(hostcxx_flags) -fPIC -c -o $@ $<
+$(host-cxxshobjs): $(obj)/%.o: $(src)/%.c FORCE
+	$(call if_changed_dep,host-cxxshobjs)
+
 # Link a shared library, based on position independent .o files
 # *.o -> .so shared library (host-cshlib)
 quiet_cmd_host-cshlib	= HOSTLLD -shared $@
@@ -165,6 +180,15 @@ quiet_cmd_host-cshlib	= HOSTLLD -shared
 $(host-cshlib): $(obj)/%: $(host-cshobjs) FORCE
 	$(call if_changed,host-cshlib)
 
+# Link a shared library, based on position independent .o files
+# *.o -> .so shared library (host-cxxshlib)
+quiet_cmd_host-cxxshlib	= HOSTLLD -shared $@
+      cmd_host-cxxshlib	= $(HOSTCXX) $(HOSTLDFLAGS) -shared -o $@ \
+			  $(addprefix $(obj)/,$($(@F:.so=-objs))) \
+			  $(HOST_LOADLIBES) $(HOSTLOADLIBES_$(@F))
+$(host-cxxshlib): $(obj)/%: $(host-cxxshobjs) FORCE
+	$(call if_changed,host-cxxshlib)
+
 targets += $(host-csingle)  $(host-cmulti) $(host-cobjs)\
-	   $(host-cxxmulti) $(host-cxxobjs) $(host-cshlib) $(host-cshobjs) 
+	   $(host-cxxmulti) $(host-cxxobjs) $(host-cshlib) $(host-cshobjs) $(host-cxxshlib) $(host-cxxshobjs)
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/mod/file2alias.c linux-3.2.71-pax/scripts/mod/file2alias.c
--- linux-3.2.71/scripts/mod/file2alias.c	2014-04-02 03:15:45.907672324 +0200
+++ linux-3.2.71-pax/scripts/mod/file2alias.c	2014-04-02 03:15:49.419672136 +0200
@@ -72,7 +72,7 @@ static void device_id_check(const char *
 			    unsigned long size, unsigned long id_size,
 			    void *symval)
 {
-	int i;
+	unsigned int i;
 
 	if (size % id_size || size < id_size) {
 		if (cross_build != 0)
@@ -102,7 +102,7 @@ static void device_id_check(const char *
 /* USB is special because the bcdDevice can be matched against a numeric range */
 /* Looks like "usb:vNpNdNdcNdscNdpNicNiscNipN" */
 static void do_usb_entry(struct usb_device_id *id,
-			 unsigned int bcdDevice_initial, int bcdDevice_initial_digits,
+			 unsigned int bcdDevice_initial, unsigned int bcdDevice_initial_digits,
 			 unsigned char range_lo, unsigned char range_hi,
 			 unsigned char max, struct module *mod)
 {
@@ -203,7 +203,7 @@ static void do_usb_entry_multi(struct us
 {
 	unsigned int devlo, devhi;
 	unsigned char chi, clo, max;
-	int ndigits;
+	unsigned int ndigits;
 
 	id->match_flags = TO_NATIVE(id->match_flags);
 	id->idVendor = TO_NATIVE(id->idVendor);
@@ -437,7 +437,7 @@ static void do_pnp_device_entry(void *sy
 	for (i = 0; i < count; i++) {
 		const char *id = (char *)devs[i].id;
 		char acpi_id[sizeof(devs[0].id)];
-		int j;
+		unsigned int j;
 
 		buf_printf(&mod->dev_table_buf,
 			   "MODULE_ALIAS(\"pnp:d%s*\");\n", id);
@@ -467,7 +467,7 @@ static void do_pnp_card_entries(void *sy
 
 		for (j = 0; j < PNP_MAX_DEVICES; j++) {
 			const char *id = (char *)card->devs[j].id;
-			int i2, j2;
+			unsigned int i2, j2;
 			int dup = 0;
 
 			if (!id[0])
@@ -493,7 +493,7 @@ static void do_pnp_card_entries(void *sy
 			/* add an individual alias for every device entry */
 			if (!dup) {
 				char acpi_id[sizeof(card->devs[0].id)];
-				int k;
+				unsigned int k;
 
 				buf_printf(&mod->dev_table_buf,
 					   "MODULE_ALIAS(\"pnp:d%s*\");\n", id);
@@ -807,7 +807,7 @@ static void dmi_ascii_filter(char *d, co
 static int do_dmi_entry(const char *filename, struct dmi_system_id *id,
 			char *alias)
 {
-	int i, j;
+	unsigned int i, j;
 
 	sprintf(alias, "dmi*");
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/mod/modpost.c linux-3.2.71-pax/scripts/mod/modpost.c
--- linux-3.2.71/scripts/mod/modpost.c	2014-06-10 10:59:38.814436241 +0200
+++ linux-3.2.71-pax/scripts/mod/modpost.c	2014-06-10 10:59:44.194435954 +0200
@@ -926,6 +926,7 @@ enum mismatch {
 	ANY_INIT_TO_ANY_EXIT,
 	ANY_EXIT_TO_ANY_INIT,
 	EXPORT_TO_INIT_EXIT,
+	DATA_TO_TEXT
 };
 
 struct sectioncheck {
@@ -1034,6 +1035,12 @@ const struct sectioncheck sectioncheck[]
 	.tosec   = { INIT_SECTIONS, EXIT_SECTIONS, NULL },
 	.mismatch = EXPORT_TO_INIT_EXIT,
 	.symbol_white_list = { DEFAULT_SYMBOL_WHITE_LIST, NULL },
+},
+/* Do not reference code from writable data */
+{
+	.fromsec = { DATA_SECTIONS, NULL },
+	.tosec   = { TEXT_SECTIONS, NULL },
+	.mismatch = DATA_TO_TEXT
 }
 };
 
@@ -1156,10 +1163,10 @@ static Elf_Sym *find_elf_symbol(struct e
 			continue;
 		if (ELF_ST_TYPE(sym->st_info) == STT_SECTION)
 			continue;
-		if (sym->st_value == addr)
-			return sym;
 		/* Find a symbol nearby - addr are maybe negative */
 		d = sym->st_value - addr;
+		if (d == 0)
+			return sym;
 		if (d < 0)
 			d = addr - sym->st_value;
 		if (d < distance) {
@@ -1438,6 +1445,14 @@ static void report_sec_mismatch(const ch
 		tosym, prl_to, prl_to, tosym);
 		free(prl_to);
 		break;
+	case DATA_TO_TEXT:
+#if 0
+		fprintf(stderr,
+		"The %s %s:%s references\n"
+		"the %s %s:%s%s\n",
+		from, fromsec, fromsym, to, tosec, tosym, to_p);
+#endif
+		break;
 	}
 	fprintf(stderr, "\n");
 }
@@ -1663,7 +1678,7 @@ static void section_rel(const char *modn
 static void check_sec_ref(struct module *mod, const char *modname,
                           struct elf_info *elf)
 {
-	int i;
+	unsigned int i;
 	Elf_Shdr *sechdrs = elf->sechdrs;
 
 	/* Walk through all sections */
@@ -1761,7 +1776,7 @@ void __attribute__((format(printf, 2, 3)
 	va_end(ap);
 }
 
-void buf_write(struct buffer *buf, const char *s, int len)
+void buf_write(struct buffer *buf, const char *s, unsigned int len)
 {
 	if (buf->size - buf->pos < len) {
 		buf->size += len + SZ;
@@ -1979,7 +1994,7 @@ static void write_if_changed(struct buff
 	if (fstat(fileno(file), &st) < 0)
 		goto close_write;
 
-	if (st.st_size != b->pos)
+	if (st.st_size != (off_t)b->pos)
 		goto close_write;
 
 	tmp = NOFAIL(malloc(b->pos));
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/mod/modpost.h linux-3.2.71-pax/scripts/mod/modpost.h
--- linux-3.2.71/scripts/mod/modpost.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/scripts/mod/modpost.h	2012-07-04 19:24:49.044063009 +0200
@@ -92,15 +92,15 @@ void *do_nofail(void *ptr, const char *e
 
 struct buffer {
 	char *p;
-	int pos;
-	int size;
+	unsigned int pos;
+	unsigned int size;
 };
 
 void __attribute__((format(printf, 2, 3)))
 buf_printf(struct buffer *buf, const char *fmt, ...);
 
 void
-buf_write(struct buffer *buf, const char *s, int len);
+buf_write(struct buffer *buf, const char *s, unsigned int len);
 
 struct module {
 	struct module *next;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/mod/sumversion.c linux-3.2.71-pax/scripts/mod/sumversion.c
--- linux-3.2.71/scripts/mod/sumversion.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/scripts/mod/sumversion.c	2012-07-04 19:24:49.044063009 +0200
@@ -470,7 +470,7 @@ static void write_version(const char *fi
 		goto out;
 	}
 
-	if (write(fd, sum, strlen(sum)+1) != strlen(sum)+1) {
+	if (write(fd, sum, strlen(sum)+1) != (ssize_t)strlen(sum)+1) {
 		warn("writing sum in %s failed: %s\n",
 			filename, strerror(errno));
 		goto out;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/module-common.lds linux-3.2.71-pax/scripts/module-common.lds
--- linux-3.2.71/scripts/module-common.lds	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/scripts/module-common.lds	2013-09-19 00:44:46.157605071 +0200
@@ -6,6 +6,10 @@
 SECTIONS {
 	/DISCARD/ : { *(.discard) }
 
+	.rodata : {
+		*(.rodata) *(.rodata.*)
+		*(.data..read_only)
+	}
 	__ksymtab		: { *(SORT(___ksymtab+*)) }
 	__ksymtab_gpl		: { *(SORT(___ksymtab_gpl+*)) }
 	__ksymtab_unused	: { *(SORT(___ksymtab_unused+*)) }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/package/builddeb linux-3.2.71-pax/scripts/package/builddeb
--- linux-3.2.71/scripts/package/builddeb	2014-04-09 12:13:43.924713383 +0200
+++ linux-3.2.71-pax/scripts/package/builddeb	2014-04-09 12:15:01.624709235 +0200
@@ -241,6 +241,7 @@ fi
 (cd $srctree; find . -name Makefile -o -name Kconfig\* -o -name \*.pl > "$objtree/debian/hdrsrcfiles")
 (cd $srctree; find arch/$SRCARCH/include include scripts -type f >> "$objtree/debian/hdrsrcfiles")
 (cd $objtree; find Module.symvers include scripts -type f >> "$objtree/debian/hdrobjfiles")
+(cd $objtree; find tools/gcc -name \*.so >> "$objtree/debian/hdrobjfiles")
 destdir=$kernel_headers_dir/usr/src/linux-headers-$version
 mkdir -p "$destdir"
 (cd $srctree; tar -c -f - -T "$objtree/debian/hdrsrcfiles") | (cd $destdir; tar -xf -)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/pnmtologo.c linux-3.2.71-pax/scripts/pnmtologo.c
--- linux-3.2.71/scripts/pnmtologo.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/scripts/pnmtologo.c	2012-07-04 19:24:49.044063009 +0200
@@ -237,14 +237,14 @@ static void write_header(void)
     fprintf(out, " *  Linux logo %s\n", logoname);
     fputs(" */\n\n", out);
     fputs("#include <linux/linux_logo.h>\n\n", out);
-    fprintf(out, "static unsigned char %s_data[] __initdata = {\n",
+    fprintf(out, "static unsigned char %s_data[] = {\n",
 	    logoname);
 }
 
 static void write_footer(void)
 {
     fputs("\n};\n\n", out);
-    fprintf(out, "const struct linux_logo %s __initconst = {\n", logoname);
+    fprintf(out, "const struct linux_logo %s = {\n", logoname);
     fprintf(out, "\t.type\t\t= %s,\n", logo_types[logo_type]);
     fprintf(out, "\t.width\t\t= %d,\n", logo_width);
     fprintf(out, "\t.height\t\t= %d,\n", logo_height);
@@ -374,7 +374,7 @@ static void write_logo_clut224(void)
     fputs("\n};\n\n", out);
 
     /* write logo clut */
-    fprintf(out, "static unsigned char %s_clut[] __initdata = {\n",
+    fprintf(out, "static unsigned char %s_clut[] = {\n",
 	    logoname);
     write_hex_cnt = 0;
     for (i = 0; i < logo_clutsize; i++) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/scripts/tags.sh linux-3.2.71-pax/scripts/tags.sh
--- linux-3.2.71/scripts/tags.sh	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/scripts/tags.sh	2012-07-04 19:24:49.044063009 +0200
@@ -116,7 +116,7 @@ docscope()
 
 dogtags()
 {
-	all_sources | gtags -f -
+	all_sources | gtags -i -f -
 }
 
 exuberant()
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/apparmor/lsm.c linux-3.2.71-pax/security/apparmor/lsm.c
--- linux-3.2.71/security/apparmor/lsm.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/security/apparmor/lsm.c	2013-03-28 01:35:23.572427934 +0100
@@ -621,7 +621,7 @@ static int apparmor_task_setrlimit(struc
 	return error;
 }
 
-static struct security_operations apparmor_ops = {
+static struct security_operations apparmor_ops __read_only = {
 	.name =				"apparmor",
 
 	.ptrace_access_check =		apparmor_ptrace_access_check,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/integrity/ima/ima_api.c linux-3.2.71-pax/security/integrity/ima/ima_api.c
--- linux-3.2.71/security/integrity/ima/ima_api.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/security/integrity/ima/ima_api.c	2012-07-04 19:24:49.044063009 +0200
@@ -75,7 +75,7 @@ void ima_add_violation(struct inode *ino
 	int result;
 
 	/* can overflow, only indicator */
-	atomic_long_inc(&ima_htable.violations);
+	atomic_long_inc_unchecked(&ima_htable.violations);
 
 	entry = kmalloc(sizeof(*entry), GFP_KERNEL);
 	if (!entry) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/integrity/ima/ima_fs.c linux-3.2.71-pax/security/integrity/ima/ima_fs.c
--- linux-3.2.71/security/integrity/ima/ima_fs.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/security/integrity/ima/ima_fs.c	2012-07-04 19:24:49.044063009 +0200
@@ -28,12 +28,12 @@
 static int valid_policy = 1;
 #define TMPBUFLEN 12
 static ssize_t ima_show_htable_value(char __user *buf, size_t count,
-				     loff_t *ppos, atomic_long_t *val)
+				     loff_t *ppos, atomic_long_unchecked_t *val)
 {
 	char tmpbuf[TMPBUFLEN];
 	ssize_t len;
 
-	len = scnprintf(tmpbuf, TMPBUFLEN, "%li\n", atomic_long_read(val));
+	len = scnprintf(tmpbuf, TMPBUFLEN, "%li\n", atomic_long_read_unchecked(val));
 	return simple_read_from_buffer(buf, count, ppos, tmpbuf, len);
 }
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/integrity/ima/ima.h linux-3.2.71-pax/security/integrity/ima/ima.h
--- linux-3.2.71/security/integrity/ima/ima.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/security/integrity/ima/ima.h	2012-07-04 19:24:49.044063009 +0200
@@ -86,8 +86,8 @@ void ima_add_violation(struct inode *ino
 extern spinlock_t ima_queue_lock;
 
 struct ima_h_table {
-	atomic_long_t len;	/* number of stored measurements in the list */
-	atomic_long_t violations;
+	atomic_long_unchecked_t len;	/* number of stored measurements in the list */
+	atomic_long_unchecked_t violations;
 	struct hlist_head queue[IMA_MEASURE_HTABLE_SIZE];
 };
 extern struct ima_h_table ima_htable;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/integrity/ima/ima_queue.c linux-3.2.71-pax/security/integrity/ima/ima_queue.c
--- linux-3.2.71/security/integrity/ima/ima_queue.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/security/integrity/ima/ima_queue.c	2012-07-04 19:24:49.048063009 +0200
@@ -81,7 +81,7 @@ static int ima_add_digest_entry(struct i
 	INIT_LIST_HEAD(&qe->later);
 	list_add_tail_rcu(&qe->later, &ima_measurements);
 
-	atomic_long_inc(&ima_htable.len);
+	atomic_long_inc_unchecked(&ima_htable.len);
 	key = ima_hash_key(entry->digest);
 	hlist_add_head_rcu(&qe->hnext, &ima_htable.queue[key]);
 	return 0;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/Kconfig linux-3.2.71-pax/security/Kconfig
--- linux-3.2.71/security/Kconfig	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/security/Kconfig	2015-03-23 11:41:29.424325306 +0100
@@ -4,6 +4,690 @@
 
 menu "Security options"
 
+menu "PaX"
+
+	config ARCH_TRACK_EXEC_LIMIT
+	bool
+
+	config PAX_KERNEXEC_PLUGIN
+	bool
+
+	config PAX_PER_CPU_PGD
+	bool
+
+	config TASK_SIZE_MAX_SHIFT
+	int
+	depends on X86_64
+	default 47 if !PAX_PER_CPU_PGD
+	default 42 if PAX_PER_CPU_PGD
+
+	config PAX_USERCOPY_SLABS
+	bool
+
+config PAX
+	bool "Enable various PaX features"
+	depends on ALPHA || ARM || AVR32 || IA64 || MIPS || PARISC || PPC || SPARC || X86
+	help
+	  This allows you to enable various PaX features.  PaX adds
+	  intrusion prevention mechanisms to the kernel that reduce
+	  the risks posed by exploitable memory corruption bugs.
+
+menu "PaX Control"
+	depends on PAX
+
+config PAX_SOFTMODE
+	bool 'Support soft mode'
+	help
+	  Enabling this option will allow you to run PaX in soft mode, that
+	  is, PaX features will not be enforced by default, only on executables
+	  marked explicitly.  You must also enable PT_PAX_FLAGS or XATTR_PAX_FLAGS
+	  support as they are the only way to mark executables for soft mode use.
+
+	  Soft mode can be activated by using the "pax_softmode=1" kernel command
+	  line option on boot.  Furthermore you can control various PaX features
+	  at runtime via the entries in /proc/sys/kernel/pax.
+
+config PAX_EI_PAX
+	bool 'Use legacy ELF header marking' if EXPERT
+	help
+	  Enabling this option will allow you to control PaX features on
+	  a per executable basis via the 'chpax' utility available at
+	  http://pax.grsecurity.net/.  The control flags will be read from
+	  an otherwise reserved part of the ELF header.  This marking has
+	  numerous drawbacks (no support for soft-mode, toolchain does not
+	  know about the non-standard use of the ELF header) therefore it
+	  has been deprecated in favour of PT_PAX_FLAGS and XATTR_PAX_FLAGS
+	  support.
+
+	  Note that if you enable PT_PAX_FLAGS or XATTR_PAX_FLAGS marking
+	  support as well, they will override the legacy EI_PAX marks.
+
+	  If you enable none of the marking options then all applications
+	  will run with PaX enabled on them by default.
+
+config PAX_PT_PAX_FLAGS
+	bool 'Use ELF program header marking'
+	help
+	  Enabling this option will allow you to control PaX features on
+	  a per executable basis via the 'paxctl' utility available at
+	  http://pax.grsecurity.net/.  The control flags will be read from
+	  a PaX specific ELF program header (PT_PAX_FLAGS).  This marking
+	  has the benefits of supporting both soft mode and being fully
+	  integrated into the toolchain (the binutils patch is available
+	  from http://pax.grsecurity.net).
+
+	  Note that if you enable the legacy EI_PAX marking support as well,
+	  the EI_PAX marks will be overridden by the PT_PAX_FLAGS marks.
+
+	  If you enable both PT_PAX_FLAGS and XATTR_PAX_FLAGS support then you
+	  must make sure that the marks are the same if a binary has both marks.
+
+	  If you enable none of the marking options then all applications
+	  will run with PaX enabled on them by default.
+
+config PAX_XATTR_PAX_FLAGS
+	bool 'Use filesystem extended attributes marking'
+	select CIFS_XATTR if CIFS
+	select EXT2_FS_XATTR if EXT2_FS
+	select EXT3_FS_XATTR if EXT3_FS
+	select JFFS2_FS_XATTR if JFFS2_FS
+	select REISERFS_FS_XATTR if REISERFS_FS
+	select SQUASHFS_XATTR if SQUASHFS
+	select TMPFS_XATTR if TMPFS
+	select UBIFS_FS_XATTR if UBIFS_FS
+	help
+	  Enabling this option will allow you to control PaX features on
+	  a per executable basis via the 'setfattr' utility.  The control
+	  flags will be read from the user.pax.flags extended attribute of
+	  the file.  This marking has the benefit of supporting binary-only
+	  applications that self-check themselves (e.g., skype) and would
+	  not tolerate chpax/paxctl changes.  The main drawback is that
+	  extended attributes are not supported by some filesystems (e.g.,
+	  isofs, udf, vfat) so copying files through such filesystems will
+	  lose the extended attributes and these PaX markings.
+
+	  Note that if you enable the legacy EI_PAX marking support as well,
+	  the EI_PAX marks will be overridden by the XATTR_PAX_FLAGS marks.
+
+	  If you enable both PT_PAX_FLAGS and XATTR_PAX_FLAGS support then you
+	  must make sure that the marks are the same if a binary has both marks.
+
+	  If you enable none of the marking options then all applications
+	  will run with PaX enabled on them by default.
+
+choice
+	prompt 'MAC system integration'
+	default PAX_NO_ACL_FLAGS
+	help
+	  Mandatory Access Control systems have the option of controlling
+	  PaX flags on a per executable basis, choose the method supported
+	  by your particular system.
+
+	  - "none": if your MAC system does not interact with PaX,
+	  - "direct": if your MAC system defines pax_set_initial_flags() itself,
+	  - "hook": if your MAC system uses the pax_set_initial_flags_func callback.
+
+	  NOTE: this option is for developers/integrators only.
+
+	config PAX_NO_ACL_FLAGS
+		bool 'none'
+
+	config PAX_HAVE_ACL_FLAGS
+		bool 'direct'
+
+	config PAX_HOOK_ACL_FLAGS
+		bool 'hook'
+endchoice
+
+endmenu
+
+menu "Non-executable pages"
+	depends on PAX
+
+config PAX_NOEXEC
+	bool "Enforce non-executable pages"
+	depends on ALPHA || (ARM && (CPU_V6 || CPU_V7)) || IA64 || MIPS || PARISC || PPC || S390 || SPARC || X86
+	help
+	  By design some architectures do not allow for protecting memory
+	  pages against execution or even if they do, Linux does not make
+	  use of this feature.  In practice this means that if a page is
+	  readable (such as the stack or heap) it is also executable.
+
+	  There is a well known exploit technique that makes use of this
+	  fact and a common programming mistake where an attacker can
+	  introduce code of his choice somewhere in the attacked program's
+	  memory (typically the stack or the heap) and then execute it.
+
+	  If the attacked program was running with different (typically
+	  higher) privileges than that of the attacker, then he can elevate
+	  his own privilege level (e.g. get a root shell, write to files for
+	  which he does not have write access to, etc).
+
+	  Enabling this option will let you choose from various features
+	  that prevent the injection and execution of 'foreign' code in
+	  a program.
+
+	  This will also break programs that rely on the old behaviour and
+	  expect that dynamically allocated memory via the malloc() family
+	  of functions is executable (which it is not).  Notable examples
+	  are the XFree86 4.x server, the java runtime and wine.
+
+config PAX_PAGEEXEC
+	bool "Paging based non-executable pages"
+	depends on PAX_NOEXEC && (!X86_32 || M586 || M586TSC || M586MMX || M686 || MPENTIUMII || MPENTIUMIII || MPENTIUMM || MCORE2 || MPENTIUM4 || MPSC || MATOM || MK7 || MK8 || MWINCHIPC6 || MWINCHIP2 || MWINCHIP3D || MVIAC3_2 || MVIAC7)
+	select X86_PAE if X86_32 && !HIGHMEM4G && (MCORE2 || MPSC || MATOM || MK8)
+	select ARCH_TRACK_EXEC_LIMIT if X86_32
+	help
+	  This implementation is based on the paging feature of the CPU.
+	  On i386 without hardware non-executable bit support there is a
+	  variable but usually low performance impact, however on Intel's
+	  P4 core based CPUs it is very high so you should not enable this
+	  for kernels meant to be used on such CPUs.
+
+	  On alpha, avr32, ia64, parisc, sparc, sparc64, x86_64 and i386
+	  with hardware non-executable bit support there is no performance
+	  impact, on ppc the impact is negligible.
+
+	  Note that several architectures require various emulations due to
+	  badly designed userland ABIs, this will cause a performance impact
+	  but will disappear as soon as userland is fixed. For example, ppc
+	  userland MUST have been built with secure-plt by a recent toolchain.
+
+config PAX_SEGMEXEC
+	bool "Segmentation based non-executable pages"
+	depends on PAX_NOEXEC && X86_32
+	help
+	  This implementation is based on the segmentation feature of the
+	  CPU and has a very small performance impact, however applications
+	  will be limited to a 1.5 GB address space instead of the normal
+	  3 GB.
+
+config PAX_EMUTRAMP
+	bool "Emulate trampolines" if (PAX_PAGEEXEC || PAX_SEGMEXEC) && (PARISC || X86)
+	default y if PARISC
+	help
+	  There are some programs and libraries that for one reason or
+	  another attempt to execute special small code snippets from
+	  non-executable memory pages.  Most notable examples are the
+	  signal handler return code generated by the kernel itself and
+	  the GCC trampolines.
+
+	  If you enabled CONFIG_PAX_PAGEEXEC or CONFIG_PAX_SEGMEXEC then
+	  such programs will no longer work under your kernel.
+
+	  As a remedy you can say Y here and use the 'chpax' or 'paxctl'
+	  utilities to enable trampoline emulation for the affected programs
+	  yet still have the protection provided by the non-executable pages.
+
+	  On parisc you MUST enable this option and EMUSIGRT as well, otherwise
+	  your system will not even boot.
+
+	  Alternatively you can say N here and use the 'chpax' or 'paxctl'
+	  utilities to disable CONFIG_PAX_PAGEEXEC and CONFIG_PAX_SEGMEXEC
+	  for the affected files.
+
+	  NOTE: enabling this feature *may* open up a loophole in the
+	  protection provided by non-executable pages that an attacker
+	  could abuse.  Therefore the best solution is to not have any
+	  files on your system that would require this option.  This can
+	  be achieved by not using libc5 (which relies on the kernel
+	  signal handler return code) and not using or rewriting programs
+	  that make use of the nested function implementation of GCC.
+	  Skilled users can just fix GCC itself so that it implements
+	  nested function calls in a way that does not interfere with PaX.
+
+config PAX_EMUSIGRT
+	bool "Automatically emulate sigreturn trampolines"
+	depends on PAX_EMUTRAMP && PARISC
+	default y
+	help
+	  Enabling this option will have the kernel automatically detect
+	  and emulate signal return trampolines executing on the stack
+	  that would otherwise lead to task termination.
+
+	  This solution is intended as a temporary one for users with
+	  legacy versions of libc (libc5, glibc 2.0, uClibc before 0.9.17,
+	  Modula-3 runtime, etc) or executables linked to such, basically
+	  everything that does not specify its own SA_RESTORER function in
+	  normal executable memory like glibc 2.1+ does.
+
+	  On parisc you MUST enable this option, otherwise your system will
+	  not even boot.
+
+	  NOTE: this feature cannot be disabled on a per executable basis
+	  and since it *does* open up a loophole in the protection provided
+	  by non-executable pages, the best solution is to not have any
+	  files on your system that would require this option.
+
+config PAX_MPROTECT
+	bool "Restrict mprotect()"
+	depends on (PAX_PAGEEXEC || PAX_SEGMEXEC)
+	help
+	  Enabling this option will prevent programs from
+	   - changing the executable status of memory pages that were
+	     not originally created as executable,
+	   - making read-only executable pages writable again,
+	   - creating executable pages from anonymous memory,
+	   - making read-only-after-relocations (RELRO) data pages writable again.
+
+	  You should say Y here to complete the protection provided by
+	  the enforcement of non-executable pages.
+
+	  NOTE: you can use the 'chpax' or 'paxctl' utilities to control
+	  this feature on a per file basis.
+
+config PAX_ELFRELOCS
+	bool "Allow ELF text relocations"
+	depends on PAX_MPROTECT
+	default n
+	help
+	  Non-executable pages and mprotect() restrictions are effective
+	  in preventing the introduction of new executable code into an
+	  attacked task's address space.  There remain only two venues
+	  for this kind of attack: if the attacker can execute already
+	  existing code in the attacked task then he can either have it
+	  create and mmap() a file containing his code or have it mmap()
+	  an already existing ELF library that does not have position
+	  independent code in it and use mprotect() on it to make it
+	  writable and copy his code there.  While protecting against
+	  the former approach is beyond PaX, the latter can be prevented
+	  by having only PIC ELF libraries on one's system (which do not
+	  need to relocate their code).  If you are sure this is your case,
+	  then disable this option otherwise be careful as you may not even
+	  be able to boot or log on your system (for example, some PAM
+	  modules are erroneously compiled as non-PIC by default).
+
+	  NOTE: if you are using dynamic ELF executables (as suggested
+	  when using ASLR) then you must have made sure that you linked
+	  your files using the PIC version of crt1 (the et_dyn.tar.gz package
+	  referenced there has already been updated to support this).
+
+config PAX_ETEXECRELOCS
+	bool "Allow ELF ET_EXEC text relocations"
+	depends on PAX_MPROTECT && (ALPHA || IA64 || PARISC)
+	select PAX_ELFRELOCS
+	default y
+	help
+	  On some architectures there are incorrectly created applications
+	  that require text relocations and would not work without enabling
+	  this option.  If you are an alpha, ia64 or parisc user, you should
+	  enable this option and disable it once you have made sure that
+	  none of your applications need it.
+
+config PAX_EMUPLT
+	bool "Automatically emulate ELF PLT"
+	depends on PAX_MPROTECT && (ALPHA || PARISC || SPARC)
+	default y
+	help
+	  Enabling this option will have the kernel automatically detect
+	  and emulate the Procedure Linkage Table entries in ELF files.
+	  On some architectures such entries are in writable memory, and
+	  become non-executable leading to task termination.  Therefore
+	  it is mandatory that you enable this option on alpha, parisc,
+	  sparc and sparc64, otherwise your system would not even boot.
+
+	  NOTE: this feature *does* open up a loophole in the protection
+	  provided by the non-executable pages, therefore the proper
+	  solution is to modify the toolchain to produce a PLT that does
+	  not need to be writable.
+
+config PAX_DLRESOLVE
+	bool 'Emulate old glibc resolver stub'
+	depends on PAX_EMUPLT && SPARC
+	default n
+	help
+	  This option is needed if userland has an old glibc (before 2.4)
+	  that puts a 'save' instruction into the runtime generated resolver
+	  stub that needs special emulation.
+
+config PAX_KERNEXEC
+	bool "Enforce non-executable kernel pages"
+	depends on X86 && !XEN && (!X86_32 || X86_WP_WORKS_OK)
+	select PAX_PER_CPU_PGD if X86_64 || (X86_32 && X86_PAE)
+	select PAX_KERNEXEC_PLUGIN if X86_64
+	help
+	  This is the kernel land equivalent of PAGEEXEC and MPROTECT,
+	  that is, enabling this option will make it harder to inject
+	  and execute 'foreign' code in kernel memory itself.
+
+choice
+	prompt "Return Address Instrumentation Method"
+	default PAX_KERNEXEC_PLUGIN_METHOD_BTS
+	depends on PAX_KERNEXEC_PLUGIN
+	help
+	  Select the method used to instrument function pointer dereferences.
+	  Note that binary modules cannot be instrumented by this approach.
+
+	  Note that the implementation requires a gcc with plugin support,
+	  i.e., gcc 4.5 or newer.  You may need to install the supporting
+	  headers explicitly in addition to the normal gcc package.
+
+	config PAX_KERNEXEC_PLUGIN_METHOD_BTS
+		bool "bts"
+		help
+		  This method is compatible with binary only modules but has
+		  a higher runtime overhead.
+
+	config PAX_KERNEXEC_PLUGIN_METHOD_OR
+		bool "or"
+		depends on !PARAVIRT
+		help
+		  This method is incompatible with binary only modules but has
+		  a lower runtime overhead.
+endchoice
+
+config PAX_KERNEXEC_PLUGIN_METHOD
+	string
+	default "bts" if PAX_KERNEXEC_PLUGIN_METHOD_BTS
+	default "or" if PAX_KERNEXEC_PLUGIN_METHOD_OR
+	default ""
+
+config PAX_KERNEXEC_MODULE_TEXT
+	int "Minimum amount of memory reserved for module code"
+	default "4"
+	depends on PAX_KERNEXEC && X86_32
+	help
+	  Due to implementation details the kernel must reserve a fixed
+	  amount of memory for runtime allocated code (such as modules)
+	  at compile time that cannot be changed at runtime.  Here you
+	  can specify the minimum amount in MB that will be reserved.
+	  Due to the same implementation details this size will always
+	  be rounded up to the next 2/4 MB boundary (depends on PAE) so
+	  the actually available memory for runtime allocated code will
+	  usually be more than this minimum.
+
+	  The default 4 MB should be enough for most users but if you have
+	  an excessive number of modules (e.g., most distribution configs
+	  compile many drivers as modules) or use huge modules such as
+	  nvidia's kernel driver, you will need to adjust this amount.
+	  A good rule of thumb is to look at your currently loaded kernel
+	  modules and add up their sizes.
+
+endmenu
+
+menu "Address Space Layout Randomization"
+	depends on PAX
+
+config PAX_ASLR
+	bool "Address Space Layout Randomization"
+	help
+	  Many if not most exploit techniques rely on the knowledge of
+	  certain addresses in the attacked program.  The following options
+	  will allow the kernel to apply a certain amount of randomization
+	  to specific parts of the program thereby forcing an attacker to
+	  guess them in most cases.  Any failed guess will most likely crash
+	  the attacked program which allows the kernel to detect such attempts
+	  and react on them.  PaX itself provides no reaction mechanisms,
+	  instead it is strongly encouraged that you make use of grsecurity's
+	  (http://www.grsecurity.net/) built-in crash detection features or
+	  develop one yourself.
+
+	  By saying Y here you can choose to randomize the following areas:
+	   - top of the task's kernel stack
+	   - top of the task's userland stack
+	   - base address for mmap() requests that do not specify one
+	     (this includes all libraries)
+	   - base address of the main executable
+
+	  It is strongly recommended to say Y here as address space layout
+	  randomization has negligible impact on performance yet it provides
+	  a very effective protection.
+
+	  NOTE: you can use the 'chpax' or 'paxctl' utilities to control
+	  this feature on a per file basis.
+
+config PAX_RANDKSTACK
+	bool "Randomize kernel stack base"
+	depends on X86_TSC && X86
+	help
+	  By saying Y here the kernel will randomize every task's kernel
+	  stack on every system call.  This will not only force an attacker
+	  to guess it but also prevent him from making use of possible
+	  leaked information about it.
+
+	  Since the kernel stack is a rather scarce resource, randomization
+	  may cause unexpected stack overflows, therefore you should very
+	  carefully test your system.  Note that once enabled in the kernel
+	  configuration, this feature cannot be disabled on a per file basis.
+
+config PAX_RANDUSTACK
+	bool
+
+config PAX_RANDMMAP
+	bool "Randomize user stack and mmap() bases"
+	depends on PAX_ASLR
+	select PAX_RANDUSTACK
+	help
+	  By saying Y here the kernel will randomize every task's userland
+	  stack and use a randomized base address for mmap() requests that
+	  do not specify one themselves.
+
+	  The stack randomization is done in two steps where the second
+	  one may apply a big amount of shift to the top of the stack and
+	  cause problems for programs that want to use lots of memory (more
+	  than 2.5 GB if SEGMEXEC is not active, or 1.25 GB when it is).
+
+	  As a result of mmap randomization all dynamically loaded libraries
+	  will appear at random addresses and therefore be harder to exploit
+	  by a technique where an attacker attempts to execute library code
+	  for his purposes (e.g. spawn a shell from an exploited program that
+	  is running at an elevated privilege level).
+
+	  Furthermore, if a program is relinked as a dynamic ELF file, its
+	  base address will be randomized as well, completing the full
+	  randomization of the address space layout.  Attacking such programs
+	  becomes a guess game.  You can find an example of doing this at
+	  http://pax.grsecurity.net/et_dyn.tar.gz and practical samples at
+	  http://www.grsecurity.net/grsec-gcc-specs.tar.gz .
+
+	  NOTE: you can use the 'chpax' or 'paxctl' utilities to control this
+	  feature on a per file basis.
+
+endmenu
+
+menu "Miscellaneous hardening features"
+
+config PAX_MEMORY_SANITIZE
+	bool "Sanitize all freed memory"
+	depends on !HIBERNATION && !DEBUG_PAGEALLOC
+	help
+	  By saying Y here the kernel will erase memory pages and slab objects
+	  as soon as they are freed.  This in turn reduces the lifetime of data
+	  stored in them, making it less likely that sensitive information such
+	  as passwords, cryptographic secrets, etc stay in memory for too long.
+
+	  This is especially useful for programs whose runtime is short, long
+	  lived processes and the kernel itself benefit from this as long as
+	  they ensure timely freeing of memory that may hold sensitive
+	  information.
+
+	  A nice side effect of the sanitization of slab objects is the
+	  reduction of possible info leaks caused by padding bytes within the
+	  leaky structures.  Use-after-free bugs for structures containing
+	  pointers can also be detected as dereferencing the sanitized pointer
+	  will generate an access violation.
+
+	  The tradeoff is performance impact, on a single CPU system kernel
+	  compilation sees a 3% slowdown, other systems and workloads may vary
+	  and you are advised to test this feature on your expected workload
+	  before deploying it.
+
+	  The slab sanitization feature excludes a few slab caches per default
+	  for performance reasons.  To extend the feature to cover those as
+	  well, pass "pax_sanitize_slab=full" as kernel command line parameter.
+
+	  To reduce the performance penalty by sanitizing pages only, albeit
+	  limiting the effectiveness of this feature at the same time, slab
+	  sanitization can be disabled with the kernel command line parameter
+	  "pax_sanitize_slab=off".
+
+	  Note that this feature does not protect data stored in live pages,
+	  e.g., process memory swapped to disk may stay there for a long time.
+
+config PAX_MEMORY_STACKLEAK
+	bool "Sanitize kernel stack"
+	depends on X86
+	help
+	  By saying Y here the kernel will erase the kernel stack before it
+	  returns from a system call.  This in turn reduces the information
+	  that a kernel stack leak bug can reveal.
+
+	  Note that such a bug can still leak information that was put on
+	  the stack by the current system call (the one eventually triggering
+	  the bug) but traces of earlier system calls on the kernel stack
+	  cannot leak anymore.
+
+	  The tradeoff is performance impact, on a single CPU system kernel
+	  compilation sees a 1% slowdown, other systems and workloads may vary
+	  and you are advised to test this feature on your expected workload
+	  before deploying it.
+
+	  Note that the full feature requires a gcc with plugin support,
+	  i.e., gcc 4.5 or newer.  You may need to install the supporting
+	  headers explicitly in addition to the normal gcc package.  Using
+	  older gcc versions means that functions with large enough stack
+	  frames may leave uninitialized memory behind that may be exposed
+	  to a later syscall leaking the stack.
+
+config PAX_MEMORY_STRUCTLEAK
+	bool "Forcibly initialize local variables copied to userland"
+	help
+	  By saying Y here the kernel will zero initialize some local
+	  variables that are going to be copied to userland.  This in
+	  turn prevents unintended information leakage from the kernel
+	  stack should later code forget to explicitly set all parts of
+	  the copied variable.
+
+	  The tradeoff is less performance impact than PAX_MEMORY_STACKLEAK
+	  at a much smaller coverage.
+
+	  Note that the implementation requires a gcc with plugin support,
+	  i.e., gcc 4.5 or newer.  You may need to install the supporting
+	  headers explicitly in addition to the normal gcc package.
+
+config PAX_MEMORY_UDEREF
+	bool "Prevent invalid userland pointer dereference"
+	depends on X86 && !UML_X86 && !XEN
+	select PAX_PER_CPU_PGD if X86_64
+	help
+	  By saying Y here the kernel will be prevented from dereferencing
+	  userland pointers in contexts where the kernel expects only kernel
+	  pointers.  This is both a useful runtime debugging feature and a
+	  security measure that prevents exploiting a class of kernel bugs.
+
+	  The tradeoff is that some virtualization solutions may experience
+	  a huge slowdown and therefore you should not enable this feature
+	  for kernels meant to run in such environments.  Whether a given VM
+	  solution is affected or not is best determined by simply trying it
+	  out, the performance impact will be obvious right on boot as this
+	  mechanism engages from very early on.  A good rule of thumb is that
+	  VMs running on CPUs without hardware virtualization support (i.e.,
+	  the majority of IA-32 CPUs) will likely experience the slowdown.
+
+config PAX_REFCOUNT
+	bool "Prevent various kernel object reference counter overflows"
+	depends on (ARM && (CPU_32v6 || CPU_32v6K || CPU_32v7)) || SPARC64 || X86
+	help
+	  By saying Y here the kernel will detect and prevent overflowing
+	  various (but not all) kinds of object reference counters.  Such
+	  overflows can normally occur due to bugs only and are often, if
+	  not always, exploitable.
+
+	  The tradeoff is that data structures protected by an overflowed
+	  refcount will never be freed and therefore will leak memory.  Note
+	  that this leak also happens even without this protection but in
+	  that case the overflow can eventually trigger the freeing of the
+	  data structure while it is still being used elsewhere, resulting
+	  in the exploitable situation that this feature prevents.
+
+	  Since this has a negligible performance impact, you should enable
+	  this feature.
+
+config PAX_USERCOPY
+	bool "Harden heap object copies between kernel and userland"
+	depends on ARM || IA64 || PPC || SPARC || X86
+	depends on SLAB || SLUB || SLOB
+	select PAX_USERCOPY_SLABS
+	help
+	  By saying Y here the kernel will enforce the size of heap objects
+	  when they are copied in either direction between the kernel and
+	  userland, even if only a part of the heap object is copied.
+
+	  Specifically, this checking prevents information leaking from the
+	  kernel heap during kernel to userland copies (if the kernel heap
+	  object is otherwise fully initialized) and prevents kernel heap
+	  overflows during userland to kernel copies.  Only objects belonging
+	  to explictly marked slub types are allowed to be copied at all.
+
+	  Note that the current implementation provides the strictest checks
+	  for the SLUB allocator.
+
+	  If frame pointers are enabled on x86, this option will also restrict
+	  copies into and out of the kernel stack to local variables within a
+	  single frame.
+
+	  Since this has a negligible performance impact, you should enable
+	  this feature.
+
+config PAX_CONSTIFY_PLUGIN
+	bool "Automatically constify eligible structures"
+	depends on !UML && PAX_KERNEXEC
+	help
+	  By saying Y here the compiler will automatically constify a class
+	  of types that contain only function pointers.  This reduces the
+	  kernel's attack surface and also produces a better memory layout.
+
+	  Note that the implementation requires a gcc with plugin support,
+	  i.e., gcc 4.5 or newer.  You may need to install the supporting
+	  headers explicitly in addition to the normal gcc package.
+
+	  Note that if some code really has to modify constified variables
+	  then the source code will have to be patched to allow it.  Examples
+	  can be found in PaX itself (the no_const attribute) and for some
+	  out-of-tree modules at http://www.grsecurity.net/~paxguy1/ .
+
+config PAX_SIZE_OVERFLOW
+	bool "Prevent various integer overflows in function size parameters"
+	depends on X86
+	help
+	  By saying Y here the kernel recomputes expressions of function
+	  arguments marked by a size_overflow attribute with double integer
+	  precision (DImode/TImode for 32/64 bit integer types).
+
+	  The recomputed argument is checked against TYPE_MAX and an event
+	  is logged on overflow and the triggering process is killed.
+
+	  Homepage: http://www.grsecurity.net/~ephox/overflow_plugin/
+
+	  Note that the implementation requires a gcc with plugin support,
+	  i.e., gcc 4.5 or newer.  You may need to install the supporting
+	  headers explicitly in addition to the normal gcc package.
+
+config PAX_LATENT_ENTROPY
+	bool "Generate some entropy during boot and runtime"
+	help
+	  By saying Y here the kernel will instrument some kernel code to
+	  extract some entropy from both original and artificially created
+	  program state.  This will help especially embedded systems where
+	  there is little 'natural' source of entropy normally.  The cost
+	  is some slowdown of the boot process and fork and irq processing.
+
+	  When pax_extra_latent_entropy is passed on the kernel command line,
+	  entropy will be extracted from up to the first 4GB of RAM while the
+	  runtime memory allocator is being initialized.  This costs even more
+	  slowdown of the boot process.
+
+	  Note that the implementation requires a gcc with plugin support,
+	  i.e., gcc 4.5 or newer.  You may need to install the supporting
+	  headers explicitly in addition to the normal gcc package.
+
+	  Note that entropy extracted this way is not cryptographically
+	  secure!
+
+endmenu
+
+endmenu
+
 config KEYS
 	bool "Enable access key retention support"
 	help
@@ -169,7 +853,7 @@ config INTEL_TXT
 config LSM_MMAP_MIN_ADDR
 	int "Low address space for LSM to protect from user allocation"
 	depends on SECURITY && SECURITY_SELINUX
-	default 32768 if ARM
+	default 32768 if ALPHA || ARM || PARISC || SPARC32
 	default 65536
 	help
 	  This is the portion of low virtual memory which should be protected
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/keys/compat.c linux-3.2.71-pax/security/keys/compat.c
--- linux-3.2.71/security/keys/compat.c	2013-03-29 02:18:38.747676281 +0100
+++ linux-3.2.71-pax/security/keys/compat.c	2013-03-29 02:21:50.123666063 +0100
@@ -44,7 +44,7 @@ long compat_keyctl_instantiate_key_iov(
 	if (ret == 0)
 		goto no_payload_free;
 
-	ret = keyctl_instantiate_key_common(id, iov, ioc, ret, ringid);
+	ret = keyctl_instantiate_key_common(id, (const struct iovec __force_user *)iov, ioc, ret, ringid);
 err:
 	if (iov != iovstack)
 		kfree(iov);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/keys/key.c linux-3.2.71-pax/security/keys/key.c
--- linux-3.2.71/security/keys/key.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/security/keys/key.c	2013-03-28 03:29:31.772062293 +0100
@@ -956,7 +956,7 @@ int register_key_type(struct key_type *k
 	}
 
 	/* store the type */
-	list_add(&ktype->link, &key_types_list);
+	pax_list_add((struct list_head *)&ktype->link, &key_types_list);
 	ret = 0;
 
 out:
@@ -976,7 +976,7 @@ EXPORT_SYMBOL(register_key_type);
 void unregister_key_type(struct key_type *ktype)
 {
 	down_write(&key_types_sem);
-	list_del_init(&ktype->link);
+	pax_list_del_init((struct list_head *)&ktype->link);
 	downgrade_write(&key_types_sem);
 	key_gc_keytype(ktype);
 	up_read(&key_types_sem);
@@ -993,9 +993,9 @@ void __init key_init(void)
 			0, SLAB_HWCACHE_ALIGN|SLAB_PANIC, NULL);
 
 	/* add the special key types */
-	list_add_tail(&key_type_keyring.link, &key_types_list);
-	list_add_tail(&key_type_dead.link, &key_types_list);
-	list_add_tail(&key_type_user.link, &key_types_list);
+	pax_list_add_tail((struct list_head *)&key_type_keyring.link, &key_types_list);
+	pax_list_add_tail((struct list_head *)&key_type_dead.link, &key_types_list);
+	pax_list_add_tail((struct list_head *)&key_type_user.link, &key_types_list);
 
 	/* record the root user tracking */
 	rb_link_node(&root_key_user.node,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/keys/keyctl.c linux-3.2.71-pax/security/keys/keyctl.c
--- linux-3.2.71/security/keys/keyctl.c	2013-04-10 12:38:44.614744750 +0200
+++ linux-3.2.71-pax/security/keys/keyctl.c	2013-04-10 12:39:37.822741909 +0200
@@ -921,7 +921,7 @@ static int keyctl_change_reqkey_auth(str
 /*
  * Copy the iovec data from userspace
  */
-static long copy_from_user_iovec(void *buffer, const struct iovec *iov,
+static long copy_from_user_iovec(void *buffer, const struct iovec __user *iov,
 				 unsigned ioc)
 {
 	for (; ioc > 0; ioc--) {
@@ -943,7 +943,7 @@ static long copy_from_user_iovec(void *b
  * If successful, 0 will be returned.
  */
 long keyctl_instantiate_key_common(key_serial_t id,
-				   const struct iovec *payload_iov,
+				   const struct iovec __user *payload_iov,
 				   unsigned ioc,
 				   size_t plen,
 				   key_serial_t ringid)
@@ -1038,7 +1038,7 @@ long keyctl_instantiate_key(key_serial_t
 			[0].iov_len  = plen
 		};
 
-		return keyctl_instantiate_key_common(id, iov, 1, plen, ringid);
+		return keyctl_instantiate_key_common(id, (const struct iovec __force_user *)iov, 1, plen, ringid);
 	}
 
 	return keyctl_instantiate_key_common(id, NULL, 0, 0, ringid);
@@ -1071,7 +1071,7 @@ long keyctl_instantiate_key_iov(key_seri
 	if (ret == 0)
 		goto no_payload_free;
 
-	ret = keyctl_instantiate_key_common(id, iov, ioc, ret, ringid);
+	ret = keyctl_instantiate_key_common(id, (const struct iovec __force_user *)iov, ioc, ret, ringid);
 err:
 	if (iov != iovstack)
 		kfree(iov);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/keys/keyring.c linux-3.2.71-pax/security/keys/keyring.c
--- linux-3.2.71/security/keys/keyring.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/security/keys/keyring.c	2012-07-04 19:24:49.048063009 +0200
@@ -214,15 +214,15 @@ static long keyring_read(const struct ke
 			ret = -EFAULT;
 
 			for (loop = 0; loop < klist->nkeys; loop++) {
+				key_serial_t serial;
 				key = klist->keys[loop];
+				serial = key->serial;
 
 				tmp = sizeof(key_serial_t);
 				if (tmp > buflen)
 					tmp = buflen;
 
-				if (copy_to_user(buffer,
-						 &key->serial,
-						 tmp) != 0)
+				if (copy_to_user(buffer, &serial, tmp))
 					goto error;
 
 				buflen -= tmp;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/security.c linux-3.2.71-pax/security/security.c
--- linux-3.2.71/security/security.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/security/security.c	2013-09-17 02:14:42.105655422 +0200
@@ -26,8 +26,8 @@
 static __initdata char chosen_lsm[SECURITY_NAME_MAX + 1] =
 	CONFIG_DEFAULT_SECURITY;
 
-static struct security_operations *security_ops;
-static struct security_operations default_security_ops = {
+struct security_operations *security_ops __read_only;
+struct security_operations default_security_ops __read_only = {
 	.name	= "default",
 };
 
@@ -66,11 +66,6 @@ int __init security_init(void)
 	return 0;
 }
 
-void reset_security_ops(void)
-{
-	security_ops = &default_security_ops;
-}
-
 /* Save user chosen LSM */
 static int __init choose_lsm(char *str)
 {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/selinux/avc.c linux-3.2.71-pax/security/selinux/avc.c
--- linux-3.2.71/security/selinux/avc.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/security/selinux/avc.c	2013-09-01 20:20:00.907780402 +0200
@@ -59,7 +59,7 @@ struct avc_node {
 struct avc_cache {
 	struct hlist_head	slots[AVC_CACHE_SLOTS]; /* head for avc_node->list */
 	spinlock_t		slots_lock[AVC_CACHE_SLOTS]; /* lock for writes */
-	atomic_t		lru_hint;	/* LRU hint for reclaim scan */
+	atomic_unchecked_t	lru_hint;	/* LRU hint for reclaim scan */
 	atomic_t		active_nodes;
 	u32			latest_notif;	/* latest revocation notification */
 };
@@ -173,7 +173,7 @@ void __init avc_init(void)
 		spin_lock_init(&avc_cache.slots_lock[i]);
 	}
 	atomic_set(&avc_cache.active_nodes, 0);
-	atomic_set(&avc_cache.lru_hint, 0);
+	atomic_set_unchecked(&avc_cache.lru_hint, 0);
 
 	avc_node_cachep = kmem_cache_create("avc_node", sizeof(struct avc_node),
 					     0, SLAB_PANIC, NULL);
@@ -251,7 +251,7 @@ static inline int avc_reclaim_node(void)
 	spinlock_t *lock;
 
 	for (try = 0, ecx = 0; try < AVC_CACHE_SLOTS; try++) {
-		hvalue = atomic_inc_return(&avc_cache.lru_hint) & (AVC_CACHE_SLOTS - 1);
+		hvalue = atomic_inc_return_unchecked(&avc_cache.lru_hint) & (AVC_CACHE_SLOTS - 1);
 		head = &avc_cache.slots[hvalue];
 		lock = &avc_cache.slots_lock[hvalue];
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/selinux/hooks.c linux-3.2.71-pax/security/selinux/hooks.c
--- linux-3.2.71/security/selinux/hooks.c	2014-12-14 21:13:45.346055348 +0100
+++ linux-3.2.71-pax/security/selinux/hooks.c	2014-12-14 21:13:52.850069367 +0100
@@ -95,8 +95,6 @@
 
 #define NUM_SEL_MNT_OPTS 5
 
-extern struct security_operations *security_ops;
-
 /* SECMARK reference count */
 static atomic_t selinux_secmark_refcount = ATOMIC_INIT(0);
 
@@ -5572,7 +5570,7 @@ static int selinux_key_getsecurity(struc
 
 #endif
 
-static struct security_operations selinux_ops = {
+static struct security_operations selinux_ops __read_only = {
 	.name =				"selinux",
 
 	.ptrace_access_check =		selinux_ptrace_access_check,
@@ -5918,6 +5916,9 @@ static void selinux_nf_ip_exit(void)
 #ifdef CONFIG_SECURITY_SELINUX_DISABLE
 static int selinux_disabled;
 
+extern struct security_operations *security_ops;
+extern struct security_operations default_security_ops;
+
 int selinux_disable(void)
 {
 	if (ss_initialized) {
@@ -5935,7 +5936,9 @@ int selinux_disable(void)
 	selinux_disabled = 1;
 	selinux_enabled = 0;
 
-	reset_security_ops();
+	pax_open_kernel();
+	security_ops = &default_security_ops;
+	pax_close_kernel();
 
 	/* Try to destroy the avc node cache */
 	avc_disable();
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/selinux/include/xfrm.h linux-3.2.71-pax/security/selinux/include/xfrm.h
--- linux-3.2.71/security/selinux/include/xfrm.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/security/selinux/include/xfrm.h	2012-07-04 19:24:49.052063009 +0200
@@ -48,7 +48,7 @@ int selinux_xfrm_decode_session(struct s
 
 static inline void selinux_xfrm_notify_policyload(void)
 {
-	atomic_inc(&flow_cache_genid);
+	atomic_inc_unchecked(&flow_cache_genid);
 }
 #else
 static inline int selinux_xfrm_enabled(void)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/smack/smack_lsm.c linux-3.2.71-pax/security/smack/smack_lsm.c
--- linux-3.2.71/security/smack/smack_lsm.c	2015-05-10 09:22:39.887493183 +0200
+++ linux-3.2.71-pax/security/smack/smack_lsm.c	2015-05-10 09:23:09.687494802 +0200
@@ -3483,7 +3483,7 @@ static int smack_inode_getsecctx(struct
 	return 0;
 }
 
-struct security_operations smack_ops = {
+struct security_operations smack_ops __read_only = {
 	.name =				"smack",
 
 	.ptrace_access_check =		smack_ptrace_access_check,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/security/tomoyo/tomoyo.c linux-3.2.71-pax/security/tomoyo/tomoyo.c
--- linux-3.2.71/security/tomoyo/tomoyo.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/security/tomoyo/tomoyo.c	2012-07-04 19:24:49.056063009 +0200
@@ -504,7 +504,7 @@ static int tomoyo_socket_sendmsg(struct
  * tomoyo_security_ops is a "struct security_operations" which is used for
  * registering TOMOYO.
  */
-static struct security_operations tomoyo_security_ops = {
+static struct security_operations tomoyo_security_ops __read_only = {
 	.name                = "tomoyo",
 	.cred_alloc_blank    = tomoyo_cred_alloc_blank,
 	.cred_prepare        = tomoyo_cred_prepare,
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/aoa/codecs/onyx.c linux-3.2.71-pax/sound/aoa/codecs/onyx.c
--- linux-3.2.71/sound/aoa/codecs/onyx.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/aoa/codecs/onyx.c	2012-07-04 19:24:49.056063009 +0200
@@ -54,7 +54,7 @@ struct onyx {
 				spdif_locked:1,
 				analog_locked:1,
 				original_mute:2;
-	int			open_count;
+	local_t			open_count;
 	struct codec_info	*codec_info;
 
 	/* mutex serializes concurrent access to the device
@@ -753,7 +753,7 @@ static int onyx_open(struct codec_info_i
 	struct onyx *onyx = cii->codec_data;
 
 	mutex_lock(&onyx->mutex);
-	onyx->open_count++;
+	local_inc(&onyx->open_count);
 	mutex_unlock(&onyx->mutex);
 
 	return 0;
@@ -765,8 +765,7 @@ static int onyx_close(struct codec_info_
 	struct onyx *onyx = cii->codec_data;
 
 	mutex_lock(&onyx->mutex);
-	onyx->open_count--;
-	if (!onyx->open_count)
+	if (local_dec_and_test(&onyx->open_count))
 		onyx->spdif_locked = onyx->analog_locked = 0;
 	mutex_unlock(&onyx->mutex);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/aoa/codecs/onyx.h linux-3.2.71-pax/sound/aoa/codecs/onyx.h
--- linux-3.2.71/sound/aoa/codecs/onyx.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/aoa/codecs/onyx.h	2012-07-04 19:24:49.056063009 +0200
@@ -11,6 +11,7 @@
 #include <linux/i2c.h>
 #include <asm/pmac_low_i2c.h>
 #include <asm/prom.h>
+#include <asm/local.h>
 
 /* PCM3052 register definitions */
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/core/oss/pcm_oss.c linux-3.2.71-pax/sound/core/oss/pcm_oss.c
--- linux-3.2.71/sound/core/oss/pcm_oss.c	2012-11-18 02:43:53.061510206 +0100
+++ linux-3.2.71-pax/sound/core/oss/pcm_oss.c	2012-11-18 02:43:59.061511207 +0100
@@ -1189,10 +1189,10 @@ snd_pcm_sframes_t snd_pcm_oss_write3(str
 		if (in_kernel) {
 			mm_segment_t fs;
 			fs = snd_enter_user();
-			ret = snd_pcm_lib_write(substream, (void __force __user *)ptr, frames);
+			ret = snd_pcm_lib_write(substream, (void __force_user *)ptr, frames);
 			snd_leave_user(fs);
 		} else {
-			ret = snd_pcm_lib_write(substream, (void __force __user *)ptr, frames);
+			ret = snd_pcm_lib_write(substream, (void __force_user *)ptr, frames);
 		}
 		if (ret != -EPIPE && ret != -ESTRPIPE)
 			break;
@@ -1234,10 +1234,10 @@ snd_pcm_sframes_t snd_pcm_oss_read3(stru
 		if (in_kernel) {
 			mm_segment_t fs;
 			fs = snd_enter_user();
-			ret = snd_pcm_lib_read(substream, (void __force __user *)ptr, frames);
+			ret = snd_pcm_lib_read(substream, (void __force_user *)ptr, frames);
 			snd_leave_user(fs);
 		} else {
-			ret = snd_pcm_lib_read(substream, (void __force __user *)ptr, frames);
+			ret = snd_pcm_lib_read(substream, (void __force_user *)ptr, frames);
 		}
 		if (ret == -EPIPE) {
 			if (runtime->status->state == SNDRV_PCM_STATE_DRAINING) {
@@ -1337,7 +1337,7 @@ static ssize_t snd_pcm_oss_write2(struct
 		struct snd_pcm_plugin_channel *channels;
 		size_t oss_frame_bytes = (runtime->oss.plugin_first->src_width * runtime->oss.plugin_first->src_format.channels) / 8;
 		if (!in_kernel) {
-			if (copy_from_user(runtime->oss.buffer, (const char __force __user *)buf, bytes))
+			if (copy_from_user(runtime->oss.buffer, (const char __force_user *)buf, bytes))
 				return -EFAULT;
 			buf = runtime->oss.buffer;
 		}
@@ -1407,7 +1407,7 @@ static ssize_t snd_pcm_oss_write1(struct
 			}
 		} else {
 			tmp = snd_pcm_oss_write2(substream,
-						 (const char __force *)buf,
+						 (const char __force_kernel *)buf,
 						 runtime->oss.period_bytes, 0);
 			if (tmp <= 0)
 				goto err;
@@ -1433,7 +1433,7 @@ static ssize_t snd_pcm_oss_read2(struct
 	struct snd_pcm_runtime *runtime = substream->runtime;
 	snd_pcm_sframes_t frames, frames1;
 #ifdef CONFIG_SND_PCM_OSS_PLUGINS
-	char __user *final_dst = (char __force __user *)buf;
+	char __user *final_dst = (char __force_user *)buf;
 	if (runtime->oss.plugin_first) {
 		struct snd_pcm_plugin_channel *channels;
 		size_t oss_frame_bytes = (runtime->oss.plugin_last->dst_width * runtime->oss.plugin_last->dst_format.channels) / 8;
@@ -1495,7 +1495,7 @@ static ssize_t snd_pcm_oss_read1(struct
 			xfer += tmp;
 			runtime->oss.buffer_used -= tmp;
 		} else {
-			tmp = snd_pcm_oss_read2(substream, (char __force *)buf,
+			tmp = snd_pcm_oss_read2(substream, (char __force_kernel *)buf,
 						runtime->oss.period_bytes, 0);
 			if (tmp <= 0)
 				goto err;
@@ -1663,7 +1663,7 @@ static int snd_pcm_oss_sync(struct snd_p
 								   size1);
 					size1 /= runtime->channels; /* frames */
 					fs = snd_enter_user();
-					snd_pcm_lib_write(substream, (void __force __user *)runtime->oss.buffer, size1);
+					snd_pcm_lib_write(substream, (void __force_user *)runtime->oss.buffer, size1);
 					snd_leave_user(fs);
 				}
 			} else if (runtime->access == SNDRV_PCM_ACCESS_RW_NONINTERLEAVED) {
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/core/pcm_compat.c linux-3.2.71-pax/sound/core/pcm_compat.c
--- linux-3.2.71/sound/core/pcm_compat.c	2014-12-14 21:13:45.346055348 +0100
+++ linux-3.2.71-pax/sound/core/pcm_compat.c	2014-12-14 21:13:52.850069367 +0100
@@ -31,7 +31,7 @@ static int snd_pcm_ioctl_delay_compat(st
 	int err;
 
 	fs = snd_enter_user();
-	err = snd_pcm_delay(substream, &delay);
+	err = snd_pcm_delay(substream, (snd_pcm_sframes_t __force_user *)&delay);
 	snd_leave_user(fs);
 	if (err < 0)
 		return err;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/core/pcm_native.c linux-3.2.71-pax/sound/core/pcm_native.c
--- linux-3.2.71/sound/core/pcm_native.c	2015-05-10 09:22:39.931493186 +0200
+++ linux-3.2.71-pax/sound/core/pcm_native.c	2015-05-10 09:23:09.703494803 +0200
@@ -2790,11 +2790,11 @@ int snd_pcm_kernel_ioctl(struct snd_pcm_
 	switch (substream->stream) {
 	case SNDRV_PCM_STREAM_PLAYBACK:
 		result = snd_pcm_playback_ioctl1(NULL, substream, cmd,
-						 (void __user *)arg);
+						 (void __force_user *)arg);
 		break;
 	case SNDRV_PCM_STREAM_CAPTURE:
 		result = snd_pcm_capture_ioctl1(NULL, substream, cmd,
-						(void __user *)arg);
+						(void __force_user *)arg);
 		break;
 	default:
 		result = -EINVAL;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/core/seq/seq_device.c linux-3.2.71-pax/sound/core/seq/seq_device.c
--- linux-3.2.71/sound/core/seq/seq_device.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/core/seq/seq_device.c	2012-07-04 19:24:49.060063009 +0200
@@ -64,7 +64,7 @@ struct ops_list {
 	int argsize;		/* argument size */
 
 	/* operators */
-	struct snd_seq_dev_ops ops;
+	struct snd_seq_dev_ops *ops;
 
 	/* registred devices */
 	struct list_head dev_list;	/* list of devices */
@@ -333,7 +333,7 @@ int snd_seq_device_register_driver(char
 
 	mutex_lock(&ops->reg_mutex);
 	/* copy driver operators */
-	ops->ops = *entry;
+	ops->ops = entry;
 	ops->driver |= DRIVER_LOADED;
 	ops->argsize = argsize;
 
@@ -463,7 +463,7 @@ static int init_device(struct snd_seq_de
 			   dev->name, ops->id, ops->argsize, dev->argsize);
 		return -EINVAL;
 	}
-	if (ops->ops.init_device(dev) >= 0) {
+	if (ops->ops->init_device(dev) >= 0) {
 		dev->status = SNDRV_SEQ_DEVICE_REGISTERED;
 		ops->num_init_devices++;
 	} else {
@@ -490,7 +490,7 @@ static int free_device(struct snd_seq_de
 			   dev->name, ops->id, ops->argsize, dev->argsize);
 		return -EINVAL;
 	}
-	if ((result = ops->ops.free_device(dev)) >= 0 || result == -ENXIO) {
+	if ((result = ops->ops->free_device(dev)) >= 0 || result == -ENXIO) {
 		dev->status = SNDRV_SEQ_DEVICE_FREE;
 		dev->driver_data = NULL;
 		ops->num_init_devices--;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/core/sound.c linux-3.2.71-pax/sound/core/sound.c
--- linux-3.2.71/sound/core/sound.c	2012-11-18 02:43:53.061510206 +0100
+++ linux-3.2.71-pax/sound/core/sound.c	2013-06-21 20:15:56.438564312 +0200
@@ -87,7 +87,7 @@ static void snd_request_other(int minor)
 	case SNDRV_MINOR_TIMER:		str = "snd-timer";	break;
 	default:			return;
 	}
-	request_module(str);
+	request_module("%s", str);
 }
 
 #endif	/* modular kernel */
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/drivers/mts64.c linux-3.2.71-pax/sound/drivers/mts64.c
--- linux-3.2.71/sound/drivers/mts64.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/drivers/mts64.c	2012-07-04 19:24:49.060063009 +0200
@@ -29,6 +29,7 @@
 #include <sound/initval.h>
 #include <sound/rawmidi.h>
 #include <sound/control.h>
+#include <asm/local.h>
 
 #define CARD_NAME "Miditerminal 4140"
 #define DRIVER_NAME "MTS64"
@@ -67,7 +68,7 @@ struct mts64 {
 	struct pardevice *pardev;
 	int pardev_claimed;
 
-	int open_count;
+	local_t open_count;
 	int current_midi_output_port;
 	int current_midi_input_port;
 	u8 mode[MTS64_NUM_INPUT_PORTS];
@@ -697,7 +698,7 @@ static int snd_mts64_rawmidi_open(struct
 {
 	struct mts64 *mts = substream->rmidi->private_data;
 
-	if (mts->open_count == 0) {
+	if (local_read(&mts->open_count) == 0) {
 		/* We don't need a spinlock here, because this is just called 
 		   if the device has not been opened before. 
 		   So there aren't any IRQs from the device */
@@ -705,7 +706,7 @@ static int snd_mts64_rawmidi_open(struct
 
 		msleep(50);
 	}
-	++(mts->open_count);
+	local_inc(&mts->open_count);
 
 	return 0;
 }
@@ -715,8 +716,7 @@ static int snd_mts64_rawmidi_close(struc
 	struct mts64 *mts = substream->rmidi->private_data;
 	unsigned long flags;
 
-	--(mts->open_count);
-	if (mts->open_count == 0) {
+	if (local_dec_return(&mts->open_count) == 0) {
 		/* We need the spinlock_irqsave here because we can still
 		   have IRQs at this point */
 		spin_lock_irqsave(&mts->lock, flags);
@@ -725,8 +725,8 @@ static int snd_mts64_rawmidi_close(struc
 
 		msleep(500);
 
-	} else if (mts->open_count < 0)
-		mts->open_count = 0;
+	} else if (local_read(&mts->open_count) < 0)
+		local_set(&mts->open_count, 0);
 
 	return 0;
 }
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/drivers/opl4/opl4_lib.c linux-3.2.71-pax/sound/drivers/opl4/opl4_lib.c
--- linux-3.2.71/sound/drivers/opl4/opl4_lib.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/drivers/opl4/opl4_lib.c	2012-07-04 19:24:49.060063009 +0200
@@ -29,7 +29,7 @@ MODULE_AUTHOR("Clemens Ladisch <clemens@
 MODULE_DESCRIPTION("OPL4 driver");
 MODULE_LICENSE("GPL");
 
-static void inline snd_opl4_wait(struct snd_opl4 *opl4)
+static inline void snd_opl4_wait(struct snd_opl4 *opl4)
 {
 	int timeout = 10;
 	while ((inb(opl4->fm_port) & OPL4_STATUS_BUSY) && --timeout > 0)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/drivers/portman2x4.c linux-3.2.71-pax/sound/drivers/portman2x4.c
--- linux-3.2.71/sound/drivers/portman2x4.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/drivers/portman2x4.c	2012-07-04 19:24:49.064063009 +0200
@@ -48,6 +48,7 @@
 #include <sound/initval.h>
 #include <sound/rawmidi.h>
 #include <sound/control.h>
+#include <asm/local.h>
 
 #define CARD_NAME "Portman 2x4"
 #define DRIVER_NAME "portman"
@@ -85,7 +86,7 @@ struct portman {
 	struct pardevice *pardev;
 	int pardev_claimed;
 
-	int open_count;
+	local_t open_count;
 	int mode[PORTMAN_NUM_INPUT_PORTS];
 	struct snd_rawmidi_substream *midi_input[PORTMAN_NUM_INPUT_PORTS];
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/firewire/amdtp.c linux-3.2.71-pax/sound/firewire/amdtp.c
--- linux-3.2.71/sound/firewire/amdtp.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/firewire/amdtp.c	2012-07-04 19:24:49.064063009 +0200
@@ -371,7 +371,7 @@ static void queue_out_packet(struct amdt
 		ptr = s->pcm_buffer_pointer + data_blocks;
 		if (ptr >= pcm->runtime->buffer_size)
 			ptr -= pcm->runtime->buffer_size;
-		ACCESS_ONCE(s->pcm_buffer_pointer) = ptr;
+		ACCESS_ONCE_RW(s->pcm_buffer_pointer) = ptr;
 
 		s->pcm_period_pointer += data_blocks;
 		if (s->pcm_period_pointer >= pcm->runtime->period_size) {
@@ -511,7 +511,7 @@ EXPORT_SYMBOL(amdtp_out_stream_start);
  */
 void amdtp_out_stream_update(struct amdtp_out_stream *s)
 {
-	ACCESS_ONCE(s->source_node_id_field) =
+	ACCESS_ONCE_RW(s->source_node_id_field) =
 		(fw_parent_device(s->unit)->card->node_id & 0x3f) << 24;
 }
 EXPORT_SYMBOL(amdtp_out_stream_update);
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/firewire/amdtp.h linux-3.2.71-pax/sound/firewire/amdtp.h
--- linux-3.2.71/sound/firewire/amdtp.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/firewire/amdtp.h	2012-07-04 19:24:49.064063009 +0200
@@ -146,7 +146,7 @@ static inline void amdtp_out_stream_pcm_
 static inline void amdtp_out_stream_pcm_trigger(struct amdtp_out_stream *s,
 						struct snd_pcm_substream *pcm)
 {
-	ACCESS_ONCE(s->pcm) = pcm;
+	ACCESS_ONCE_RW(s->pcm) = pcm;
 }
 
 /**
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/firewire/isight.c linux-3.2.71-pax/sound/firewire/isight.c
--- linux-3.2.71/sound/firewire/isight.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/firewire/isight.c	2012-07-04 19:24:49.064063009 +0200
@@ -96,7 +96,7 @@ static void isight_update_pointers(struc
 	ptr += count;
 	if (ptr >= runtime->buffer_size)
 		ptr -= runtime->buffer_size;
-	ACCESS_ONCE(isight->buffer_pointer) = ptr;
+	ACCESS_ONCE_RW(isight->buffer_pointer) = ptr;
 
 	isight->period_counter += count;
 	if (isight->period_counter >= runtime->period_size) {
@@ -307,7 +307,7 @@ static int isight_hw_params(struct snd_p
 	if (err < 0)
 		return err;
 
-	ACCESS_ONCE(isight->pcm_active) = true;
+	ACCESS_ONCE_RW(isight->pcm_active) = true;
 
 	return 0;
 }
@@ -340,7 +340,7 @@ static int isight_hw_free(struct snd_pcm
 {
 	struct isight *isight = substream->private_data;
 
-	ACCESS_ONCE(isight->pcm_active) = false;
+	ACCESS_ONCE_RW(isight->pcm_active) = false;
 
 	mutex_lock(&isight->mutex);
 	isight_stop_streaming(isight);
@@ -433,10 +433,10 @@ static int isight_trigger(struct snd_pcm
 
 	switch (cmd) {
 	case SNDRV_PCM_TRIGGER_START:
-		ACCESS_ONCE(isight->pcm_running) = true;
+		ACCESS_ONCE_RW(isight->pcm_running) = true;
 		break;
 	case SNDRV_PCM_TRIGGER_STOP:
-		ACCESS_ONCE(isight->pcm_running) = false;
+		ACCESS_ONCE_RW(isight->pcm_running) = false;
 		break;
 	default:
 		return -EINVAL;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/oss/sb_audio.c linux-3.2.71-pax/sound/oss/sb_audio.c
--- linux-3.2.71/sound/oss/sb_audio.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/oss/sb_audio.c	2012-07-04 19:24:49.064063009 +0200
@@ -901,7 +901,7 @@ sb16_copy_from_user(int dev,
 		buf16 = (signed short *)(localbuf + localoffs);
 		while (c)
 		{
-			locallen = (c >= LBUFCOPYSIZE ? LBUFCOPYSIZE : c);
+			locallen = ((unsigned)c >= LBUFCOPYSIZE ? LBUFCOPYSIZE : c);
 			if (copy_from_user(lbuf8,
 					   userbuf+useroffs + p,
 					   locallen))
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/oss/swarm_cs4297a.c linux-3.2.71-pax/sound/oss/swarm_cs4297a.c
--- linux-3.2.71/sound/oss/swarm_cs4297a.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/oss/swarm_cs4297a.c	2012-07-04 19:24:49.068063009 +0200
@@ -2606,7 +2606,6 @@ static int __init cs4297a_init(void)
 {
 	struct cs4297a_state *s;
 	u32 pwr, id;
-	mm_segment_t fs;
 	int rval;
 #ifndef CONFIG_BCM_CS4297A_CSWARM
 	u64 cfg;
@@ -2696,22 +2695,23 @@ static int __init cs4297a_init(void)
         if (!rval) {
 		char *sb1250_duart_present;
 
+#if 0
+                mm_segment_t fs;
                 fs = get_fs();
                 set_fs(KERNEL_DS);
-#if 0
                 val = SOUND_MASK_LINE;
                 mixer_ioctl(s, SOUND_MIXER_WRITE_RECSRC, (unsigned long) &val);
                 for (i = 0; i < ARRAY_SIZE(initvol); i++) {
                         val = initvol[i].vol;
                         mixer_ioctl(s, initvol[i].mixch, (unsigned long) &val);
                 }
+                set_fs(fs);
 //                cs4297a_write_ac97(s, 0x18, 0x0808);
 #else
                 //                cs4297a_write_ac97(s, 0x5e, 0x180);
                 cs4297a_write_ac97(s, 0x02, 0x0808);
                 cs4297a_write_ac97(s, 0x18, 0x0808);
 #endif
-                set_fs(fs);
 
                 list_add(&s->list, &cs4297a_devs);
 
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/pci/hda/hda_codec.c linux-3.2.71-pax/sound/pci/hda/hda_codec.c
--- linux-3.2.71/sound/pci/hda/hda_codec.c	2015-02-20 12:37:33.261178766 +0100
+++ linux-3.2.71-pax/sound/pci/hda/hda_codec.c	2015-02-20 12:37:41.929178303 +0100
@@ -852,14 +852,10 @@ find_codec_preset(struct hda_codec *code
 	mutex_unlock(&preset_mutex);
 
 	if (mod_requested < HDA_MODREQ_MAX_COUNT) {
-		char name[32];
 		if (!mod_requested)
-			snprintf(name, sizeof(name), "snd-hda-codec-id:%08x",
-				 codec->vendor_id);
+			request_module("snd-hda-codec-id:%08x", codec->vendor_id);
 		else
-			snprintf(name, sizeof(name), "snd-hda-codec-id:%04x*",
-				 (codec->vendor_id >> 16) & 0xffff);
-		request_module(name);
+			request_module("snd-hda-codec-id:%04x*", (codec->vendor_id >> 16) & 0xffff);
 		mod_requested++;
 		goto again;
 	}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/pci/ymfpci/ymfpci_main.c linux-3.2.71-pax/sound/pci/ymfpci/ymfpci_main.c
--- linux-3.2.71/sound/pci/ymfpci/ymfpci_main.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/pci/ymfpci/ymfpci_main.c	2012-07-04 19:24:49.068063009 +0200
@@ -203,8 +203,8 @@ static void snd_ymfpci_hw_stop(struct sn
 		if ((snd_ymfpci_readl(chip, YDSXGR_STATUS) & 2) == 0)
 			break;
 	}
-	if (atomic_read(&chip->interrupt_sleep_count)) {
-		atomic_set(&chip->interrupt_sleep_count, 0);
+	if (atomic_read_unchecked(&chip->interrupt_sleep_count)) {
+		atomic_set_unchecked(&chip->interrupt_sleep_count, 0);
 		wake_up(&chip->interrupt_sleep);
 	}
       __end:
@@ -788,7 +788,7 @@ static void snd_ymfpci_irq_wait(struct s
 		 	continue;
 		init_waitqueue_entry(&wait, current);
 		add_wait_queue(&chip->interrupt_sleep, &wait);
-		atomic_inc(&chip->interrupt_sleep_count);
+		atomic_inc_unchecked(&chip->interrupt_sleep_count);
 		schedule_timeout_uninterruptible(msecs_to_jiffies(50));
 		remove_wait_queue(&chip->interrupt_sleep, &wait);
 	}
@@ -826,8 +826,8 @@ static irqreturn_t snd_ymfpci_interrupt(
 		snd_ymfpci_writel(chip, YDSXGR_MODE, mode);
 		spin_unlock(&chip->reg_lock);
 
-		if (atomic_read(&chip->interrupt_sleep_count)) {
-			atomic_set(&chip->interrupt_sleep_count, 0);
+		if (atomic_read_unchecked(&chip->interrupt_sleep_count)) {
+			atomic_set_unchecked(&chip->interrupt_sleep_count, 0);
 			wake_up(&chip->interrupt_sleep);
 		}
 	}
@@ -2382,7 +2382,7 @@ int __devinit snd_ymfpci_create(struct s
 	spin_lock_init(&chip->reg_lock);
 	spin_lock_init(&chip->voice_lock);
 	init_waitqueue_head(&chip->interrupt_sleep);
-	atomic_set(&chip->interrupt_sleep_count, 0);
+	atomic_set_unchecked(&chip->interrupt_sleep_count, 0);
 	chip->card = card;
 	chip->pci = pci;
 	chip->irq = -1;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/soc/fsl/fsl_ssi.c linux-3.2.71-pax/sound/soc/fsl/fsl_ssi.c
--- linux-3.2.71/sound/soc/fsl/fsl_ssi.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/soc/fsl/fsl_ssi.c	2013-05-23 23:03:18.278325309 +0200
@@ -608,7 +608,7 @@ static int __devinit fsl_ssi_probe(struc
 {
 	struct fsl_ssi_private *ssi_private;
 	int ret = 0;
-	struct device_attribute *dev_attr = NULL;
+	device_attribute_no_const *dev_attr = NULL;
 	struct device_node *np = pdev->dev.of_node;
 	const char *p, *sprop;
 	const uint32_t *iprop;
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/soc/soc-pcm.c linux-3.2.71-pax/sound/soc/soc-pcm.c
--- linux-3.2.71/sound/soc/soc-pcm.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/soc/soc-pcm.c	2013-01-17 00:43:31.202564576 +0100
@@ -627,13 +627,15 @@ int soc_new_pcm(struct snd_soc_pcm_runti
 	rtd->pcm = pcm;
 	pcm->private_data = rtd;
 	if (platform->driver->ops) {
-		soc_pcm_ops.mmap = platform->driver->ops->mmap;
-		soc_pcm_ops.pointer = platform->driver->ops->pointer;
-		soc_pcm_ops.ioctl = platform->driver->ops->ioctl;
-		soc_pcm_ops.copy = platform->driver->ops->copy;
-		soc_pcm_ops.silence = platform->driver->ops->silence;
-		soc_pcm_ops.ack = platform->driver->ops->ack;
-		soc_pcm_ops.page = platform->driver->ops->page;
+		pax_open_kernel();
+		*(void **)&soc_pcm_ops.mmap = platform->driver->ops->mmap;
+		*(void **)&soc_pcm_ops.pointer = platform->driver->ops->pointer;
+		*(void **)&soc_pcm_ops.ioctl = platform->driver->ops->ioctl;
+		*(void **)&soc_pcm_ops.copy = platform->driver->ops->copy;
+		*(void **)&soc_pcm_ops.silence = platform->driver->ops->silence;
+		*(void **)&soc_pcm_ops.ack = platform->driver->ops->ack;
+		*(void **)&soc_pcm_ops.page = platform->driver->ops->page;
+		pax_close_kernel();
 	}
 
 	if (playback)
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/sound_core.c linux-3.2.71-pax/sound/sound_core.c
--- linux-3.2.71/sound/sound_core.c	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/sound/sound_core.c	2013-06-21 20:15:56.438564312 +0200
@@ -293,7 +293,7 @@ retry:
 	}
 
 	device_create(sound_class, dev, MKDEV(SOUND_MAJOR, s->unit_minor),
-		      NULL, s->name+6);
+		      NULL, "%s", s->name+6);
 	return s->unit_minor;
 
 fail:
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/sound/usb/card.h linux-3.2.71-pax/sound/usb/card.h
--- linux-3.2.71/sound/usb/card.h	2013-06-21 21:22:07.706352277 +0200
+++ linux-3.2.71-pax/sound/usb/card.h	2013-06-21 21:21:57.542352820 +0200
@@ -45,6 +45,7 @@ struct snd_urb_ops {
 	int (*prepare_sync)(struct snd_usb_substream *subs, struct snd_pcm_runtime *runtime, struct urb *u);
 	int (*retire_sync)(struct snd_usb_substream *subs, struct snd_pcm_runtime *runtime, struct urb *u);
 };
+typedef struct snd_urb_ops __no_const snd_urb_ops_no_const;
 
 struct snd_usb_substream {
 	struct snd_usb_stream *stream;
@@ -96,7 +97,7 @@ struct snd_usb_substream {
 	struct snd_pcm_hw_constraint_list rate_list;	/* limited rates */
 	spinlock_t lock;
 
-	struct snd_urb_ops ops;		/* callbacks (must be filled at init) */
+	snd_urb_ops_no_const ops;	/* callbacks (must be filled at init) */
 	int last_frame_number;          /* stored frame number */
 	int last_delay;                 /* stored delay */
 };
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/checker_plugin.c linux-3.2.71-pax/tools/gcc/checker_plugin.c
--- linux-3.2.71/tools/gcc/checker_plugin.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/checker_plugin.c	2014-01-28 04:21:56.417073846 +0100
@@ -0,0 +1,150 @@
+/*
+ * Copyright 2011-2014 by the PaX Team <pageexec@freemail.hu>
+ * Licensed under the GPL v2
+ *
+ * Note: the choice of the license means that the compilation process is
+ *       NOT 'eligible' as defined by gcc's library exception to the GPL v3,
+ *       but for the kernel it doesn't matter since it doesn't link against
+ *       any of the gcc libraries
+ *
+ * gcc plugin to implement various sparse (source code checker) features
+ *
+ * TODO:
+ * - define separate __iomem, __percpu and __rcu address spaces (lots of code to patch)
+ *
+ * BUGS:
+ * - none known
+ */
+
+#include "gcc-common.h"
+
+extern void c_register_addr_space (const char *str, addr_space_t as);
+extern enum machine_mode default_addr_space_pointer_mode (addr_space_t);
+extern enum machine_mode default_addr_space_address_mode (addr_space_t);
+extern bool default_addr_space_valid_pointer_mode(enum machine_mode mode, addr_space_t as);
+extern bool default_addr_space_legitimate_address_p(enum machine_mode mode, rtx mem, bool strict, addr_space_t as);
+extern rtx default_addr_space_legitimize_address(rtx x, rtx oldx, enum machine_mode mode, addr_space_t as);
+
+int plugin_is_GPL_compatible;
+
+static struct plugin_info checker_plugin_info = {
+	.version	= "201304082245",
+	.help		= NULL,
+};
+
+#define ADDR_SPACE_KERNEL		0
+#define ADDR_SPACE_FORCE_KERNEL		1
+#define ADDR_SPACE_USER			2
+#define ADDR_SPACE_FORCE_USER		3
+#define ADDR_SPACE_IOMEM		0
+#define ADDR_SPACE_FORCE_IOMEM		0
+#define ADDR_SPACE_PERCPU		0
+#define ADDR_SPACE_FORCE_PERCPU		0
+#define ADDR_SPACE_RCU			0
+#define ADDR_SPACE_FORCE_RCU		0
+
+static enum machine_mode checker_addr_space_pointer_mode(addr_space_t addrspace)
+{
+	return default_addr_space_pointer_mode(ADDR_SPACE_GENERIC);
+}
+
+static enum machine_mode checker_addr_space_address_mode(addr_space_t addrspace)
+{
+	return default_addr_space_address_mode(ADDR_SPACE_GENERIC);
+}
+
+static bool checker_addr_space_valid_pointer_mode(enum machine_mode mode, addr_space_t as)
+{
+	return default_addr_space_valid_pointer_mode(mode, as);
+}
+
+static bool checker_addr_space_legitimate_address_p(enum machine_mode mode, rtx mem, bool strict, addr_space_t as)
+{
+	return default_addr_space_legitimate_address_p(mode, mem, strict, ADDR_SPACE_GENERIC);
+}
+
+static rtx checker_addr_space_legitimize_address(rtx x, rtx oldx, enum machine_mode mode, addr_space_t as)
+{
+	return default_addr_space_legitimize_address(x, oldx, mode, as);
+}
+
+static bool checker_addr_space_subset_p(addr_space_t subset, addr_space_t superset)
+{
+	if (subset == ADDR_SPACE_FORCE_KERNEL && superset == ADDR_SPACE_KERNEL)
+		return true;
+
+	if (subset == ADDR_SPACE_FORCE_USER && superset == ADDR_SPACE_USER)
+		return true;
+
+	if (subset == ADDR_SPACE_FORCE_IOMEM && superset == ADDR_SPACE_IOMEM)
+		return true;
+
+	if (subset == ADDR_SPACE_KERNEL && superset == ADDR_SPACE_FORCE_USER)
+		return true;
+
+	if (subset == ADDR_SPACE_KERNEL && superset == ADDR_SPACE_FORCE_IOMEM)
+		return true;
+
+	if (subset == ADDR_SPACE_USER && superset == ADDR_SPACE_FORCE_KERNEL)
+		return true;
+
+	if (subset == ADDR_SPACE_IOMEM && superset == ADDR_SPACE_FORCE_KERNEL)
+		return true;
+
+	return subset == superset;
+}
+
+static rtx checker_addr_space_convert(rtx op, tree from_type, tree to_type)
+{
+//	addr_space_t from_as = TYPE_ADDR_SPACE(TREE_TYPE(from_type));
+//	addr_space_t to_as = TYPE_ADDR_SPACE(TREE_TYPE(to_type));
+
+	return op;
+}
+
+static void register_checker_address_spaces(void *event_data, void *data)
+{
+	c_register_addr_space("__kernel", ADDR_SPACE_KERNEL);
+	c_register_addr_space("__force_kernel", ADDR_SPACE_FORCE_KERNEL);
+	c_register_addr_space("__user", ADDR_SPACE_USER);
+	c_register_addr_space("__force_user", ADDR_SPACE_FORCE_USER);
+//	c_register_addr_space("__iomem", ADDR_SPACE_IOMEM);
+//	c_register_addr_space("__force_iomem", ADDR_SPACE_FORCE_IOMEM);
+//	c_register_addr_space("__percpu", ADDR_SPACE_PERCPU);
+//	c_register_addr_space("__force_percpu", ADDR_SPACE_FORCE_PERCPU);
+//	c_register_addr_space("__rcu", ADDR_SPACE_RCU);
+//	c_register_addr_space("__force_rcu", ADDR_SPACE_FORCE_RCU);
+
+	targetm.addr_space.pointer_mode		= checker_addr_space_pointer_mode;
+	targetm.addr_space.address_mode		= checker_addr_space_address_mode;
+	targetm.addr_space.valid_pointer_mode	= checker_addr_space_valid_pointer_mode;
+	targetm.addr_space.legitimate_address_p	= checker_addr_space_legitimate_address_p;
+//	targetm.addr_space.legitimize_address	= checker_addr_space_legitimize_address;
+	targetm.addr_space.subset_p		= checker_addr_space_subset_p;
+	targetm.addr_space.convert		= checker_addr_space_convert;
+}
+
+int plugin_init(struct plugin_name_args *plugin_info, struct plugin_gcc_version *version)
+{
+	const char * const plugin_name = plugin_info->base_name;
+	const int argc = plugin_info->argc;
+	const struct plugin_argument * const argv = plugin_info->argv;
+	int i;
+
+	if (!plugin_default_version_check(version, &gcc_version)) {
+		error(G_("incompatible gcc/plugin versions"));
+		return 1;
+	}
+
+	register_callback(plugin_name, PLUGIN_INFO, NULL, &checker_plugin_info);
+
+	for (i = 0; i < argc; ++i)
+		error(G_("unkown option '-fplugin-arg-%s-%s'"), plugin_name, argv[i].key);
+
+	if (TARGET_64BIT == 0)
+		return 0;
+
+	register_callback(plugin_name, PLUGIN_PRAGMAS, register_checker_address_spaces, NULL);
+
+	return 0;
+}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/colorize_plugin.c linux-3.2.71-pax/tools/gcc/colorize_plugin.c
--- linux-3.2.71/tools/gcc/colorize_plugin.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/colorize_plugin.c	2015-04-30 03:07:38.396532395 +0200
@@ -0,0 +1,215 @@
+/*
+ * Copyright 2012-2015 by PaX Team <pageexec@freemail.hu>
+ * Licensed under the GPL v2
+ *
+ * Note: the choice of the license means that the compilation process is
+ *       NOT 'eligible' as defined by gcc's library exception to the GPL v3,
+ *       but for the kernel it doesn't matter since it doesn't link against
+ *       any of the gcc libraries
+ *
+ * gcc plugin to colorize diagnostic output
+ *
+ */
+
+#include "gcc-common.h"
+
+int plugin_is_GPL_compatible;
+
+static struct plugin_info colorize_plugin_info = {
+	.version	= "201404202350",
+	.help		= "color=[never|always|auto]\tdetermine when to colorize\n",
+};
+
+#define GREEN		"\033[32m\033[K"
+#define LIGHTGREEN	"\033[1;32m\033[K"
+#define YELLOW		"\033[33m\033[K"
+#define LIGHTYELLOW	"\033[1;33m\033[K"
+#define RED		"\033[31m\033[K"
+#define LIGHTRED	"\033[1;31m\033[K"
+#define BLUE		"\033[34m\033[K"
+#define LIGHTBLUE	"\033[1;34m\033[K"
+#define BRIGHT		"\033[1;m\033[K"
+#define NORMAL		"\033[m\033[K"
+
+static diagnostic_starter_fn old_starter;
+static diagnostic_finalizer_fn old_finalizer;
+
+static void start_colorize(diagnostic_context *context, diagnostic_info *diagnostic)
+{
+	const char *color;
+	char *newprefix;
+
+	switch (diagnostic->kind) {
+	case DK_NOTE:
+		color = LIGHTBLUE;
+		break;
+
+	case DK_PEDWARN:
+	case DK_WARNING:
+		color = LIGHTYELLOW;
+		break;
+
+	case DK_ERROR:
+	case DK_FATAL:
+	case DK_ICE:
+	case DK_PERMERROR:
+	case DK_SORRY:
+		color = LIGHTRED;
+		break;
+
+	default:
+		color = NORMAL;
+	}
+
+	old_starter(context, diagnostic);
+	if (-1 == asprintf(&newprefix, "%s%s" NORMAL, color, context->printer->prefix))
+		return;
+	pp_destroy_prefix(context->printer);
+	pp_set_prefix(context->printer, newprefix);
+}
+
+static void finalize_colorize(diagnostic_context *context, diagnostic_info *diagnostic)
+{
+	old_finalizer(context, diagnostic);
+}
+
+static void colorize_arm(void)
+{
+	old_starter = diagnostic_starter(global_dc);
+	old_finalizer = diagnostic_finalizer(global_dc);
+
+	diagnostic_starter(global_dc) = start_colorize;
+	diagnostic_finalizer(global_dc) = finalize_colorize;
+}
+
+static unsigned int execute_colorize_rearm(void)
+{
+	if (diagnostic_starter(global_dc) == start_colorize)
+		return 0;
+
+	colorize_arm();
+	return 0;
+}
+
+#if BUILDING_GCC_VERSION >= 4009
+namespace {
+static const struct pass_data colorize_rearm_pass_data = {
+#else
+struct simple_ipa_opt_pass colorize_rearm_pass = {
+	.pass = {
+#endif
+		.type			= SIMPLE_IPA_PASS,
+		.name			= "colorize_rearm",
+#if BUILDING_GCC_VERSION >= 4008
+		.optinfo_flags		= OPTGROUP_NONE,
+#endif
+#if BUILDING_GCC_VERSION >= 5000
+#elif BUILDING_GCC_VERSION == 4009
+		.has_gate		= false,
+		.has_execute		= true,
+#else
+		.gate			= NULL,
+		.execute		= execute_colorize_rearm,
+		.sub			= NULL,
+		.next			= NULL,
+		.static_pass_number	= 0,
+#endif
+		.tv_id			= TV_NONE,
+		.properties_required	= 0,
+		.properties_provided	= 0,
+		.properties_destroyed	= 0,
+		.todo_flags_start	= 0,
+		.todo_flags_finish	= 0
+#if BUILDING_GCC_VERSION < 4009
+	}
+#endif
+};
+
+#if BUILDING_GCC_VERSION >= 4009
+class colorize_rearm_pass : public simple_ipa_opt_pass {
+public:
+	colorize_rearm_pass() : simple_ipa_opt_pass(colorize_rearm_pass_data, g) {}
+#if BUILDING_GCC_VERSION >= 5000
+	virtual unsigned int execute(function *) { return execute_colorize_rearm(); }
+#else
+	unsigned int execute() { return execute_colorize_rearm(); }
+#endif
+};
+}
+
+static opt_pass *make_colorize_rearm_pass(void)
+{
+	return new colorize_rearm_pass();
+}
+#else
+static struct opt_pass *make_colorize_rearm_pass(void)
+{
+	return &colorize_rearm_pass.pass;
+}
+#endif
+
+static void colorize_start_unit(void *gcc_data, void *user_data)
+{
+	colorize_arm();
+}
+
+static bool should_colorize(void)
+{
+#if BUILDING_GCC_VERSION >= 4009
+	return false;
+#else
+	char const *t = getenv("TERM");
+
+	return t && strcmp(t, "dumb") && isatty(STDERR_FILENO);
+#endif
+}
+
+int plugin_init(struct plugin_name_args *plugin_info, struct plugin_gcc_version *version)
+{
+	const char * const plugin_name = plugin_info->base_name;
+	const int argc = plugin_info->argc;
+	const struct plugin_argument * const argv = plugin_info->argv;
+	int i;
+	struct register_pass_info colorize_rearm_pass_info;
+	bool colorize;
+
+	colorize_rearm_pass_info.pass				= make_colorize_rearm_pass();
+	colorize_rearm_pass_info.reference_pass_name		= "*free_lang_data";
+	colorize_rearm_pass_info.ref_pass_instance_number	= 1;
+	colorize_rearm_pass_info.pos_op 			= PASS_POS_INSERT_AFTER;
+
+	if (!plugin_default_version_check(version, &gcc_version)) {
+		error(G_("incompatible gcc/plugin versions"));
+		return 1;
+	}
+
+	register_callback(plugin_name, PLUGIN_INFO, NULL, &colorize_plugin_info);
+
+	colorize = getenv("GCC_COLORS") ? should_colorize() : false;
+
+	for (i = 0; i < argc; ++i) {
+		if (!strcmp(argv[i].key, "color")) {
+			if (!argv[i].value) {
+				error(G_("no value supplied for option '-fplugin-arg-%s-%s'"), plugin_name, argv[i].key);
+				continue;
+			}
+			if (!strcmp(argv[i].value, "always"))
+				colorize = true;
+			else if (!strcmp(argv[i].value, "never"))
+				colorize = false;
+			else if (!strcmp(argv[i].value, "auto"))
+				colorize = should_colorize();
+			else
+				error(G_("invalid option argument '-fplugin-arg-%s-%s=%s'"), plugin_name, argv[i].key, argv[i].value);
+			continue;
+		}
+		error(G_("unkown option '-fplugin-arg-%s-%s'"), plugin_name, argv[i].key);
+	}
+
+	if (colorize) {
+		// TODO: parse GCC_COLORS as used by gcc 4.9+
+		register_callback(plugin_name, PLUGIN_START_UNIT, &colorize_start_unit, NULL);
+		register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &colorize_rearm_pass_info);
+	}
+	return 0;
+}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/constify_plugin.c linux-3.2.71-pax/tools/gcc/constify_plugin.c
--- linux-3.2.71/tools/gcc/constify_plugin.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/constify_plugin.c	2015-07-13 19:15:01.598868640 +0200
@@ -0,0 +1,568 @@
+/*
+ * Copyright 2011 by Emese Revfy <re.emese@gmail.com>
+ * Copyright 2011-2015 by PaX Team <pageexec@freemail.hu>
+ * Licensed under the GPL v2, or (at your option) v3
+ *
+ * This gcc plugin constifies all structures which contain only function pointers or are explicitly marked for constification.
+ *
+ * Homepage:
+ * http://www.grsecurity.net/~ephox/const_plugin/
+ *
+ * Usage:
+ * $ gcc -I`gcc -print-file-name=plugin`/include -fPIC -shared -O2 -o constify_plugin.so constify_plugin.c
+ * $ gcc -fplugin=constify_plugin.so test.c -O2
+ */
+
+#include "gcc-common.h"
+
+// unused C type flag in all versions 4.5-5.0
+#define TYPE_CONSTIFY_VISITED(TYPE) TYPE_LANG_FLAG_4(TYPE)
+
+int plugin_is_GPL_compatible;
+
+static struct plugin_info const_plugin_info = {
+	.version	= "201401270210",
+	.help		= "no-constify\tturn off constification\n",
+};
+
+typedef struct {
+	bool has_fptr_field;
+	bool has_writable_field;
+	bool has_do_const_field;
+	bool has_no_const_field;
+} constify_info;
+
+static const_tree get_field_type(const_tree field)
+{
+	return strip_array_types(TREE_TYPE(field));
+}
+
+static bool is_fptr(const_tree field)
+{
+	const_tree ptr = get_field_type(field);
+
+	if (TREE_CODE(ptr) != POINTER_TYPE)
+		return false;
+
+	return TREE_CODE(TREE_TYPE(ptr)) == FUNCTION_TYPE;
+}
+
+/*
+ * determine whether the given structure type meets the requirements for automatic constification,
+ * including the constification attributes on nested structure types
+ */
+static void constifiable(const_tree node, constify_info *cinfo)
+{
+	const_tree field;
+
+	gcc_assert(TREE_CODE(node) == RECORD_TYPE || TREE_CODE(node) == UNION_TYPE);
+
+	// e.g., pointer to structure fields while still constructing the structure type
+	if (TYPE_FIELDS(node) == NULL_TREE)
+		return;
+
+	for (field = TYPE_FIELDS(node); field; field = TREE_CHAIN(field)) {
+		const_tree type = get_field_type(field);
+		enum tree_code code = TREE_CODE(type);
+
+		if (node == type)
+			continue;
+
+		if (is_fptr(field))
+			cinfo->has_fptr_field = true;
+		else if (!TREE_READONLY(field))
+			cinfo->has_writable_field = true;
+
+		if (code == RECORD_TYPE || code == UNION_TYPE) {
+			if (lookup_attribute("do_const", TYPE_ATTRIBUTES(type)))
+				cinfo->has_do_const_field = true;
+			else if (lookup_attribute("no_const", TYPE_ATTRIBUTES(type)))
+				cinfo->has_no_const_field = true;
+			else
+				constifiable(type, cinfo);
+		}
+	}
+}
+
+static bool constified(const_tree node)
+{
+	constify_info cinfo = {
+		.has_fptr_field = false,
+		.has_writable_field = false,
+		.has_do_const_field = false,
+		.has_no_const_field = false
+	};
+
+	gcc_assert(TREE_CODE(node) == RECORD_TYPE || TREE_CODE(node) == UNION_TYPE);
+
+	if (lookup_attribute("no_const", TYPE_ATTRIBUTES(node))) {
+//		gcc_assert(!TYPE_READONLY(node));
+		return false;
+	}
+
+	if (lookup_attribute("do_const", TYPE_ATTRIBUTES(node))) {
+		gcc_assert(TYPE_READONLY(node));
+		return true;
+	}
+
+	constifiable(node, &cinfo);
+	if ((!cinfo.has_fptr_field || cinfo.has_writable_field) && !cinfo.has_do_const_field)
+		return false;
+
+	return TYPE_READONLY(node);
+}
+
+static void deconstify_tree(tree node);
+
+static void deconstify_type(tree type)
+{
+	tree field;
+
+	gcc_assert(TREE_CODE(type) == RECORD_TYPE || TREE_CODE(type) == UNION_TYPE);
+
+	for (field = TYPE_FIELDS(type); field; field = TREE_CHAIN(field)) {
+		const_tree fieldtype = get_field_type(field);
+
+		// special case handling of simple ptr-to-same-array-type members
+		if (TREE_CODE(TREE_TYPE(field)) == POINTER_TYPE) {
+			tree ptrtype = TREE_TYPE(TREE_TYPE(field));
+
+			if (TREE_TYPE(TREE_TYPE(field)) == type)
+				continue;
+			if (TREE_CODE(ptrtype) != RECORD_TYPE && TREE_CODE(ptrtype) != UNION_TYPE)
+				continue;
+			if (!constified(ptrtype))
+				continue;
+			if (TYPE_MAIN_VARIANT(ptrtype) == TYPE_MAIN_VARIANT(type)) {
+				TREE_TYPE(field) = copy_node(TREE_TYPE(field));
+				TREE_TYPE(TREE_TYPE(field)) = build_qualified_type(type, TYPE_QUALS(ptrtype) & ~TYPE_QUAL_CONST);
+			}
+			continue;
+		}
+		if (TREE_CODE(fieldtype) != RECORD_TYPE && TREE_CODE(fieldtype) != UNION_TYPE)
+			continue;
+		if (!constified(fieldtype))
+			continue;
+
+		deconstify_tree(field);
+		TREE_READONLY(field) = 0;
+	}
+	TYPE_READONLY(type) = 0;
+	C_TYPE_FIELDS_READONLY(type) = 0;
+	if (lookup_attribute("do_const", TYPE_ATTRIBUTES(type))) {
+		TYPE_ATTRIBUTES(type) = copy_list(TYPE_ATTRIBUTES(type));
+		TYPE_ATTRIBUTES(type) = remove_attribute("do_const", TYPE_ATTRIBUTES(type));
+	}
+}
+
+static void deconstify_tree(tree node)
+{
+	tree old_type, new_type, field;
+
+	old_type = TREE_TYPE(node);
+	while (TREE_CODE(old_type) == ARRAY_TYPE && TREE_CODE(TREE_TYPE(old_type)) != ARRAY_TYPE) {
+		node = TREE_TYPE(node) = copy_node(old_type);
+		old_type = TREE_TYPE(old_type);
+	}
+
+	gcc_assert(TREE_CODE(old_type) == RECORD_TYPE || TREE_CODE(old_type) == UNION_TYPE);
+	gcc_assert(TYPE_READONLY(old_type) && (TYPE_QUALS(old_type) & TYPE_QUAL_CONST));
+
+	new_type = build_qualified_type(old_type, TYPE_QUALS(old_type) & ~TYPE_QUAL_CONST);
+	TYPE_FIELDS(new_type) = copy_list(TYPE_FIELDS(new_type));
+	for (field = TYPE_FIELDS(new_type); field; field = TREE_CHAIN(field))
+		DECL_FIELD_CONTEXT(field) = new_type;
+
+	deconstify_type(new_type);
+
+	TREE_TYPE(node) = new_type;
+}
+
+static tree handle_no_const_attribute(tree *node, tree name, tree args, int flags, bool *no_add_attrs)
+{
+	tree type;
+	constify_info cinfo = {
+		.has_fptr_field = false,
+		.has_writable_field = false,
+		.has_do_const_field = false,
+		.has_no_const_field = false
+	};
+
+	*no_add_attrs = true;
+	if (TREE_CODE(*node) == FUNCTION_DECL) {
+		error("%qE attribute does not apply to functions (%qF)", name, *node);
+		return NULL_TREE;
+	}
+
+	if (TREE_CODE(*node) == PARM_DECL) {
+		error("%qE attribute does not apply to function parameters (%qD)", name, *node);
+		return NULL_TREE;
+	}
+
+	if (TREE_CODE(*node) == VAR_DECL) {
+		error("%qE attribute does not apply to variables (%qD)", name, *node);
+		return NULL_TREE;
+	}
+
+	if (TYPE_P(*node)) {
+		type = *node;
+	} else {
+		gcc_assert(TREE_CODE(*node) == TYPE_DECL);
+		type = TREE_TYPE(*node);
+	}
+
+	if (TREE_CODE(type) != RECORD_TYPE && TREE_CODE(type) != UNION_TYPE) {
+		error("%qE attribute used on %qT applies to struct and union types only", name, type);
+		return NULL_TREE;
+	}
+
+	if (lookup_attribute(IDENTIFIER_POINTER(name), TYPE_ATTRIBUTES(type))) {
+		error("%qE attribute is already applied to the type %qT", name, type);
+		return NULL_TREE;
+	}
+
+	if (TYPE_P(*node)) {
+		if (lookup_attribute("do_const", TYPE_ATTRIBUTES(type)))
+			error("%qE attribute used on type %qT is incompatible with 'do_const'", name, type);
+		else
+			*no_add_attrs = false;
+		return NULL_TREE;
+	}
+
+	constifiable(type, &cinfo);
+	if ((cinfo.has_fptr_field && !cinfo.has_writable_field) || lookup_attribute("do_const", TYPE_ATTRIBUTES(type))) {
+		deconstify_tree(*node);
+		TYPE_CONSTIFY_VISITED(TREE_TYPE(*node)) = 1;
+		return NULL_TREE;
+	}
+
+	if (TYPE_FIELDS(type))
+		error("%qE attribute used on type %qT that is not constified", name, type);
+	return NULL_TREE;
+}
+
+static void constify_type(tree type)
+{
+	TYPE_READONLY(type) = 1;
+	C_TYPE_FIELDS_READONLY(type) = 1;
+	TYPE_CONSTIFY_VISITED(type) = 1;
+//	TYPE_ATTRIBUTES(type) = copy_list(TYPE_ATTRIBUTES(type));
+//	TYPE_ATTRIBUTES(type) = tree_cons(get_identifier("do_const"), NULL_TREE, TYPE_ATTRIBUTES(type));
+}
+
+static tree handle_do_const_attribute(tree *node, tree name, tree args, int flags, bool *no_add_attrs)
+{
+	*no_add_attrs = true;
+	if (!TYPE_P(*node)) {
+		error("%qE attribute applies to types only (%qD)", name, *node);
+		return NULL_TREE;
+	}
+
+	if (TREE_CODE(*node) != RECORD_TYPE && TREE_CODE(*node) != UNION_TYPE) {
+		error("%qE attribute used on %qT applies to struct and union types only", name, *node);
+		return NULL_TREE;
+	}
+
+	if (lookup_attribute(IDENTIFIER_POINTER(name), TYPE_ATTRIBUTES(*node))) {
+		error("%qE attribute used on %qT is already applied to the type", name, *node);
+		return NULL_TREE;
+	}
+
+	if (lookup_attribute("no_const", TYPE_ATTRIBUTES(*node))) {
+		error("%qE attribute used on %qT is incompatible with 'no_const'", name, *node);
+		return NULL_TREE;
+	}
+
+	*no_add_attrs = false;
+	return NULL_TREE;
+}
+
+static struct attribute_spec no_const_attr = {
+	.name			= "no_const",
+	.min_length		= 0,
+	.max_length		= 0,
+	.decl_required		= false,
+	.type_required		= false,
+	.function_type_required	= false,
+	.handler		= handle_no_const_attribute,
+#if BUILDING_GCC_VERSION >= 4007
+	.affects_type_identity	= true
+#endif
+};
+
+static struct attribute_spec do_const_attr = {
+	.name			= "do_const",
+	.min_length		= 0,
+	.max_length		= 0,
+	.decl_required		= false,
+	.type_required		= false,
+	.function_type_required	= false,
+	.handler		= handle_do_const_attribute,
+#if BUILDING_GCC_VERSION >= 4007
+	.affects_type_identity	= true
+#endif
+};
+
+static void register_attributes(void *event_data, void *data)
+{
+	register_attribute(&no_const_attr);
+	register_attribute(&do_const_attr);
+}
+
+static void finish_type(void *event_data, void *data)
+{
+	tree type = (tree)event_data;
+	constify_info cinfo = {
+		.has_fptr_field = false,
+		.has_writable_field = false,
+		.has_do_const_field = false,
+		.has_no_const_field = false
+	};
+
+	if (type == NULL_TREE || type == error_mark_node)
+		return;
+
+#if BUILDING_GCC_VERSION >= 5000
+	if (TREE_CODE(type) == ENUMERAL_TYPE)
+		return;
+#endif
+
+	if (TYPE_FIELDS(type) == NULL_TREE || TYPE_CONSTIFY_VISITED(type))
+		return;
+
+	constifiable(type, &cinfo);
+
+	if (lookup_attribute("no_const", TYPE_ATTRIBUTES(type))) {
+		if ((cinfo.has_fptr_field && !cinfo.has_writable_field) || cinfo.has_do_const_field) {
+			deconstify_type(type);
+			TYPE_CONSTIFY_VISITED(type) = 1;
+		} else
+			error("'no_const' attribute used on type %qT that is not constified", type);
+		return;
+	}
+
+	if (lookup_attribute("do_const", TYPE_ATTRIBUTES(type))) {
+		if (!cinfo.has_writable_field) {
+			error("'do_const' attribute used on type %qT that is%sconstified", type, cinfo.has_fptr_field ? " " : " not ");
+			return;
+		}
+		constify_type(type);
+		return;
+	}
+
+	if (cinfo.has_fptr_field && !cinfo.has_writable_field) {
+		if (lookup_attribute("do_const", TYPE_ATTRIBUTES(type))) {
+			error("'do_const' attribute used on type %qT that is constified", type);
+			return;
+		}
+		constify_type(type);
+		return;
+	}
+
+	deconstify_type(type);
+	TYPE_CONSTIFY_VISITED(type) = 1;
+}
+
+static void check_global_variables(void *event_data, void *data)
+{
+#if BUILDING_GCC_VERSION >= 4009
+	varpool_node *node;
+#else
+	struct varpool_node *node;
+#endif
+
+	FOR_EACH_VARIABLE(node) {
+		tree var = NODE_DECL(node);
+		tree type = TREE_TYPE(var);
+
+		if (TREE_CODE(type) != RECORD_TYPE && TREE_CODE(type) != UNION_TYPE)
+			continue;
+
+		if (!TYPE_READONLY(type) || !C_TYPE_FIELDS_READONLY(type))
+			continue;
+
+		if (!TYPE_CONSTIFY_VISITED(type))
+			continue;
+
+		if (DECL_EXTERNAL(var))
+			continue;
+
+		if (DECL_INITIAL(var))
+			continue;
+
+		// this works around a gcc bug/feature where uninitialized globals
+		// are moved into the .bss section regardless of any constification
+		DECL_INITIAL(var) = build_constructor(type, NULL);
+//		inform(DECL_SOURCE_LOCATION(var), "constified variable %qE moved into .rodata", var);
+	}
+}
+
+static unsigned int check_local_variables(void)
+{
+	unsigned int ret = 0;
+	tree var;
+
+	unsigned int i;
+
+	FOR_EACH_LOCAL_DECL(cfun, i, var) {
+		tree type = TREE_TYPE(var);
+
+		gcc_assert(DECL_P(var));
+		if (is_global_var(var))
+			continue;
+
+		if (TREE_CODE(type) != RECORD_TYPE && TREE_CODE(type) != UNION_TYPE)
+			continue;
+
+		if (!TYPE_READONLY(type) || !C_TYPE_FIELDS_READONLY(type))
+			continue;
+
+		if (!TYPE_CONSTIFY_VISITED(type))
+			continue;
+
+		error_at(DECL_SOURCE_LOCATION(var), "constified variable %qE cannot be local", var);
+		ret = 1;
+	}
+	return ret;
+}
+
+#if BUILDING_GCC_VERSION >= 4009
+namespace {
+static const struct pass_data check_local_variables_pass_data = {
+#else
+static struct gimple_opt_pass check_local_variables_pass = {
+	.pass = {
+#endif
+		.type			= GIMPLE_PASS,
+		.name			= "check_local_variables",
+#if BUILDING_GCC_VERSION >= 4008
+		.optinfo_flags		= OPTGROUP_NONE,
+#endif
+#if BUILDING_GCC_VERSION >= 5000
+#elif BUILDING_GCC_VERSION == 4009
+		.has_gate		= false,
+		.has_execute		= true,
+#else
+		.gate			= NULL,
+		.execute		= check_local_variables,
+		.sub			= NULL,
+		.next			= NULL,
+		.static_pass_number	= 0,
+#endif
+		.tv_id			= TV_NONE,
+		.properties_required	= 0,
+		.properties_provided	= 0,
+		.properties_destroyed	= 0,
+		.todo_flags_start	= 0,
+		.todo_flags_finish	= 0
+#if BUILDING_GCC_VERSION < 4009
+	}
+#endif
+};
+
+#if BUILDING_GCC_VERSION >= 4009
+class check_local_variables_pass : public gimple_opt_pass {
+public:
+	check_local_variables_pass() : gimple_opt_pass(check_local_variables_pass_data, g) {}
+#if BUILDING_GCC_VERSION >= 5000
+	virtual unsigned int execute(function *) { return check_local_variables(); }
+#else
+	unsigned int execute() { return check_local_variables(); }
+#endif
+};
+}
+
+static opt_pass *make_check_local_variables_pass(void)
+{
+	return new check_local_variables_pass();
+}
+#else
+static struct opt_pass *make_check_local_variables_pass(void)
+{
+	return &check_local_variables_pass.pass;
+}
+#endif
+
+static struct {
+	const char *name;
+	const char *asm_op;
+} sections[] = {
+	{".init.rodata",     "\t.section\t.init.rodata,\"a\""},
+	{".ref.rodata",      "\t.section\t.ref.rodata,\"a\""},
+	{".devinit.rodata",  "\t.section\t.devinit.rodata,\"a\""},
+	{".devexit.rodata",  "\t.section\t.devexit.rodata,\"a\""},
+	{".cpuinit.rodata",  "\t.section\t.cpuinit.rodata,\"a\""},
+	{".cpuexit.rodata",  "\t.section\t.cpuexit.rodata,\"a\""},
+	{".meminit.rodata",  "\t.section\t.meminit.rodata,\"a\""},
+	{".memexit.rodata",  "\t.section\t.memexit.rodata,\"a\""},
+	{".data..read_only", "\t.section\t.data..read_only,\"a\""},
+};
+
+static unsigned int (*old_section_type_flags)(tree decl, const char *name, int reloc);
+
+static unsigned int constify_section_type_flags(tree decl, const char *name, int reloc)
+{
+	size_t i;
+
+	for (i = 0; i < ARRAY_SIZE(sections); i++)
+		if (!strcmp(sections[i].name, name))
+			return 0;
+	return old_section_type_flags(decl, name, reloc);
+}
+
+static void constify_start_unit(void *gcc_data, void *user_data)
+{
+//	size_t i;
+
+//	for (i = 0; i < ARRAY_SIZE(sections); i++)
+//		sections[i].section = get_unnamed_section(0, output_section_asm_op, sections[i].asm_op);
+//		sections[i].section = get_section(sections[i].name, 0, NULL);
+
+	old_section_type_flags = targetm.section_type_flags;
+	targetm.section_type_flags = constify_section_type_flags;
+}
+
+int plugin_init(struct plugin_name_args *plugin_info, struct plugin_gcc_version *version)
+{
+	const char * const plugin_name = plugin_info->base_name;
+	const int argc = plugin_info->argc;
+	const struct plugin_argument * const argv = plugin_info->argv;
+	int i;
+	bool constify = true;
+
+	struct register_pass_info check_local_variables_pass_info;
+
+	check_local_variables_pass_info.pass				= make_check_local_variables_pass();
+	check_local_variables_pass_info.reference_pass_name		= "ssa";
+	check_local_variables_pass_info.ref_pass_instance_number	= 1;
+	check_local_variables_pass_info.pos_op				= PASS_POS_INSERT_BEFORE;
+
+	if (!plugin_default_version_check(version, &gcc_version)) {
+		error(G_("incompatible gcc/plugin versions"));
+		return 1;
+	}
+
+	for (i = 0; i < argc; ++i) {
+		if (!(strcmp(argv[i].key, "no-constify"))) {
+			constify = false;
+			continue;
+		}
+		error(G_("unkown option '-fplugin-arg-%s-%s'"), plugin_name, argv[i].key);
+	}
+
+	if (strncmp(lang_hooks.name, "GNU C", 5) && !strncmp(lang_hooks.name, "GNU C+", 6)) {
+		inform(UNKNOWN_LOCATION, G_("%s supports C only, not %s"), plugin_name, lang_hooks.name);
+		constify = false;
+	}
+
+	register_callback(plugin_name, PLUGIN_INFO, NULL, &const_plugin_info);
+	if (constify) {
+		register_callback(plugin_name, PLUGIN_ALL_IPA_PASSES_START, check_global_variables, NULL);
+		register_callback(plugin_name, PLUGIN_FINISH_TYPE, finish_type, NULL);
+		register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &check_local_variables_pass_info);
+		register_callback(plugin_name, PLUGIN_START_UNIT, constify_start_unit, NULL);
+	}
+	register_callback(plugin_name, PLUGIN_ATTRIBUTES, register_attributes, NULL);
+
+	return 0;
+}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/gcc-common.h linux-3.2.71-pax/tools/gcc/gcc-common.h
--- linux-3.2.71/tools/gcc/gcc-common.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/gcc-common.h	2015-07-13 23:28:16.198057366 +0200
@@ -0,0 +1,787 @@
+#ifndef GCC_COMMON_H_INCLUDED
+#define GCC_COMMON_H_INCLUDED
+
+#include "plugin.h"
+#include "bversion.h"
+#include "plugin-version.h"
+#include "config.h"
+#include "system.h"
+#include "coretypes.h"
+#include "tm.h"
+#include "line-map.h"
+#include "input.h"
+#include "tree.h"
+
+#include "tree-inline.h"
+#include "version.h"
+#include "rtl.h"
+#include "tm_p.h"
+#include "flags.h"
+//#include "insn-attr.h"
+//#include "insn-config.h"
+//#include "insn-flags.h"
+#include "hard-reg-set.h"
+//#include "recog.h"
+#include "output.h"
+#include "except.h"
+#include "function.h"
+#include "toplev.h"
+//#include "expr.h"
+#include "basic-block.h"
+#include "intl.h"
+#include "ggc.h"
+//#include "regs.h"
+#include "timevar.h"
+
+#include "params.h"
+
+#if BUILDING_GCC_VERSION <= 4009
+#include "pointer-set.h"
+#else
+#include "hash-map.h"
+#endif
+
+#include "emit-rtl.h"
+//#include "reload.h"
+//#include "ira.h"
+//#include "dwarf2asm.h"
+#include "debug.h"
+#include "target.h"
+#include "langhooks.h"
+#include "cfgloop.h"
+//#include "hosthooks.h"
+#include "cgraph.h"
+#include "opts.h"
+//#include "coverage.h"
+//#include "value-prof.h"
+
+#if BUILDING_GCC_VERSION == 4005
+#include <sys/mman.h>
+#endif
+
+#if BUILDING_GCC_VERSION >= 4007
+#include "tree-pretty-print.h"
+#include "gimple-pretty-print.h"
+#endif
+
+#if BUILDING_GCC_VERSION >= 4006
+//#include "c-tree.h"
+//#include "cp/cp-tree.h"
+#include "c-family/c-common.h"
+#else
+#include "c-common.h"
+#endif
+
+#if BUILDING_GCC_VERSION <= 4008
+#include "tree-flow.h"
+#else
+#include "tree-cfgcleanup.h"
+#include "tree-ssa-operands.h"
+#include "tree-into-ssa.h"
+#endif
+
+#if BUILDING_GCC_VERSION >= 4008
+#include "is-a.h"
+#endif
+
+#include "diagnostic.h"
+//#include "tree-diagnostic.h"
+#include "tree-dump.h"
+#include "tree-pass.h"
+//#include "df.h"
+#include "predict.h"
+#include "ipa-utils.h"
+
+#if BUILDING_GCC_VERSION >= 4009
+#include "varasm.h"
+#include "stor-layout.h"
+#include "internal-fn.h"
+#include "gimple-expr.h"
+#include "gimple-fold.h"
+//#include "diagnostic-color.h"
+#include "context.h"
+#include "tree-ssa-alias.h"
+#include "tree-ssa.h"
+#include "stringpool.h"
+#include "tree-ssanames.h"
+#include "print-tree.h"
+#include "tree-eh.h"
+#include "stmt.h"
+#include "gimplify.h"
+#endif
+
+#include "gimple.h"
+
+#if BUILDING_GCC_VERSION >= 4009
+#include "tree-ssa-operands.h"
+#include "tree-phinodes.h"
+#include "tree-cfg.h"
+#include "gimple-iterator.h"
+#include "gimple-ssa.h"
+#include "ssa-iterators.h"
+#endif
+
+//#include "lto/lto.h"
+#if BUILDING_GCC_VERSION >= 4007
+//#include "data-streamer.h"
+#else
+//#include "lto-streamer.h"
+#endif
+//#include "lto-compress.h"
+#if BUILDING_GCC_VERSION >= 5000
+//#include "lto-section-names.h"
+#include "builtins.h"
+#endif
+
+//#include "expr.h" where are you...
+extern rtx emit_move_insn(rtx x, rtx y);
+
+// missing from basic_block.h...
+extern void debug_dominance_info(enum cdi_direction dir);
+extern void debug_dominance_tree(enum cdi_direction dir, basic_block root);
+
+#ifdef __cplusplus
+static inline void debug_tree(const_tree t)
+{
+	debug_tree(CONST_CAST_TREE(t));
+}
+#else
+#define debug_tree(t) debug_tree(CONST_CAST_TREE(t))
+#endif
+
+#define __unused __attribute__((__unused__))
+
+#define DECL_NAME_POINTER(node) IDENTIFIER_POINTER(DECL_NAME(node))
+#define DECL_NAME_LENGTH(node) IDENTIFIER_LENGTH(DECL_NAME(node))
+#define TYPE_NAME_POINTER(node) IDENTIFIER_POINTER(TYPE_NAME(node))
+#define TYPE_NAME_LENGTH(node) IDENTIFIER_LENGTH(TYPE_NAME(node))
+
+// should come from c-tree.h if only it were installed for gcc 4.5...
+#define C_TYPE_FIELDS_READONLY(TYPE) TREE_LANG_FLAG_1(TYPE)
+
+#if BUILDING_GCC_VERSION == 4005
+#define FOR_EACH_LOCAL_DECL(FUN, I, D) for (tree vars = (FUN)->local_decls, (I) = 0; vars && ((D) = TREE_VALUE(vars)); vars = TREE_CHAIN(vars), (I)++)
+#define DECL_CHAIN(NODE) (TREE_CHAIN(DECL_MINIMAL_CHECK(NODE)))
+#define FOR_EACH_VEC_ELT(T, V, I, P) for (I = 0; VEC_iterate(T, (V), (I), (P)); ++(I))
+#define TODO_rebuild_cgraph_edges 0
+#define SCOPE_FILE_SCOPE_P(EXP) (!(EXP))
+
+#ifndef O_BINARY
+#define O_BINARY 0
+#endif
+
+static inline bool gimple_call_builtin_p(gimple stmt, enum built_in_function code)
+{
+	tree fndecl;
+
+	if (!is_gimple_call(stmt))
+		return false;
+	fndecl = gimple_call_fndecl(stmt);
+	if (!fndecl || DECL_BUILT_IN_CLASS(fndecl) != BUILT_IN_NORMAL)
+		return false;
+//	print_node(stderr, "pax", fndecl, 4);
+	return DECL_FUNCTION_CODE(fndecl) == code;
+}
+
+static inline bool is_simple_builtin(tree decl)
+{
+	if (decl && DECL_BUILT_IN_CLASS(decl) != BUILT_IN_NORMAL)
+		return false;
+
+	switch (DECL_FUNCTION_CODE(decl)) {
+	/* Builtins that expand to constants. */
+	case BUILT_IN_CONSTANT_P:
+	case BUILT_IN_EXPECT:
+	case BUILT_IN_OBJECT_SIZE:
+	case BUILT_IN_UNREACHABLE:
+	/* Simple register moves or loads from stack. */
+	case BUILT_IN_RETURN_ADDRESS:
+	case BUILT_IN_EXTRACT_RETURN_ADDR:
+	case BUILT_IN_FROB_RETURN_ADDR:
+	case BUILT_IN_RETURN:
+	case BUILT_IN_AGGREGATE_INCOMING_ADDRESS:
+	case BUILT_IN_FRAME_ADDRESS:
+	case BUILT_IN_VA_END:
+	case BUILT_IN_STACK_SAVE:
+	case BUILT_IN_STACK_RESTORE:
+	/* Exception state returns or moves registers around. */
+	case BUILT_IN_EH_FILTER:
+	case BUILT_IN_EH_POINTER:
+	case BUILT_IN_EH_COPY_VALUES:
+	return true;
+
+	default:
+	return false;
+	}
+}
+
+static inline void add_local_decl(struct function *fun, tree d)
+{
+	gcc_assert(TREE_CODE(d) == VAR_DECL);
+	fun->local_decls = tree_cons(NULL_TREE, d, fun->local_decls);
+}
+#endif
+
+#if BUILDING_GCC_VERSION <= 4006
+#define ANY_RETURN_P(rtx) (GET_CODE(rtx) == RETURN)
+#define C_DECL_REGISTER(EXP) DECL_LANG_FLAG_4(EXP)
+#define EDGE_PRESERVE 0ULL
+#define HOST_WIDE_INT_PRINT_HEX_PURE "%" HOST_WIDE_INT_PRINT "x"
+#define flag_fat_lto_objects true
+
+#define get_random_seed(noinit) ({						\
+	unsigned HOST_WIDE_INT seed;						\
+	sscanf(get_random_seed(noinit), "%" HOST_WIDE_INT_PRINT "x", &seed);	\
+	seed * seed; })
+
+#define int_const_binop(code, arg1, arg2) int_const_binop((code), (arg1), (arg2), 0)
+
+static inline bool gimple_clobber_p(gimple s __unused)
+{
+	return false;
+}
+
+static inline bool gimple_asm_clobbers_memory_p(const_gimple stmt)
+{
+	unsigned i;
+
+	for (i = 0; i < gimple_asm_nclobbers(stmt); i++) {
+		tree op = gimple_asm_clobber_op(stmt, i);
+		if (!strcmp(TREE_STRING_POINTER(TREE_VALUE(op)), "memory"))
+			return true;
+	}
+
+	return false;
+}
+
+static inline tree builtin_decl_implicit(enum built_in_function fncode)
+{
+	return implicit_built_in_decls[fncode];
+}
+
+static inline int ipa_reverse_postorder(struct cgraph_node **order)
+{
+	return cgraph_postorder(order);
+}
+
+static inline struct cgraph_node *cgraph_get_create_node(tree decl)
+{
+	struct cgraph_node *node = cgraph_get_node(decl);
+
+	return node ? node : cgraph_node(decl);
+}
+
+static inline bool cgraph_function_with_gimple_body_p(struct cgraph_node *node)
+{
+	return node->analyzed && !node->thunk.thunk_p && !node->alias;
+}
+
+static inline struct cgraph_node *cgraph_first_function_with_gimple_body(void)
+{
+	struct cgraph_node *node;
+
+	for (node = cgraph_nodes; node; node = node->next)
+		if (cgraph_function_with_gimple_body_p(node))
+			return node;
+	return NULL;
+}
+
+static inline struct cgraph_node *cgraph_next_function_with_gimple_body(struct cgraph_node *node)
+{
+	for (node = node->next; node; node = node->next)
+		if (cgraph_function_with_gimple_body_p(node))
+			return node;
+	return NULL;
+}
+
+#define FOR_EACH_FUNCTION_WITH_GIMPLE_BODY(node) \
+	for ((node) = cgraph_first_function_with_gimple_body(); (node); \
+		(node) = cgraph_next_function_with_gimple_body(node))
+
+static inline void varpool_add_new_variable(tree decl)
+{
+	varpool_finalize_decl(decl);
+}
+#endif
+
+#if BUILDING_GCC_VERSION == 4006
+extern void debug_gimple_stmt(gimple);
+extern void debug_gimple_seq(gimple_seq);
+extern void print_gimple_seq(FILE *, gimple_seq, int, int);
+extern void print_gimple_stmt(FILE *, gimple, int, int);
+extern void print_gimple_expr(FILE *, gimple, int, int);
+extern void dump_gimple_stmt(pretty_printer *, gimple, int, int);
+#endif
+
+#if BUILDING_GCC_VERSION <= 4007
+#define FOR_EACH_FUNCTION(node) for (node = cgraph_nodes; node; node = node->next)
+#define FOR_EACH_VARIABLE(node) for (node = varpool_nodes; node; node = node->next)
+#define PROP_loops 0
+#define NODE_SYMBOL(node) (node)
+#define NODE_DECL(node) (node)->decl
+#define INSN_LOCATION(INSN) RTL_LOCATION(INSN)
+
+static inline int bb_loop_depth(const_basic_block bb)
+{
+	return bb->loop_father ? loop_depth(bb->loop_father) : 0;
+}
+
+static inline bool gimple_store_p(gimple gs)
+{
+	tree lhs = gimple_get_lhs(gs);
+	return lhs && !is_gimple_reg(lhs);
+}
+#endif
+
+#if BUILDING_GCC_VERSION == 4007 || BUILDING_GCC_VERSION == 4008
+static inline struct cgraph_node *cgraph_alias_target(struct cgraph_node *n)
+{
+	return cgraph_alias_aliased_node(n);
+}
+#endif
+
+#if BUILDING_GCC_VERSION >= 4007 && BUILDING_GCC_VERSION <= 4009
+#define cgraph_create_edge(caller, callee, call_stmt, count, freq, nest) \
+	cgraph_create_edge((caller), (callee), (call_stmt), (count), (freq))
+#define cgraph_create_edge_including_clones(caller, callee, old_call_stmt, call_stmt, count, freq, nest, reason) \
+	cgraph_create_edge_including_clones((caller), (callee), (old_call_stmt), (call_stmt), (count), (freq), (reason))
+#endif
+
+#if BUILDING_GCC_VERSION <= 4008
+#define ENTRY_BLOCK_PTR_FOR_FN(FN)	ENTRY_BLOCK_PTR_FOR_FUNCTION(FN)
+#define EXIT_BLOCK_PTR_FOR_FN(FN)	EXIT_BLOCK_PTR_FOR_FUNCTION(FN)
+#define basic_block_info_for_fn(FN)	((FN)->cfg->x_basic_block_info)
+#define n_basic_blocks_for_fn(FN)	((FN)->cfg->x_n_basic_blocks)
+#define n_edges_for_fn(FN)		((FN)->cfg->x_n_edges)
+#define last_basic_block_for_fn(FN)	((FN)->cfg->x_last_basic_block)
+#define label_to_block_map_for_fn(FN)	((FN)->cfg->x_label_to_block_map)
+#define profile_status_for_fn(FN)	((FN)->cfg->x_profile_status)
+#define BASIC_BLOCK_FOR_FN(FN, N)	BASIC_BLOCK_FOR_FUNCTION((FN), (N))
+#define NODE_IMPLICIT_ALIAS(node)	(node)->same_body_alias
+
+static inline bool tree_fits_shwi_p(const_tree t)
+{
+	if (t == NULL_TREE || TREE_CODE(t) != INTEGER_CST)
+		return false;
+
+	if (TREE_INT_CST_HIGH(t) == 0 && (HOST_WIDE_INT)TREE_INT_CST_LOW(t) >= 0)
+		return true;
+
+	if (TREE_INT_CST_HIGH(t) == -1 && (HOST_WIDE_INT)TREE_INT_CST_LOW(t) < 0 && !TYPE_UNSIGNED(TREE_TYPE(t)))
+		return true;
+
+	return false;
+}
+
+static inline bool tree_fits_uhwi_p(const_tree t)
+{
+	if (t == NULL_TREE || TREE_CODE(t) != INTEGER_CST)
+		return false;
+
+	return TREE_INT_CST_HIGH(t) == 0;
+}
+
+static inline HOST_WIDE_INT tree_to_shwi(const_tree t)
+{
+	gcc_assert(tree_fits_shwi_p(t));
+	return TREE_INT_CST_LOW(t);
+}
+
+static inline unsigned HOST_WIDE_INT tree_to_uhwi(const_tree t)
+{
+	gcc_assert(tree_fits_uhwi_p(t));
+	return TREE_INT_CST_LOW(t);
+}
+
+static inline const char *get_tree_code_name(enum tree_code code)
+{
+	gcc_assert(code < MAX_TREE_CODES);
+	return tree_code_name[code];
+}
+
+#define ipa_remove_stmt_references(cnode, stmt)
+
+typedef union gimple_statement_d gasm;
+typedef union gimple_statement_d gassign;
+typedef union gimple_statement_d gcall;
+typedef union gimple_statement_d gcond;
+typedef union gimple_statement_d gdebug;
+typedef union gimple_statement_d gphi;
+typedef union gimple_statement_d greturn;
+
+static inline gasm *as_a_gasm(gimple stmt)
+{
+	return stmt;
+}
+
+static inline const gasm *as_a_const_gasm(const_gimple stmt)
+{
+	return stmt;
+}
+
+static inline gassign *as_a_gassign(gimple stmt)
+{
+	return stmt;
+}
+
+static inline const gassign *as_a_const_gassign(const_gimple stmt)
+{
+	return stmt;
+}
+
+static inline gcall *as_a_gcall(gimple stmt)
+{
+	return stmt;
+}
+
+static inline const gcall *as_a_const_gcall(const_gimple stmt)
+{
+	return stmt;
+}
+
+static inline gcond *as_a_gcond(gimple stmt)
+{
+	return stmt;
+}
+
+static inline const gcond *as_a_const_gcond(const_gimple stmt)
+{
+	return stmt;
+}
+
+static inline gdebug *as_a_gdebug(gimple stmt)
+{
+	return stmt;
+}
+
+static inline const gdebug *as_a_const_gdebug(const_gimple stmt)
+{
+	return stmt;
+}
+
+static inline gphi *as_a_gphi(gimple stmt)
+{
+	return stmt;
+}
+
+static inline const gphi *as_a_const_gphi(const_gimple stmt)
+{
+	return stmt;
+}
+
+static inline greturn *as_a_greturn(gimple stmt)
+{
+	return stmt;
+}
+
+static inline const greturn *as_a_const_greturn(const_gimple stmt)
+{
+	return stmt;
+}
+#endif
+
+#if BUILDING_GCC_VERSION == 4008
+#define NODE_SYMBOL(node) (&(node)->symbol)
+#define NODE_DECL(node) (node)->symbol.decl
+#endif
+
+#if BUILDING_GCC_VERSION >= 4008
+#define add_referenced_var(var)
+#define mark_sym_for_renaming(var)
+#define varpool_mark_needed_node(node)
+#define create_var_ann(var)
+#define TODO_dump_func 0
+#define TODO_dump_cgraph 0
+#endif
+
+#if BUILDING_GCC_VERSION <= 4009
+#define TODO_verify_il 0
+#define AVAIL_INTERPOSABLE AVAIL_OVERWRITABLE
+
+#define section_name_prefix LTO_SECTION_NAME_PREFIX
+#define fatal_error(loc, gmsgid, ...) fatal_error((gmsgid), __VA_ARGS__)
+
+typedef struct rtx_def rtx_insn;
+
+static inline void set_decl_section_name(tree node, const char *value)
+{
+	DECL_SECTION_NAME(node) = build_string(strlen(value) + 1, value);
+}
+#endif
+
+#if BUILDING_GCC_VERSION == 4009
+typedef struct gimple_statement_asm gasm;
+typedef struct gimple_statement_base gassign;
+typedef struct gimple_statement_call gcall;
+typedef struct gimple_statement_base gcond;
+typedef struct gimple_statement_base gdebug;
+typedef struct gimple_statement_phi gphi;
+typedef struct gimple_statement_base greturn;
+
+static inline gasm *as_a_gasm(gimple stmt)
+{
+	return as_a<gasm>(stmt);
+}
+
+static inline const gasm *as_a_const_gasm(const_gimple stmt)
+{
+	return as_a<const gasm>(stmt);
+}
+
+static inline gassign *as_a_gassign(gimple stmt)
+{
+	return stmt;
+}
+
+static inline const gassign *as_a_const_gassign(const_gimple stmt)
+{
+	return stmt;
+}
+
+static inline gcall *as_a_gcall(gimple stmt)
+{
+	return as_a<gcall>(stmt);
+}
+
+static inline const gcall *as_a_const_gcall(const_gimple stmt)
+{
+	return as_a<const gcall>(stmt);
+}
+
+static inline gcond *as_a_gcond(gimple stmt)
+{
+	return stmt;
+}
+
+static inline const gcond *as_a_const_gcond(const_gimple stmt)
+{
+	return stmt;
+}
+
+static inline gdebug *as_a_gdebug(gimple stmt)
+{
+	return stmt;
+}
+
+static inline const gdebug *as_a_const_gdebug(const_gimple stmt)
+{
+	return stmt;
+}
+
+static inline gphi *as_a_gphi(gimple stmt)
+{
+	return as_a<gphi>(stmt);
+}
+
+static inline const gphi *as_a_const_gphi(const_gimple stmt)
+{
+	return as_a<const gphi>(stmt);
+}
+
+static inline greturn *as_a_greturn(gimple stmt)
+{
+	return stmt;
+}
+
+static inline const greturn *as_a_const_greturn(const_gimple stmt)
+{
+	return stmt;
+}
+#endif
+
+#if BUILDING_GCC_VERSION >= 4009
+#define TODO_ggc_collect 0
+#define NODE_SYMBOL(node) (node)
+#define NODE_DECL(node) (node)->decl
+#define cgraph_node_name(node) (node)->name()
+#define NODE_IMPLICIT_ALIAS(node) (node)->cpp_implicit_alias
+#endif
+
+#if BUILDING_GCC_VERSION >= 5000
+#define TODO_verify_ssa TODO_verify_il
+#define TODO_verify_flow TODO_verify_il
+#define TODO_verify_stmts TODO_verify_il
+#define TODO_verify_rtl_sharing TODO_verify_il
+
+//#define TREE_INT_CST_HIGH(NODE) ({ TREE_INT_CST_EXT_NUNITS(NODE) > 1 ? (unsigned HOST_WIDE_INT)TREE_INT_CST_ELT(NODE, 1) : 0; })
+
+#define INSN_DELETED_P(insn) (insn)->deleted()
+
+// symtab/cgraph related
+#define debug_cgraph_node(node) (node)->debug()
+#define cgraph_get_node(decl) cgraph_node::get(decl)
+#define cgraph_get_create_node(decl) cgraph_node::get_create(decl)
+#define cgraph_n_nodes symtab->cgraph_count
+#define cgraph_max_uid symtab->cgraph_max_uid
+#define varpool_get_node(decl) varpool_node::get(decl)
+
+#define cgraph_create_edge(caller, callee, call_stmt, count, freq, nest) \
+	(caller)->create_edge((callee), (call_stmt), (count), (freq))
+#define cgraph_create_edge_including_clones(caller, callee, old_call_stmt, call_stmt, count, freq, nest, reason) \
+	(caller)->create_edge_including_clones((callee), (old_call_stmt), (call_stmt), (count), (freq), (reason))
+
+typedef struct cgraph_node *cgraph_node_ptr;
+typedef struct cgraph_edge *cgraph_edge_p;
+typedef struct varpool_node *varpool_node_ptr;
+
+static inline void change_decl_assembler_name(tree decl, tree name)
+{
+	symtab->change_decl_assembler_name(decl, name);
+}
+
+static inline void varpool_finalize_decl(tree decl)
+{
+	varpool_node::finalize_decl(decl);
+}
+
+static inline void varpool_add_new_variable(tree decl)
+{
+	varpool_node::add(decl);
+}
+
+static inline unsigned int rebuild_cgraph_edges(void)
+{
+	return cgraph_edge::rebuild_edges();
+}
+
+static inline cgraph_node_ptr cgraph_function_node(cgraph_node_ptr node, enum availability *availability)
+{
+	return node->function_symbol(availability);
+}
+
+static inline cgraph_node_ptr cgraph_function_or_thunk_node(cgraph_node_ptr node, enum availability *availability = NULL)
+{
+	return node->ultimate_alias_target(availability);
+}
+
+static inline bool cgraph_only_called_directly_p(cgraph_node_ptr node)
+{
+	return node->only_called_directly_p();
+}
+
+static inline enum availability cgraph_function_body_availability(cgraph_node_ptr node)
+{
+	return node->get_availability();
+}
+
+static inline cgraph_node_ptr cgraph_alias_target(cgraph_node_ptr node)
+{
+	return node->get_alias_target();
+}
+
+static inline struct cgraph_node_hook_list *cgraph_add_function_insertion_hook(cgraph_node_hook hook, void *data)
+{
+	return symtab->add_cgraph_insertion_hook(hook, data);
+}
+
+static inline void cgraph_remove_function_insertion_hook(struct cgraph_node_hook_list *entry)
+{
+	symtab->remove_cgraph_insertion_hook(entry);
+}
+
+static inline struct cgraph_node_hook_list *cgraph_add_node_removal_hook(cgraph_node_hook hook, void *data)
+{
+	return symtab->add_cgraph_removal_hook(hook, data);
+}
+
+static inline void cgraph_remove_node_removal_hook(struct cgraph_node_hook_list *entry)
+{
+	symtab->remove_cgraph_removal_hook(entry);
+}
+
+static inline struct cgraph_2node_hook_list *cgraph_add_node_duplication_hook(cgraph_2node_hook hook, void *data)
+{
+	return symtab->add_cgraph_duplication_hook(hook, data);
+}
+
+static inline void cgraph_remove_node_duplication_hook(struct cgraph_2node_hook_list *entry)
+{
+	symtab->remove_cgraph_duplication_hook(entry);
+}
+
+// gimple related
+static inline gimple gimple_build_assign_with_ops(enum tree_code subcode, tree lhs, tree op1, tree op2 MEM_STAT_DECL)
+{
+	return gimple_build_assign(lhs, subcode, op1, op2 PASS_MEM_STAT);
+}
+
+template <>
+template <>
+inline bool is_a_helper<const gassign *>::test(const_gimple gs)
+{
+	return gs->code == GIMPLE_ASSIGN;
+}
+
+template <>
+template <>
+inline bool is_a_helper<const greturn *>::test(const_gimple gs)
+{
+	return gs->code == GIMPLE_RETURN;
+}
+
+static inline gasm *as_a_gasm(gimple stmt)
+{
+	return as_a<gasm *>(stmt);
+}
+
+static inline const gasm *as_a_const_gasm(const_gimple stmt)
+{
+	return as_a<const gasm *>(stmt);
+}
+
+static inline gassign *as_a_gassign(gimple stmt)
+{
+	return as_a<gassign *>(stmt);
+}
+
+static inline const gassign *as_a_const_gassign(const_gimple stmt)
+{
+	return as_a<const gassign *>(stmt);
+}
+
+static inline gcall *as_a_gcall(gimple stmt)
+{
+	return as_a<gcall *>(stmt);
+}
+
+static inline const gcall *as_a_const_gcall(const_gimple stmt)
+{
+	return as_a<const gcall *>(stmt);
+}
+
+static inline gphi *as_a_gphi(gimple stmt)
+{
+	return as_a<gphi *>(stmt);
+}
+
+static inline const gphi *as_a_const_gphi(const_gimple stmt)
+{
+	return as_a<const gphi *>(stmt);
+}
+
+static inline greturn *as_a_greturn(gimple stmt)
+{
+	return as_a<greturn *>(stmt);
+}
+
+static inline const greturn *as_a_const_greturn(const_gimple stmt)
+{
+	return as_a<const greturn *>(stmt);
+}
+
+// IPA/LTO related
+#define ipa_ref_list_referring_iterate(L,I,P) (L)->referring.iterate((I), &(P))
+#define ipa_ref_list_reference_iterate(L,I,P) (L)->reference.iterate((I), &(P))
+
+static inline cgraph_node_ptr ipa_ref_referring_node(struct ipa_ref *ref)
+{
+	return dyn_cast<cgraph_node_ptr>(ref->referring);
+}
+
+static inline void ipa_remove_stmt_references(symtab_node *referring_node, gimple stmt)
+{
+	referring_node->remove_stmt_references(stmt);
+}
+#endif
+
+#endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/kallocstat_plugin.c linux-3.2.71-pax/tools/gcc/kallocstat_plugin.c
--- linux-3.2.71/tools/gcc/kallocstat_plugin.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/kallocstat_plugin.c	2015-04-30 03:07:38.400532395 +0200
@@ -0,0 +1,188 @@
+/*
+ * Copyright 2011-2015 by the PaX Team <pageexec@freemail.hu>
+ * Licensed under the GPL v2
+ *
+ * Note: the choice of the license means that the compilation process is
+ *       NOT 'eligible' as defined by gcc's library exception to the GPL v3,
+ *       but for the kernel it doesn't matter since it doesn't link against
+ *       any of the gcc libraries
+ *
+ * gcc plugin to find the distribution of k*alloc sizes
+ *
+ * TODO:
+ *
+ * BUGS:
+ * - none known
+ */
+
+#include "gcc-common.h"
+
+int plugin_is_GPL_compatible;
+
+static struct plugin_info kallocstat_plugin_info = {
+	.version	= "201401260140",
+	.help		= NULL
+};
+
+static const char * const kalloc_functions[] = {
+	"__kmalloc",
+	"kmalloc",
+	"kmalloc_large",
+	"kmalloc_node",
+	"kmalloc_order",
+	"kmalloc_order_trace",
+	"kmalloc_slab",
+	"kzalloc",
+	"kzalloc_node",
+};
+
+static bool is_kalloc(const char *fnname)
+{
+	size_t i;
+
+	for (i = 0; i < ARRAY_SIZE(kalloc_functions); i++)
+		if (!strcmp(fnname, kalloc_functions[i]))
+			return true;
+	return false;
+}
+
+static unsigned int execute_kallocstat(void)
+{
+	basic_block bb;
+
+	// 1. loop through BBs and GIMPLE statements
+	FOR_EACH_BB_FN(bb, cfun) {
+		gimple_stmt_iterator gsi;
+		for (gsi = gsi_start_bb(bb); !gsi_end_p(gsi); gsi_next(&gsi)) {
+			// gimple match: 
+			tree fndecl, size;
+			gimple stmt;
+			const char *fnname;
+
+			// is it a call
+			stmt = gsi_stmt(gsi);
+			if (!is_gimple_call(stmt))
+				continue;
+			fndecl = gimple_call_fndecl(stmt);
+			if (fndecl == NULL_TREE)
+				continue;
+			if (TREE_CODE(fndecl) != FUNCTION_DECL)
+				continue;
+
+			// is it a call to k*alloc
+			fnname = DECL_NAME_POINTER(fndecl);
+			if (!is_kalloc(fnname))
+				continue;
+
+			// is the size arg const or the result of a simple const assignment
+			size = gimple_call_arg(stmt, 0);
+			while (true) {
+				expanded_location xloc;
+				size_t size_val;
+
+				if (TREE_CONSTANT(size)) {
+					xloc = expand_location(gimple_location(stmt));
+					if (!xloc.file)
+						xloc = expand_location(DECL_SOURCE_LOCATION(current_function_decl));
+					size_val = TREE_INT_CST_LOW(size);
+					fprintf(stderr, "kallocsize: %8zu %8zx %s %s:%u\n", size_val, size_val, fnname, xloc.file, xloc.line);
+					break;
+				}
+
+				if (TREE_CODE(size) != SSA_NAME)
+					break;
+				stmt = SSA_NAME_DEF_STMT(size);
+//debug_gimple_stmt(stmt);
+//debug_tree(size);
+				if (!stmt || !is_gimple_assign(stmt))
+					break;
+				if (gimple_num_ops(stmt) != 2)
+					break;
+				size = gimple_assign_rhs1(stmt);
+			}
+//print_gimple_stmt(stderr, call_stmt, 0, TDF_LINENO);
+//debug_tree(gimple_call_fn(call_stmt));
+//print_node(stderr, "pax", fndecl, 4);
+		}
+	}
+
+	return 0;
+}
+
+#if BUILDING_GCC_VERSION >= 4009
+namespace {
+static const struct pass_data kallocstat_pass_data = {
+#else
+static struct gimple_opt_pass kallocstat_pass = {
+	.pass = {
+#endif
+		.type			= GIMPLE_PASS,
+		.name			= "kallocstat",
+#if BUILDING_GCC_VERSION >= 4008
+		.optinfo_flags		= OPTGROUP_NONE,
+#endif
+#if BUILDING_GCC_VERSION >= 5000
+#elif BUILDING_GCC_VERSION == 4009
+		.has_gate		= false,
+		.has_execute		= true,
+#else
+		.gate			= NULL,
+		.execute		= execute_kallocstat,
+		.sub			= NULL,
+		.next			= NULL,
+		.static_pass_number	= 0,
+#endif
+		.tv_id			= TV_NONE,
+		.properties_required	= 0,
+		.properties_provided	= 0,
+		.properties_destroyed	= 0,
+		.todo_flags_start	= 0,
+		.todo_flags_finish	= 0
+#if BUILDING_GCC_VERSION < 4009
+	}
+#endif
+};
+
+#if BUILDING_GCC_VERSION >= 4009
+class kallocstat_pass : public gimple_opt_pass {
+public:
+	kallocstat_pass() : gimple_opt_pass(kallocstat_pass_data, g) {}
+#if BUILDING_GCC_VERSION >= 5000
+	virtual unsigned int execute(function *) { return execute_kallocstat(); }
+#else
+	unsigned int execute() { return execute_kallocstat(); }
+#endif
+};
+}
+
+static opt_pass *make_kallocstat_pass(void)
+{
+	return new kallocstat_pass();
+}
+#else
+static struct opt_pass *make_kallocstat_pass(void)
+{
+	return &kallocstat_pass.pass;
+}
+#endif
+
+int plugin_init(struct plugin_name_args *plugin_info, struct plugin_gcc_version *version)
+{
+	const char * const plugin_name = plugin_info->base_name;
+	struct register_pass_info kallocstat_pass_info;
+
+	kallocstat_pass_info.pass			= make_kallocstat_pass();
+	kallocstat_pass_info.reference_pass_name	= "ssa";
+	kallocstat_pass_info.ref_pass_instance_number	= 1;
+	kallocstat_pass_info.pos_op 			= PASS_POS_INSERT_AFTER;
+
+	if (!plugin_default_version_check(version, &gcc_version)) {
+		error(G_("incompatible gcc/plugin versions"));
+		return 1;
+	}
+
+	register_callback(plugin_name, PLUGIN_INFO, NULL, &kallocstat_plugin_info);
+	register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &kallocstat_pass_info);
+
+	return 0;
+}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/kernexec_plugin.c linux-3.2.71-pax/tools/gcc/kernexec_plugin.c
--- linux-3.2.71/tools/gcc/kernexec_plugin.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/kernexec_plugin.c	2015-07-13 23:32:15.038044614 +0200
@@ -0,0 +1,551 @@
+/*
+ * Copyright 2011-2015 by the PaX Team <pageexec@freemail.hu>
+ * Licensed under the GPL v2
+ *
+ * Note: the choice of the license means that the compilation process is
+ *       NOT 'eligible' as defined by gcc's library exception to the GPL v3,
+ *       but for the kernel it doesn't matter since it doesn't link against
+ *       any of the gcc libraries
+ *
+ * gcc plugin to make KERNEXEC/amd64 almost as good as it is on i386
+ *
+ * TODO:
+ *
+ * BUGS:
+ * - none known
+ */
+
+#include "gcc-common.h"
+
+int plugin_is_GPL_compatible;
+
+static struct plugin_info kernexec_plugin_info = {
+	.version	= "201401260140",
+	.help		= "method=[bts|or]\tinstrumentation method\n"
+};
+
+static void (*kernexec_instrument_fptr)(gimple_stmt_iterator *);
+static void (*kernexec_instrument_retaddr)(rtx);
+
+/*
+ * add special KERNEXEC instrumentation: reload %r12 after it has been clobbered
+ */
+static void kernexec_reload_fptr_mask(gimple_stmt_iterator *gsi)
+{
+	gimple stmt;
+	gasm *asm_movabs_stmt;
+
+	// build asm volatile("movabs $0x8000000000000000, %%r12\n\t" : : : );
+	stmt = gimple_build_asm_vec("movabs $0x8000000000000000, %%r12\n\t", NULL, NULL, NULL, NULL);
+	asm_movabs_stmt = as_a_gasm(stmt);
+	gimple_asm_set_volatile(asm_movabs_stmt, true);
+	gsi_insert_after(gsi, asm_movabs_stmt, GSI_CONTINUE_LINKING);
+	update_stmt(asm_movabs_stmt);
+}
+
+/*
+ * find all asm() stmts that clobber r12 and add a reload of r12
+ */
+static unsigned int execute_kernexec_reload(void)
+{
+	basic_block bb;
+
+	// 1. loop through BBs and GIMPLE statements
+	FOR_EACH_BB_FN(bb, cfun) {
+		gimple_stmt_iterator gsi;
+
+		for (gsi = gsi_start_bb(bb); !gsi_end_p(gsi); gsi_next(&gsi)) {
+			// gimple match: __asm__ ("" :  :  : "r12");
+			gimple stmt;
+			gasm *asm_stmt;
+			size_t nclobbers;
+
+			// is it an asm ...
+			stmt = gsi_stmt(gsi);
+			if (gimple_code(stmt) != GIMPLE_ASM)
+				continue;
+
+			asm_stmt = as_a_gasm(stmt);
+
+			// ... clobbering r12
+			nclobbers = gimple_asm_nclobbers(asm_stmt);
+			while (nclobbers--) {
+				tree op = gimple_asm_clobber_op(asm_stmt, nclobbers);
+				if (strcmp(TREE_STRING_POINTER(TREE_VALUE(op)), "r12"))
+					continue;
+				kernexec_reload_fptr_mask(&gsi);
+//print_gimple_stmt(stderr, asm_stmt, 0, TDF_LINENO);
+				break;
+			}
+		}
+	}
+
+	return 0;
+}
+
+/*
+ * add special KERNEXEC instrumentation: force MSB of fptr to 1, which will produce
+ * a non-canonical address from a userland ptr and will just trigger a GPF on dereference
+ */
+static void kernexec_instrument_fptr_bts(gimple_stmt_iterator *gsi)
+{
+	gimple assign_intptr, assign_new_fptr;
+	gcall *call_stmt;
+	tree intptr, orptr, old_fptr, new_fptr, kernexec_mask;
+
+	call_stmt = as_a_gcall(gsi_stmt(*gsi));
+	old_fptr = gimple_call_fn(call_stmt);
+
+	// create temporary unsigned long variable used for bitops and cast fptr to it
+	intptr = create_tmp_var(long_unsigned_type_node, "kernexec_bts");
+	add_referenced_var(intptr);
+	intptr = make_ssa_name(intptr, NULL);
+	assign_intptr = gimple_build_assign(intptr, fold_convert(long_unsigned_type_node, old_fptr));
+	SSA_NAME_DEF_STMT(intptr) = assign_intptr;
+	gsi_insert_before(gsi, assign_intptr, GSI_SAME_STMT);
+	update_stmt(assign_intptr);
+
+	// apply logical or to temporary unsigned long and bitmask
+	kernexec_mask = build_int_cstu(long_long_unsigned_type_node, 0x8000000000000000LL);
+//	kernexec_mask = build_int_cstu(long_long_unsigned_type_node, 0xffffffff80000000LL);
+	orptr = fold_build2(BIT_IOR_EXPR, long_long_unsigned_type_node, intptr, kernexec_mask);
+	intptr = make_ssa_name(SSA_NAME_VAR(intptr), NULL);
+	assign_intptr = gimple_build_assign(intptr, orptr);
+	SSA_NAME_DEF_STMT(intptr) = assign_intptr;
+	gsi_insert_before(gsi, assign_intptr, GSI_SAME_STMT);
+	update_stmt(assign_intptr);
+
+	// cast temporary unsigned long back to a temporary fptr variable
+	new_fptr = create_tmp_var(TREE_TYPE(old_fptr), "kernexec_fptr");
+	add_referenced_var(new_fptr);
+	new_fptr = make_ssa_name(new_fptr, NULL);
+	assign_new_fptr = gimple_build_assign(new_fptr, fold_convert(TREE_TYPE(old_fptr), intptr));
+	SSA_NAME_DEF_STMT(new_fptr) = assign_new_fptr;
+	gsi_insert_before(gsi, assign_new_fptr, GSI_SAME_STMT);
+	update_stmt(assign_new_fptr);
+
+	// replace call stmt fn with the new fptr
+	gimple_call_set_fn(call_stmt, new_fptr);
+	update_stmt(call_stmt);
+}
+
+static void kernexec_instrument_fptr_or(gimple_stmt_iterator *gsi)
+{
+	gimple stmt;
+	gasm *asm_or_stmt;
+	gcall *call_stmt;
+	tree old_fptr, new_fptr, input, output;
+#if BUILDING_GCC_VERSION <= 4007
+	VEC(tree, gc) *inputs = NULL;
+	VEC(tree, gc) *outputs = NULL;
+#else
+	vec<tree, va_gc> *inputs = NULL;
+	vec<tree, va_gc> *outputs = NULL;
+#endif
+
+	call_stmt = as_a_gcall(gsi_stmt(*gsi));
+	old_fptr = gimple_call_fn(call_stmt);
+
+	// create temporary fptr variable
+	new_fptr = create_tmp_var(TREE_TYPE(old_fptr), "kernexec_or");
+	add_referenced_var(new_fptr);
+	new_fptr = make_ssa_name(new_fptr, NULL);
+
+	// build asm volatile("orq %%r12, %0\n\t" : "=r"(new_fptr) : "0"(old_fptr));
+	input = build_tree_list(NULL_TREE, build_string(2, "0"));
+	input = chainon(NULL_TREE, build_tree_list(input, old_fptr));
+	output = build_tree_list(NULL_TREE, build_string(3, "=r"));
+	output = chainon(NULL_TREE, build_tree_list(output, new_fptr));
+#if BUILDING_GCC_VERSION <= 4007
+	VEC_safe_push(tree, gc, inputs, input);
+	VEC_safe_push(tree, gc, outputs, output);
+#else
+	vec_safe_push(inputs, input);
+	vec_safe_push(outputs, output);
+#endif
+	stmt = gimple_build_asm_vec("orq %%r12, %0\n\t", inputs, outputs, NULL, NULL);
+	asm_or_stmt = as_a_gasm(stmt);
+	SSA_NAME_DEF_STMT(new_fptr) = asm_or_stmt;
+	gimple_asm_set_volatile(asm_or_stmt, true);
+	gsi_insert_before(gsi, asm_or_stmt, GSI_SAME_STMT);
+	update_stmt(asm_or_stmt);
+
+	// replace call stmt fn with the new fptr
+	gimple_call_set_fn(call_stmt, new_fptr);
+	update_stmt(call_stmt);
+}
+
+/*
+ * find all C level function pointer dereferences and forcibly set the highest bit of the pointer
+ */
+static unsigned int execute_kernexec_fptr(void)
+{
+	basic_block bb;
+
+	// 1. loop through BBs and GIMPLE statements
+	FOR_EACH_BB_FN(bb, cfun) {
+		gimple_stmt_iterator gsi;
+
+		for (gsi = gsi_start_bb(bb); !gsi_end_p(gsi); gsi_next(&gsi)) {
+			// gimple match: h_1 = get_fptr (); D.2709_3 = h_1 (x_2(D));
+			tree fn;
+			gimple stmt;
+			gcall *call_stmt;
+
+			// is it a call ...
+			stmt = gsi_stmt(gsi);
+			if (!is_gimple_call(stmt))
+				continue;
+			call_stmt = as_a_gcall(stmt);
+			fn = gimple_call_fn(call_stmt);
+			if (TREE_CODE(fn) == ADDR_EXPR)
+				continue;
+			if (TREE_CODE(fn) != SSA_NAME)
+				gcc_unreachable();
+
+			// ... through a function pointer
+			if (SSA_NAME_VAR(fn) != NULL_TREE) {
+				fn = SSA_NAME_VAR(fn);
+				if (TREE_CODE(fn) != VAR_DECL && TREE_CODE(fn) != PARM_DECL) {
+					debug_tree(fn);
+					gcc_unreachable();
+				}
+			}
+			fn = TREE_TYPE(fn);
+			if (TREE_CODE(fn) != POINTER_TYPE)
+				continue;
+			fn = TREE_TYPE(fn);
+			if (TREE_CODE(fn) != FUNCTION_TYPE)
+				continue;
+
+			kernexec_instrument_fptr(&gsi);
+
+//debug_tree(gimple_call_fn(call_stmt));
+//print_gimple_stmt(stderr, call_stmt, 0, TDF_LINENO);
+		}
+	}
+
+	return 0;
+}
+
+// add special KERNEXEC instrumentation: btsq $63,(%rsp) just before retn
+static void kernexec_instrument_retaddr_bts(rtx insn)
+{
+	rtx btsq;
+	rtvec argvec, constraintvec, labelvec;
+	int line;
+
+	// create asm volatile("btsq $63,(%%rsp)":::)
+	argvec = rtvec_alloc(0);
+	constraintvec = rtvec_alloc(0);
+	labelvec = rtvec_alloc(0);
+	line = expand_location(RTL_LOCATION(insn)).line;
+	btsq = gen_rtx_ASM_OPERANDS(VOIDmode, "btsq $63,(%%rsp)", empty_string, 0, argvec, constraintvec, labelvec, line);
+	MEM_VOLATILE_P(btsq) = 1;
+//	RTX_FRAME_RELATED_P(btsq) = 1; // not for ASM_OPERANDS
+	emit_insn_before(btsq, insn);
+}
+
+// add special KERNEXEC instrumentation: orq %r12,(%rsp) just before retn
+static void kernexec_instrument_retaddr_or(rtx insn)
+{
+	rtx orq;
+	rtvec argvec, constraintvec, labelvec;
+	int line;
+
+	// create asm volatile("orq %%r12,(%%rsp)":::)
+	argvec = rtvec_alloc(0);
+	constraintvec = rtvec_alloc(0);
+	labelvec = rtvec_alloc(0);
+	line = expand_location(RTL_LOCATION(insn)).line;
+	orq = gen_rtx_ASM_OPERANDS(VOIDmode, "orq %%r12,(%%rsp)", empty_string, 0, argvec, constraintvec, labelvec, line);
+	MEM_VOLATILE_P(orq) = 1;
+//	RTX_FRAME_RELATED_P(orq) = 1; // not for ASM_OPERANDS
+	emit_insn_before(orq, insn);
+}
+
+/*
+ * find all asm level function returns and forcibly set the highest bit of the return address
+ */
+static unsigned int execute_kernexec_retaddr(void)
+{
+	rtx_insn *insn;
+
+//	if (stack_realign_drap)
+//		inform(DECL_SOURCE_LOCATION(current_function_decl), "drap detected in %s\n", IDENTIFIER_POINTER(DECL_NAME(current_function_decl)));
+
+	// 1. find function returns
+	for (insn = get_insns(); insn; insn = NEXT_INSN(insn)) {
+		// rtl match: (jump_insn 41 40 42 2 (return) fptr.c:42 634 {return_internal} (nil))
+		//            (jump_insn 12 9 11 2 (parallel [ (return) (unspec [ (0) ] UNSPEC_REP) ]) fptr.c:46 635 {return_internal_long} (nil))
+		//            (jump_insn 97 96 98 6 (simple_return) fptr.c:50 -1 (nil) -> simple_return)
+		rtx body;
+
+		// is it a retn
+		if (!JUMP_P(insn))
+			continue;
+		body = PATTERN(insn);
+		if (GET_CODE(body) == PARALLEL)
+			body = XVECEXP(body, 0, 0);
+		if (!ANY_RETURN_P(body))
+			continue;
+		kernexec_instrument_retaddr(insn);
+	}
+
+//	print_simple_rtl(stderr, get_insns());
+//	print_rtl(stderr, get_insns());
+
+	return 0;
+}
+
+static bool kernexec_cmodel_check(void)
+{
+	tree section;
+
+	if (ix86_cmodel != CM_KERNEL)
+		return false;
+
+	section = lookup_attribute("section", DECL_ATTRIBUTES(current_function_decl));
+	if (!section || !TREE_VALUE(section))
+		return true;
+
+	section = TREE_VALUE(TREE_VALUE(section));
+	if (strncmp(TREE_STRING_POINTER(section), ".vsyscall_", 10))
+		return true;
+
+	return false;
+}
+
+#if BUILDING_GCC_VERSION >= 4009
+namespace {
+static const struct pass_data kernexec_reload_pass_data = {
+#else
+static struct gimple_opt_pass kernexec_reload_pass = {
+	.pass = {
+#endif
+		.type			= GIMPLE_PASS,
+		.name			= "kernexec_reload",
+#if BUILDING_GCC_VERSION >= 4008
+		.optinfo_flags		= OPTGROUP_NONE,
+#endif
+#if BUILDING_GCC_VERSION >= 5000
+#elif BUILDING_GCC_VERSION == 4009
+		.has_gate		= true,
+		.has_execute		= true,
+#else
+		.gate			= kernexec_cmodel_check,
+		.execute		= execute_kernexec_reload,
+		.sub			= NULL,
+		.next			= NULL,
+		.static_pass_number	= 0,
+#endif
+		.tv_id			= TV_NONE,
+		.properties_required	= 0,
+		.properties_provided	= 0,
+		.properties_destroyed	= 0,
+		.todo_flags_start	= 0,
+		.todo_flags_finish	= TODO_verify_ssa | TODO_verify_stmts | TODO_dump_func | TODO_remove_unused_locals | TODO_update_ssa_no_phi
+#if BUILDING_GCC_VERSION < 4009
+	}
+#endif
+};
+
+#if BUILDING_GCC_VERSION >= 4009
+static const struct pass_data kernexec_fptr_pass_data = {
+#else
+static struct gimple_opt_pass kernexec_fptr_pass = {
+	.pass = {
+#endif
+		.type			= GIMPLE_PASS,
+		.name			= "kernexec_fptr",
+#if BUILDING_GCC_VERSION >= 4008
+		.optinfo_flags		= OPTGROUP_NONE,
+#endif
+#if BUILDING_GCC_VERSION >= 5000
+#elif BUILDING_GCC_VERSION == 4009
+		.has_gate		= true,
+		.has_execute		= true,
+#else
+		.gate			= kernexec_cmodel_check,
+		.execute		= execute_kernexec_fptr,
+		.sub			= NULL,
+		.next			= NULL,
+		.static_pass_number	= 0,
+#endif
+		.tv_id			= TV_NONE,
+		.properties_required	= 0,
+		.properties_provided	= 0,
+		.properties_destroyed	= 0,
+		.todo_flags_start	= 0,
+		.todo_flags_finish	= TODO_verify_ssa | TODO_verify_stmts | TODO_dump_func | TODO_remove_unused_locals | TODO_update_ssa_no_phi
+#if BUILDING_GCC_VERSION < 4009
+	}
+#endif
+};
+
+#if BUILDING_GCC_VERSION >= 4009
+static const struct pass_data kernexec_retaddr_pass_data = {
+#else
+static struct rtl_opt_pass kernexec_retaddr_pass = {
+	.pass = {
+#endif
+		.type			= RTL_PASS,
+		.name			= "kernexec_retaddr",
+#if BUILDING_GCC_VERSION >= 4008
+		.optinfo_flags		= OPTGROUP_NONE,
+#endif
+#if BUILDING_GCC_VERSION >= 5000
+#elif BUILDING_GCC_VERSION == 4009
+		.has_gate		= true,
+		.has_execute		= true,
+#else
+		.gate			= kernexec_cmodel_check,
+		.execute		= execute_kernexec_retaddr,
+		.sub			= NULL,
+		.next			= NULL,
+		.static_pass_number	= 0,
+#endif
+		.tv_id			= TV_NONE,
+		.properties_required	= 0,
+		.properties_provided	= 0,
+		.properties_destroyed	= 0,
+		.todo_flags_start	= 0,
+		.todo_flags_finish	= TODO_dump_func | TODO_ggc_collect
+#if BUILDING_GCC_VERSION < 4009
+	}
+#endif
+};
+
+#if BUILDING_GCC_VERSION >= 4009
+class kernexec_reload_pass : public gimple_opt_pass {
+public:
+	kernexec_reload_pass() : gimple_opt_pass(kernexec_reload_pass_data, g) {}
+#if BUILDING_GCC_VERSION >= 5000
+	virtual bool gate(function *) { return kernexec_cmodel_check(); }
+	virtual unsigned int execute(function *) { return execute_kernexec_reload(); }
+#else
+	bool gate() { return kernexec_cmodel_check(); }
+	unsigned int execute() { return execute_kernexec_reload(); }
+#endif
+};
+
+class kernexec_fptr_pass : public gimple_opt_pass {
+public:
+	kernexec_fptr_pass() : gimple_opt_pass(kernexec_fptr_pass_data, g) {}
+#if BUILDING_GCC_VERSION >= 5000
+	virtual bool gate(function *) { return kernexec_cmodel_check(); }
+	virtual unsigned int execute(function *) { return execute_kernexec_fptr(); }
+#else
+	bool gate() { return kernexec_cmodel_check(); }
+	unsigned int execute() { return execute_kernexec_fptr(); }
+#endif
+};
+
+class kernexec_retaddr_pass : public rtl_opt_pass {
+public:
+	kernexec_retaddr_pass() : rtl_opt_pass(kernexec_retaddr_pass_data, g) {}
+#if BUILDING_GCC_VERSION >= 5000
+	virtual bool gate(function *) { return kernexec_cmodel_check(); }
+	virtual unsigned int execute(function *) { return execute_kernexec_retaddr(); }
+#else
+	bool gate() { return kernexec_cmodel_check(); }
+	unsigned int execute() { return execute_kernexec_retaddr(); }
+#endif
+};
+}
+
+static opt_pass *make_kernexec_reload_pass(void)
+{
+	return new kernexec_reload_pass();
+}
+
+static opt_pass *make_kernexec_fptr_pass(void)
+{
+	return new kernexec_fptr_pass();
+}
+
+static opt_pass *make_kernexec_retaddr_pass(void)
+{
+	return new kernexec_retaddr_pass();
+}
+#else
+static struct opt_pass *make_kernexec_reload_pass(void)
+{
+	return &kernexec_reload_pass.pass;
+}
+
+static struct opt_pass *make_kernexec_fptr_pass(void)
+{
+	return &kernexec_fptr_pass.pass;
+}
+
+static struct opt_pass *make_kernexec_retaddr_pass(void)
+{
+	return &kernexec_retaddr_pass.pass;
+}
+#endif
+
+int plugin_init(struct plugin_name_args *plugin_info, struct plugin_gcc_version *version)
+{
+	const char * const plugin_name = plugin_info->base_name;
+	const int argc = plugin_info->argc;
+	const struct plugin_argument * const argv = plugin_info->argv;
+	int i;
+	struct register_pass_info kernexec_reload_pass_info;
+	struct register_pass_info kernexec_fptr_pass_info;
+	struct register_pass_info kernexec_retaddr_pass_info;
+
+	kernexec_reload_pass_info.pass				= make_kernexec_reload_pass();
+	kernexec_reload_pass_info.reference_pass_name		= "ssa";
+	kernexec_reload_pass_info.ref_pass_instance_number	= 1;
+	kernexec_reload_pass_info.pos_op 			= PASS_POS_INSERT_AFTER;
+
+	kernexec_fptr_pass_info.pass				= make_kernexec_fptr_pass();
+	kernexec_fptr_pass_info.reference_pass_name		= "ssa";
+	kernexec_fptr_pass_info.ref_pass_instance_number	= 1;
+	kernexec_fptr_pass_info.pos_op 				= PASS_POS_INSERT_AFTER;
+
+	kernexec_retaddr_pass_info.pass				= make_kernexec_retaddr_pass();
+	kernexec_retaddr_pass_info.reference_pass_name		= "pro_and_epilogue";
+	kernexec_retaddr_pass_info.ref_pass_instance_number	= 1;
+	kernexec_retaddr_pass_info.pos_op 			= PASS_POS_INSERT_AFTER;
+
+	if (!plugin_default_version_check(version, &gcc_version)) {
+		error(G_("incompatible gcc/plugin versions"));
+		return 1;
+	}
+
+	register_callback(plugin_name, PLUGIN_INFO, NULL, &kernexec_plugin_info);
+
+	if (TARGET_64BIT == 0)
+		return 0;
+
+	for (i = 0; i < argc; ++i) {
+		if (!strcmp(argv[i].key, "method")) {
+			if (!argv[i].value) {
+				error(G_("no value supplied for option '-fplugin-arg-%s-%s'"), plugin_name, argv[i].key);
+				continue;
+			}
+			if (!strcmp(argv[i].value, "bts")) {
+				kernexec_instrument_fptr = kernexec_instrument_fptr_bts;
+				kernexec_instrument_retaddr = kernexec_instrument_retaddr_bts;
+			} else if (!strcmp(argv[i].value, "or")) {
+				kernexec_instrument_fptr = kernexec_instrument_fptr_or;
+				kernexec_instrument_retaddr = kernexec_instrument_retaddr_or;
+				fix_register("r12", 1, 1);
+			} else
+				error(G_("invalid option argument '-fplugin-arg-%s-%s=%s'"), plugin_name, argv[i].key, argv[i].value);
+			continue;
+		}
+		error(G_("unkown option '-fplugin-arg-%s-%s'"), plugin_name, argv[i].key);
+	}
+	if (!kernexec_instrument_fptr || !kernexec_instrument_retaddr)
+		error(G_("no instrumentation method was selected via '-fplugin-arg-%s-method'"), plugin_name);
+
+	if (kernexec_instrument_fptr == kernexec_instrument_fptr_or)
+		register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &kernexec_reload_pass_info);
+	register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &kernexec_fptr_pass_info);
+	register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &kernexec_retaddr_pass_info);
+
+	return 0;
+}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/latent_entropy_plugin.c linux-3.2.71-pax/tools/gcc/latent_entropy_plugin.c
--- linux-3.2.71/tools/gcc/latent_entropy_plugin.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/latent_entropy_plugin.c	2015-04-30 03:07:38.400532395 +0200
@@ -0,0 +1,474 @@
+/*
+ * Copyright 2012-2015 by the PaX Team <pageexec@freemail.hu>
+ * Licensed under the GPL v2
+ *
+ * Note: the choice of the license means that the compilation process is
+ *       NOT 'eligible' as defined by gcc's library exception to the GPL v3,
+ *       but for the kernel it doesn't matter since it doesn't link against
+ *       any of the gcc libraries
+ *
+ * gcc plugin to help generate a little bit of entropy from program state,
+ * used throughout the uptime of the kernel
+ *
+ * TODO:
+ * - add ipa pass to identify not explicitly marked candidate functions
+ * - mix in more program state (function arguments/return values, loop variables, etc)
+ * - more instrumentation control via attribute parameters
+ *
+ * BUGS:
+ * - none known
+ */
+
+#include "gcc-common.h"
+
+int plugin_is_GPL_compatible;
+
+static GTY(()) tree latent_entropy_decl;
+
+static struct plugin_info latent_entropy_plugin_info = {
+	.version	= "201504282240",
+	.help		= NULL
+};
+
+static unsigned HOST_WIDE_INT seed;
+static unsigned HOST_WIDE_INT get_random_const(void)
+{
+	unsigned int i;
+	unsigned HOST_WIDE_INT ret = 0;
+
+	for (i = 0; i < 8 * sizeof ret; i++) {
+		ret = (ret << 1) | (seed & 1);
+		seed >>= 1;
+		if (ret & 1)
+			seed ^= 0xD800000000000000ULL;
+	}
+
+	return ret;
+}
+
+static tree handle_latent_entropy_attribute(tree *node, tree name, tree args, int flags, bool *no_add_attrs)
+{
+	tree type;
+	unsigned long long mask;
+#if BUILDING_GCC_VERSION <= 4007
+	VEC(constructor_elt, gc) *vals;
+#else
+	vec<constructor_elt, va_gc> *vals;
+#endif
+
+	switch (TREE_CODE(*node)) {
+	default:
+		*no_add_attrs = true;
+		error("%qE attribute only applies to functions and variables", name);
+		break;
+
+	case VAR_DECL:
+		if (DECL_INITIAL(*node)) {
+			*no_add_attrs = true;
+			error("variable %qD with %qE attribute must not be initialized", *node, name);
+			break;
+		}
+
+		if (!TREE_STATIC(*node)) {
+			*no_add_attrs = true;
+			error("variable %qD with %qE attribute must not be local", *node, name);
+			break;
+		}
+
+		type = TREE_TYPE(*node);
+		switch (TREE_CODE(type)) {
+		default:
+			*no_add_attrs = true;
+			error("variable %qD with %qE attribute must be an integer or a fixed length integer array type or a fixed sized structure with integer fields", *node, name);
+			break;
+
+		case RECORD_TYPE: {
+			tree field;
+			unsigned int nelt = 0;
+
+			for (field = TYPE_FIELDS(type); field; nelt++, field = TREE_CHAIN(field)) {
+				tree fieldtype;
+
+				fieldtype = TREE_TYPE(field);
+				if (TREE_CODE(fieldtype) != INTEGER_TYPE) {
+					*no_add_attrs = true;
+					error("structure variable %qD with %qE attribute has a non-integer field %qE", *node, name, field);
+					break;
+				}
+			}
+
+			if (field)
+				break;
+
+#if BUILDING_GCC_VERSION <= 4007
+			vals = VEC_alloc(constructor_elt, gc, nelt);
+#else
+			vec_alloc(vals, nelt);
+#endif
+
+			for (field = TYPE_FIELDS(type); field; field = TREE_CHAIN(field)) {
+				tree fieldtype;
+
+				fieldtype = TREE_TYPE(field);
+				mask = 1ULL << (TREE_INT_CST_LOW(TYPE_SIZE(fieldtype)) - 1);
+				mask = 2 * (mask - 1) + 1;
+
+				if (TYPE_UNSIGNED(fieldtype))
+					CONSTRUCTOR_APPEND_ELT(vals, field, build_int_cstu(fieldtype, mask & get_random_const()));
+				else
+					CONSTRUCTOR_APPEND_ELT(vals, field, build_int_cst(fieldtype, mask & get_random_const()));
+			}
+
+			DECL_INITIAL(*node) = build_constructor(type, vals);
+//debug_tree(DECL_INITIAL(*node));
+			break;
+		}
+
+		case INTEGER_TYPE:
+			mask = 1ULL << (TREE_INT_CST_LOW(TYPE_SIZE(type)) - 1);
+			mask = 2 * (mask - 1) + 1;
+
+			if (TYPE_UNSIGNED(type))
+				DECL_INITIAL(*node) = build_int_cstu(type, mask & get_random_const());
+			else
+				DECL_INITIAL(*node) = build_int_cst(type, mask & get_random_const());
+			break;
+
+		case ARRAY_TYPE: {
+			tree elt_type, array_size, elt_size;
+			unsigned int i, nelt;
+
+			elt_type = TREE_TYPE(type);
+			elt_size = TYPE_SIZE_UNIT(TREE_TYPE(type));
+			array_size = TYPE_SIZE_UNIT(type);
+
+			if (TREE_CODE(elt_type) != INTEGER_TYPE || !array_size || TREE_CODE(array_size) != INTEGER_CST) {
+				*no_add_attrs = true;
+				error("array variable %qD with %qE attribute must be a fixed length integer array type", *node, name);
+				break;
+			}
+
+			nelt = TREE_INT_CST_LOW(array_size) / TREE_INT_CST_LOW(elt_size);
+#if BUILDING_GCC_VERSION <= 4007
+			vals = VEC_alloc(constructor_elt, gc, nelt);
+#else
+			vec_alloc(vals, nelt);
+#endif
+
+			mask = 1ULL << (TREE_INT_CST_LOW(TYPE_SIZE(elt_type)) - 1);
+			mask = 2 * (mask - 1) + 1;
+
+			for (i = 0; i < nelt; i++)
+				if (TYPE_UNSIGNED(elt_type))
+					CONSTRUCTOR_APPEND_ELT(vals, size_int(i), build_int_cstu(elt_type, mask & get_random_const()));
+				else
+					CONSTRUCTOR_APPEND_ELT(vals, size_int(i), build_int_cst(elt_type, mask & get_random_const()));
+
+			DECL_INITIAL(*node) = build_constructor(type, vals);
+//debug_tree(DECL_INITIAL(*node));
+			break;
+		}
+		}
+		break;
+
+	case FUNCTION_DECL:
+		break;
+	}
+
+	return NULL_TREE;
+}
+
+static struct attribute_spec latent_entropy_attr = {
+	.name				= "latent_entropy",
+	.min_length			= 0,
+	.max_length			= 0,
+	.decl_required			= true,
+	.type_required			= false,
+	.function_type_required		= false,
+	.handler			= handle_latent_entropy_attribute,
+#if BUILDING_GCC_VERSION >= 4007
+	.affects_type_identity		= false
+#endif
+};
+
+static void register_attributes(void *event_data, void *data)
+{
+	register_attribute(&latent_entropy_attr);
+}
+
+static bool gate_latent_entropy(void)
+{
+	// don't bother with noreturn functions for now
+	if (TREE_THIS_VOLATILE(current_function_decl))
+		return false;
+
+	// gcc-4.5 doesn't discover some trivial noreturn functions
+	if (EDGE_COUNT(EXIT_BLOCK_PTR_FOR_FN(cfun)->preds) == 0)
+		return false;
+
+	return lookup_attribute("latent_entropy", DECL_ATTRIBUTES(current_function_decl)) != NULL_TREE;
+}
+
+static enum tree_code get_op(tree *rhs)
+{
+	static enum tree_code op;
+	unsigned HOST_WIDE_INT random_const;
+
+	random_const = get_random_const();
+
+	switch (op) {
+	case BIT_XOR_EXPR:
+		op = PLUS_EXPR;
+		break;
+
+	case PLUS_EXPR:
+		if (rhs) {
+			op = LROTATE_EXPR;
+			random_const &= HOST_BITS_PER_WIDE_INT - 1;
+			break;
+		}
+
+	case LROTATE_EXPR:
+	default:
+		op = BIT_XOR_EXPR;
+		break;
+	}
+	if (rhs)
+		*rhs = build_int_cstu(unsigned_intDI_type_node, random_const);
+	return op;
+}
+
+static void perturb_local_entropy(basic_block bb, tree local_entropy)
+{
+	gimple_stmt_iterator gsi;
+	gimple assign;
+	tree addxorrol, rhs;
+	enum tree_code op;
+
+	op = get_op(&rhs);
+	addxorrol = fold_build2_loc(UNKNOWN_LOCATION, op, unsigned_intDI_type_node, local_entropy, rhs);
+	assign = gimple_build_assign(local_entropy, addxorrol);
+	gsi = gsi_after_labels(bb);
+	gsi_insert_before(&gsi, assign, GSI_NEW_STMT);
+	update_stmt(assign);
+//debug_bb(bb);
+}
+
+static void perturb_latent_entropy(basic_block bb, tree rhs)
+{
+	gimple_stmt_iterator gsi;
+	gimple assign;
+	tree addxorrol, temp;
+
+	// 1. create temporary copy of latent_entropy
+	temp = create_tmp_var(unsigned_intDI_type_node, "temp_latent_entropy");
+	add_referenced_var(temp);
+
+	// 2. read...
+	temp = make_ssa_name(temp, NULL);
+	assign = gimple_build_assign(temp, latent_entropy_decl);
+	SSA_NAME_DEF_STMT(temp) = assign;
+	add_referenced_var(latent_entropy_decl);
+	gsi = gsi_after_labels(bb);
+	gsi_insert_after(&gsi, assign, GSI_NEW_STMT);
+	update_stmt(assign);
+
+	// 3. ...modify...
+	addxorrol = fold_build2_loc(UNKNOWN_LOCATION, get_op(NULL), unsigned_intDI_type_node, temp, rhs);
+	temp = make_ssa_name(SSA_NAME_VAR(temp), NULL);
+	assign = gimple_build_assign(temp, addxorrol);
+	SSA_NAME_DEF_STMT(temp) = assign;
+	gsi_insert_after(&gsi, assign, GSI_NEW_STMT);
+	update_stmt(assign);
+
+	// 4. ...write latent_entropy
+	assign = gimple_build_assign(latent_entropy_decl, temp);
+	gsi_insert_after(&gsi, assign, GSI_NEW_STMT);
+	update_stmt(assign);
+}
+
+static unsigned int execute_latent_entropy(void)
+{
+	basic_block bb;
+	gimple assign;
+	gimple_stmt_iterator gsi;
+	tree local_entropy;
+
+	if (!latent_entropy_decl) {
+#if BUILDING_GCC_VERSION >= 4009
+		varpool_node *node;
+#else
+		struct varpool_node *node;
+#endif
+
+		FOR_EACH_VARIABLE(node) {
+			tree var = NODE_DECL(node);
+
+			if (DECL_NAME_LENGTH(var) < sizeof("latent_entropy") - 1)
+				continue;
+			if (strcmp(IDENTIFIER_POINTER(DECL_NAME(var)), "latent_entropy"))
+				continue;
+			latent_entropy_decl = var;
+//			debug_tree(var);
+			break;
+		}
+		if (!latent_entropy_decl) {
+//			debug_tree(current_function_decl);
+			return 0;
+		}
+	}
+
+//fprintf(stderr, "latent_entropy: %s\n", IDENTIFIER_POINTER(DECL_NAME(current_function_decl)));
+
+	// 1. create local entropy variable
+	local_entropy = create_tmp_var(unsigned_intDI_type_node, "local_entropy");
+	add_referenced_var(local_entropy);
+	mark_sym_for_renaming(local_entropy);
+
+	// 2. initialize local entropy variable
+	bb = split_block_after_labels(ENTRY_BLOCK_PTR_FOR_FN(cfun))->dest;
+	if (dom_info_available_p(CDI_DOMINATORS))
+		set_immediate_dominator(CDI_DOMINATORS, bb, ENTRY_BLOCK_PTR_FOR_FN(cfun));
+	gsi = gsi_start_bb(bb);
+
+	assign = gimple_build_assign(local_entropy, build_int_cstu(unsigned_intDI_type_node, get_random_const()));
+//	gimple_set_location(assign, loc);
+	gsi_insert_after(&gsi, assign, GSI_NEW_STMT);
+	update_stmt(assign);
+//debug_bb(bb);
+	gcc_assert(single_succ_p(bb));
+	bb = single_succ(bb);
+
+	// 3. instrument each BB with an operation on the local entropy variable
+	while (bb != EXIT_BLOCK_PTR_FOR_FN(cfun)) {
+		perturb_local_entropy(bb, local_entropy);
+//debug_bb(bb);
+		bb = bb->next_bb;
+	};
+
+	// 4. mix local entropy into the global entropy variable
+	gcc_assert(single_pred_p(EXIT_BLOCK_PTR_FOR_FN(cfun)));
+	perturb_latent_entropy(single_pred(EXIT_BLOCK_PTR_FOR_FN(cfun)), local_entropy);
+//debug_bb(single_pred(EXIT_BLOCK_PTR_FOR_FN(cfun)));
+	return 0;
+}
+
+static void latent_entropy_start_unit(void *gcc_data, void *user_data)
+{
+	tree latent_entropy_type;
+
+	seed = get_random_seed(false);
+
+	if (in_lto_p)
+		return;
+
+	// extern volatile u64 latent_entropy
+	gcc_assert(TYPE_PRECISION(long_long_unsigned_type_node) == 64);
+	latent_entropy_type = build_qualified_type(long_long_unsigned_type_node, TYPE_QUALS(long_long_unsigned_type_node) | TYPE_QUAL_VOLATILE);
+	latent_entropy_decl = build_decl(UNKNOWN_LOCATION, VAR_DECL, get_identifier("latent_entropy"), latent_entropy_type);
+
+	TREE_STATIC(latent_entropy_decl) = 1;
+	TREE_PUBLIC(latent_entropy_decl) = 1;
+	TREE_USED(latent_entropy_decl) = 1;
+	DECL_PRESERVE_P(latent_entropy_decl) = 1;
+	TREE_THIS_VOLATILE(latent_entropy_decl) = 1;
+	DECL_EXTERNAL(latent_entropy_decl) = 1;
+	DECL_ARTIFICIAL(latent_entropy_decl) = 1;
+	lang_hooks.decls.pushdecl(latent_entropy_decl);
+//	DECL_ASSEMBLER_NAME(latent_entropy_decl);
+//	varpool_finalize_decl(latent_entropy_decl);
+//	varpool_mark_needed_node(latent_entropy_decl);
+}
+
+#if BUILDING_GCC_VERSION >= 4009
+namespace {
+static const struct pass_data latent_entropy_pass_data = {
+#else
+static struct gimple_opt_pass latent_entropy_pass = {
+	.pass = {
+#endif
+		.type			= GIMPLE_PASS,
+		.name			= "latent_entropy",
+#if BUILDING_GCC_VERSION >= 4008
+		.optinfo_flags		= OPTGROUP_NONE,
+#endif
+#if BUILDING_GCC_VERSION >= 5000
+#elif BUILDING_GCC_VERSION == 4009
+		.has_gate		= true,
+		.has_execute		= true,
+#else
+		.gate			= gate_latent_entropy,
+		.execute		= execute_latent_entropy,
+		.sub			= NULL,
+		.next			= NULL,
+		.static_pass_number	= 0,
+#endif
+		.tv_id			= TV_NONE,
+		.properties_required	= PROP_gimple_leh | PROP_cfg,
+		.properties_provided	= 0,
+		.properties_destroyed	= 0,
+		.todo_flags_start	= 0, //TODO_verify_ssa | TODO_verify_flow | TODO_verify_stmts,
+		.todo_flags_finish	= TODO_verify_ssa | TODO_verify_stmts | TODO_dump_func | TODO_update_ssa
+#if BUILDING_GCC_VERSION < 4009
+	}
+#endif
+};
+
+#if BUILDING_GCC_VERSION >= 4009
+class latent_entropy_pass : public gimple_opt_pass {
+public:
+	latent_entropy_pass() : gimple_opt_pass(latent_entropy_pass_data, g) {}
+#if BUILDING_GCC_VERSION >= 5000
+	virtual bool gate(function *) { return gate_latent_entropy(); }
+	virtual unsigned int execute(function *) { return execute_latent_entropy(); }
+#else
+	bool gate() { return gate_latent_entropy(); }
+	unsigned int execute() { return execute_latent_entropy(); }
+#endif
+};
+}
+
+static opt_pass *make_latent_entropy_pass(void)
+{
+	return new latent_entropy_pass();
+}
+#else
+static struct opt_pass *make_latent_entropy_pass(void)
+{
+	return &latent_entropy_pass.pass;
+}
+#endif
+
+int plugin_init(struct plugin_name_args *plugin_info, struct plugin_gcc_version *version)
+{
+	const char * const plugin_name = plugin_info->base_name;
+	struct register_pass_info latent_entropy_pass_info;
+
+	latent_entropy_pass_info.pass				= make_latent_entropy_pass();
+	latent_entropy_pass_info.reference_pass_name		= "optimized";
+	latent_entropy_pass_info.ref_pass_instance_number	= 1;
+	latent_entropy_pass_info.pos_op 			= PASS_POS_INSERT_BEFORE;
+	static const struct ggc_root_tab gt_ggc_r_gt_latent_entropy[] = {
+		{
+			.base = &latent_entropy_decl,
+			.nelt = 1,
+			.stride = sizeof(latent_entropy_decl),
+			.cb = &gt_ggc_mx_tree_node,
+			.pchw = &gt_pch_nx_tree_node
+		},
+		LAST_GGC_ROOT_TAB
+	};
+
+	if (!plugin_default_version_check(version, &gcc_version)) {
+		error(G_("incompatible gcc/plugin versions"));
+		return 1;
+	}
+
+	register_callback(plugin_name, PLUGIN_INFO, NULL, &latent_entropy_plugin_info);
+	register_callback(plugin_name, PLUGIN_START_UNIT, &latent_entropy_start_unit, NULL);
+	register_callback(plugin_name, PLUGIN_REGISTER_GGC_ROOTS, NULL, (void *)&gt_ggc_r_gt_latent_entropy);
+	register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &latent_entropy_pass_info);
+	register_callback(plugin_name, PLUGIN_ATTRIBUTES, register_attributes, NULL);
+
+	return 0;
+}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/Makefile linux-3.2.71-pax/tools/gcc/Makefile
--- linux-3.2.71/tools/gcc/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/Makefile	2015-04-30 03:07:38.400532395 +0200
@@ -0,0 +1,40 @@
+#CC := gcc
+#PLUGIN_SOURCE_FILES := pax_plugin.c
+#PLUGIN_OBJECT_FILES := $(patsubst %.c,%.o,$(PLUGIN_SOURCE_FILES))
+GCCPLUGINS_DIR := $(shell $(CC) -print-file-name=plugin)
+#CFLAGS += -I$(GCCPLUGINS_DIR)/include -fPIC -O2 -Wall -W -std=gnu99
+
+ifeq ($(PLUGINCC),$(HOSTCC))
+HOSTLIBS := hostlibs
+HOST_EXTRACFLAGS += -I$(GCCPLUGINS_DIR)/include -I$(src) -std=gnu99 -ggdb
+export HOST_EXTRACFLAGS
+else
+HOSTLIBS := hostcxxlibs
+HOST_EXTRACXXFLAGS += -I$(GCCPLUGINS_DIR)/include -I$(src) -std=gnu++98 -fno-rtti -fno-exceptions -fasynchronous-unwind-tables -ggdb -Wno-unused-parameter -Wno-narrowing -Wno-unused-variable
+export HOST_EXTRACXXFLAGS
+endif
+
+export GCCPLUGINS_DIR HOSTLIBS
+
+$(HOSTLIBS)-$(CONFIG_PAX_CONSTIFY_PLUGIN) := constify_plugin.so
+$(HOSTLIBS)-$(CONFIG_PAX_MEMORY_STACKLEAK) += stackleak_plugin.so
+$(HOSTLIBS)-$(CONFIG_KALLOCSTAT_PLUGIN) += kallocstat_plugin.so
+$(HOSTLIBS)-$(CONFIG_PAX_KERNEXEC_PLUGIN) += kernexec_plugin.so
+$(HOSTLIBS)-$(CONFIG_CHECKER_PLUGIN) += checker_plugin.so
+$(HOSTLIBS)-y += colorize_plugin.so
+$(HOSTLIBS)-$(CONFIG_PAX_LATENT_ENTROPY) += latent_entropy_plugin.so
+$(HOSTLIBS)-$(CONFIG_PAX_MEMORY_STRUCTLEAK) += structleak_plugin.so
+
+subdir-$(CONFIG_PAX_SIZE_OVERFLOW) := size_overflow_plugin
+subdir- += size_overflow_plugin
+
+always := $($(HOSTLIBS)-y)
+
+constify_plugin-objs := constify_plugin.o
+stackleak_plugin-objs := stackleak_plugin.o
+kallocstat_plugin-objs := kallocstat_plugin.o
+kernexec_plugin-objs := kernexec_plugin.o
+checker_plugin-objs := checker_plugin.o
+colorize_plugin-objs := colorize_plugin.o
+latent_entropy_plugin-objs := latent_entropy_plugin.o
+structleak_plugin-objs := structleak_plugin.o
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/generate_size_overflow_hash.sh linux-3.2.71-pax/tools/gcc/size_overflow_plugin/generate_size_overflow_hash.sh
--- linux-3.2.71/tools/gcc/size_overflow_plugin/generate_size_overflow_hash.sh	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/generate_size_overflow_hash.sh	2014-06-02 18:46:28.270285437 +0200
@@ -0,0 +1,102 @@
+#!/bin/bash
+
+# This script generates the hash table (size_overflow_hash.h) for the size_overflow gcc plugin (size_overflow_plugin.c).
+
+header1="size_overflow_hash.h"
+database="size_overflow_hash.data"
+n=65536
+hashtable_name="size_overflow_hash"
+
+usage() {
+cat <<EOF
+usage: $0 options
+OPTIONS:
+        -h|--help               help
+	-o			header file
+	-d			database file
+	-n			hash array size
+	-s			name of the hash table
+EOF
+    return 0
+}
+
+while true
+do
+    case "$1" in
+    -h|--help)	usage && exit 0;;
+    -n)		n=$2; shift 2;;
+    -o)		header1="$2"; shift 2;;
+    -d)		database="$2"; shift 2;;
+    -s)		hashtable_name="$2"; shift 2;;
+    --)		shift 1; break ;;
+     *)		break ;;
+    esac
+done
+
+create_defines() {
+	for i in `seq 0 31`
+	do
+		echo -e "#define PARAM"$i" (1U << "$i")" >> "$header1"
+	done
+	echo >> "$header1"
+}
+
+create_structs() {
+	rm -f "$header1"
+
+	create_defines
+
+	cat "$database" | while read data
+	do
+		data_array=($data)
+		struct_hash_name="${data_array[0]}"
+		funcn="${data_array[1]}"
+		params="${data_array[2]}"
+		next="${data_array[4]}"
+
+		echo "const struct size_overflow_hash $struct_hash_name = {" >> "$header1"
+
+		echo -e "\t.next\t= $next,\n\t.name\t= \"$funcn\"," >> "$header1"
+		echo -en "\t.param\t= " >> "$header1"
+		line=
+		for param_num in ${params//-/ };
+		do
+			line="${line}PARAM"$param_num"|"
+		done
+
+		echo -e "${line%?},\n};\n" >> "$header1"
+	done
+}
+
+create_headers() {
+	echo "const struct size_overflow_hash * const $hashtable_name[$n] = {" >> "$header1"
+}
+
+create_array_elements() {
+	index=0
+	grep -v "nohasharray" $database | sort -n -k 4 | while read data
+	do
+		data_array=($data)
+		i="${data_array[3]}"
+		hash="${data_array[0]}"
+		while [[ $index -lt $i ]]
+		do
+			echo -e "\t["$index"]\t= NULL," >> "$header1"
+			index=$(($index + 1))
+		done
+		index=$(($index + 1))
+		echo -e "\t["$i"]\t= &"$hash"," >> "$header1"
+	done
+	echo '};' >> $header1
+}
+
+size_overflow_plugin_dir=`dirname $header1`
+if [ "$size_overflow_plugin_dir" != '.' ]; then
+	mkdir -p "$size_overflow_plugin_dir" 2> /dev/null
+fi
+
+create_structs
+create_headers
+create_array_elements
+
+exit 0
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/.gitignore linux-3.2.71-pax/tools/gcc/size_overflow_plugin/.gitignore
--- linux-3.2.71/tools/gcc/size_overflow_plugin/.gitignore	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/.gitignore	2014-06-02 19:05:58.250222969 +0200
@@ -0,0 +1 @@
+size_overflow_hash.h
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/insert_size_overflow_asm.c linux-3.2.71-pax/tools/gcc/size_overflow_plugin/insert_size_overflow_asm.c
--- linux-3.2.71/tools/gcc/size_overflow_plugin/insert_size_overflow_asm.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/insert_size_overflow_asm.c	2014-07-27 23:41:39.589093822 +0200
@@ -0,0 +1,748 @@
+/*
+ * Copyright 2011-2014 by Emese Revfy <re.emese@gmail.com>
+ * Licensed under the GPL v2, or (at your option) v3
+ *
+ * Homepage:
+ * http://www.grsecurity.net/~ephox/overflow_plugin/
+ *
+ * Documentation:
+ * http://forums.grsecurity.net/viewtopic.php?f=7&t=3043
+ *
+ * This plugin recomputes expressions of function arguments marked by a size_overflow attribute
+ * with double integer precision (DImode/TImode for 32/64 bit integer types).
+ * The recomputed argument is checked against TYPE_MAX and an event is logged on overflow and the triggering process is killed.
+ *
+ * Usage:
+ * $ make
+ * $ make run
+ */
+
+#include "gcc-common.h"
+#include "size_overflow.h"
+
+static void search_size_overflow_attribute(struct pointer_set_t *visited, tree lhs);
+static enum mark search_intentional(struct pointer_set_t *visited, const_tree lhs);
+
+// data for the size_overflow asm stmt
+struct asm_data {
+	gimple def_stmt;
+	tree input;
+	tree output;
+};
+
+#if BUILDING_GCC_VERSION <= 4007
+static VEC(tree, gc) *create_asm_io_list(tree string, tree io)
+#else
+static vec<tree, va_gc> *create_asm_io_list(tree string, tree io)
+#endif
+{
+	tree list;
+#if BUILDING_GCC_VERSION <= 4007
+	VEC(tree, gc) *vec_list = NULL;
+#else
+	vec<tree, va_gc> *vec_list = NULL;
+#endif
+
+	list = build_tree_list(NULL_TREE, string);
+	list = chainon(NULL_TREE, build_tree_list(list, io));
+#if BUILDING_GCC_VERSION <= 4007
+	VEC_safe_push(tree, gc, vec_list, list);
+#else
+	vec_safe_push(vec_list, list);
+#endif
+	return vec_list;
+}
+
+static void create_asm_stmt(const char *str, tree str_input, tree str_output, struct asm_data *asm_data)
+{
+	gimple asm_stmt;
+	gimple_stmt_iterator gsi;
+#if BUILDING_GCC_VERSION <= 4007
+	VEC(tree, gc) *input, *output = NULL;
+#else
+	vec<tree, va_gc> *input, *output = NULL;
+#endif
+
+	input = create_asm_io_list(str_input, asm_data->input);
+
+	if (asm_data->output)
+		output = create_asm_io_list(str_output, asm_data->output);
+
+	asm_stmt = gimple_build_asm_vec(str, input, output, NULL, NULL);
+	gsi = gsi_for_stmt(asm_data->def_stmt);
+	gsi_insert_after(&gsi, asm_stmt, GSI_NEW_STMT);
+
+	if (asm_data->output)
+		SSA_NAME_DEF_STMT(asm_data->output) = asm_stmt;
+}
+
+static void replace_call_lhs(const struct asm_data *asm_data)
+{
+	gimple_set_lhs(asm_data->def_stmt, asm_data->input);
+	update_stmt(asm_data->def_stmt);
+	SSA_NAME_DEF_STMT(asm_data->input) = asm_data->def_stmt;
+}
+
+static enum mark search_intentional_phi(struct pointer_set_t *visited, const_tree result)
+{
+	enum mark cur_fndecl_attr;
+	gimple phi = get_def_stmt(result);
+	unsigned int i, n = gimple_phi_num_args(phi);
+
+	pointer_set_insert(visited, phi);
+	for (i = 0; i < n; i++) {
+		tree arg = gimple_phi_arg_def(phi, i);
+
+		cur_fndecl_attr = search_intentional(visited, arg);
+		if (cur_fndecl_attr != MARK_NO)
+			return cur_fndecl_attr;
+	}
+	return MARK_NO;
+}
+
+static enum mark search_intentional_binary(struct pointer_set_t *visited, const_tree lhs)
+{
+	enum mark cur_fndecl_attr;
+	const_tree rhs1, rhs2;
+	gimple def_stmt = get_def_stmt(lhs);
+
+	rhs1 = gimple_assign_rhs1(def_stmt);
+	rhs2 = gimple_assign_rhs2(def_stmt);
+
+	cur_fndecl_attr = search_intentional(visited, rhs1);
+	if (cur_fndecl_attr != MARK_NO)
+		return cur_fndecl_attr;
+	return search_intentional(visited, rhs2);
+}
+
+// Look up the intentional_overflow attribute on the caller and the callee functions.
+static enum mark search_intentional(struct pointer_set_t *visited, const_tree lhs)
+{
+	const_gimple def_stmt;
+
+	if (TREE_CODE(lhs) != SSA_NAME)
+		return get_intentional_attr_type(lhs);
+
+	def_stmt = get_def_stmt(lhs);
+	if (!def_stmt)
+		return MARK_NO;
+
+	if (pointer_set_contains(visited, def_stmt))
+		return MARK_NO;
+
+	switch (gimple_code(def_stmt)) {
+	case GIMPLE_NOP:
+		return search_intentional(visited, SSA_NAME_VAR(lhs));
+	case GIMPLE_ASM:
+		if (is_size_overflow_intentional_asm_turn_off(def_stmt))
+			return MARK_TURN_OFF;
+		return MARK_NO;
+	case GIMPLE_CALL:
+		return MARK_NO;
+	case GIMPLE_PHI:
+		return search_intentional_phi(visited, lhs);
+	case GIMPLE_ASSIGN:
+		switch (gimple_num_ops(def_stmt)) {
+		case 2:
+			return search_intentional(visited, gimple_assign_rhs1(def_stmt));
+		case 3:
+			return search_intentional_binary(visited, lhs);
+		}
+	case GIMPLE_RETURN:
+		return MARK_NO;
+	default:
+		debug_gimple_stmt((gimple)def_stmt);
+		error("%s: unknown gimple code", __func__);
+		gcc_unreachable();
+	}
+}
+
+// Check the intentional_overflow attribute and create the asm comment string for the size_overflow asm stmt.
+static enum mark check_intentional_attribute_gimple(const_tree arg, const_gimple stmt, unsigned int argnum)
+{
+	const_tree fndecl;
+	struct pointer_set_t *visited;
+	enum mark cur_fndecl_attr, decl_attr = MARK_NO;
+
+	fndecl = get_interesting_orig_fndecl(stmt, argnum);
+	if (is_end_intentional_intentional_attr(fndecl, argnum))
+		decl_attr = MARK_NOT_INTENTIONAL;
+	else if (is_yes_intentional_attr(fndecl, argnum))
+		decl_attr = MARK_YES;
+	else if (is_turn_off_intentional_attr(fndecl) || is_turn_off_intentional_attr(DECL_ORIGIN(current_function_decl))) {
+		return MARK_TURN_OFF;
+	}
+
+	visited = pointer_set_create();
+	cur_fndecl_attr = search_intentional(visited, arg);
+	pointer_set_destroy(visited);
+
+	switch (cur_fndecl_attr) {
+	case MARK_NO:
+	case MARK_TURN_OFF:
+		return cur_fndecl_attr;
+	default:
+		print_missing_intentional(decl_attr, cur_fndecl_attr, fndecl, argnum);
+		return MARK_YES;
+	}
+}
+
+static void check_missing_size_overflow_attribute(tree var)
+{
+	tree orig_fndecl;
+	unsigned int num;
+
+	if (is_a_return_check(var))
+		orig_fndecl = DECL_ORIGIN(var);
+	else
+		orig_fndecl = DECL_ORIGIN(current_function_decl);
+
+	num = get_function_num(var, orig_fndecl);
+	if (num == CANNOT_FIND_ARG)
+		return;
+
+	is_missing_function(orig_fndecl, num);
+}
+
+static void search_size_overflow_attribute_phi(struct pointer_set_t *visited, const_tree result)
+{
+	gimple phi = get_def_stmt(result);
+	unsigned int i, n = gimple_phi_num_args(phi);
+
+	pointer_set_insert(visited, phi);
+	for (i = 0; i < n; i++) {
+		tree arg = gimple_phi_arg_def(phi, i);
+
+		search_size_overflow_attribute(visited, arg);
+	}
+}
+
+static void search_size_overflow_attribute_binary(struct pointer_set_t *visited, const_tree lhs)
+{
+	const_gimple def_stmt = get_def_stmt(lhs);
+	tree rhs1, rhs2;
+
+	rhs1 = gimple_assign_rhs1(def_stmt);
+	rhs2 = gimple_assign_rhs2(def_stmt);
+
+	search_size_overflow_attribute(visited, rhs1);
+	search_size_overflow_attribute(visited, rhs2);
+}
+
+static void search_size_overflow_attribute(struct pointer_set_t *visited, tree lhs)
+{
+	const_gimple def_stmt;
+
+	if (TREE_CODE(lhs) == PARM_DECL) {
+		check_missing_size_overflow_attribute(lhs);
+		return;
+	}
+
+	def_stmt = get_def_stmt(lhs);
+	if (!def_stmt)
+		return;
+
+	if (pointer_set_insert(visited, def_stmt))
+		return;
+
+	switch (gimple_code(def_stmt)) {
+	case GIMPLE_NOP:
+		return search_size_overflow_attribute(visited, SSA_NAME_VAR(lhs));
+	case GIMPLE_ASM:
+		return;
+	case GIMPLE_CALL: {
+		tree fndecl = gimple_call_fndecl(def_stmt);
+
+		if (fndecl == NULL_TREE)
+			return;
+		check_missing_size_overflow_attribute(fndecl);
+		return;
+	}
+	case GIMPLE_PHI:
+		return search_size_overflow_attribute_phi(visited, lhs);
+	case GIMPLE_ASSIGN:
+		switch (gimple_num_ops(def_stmt)) {
+		case 2:
+			return search_size_overflow_attribute(visited, gimple_assign_rhs1(def_stmt));
+		case 3:
+			return search_size_overflow_attribute_binary(visited, lhs);
+		}
+	default:
+		debug_gimple_stmt((gimple)def_stmt);
+		error("%s: unknown gimple code", __func__);
+		gcc_unreachable();
+	}
+}
+
+// Search missing entries in the hash table (invoked from the gimple pass)
+static void search_missing_size_overflow_attribute_gimple(const_gimple stmt, unsigned int num)
+{
+	tree fndecl = NULL_TREE;
+	tree lhs;
+	struct pointer_set_t *visited;
+
+	if (is_turn_off_intentional_attr(DECL_ORIGIN(current_function_decl)))
+		return;
+
+	if (num == 0) {
+		gcc_assert(gimple_code(stmt) == GIMPLE_RETURN);
+		lhs = gimple_return_retval(stmt);
+	} else {
+		gcc_assert(is_gimple_call(stmt));
+		lhs = gimple_call_arg(stmt, num - 1);
+		fndecl = gimple_call_fndecl(stmt);
+	}
+
+	if (fndecl != NULL_TREE && is_turn_off_intentional_attr(DECL_ORIGIN(fndecl)))
+		return;
+
+	visited = pointer_set_create();
+	search_size_overflow_attribute(visited, lhs);
+	pointer_set_destroy(visited);
+}
+
+static void create_output_from_phi(gimple stmt, unsigned int argnum, struct asm_data *asm_data)
+{
+	gimple_stmt_iterator gsi;
+	gimple assign;
+
+	assign = gimple_build_assign(asm_data->input, asm_data->output);
+	gsi = gsi_for_stmt(stmt);
+	gsi_insert_before(&gsi, assign, GSI_NEW_STMT);
+	asm_data->def_stmt = assign;
+
+	asm_data->output = create_new_var(TREE_TYPE(asm_data->output));
+	asm_data->output = make_ssa_name(asm_data->output, stmt);
+	if (gimple_code(stmt) == GIMPLE_RETURN)
+		gimple_return_set_retval(stmt, asm_data->output);
+	else
+		gimple_call_set_arg(stmt, argnum - 1, asm_data->output);
+	update_stmt(stmt);
+}
+
+static char *create_asm_comment(unsigned int argnum, const_gimple stmt , const char *mark_str)
+{
+	const char *fn_name;
+	char *asm_comment;
+	unsigned int len;
+
+	if (argnum == 0)
+		fn_name = DECL_NAME_POINTER(current_function_decl);
+	else
+		fn_name = DECL_NAME_POINTER(gimple_call_fndecl(stmt));
+
+	len = asprintf(&asm_comment, "%s %s %u", mark_str, fn_name, argnum);
+	gcc_assert(len > 0);
+
+	return asm_comment;
+}
+
+static const char *convert_mark_to_str(enum mark mark)
+{
+	switch (mark) {
+	case MARK_NO:
+		return OK_ASM_STR;
+	case MARK_YES:
+	case MARK_NOT_INTENTIONAL:
+		return YES_ASM_STR;
+	case MARK_TURN_OFF:
+		return TURN_OFF_ASM_STR;
+	}
+
+	gcc_unreachable();
+}
+
+/* Create the input of the size_overflow asm stmt.
+ * When the arg of the callee function is a parm_decl it creates this kind of size_overflow asm stmt:
+ *   __asm__("# size_overflow MARK_YES" :  : "rm" size_1(D));
+ * The input field in asm_data will be empty if there is no need for further size_overflow asm stmt insertion.
+ * otherwise create the input (for a phi stmt the output too) of the asm stmt.
+ */
+static void create_asm_input(gimple stmt, unsigned int argnum, struct asm_data *asm_data)
+{
+	if (!asm_data->def_stmt) {
+		asm_data->input = NULL_TREE;
+		return;
+	}
+
+	asm_data->input = create_new_var(TREE_TYPE(asm_data->output));
+	asm_data->input = make_ssa_name(asm_data->input, asm_data->def_stmt);
+
+	switch (gimple_code(asm_data->def_stmt)) {
+	case GIMPLE_ASSIGN:
+	case GIMPLE_CALL:
+		replace_call_lhs(asm_data);
+		break;
+	case GIMPLE_PHI:
+		create_output_from_phi(stmt, argnum, asm_data);
+		break;
+	case GIMPLE_NOP: {
+		enum mark mark;
+		const char *mark_str;
+		char *asm_comment;
+
+		mark = check_intentional_attribute_gimple(asm_data->output, stmt, argnum);
+
+		asm_data->input = asm_data->output;
+		asm_data->output = NULL;
+		asm_data->def_stmt = stmt;
+
+		mark_str = convert_mark_to_str(mark);
+		asm_comment = create_asm_comment(argnum, stmt, mark_str);
+
+		create_asm_stmt(asm_comment, build_string(3, "rm"), NULL, asm_data);
+		free(asm_comment);
+		asm_data->input = NULL_TREE;
+		break;
+	}
+	case GIMPLE_ASM:
+		if (is_size_overflow_asm(asm_data->def_stmt)) {
+			asm_data->input = NULL_TREE;
+			break;
+		}
+	default:
+		debug_gimple_stmt(asm_data->def_stmt);
+		gcc_unreachable();
+	}
+}
+
+/* This is the gimple part of searching for a missing size_overflow attribute. If the intentional_overflow attribute type
+ * is of the right kind create the appropriate size_overflow asm stmts:
+ *   __asm__("# size_overflow" : =rm" D.3344_8 : "0" cicus.4_16);
+ *   __asm__("# size_overflow MARK_YES" :  : "rm" size_1(D));
+ */
+static void create_size_overflow_asm(gimple stmt, tree output_node, unsigned int argnum)
+{
+	struct asm_data asm_data;
+	const char *mark_str;
+	char *asm_comment;
+	enum mark mark;
+
+	if (is_gimple_constant(output_node))
+		return;
+
+	asm_data.output = output_node;
+	mark = check_intentional_attribute_gimple(asm_data.output, stmt, argnum);
+	if (mark != MARK_TURN_OFF)
+		search_missing_size_overflow_attribute_gimple(stmt, argnum);
+
+	asm_data.def_stmt = get_def_stmt(asm_data.output);
+	if (is_size_overflow_intentional_asm_turn_off(asm_data.def_stmt))
+		return;
+
+	create_asm_input(stmt, argnum, &asm_data);
+	if (asm_data.input == NULL_TREE)
+		return;
+
+	mark_str = convert_mark_to_str(mark);
+	asm_comment = create_asm_comment(argnum, stmt, mark_str);
+	create_asm_stmt(asm_comment, build_string(2, "0"), build_string(4, "=rm"), &asm_data);
+	free(asm_comment);
+}
+
+// Insert an asm stmt with "MARK_TURN_OFF", "MARK_YES" or "MARK_NOT_INTENTIONAL".
+static bool create_mark_asm(gimple stmt, enum mark mark)
+{
+	struct asm_data asm_data;
+	const char *asm_str;
+
+	switch (mark) {
+	case MARK_TURN_OFF:
+		asm_str = TURN_OFF_ASM_STR;
+		break;
+	case MARK_NOT_INTENTIONAL:
+	case MARK_YES:
+		asm_str = YES_ASM_STR;
+		break;
+	default:
+		gcc_unreachable();
+	}
+
+	asm_data.def_stmt = stmt;
+	asm_data.output = gimple_call_lhs(stmt);
+
+	if (asm_data.output == NULL_TREE) {
+		asm_data.input = gimple_call_arg(stmt, 0);
+		if (is_gimple_constant(asm_data.input))
+			return false;
+		asm_data.output = NULL;
+		create_asm_stmt(asm_str, build_string(3, "rm"), NULL, &asm_data);
+		return true;
+	}
+
+	create_asm_input(stmt, 0, &asm_data);
+	gcc_assert(asm_data.input != NULL_TREE);
+
+	create_asm_stmt(asm_str, build_string(2, "0"), build_string(4, "=rm"), &asm_data);
+	return true;
+}
+
+static void walk_use_def_ptr(struct pointer_set_t *visited, const_tree lhs)
+{
+	gimple def_stmt;
+
+	def_stmt = get_def_stmt(lhs);
+	if (!def_stmt)
+		return;
+
+	if (pointer_set_insert(visited, def_stmt))
+		return;
+
+	switch (gimple_code(def_stmt)) {
+	case GIMPLE_NOP:
+	case GIMPLE_ASM:
+	case GIMPLE_CALL:
+		break;
+	case GIMPLE_PHI: {
+		unsigned int i, n = gimple_phi_num_args(def_stmt);
+
+		pointer_set_insert(visited, def_stmt);
+
+		for (i = 0; i < n; i++) {
+			tree arg = gimple_phi_arg_def(def_stmt, i);
+
+			walk_use_def_ptr(visited, arg);
+		}
+	}
+	case GIMPLE_ASSIGN:
+		switch (gimple_num_ops(def_stmt)) {
+		case 2:
+			walk_use_def_ptr(visited, gimple_assign_rhs1(def_stmt));
+			return;
+		case 3:
+			walk_use_def_ptr(visited, gimple_assign_rhs1(def_stmt));
+			walk_use_def_ptr(visited, gimple_assign_rhs2(def_stmt));
+			return;
+		default:
+			return;
+		}
+	default:
+		debug_gimple_stmt((gimple)def_stmt);
+		error("%s: unknown gimple code", __func__);
+		gcc_unreachable();
+	}
+}
+
+// Look for a ptr - ptr expression (e.g., cpuset_common_file_read() s - page)
+static void insert_mark_not_intentional_asm_at_ptr(const_tree arg)
+{
+	struct pointer_set_t *visited;
+
+	visited = pointer_set_create();
+	walk_use_def_ptr(visited, arg);
+	pointer_set_destroy(visited);
+}
+
+// Determine the return value and insert the asm stmt to mark the return stmt.
+static void insert_asm_ret(gimple stmt)
+{
+	tree ret;
+
+	ret = gimple_return_retval(stmt);
+	create_size_overflow_asm(stmt, ret, 0);
+}
+
+// Determine the correct arg index and arg and insert the asm stmt to mark the stmt.
+static void insert_asm_arg(gimple stmt, unsigned int orig_argnum)
+{
+	tree arg;
+	unsigned int argnum;
+
+	argnum = get_correct_arg_count(orig_argnum, gimple_call_fndecl(stmt));
+	gcc_assert(argnum != 0);
+	if (argnum == CANNOT_FIND_ARG)
+		return;
+
+	arg = gimple_call_arg(stmt, argnum - 1);
+	gcc_assert(arg != NULL_TREE);
+
+	// skip all ptr - ptr expressions
+	insert_mark_not_intentional_asm_at_ptr(arg);
+
+	create_size_overflow_asm(stmt, arg, argnum);
+}
+
+// If a function arg or the return value is marked by the size_overflow attribute then set its index in the array.
+static void set_argnum_attribute(const_tree attr, bool *argnums)
+{
+	unsigned int argnum;
+	tree attr_value;
+
+	for (attr_value = TREE_VALUE(attr); attr_value; attr_value = TREE_CHAIN(attr_value)) {
+		argnum = TREE_INT_CST_LOW(TREE_VALUE(attr_value));
+		argnums[argnum] = true;
+	}
+}
+
+// If a function arg or the return value is in the hash table then set its index in the array.
+static void set_argnum_hash(tree fndecl, bool *argnums)
+{
+	unsigned int num;
+	const struct size_overflow_hash *hash;
+
+	hash = get_function_hash(DECL_ORIGIN(fndecl));
+	if (!hash)
+		return;
+
+	for (num = 0; num <= MAX_PARAM; num++) {
+		if (!(hash->param & (1U << num)))
+			continue;
+
+		argnums[num] = true;
+	}
+}
+
+static bool is_all_the_argnums_empty(bool *argnums)
+{
+	unsigned int i;
+
+	for (i = 0; i <= MAX_PARAM; i++)
+		if (argnums[i])
+			return false;
+	return true;
+}
+
+// Check whether the arguments or the return value of the function are in the hash table or are marked by the size_overflow attribute.
+static void search_interesting_args(tree fndecl, bool *argnums)
+{
+	const_tree attr;
+
+	set_argnum_hash(fndecl, argnums);
+	if (!is_all_the_argnums_empty(argnums))
+		return;
+
+	attr = lookup_attribute("size_overflow", DECL_ATTRIBUTES(fndecl));
+	if (attr && TREE_VALUE(attr))
+		set_argnum_attribute(attr, argnums);
+}
+
+/*
+ * Look up the intentional_overflow attribute that turns off ipa based duplication
+ * on the callee function.
+ */
+static bool is_mark_turn_off_attribute(gimple stmt)
+{
+	enum mark mark;
+	const_tree fndecl = gimple_call_fndecl(stmt);
+
+	mark = get_intentional_attr_type(DECL_ORIGIN(fndecl));
+	if (mark == MARK_TURN_OFF)
+		return true;
+	return false;
+}
+
+// If the argument(s) of the callee function is/are in the hash table or are marked by an attribute then mark the call stmt with an asm stmt
+static void handle_interesting_function(gimple stmt)
+{
+	unsigned int argnum;
+	tree fndecl;
+	bool orig_argnums[MAX_PARAM + 1] = {false};
+
+	if (gimple_call_num_args(stmt) == 0)
+		return;
+	fndecl = gimple_call_fndecl(stmt);
+	if (fndecl == NULL_TREE)
+		return;
+	fndecl = DECL_ORIGIN(fndecl);
+
+	if (is_mark_turn_off_attribute(stmt)) {
+		create_mark_asm(stmt, MARK_TURN_OFF);
+		return;
+	}
+
+	search_interesting_args(fndecl, orig_argnums);
+
+	for (argnum = 1; argnum < MAX_PARAM; argnum++)
+		if (orig_argnums[argnum])
+			insert_asm_arg(stmt, argnum);
+}
+
+// If the return value of the caller function is in hash table (its index is 0) then mark the return stmt with an asm stmt
+static void handle_interesting_ret(gimple stmt)
+{
+	bool orig_argnums[MAX_PARAM + 1] = {false};
+
+	search_interesting_args(current_function_decl, orig_argnums);
+
+	if (orig_argnums[0])
+		insert_asm_ret(stmt);
+}
+
+// Iterate over all the stmts and search for call and return stmts and mark them if they're in the hash table
+static unsigned int search_interesting_functions(void)
+{
+	basic_block bb;
+
+	FOR_ALL_BB_FN(bb, cfun) {
+		gimple_stmt_iterator gsi;
+
+		for (gsi = gsi_start_bb(bb); !gsi_end_p(gsi); gsi_next(&gsi)) {
+			gimple stmt = gsi_stmt(gsi);
+
+			if (is_size_overflow_asm(stmt))
+				continue;
+
+			if (is_gimple_call(stmt))
+				handle_interesting_function(stmt);
+			else if (gimple_code(stmt) == GIMPLE_RETURN)
+				handle_interesting_ret(stmt);
+		}
+	}
+	return 0;
+}
+
+/*
+ * A lot of functions get inlined before the ipa passes so after the build_ssa gimple pass
+ * this pass inserts asm stmts to mark the interesting args
+ * that the ipa pass will detect and insert the size overflow checks for.
+ */
+#if BUILDING_GCC_VERSION >= 4009
+static const struct pass_data insert_size_overflow_asm_pass_data = {
+#else
+static struct gimple_opt_pass insert_size_overflow_asm_pass = {
+	.pass = {
+#endif
+		.type			= GIMPLE_PASS,
+		.name			= "insert_size_overflow_asm",
+#if BUILDING_GCC_VERSION >= 4008
+		.optinfo_flags		= OPTGROUP_NONE,
+#endif
+#if BUILDING_GCC_VERSION >= 4009
+		.has_gate		= false,
+		.has_execute		= true,
+#else
+		.gate			= NULL,
+		.execute		= search_interesting_functions,
+		.sub			= NULL,
+		.next			= NULL,
+		.static_pass_number	= 0,
+#endif
+		.tv_id			= TV_NONE,
+		.properties_required	= PROP_cfg,
+		.properties_provided	= 0,
+		.properties_destroyed	= 0,
+		.todo_flags_start	= 0,
+		.todo_flags_finish	= TODO_dump_func | TODO_verify_ssa | TODO_verify_stmts | TODO_remove_unused_locals | TODO_update_ssa_no_phi | TODO_cleanup_cfg | TODO_ggc_collect | TODO_verify_flow
+#if BUILDING_GCC_VERSION < 4009
+	}
+#endif
+};
+
+#if BUILDING_GCC_VERSION >= 4009
+namespace {
+class insert_size_overflow_asm_pass : public gimple_opt_pass {
+public:
+	insert_size_overflow_asm_pass() : gimple_opt_pass(insert_size_overflow_asm_pass_data, g) {}
+	unsigned int execute() { return search_interesting_functions(); }
+};
+}
+#endif
+
+struct opt_pass *make_insert_size_overflow_asm_pass(void)
+{
+#if BUILDING_GCC_VERSION >= 4009
+	return new insert_size_overflow_asm_pass();
+#else
+	return &insert_size_overflow_asm_pass.pass;
+#endif
+}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/insert_size_overflow_check_core.c linux-3.2.71-pax/tools/gcc/size_overflow_plugin/insert_size_overflow_check_core.c
--- linux-3.2.71/tools/gcc/size_overflow_plugin/insert_size_overflow_check_core.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/insert_size_overflow_check_core.c	2014-07-27 23:41:39.589093822 +0200
@@ -0,0 +1,943 @@
+/*
+ * Copyright 2011-2014 by Emese Revfy <re.emese@gmail.com>
+ * Licensed under the GPL v2, or (at your option) v3
+ *
+ * Homepage:
+ * http://www.grsecurity.net/~ephox/overflow_plugin/
+ *
+ * Documentation:
+ * http://forums.grsecurity.net/viewtopic.php?f=7&t=3043
+ *
+ * This plugin recomputes expressions of function arguments marked by a size_overflow attribute
+ * with double integer precision (DImode/TImode for 32/64 bit integer types).
+ * The recomputed argument is checked against TYPE_MAX and an event is logged on overflow and the triggering process is killed.
+ *
+ * Usage:
+ * $ make
+ * $ make run
+ */
+
+#include "gcc-common.h"
+#include "size_overflow.h"
+
+#define MIN_CHECK true
+#define MAX_CHECK false
+
+static tree get_size_overflow_type(struct visited *visited, const_gimple stmt, const_tree node)
+{
+	const_tree type;
+	tree new_type;
+
+	gcc_assert(node != NULL_TREE);
+
+	type = TREE_TYPE(node);
+
+	if (pointer_set_contains(visited->my_stmts, stmt))
+		return TREE_TYPE(node);
+
+	switch (TYPE_MODE(type)) {
+	case QImode:
+		new_type = size_overflow_type_HI;
+		break;
+	case HImode:
+		new_type = size_overflow_type_SI;
+		break;
+	case SImode:
+		new_type = size_overflow_type_DI;
+		break;
+	case DImode:
+		if (LONG_TYPE_SIZE == GET_MODE_BITSIZE(SImode))
+			new_type = TYPE_UNSIGNED(type) ? unsigned_intDI_type_node : intDI_type_node;
+		else
+			new_type = size_overflow_type_TI;
+		break;
+	case TImode:
+		gcc_assert(!TYPE_UNSIGNED(type));
+		new_type = size_overflow_type_TI;
+		break;
+	default:
+		debug_tree((tree)node);
+		error("%s: unsupported gcc configuration (%qE).", __func__, current_function_decl);
+		gcc_unreachable();
+	}
+
+	if (TYPE_QUALS(type) != 0)
+		return build_qualified_type(new_type, TYPE_QUALS(type));
+	return new_type;
+}
+
+static tree get_lhs(const_gimple stmt)
+{
+	switch (gimple_code(stmt)) {
+	case GIMPLE_ASSIGN:
+	case GIMPLE_CALL:
+		return gimple_get_lhs(stmt);
+	case GIMPLE_PHI:
+		return gimple_phi_result(stmt);
+	default:
+		return NULL_TREE;
+	}
+}
+
+static tree cast_to_new_size_overflow_type(struct visited *visited, gimple stmt, tree rhs, tree size_overflow_type, bool before)
+{
+	gimple_stmt_iterator gsi;
+	tree lhs;
+	gimple new_stmt;
+
+	if (rhs == NULL_TREE)
+		return NULL_TREE;
+
+	gsi = gsi_for_stmt(stmt);
+	new_stmt = build_cast_stmt(visited, size_overflow_type, rhs, CREATE_NEW_VAR, &gsi, before, false);
+	pointer_set_insert(visited->my_stmts, new_stmt);
+
+	lhs = get_lhs(new_stmt);
+	gcc_assert(lhs != NULL_TREE);
+	return lhs;
+}
+
+tree create_assign(struct visited *visited, gimple oldstmt, tree rhs1, bool before)
+{
+	tree lhs, dst_type;
+	gimple_stmt_iterator gsi;
+
+	if (rhs1 == NULL_TREE) {
+		debug_gimple_stmt(oldstmt);
+		error("%s: rhs1 is NULL_TREE", __func__);
+		gcc_unreachable();
+	}
+
+	switch (gimple_code(oldstmt)) {
+	case GIMPLE_ASM:
+		lhs = rhs1;
+		break;
+	case GIMPLE_CALL:
+	case GIMPLE_ASSIGN:
+		lhs = gimple_get_lhs(oldstmt);
+		break;
+	default:
+		debug_gimple_stmt(oldstmt);
+		gcc_unreachable();
+	}
+
+	gsi = gsi_for_stmt(oldstmt);
+	pointer_set_insert(visited->stmts, oldstmt);
+	if (lookup_stmt_eh_lp(oldstmt) != 0) {
+		basic_block next_bb, cur_bb;
+		const_edge e;
+
+		gcc_assert(before == false);
+		gcc_assert(stmt_can_throw_internal(oldstmt));
+		gcc_assert(gimple_code(oldstmt) == GIMPLE_CALL);
+		gcc_assert(!gsi_end_p(gsi));
+
+		cur_bb = gimple_bb(oldstmt);
+		next_bb = cur_bb->next_bb;
+		e = find_edge(cur_bb, next_bb);
+		gcc_assert(e != NULL);
+		gcc_assert(e->flags & EDGE_FALLTHRU);
+
+		gsi = gsi_after_labels(next_bb);
+		gcc_assert(!gsi_end_p(gsi));
+
+		before = true;
+		oldstmt = gsi_stmt(gsi);
+	}
+
+	dst_type = get_size_overflow_type(visited, oldstmt, lhs);
+
+	if (is_gimple_constant(rhs1))
+		return cast_a_tree(dst_type, rhs1);
+	return cast_to_new_size_overflow_type(visited, oldstmt, rhs1, dst_type, before);
+}
+
+tree dup_assign(struct visited *visited, gimple oldstmt, const_tree node, tree rhs1, tree rhs2, tree __unused rhs3)
+{
+	gimple stmt;
+	gimple_stmt_iterator gsi;
+	tree size_overflow_type, new_var, lhs = gimple_assign_lhs(oldstmt);
+
+	if (pointer_set_contains(visited->my_stmts, oldstmt))
+		return lhs;
+
+	if (gimple_num_ops(oldstmt) != 4 && rhs1 == NULL_TREE) {
+		rhs1 = gimple_assign_rhs1(oldstmt);
+		rhs1 = create_assign(visited, oldstmt, rhs1, BEFORE_STMT);
+	}
+	if (gimple_num_ops(oldstmt) == 3 && rhs2 == NULL_TREE) {
+		rhs2 = gimple_assign_rhs2(oldstmt);
+		rhs2 = create_assign(visited, oldstmt, rhs2, BEFORE_STMT);
+	}
+
+	stmt = gimple_copy(oldstmt);
+	gimple_set_location(stmt, gimple_location(oldstmt));
+	pointer_set_insert(visited->my_stmts, stmt);
+
+	if (gimple_assign_rhs_code(oldstmt) == WIDEN_MULT_EXPR)
+		gimple_assign_set_rhs_code(stmt, MULT_EXPR);
+
+	size_overflow_type = get_size_overflow_type(visited, oldstmt, node);
+
+	new_var = create_new_var(size_overflow_type);
+	new_var = make_ssa_name(new_var, stmt);
+	gimple_assign_set_lhs(stmt, new_var);
+
+	if (rhs1 != NULL_TREE)
+		gimple_assign_set_rhs1(stmt, rhs1);
+
+	if (rhs2 != NULL_TREE)
+		gimple_assign_set_rhs2(stmt, rhs2);
+#if BUILDING_GCC_VERSION >= 4006
+	if (rhs3 != NULL_TREE)
+		gimple_assign_set_rhs3(stmt, rhs3);
+#endif
+	gimple_set_vuse(stmt, gimple_vuse(oldstmt));
+	gimple_set_vdef(stmt, gimple_vdef(oldstmt));
+
+	gsi = gsi_for_stmt(oldstmt);
+	gsi_insert_after(&gsi, stmt, GSI_SAME_STMT);
+	update_stmt(stmt);
+	pointer_set_insert(visited->stmts, oldstmt);
+	return gimple_assign_lhs(stmt);
+}
+
+static tree cast_parm_decl(struct visited *visited, tree phi_ssa_name, tree arg, tree size_overflow_type, basic_block bb)
+{
+	gimple assign;
+	gimple_stmt_iterator gsi;
+	basic_block first_bb;
+
+	gcc_assert(SSA_NAME_IS_DEFAULT_DEF(arg));
+
+	if (bb->index == 0) {
+		first_bb = split_block_after_labels(ENTRY_BLOCK_PTR_FOR_FN(cfun))->dest;
+		gcc_assert(dom_info_available_p(CDI_DOMINATORS));
+		set_immediate_dominator(CDI_DOMINATORS, first_bb, ENTRY_BLOCK_PTR_FOR_FN(cfun));
+		bb = first_bb;
+	}
+
+	gsi = gsi_after_labels(bb);
+	assign = build_cast_stmt(visited, size_overflow_type, arg, phi_ssa_name, &gsi, BEFORE_STMT, false);
+	pointer_set_insert(visited->my_stmts, assign);
+
+	return gimple_assign_lhs(assign);
+}
+
+static tree use_phi_ssa_name(struct visited *visited, tree ssa_name_var, tree new_arg)
+{
+	gimple_stmt_iterator gsi;
+	gimple assign, def_stmt = get_def_stmt(new_arg);
+
+	if (gimple_code(def_stmt) == GIMPLE_PHI) {
+		gsi = gsi_after_labels(gimple_bb(def_stmt));
+		assign = build_cast_stmt(visited, TREE_TYPE(new_arg), new_arg, ssa_name_var, &gsi, BEFORE_STMT, true);
+	} else {
+		gsi = gsi_for_stmt(def_stmt);
+		assign = build_cast_stmt(visited, TREE_TYPE(new_arg), new_arg, ssa_name_var, &gsi, AFTER_STMT, true);
+	}
+
+	pointer_set_insert(visited->my_stmts, assign);
+	return gimple_assign_lhs(assign);
+}
+
+static tree cast_visited_phi_arg(struct visited *visited, tree ssa_name_var, tree arg, tree size_overflow_type)
+{
+	basic_block bb;
+	gimple_stmt_iterator gsi;
+	const_gimple def_stmt;
+	gimple assign;
+
+	def_stmt = get_def_stmt(arg);
+	bb = gimple_bb(def_stmt);
+	gcc_assert(bb->index != 0);
+	gsi = gsi_after_labels(bb);
+
+	assign = build_cast_stmt(visited, size_overflow_type, arg, ssa_name_var, &gsi, BEFORE_STMT, false);
+	pointer_set_insert(visited->my_stmts, assign);
+	return gimple_assign_lhs(assign);
+}
+
+static tree create_new_phi_arg(struct visited *visited, tree ssa_name_var, tree new_arg, gimple oldstmt, unsigned int i)
+{
+	tree size_overflow_type;
+	tree arg;
+	const_gimple def_stmt;
+
+	if (new_arg != NULL_TREE && is_gimple_constant(new_arg))
+		return new_arg;
+
+	arg = gimple_phi_arg_def(oldstmt, i);
+	def_stmt = get_def_stmt(arg);
+	gcc_assert(def_stmt != NULL);
+	size_overflow_type = get_size_overflow_type(visited, oldstmt, arg);
+
+	switch (gimple_code(def_stmt)) {
+	case GIMPLE_PHI:
+		return cast_visited_phi_arg(visited, ssa_name_var, arg, size_overflow_type);
+	case GIMPLE_NOP: {
+		basic_block bb;
+
+		bb = gimple_phi_arg_edge(oldstmt, i)->src;
+		return cast_parm_decl(visited, ssa_name_var, arg, size_overflow_type, bb);
+	}
+	case GIMPLE_ASM: {
+		gimple_stmt_iterator gsi;
+		gimple assign, stmt = get_def_stmt(arg);
+
+		gsi = gsi_for_stmt(stmt);
+		assign = build_cast_stmt(visited, size_overflow_type, arg, ssa_name_var, &gsi, AFTER_STMT, false);
+		pointer_set_insert(visited->my_stmts, assign);
+		return gimple_assign_lhs(assign);
+	}
+	default:
+		gcc_assert(new_arg != NULL_TREE);
+		gcc_assert(types_compatible_p(TREE_TYPE(new_arg), size_overflow_type));
+		return use_phi_ssa_name(visited, ssa_name_var, new_arg);
+	}
+}
+
+static gimple overflow_create_phi_node(struct visited *visited, gimple oldstmt, tree result)
+{
+	basic_block bb;
+	gimple phi;
+	gimple_seq seq;
+	gimple_stmt_iterator gsi = gsi_for_stmt(oldstmt);
+
+	bb = gsi_bb(gsi);
+
+	if (result == NULL_TREE) {
+		tree old_result = gimple_phi_result(oldstmt);
+		tree size_overflow_type = get_size_overflow_type(visited, oldstmt, old_result);
+
+		result = create_new_var(size_overflow_type);
+	}
+
+	phi = create_phi_node(result, bb);
+	gimple_phi_set_result(phi, make_ssa_name(result, phi));
+	seq = phi_nodes(bb);
+	gsi = gsi_last(seq);
+	gsi_remove(&gsi, false);
+
+	gsi = gsi_for_stmt(oldstmt);
+	gsi_insert_after(&gsi, phi, GSI_NEW_STMT);
+	gimple_set_bb(phi, bb);
+	return phi;
+}
+
+#if BUILDING_GCC_VERSION <= 4007
+static tree create_new_phi_node(struct visited *visited, VEC(tree, heap) **args, tree ssa_name_var, gimple oldstmt)
+#else
+static tree create_new_phi_node(struct visited *visited, vec<tree, va_heap, vl_embed> *&args, tree ssa_name_var, gimple oldstmt)
+#endif
+{
+	gimple new_phi;
+	unsigned int i;
+	tree arg, result;
+	location_t loc = gimple_location(oldstmt);
+
+#if BUILDING_GCC_VERSION <= 4007
+	gcc_assert(!VEC_empty(tree, *args));
+#else
+	gcc_assert(!args->is_empty());
+#endif
+
+	new_phi = overflow_create_phi_node(visited, oldstmt, ssa_name_var);
+	result = gimple_phi_result(new_phi);
+	ssa_name_var = SSA_NAME_VAR(result);
+
+#if BUILDING_GCC_VERSION <= 4007
+	FOR_EACH_VEC_ELT(tree, *args, i, arg) {
+#else
+	FOR_EACH_VEC_SAFE_ELT(args, i, arg) {
+#endif
+		arg = create_new_phi_arg(visited, ssa_name_var, arg, oldstmt, i);
+		add_phi_arg(new_phi, arg, gimple_phi_arg_edge(oldstmt, i), loc);
+	}
+
+#if BUILDING_GCC_VERSION <= 4007
+	VEC_free(tree, heap, *args);
+#else
+	vec_free(args);
+#endif
+	update_stmt(new_phi);
+	pointer_set_insert(visited->my_stmts, new_phi);
+	return result;
+}
+
+static tree handle_phi(struct visited *visited, struct cgraph_node *caller_node, tree orig_result)
+{
+	tree ssa_name_var = NULL_TREE;
+#if BUILDING_GCC_VERSION <= 4007
+	VEC(tree, heap) *args = NULL;
+#else
+	vec<tree, va_heap, vl_embed> *args = NULL;
+#endif
+	gimple oldstmt = get_def_stmt(orig_result);
+	unsigned int i, len = gimple_phi_num_args(oldstmt);
+
+	pointer_set_insert(visited->stmts, oldstmt);
+	for (i = 0; i < len; i++) {
+		tree arg, new_arg;
+
+		arg = gimple_phi_arg_def(oldstmt, i);
+		new_arg = expand(visited, caller_node, arg);
+
+		if (ssa_name_var == NULL_TREE && new_arg != NULL_TREE)
+			ssa_name_var = SSA_NAME_VAR(new_arg);
+
+		if (is_gimple_constant(arg)) {
+			tree size_overflow_type = get_size_overflow_type(visited, oldstmt, arg);
+
+			new_arg = cast_a_tree(size_overflow_type, arg);
+		}
+
+#if BUILDING_GCC_VERSION <= 4007
+		VEC_safe_push(tree, heap, args, new_arg);
+#else
+		vec_safe_push(args, new_arg);
+#endif
+	}
+
+#if BUILDING_GCC_VERSION <= 4007
+	return create_new_phi_node(visited, &args, ssa_name_var, oldstmt);
+#else
+	return create_new_phi_node(visited, args, ssa_name_var, oldstmt);
+#endif
+}
+
+static tree create_cast_assign(struct visited *visited, gimple stmt)
+{
+	tree rhs1 = gimple_assign_rhs1(stmt);
+	tree lhs = gimple_assign_lhs(stmt);
+	const_tree rhs1_type = TREE_TYPE(rhs1);
+	const_tree lhs_type = TREE_TYPE(lhs);
+
+	if (TYPE_UNSIGNED(rhs1_type) == TYPE_UNSIGNED(lhs_type))
+		return create_assign(visited, stmt, lhs, AFTER_STMT);
+
+	return create_assign(visited, stmt, rhs1, AFTER_STMT);
+}
+
+static bool skip_lhs_cast_check(const_gimple stmt)
+{
+	const_tree rhs = gimple_assign_rhs1(stmt);
+	const_gimple def_stmt = get_def_stmt(rhs);
+
+	// 3.8.2 kernel/futex_compat.c compat_exit_robust_list(): get_user() 64 ulong -> int (compat_long_t), int max
+	if (gimple_code(def_stmt) == GIMPLE_ASM)
+		return true;
+
+	if (is_const_plus_unsigned_signed_truncation(rhs))
+		return true;
+
+	return false;
+}
+
+static tree create_string_param(tree string)
+{
+	tree i_type, a_type;
+	const int length = TREE_STRING_LENGTH(string);
+
+	gcc_assert(length > 0);
+
+	i_type = build_index_type(build_int_cst(NULL_TREE, length - 1));
+	a_type = build_array_type(char_type_node, i_type);
+
+	TREE_TYPE(string) = a_type;
+	TREE_CONSTANT(string) = 1;
+	TREE_READONLY(string) = 1;
+
+	return build1(ADDR_EXPR, ptr_type_node, string);
+}
+
+static void insert_cond(basic_block cond_bb, tree arg, enum tree_code cond_code, tree type_value)
+{
+	gimple cond_stmt;
+	gimple_stmt_iterator gsi = gsi_last_bb(cond_bb);
+
+	cond_stmt = gimple_build_cond(cond_code, arg, type_value, NULL_TREE, NULL_TREE);
+	gsi_insert_after(&gsi, cond_stmt, GSI_CONTINUE_LINKING);
+	update_stmt(cond_stmt);
+}
+
+static void insert_cond_result(struct cgraph_node *caller_node, basic_block bb_true, const_gimple stmt, const_tree arg, bool min)
+{
+	gimple func_stmt;
+	const_gimple def_stmt;
+	const_tree loc_line;
+	tree loc_file, ssa_name, current_func;
+	expanded_location xloc;
+	char *ssa_name_buf;
+	int len;
+	struct cgraph_edge *edge;
+	struct cgraph_node *callee_node;
+	int frequency;
+	gimple_stmt_iterator gsi = gsi_start_bb(bb_true);
+
+	def_stmt = get_def_stmt(arg);
+	xloc = expand_location(gimple_location(def_stmt));
+
+	if (!gimple_has_location(def_stmt)) {
+		xloc = expand_location(gimple_location(stmt));
+		if (!gimple_has_location(stmt))
+			xloc = expand_location(DECL_SOURCE_LOCATION(current_function_decl));
+	}
+
+	loc_line = build_int_cstu(unsigned_type_node, xloc.line);
+
+	loc_file = build_string(strlen(xloc.file) + 1, xloc.file);
+	loc_file = create_string_param(loc_file);
+
+	current_func = build_string(DECL_NAME_LENGTH(current_function_decl) + 1, DECL_NAME_POINTER(current_function_decl));
+	current_func = create_string_param(current_func);
+
+	gcc_assert(DECL_NAME(SSA_NAME_VAR(arg)) != NULL);
+	call_count++;
+	len = asprintf(&ssa_name_buf, "%s_%u %s, count: %u\n", DECL_NAME_POINTER(SSA_NAME_VAR(arg)), SSA_NAME_VERSION(arg), min ? "min" : "max", call_count);
+	gcc_assert(len > 0);
+	ssa_name = build_string(len + 1, ssa_name_buf);
+	free(ssa_name_buf);
+	ssa_name = create_string_param(ssa_name);
+
+	// void report_size_overflow(const char *file, unsigned int line, const char *func, const char *ssa_name)
+	func_stmt = gimple_build_call(report_size_overflow_decl, 4, loc_file, loc_line, current_func, ssa_name);
+	gsi_insert_after(&gsi, func_stmt, GSI_CONTINUE_LINKING);
+
+	callee_node = cgraph_get_create_node(report_size_overflow_decl);
+	frequency = compute_call_stmt_bb_frequency(current_function_decl, bb_true);
+
+	edge = cgraph_create_edge(caller_node, callee_node, func_stmt, bb_true->count, frequency, bb_true->loop_depth);
+	gcc_assert(edge != NULL);
+}
+
+static void insert_check_size_overflow(struct cgraph_node *caller_node, gimple stmt, enum tree_code cond_code, tree arg, tree type_value, bool before, bool min)
+{
+	basic_block cond_bb, join_bb, bb_true;
+	edge e;
+	gimple_stmt_iterator gsi = gsi_for_stmt(stmt);
+
+	cond_bb = gimple_bb(stmt);
+	if (before)
+		gsi_prev(&gsi);
+	if (gsi_end_p(gsi))
+		e = split_block_after_labels(cond_bb);
+	else
+		e = split_block(cond_bb, gsi_stmt(gsi));
+	cond_bb = e->src;
+	join_bb = e->dest;
+	e->flags = EDGE_FALSE_VALUE;
+	e->probability = REG_BR_PROB_BASE;
+
+	bb_true = create_empty_bb(cond_bb);
+	make_edge(cond_bb, bb_true, EDGE_TRUE_VALUE);
+	make_edge(cond_bb, join_bb, EDGE_FALSE_VALUE);
+	make_edge(bb_true, join_bb, EDGE_FALLTHRU);
+
+	gcc_assert(dom_info_available_p(CDI_DOMINATORS));
+	set_immediate_dominator(CDI_DOMINATORS, bb_true, cond_bb);
+	set_immediate_dominator(CDI_DOMINATORS, join_bb, cond_bb);
+
+	if (current_loops != NULL) {
+		gcc_assert(cond_bb->loop_father == join_bb->loop_father);
+		add_bb_to_loop(bb_true, cond_bb->loop_father);
+	}
+
+	insert_cond(cond_bb, arg, cond_code, type_value);
+	insert_cond_result(caller_node, bb_true, stmt, arg, min);
+
+//	print_the_code_insertions(stmt);
+}
+
+void check_size_overflow(struct cgraph_node *caller_node, gimple stmt, tree size_overflow_type, tree cast_rhs, tree rhs, bool before)
+{
+	const_tree rhs_type = TREE_TYPE(rhs);
+	tree cast_rhs_type, type_max_type, type_min_type, type_max, type_min;
+
+	gcc_assert(rhs_type != NULL_TREE);
+	if (TREE_CODE(rhs_type) == POINTER_TYPE)
+		return;
+
+	gcc_assert(TREE_CODE(rhs_type) == INTEGER_TYPE || TREE_CODE(rhs_type) == ENUMERAL_TYPE);
+
+	if (is_const_plus_unsigned_signed_truncation(rhs))
+		return;
+
+	type_max = cast_a_tree(size_overflow_type, TYPE_MAX_VALUE(rhs_type));
+	// typemax (-1) < typemin (0)
+	if (TREE_OVERFLOW(type_max))
+		return;
+
+	type_min = cast_a_tree(size_overflow_type, TYPE_MIN_VALUE(rhs_type));
+
+	cast_rhs_type = TREE_TYPE(cast_rhs);
+	type_max_type = TREE_TYPE(type_max);
+	gcc_assert(types_compatible_p(cast_rhs_type, type_max_type));
+
+	insert_check_size_overflow(caller_node, stmt, GT_EXPR, cast_rhs, type_max, before, MAX_CHECK);
+
+	// special case: get_size_overflow_type(), 32, u64->s
+	if (LONG_TYPE_SIZE == GET_MODE_BITSIZE(SImode) && TYPE_UNSIGNED(size_overflow_type) && !TYPE_UNSIGNED(rhs_type))
+		return;
+
+	type_min_type = TREE_TYPE(type_min);
+	gcc_assert(types_compatible_p(type_max_type, type_min_type));
+	insert_check_size_overflow(caller_node, stmt, LT_EXPR, cast_rhs, type_min, before, MIN_CHECK);
+}
+
+static tree create_cast_overflow_check(struct visited *visited, struct cgraph_node *caller_node, tree new_rhs1, gimple stmt)
+{
+	bool cast_lhs, cast_rhs;
+	tree lhs = gimple_assign_lhs(stmt);
+	tree rhs = gimple_assign_rhs1(stmt);
+	const_tree lhs_type = TREE_TYPE(lhs);
+	const_tree rhs_type = TREE_TYPE(rhs);
+	enum machine_mode lhs_mode = TYPE_MODE(lhs_type);
+	enum machine_mode rhs_mode = TYPE_MODE(rhs_type);
+	unsigned int lhs_size = GET_MODE_BITSIZE(lhs_mode);
+	unsigned int rhs_size = GET_MODE_BITSIZE(rhs_mode);
+
+	static bool check_lhs[3][4] = {
+		// ss    su     us     uu
+		{ false, true,  true,  false }, // lhs > rhs
+		{ false, false, false, false }, // lhs = rhs
+		{ true,  true,  true,  true  }, // lhs < rhs
+	};
+
+	static bool check_rhs[3][4] = {
+		// ss    su     us     uu
+		{ true,  false, true,  true  }, // lhs > rhs
+		{ true,  false, true,  true  }, // lhs = rhs
+		{ true,  false, true,  true  }, // lhs < rhs
+	};
+
+	// skip lhs check on signed SI -> HI cast or signed SI -> QI cast !!!!
+	if (rhs_mode == SImode && !TYPE_UNSIGNED(rhs_type) && (lhs_mode == HImode || lhs_mode == QImode))
+		return create_assign(visited, stmt, lhs, AFTER_STMT);
+
+	if (lhs_size > rhs_size) {
+		cast_lhs = check_lhs[0][TYPE_UNSIGNED(rhs_type) + 2 * TYPE_UNSIGNED(lhs_type)];
+		cast_rhs = check_rhs[0][TYPE_UNSIGNED(rhs_type) + 2 * TYPE_UNSIGNED(lhs_type)];
+	} else if (lhs_size == rhs_size) {
+		cast_lhs = check_lhs[1][TYPE_UNSIGNED(rhs_type) + 2 * TYPE_UNSIGNED(lhs_type)];
+		cast_rhs = check_rhs[1][TYPE_UNSIGNED(rhs_type) + 2 * TYPE_UNSIGNED(lhs_type)];
+	} else {
+		cast_lhs = check_lhs[2][TYPE_UNSIGNED(rhs_type) + 2 * TYPE_UNSIGNED(lhs_type)];
+		cast_rhs = check_rhs[2][TYPE_UNSIGNED(rhs_type) + 2 * TYPE_UNSIGNED(lhs_type)];
+	}
+
+	if (!cast_lhs && !cast_rhs)
+		return dup_assign(visited, stmt, lhs, new_rhs1, NULL_TREE, NULL_TREE);
+
+	if (cast_lhs && !skip_lhs_cast_check(stmt))
+		check_size_overflow(caller_node, stmt, TREE_TYPE(new_rhs1), new_rhs1, lhs, BEFORE_STMT);
+
+	if (cast_rhs)
+		check_size_overflow(caller_node, stmt, TREE_TYPE(new_rhs1), new_rhs1, rhs, BEFORE_STMT);
+
+	return dup_assign(visited, stmt, lhs, new_rhs1, NULL_TREE, NULL_TREE);
+}
+
+static tree handle_unary_rhs(struct visited *visited, struct cgraph_node *caller_node, gimple stmt)
+{
+	enum tree_code rhs_code;
+	tree rhs1, new_rhs1, lhs = gimple_assign_lhs(stmt);
+
+	if (pointer_set_contains(visited->my_stmts, stmt))
+		return lhs;
+
+	rhs1 = gimple_assign_rhs1(stmt);
+	if (TREE_CODE(TREE_TYPE(rhs1)) == POINTER_TYPE)
+		return create_assign(visited, stmt, lhs, AFTER_STMT);
+
+	new_rhs1 = expand(visited, caller_node, rhs1);
+
+	if (new_rhs1 == NULL_TREE)
+		return create_cast_assign(visited, stmt);
+
+	if (pointer_set_contains(visited->no_cast_check, stmt))
+		return dup_assign(visited, stmt, lhs, new_rhs1, NULL_TREE, NULL_TREE);
+
+	rhs_code = gimple_assign_rhs_code(stmt);
+	if (rhs_code == BIT_NOT_EXPR || rhs_code == NEGATE_EXPR) {
+		tree size_overflow_type = get_size_overflow_type(visited, stmt, rhs1);
+
+		new_rhs1 = cast_to_new_size_overflow_type(visited, stmt, new_rhs1, size_overflow_type, BEFORE_STMT);
+		check_size_overflow(caller_node, stmt, size_overflow_type, new_rhs1, rhs1, BEFORE_STMT);
+		return create_assign(visited, stmt, lhs, AFTER_STMT);
+	}
+
+	if (!gimple_assign_cast_p(stmt))
+		return dup_assign(visited, stmt, lhs, new_rhs1, NULL_TREE, NULL_TREE);
+
+	return create_cast_overflow_check(visited, caller_node, new_rhs1, stmt);
+}
+
+static tree handle_unary_ops(struct visited *visited, struct cgraph_node *caller_node, gimple stmt)
+{
+	tree rhs1, lhs = gimple_assign_lhs(stmt);
+	gimple def_stmt = get_def_stmt(lhs);
+
+	gcc_assert(gimple_code(def_stmt) != GIMPLE_NOP);
+	rhs1 = gimple_assign_rhs1(def_stmt);
+
+	if (is_gimple_constant(rhs1))
+		return create_assign(visited, def_stmt, lhs, AFTER_STMT);
+
+	switch (TREE_CODE(rhs1)) {
+	case SSA_NAME: {
+		tree ret = handle_unary_rhs(visited, caller_node, def_stmt);
+
+		if (gimple_assign_cast_p(stmt))
+			unsigned_signed_cast_intentional_overflow(visited, stmt);
+		return ret;
+	}
+	case ARRAY_REF:
+	case BIT_FIELD_REF:
+	case ADDR_EXPR:
+	case COMPONENT_REF:
+	case INDIRECT_REF:
+#if BUILDING_GCC_VERSION >= 4006
+	case MEM_REF:
+#endif
+	case TARGET_MEM_REF:
+	case VIEW_CONVERT_EXPR:
+		return create_assign(visited, def_stmt, lhs, AFTER_STMT);
+	case PARM_DECL:
+	case VAR_DECL:
+		return create_assign(visited, stmt, lhs, AFTER_STMT);
+
+	default:
+		debug_gimple_stmt(def_stmt);
+		debug_tree(rhs1);
+		gcc_unreachable();
+	}
+}
+
+static void __unused print_the_code_insertions(const_gimple stmt)
+{
+	location_t loc = gimple_location(stmt);
+
+	inform(loc, "Integer size_overflow check applied here.");
+}
+
+static bool is_from_cast(const_tree node)
+{
+	gimple def_stmt = get_def_stmt(node);
+
+	if (!def_stmt)
+		return false;
+
+	if (gimple_assign_cast_p(def_stmt))
+		return true;
+
+	return false;
+}
+
+// Skip duplication when there is a minus expr and the type of rhs1 or rhs2 is a pointer_type.
+static bool is_a_ptr_minus(gimple stmt)
+{
+	const_tree rhs1, rhs2, ptr1_rhs, ptr2_rhs;
+
+	if (gimple_assign_rhs_code(stmt) != MINUS_EXPR)
+		return false;
+
+	rhs1 = gimple_assign_rhs1(stmt);
+	if (!is_from_cast(rhs1))
+		return false;
+
+	rhs2 = gimple_assign_rhs2(stmt);
+	if (!is_from_cast(rhs2))
+		return false;
+
+	ptr1_rhs = gimple_assign_rhs1(get_def_stmt(rhs1));
+	ptr2_rhs = gimple_assign_rhs1(get_def_stmt(rhs2));
+
+	if (TREE_CODE(TREE_TYPE(ptr1_rhs)) != POINTER_TYPE && TREE_CODE(TREE_TYPE(ptr2_rhs)) != POINTER_TYPE)
+		return false;
+
+	return true;
+}
+
+static tree handle_binary_ops(struct visited *visited, struct cgraph_node *caller_node, tree lhs)
+{
+	enum intentional_overflow_type res;
+	tree rhs1, rhs2, new_lhs;
+	gimple def_stmt = get_def_stmt(lhs);
+	tree new_rhs1 = NULL_TREE;
+	tree new_rhs2 = NULL_TREE;
+
+	if (is_a_ptr_minus(def_stmt))
+		return create_assign(visited, def_stmt, lhs, AFTER_STMT);
+
+	rhs1 = gimple_assign_rhs1(def_stmt);
+	rhs2 = gimple_assign_rhs2(def_stmt);
+
+	/* no DImode/TImode division in the 32/64 bit kernel */
+	switch (gimple_assign_rhs_code(def_stmt)) {
+	case RDIV_EXPR:
+	case TRUNC_DIV_EXPR:
+	case CEIL_DIV_EXPR:
+	case FLOOR_DIV_EXPR:
+	case ROUND_DIV_EXPR:
+	case TRUNC_MOD_EXPR:
+	case CEIL_MOD_EXPR:
+	case FLOOR_MOD_EXPR:
+	case ROUND_MOD_EXPR:
+	case EXACT_DIV_EXPR:
+	case POINTER_PLUS_EXPR:
+	case BIT_AND_EXPR:
+		return create_assign(visited, def_stmt, lhs, AFTER_STMT);
+	default:
+		break;
+	}
+
+	new_lhs = handle_integer_truncation(visited, caller_node, lhs);
+	if (new_lhs != NULL_TREE)
+		return new_lhs;
+
+	if (TREE_CODE(rhs1) == SSA_NAME)
+		new_rhs1 = expand(visited, caller_node, rhs1);
+	if (TREE_CODE(rhs2) == SSA_NAME)
+		new_rhs2 = expand(visited, caller_node, rhs2);
+
+	res = add_mul_intentional_overflow(def_stmt);
+	if (res != NO_INTENTIONAL_OVERFLOW) {
+		new_lhs = dup_assign(visited, def_stmt, lhs, new_rhs1, new_rhs2, NULL_TREE);
+		insert_cast_expr(visited, get_def_stmt(new_lhs), res);
+		return new_lhs;
+	}
+
+	if (skip_expr_on_double_type(def_stmt)) {
+		new_lhs = dup_assign(visited, def_stmt, lhs, new_rhs1, new_rhs2, NULL_TREE);
+		insert_cast_expr(visited, get_def_stmt(new_lhs), NO_INTENTIONAL_OVERFLOW);
+		return new_lhs;
+	}
+
+	if (is_a_neg_overflow(def_stmt, rhs2))
+		return handle_intentional_overflow(visited, caller_node, true, def_stmt, new_rhs1, NULL_TREE);
+	if (is_a_neg_overflow(def_stmt, rhs1))
+		return handle_intentional_overflow(visited, caller_node, true, def_stmt, new_rhs2, new_rhs2);
+
+
+	if (is_a_constant_overflow(def_stmt, rhs2))
+		return handle_intentional_overflow(visited, caller_node, !is_a_cast_and_const_overflow(rhs1), def_stmt, new_rhs1, NULL_TREE);
+	if (is_a_constant_overflow(def_stmt, rhs1))
+		return handle_intentional_overflow(visited, caller_node, !is_a_cast_and_const_overflow(rhs2), def_stmt, new_rhs2, new_rhs2);
+
+	// the const is between 0 and (signed) MAX
+	if (is_gimple_constant(rhs1))
+		new_rhs1 = create_assign(visited, def_stmt, rhs1, BEFORE_STMT);
+	if (is_gimple_constant(rhs2))
+		new_rhs2 = create_assign(visited, def_stmt, rhs2, BEFORE_STMT);
+
+	return dup_assign(visited, def_stmt, lhs, new_rhs1, new_rhs2, NULL_TREE);
+}
+
+#if BUILDING_GCC_VERSION >= 4006
+static tree get_new_rhs(struct visited *visited, struct cgraph_node *caller_node, tree size_overflow_type, tree rhs)
+{
+	if (is_gimple_constant(rhs))
+		return cast_a_tree(size_overflow_type, rhs);
+	if (TREE_CODE(rhs) != SSA_NAME)
+		return NULL_TREE;
+	return expand(visited, caller_node, rhs);
+}
+
+static tree handle_ternary_ops(struct visited *visited, struct cgraph_node *caller_node, tree lhs)
+{
+	tree rhs1, rhs2, rhs3, new_rhs1, new_rhs2, new_rhs3, size_overflow_type;
+	gimple def_stmt = get_def_stmt(lhs);
+
+	size_overflow_type = get_size_overflow_type(visited, def_stmt, lhs);
+
+	rhs1 = gimple_assign_rhs1(def_stmt);
+	rhs2 = gimple_assign_rhs2(def_stmt);
+	rhs3 = gimple_assign_rhs3(def_stmt);
+	new_rhs1 = get_new_rhs(visited, caller_node, size_overflow_type, rhs1);
+	new_rhs2 = get_new_rhs(visited, caller_node, size_overflow_type, rhs2);
+	new_rhs3 = get_new_rhs(visited, caller_node, size_overflow_type, rhs3);
+
+	return dup_assign(visited, def_stmt, lhs, new_rhs1, new_rhs2, new_rhs3);
+}
+#endif
+
+static tree get_my_stmt_lhs(struct visited *visited, gimple stmt)
+{
+	gimple_stmt_iterator gsi;
+	gimple next_stmt = NULL;
+
+	gsi = gsi_for_stmt(stmt);
+
+	do {
+		gsi_next(&gsi);
+		next_stmt = gsi_stmt(gsi);
+
+		if (gimple_code(stmt) == GIMPLE_PHI && !pointer_set_contains(visited->my_stmts, next_stmt))
+			return NULL_TREE;
+
+		if (pointer_set_contains(visited->my_stmts, next_stmt) && !pointer_set_contains(visited->skip_expr_casts, next_stmt))
+			break;
+
+		gcc_assert(pointer_set_contains(visited->my_stmts, next_stmt));
+	} while (!gsi_end_p(gsi));
+
+	gcc_assert(next_stmt);
+	return get_lhs(next_stmt);
+}
+
+static tree expand_visited(struct visited *visited, gimple def_stmt)
+{
+	gimple_stmt_iterator gsi;
+	enum gimple_code code = gimple_code(def_stmt);
+
+	if (code == GIMPLE_ASM)
+		return NULL_TREE;
+
+	gsi = gsi_for_stmt(def_stmt);
+	gsi_next(&gsi);
+
+	if (gimple_code(def_stmt) == GIMPLE_PHI && gsi_end_p(gsi))
+		return NULL_TREE;
+	return get_my_stmt_lhs(visited, def_stmt);
+}
+
+tree expand(struct visited *visited, struct cgraph_node *caller_node, tree lhs)
+{
+	gimple def_stmt;
+
+	def_stmt = get_def_stmt(lhs);
+
+	if (!def_stmt || gimple_code(def_stmt) == GIMPLE_NOP)
+		return NULL_TREE;
+
+	if (pointer_set_contains(visited->my_stmts, def_stmt))
+		return lhs;
+
+	if (pointer_set_contains(visited->stmts, def_stmt))
+		return expand_visited(visited, def_stmt);
+
+	switch (gimple_code(def_stmt)) {
+	case GIMPLE_PHI:
+		return handle_phi(visited, caller_node, lhs);
+	case GIMPLE_CALL:
+	case GIMPLE_ASM:
+		return create_assign(visited, def_stmt, lhs, AFTER_STMT);
+	case GIMPLE_ASSIGN:
+		switch (gimple_num_ops(def_stmt)) {
+		case 2:
+			return handle_unary_ops(visited, caller_node, def_stmt);
+		case 3:
+			return handle_binary_ops(visited, caller_node, lhs);
+#if BUILDING_GCC_VERSION >= 4006
+		case 4:
+			return handle_ternary_ops(visited, caller_node, lhs);
+#endif
+		}
+	default:
+		debug_gimple_stmt(def_stmt);
+		error("%s: unknown gimple code", __func__);
+		gcc_unreachable();
+	}
+}
+
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/insert_size_overflow_check_ipa.c linux-3.2.71-pax/tools/gcc/size_overflow_plugin/insert_size_overflow_check_ipa.c
--- linux-3.2.71/tools/gcc/size_overflow_plugin/insert_size_overflow_check_ipa.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/insert_size_overflow_check_ipa.c	2014-07-27 23:41:39.593093822 +0200
@@ -0,0 +1,1141 @@
+/*
+ * Copyright 2011-2014 by Emese Revfy <re.emese@gmail.com>
+ * Licensed under the GPL v2, or (at your option) v3
+ *
+ * Homepage:
+ * http://www.grsecurity.net/~ephox/overflow_plugin/
+ *
+ * Documentation:
+ * http://forums.grsecurity.net/viewtopic.php?f=7&t=3043
+ *
+ * This plugin recomputes expressions of function arguments marked by a size_overflow attribute
+ * with double integer precision (DImode/TImode for 32/64 bit integer types).
+ * The recomputed argument is checked against TYPE_MAX and an event is logged on overflow and the triggering process is killed.
+ *
+ * Usage:
+ * $ make
+ * $ make run
+ */
+
+#include "gcc-common.h"
+#include "size_overflow.h"
+
+#define VEC_LEN 128
+#define RET_CHECK NULL_TREE
+#define WRONG_NODE 32
+#define NOT_INTENTIONAL_ASM NULL
+
+unsigned int call_count;
+
+static void set_conditions(struct pointer_set_t *visited, bool *interesting_conditions, const_tree lhs);
+static void walk_use_def(struct pointer_set_t *visited, struct interesting_node *cur_node, tree lhs);
+
+struct visited_fns {
+	struct visited_fns *next;
+	const_tree fndecl;
+	unsigned int num;
+	const_gimple first_stmt;
+};
+
+struct next_cgraph_node {
+	struct next_cgraph_node *next;
+	struct cgraph_node *current_function;
+	tree callee_fndecl;
+	unsigned int num;
+};
+
+// Don't want to duplicate entries in next_cgraph_node
+static bool is_in_next_cgraph_node(struct next_cgraph_node *head, struct cgraph_node *node, const_tree fndecl, unsigned int num)
+{
+	const_tree new_callee_fndecl;
+	struct next_cgraph_node *cur_node;
+
+	if (fndecl == RET_CHECK)
+		new_callee_fndecl = NODE_DECL(node);
+	else
+		new_callee_fndecl = fndecl;
+
+	for (cur_node = head; cur_node; cur_node = cur_node->next) {
+		if (!operand_equal_p(NODE_DECL(cur_node->current_function), NODE_DECL(node), 0))
+			continue;
+		if (!operand_equal_p(cur_node->callee_fndecl, new_callee_fndecl, 0))
+			continue;
+		if (num == cur_node->num)
+			return true;
+	}
+	return false;
+}
+
+/* Add a next_cgraph_node into the list for handle_function().
+ * handle_function()  iterates over all the next cgraph nodes and
+ * starts the overflow check insertion process.
+ */
+static struct next_cgraph_node *create_new_next_cgraph_node(struct next_cgraph_node *head, struct cgraph_node *node, tree fndecl, unsigned int num)
+{
+	struct next_cgraph_node *new_node;
+
+	if (is_in_next_cgraph_node(head, node, fndecl, num))
+		return head;
+
+	new_node = (struct next_cgraph_node *)xmalloc(sizeof(*new_node));
+	new_node->current_function = node;
+	new_node->next = NULL;
+	new_node->num = num;
+	if (fndecl == RET_CHECK)
+		new_node->callee_fndecl = NODE_DECL(node);
+	else
+		new_node->callee_fndecl = fndecl;
+
+	if (!head)
+		return new_node;
+
+	new_node->next = head;
+	return new_node;
+}
+
+static struct next_cgraph_node *create_new_next_cgraph_nodes(struct next_cgraph_node *head, struct cgraph_node *node, unsigned int num)
+{
+	struct cgraph_edge *e;
+
+	if (num == 0)
+		return create_new_next_cgraph_node(head, node, RET_CHECK, num);
+
+	for (e = node->callers; e; e = e->next_caller) {
+		tree fndecl = gimple_call_fndecl(e->call_stmt);
+
+		gcc_assert(fndecl != NULL_TREE);
+		head = create_new_next_cgraph_node(head, e->caller, fndecl, num);
+	}
+
+	return head;
+}
+
+struct missing_functions {
+	struct missing_functions *next;
+	const_tree node;
+	tree fndecl;
+};
+
+static struct missing_functions *create_new_missing_function(struct missing_functions *missing_fn_head, tree node)
+{
+	struct missing_functions *new_function;
+
+	new_function = (struct missing_functions *)xmalloc(sizeof(*new_function));
+	new_function->node = node;
+	new_function->next = NULL;
+
+	if (TREE_CODE(node) == FUNCTION_DECL)
+		new_function->fndecl = node;
+	else
+		new_function->fndecl = current_function_decl;
+	gcc_assert(new_function->fndecl);
+
+	if (!missing_fn_head)
+		return new_function;
+
+	new_function->next = missing_fn_head;
+	return new_function;
+}
+
+/* If the function is missing from the hash table and it is a static function
+ * then create a next_cgraph_node from it for handle_function()
+ */
+static struct next_cgraph_node *check_missing_overflow_attribute_and_create_next_node(struct next_cgraph_node *cnodes, struct missing_functions *missing_fn_head)
+{
+	unsigned int num;
+	const_tree orig_fndecl;
+	struct cgraph_node *next_node = NULL;
+
+	orig_fndecl = DECL_ORIGIN(missing_fn_head->fndecl);
+
+	num = get_function_num(missing_fn_head->node, orig_fndecl);
+	if (num == CANNOT_FIND_ARG)
+		return cnodes;
+
+	if (!is_missing_function(orig_fndecl, num))
+		return cnodes;
+
+	next_node = cgraph_get_node(missing_fn_head->fndecl);
+	if (next_node && next_node->local.local)
+		cnodes = create_new_next_cgraph_nodes(cnodes, next_node, num);
+	return cnodes;
+}
+
+/* Search for missing size_overflow attributes on the last nodes in ipa and collect them
+ * into the next_cgraph_node list. They will be the next interesting returns or callees.
+ */
+static struct next_cgraph_node *search_overflow_attribute(struct next_cgraph_node *cnodes, struct interesting_node *cur_node)
+{
+	unsigned int i;
+	tree node;
+	struct missing_functions *cur, *missing_fn_head = NULL;
+
+#if BUILDING_GCC_VERSION <= 4007
+	FOR_EACH_VEC_ELT(tree, cur_node->last_nodes, i, node) {
+#else
+	FOR_EACH_VEC_ELT(*cur_node->last_nodes, i, node) {
+#endif
+		switch (TREE_CODE(node)) {
+		case PARM_DECL:
+			if (TREE_CODE(TREE_TYPE(node)) != INTEGER_TYPE)
+				break;
+		case FUNCTION_DECL:
+			missing_fn_head = create_new_missing_function(missing_fn_head, node);
+			break;
+		default:
+			break;
+		}
+	}
+
+	while (missing_fn_head) {
+		cnodes = check_missing_overflow_attribute_and_create_next_node(cnodes, missing_fn_head);
+
+		cur = missing_fn_head->next;
+		free(missing_fn_head);
+		missing_fn_head = cur;
+	}
+
+	return cnodes;
+}
+
+static void walk_phi_set_conditions(struct pointer_set_t *visited, bool *interesting_conditions, const_tree result)
+{
+	gimple phi = get_def_stmt(result);
+	unsigned int i, n = gimple_phi_num_args(phi);
+
+	pointer_set_insert(visited, phi);
+	for (i = 0; i < n; i++) {
+		const_tree arg = gimple_phi_arg_def(phi, i);
+
+		set_conditions(visited, interesting_conditions, arg);
+	}
+}
+
+enum conditions {
+	FROM_CONST, NOT_UNARY, CAST, RET, PHI
+};
+
+// Search for constants, cast assignments and binary/ternary assignments
+static void set_conditions(struct pointer_set_t *visited, bool *interesting_conditions, const_tree lhs)
+{
+	gimple def_stmt = get_def_stmt(lhs);
+
+	if (is_gimple_constant(lhs)) {
+		interesting_conditions[FROM_CONST] = true;
+		return;
+	}
+
+	if (!def_stmt)
+		return;
+
+	if (pointer_set_contains(visited, def_stmt))
+		return;
+
+	switch (gimple_code(def_stmt)) {
+	case GIMPLE_CALL:
+		if (lhs == gimple_call_lhs(def_stmt))
+			interesting_conditions[RET] = true;
+		return;
+	case GIMPLE_NOP:
+	case GIMPLE_ASM:
+		return;
+	case GIMPLE_PHI:
+		interesting_conditions[PHI] = true;
+		return walk_phi_set_conditions(visited, interesting_conditions, lhs);
+	case GIMPLE_ASSIGN:
+		if (gimple_num_ops(def_stmt) == 2) {
+			const_tree rhs = gimple_assign_rhs1(def_stmt);
+
+			if (gimple_assign_cast_p(def_stmt))
+				interesting_conditions[CAST] = true;
+
+			return set_conditions(visited, interesting_conditions, rhs);
+		} else {
+			interesting_conditions[NOT_UNARY] = true;
+			return;
+		}
+	default:
+		debug_gimple_stmt(def_stmt);
+		gcc_unreachable();
+	}
+}
+
+// determine whether duplication will be necessary or not.
+static void search_interesting_conditions(struct interesting_node *cur_node, bool *interesting_conditions)
+{
+	struct pointer_set_t *visited;
+
+	if (gimple_assign_cast_p(cur_node->first_stmt))
+		interesting_conditions[CAST] = true;
+	else if (is_gimple_assign(cur_node->first_stmt) && gimple_num_ops(cur_node->first_stmt) > 2)
+		interesting_conditions[NOT_UNARY] = true;
+
+	visited = pointer_set_create();
+	set_conditions(visited, interesting_conditions, cur_node->node);
+	pointer_set_destroy(visited);
+}
+
+// Remove the size_overflow asm stmt and create an assignment from the input and output of the asm
+static void replace_size_overflow_asm_with_assign(gimple asm_stmt, tree lhs, tree rhs)
+{
+	gimple assign;
+	gimple_stmt_iterator gsi;
+
+	// already removed
+	if (gimple_bb(asm_stmt) == NULL)
+		return;
+	gsi = gsi_for_stmt(asm_stmt);
+
+	assign = gimple_build_assign(lhs, rhs);
+	gsi_insert_before(&gsi, assign, GSI_SAME_STMT);
+	SSA_NAME_DEF_STMT(lhs) = assign;
+
+	gsi_remove(&gsi, true);
+}
+
+/* Get the fndecl of an interesting stmt, the fndecl is the caller function if the interesting
+ * stmt is a return otherwise it is the callee function.
+ */
+const_tree get_interesting_orig_fndecl(const_gimple stmt, unsigned int argnum)
+{
+	const_tree fndecl;
+
+	if (argnum == 0)
+		fndecl = current_function_decl;
+	else
+		fndecl = gimple_call_fndecl(stmt);
+
+	if (fndecl == NULL_TREE)
+		return NULL_TREE;
+
+	return DECL_ORIGIN(fndecl);
+}
+
+// e.g., 3.8.2, 64, arch/x86/ia32/ia32_signal.c copy_siginfo_from_user32(): compat_ptr() u32 max
+static bool skip_asm(const_tree arg)
+{
+	gimple def_stmt = get_def_stmt(arg);
+
+	if (!def_stmt || !gimple_assign_cast_p(def_stmt))
+		return false;
+
+	def_stmt = get_def_stmt(gimple_assign_rhs1(def_stmt));
+	return def_stmt && gimple_code(def_stmt) == GIMPLE_ASM;
+}
+
+static void walk_use_def_phi(struct pointer_set_t *visited, struct interesting_node *cur_node, tree result)
+{
+	gimple phi = get_def_stmt(result);
+	unsigned int i, n = gimple_phi_num_args(phi);
+
+	pointer_set_insert(visited, phi);
+	for (i = 0; i < n; i++) {
+		tree arg = gimple_phi_arg_def(phi, i);
+
+		walk_use_def(visited, cur_node, arg);
+	}
+}
+
+static void walk_use_def_binary(struct pointer_set_t *visited, struct interesting_node *cur_node, tree lhs)
+{
+	gimple def_stmt = get_def_stmt(lhs);
+	tree rhs1, rhs2;
+
+	rhs1 = gimple_assign_rhs1(def_stmt);
+	rhs2 = gimple_assign_rhs2(def_stmt);
+
+	walk_use_def(visited, cur_node, rhs1);
+	walk_use_def(visited, cur_node, rhs2);
+}
+
+static void insert_last_node(struct interesting_node *cur_node, tree node)
+{
+	unsigned int i;
+	tree element;
+	enum tree_code code;
+
+	gcc_assert(node != NULL_TREE);
+
+	if (is_gimple_constant(node))
+		return;
+
+	code = TREE_CODE(node);
+	if (code == VAR_DECL) {
+		node = DECL_ORIGIN(node);
+		code = TREE_CODE(node);
+	}
+
+	if (code != PARM_DECL && code != FUNCTION_DECL && code != COMPONENT_REF)
+		return;
+
+#if BUILDING_GCC_VERSION <= 4007
+	FOR_EACH_VEC_ELT(tree, cur_node->last_nodes, i, element) {
+#else
+	FOR_EACH_VEC_ELT(*cur_node->last_nodes, i, element) {
+#endif
+		if (operand_equal_p(node, element, 0))
+			return;
+	}
+
+#if BUILDING_GCC_VERSION <= 4007
+	gcc_assert(VEC_length(tree, cur_node->last_nodes) < VEC_LEN);
+	VEC_safe_push(tree, gc, cur_node->last_nodes, node);
+#else
+	gcc_assert(cur_node->last_nodes->length() < VEC_LEN);
+	vec_safe_push(cur_node->last_nodes, node);
+#endif
+}
+
+// a size_overflow asm stmt in the control flow doesn't stop the recursion
+static void handle_asm_stmt(struct pointer_set_t *visited, struct interesting_node *cur_node, tree lhs, const_gimple stmt)
+{
+	if (!is_size_overflow_asm(stmt))
+		walk_use_def(visited, cur_node, SSA_NAME_VAR(lhs));
+}
+
+/* collect the parm_decls and fndecls (for checking a missing size_overflow attribute (ret or arg) or intentional_overflow)
+ * and component refs (for checking the intentional_overflow attribute).
+ */
+static void walk_use_def(struct pointer_set_t *visited, struct interesting_node *cur_node, tree lhs)
+{
+	const_gimple def_stmt;
+
+	if (TREE_CODE(lhs) != SSA_NAME) {
+		insert_last_node(cur_node, lhs);
+		return;
+	}
+
+	def_stmt = get_def_stmt(lhs);
+	if (!def_stmt)
+		return;
+
+	if (pointer_set_insert(visited, def_stmt))
+		return;
+
+	switch (gimple_code(def_stmt)) {
+	case GIMPLE_NOP:
+		return walk_use_def(visited, cur_node, SSA_NAME_VAR(lhs));
+	case GIMPLE_ASM:
+		return handle_asm_stmt(visited, cur_node, lhs, def_stmt);
+	case GIMPLE_CALL: {
+		tree fndecl = gimple_call_fndecl(def_stmt);
+
+		if (fndecl == NULL_TREE)
+			return;
+		insert_last_node(cur_node, fndecl);
+		return;
+	}
+	case GIMPLE_PHI:
+		return walk_use_def_phi(visited, cur_node, lhs);
+	case GIMPLE_ASSIGN:
+		switch (gimple_num_ops(def_stmt)) {
+		case 2:
+			return walk_use_def(visited, cur_node, gimple_assign_rhs1(def_stmt));
+		case 3:
+			return walk_use_def_binary(visited, cur_node, lhs);
+		}
+	default:
+		debug_gimple_stmt((gimple)def_stmt);
+		error("%s: unknown gimple code", __func__);
+		gcc_unreachable();
+	}
+}
+
+// Collect all the last nodes for checking the intentional_overflow and size_overflow attributes
+static void set_last_nodes(struct interesting_node *cur_node)
+{
+	struct pointer_set_t *visited;
+
+	visited = pointer_set_create();
+	walk_use_def(visited, cur_node, cur_node->node);
+	pointer_set_destroy(visited);
+}
+
+enum precond {
+	NO_ATTRIBUTE_SEARCH, NO_CHECK_INSERT, NONE
+};
+
+/* If there is a mark_turn_off intentional attribute on the caller or the callee then there is no duplication and missing size_overflow attribute check anywhere.
+ * There is only missing size_overflow attribute checking if the intentional_overflow attribute is the mark_no type.
+ * Stmt duplication is unnecessary if there are no binary/ternary assignements or if the unary assignment isn't a cast.
+ * It skips the possible error codes too.
+ */
+static enum precond check_preconditions(struct interesting_node *cur_node)
+{
+	bool interesting_conditions[5] = {false, false, false, false, false};
+
+	set_last_nodes(cur_node);
+
+	check_intentional_attribute_ipa(cur_node);
+	if (cur_node->intentional_attr_decl == MARK_TURN_OFF || cur_node->intentional_attr_cur_fndecl == MARK_TURN_OFF)
+		return NO_ATTRIBUTE_SEARCH;
+
+	search_interesting_conditions(cur_node, interesting_conditions);
+
+	// error code: a phi, unary assign (not cast) and returns only
+	if (!interesting_conditions[NOT_UNARY] && interesting_conditions[PHI] && interesting_conditions[RET] && !interesting_conditions[CAST])
+		return NO_ATTRIBUTE_SEARCH;
+
+	// error code: def_stmts trace back to a constant and there are no binary/ternary assigments
+	if (interesting_conditions[CAST] && interesting_conditions[FROM_CONST] && !interesting_conditions[NOT_UNARY])
+		return NO_ATTRIBUTE_SEARCH;
+
+	// unnecessary overflow check
+	if (!interesting_conditions[CAST] && !interesting_conditions[NOT_UNARY])
+		return NO_CHECK_INSERT;
+
+	if (cur_node->intentional_attr_cur_fndecl != MARK_NO)
+		return NO_CHECK_INSERT;
+
+	return NONE;
+}
+
+static tree cast_to_orig_type(struct visited *visited, gimple stmt, const_tree orig_node, tree new_node)
+{
+	const_gimple assign;
+	tree orig_type = TREE_TYPE(orig_node);
+	gimple_stmt_iterator gsi = gsi_for_stmt(stmt);
+
+	assign = build_cast_stmt(visited, orig_type, new_node, CREATE_NEW_VAR, &gsi, BEFORE_STMT, false);
+	return gimple_assign_lhs(assign);
+}
+
+static void change_orig_node(struct visited *visited, struct interesting_node *cur_node, tree new_node)
+{
+	void (*set_rhs)(gimple, tree);
+	gimple stmt = cur_node->first_stmt;
+	const_tree orig_node = cur_node->node;
+
+	switch (gimple_code(stmt)) {
+	case GIMPLE_RETURN:
+		gimple_return_set_retval(stmt, cast_to_orig_type(visited, stmt, orig_node, new_node));
+		break;
+	case GIMPLE_CALL:
+		gimple_call_set_arg(stmt, cur_node->num - 1, cast_to_orig_type(visited, stmt, orig_node, new_node));
+		break;
+	case GIMPLE_ASSIGN:
+		switch (cur_node->num) {
+		case 1:
+			set_rhs = &gimple_assign_set_rhs1;
+			break;
+		case 2:
+			set_rhs = &gimple_assign_set_rhs2;
+			break;
+#if BUILDING_GCC_VERSION >= 4006
+		case 3:
+			set_rhs = &gimple_assign_set_rhs3;
+			break;
+#endif
+		default:
+			gcc_unreachable();
+		}
+
+		set_rhs(stmt, cast_to_orig_type(visited, stmt, orig_node, new_node));
+		break;
+	default:
+		debug_gimple_stmt(stmt);
+		gcc_unreachable();
+	}
+
+	update_stmt(stmt);
+}
+
+static struct visited *create_visited(void)
+{
+	struct visited *new_node;
+
+	new_node = (struct visited *)xmalloc(sizeof(*new_node));
+	new_node->stmts = pointer_set_create();
+	new_node->my_stmts = pointer_set_create();
+	new_node->skip_expr_casts = pointer_set_create();
+	new_node->no_cast_check = pointer_set_create();
+	return new_node;
+}
+
+static void free_visited(struct visited *visited)
+{
+	pointer_set_destroy(visited->stmts);
+	pointer_set_destroy(visited->my_stmts);
+	pointer_set_destroy(visited->skip_expr_casts);
+	pointer_set_destroy(visited->no_cast_check);
+
+	free(visited);
+}
+
+/* This function calls the main recursion function (expand) that duplicates the stmts. Before that it checks the intentional_overflow attribute and asm stmts,
+ * it decides whether the duplication is necessary or not and it searches for missing size_overflow attributes. After expand() it changes the orig node to the duplicated node
+ * in the original stmt (first stmt) and it inserts the overflow check for the arg of the callee or for the return value.
+ */
+static struct next_cgraph_node *handle_interesting_stmt(struct visited *visited, struct next_cgraph_node *cnodes, struct interesting_node *cur_node, struct cgraph_node *caller_node)
+{
+	enum precond ret;
+	tree new_node, orig_node = cur_node->node;
+
+	ret = check_preconditions(cur_node);
+	if (ret == NO_ATTRIBUTE_SEARCH)
+		return cnodes;
+
+	cnodes = search_overflow_attribute(cnodes, cur_node);
+
+	if (ret == NO_CHECK_INSERT)
+		return cnodes;
+
+	new_node = expand(visited, caller_node, orig_node);
+	if (new_node == NULL_TREE)
+		return cnodes;
+
+	change_orig_node(visited, cur_node, new_node);
+	check_size_overflow(caller_node, cur_node->first_stmt, TREE_TYPE(new_node), new_node, orig_node, BEFORE_STMT);
+
+	return cnodes;
+}
+
+// Check visited_fns interesting nodes.
+static bool is_in_interesting_node(struct interesting_node *head, const_gimple first_stmt, const_tree node, unsigned int num)
+{
+	struct interesting_node *cur;
+
+	for (cur = head; cur; cur = cur->next) {
+		if (!operand_equal_p(node, cur->node, 0))
+			continue;
+		if (num != cur->num)
+			continue;
+		if (first_stmt == cur->first_stmt)
+			return true;
+	}
+	return false;
+}
+
+/* Create an interesting node. The ipa pass starts to duplicate from these stmts.
+   first_stmt: it is the call or assignment or ret stmt, change_orig_node() will change the original node (retval, or function arg) in this
+   last_nodes: they are the last stmts in the recursion (they haven't a def_stmt). They are useful in the missing size_overflow attribute check and
+               the intentional_overflow attribute check. They are collected by set_last_nodes().
+   num: arg count of a call stmt or 0 when it is a ret
+   node: the recursion starts from here, it is a call arg or a return value
+   fndecl: the fndecl of the interesting node when the node is an arg. it is the fndecl of the callee function otherwise it is the fndecl of the caller (current_function_fndecl) function.
+   intentional_attr_decl: intentional_overflow attribute of the callee function
+   intentional_attr_cur_fndecl: intentional_overflow attribute of the caller function
+   intentional_mark_from_gimple: the intentional overflow type of size_overflow asm stmt from gimple if it exists
+ */
+static struct interesting_node *create_new_interesting_node(struct interesting_node *head, gimple first_stmt, tree node, unsigned int num, gimple asm_stmt)
+{
+	struct interesting_node *new_node;
+	tree fndecl;
+	enum gimple_code code;
+
+	gcc_assert(node != NULL_TREE);
+	code = gimple_code(first_stmt);
+	gcc_assert(code == GIMPLE_CALL || code == GIMPLE_ASM || code == GIMPLE_ASSIGN || code == GIMPLE_RETURN);
+
+	if (num == CANNOT_FIND_ARG)
+		return head;
+
+	if (skip_types(node))
+		return head;
+
+	if (skip_asm(node))
+		return head;
+
+	if (is_gimple_call(first_stmt))
+		fndecl = gimple_call_fndecl(first_stmt);
+	else
+		fndecl = current_function_decl;
+
+	if (fndecl == NULL_TREE)
+		return head;
+
+	if (is_in_interesting_node(head, first_stmt, node, num))
+		return head;
+
+	new_node = (struct interesting_node *)xmalloc(sizeof(*new_node));
+
+	new_node->next = NULL;
+	new_node->first_stmt = first_stmt;
+#if BUILDING_GCC_VERSION <= 4007
+	new_node->last_nodes = VEC_alloc(tree, gc, VEC_LEN);
+#else
+	vec_alloc(new_node->last_nodes, VEC_LEN);
+#endif
+	new_node->num = num;
+	new_node->node = node;
+	new_node->fndecl = fndecl;
+	new_node->intentional_attr_decl = MARK_NO;
+	new_node->intentional_attr_cur_fndecl = MARK_NO;
+	new_node->intentional_mark_from_gimple = asm_stmt;
+
+	if (!head)
+		return new_node;
+
+	new_node->next = head;
+	return new_node;
+}
+
+/* Check the ret stmts in the functions on the next cgraph node list (these functions will be in the hash table and they are reachable from ipa).
+ * If the ret stmt is in the next cgraph node list then it's an interesting ret.
+ */
+static struct interesting_node *handle_stmt_by_cgraph_nodes_ret(struct interesting_node *head, gimple stmt, struct next_cgraph_node *next_node)
+{
+	struct next_cgraph_node *cur_node;
+	tree ret = gimple_return_retval(stmt);
+
+	if (ret == NULL_TREE)
+		return head;
+
+	for (cur_node = next_node; cur_node; cur_node = cur_node->next) {
+		if (!operand_equal_p(cur_node->callee_fndecl, DECL_ORIGIN(current_function_decl), 0))
+			continue;
+		if (cur_node->num == 0)
+			head = create_new_interesting_node(head, stmt, ret, 0, NOT_INTENTIONAL_ASM);
+	}
+
+	return head;
+}
+
+/* Check the call stmts in the functions on the next cgraph node list (these functions will be in the hash table and they are reachable from ipa).
+ * If the call stmt is in the next cgraph node list then it's an interesting call.
+ */
+static struct interesting_node *handle_stmt_by_cgraph_nodes_call(struct interesting_node *head, gimple stmt, struct next_cgraph_node *next_node)
+{
+	unsigned int argnum;
+	tree arg;
+	const_tree fndecl;
+	struct next_cgraph_node *cur_node;
+
+	fndecl = gimple_call_fndecl(stmt);
+	if (fndecl == NULL_TREE)
+		return head;
+
+	for (cur_node = next_node; cur_node; cur_node = cur_node->next) {
+		if (!operand_equal_p(cur_node->callee_fndecl, fndecl, 0))
+			continue;
+		argnum = get_correct_arg_count(cur_node->num, fndecl);
+		gcc_assert(argnum != CANNOT_FIND_ARG);
+		if (argnum == 0)
+			continue;
+
+		arg = gimple_call_arg(stmt, argnum - 1);
+		head = create_new_interesting_node(head, stmt, arg, argnum, NOT_INTENTIONAL_ASM);
+	}
+
+	return head;
+}
+
+static unsigned int check_ops(const_tree orig_node, const_tree node, unsigned int ret_count)
+{
+	if (!operand_equal_p(orig_node, node, 0))
+		return WRONG_NODE;
+	if (skip_types(node))
+		return WRONG_NODE;
+	return ret_count;
+}
+
+// Get the index of the rhs node in an assignment
+static unsigned int get_assign_ops_count(const_gimple stmt, tree node)
+{
+	const_tree rhs1, rhs2;
+	unsigned int ret;
+
+	gcc_assert(stmt);
+	gcc_assert(is_gimple_assign(stmt));
+
+	rhs1 = gimple_assign_rhs1(stmt);
+	gcc_assert(rhs1 != NULL_TREE);
+
+	switch (gimple_num_ops(stmt)) {
+	case 2:
+		return check_ops(node, rhs1, 1);
+	case 3:
+		ret = check_ops(node, rhs1, 1);
+		if (ret != WRONG_NODE)
+			return ret;
+
+		rhs2 = gimple_assign_rhs2(stmt);
+		gcc_assert(rhs2 != NULL_TREE);
+		return check_ops(node, rhs2, 2);
+	default:
+		gcc_unreachable();
+	}
+}
+
+// Find the correct arg number of a call stmt. It is needed when the interesting function is a cloned function.
+static unsigned int find_arg_number_gimple(const_tree arg, const_gimple stmt)
+{
+	unsigned int i;
+
+	if (gimple_call_fndecl(stmt) == NULL_TREE)
+		return CANNOT_FIND_ARG;
+
+	for (i = 0; i < gimple_call_num_args(stmt); i++) {
+		tree node;
+
+		node = gimple_call_arg(stmt, i);
+		if (!operand_equal_p(arg, node, 0))
+			continue;
+		if (!skip_types(node))
+			return i + 1;
+	}
+
+	return CANNOT_FIND_ARG;
+}
+
+/* starting from the size_overflow asm stmt collect interesting stmts. They can be
+ * any of return, call or assignment stmts (because of inlining).
+ */
+static struct interesting_node *get_interesting_ret_or_call(struct pointer_set_t *visited, struct interesting_node *head, tree node, gimple intentional_asm)
+{
+	use_operand_p use_p;
+	imm_use_iterator imm_iter;
+	unsigned int argnum;
+
+	gcc_assert(TREE_CODE(node) == SSA_NAME);
+
+	if (pointer_set_insert(visited, node))
+		return head;
+
+	FOR_EACH_IMM_USE_FAST(use_p, imm_iter, node) {
+		gimple stmt = USE_STMT(use_p);
+
+		if (stmt == NULL)
+			return head;
+		if (is_gimple_debug(stmt))
+			continue;
+
+		switch (gimple_code(stmt)) {
+		case GIMPLE_CALL:
+			argnum = find_arg_number_gimple(node, stmt);
+			head = create_new_interesting_node(head, stmt, node, argnum, intentional_asm);
+			break;
+		case GIMPLE_RETURN:
+			head = create_new_interesting_node(head, stmt, node, 0, intentional_asm);
+			break;
+		case GIMPLE_ASSIGN:
+			argnum = get_assign_ops_count(stmt, node);
+			head = create_new_interesting_node(head, stmt, node, argnum, intentional_asm);
+			break;
+		case GIMPLE_PHI: {
+			tree result = gimple_phi_result(stmt);
+			head = get_interesting_ret_or_call(visited, head, result, intentional_asm);
+			break;
+		}
+		case GIMPLE_ASM:
+			if (gimple_asm_noutputs(stmt) != 0)
+				break;
+			if (!is_size_overflow_asm(stmt))
+				break;
+			head = create_new_interesting_node(head, stmt, node, 1, intentional_asm);
+			break;
+		case GIMPLE_COND:
+		case GIMPLE_SWITCH:
+			break;
+		default:
+			debug_gimple_stmt(stmt);
+			gcc_unreachable();
+			break;
+		}
+	}
+	return head;
+}
+
+static void remove_size_overflow_asm(gimple stmt)
+{
+	gimple_stmt_iterator gsi;
+	tree input, output;
+
+	if (!is_size_overflow_asm(stmt))
+		return;
+
+	if (gimple_asm_noutputs(stmt) == 0) {
+		gsi = gsi_for_stmt(stmt);
+		ipa_remove_stmt_references(cgraph_get_create_node(current_function_decl), stmt);
+		gsi_remove(&gsi, true);
+		return;
+	}
+
+	input = gimple_asm_input_op(stmt, 0);
+	output = gimple_asm_output_op(stmt, 0);
+	replace_size_overflow_asm_with_assign(stmt, TREE_VALUE(output), TREE_VALUE(input));
+}
+
+/* handle the size_overflow asm stmts from the gimple pass and collect the interesting stmts.
+ * If the asm stmt is a parm_decl kind (noutputs == 0) then remove it.
+ * If it is a simple asm stmt then replace it with an assignment from the asm input to the asm output.
+ */
+static struct interesting_node *handle_stmt_by_size_overflow_asm(gimple stmt, struct interesting_node *head)
+{
+	const_tree output;
+	struct pointer_set_t *visited;
+	gimple intentional_asm = NOT_INTENTIONAL_ASM;
+
+	if (!is_size_overflow_asm(stmt))
+		return head;
+
+	if (is_size_overflow_intentional_asm_yes(stmt) || is_size_overflow_intentional_asm_turn_off(stmt))
+		intentional_asm = stmt;
+
+	gcc_assert(gimple_asm_ninputs(stmt) == 1);
+
+	if (gimple_asm_noutputs(stmt) == 0 && is_size_overflow_intentional_asm_turn_off(stmt))
+		return head;
+
+	if (gimple_asm_noutputs(stmt) == 0) {
+		const_tree input;
+
+		if (!is_size_overflow_intentional_asm_turn_off(stmt))
+			return head;
+
+		input = gimple_asm_input_op(stmt, 0);
+		remove_size_overflow_asm(stmt);
+		if (is_gimple_constant(TREE_VALUE(input)))
+			return head;
+		visited = pointer_set_create();
+		head = get_interesting_ret_or_call(visited, head, TREE_VALUE(input), intentional_asm);
+		pointer_set_destroy(visited);
+		return head;
+	}
+
+	if (!is_size_overflow_intentional_asm_yes(stmt) && !is_size_overflow_intentional_asm_turn_off(stmt))
+		remove_size_overflow_asm(stmt);
+
+	visited = pointer_set_create();
+	output = gimple_asm_output_op(stmt, 0);
+	head = get_interesting_ret_or_call(visited, head, TREE_VALUE(output), intentional_asm);
+	pointer_set_destroy(visited);
+	return head;
+}
+
+/* Iterate over all the stmts of a function and look for the size_overflow asm stmts (they were created in the gimple pass)
+ * or a call stmt or a return stmt and store them in the interesting_node list
+ */
+static struct interesting_node *collect_interesting_stmts(struct next_cgraph_node *next_node)
+{
+	basic_block bb;
+	struct interesting_node *head = NULL;
+
+	FOR_ALL_BB_FN(bb, cfun) {
+		gimple_stmt_iterator gsi;
+
+		for (gsi = gsi_start_bb(bb); !gsi_end_p(gsi); gsi_next(&gsi)) {
+			enum gimple_code code;
+			gimple stmt = gsi_stmt(gsi);
+
+			code = gimple_code(stmt);
+
+			if (code == GIMPLE_ASM)
+				head = handle_stmt_by_size_overflow_asm(stmt, head);
+
+			if (!next_node)
+				continue;
+			if (code == GIMPLE_CALL)
+				head = handle_stmt_by_cgraph_nodes_call(head, stmt, next_node);
+			if (code == GIMPLE_RETURN)
+				head = handle_stmt_by_cgraph_nodes_ret(head, stmt, next_node);
+		}
+	}
+	return head;
+}
+
+static void free_interesting_node(struct interesting_node *head)
+{
+	struct interesting_node *cur;
+
+	while (head) {
+		cur = head->next;
+#if BUILDING_GCC_VERSION <= 4007
+		VEC_free(tree, gc, head->last_nodes);
+#else
+		vec_free(head->last_nodes);
+#endif
+		free(head);
+		head = cur;
+	}
+}
+
+static struct visited_fns *insert_visited_fns_function(struct visited_fns *head, struct interesting_node *cur_node)
+{
+	struct visited_fns *new_visited_fns;
+
+	new_visited_fns = (struct visited_fns *)xmalloc(sizeof(*new_visited_fns));
+	new_visited_fns->fndecl = cur_node->fndecl;
+	new_visited_fns->num = cur_node->num;
+	new_visited_fns->first_stmt = cur_node->first_stmt;
+	new_visited_fns->next = NULL;
+
+	if (!head)
+		return new_visited_fns;
+
+	new_visited_fns->next = head;
+	return new_visited_fns;
+}
+
+/* Check whether the function was already visited_fns. If the fndecl, the arg count of the fndecl and the first_stmt (call or return) are same then
+ * it is a visited_fns function.
+ */
+static bool is_visited_fns_function(struct visited_fns *head, struct interesting_node *cur_node)
+{
+	struct visited_fns *cur;
+
+	if (!head)
+		return false;
+
+	for (cur = head; cur; cur = cur->next) {
+		if (cur_node->first_stmt != cur->first_stmt)
+			continue;
+		if (!operand_equal_p(cur_node->fndecl, cur->fndecl, 0))
+			continue;
+		if (cur_node->num == cur->num)
+			return true;
+	}
+	return false;
+}
+
+static void free_next_cgraph_node(struct next_cgraph_node *head)
+{
+	struct next_cgraph_node *cur;
+
+	while (head) {
+		cur = head->next;
+		free(head);
+		head = cur;
+	}
+}
+
+static void remove_all_size_overflow_asm(void)
+{
+	basic_block bb;
+
+	FOR_ALL_BB_FN(bb, cfun) {
+		gimple_stmt_iterator si;
+
+		for (si = gsi_start_bb(bb); !gsi_end_p(si); gsi_next(&si))
+			remove_size_overflow_asm(gsi_stmt(si));
+	}
+}
+
+/* Main recursive walk of the ipa pass: iterate over the collected interesting stmts in a function
+ * (they are interesting if they have an associated size_overflow asm stmt) and recursively walk
+ * the newly collected interesting functions (they are interesting if there is control flow between
+ * the interesting stmts and them).
+ */
+static struct visited_fns *handle_function(struct cgraph_node *node, struct next_cgraph_node *next_node, struct visited_fns *visited_fns)
+{
+	struct visited *visited;
+	struct interesting_node *head, *cur_node;
+	struct next_cgraph_node *cur_cnodes, *cnodes_head = NULL;
+
+	set_current_function_decl(NODE_DECL(node));
+	call_count = 0;
+
+	head = collect_interesting_stmts(next_node);
+
+	visited = create_visited();
+	for (cur_node = head; cur_node; cur_node = cur_node->next) {
+		if (is_visited_fns_function(visited_fns, cur_node))
+			continue;
+		cnodes_head = handle_interesting_stmt(visited, cnodes_head, cur_node, node);
+		visited_fns = insert_visited_fns_function(visited_fns, cur_node);
+	}
+
+	free_visited(visited);
+	free_interesting_node(head);
+	remove_all_size_overflow_asm();
+	unset_current_function_decl();
+
+	for (cur_cnodes = cnodes_head; cur_cnodes; cur_cnodes = cur_cnodes->next)
+		visited_fns = handle_function(cur_cnodes->current_function, cur_cnodes, visited_fns);
+
+	free_next_cgraph_node(cnodes_head);
+	return visited_fns;
+}
+
+static void free_visited_fns(struct visited_fns *head)
+{
+	struct visited_fns *cur;
+
+	while (head) {
+		cur = head->next;
+		free(head);
+		head = cur;
+	}
+}
+
+// Main entry point of the ipa pass: erases the plf flag of all stmts and iterates over all the functions
+unsigned int search_function(void)
+{
+	struct cgraph_node *node;
+	struct visited_fns *visited_fns = NULL;
+
+	FOR_EACH_FUNCTION_WITH_GIMPLE_BODY(node) {
+		gcc_assert(cgraph_function_flags_ready);
+#if BUILDING_GCC_VERSION <= 4007
+		gcc_assert(node->reachable);
+#endif
+
+		visited_fns = handle_function(node, NULL, visited_fns);
+	}
+
+	free_visited_fns(visited_fns);
+	return 0;
+}
+
+#if BUILDING_GCC_VERSION >= 4009
+static const struct pass_data insert_size_overflow_check_data = {
+#else
+static struct ipa_opt_pass_d insert_size_overflow_check = {
+	.pass = {
+#endif
+		.type			= SIMPLE_IPA_PASS,
+		.name			= "size_overflow",
+#if BUILDING_GCC_VERSION >= 4008
+		.optinfo_flags		= OPTGROUP_NONE,
+#endif
+#if BUILDING_GCC_VERSION >= 4009
+		.has_gate		= false,
+		.has_execute		= true,
+#else
+		.gate			= NULL,
+		.execute		= search_function,
+		.sub			= NULL,
+		.next			= NULL,
+		.static_pass_number	= 0,
+#endif
+		.tv_id			= TV_NONE,
+		.properties_required	= 0,
+		.properties_provided	= 0,
+		.properties_destroyed	= 0,
+		.todo_flags_start	= 0,
+		.todo_flags_finish	= TODO_verify_ssa | TODO_verify_stmts | TODO_remove_unused_locals | TODO_ggc_collect | TODO_verify_flow | TODO_dump_cgraph | TODO_dump_func | TODO_update_ssa_no_phi,
+#if BUILDING_GCC_VERSION < 4009
+	},
+	.generate_summary		= NULL,
+	.write_summary			= NULL,
+	.read_summary			= NULL,
+#if BUILDING_GCC_VERSION >= 4006
+	.write_optimization_summary	= NULL,
+	.read_optimization_summary	= NULL,
+#endif
+	.stmt_fixup			= NULL,
+	.function_transform_todo_flags_start		= 0,
+	.function_transform		= NULL,
+	.variable_transform		= NULL,
+#endif
+};
+
+#if BUILDING_GCC_VERSION >= 4009
+namespace {
+class insert_size_overflow_check : public ipa_opt_pass_d {
+public:
+	insert_size_overflow_check() : ipa_opt_pass_d(insert_size_overflow_check_data, g, NULL, NULL, NULL, NULL, NULL, NULL, 0, NULL, NULL) {}
+	unsigned int execute() { return search_function(); }
+};
+}
+#endif
+
+struct opt_pass *make_insert_size_overflow_check(void)
+{
+#if BUILDING_GCC_VERSION >= 4009
+	return new insert_size_overflow_check();
+#else
+	return &insert_size_overflow_check.pass;
+#endif
+}
+
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/intentional_overflow.c linux-3.2.71-pax/tools/gcc/size_overflow_plugin/intentional_overflow.c
--- linux-3.2.71/tools/gcc/size_overflow_plugin/intentional_overflow.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/intentional_overflow.c	2014-07-27 23:41:39.593093822 +0200
@@ -0,0 +1,736 @@
+/*
+ * Copyright 2011-2014 by Emese Revfy <re.emese@gmail.com>
+ * Licensed under the GPL v2, or (at your option) v3
+ *
+ * Homepage:
+ * http://www.grsecurity.net/~ephox/overflow_plugin/
+ *
+ * Documentation:
+ * http://forums.grsecurity.net/viewtopic.php?f=7&t=3043
+ *
+ * This plugin recomputes expressions of function arguments marked by a size_overflow attribute
+ * with double integer precision (DImode/TImode for 32/64 bit integer types).
+ * The recomputed argument is checked against TYPE_MAX and an event is logged on overflow and the triggering process is killed.
+ *
+ * Usage:
+ * $ make
+ * $ make run
+ */
+
+#include "gcc-common.h"
+#include "size_overflow.h"
+
+/* Get the param of the intentional_overflow attribute.
+ *   * 0: MARK_NOT_INTENTIONAL
+ *   * 1..MAX_PARAM: MARK_YES
+ *   * -1: MARK_TURN_OFF
+ */
+static tree get_attribute_param(const_tree decl)
+{
+	const_tree attr;
+
+	if (decl == NULL_TREE)
+		return NULL_TREE;
+
+	attr = lookup_attribute("intentional_overflow", DECL_ATTRIBUTES(decl));
+	if (!attr || !TREE_VALUE(attr))
+		return NULL_TREE;
+
+	return TREE_VALUE(attr);
+}
+
+// MARK_TURN_OFF
+bool is_turn_off_intentional_attr(const_tree decl)
+{
+	const_tree param_head;
+
+	param_head = get_attribute_param(decl);
+	if (param_head == NULL_TREE)
+		return false;
+
+	if (TREE_INT_CST_HIGH(TREE_VALUE(param_head)) == -1)
+		return true;
+	return false;
+}
+
+// MARK_NOT_INTENTIONAL
+bool is_end_intentional_intentional_attr(const_tree decl, unsigned int argnum)
+{
+	const_tree param_head;
+
+	if (argnum == 0)
+		return false;
+
+	param_head = get_attribute_param(decl);
+	if (param_head == NULL_TREE)
+		return false;
+
+	if (!TREE_INT_CST_LOW(TREE_VALUE(param_head)))
+		return true;
+	return false;
+}
+
+// MARK_YES
+bool is_yes_intentional_attr(const_tree decl, unsigned int argnum)
+{
+	tree param, param_head;
+
+	if (argnum == 0)
+		return false;
+
+	param_head = get_attribute_param(decl);
+	for (param = param_head; param; param = TREE_CHAIN(param))
+		if (argnum == TREE_INT_CST_LOW(TREE_VALUE(param)))
+			return true;
+	return false;
+}
+
+void print_missing_intentional(enum mark callee_attr, enum mark caller_attr, const_tree decl, unsigned int argnum)
+{
+	location_t loc;
+
+	if (caller_attr == MARK_NO || caller_attr == MARK_NOT_INTENTIONAL || caller_attr == MARK_TURN_OFF)
+		return;
+
+	if (callee_attr == MARK_NOT_INTENTIONAL || callee_attr == MARK_YES)
+		return;
+
+	loc = DECL_SOURCE_LOCATION(decl);
+	inform(loc, "The intentional_overflow attribute is missing from +%s+%u+", DECL_NAME_POINTER(decl), argnum);
+}
+
+// Get the field decl of a component ref for intentional_overflow checking
+static const_tree search_field_decl(const_tree comp_ref)
+{
+	const_tree field = NULL_TREE;
+	unsigned int i, len = TREE_OPERAND_LENGTH(comp_ref);
+
+	for (i = 0; i < len; i++) {
+		field = TREE_OPERAND(comp_ref, i);
+		if (TREE_CODE(field) == FIELD_DECL)
+			break;
+	}
+	gcc_assert(TREE_CODE(field) == FIELD_DECL);
+	return field;
+}
+
+/* Get the type of the intentional_overflow attribute of a node
+ *  * MARK_TURN_OFF
+ *  * MARK_YES
+ *  * MARK_NO
+ *  * MARK_NOT_INTENTIONAL
+ */
+enum mark get_intentional_attr_type(const_tree node)
+{
+	const_tree cur_decl;
+
+	if (node == NULL_TREE)
+		return MARK_NO;
+
+	switch (TREE_CODE(node)) {
+	case COMPONENT_REF:
+		cur_decl = search_field_decl(node);
+		if (is_turn_off_intentional_attr(cur_decl))
+			return MARK_TURN_OFF;
+		if (is_end_intentional_intentional_attr(cur_decl, 1))
+			return MARK_YES;
+		break;
+	case PARM_DECL: {
+		unsigned int argnum;
+
+		cur_decl = DECL_ORIGIN(current_function_decl);
+		argnum = find_arg_number_tree(node, cur_decl);
+		if (argnum == CANNOT_FIND_ARG)
+			return MARK_NO;
+		if (is_yes_intentional_attr(cur_decl, argnum))
+			return MARK_YES;
+		if (is_end_intentional_intentional_attr(cur_decl, argnum))
+			return MARK_NOT_INTENTIONAL;
+		break;
+	}
+	case FUNCTION_DECL:
+		if (is_turn_off_intentional_attr(DECL_ORIGIN(node)))
+			return MARK_TURN_OFF;
+		break;
+	default:
+		break;
+	}
+	return MARK_NO;
+}
+
+// Search for the intentional_overflow attribute on the last nodes
+static enum mark search_last_nodes_intentional(struct interesting_node *cur_node)
+{
+	unsigned int i;
+	tree last_node;
+	enum mark mark = MARK_NO;
+
+#if BUILDING_GCC_VERSION <= 4007
+	FOR_EACH_VEC_ELT(tree, cur_node->last_nodes, i, last_node) {
+#else
+	FOR_EACH_VEC_ELT(*cur_node->last_nodes, i, last_node) {
+#endif
+		mark = get_intentional_attr_type(last_node);
+		if (mark != MARK_NO)
+			break;
+	}
+	return mark;
+}
+
+/* Check the intentional kind of size_overflow asm stmt (created by the gimple pass) and
+ * set the appropriate intentional_overflow type. Delete the asm stmt in the end.
+ */
+static bool is_intentional_attribute_from_gimple(struct interesting_node *cur_node)
+{
+	if (!cur_node->intentional_mark_from_gimple)
+		return false;
+
+	if (is_size_overflow_intentional_asm_yes(cur_node->intentional_mark_from_gimple))
+		cur_node->intentional_attr_cur_fndecl = MARK_YES;
+	else
+		cur_node->intentional_attr_cur_fndecl = MARK_TURN_OFF;
+
+	// skip param decls
+	if (gimple_asm_noutputs(cur_node->intentional_mark_from_gimple) == 0)
+		return true;
+	return true;
+}
+
+/* Search intentional_overflow attribute on caller and on callee too.
+ * 0</MARK_YES: no dup, search size_overflow and intentional_overflow attributes
+ * 0/MARK_NOT_INTENTIONAL: no dup, search size_overflow attribute (int)
+ * -1/MARK_TURN_OFF: no dup, no search, current_function_decl -> no dup
+*/
+void check_intentional_attribute_ipa(struct interesting_node *cur_node)
+{
+	const_tree fndecl;
+
+	if (is_intentional_attribute_from_gimple(cur_node))
+		return;
+
+	if (is_turn_off_intentional_attr(DECL_ORIGIN(current_function_decl))) {
+		cur_node->intentional_attr_cur_fndecl = MARK_TURN_OFF;
+		return;
+	}
+
+	if (gimple_code(cur_node->first_stmt) == GIMPLE_ASM) {
+		cur_node->intentional_attr_cur_fndecl = MARK_NOT_INTENTIONAL;
+		return;
+	}
+
+	if (gimple_code(cur_node->first_stmt) == GIMPLE_ASSIGN)
+		return;
+
+	fndecl = get_interesting_orig_fndecl(cur_node->first_stmt, cur_node->num);
+	if (is_turn_off_intentional_attr(fndecl)) {
+		cur_node->intentional_attr_decl = MARK_TURN_OFF;
+		return;
+	}
+
+	if (is_end_intentional_intentional_attr(fndecl, cur_node->num))
+		cur_node->intentional_attr_decl = MARK_NOT_INTENTIONAL;
+	else if (is_yes_intentional_attr(fndecl, cur_node->num))
+		cur_node->intentional_attr_decl = MARK_YES;
+
+	cur_node->intentional_attr_cur_fndecl = search_last_nodes_intentional(cur_node);
+	print_missing_intentional(cur_node->intentional_attr_decl, cur_node->intentional_attr_cur_fndecl, cur_node->fndecl, cur_node->num);
+}
+
+bool is_a_cast_and_const_overflow(const_tree no_const_rhs)
+{
+	const_tree rhs1, lhs, rhs1_type, lhs_type;
+	enum machine_mode lhs_mode, rhs_mode;
+	gimple def_stmt = get_def_stmt(no_const_rhs);
+
+	if (!def_stmt || !gimple_assign_cast_p(def_stmt))
+		return false;
+
+	rhs1 = gimple_assign_rhs1(def_stmt);
+	lhs = gimple_assign_lhs(def_stmt);
+	rhs1_type = TREE_TYPE(rhs1);
+	lhs_type = TREE_TYPE(lhs);
+	rhs_mode = TYPE_MODE(rhs1_type);
+	lhs_mode = TYPE_MODE(lhs_type);
+	if (TYPE_UNSIGNED(lhs_type) == TYPE_UNSIGNED(rhs1_type) || lhs_mode != rhs_mode)
+		return false;
+
+	return true;
+}
+
+static unsigned int uses_num(tree node)
+{
+	imm_use_iterator imm_iter;
+	use_operand_p use_p;
+	unsigned int num = 0;
+
+	FOR_EACH_IMM_USE_FAST(use_p, imm_iter, node) {
+		gimple use_stmt = USE_STMT(use_p);
+
+		if (use_stmt == NULL)
+			return num;
+		if (is_gimple_debug(use_stmt))
+			continue;
+		if (gimple_assign_cast_p(use_stmt) && is_size_overflow_type(gimple_assign_lhs(use_stmt)))
+			continue;
+		num++;
+	}
+	return num;
+}
+
+static bool no_uses(tree node)
+{
+	return !uses_num(node);
+}
+
+// 3.8.5 mm/page-writeback.c __ilog2_u64(): ret, uint + uintmax; uint -> int; int max
+bool is_const_plus_unsigned_signed_truncation(const_tree lhs)
+{
+	tree rhs1, lhs_type, rhs_type, rhs2, not_const_rhs;
+	gimple def_stmt = get_def_stmt(lhs);
+
+	if (!def_stmt || !gimple_assign_cast_p(def_stmt))
+		return false;
+
+	rhs1 = gimple_assign_rhs1(def_stmt);
+	rhs_type = TREE_TYPE(rhs1);
+	lhs_type = TREE_TYPE(lhs);
+	if (TYPE_UNSIGNED(lhs_type) || !TYPE_UNSIGNED(rhs_type))
+		return false;
+	if (TYPE_MODE(lhs_type) != TYPE_MODE(rhs_type))
+		return false;
+
+	def_stmt = get_def_stmt(rhs1);
+	if (!def_stmt || !is_gimple_assign(def_stmt) || gimple_num_ops(def_stmt) != 3)
+		return false;
+
+	if (gimple_assign_rhs_code(def_stmt) != PLUS_EXPR)
+		return false;
+
+	rhs1 = gimple_assign_rhs1(def_stmt);
+	rhs2 = gimple_assign_rhs2(def_stmt);
+	if (!is_gimple_constant(rhs1) && !is_gimple_constant(rhs2))
+		return false;
+
+	if (is_gimple_constant(rhs2))
+		not_const_rhs = rhs1;
+	else
+		not_const_rhs = rhs2;
+
+	return no_uses(not_const_rhs);
+}
+
+static bool is_lt_signed_type_max(const_tree rhs)
+{
+	const_tree new_type, type_max, type = TREE_TYPE(rhs);
+
+	if (!TYPE_UNSIGNED(type))
+		return true;
+
+	switch (TYPE_MODE(type)) {
+	case QImode:
+		new_type = intQI_type_node;
+		break;
+	case HImode:
+		new_type = intHI_type_node;
+		break;
+	case SImode:
+		new_type = intSI_type_node;
+		break;
+	case DImode:
+		new_type = intDI_type_node;
+		break;
+	default:
+		debug_tree((tree)type);
+		gcc_unreachable();
+	}
+
+	type_max = TYPE_MAX_VALUE(new_type);
+	if (!tree_int_cst_lt(type_max, rhs))
+		return true;
+
+	return false;
+}
+
+static bool is_gt_zero(const_tree rhs)
+{
+	const_tree type = TREE_TYPE(rhs);
+
+	if (TYPE_UNSIGNED(type))
+		return true;
+
+	if (!tree_int_cst_lt(rhs, integer_zero_node))
+		return true;
+
+	return false;
+}
+
+bool is_a_constant_overflow(const_gimple stmt, const_tree rhs)
+{
+	if (gimple_assign_rhs_code(stmt) == MIN_EXPR)
+		return false;
+	if (!is_gimple_constant(rhs))
+		return false;
+
+	// If the const is between 0 and the max value of the signed type of the same bitsize then there is no intentional overflow
+	if (is_lt_signed_type_max(rhs) && is_gt_zero(rhs))
+		return false;
+
+	return true;
+}
+
+static tree change_assign_rhs(struct visited *visited, gimple stmt, const_tree orig_rhs, tree new_rhs)
+{
+	gimple assign;
+	gimple_stmt_iterator gsi = gsi_for_stmt(stmt);
+	tree origtype = TREE_TYPE(orig_rhs);
+
+	gcc_assert(is_gimple_assign(stmt));
+
+	assign = build_cast_stmt(visited, origtype, new_rhs, CREATE_NEW_VAR, &gsi, BEFORE_STMT, false);
+	pointer_set_insert(visited->my_stmts, assign);
+	return gimple_assign_lhs(assign);
+}
+
+tree handle_intentional_overflow(struct visited *visited, struct cgraph_node *caller_node, bool check_overflow, gimple stmt, tree change_rhs, tree new_rhs2)
+{
+	tree new_rhs, orig_rhs;
+	void (*gimple_assign_set_rhs)(gimple, tree);
+	tree rhs1 = gimple_assign_rhs1(stmt);
+	tree rhs2 = gimple_assign_rhs2(stmt);
+	tree lhs = gimple_assign_lhs(stmt);
+
+	if (!check_overflow)
+		return create_assign(visited, stmt, lhs, AFTER_STMT);
+
+	if (change_rhs == NULL_TREE)
+		return create_assign(visited, stmt, lhs, AFTER_STMT);
+
+	if (new_rhs2 == NULL_TREE) {
+		orig_rhs = rhs1;
+		gimple_assign_set_rhs = &gimple_assign_set_rhs1;
+	} else {
+		orig_rhs = rhs2;
+		gimple_assign_set_rhs = &gimple_assign_set_rhs2;
+	}
+
+	check_size_overflow(caller_node, stmt, TREE_TYPE(change_rhs), change_rhs, orig_rhs, BEFORE_STMT);
+
+	new_rhs = change_assign_rhs(visited, stmt, orig_rhs, change_rhs);
+	gimple_assign_set_rhs(stmt, new_rhs);
+	update_stmt(stmt);
+
+	return create_assign(visited, stmt, lhs, AFTER_STMT);
+}
+
+static bool is_subtraction_special(struct visited *visited, const_gimple stmt)
+{
+	gimple rhs1_def_stmt, rhs2_def_stmt;
+	const_tree rhs1_def_stmt_rhs1, rhs2_def_stmt_rhs1, rhs1_def_stmt_lhs, rhs2_def_stmt_lhs;
+	enum machine_mode rhs1_def_stmt_rhs1_mode, rhs2_def_stmt_rhs1_mode, rhs1_def_stmt_lhs_mode, rhs2_def_stmt_lhs_mode;
+	const_tree rhs1 = gimple_assign_rhs1(stmt);
+	const_tree rhs2 = gimple_assign_rhs2(stmt);
+
+	if (is_gimple_constant(rhs1) || is_gimple_constant(rhs2))
+		return false;
+
+	gcc_assert(TREE_CODE(rhs1) == SSA_NAME && TREE_CODE(rhs2) == SSA_NAME);
+
+	if (gimple_assign_rhs_code(stmt) != MINUS_EXPR)
+		return false;
+
+	rhs1_def_stmt = get_def_stmt(rhs1);
+	rhs2_def_stmt = get_def_stmt(rhs2);
+	if (!gimple_assign_cast_p(rhs1_def_stmt) || !gimple_assign_cast_p(rhs2_def_stmt))
+		return false;
+
+	rhs1_def_stmt_rhs1 = gimple_assign_rhs1(rhs1_def_stmt);
+	rhs2_def_stmt_rhs1 = gimple_assign_rhs1(rhs2_def_stmt);
+	rhs1_def_stmt_lhs = gimple_assign_lhs(rhs1_def_stmt);
+	rhs2_def_stmt_lhs = gimple_assign_lhs(rhs2_def_stmt);
+	rhs1_def_stmt_rhs1_mode = TYPE_MODE(TREE_TYPE(rhs1_def_stmt_rhs1));
+	rhs2_def_stmt_rhs1_mode = TYPE_MODE(TREE_TYPE(rhs2_def_stmt_rhs1));
+	rhs1_def_stmt_lhs_mode = TYPE_MODE(TREE_TYPE(rhs1_def_stmt_lhs));
+	rhs2_def_stmt_lhs_mode = TYPE_MODE(TREE_TYPE(rhs2_def_stmt_lhs));
+	if (GET_MODE_BITSIZE(rhs1_def_stmt_rhs1_mode) <= GET_MODE_BITSIZE(rhs1_def_stmt_lhs_mode))
+		return false;
+	if (GET_MODE_BITSIZE(rhs2_def_stmt_rhs1_mode) <= GET_MODE_BITSIZE(rhs2_def_stmt_lhs_mode))
+		return false;
+
+	pointer_set_insert(visited->no_cast_check, rhs1_def_stmt);
+	pointer_set_insert(visited->no_cast_check, rhs2_def_stmt);
+	return true;
+}
+
+static gimple create_binary_assign(struct visited *visited, enum tree_code code, gimple stmt, tree rhs1, tree rhs2)
+{
+	gimple assign;
+	gimple_stmt_iterator gsi = gsi_for_stmt(stmt);
+	tree type = TREE_TYPE(rhs1);
+	tree lhs = create_new_var(type);
+
+	gcc_assert(types_compatible_p(type, TREE_TYPE(rhs2)));
+	assign = gimple_build_assign_with_ops(code, lhs, rhs1, rhs2);
+	gimple_assign_set_lhs(assign, make_ssa_name(lhs, assign));
+
+	gsi_insert_before(&gsi, assign, GSI_NEW_STMT);
+	update_stmt(assign);
+	pointer_set_insert(visited->my_stmts, assign);
+	return assign;
+}
+
+static tree cast_to_TI_type(struct visited *visited, gimple stmt, tree node)
+{
+	gimple_stmt_iterator gsi;
+	gimple cast_stmt;
+	tree type = TREE_TYPE(node);
+
+	if (types_compatible_p(type, intTI_type_node))
+		return node;
+
+	gsi = gsi_for_stmt(stmt);
+	cast_stmt = build_cast_stmt(visited, intTI_type_node, node, CREATE_NEW_VAR, &gsi, BEFORE_STMT, false);
+	pointer_set_insert(visited->my_stmts, cast_stmt);
+	return gimple_assign_lhs(cast_stmt);
+}
+
+static tree get_def_stmt_rhs(struct visited *visited, const_tree var)
+{
+	tree rhs1, def_stmt_rhs1;
+	gimple rhs1_def_stmt, def_stmt_rhs1_def_stmt, def_stmt;
+
+	def_stmt = get_def_stmt(var);
+	if (!gimple_assign_cast_p(def_stmt))
+		return NULL_TREE;
+	gcc_assert(gimple_code(def_stmt) != GIMPLE_NOP && pointer_set_contains(visited->my_stmts, def_stmt) && gimple_assign_cast_p(def_stmt));
+
+	rhs1 = gimple_assign_rhs1(def_stmt);
+	rhs1_def_stmt = get_def_stmt(rhs1);
+	if (!gimple_assign_cast_p(rhs1_def_stmt))
+		return rhs1;
+
+	def_stmt_rhs1 = gimple_assign_rhs1(rhs1_def_stmt);
+	def_stmt_rhs1_def_stmt = get_def_stmt(def_stmt_rhs1);
+
+	switch (gimple_code(def_stmt_rhs1_def_stmt)) {
+	case GIMPLE_CALL:
+	case GIMPLE_NOP:
+	case GIMPLE_ASM:
+	case GIMPLE_PHI:
+		return def_stmt_rhs1;
+	case GIMPLE_ASSIGN:
+		return rhs1;
+	default:
+		debug_gimple_stmt(def_stmt_rhs1_def_stmt);
+		gcc_unreachable();
+	}
+}
+
+tree handle_integer_truncation(struct visited *visited, struct cgraph_node *caller_node, const_tree lhs)
+{
+	tree new_rhs1, new_rhs2;
+	tree new_rhs1_def_stmt_rhs1, new_rhs2_def_stmt_rhs1, new_lhs;
+	gimple assign, stmt = get_def_stmt(lhs);
+	tree rhs1 = gimple_assign_rhs1(stmt);
+	tree rhs2 = gimple_assign_rhs2(stmt);
+
+	if (!is_subtraction_special(visited, stmt))
+		return NULL_TREE;
+
+	new_rhs1 = expand(visited, caller_node, rhs1);
+	new_rhs2 = expand(visited, caller_node, rhs2);
+
+	new_rhs1_def_stmt_rhs1 = get_def_stmt_rhs(visited, new_rhs1);
+	new_rhs2_def_stmt_rhs1 = get_def_stmt_rhs(visited, new_rhs2);
+
+	if (new_rhs1_def_stmt_rhs1 == NULL_TREE || new_rhs2_def_stmt_rhs1 == NULL_TREE)
+		return NULL_TREE;
+
+	if (!types_compatible_p(TREE_TYPE(new_rhs1_def_stmt_rhs1), TREE_TYPE(new_rhs2_def_stmt_rhs1))) {
+		new_rhs1_def_stmt_rhs1 = cast_to_TI_type(visited, stmt, new_rhs1_def_stmt_rhs1);
+		new_rhs2_def_stmt_rhs1 = cast_to_TI_type(visited, stmt, new_rhs2_def_stmt_rhs1);
+	}
+
+	assign = create_binary_assign(visited, MINUS_EXPR, stmt, new_rhs1_def_stmt_rhs1, new_rhs2_def_stmt_rhs1);
+	new_lhs = gimple_assign_lhs(assign);
+	check_size_overflow(caller_node, assign, TREE_TYPE(new_lhs), new_lhs, rhs1, AFTER_STMT);
+
+	return dup_assign(visited, stmt, lhs, new_rhs1, new_rhs2, NULL_TREE);
+}
+
+bool is_a_neg_overflow(const_gimple stmt, const_tree rhs)
+{
+	const_gimple def_stmt;
+
+	if (TREE_CODE(rhs) != SSA_NAME)
+		return false;
+
+	if (gimple_assign_rhs_code(stmt) != PLUS_EXPR)
+		return false;
+
+	def_stmt = get_def_stmt(rhs);
+	if (!is_gimple_assign(def_stmt) || gimple_assign_rhs_code(def_stmt) != BIT_NOT_EXPR)
+		return false;
+
+	return true;
+}
+
+/* e.g., drivers/acpi/acpica/utids.c acpi_ut_execute_CID()
+ * ((count - 1) * sizeof(struct acpi_pnp_dee_id_list) -> (count + fffffff) * 16
+ * fffffff * 16 > signed max -> truncate
+ */
+static bool look_for_mult_and_add(const_gimple stmt)
+{
+	const_tree res;
+	tree rhs1, rhs2, def_rhs1, def_rhs2, const_rhs, def_const_rhs;
+	const_gimple def_stmt;
+
+	if (!stmt || gimple_code(stmt) == GIMPLE_NOP)
+		return false;
+	if (!is_gimple_assign(stmt))
+		return false;
+	if (gimple_assign_rhs_code(stmt) != MULT_EXPR)
+		return false;
+
+	rhs1 = gimple_assign_rhs1(stmt);
+	rhs2 = gimple_assign_rhs2(stmt);
+	if (is_gimple_constant(rhs1)) {
+		const_rhs = rhs1;
+		def_stmt = get_def_stmt(rhs2);
+	} else if (is_gimple_constant(rhs2)) {
+		const_rhs = rhs2;
+		def_stmt = get_def_stmt(rhs1);
+	} else
+		return false;
+
+	if (!is_gimple_assign(def_stmt))
+		return false;
+
+	if (gimple_assign_rhs_code(def_stmt) != PLUS_EXPR && gimple_assign_rhs_code(def_stmt) != MINUS_EXPR)
+		return false;
+
+	def_rhs1 = gimple_assign_rhs1(def_stmt);
+	def_rhs2 = gimple_assign_rhs2(def_stmt);
+	if (is_gimple_constant(def_rhs1))
+		def_const_rhs = def_rhs1;
+	else if (is_gimple_constant(def_rhs2))
+		def_const_rhs = def_rhs2;
+	else
+		return false;
+
+	res = fold_binary_loc(gimple_location(def_stmt), MULT_EXPR, TREE_TYPE(const_rhs), const_rhs, def_const_rhs);
+	if (is_lt_signed_type_max(res) && is_gt_zero(res))
+		return false;
+	return true;
+}
+
+enum intentional_overflow_type add_mul_intentional_overflow(const_gimple stmt)
+{
+	const_gimple def_stmt_1, def_stmt_2;
+	const_tree rhs1, rhs2;
+	bool add_mul_rhs1, add_mul_rhs2;
+
+	rhs1 = gimple_assign_rhs1(stmt);
+	def_stmt_1 = get_def_stmt(rhs1);
+	add_mul_rhs1 = look_for_mult_and_add(def_stmt_1);
+
+	rhs2 = gimple_assign_rhs2(stmt);
+	def_stmt_2 = get_def_stmt(rhs2);
+	add_mul_rhs2 = look_for_mult_and_add(def_stmt_2);
+
+	if (add_mul_rhs1)
+		return RHS1_INTENTIONAL_OVERFLOW;
+	if (add_mul_rhs2)
+		return RHS2_INTENTIONAL_OVERFLOW;
+	return NO_INTENTIONAL_OVERFLOW;
+}
+
+static gimple get_dup_stmt(struct visited *visited, gimple stmt)
+{
+	gimple my_stmt;
+	gimple_stmt_iterator gsi = gsi_for_stmt(stmt);
+
+	gsi_next(&gsi);
+	my_stmt = gsi_stmt(gsi);
+
+	gcc_assert(pointer_set_contains(visited->my_stmts, my_stmt));
+	gcc_assert(gimple_assign_rhs_code(stmt) == gimple_assign_rhs_code(my_stmt));
+
+	return my_stmt;
+}
+
+/* unsigned type -> unary or binary assign (rhs1 or rhs2 is constant)
+ * unsigned type cast to signed type, unsigned type: no more uses
+ * e.g., lib/vsprintf.c:simple_strtol()
+ * _10 = (unsigned long int) _9
+ * _11 = -_10;
+ * _12 = (long int) _11; (_11_ no more uses)
+ */
+static bool is_call_or_cast(gimple stmt)
+{
+	return gimple_assign_cast_p(stmt) || is_gimple_call(stmt);
+}
+
+static bool is_unsigned_cast_or_call_def_stmt(const_tree node)
+{
+	const_tree rhs;
+	gimple def_stmt;
+
+	if (node == NULL_TREE)
+		return true;
+	if (is_gimple_constant(node))
+		return true;
+
+	def_stmt = get_def_stmt(node);
+	if (!def_stmt)
+		return false;
+
+	if (is_call_or_cast(def_stmt))
+		return true;
+
+	if (!is_gimple_assign(def_stmt) || gimple_num_ops(def_stmt) != 2)
+		return false;
+	rhs = gimple_assign_rhs1(def_stmt);
+	def_stmt = get_def_stmt(rhs);
+	if (!def_stmt)
+		return false;
+	return is_call_or_cast(def_stmt);
+}
+
+void unsigned_signed_cast_intentional_overflow(struct visited *visited, gimple stmt)
+{
+	unsigned int use_num;
+	gimple so_stmt;
+	const_gimple def_stmt;
+	const_tree rhs1, rhs2;
+	tree rhs = gimple_assign_rhs1(stmt);
+	tree lhs_type = TREE_TYPE(gimple_assign_lhs(stmt));
+	const_tree rhs_type = TREE_TYPE(rhs);
+
+	if (!(TYPE_UNSIGNED(rhs_type) && !TYPE_UNSIGNED(lhs_type)))
+		return;
+	if (GET_MODE_BITSIZE(TYPE_MODE(rhs_type)) != GET_MODE_BITSIZE(TYPE_MODE(lhs_type)))
+		return;
+	use_num = uses_num(rhs);
+	if (use_num != 1)
+		return;
+
+	def_stmt = get_def_stmt(rhs);
+	if (!def_stmt)
+		return;
+	if (!is_gimple_assign(def_stmt))
+		return;
+
+	rhs1 = gimple_assign_rhs1(def_stmt);
+	if (!is_unsigned_cast_or_call_def_stmt(rhs1))
+		return;
+
+	rhs2 = gimple_assign_rhs2(def_stmt);
+	if (!is_unsigned_cast_or_call_def_stmt(rhs2))
+		return;
+	if (gimple_num_ops(def_stmt) == 3 && !is_gimple_constant(rhs1) && !is_gimple_constant(rhs2))
+		return;
+
+	so_stmt = get_dup_stmt(visited, stmt);
+	create_up_and_down_cast(visited, so_stmt, lhs_type, gimple_assign_rhs1(so_stmt));
+}
+
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/Makefile linux-3.2.71-pax/tools/gcc/size_overflow_plugin/Makefile
--- linux-3.2.71/tools/gcc/size_overflow_plugin/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/Makefile	2014-06-02 18:46:28.278285436 +0200
@@ -0,0 +1,20 @@
+$(HOSTLIBS)-$(CONFIG_PAX_SIZE_OVERFLOW) += size_overflow_plugin.so
+always := $($(HOSTLIBS)-y)
+
+size_overflow_plugin-objs := $(patsubst $(srctree)/$(src)/%.c,%.o,$(wildcard $(srctree)/$(src)/*.c))
+
+$(patsubst $(srctree)/$(src)/%.c,$(obj)/%.o,$(wildcard $(srctree)/$(src)/*.c)): $(objtree)/$(obj)/size_overflow_hash.h $(objtree)/$(obj)/size_overflow_hash_aux.h
+
+quiet_cmd_build_size_overflow_hash = GENHASH  $@
+      cmd_build_size_overflow_hash = \
+	$(CONFIG_SHELL) $(srctree)/$(src)/generate_size_overflow_hash.sh -s size_overflow_hash -d $< -o $@
+$(objtree)/$(obj)/size_overflow_hash.h: $(src)/size_overflow_hash.data FORCE
+	$(call if_changed,build_size_overflow_hash)
+
+quiet_cmd_build_size_overflow_hash_aux = GENHASH  $@
+      cmd_build_size_overflow_hash_aux = \
+	$(CONFIG_SHELL) $(srctree)/$(src)/generate_size_overflow_hash.sh -s size_overflow_hash_aux -d $< -o $@
+$(objtree)/$(obj)/size_overflow_hash_aux.h: $(src)/size_overflow_hash_aux.data FORCE
+	$(call if_changed,build_size_overflow_hash_aux)
+
+targets += size_overflow_hash.h size_overflow_hash_aux.h
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/misc.c linux-3.2.71-pax/tools/gcc/size_overflow_plugin/misc.c
--- linux-3.2.71/tools/gcc/size_overflow_plugin/misc.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/misc.c	2014-06-02 18:55:20.510257019 +0200
@@ -0,0 +1,203 @@
+/*
+ * Copyright 2011-2014 by Emese Revfy <re.emese@gmail.com>
+ * Licensed under the GPL v2, or (at your option) v3
+ *
+ * Homepage:
+ * http://www.grsecurity.net/~ephox/overflow_plugin/
+ *
+ * Documentation:
+ * http://forums.grsecurity.net/viewtopic.php?f=7&t=3043
+ *
+ * This plugin recomputes expressions of function arguments marked by a size_overflow attribute
+ * with double integer precision (DImode/TImode for 32/64 bit integer types).
+ * The recomputed argument is checked against TYPE_MAX and an event is logged on overflow and the triggering process is killed.
+ *
+ * Usage:
+ * $ make
+ * $ make run
+ */
+
+#include "gcc-common.h"
+#include "size_overflow.h"
+
+void set_current_function_decl(tree fndecl)
+{
+	gcc_assert(fndecl != NULL_TREE);
+
+	push_cfun(DECL_STRUCT_FUNCTION(fndecl));
+	calculate_dominance_info(CDI_DOMINATORS);
+	current_function_decl = fndecl;
+}
+
+void unset_current_function_decl(void)
+{
+	free_dominance_info(CDI_DOMINATORS);
+	pop_cfun();
+	current_function_decl = NULL_TREE;
+}
+
+static bool is_bool(const_tree node)
+{
+	const_tree type;
+
+	if (node == NULL_TREE)
+		return false;
+
+	type = TREE_TYPE(node);
+	if (!INTEGRAL_TYPE_P(type))
+		return false;
+	if (TREE_CODE(type) == BOOLEAN_TYPE)
+		return true;
+	if (TYPE_PRECISION(type) == 1)
+		return true;
+	return false;
+}
+
+bool skip_types(const_tree var)
+{
+	tree type;
+	enum tree_code code;
+
+	if (is_gimple_constant(var))
+		return true;
+
+	switch (TREE_CODE(var)) {
+		case ADDR_EXPR:
+#if BUILDING_GCC_VERSION >= 4006
+		case MEM_REF:
+#endif
+		case ARRAY_REF:
+		case BIT_FIELD_REF:
+		case INDIRECT_REF:
+		case TARGET_MEM_REF:
+		case COMPONENT_REF:
+		case VAR_DECL:
+		case VIEW_CONVERT_EXPR:
+			return true;
+		default:
+			break;
+	}
+
+	code = TREE_CODE(var);
+	gcc_assert(code == SSA_NAME || code == PARM_DECL);
+
+	type = TREE_TYPE(var);
+	switch (TREE_CODE(type)) {
+		case INTEGER_TYPE:
+		case ENUMERAL_TYPE:
+			return false;
+		case BOOLEAN_TYPE:
+			return is_bool(var);
+		default:
+			return true;
+	}
+}
+
+gimple get_def_stmt(const_tree node)
+{
+	gcc_assert(node != NULL_TREE);
+
+	if (skip_types(node))
+		return NULL;
+
+	if (TREE_CODE(node) != SSA_NAME)
+		return NULL;
+	return SSA_NAME_DEF_STMT(node);
+}
+
+tree create_new_var(tree type)
+{
+	tree new_var = create_tmp_var(type, "cicus");
+
+	add_referenced_var(new_var);
+	return new_var;
+}
+
+static bool skip_cast(tree dst_type, const_tree rhs, bool force)
+{
+	const_gimple def_stmt = get_def_stmt(rhs);
+
+	if (force)
+		return false;
+
+	if (is_gimple_constant(rhs))
+		return false;
+
+	if (!def_stmt || gimple_code(def_stmt) == GIMPLE_NOP)
+		return false;
+
+	if (!types_compatible_p(dst_type, TREE_TYPE(rhs)))
+		return false;
+
+	// DI type can be on 32 bit (from create_assign) but overflow type stays DI
+	if (LONG_TYPE_SIZE == GET_MODE_BITSIZE(SImode))
+		return false;
+
+	return true;
+}
+
+tree cast_a_tree(tree type, tree var)
+{
+	gcc_assert(type != NULL_TREE);
+	gcc_assert(var != NULL_TREE);
+	gcc_assert(fold_convertible_p(type, var));
+
+	return fold_convert(type, var);
+}
+
+gimple build_cast_stmt(struct visited *visited, tree dst_type, tree rhs, tree lhs, gimple_stmt_iterator *gsi, bool before, bool force)
+{
+	gimple assign, def_stmt;
+
+	gcc_assert(dst_type != NULL_TREE && rhs != NULL_TREE);
+	gcc_assert(!is_gimple_constant(rhs));
+	if (gsi_end_p(*gsi) && before == AFTER_STMT)
+		gcc_unreachable();
+
+	def_stmt = get_def_stmt(rhs);
+	if (def_stmt && gimple_code(def_stmt) != GIMPLE_NOP && skip_cast(dst_type, rhs, force) && pointer_set_contains(visited->my_stmts, def_stmt))
+		return def_stmt;
+
+	if (lhs == CREATE_NEW_VAR)
+		lhs = create_new_var(dst_type);
+
+	assign = gimple_build_assign(lhs, cast_a_tree(dst_type, rhs));
+
+	if (!gsi_end_p(*gsi)) {
+		location_t loc = gimple_location(gsi_stmt(*gsi));
+		gimple_set_location(assign, loc);
+	}
+
+	gimple_assign_set_lhs(assign, make_ssa_name(lhs, assign));
+
+	if (before)
+		gsi_insert_before(gsi, assign, GSI_NEW_STMT);
+	else
+		gsi_insert_after(gsi, assign, GSI_NEW_STMT);
+	update_stmt(assign);
+	return assign;
+}
+
+bool is_size_overflow_type(const_tree var)
+{
+	const char *name;
+	const_tree type_name, type;
+
+	if (var == NULL_TREE)
+		return false;
+
+	type = TREE_TYPE(var);
+	type_name = TYPE_NAME(type);
+	if (type_name == NULL_TREE)
+		return false;
+
+	if (DECL_P(type_name))
+		name = DECL_NAME_POINTER(type_name);
+	else
+		name = IDENTIFIER_POINTER(type_name);
+
+	if (!strncmp(name, "size_overflow_type", 18))
+		return true;
+	return false;
+}
+
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/remove_unnecessary_dup.c linux-3.2.71-pax/tools/gcc/size_overflow_plugin/remove_unnecessary_dup.c
--- linux-3.2.71/tools/gcc/size_overflow_plugin/remove_unnecessary_dup.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/remove_unnecessary_dup.c	2014-06-02 19:05:58.258222968 +0200
@@ -0,0 +1,138 @@
+/*
+ * Copyright 2011-2014 by Emese Revfy <re.emese@gmail.com>
+ * Licensed under the GPL v2, or (at your option) v3
+ *
+ * Homepage:
+ * http://www.grsecurity.net/~ephox/overflow_plugin/
+ *
+ * Documentation:
+ * http://forums.grsecurity.net/viewtopic.php?f=7&t=3043
+ *
+ * This plugin recomputes expressions of function arguments marked by a size_overflow attribute
+ * with double integer precision (DImode/TImode for 32/64 bit integer types).
+ * The recomputed argument is checked against TYPE_MAX and an event is logged on overflow and the triggering process is killed.
+ *
+ * Usage:
+ * $ make
+ * $ make run
+ */
+
+#include "gcc-common.h"
+#include "size_overflow.h"
+
+bool skip_expr_on_double_type(const_gimple stmt)
+{
+	enum tree_code code = gimple_assign_rhs_code(stmt);
+
+	switch (code) {
+	case RSHIFT_EXPR:
+	case TRUNC_DIV_EXPR:
+	case CEIL_DIV_EXPR:
+	case FLOOR_DIV_EXPR:
+	case ROUND_DIV_EXPR:
+	case EXACT_DIV_EXPR:
+	case RDIV_EXPR:
+	case TRUNC_MOD_EXPR:
+	case CEIL_MOD_EXPR:
+	case FLOOR_MOD_EXPR:
+	case ROUND_MOD_EXPR:
+		return true;
+	default:
+		return false;
+	}
+}
+
+void create_up_and_down_cast(struct visited *visited, gimple use_stmt, tree orig_type, tree rhs)
+{
+	const_tree orig_rhs1;
+	tree down_lhs, new_lhs, dup_type = TREE_TYPE(rhs);
+	gimple down_cast, up_cast;
+	gimple_stmt_iterator gsi = gsi_for_stmt(use_stmt);
+
+	down_cast = build_cast_stmt(visited, orig_type, rhs, CREATE_NEW_VAR, &gsi, BEFORE_STMT, false);
+	down_lhs = gimple_assign_lhs(down_cast);
+
+	gsi = gsi_for_stmt(use_stmt);
+	up_cast = build_cast_stmt(visited, dup_type, down_lhs, CREATE_NEW_VAR, &gsi, BEFORE_STMT, false);
+	new_lhs = gimple_assign_lhs(up_cast);
+
+	orig_rhs1 = gimple_assign_rhs1(use_stmt);
+	if (operand_equal_p(orig_rhs1, rhs, 0))
+		gimple_assign_set_rhs1(use_stmt, new_lhs);
+	else
+		gimple_assign_set_rhs2(use_stmt, new_lhs);
+	update_stmt(use_stmt);
+
+	pointer_set_insert(visited->my_stmts, up_cast);
+	pointer_set_insert(visited->my_stmts, down_cast);
+	pointer_set_insert(visited->skip_expr_casts, up_cast);
+	pointer_set_insert(visited->skip_expr_casts, down_cast);
+}
+
+static tree get_proper_unsigned_half_type(const_tree node)
+{
+	tree new_type, type;
+
+	gcc_assert(is_size_overflow_type(node));
+
+	type = TREE_TYPE(node);
+	switch (TYPE_MODE(type)) {
+	case HImode:
+		new_type = unsigned_intQI_type_node;
+		break;
+	case SImode:
+		new_type = unsigned_intHI_type_node;
+		break;
+	case DImode:
+		new_type = unsigned_intSI_type_node;
+		break;
+	case TImode:
+		new_type = unsigned_intDI_type_node;
+		break;
+	default:
+		gcc_unreachable();
+	}
+
+	if (TYPE_QUALS(type) != 0)
+		return build_qualified_type(new_type, TYPE_QUALS(type));
+	return new_type;
+}
+
+static void insert_cast_rhs(struct visited *visited, gimple stmt, tree rhs)
+{
+	tree type;
+
+	if (rhs == NULL_TREE)
+		return;
+	if (!is_size_overflow_type(rhs))
+		return;
+
+	type = get_proper_unsigned_half_type(rhs);
+	if (is_gimple_constant(rhs))
+		return;
+	create_up_and_down_cast(visited, stmt, type, rhs);
+}
+
+static void insert_cast(struct visited *visited, gimple stmt, tree rhs)
+{
+	if (LONG_TYPE_SIZE == GET_MODE_BITSIZE(SImode) && !is_size_overflow_type(rhs))
+		return;
+	gcc_assert(is_size_overflow_type(rhs));
+	insert_cast_rhs(visited, stmt, rhs);
+}
+
+void insert_cast_expr(struct visited *visited, gimple stmt, enum intentional_overflow_type type)
+{
+	tree rhs1, rhs2;
+
+	if (type == NO_INTENTIONAL_OVERFLOW || type == RHS1_INTENTIONAL_OVERFLOW) {
+		rhs1 = gimple_assign_rhs1(stmt);
+		insert_cast(visited, stmt, rhs1);
+	}
+
+	if (type == NO_INTENTIONAL_OVERFLOW || type == RHS2_INTENTIONAL_OVERFLOW) {
+		rhs2 = gimple_assign_rhs2(stmt);
+		insert_cast(visited, stmt, rhs2);
+	}
+}
+
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/size_overflow_debug.c linux-3.2.71-pax/tools/gcc/size_overflow_plugin/size_overflow_debug.c
--- linux-3.2.71/tools/gcc/size_overflow_plugin/size_overflow_debug.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/size_overflow_debug.c	2014-06-02 18:46:28.278285436 +0200
@@ -0,0 +1,116 @@
+/*
+ * Copyright 2011-2014 by Emese Revfy <re.emese@gmail.com>
+ * Licensed under the GPL v2, or (at your option) v3
+ *
+ * Homepage:
+ * http://www.grsecurity.net/~ephox/overflow_plugin/
+ *
+ * Documentation:
+ * http://forums.grsecurity.net/viewtopic.php?f=7&t=3043
+ *
+ * This plugin recomputes expressions of function arguments marked by a size_overflow attribute
+ * with double integer precision (DImode/TImode for 32/64 bit integer types).
+ * The recomputed argument is checked against TYPE_MAX and an event is logged on overflow and the triggering process is killed.
+ *
+ * Usage:
+ * $ make
+ * $ make run
+ */
+
+#include "gcc-common.h"
+
+static unsigned int dump_functions(void)
+{
+	struct cgraph_node *node;
+
+	FOR_EACH_FUNCTION_WITH_GIMPLE_BODY(node) {
+		basic_block bb;
+
+		push_cfun(DECL_STRUCT_FUNCTION(NODE_DECL(node)));
+		current_function_decl = NODE_DECL(node);
+
+		fprintf(stderr, "-----------------------------------------\n%s\n-----------------------------------------\n", DECL_NAME_POINTER(current_function_decl));
+
+		FOR_ALL_BB_FN(bb, cfun) {
+			gimple_stmt_iterator si;
+
+			fprintf(stderr, "<bb %u>:\n", bb->index);
+			for (si = gsi_start_phis(bb); !gsi_end_p(si); gsi_next(&si))
+				debug_gimple_stmt(gsi_stmt(si));
+			for (si = gsi_start_bb(bb); !gsi_end_p(si); gsi_next(&si))
+				debug_gimple_stmt(gsi_stmt(si));
+			fprintf(stderr, "\n");
+		}
+
+		fprintf(stderr, "-------------------------------------------------------------------------\n");
+
+		pop_cfun();
+		current_function_decl = NULL_TREE;
+	}
+
+	fprintf(stderr, "###############################################################################\n");
+
+	return 0;
+}
+
+#if BUILDING_GCC_VERSION >= 4009
+static const struct pass_data dump_pass_data = {
+#else
+static struct ipa_opt_pass_d dump_pass = {
+	.pass = {
+#endif
+		.type			= SIMPLE_IPA_PASS,
+		.name			= "dump",
+#if BUILDING_GCC_VERSION >= 4008
+		.optinfo_flags		= OPTGROUP_NONE,
+#endif
+#if BUILDING_GCC_VERSION >= 4009
+		.has_gate		= false,
+		.has_execute		= true,
+#else
+		.gate			= NULL,
+		.execute		= dump_functions,
+		.sub			= NULL,
+		.next			= NULL,
+		.static_pass_number	= 0,
+#endif
+		.tv_id			= TV_NONE,
+		.properties_required	= 0,
+		.properties_provided	= 0,
+		.properties_destroyed	= 0,
+		.todo_flags_start	= 0,
+		.todo_flags_finish	= 0,
+#if BUILDING_GCC_VERSION < 4009
+	},
+	.generate_summary		= NULL,
+	.write_summary			= NULL,
+	.read_summary			= NULL,
+#if BUILDING_GCC_VERSION >= 4006
+	.write_optimization_summary	= NULL,
+	.read_optimization_summary	= NULL,
+#endif
+	.stmt_fixup			= NULL,
+	.function_transform_todo_flags_start		= 0,
+	.function_transform		= NULL,
+	.variable_transform		= NULL,
+#endif
+};
+
+#if BUILDING_GCC_VERSION >= 4009
+namespace {
+class dump_pass : public ipa_opt_pass_d {
+public:
+	dump_pass() : ipa_opt_pass_d(dump_pass_data, g, NULL, NULL, NULL, NULL, NULL, NULL, 0, NULL, NULL) {}
+	unsigned int execute() { return dump_functions(); }
+};
+}
+#endif
+
+struct opt_pass *make_dump_pass(void)
+{
+#if BUILDING_GCC_VERSION >= 4009
+	return new dump_pass();
+#else
+	return &dump_pass.pass;
+#endif
+}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/size_overflow.h linux-3.2.71-pax/tools/gcc/size_overflow_plugin/size_overflow.h
--- linux-3.2.71/tools/gcc/size_overflow_plugin/size_overflow.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/size_overflow.h	2015-04-30 03:15:24.116546088 +0200
@@ -0,0 +1,127 @@
+#ifndef SIZE_OVERFLOW_H
+#define SIZE_OVERFLOW_H
+
+#define CREATE_NEW_VAR NULL_TREE
+#define CANNOT_FIND_ARG 32
+#define MAX_PARAM 31
+#define BEFORE_STMT true
+#define AFTER_STMT false
+
+#define TURN_OFF_ASM_STR "# size_overflow MARK_TURN_OFF "
+#define YES_ASM_STR "# size_overflow MARK_YES "
+#define OK_ASM_STR "# size_overflow "
+
+enum mark {
+	MARK_NO, MARK_YES, MARK_NOT_INTENTIONAL, MARK_TURN_OFF
+};
+
+enum intentional_overflow_type {
+	NO_INTENTIONAL_OVERFLOW, RHS1_INTENTIONAL_OVERFLOW, RHS2_INTENTIONAL_OVERFLOW
+};
+
+struct visited {
+	struct pointer_set_t *stmts;
+	struct pointer_set_t *my_stmts;
+	struct pointer_set_t *skip_expr_casts;
+	struct pointer_set_t *no_cast_check;
+};
+
+// size_overflow_plugin.c
+extern GTY(()) tree report_size_overflow_decl;
+extern GTY(()) tree size_overflow_type_HI;
+extern GTY(()) tree size_overflow_type_SI;
+extern GTY(()) tree size_overflow_type_DI;
+extern GTY(()) tree size_overflow_type_TI;
+
+
+// size_overflow_plugin_hash.c
+struct size_overflow_hash {
+	const struct size_overflow_hash * const next;
+	const char * const name;
+	const unsigned int param;
+};
+
+struct interesting_node {
+	struct interesting_node *next;
+	gimple first_stmt;
+	const_tree fndecl;
+	tree node;
+#if BUILDING_GCC_VERSION <= 4007
+	VEC(tree, gc) *last_nodes;
+#else
+	vec<tree, va_gc> *last_nodes;
+#endif
+	unsigned int num;
+	enum mark intentional_attr_decl;
+	enum mark intentional_attr_cur_fndecl;
+	gimple intentional_mark_from_gimple;
+};
+
+extern bool is_size_overflow_asm(const_gimple stmt);
+extern unsigned int get_function_num(const_tree node, const_tree orig_fndecl);
+extern unsigned int get_correct_arg_count(unsigned int argnum, const_tree fndecl);
+extern bool is_missing_function(const_tree orig_fndecl, unsigned int num);
+extern bool is_a_return_check(const_tree node);
+extern const struct size_overflow_hash *get_function_hash(const_tree fndecl);
+extern unsigned int find_arg_number_tree(const_tree arg, const_tree func);
+
+
+// size_overflow_debug.c
+extern struct opt_pass *make_dump_pass(void);
+
+
+// intentional_overflow.c
+extern enum mark get_intentional_attr_type(const_tree node);
+extern bool is_size_overflow_intentional_asm_yes(const_gimple stmt);
+extern bool is_size_overflow_intentional_asm_turn_off(const_gimple stmt);
+extern bool is_end_intentional_intentional_attr(const_tree decl, unsigned int argnum);
+extern bool is_yes_intentional_attr(const_tree decl, unsigned int argnum);
+extern bool is_turn_off_intentional_attr(const_tree decl);
+extern void print_missing_intentional(enum mark callee_attr, enum mark caller_attr, const_tree decl, unsigned int argnum);
+extern void check_intentional_attribute_ipa(struct interesting_node *cur_node);
+extern bool is_a_cast_and_const_overflow(const_tree no_const_rhs);
+extern bool is_const_plus_unsigned_signed_truncation(const_tree lhs);
+extern bool is_a_constant_overflow(const_gimple stmt, const_tree rhs);
+extern tree handle_intentional_overflow(struct visited *visited, struct cgraph_node *caller_node, bool check_overflow, gimple stmt, tree change_rhs, tree new_rhs2);
+extern tree handle_integer_truncation(struct visited *visited, struct cgraph_node *caller_node, const_tree lhs);
+extern bool is_a_neg_overflow(const_gimple stmt, const_tree rhs);
+extern enum intentional_overflow_type add_mul_intentional_overflow(const_gimple def_stmt);
+extern void unsigned_signed_cast_intentional_overflow(struct visited *visited, gimple stmt);
+
+
+// insert_size_overflow_check_ipa.c
+extern unsigned int search_function(void);
+extern unsigned int call_count;
+extern struct opt_pass *make_insert_size_overflow_check(void);
+extern const_tree get_interesting_orig_fndecl(const_gimple stmt, unsigned int argnum);
+
+
+// insert_size_overflow_asm.c
+extern struct opt_pass *make_insert_size_overflow_asm_pass(void);
+
+
+// misc.c
+extern void set_current_function_decl(tree fndecl);
+extern void unset_current_function_decl(void);
+extern gimple get_def_stmt(const_tree node);
+extern tree create_new_var(tree type);
+extern gimple build_cast_stmt(struct visited *visited, tree dst_type, tree rhs, tree lhs, gimple_stmt_iterator *gsi, bool before, bool force);
+extern bool skip_types(const_tree var);
+extern tree cast_a_tree(tree type, tree var);
+extern bool is_size_overflow_type(const_tree var);
+
+
+// insert_size_overflow_check_core.c
+extern tree expand(struct visited *visited, struct cgraph_node *caller_node, tree lhs);
+extern void check_size_overflow(struct cgraph_node *caller_node, gimple stmt, tree size_overflow_type, tree cast_rhs, tree rhs, bool before);
+extern tree dup_assign(struct visited *visited, gimple oldstmt, const_tree node, tree rhs1, tree rhs2, tree __unused rhs3);
+extern tree create_assign(struct visited *visited, gimple oldstmt, tree rhs1, bool before);
+
+
+// remove_unnecessary_dup.c
+extern struct opt_pass *make_remove_unnecessary_dup_pass(void);
+extern void insert_cast_expr(struct visited *visited, gimple stmt, enum intentional_overflow_type type);
+extern bool skip_expr_on_double_type(const_gimple stmt);
+extern void create_up_and_down_cast(struct visited *visited, gimple use_stmt, tree orig_type, tree rhs);
+
+#endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/size_overflow_hash_aux.data linux-3.2.71-pax/tools/gcc/size_overflow_plugin/size_overflow_hash_aux.data
--- linux-3.2.71/tools/gcc/size_overflow_plugin/size_overflow_hash_aux.data	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/size_overflow_hash_aux.data	2014-04-18 00:55:39.852449728 +0200
@@ -0,0 +1,91 @@
+spa_set_aux_vdevs_746 spa_set_aux_vdevs 3 746 NULL
+zfs_lookup_2144 zfs_lookup 0 2144 NULL
+mappedread_2627 mappedread 2 2627 NULL
+vdev_disk_dio_alloc_2957 vdev_disk_dio_alloc 1 2957 NULL
+nv_alloc_pushpage_spl_4286 nv_alloc_pushpage_spl 2 4286 NULL
+zpl_xattr_get_4574 zpl_xattr_get 0 4574 NULL
+sa_replace_all_by_template_5699 sa_replace_all_by_template 3 5699 NULL
+dmu_write_6048 dmu_write 4-3 6048 NULL
+dmu_buf_hold_array_6095 dmu_buf_hold_array 4-3 6095 NULL
+update_pages_6225 update_pages 2-3 6225 NULL
+bio_nr_pages_7117 bio_nr_pages 0-2 7117 NULL
+dmu_buf_hold_array_by_bonus_8562 dmu_buf_hold_array_by_bonus 3-2 8562 NULL
+zpios_dmu_write_8858 zpios_dmu_write 4-5 8858 NULL
+ddi_copyout_9401 ddi_copyout 3 9401 NULL
+avl_numnodes_12384 avl_numnodes 0 12384 NULL
+dmu_write_uio_dnode_12473 dmu_write_uio_dnode 3 12473 NULL
+dmu_xuio_init_12866 dmu_xuio_init 2 12866 NULL
+zpl_read_common_14389 zpl_read_common 0 14389 NULL
+dmu_snapshot_realname_14632 dmu_snapshot_realname 4 14632 NULL
+kmem_alloc_debug_14852 kmem_alloc_debug 1 14852 NULL
+kmalloc_node_nofail_15151 kmalloc_node_nofail 1 15151 NULL
+dmu_write_uio_16351 dmu_write_uio 4 16351 NULL
+zfs_log_write_16524 zfs_log_write 6-5 16524 NULL
+sa_build_layouts_16910 sa_build_layouts 3 16910 NULL
+dsl_dir_namelen_17053 dsl_dir_namelen 0 17053 NULL
+kcopy_copy_to_user_17336 kcopy_copy_to_user 5 17336 NULL
+sa_add_layout_entry_17507 sa_add_layout_entry 3 17507 NULL
+sa_attr_table_setup_18029 sa_attr_table_setup 3 18029 NULL
+uiocopy_18680 uiocopy 2 18680 NULL
+dmu_buf_hold_array_by_dnode_19125 dmu_buf_hold_array_by_dnode 2-3 19125 NULL
+zpl_acl_from_xattr_21141 zpl_acl_from_xattr 2 21141 NULL
+dsl_pool_tx_assign_init_22518 dsl_pool_tx_assign_init 2 22518 NULL
+nvlist_lookup_byte_array_22527 nvlist_lookup_byte_array 0 22527 NULL
+sa_replace_all_by_template_locked_22533 sa_replace_all_by_template_locked 3 22533 NULL
+tsd_hash_table_init_22559 tsd_hash_table_init 1 22559 NULL
+spa_vdev_remove_aux_23966 spa_vdev_remove_aux 4 23966 NULL
+zpl_xattr_acl_set_access_24129 zpl_xattr_acl_set_access 4 24129 NULL
+dmu_assign_arcbuf_24622 dmu_assign_arcbuf 2 24622 NULL
+zap_lookup_norm_25166 zap_lookup_norm 9 25166 NULL
+dmu_prealloc_25456 dmu_prealloc 4-3 25456 NULL
+kmalloc_nofail_26347 kmalloc_nofail 1 26347 NULL
+zfsctl_snapshot_zpath_27578 zfsctl_snapshot_zpath 2 27578 NULL
+zpios_dmu_read_30015 zpios_dmu_read 4-5 30015 NULL
+splat_write_30943 splat_write 3 30943 NULL
+zpl_xattr_get_sa_31183 zpl_xattr_get_sa 0 31183 NULL
+dmu_read_uio_31467 dmu_read_uio 4 31467 NULL
+zfs_replay_fuids_31479 zfs_replay_fuids 4 31479 NULL
+spa_history_log_to_phys_31632 spa_history_log_to_phys 0-1 31632 NULL
+__zpl_xattr_get_32601 __zpl_xattr_get 0 32601 NULL
+proc_copyout_string_34049 proc_copyout_string 2 34049 NULL
+nv_alloc_sleep_spl_34544 nv_alloc_sleep_spl 2 34544 NULL
+nv_alloc_nosleep_spl_34761 nv_alloc_nosleep_spl 2 34761 NULL
+zap_leaf_array_match_36922 zap_leaf_array_match 4 36922 NULL
+copyinstr_36980 copyinstr 3 36980 NULL
+zpl_xattr_acl_set_default_37864 zpl_xattr_acl_set_default 4 37864 NULL
+splat_read_38116 splat_read 3 38116 NULL
+sa_setup_38756 sa_setup 4 38756 NULL
+vdev_disk_physio_39898 vdev_disk_physio 3 39898 NULL
+arc_buf_size_39982 arc_buf_size 0 39982 NULL
+kzalloc_nofail_40719 kzalloc_nofail 1 40719 NULL
+fuidstr_to_sid_40777 fuidstr_to_sid 4 40777 NULL
+vdev_raidz_matrix_reconstruct_40852 vdev_raidz_matrix_reconstruct 2-3 40852 NULL
+sa_find_layout_40892 sa_find_layout 4 40892 NULL
+zpl_xattr_get_dir_41918 zpl_xattr_get_dir 0 41918 NULL
+zfs_sa_get_xattr_42600 zfs_sa_get_xattr 0 42600 NULL
+zpl_xattr_acl_set_42808 zpl_xattr_acl_set 4 42808 NULL
+xdr_dec_array_43091 xdr_dec_array 5 43091 NULL
+dsl_dataset_namelen_43136 dsl_dataset_namelen 0 43136 NULL
+kcopy_write_43683 kcopy_write 3 43683 NULL
+uiomove_44355 uiomove 2 44355 NULL
+dmu_read_44418 dmu_read 4-3 44418 NULL
+ddi_copyin_44846 ddi_copyin 3 44846 NULL
+kcopy_do_get_45061 kcopy_do_get 5 45061 NULL
+copyin_45945 copyin 3 45945 NULL
+zil_itx_create_46555 zil_itx_create 2 46555 NULL
+dmu_write_uio_dbuf_48064 dmu_write_uio_dbuf 3 48064 NULL
+spa_history_write_49650 spa_history_write 3 49650 NULL
+kcopy_copy_pages_to_user_49823 kcopy_copy_pages_to_user 3-4 49823 NULL
+zfs_log_write_50162 zfs_log_write 6-5 50162 NULL
+i_fm_alloc_51038 i_fm_alloc 2 51038 NULL
+copyout_51409 copyout 3 51409 NULL
+zvol_log_write_54898 zvol_log_write 4-3 54898 NULL
+zfs_acl_node_alloc_55641 zfs_acl_node_alloc 1 55641 NULL
+get_nvlist_56685 get_nvlist 2 56685 NULL
+zprop_get_numprops_56820 zprop_get_numprops 0 56820 NULL
+splat_taskq_test4_common_59829 splat_taskq_test4_common 5 59829 NULL
+zfs_replay_domain_cnt_61399 zfs_replay_domain_cnt 0 61399 NULL
+zpios_write_61823 zpios_write 3 61823 NULL
+proc_copyin_string_62019 proc_copyin_string 4 62019 NULL
+random_get_pseudo_bytes_64611 random_get_pseudo_bytes 2 64611 NULL
+zpios_read_64734 zpios_read 3 64734 NULL
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/size_overflow_hash.data linux-3.2.71-pax/tools/gcc/size_overflow_plugin/size_overflow_hash.data
--- linux-3.2.71/tools/gcc/size_overflow_plugin/size_overflow_hash.data	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/size_overflow_hash.data	2015-03-11 16:31:52.471130152 +0100
@@ -0,0 +1,4441 @@
+intel_fake_agp_alloc_by_type_1 intel_fake_agp_alloc_by_type 1 1 NULL
+compat_sock_setsockopt_23 compat_sock_setsockopt 5 23 NULL
+carl9170_alloc_27 carl9170_alloc 1 27 NULL
+sel_read_policyvers_55 sel_read_policyvers 3 55 NULL nohasharray
+padzero_55 padzero 1 55 &sel_read_policyvers_55
+cfg80211_disconnected_57 cfg80211_disconnected 4 57 NULL
+vis_data_count_prim_sec_64 vis_data_count_prim_sec 0 64 NULL
+__skb_to_sgvec_72 __skb_to_sgvec 0 72 NULL
+snd_korg1212_copy_to_92 snd_korg1212_copy_to 6 92 NULL
+load_msg_95 load_msg 2 95 NULL
+ipath_verbs_send_117 ipath_verbs_send 5-3 117 NULL
+init_q_132 init_q 4 132 NULL
+memstick_alloc_host_142 memstick_alloc_host 1 142 NULL
+ext4_ext_get_actual_len_153 ext4_ext_get_actual_len 0 153 NULL nohasharray
+tracing_trace_options_write_153 tracing_trace_options_write 3 153 &ext4_ext_get_actual_len_153
+iscsi_session_setup_196 iscsi_session_setup 4-5 196 NULL
+device_add_bin_attributes_205 device_add_bin_attributes 0 205 NULL
+tcp_skb_seglen_221 tcp_skb_seglen 0 221 NULL
+proc_scsi_write_proc_267 proc_scsi_write_proc 3 267 NULL
+generic_file_direct_write_291 generic_file_direct_write 0 291 NULL
+read_file_war_stats_292 read_file_war_stats 3 292 NULL
+platform_device_add_data_310 platform_device_add_data 3 310 NULL
+iwl_dbgfs_tx_statistics_read_314 iwl_dbgfs_tx_statistics_read 3 314 NULL nohasharray
+dn_setsockopt_314 dn_setsockopt 5 314 &iwl_dbgfs_tx_statistics_read_314
+ath9k_wmi_cmd_327 ath9k_wmi_cmd 4 327 NULL
+sysfs_create_dir_398 sysfs_create_dir 0 398 NULL
+btmrvl_txdnldready_read_413 btmrvl_txdnldready_read 3 413 NULL
+lbs_rdmac_read_418 lbs_rdmac_read 3 418 NULL
+snd_ca0106_ptr_read_467 snd_ca0106_ptr_read 0 467 NULL
+_alloc_get_attr_desc_470 _alloc_get_attr_desc 2 470 NULL
+pidlist_resize_496 pidlist_resize 2 496 NULL
+iwl_dbgfs_protection_mode_write_502 iwl_dbgfs_protection_mode_write 3 502 NULL
+smp_send_cmd_512 smp_send_cmd 3 512 NULL
+ocfs2_validate_meta_ecc_bhs_527 ocfs2_validate_meta_ecc_bhs 0 527 NULL
+ipv6_skip_exthdr_536 ipv6_skip_exthdr 0-2 536 NULL
+iwl_dbgfs_wowlan_sram_read_540 iwl_dbgfs_wowlan_sram_read 3 540 NULL
+dle_count_543 dle_count 0 543 NULL
+devres_alloc_551 devres_alloc 2 551 NULL
+snd_aw2_saa7146_get_hw_ptr_playback_558 snd_aw2_saa7146_get_hw_ptr_playback 0 558 NULL
+start_isoc_chain_565 start_isoc_chain 2 565 NULL nohasharray
+dev_hard_header_565 dev_hard_header 0 565 &start_isoc_chain_565
+compat_sys_preadv_583 compat_sys_preadv 3 583 NULL
+unlink_queued_645 unlink_queued 3-4 645 NULL
+ceph_copy_user_to_page_vector_656 ceph_copy_user_to_page_vector 4-3 656 NULL
+xfrm_aevent_msgsize_674 xfrm_aevent_msgsize 0 674 NULL
+rtl8169_try_rx_copy_705 rtl8169_try_rx_copy 3 705 NULL
+sctp_setsockopt_peer_addr_params_734 sctp_setsockopt_peer_addr_params 3 734 NULL
+ddp_set_map_751 ddp_set_map 4 751 NULL
+iwl_read_targ_mem_772 iwl_read_targ_mem 0 772 NULL
+jbd2_journal_dirty_metadata_784 jbd2_journal_dirty_metadata 0 784 NULL
+if_writecmd_815 if_writecmd 2 815 NULL
+aac_change_queue_depth_825 aac_change_queue_depth 2 825 NULL
+read_fifo_826 read_fifo 3 826 NULL
+o2net_send_message_vec_879 o2net_send_message_vec 4 879 NULL nohasharray
+iwl_dbgfs_fh_reg_read_879 iwl_dbgfs_fh_reg_read 3 879 &o2net_send_message_vec_879
+snd_pcm_action_single_905 snd_pcm_action_single 0 905 NULL
+btmrvl_hsstate_read_920 btmrvl_hsstate_read 3 920 NULL
+v4l2_ctrl_handler_init_928 v4l2_ctrl_handler_init 2 928 NULL
+carl9170_cmd_buf_950 carl9170_cmd_buf 3 950 NULL
+__nodes_weight_956 __nodes_weight 2-0 956 NULL
+sys_msgrcv_959 sys_msgrcv 3 959 NULL
+hdlcdev_rx_997 hdlcdev_rx 3 997 NULL
+free_ind_block_999 free_ind_block 0 999 NULL
+readreg_1017 readreg 0-1 1017 NULL
+gigaset_initdriver_1060 gigaset_initdriver 2 1060 NULL
+Read_hfc16_1070 Read_hfc16 0 1070 NULL
+agp_create_memory_1075 agp_create_memory 1 1075 NULL
+_scsih_adjust_queue_depth_1083 _scsih_adjust_queue_depth 2 1083 NULL
+llc_mac_hdr_init_1094 llc_mac_hdr_init 0 1094 NULL nohasharray
+inode_ref_info_1094 inode_ref_info 0 1094 &llc_mac_hdr_init_1094
+__arch_hweight8_1105 __arch_hweight8 0 1105 NULL
+__btrfs_cow_block_1125 __btrfs_cow_block 0 1125 NULL
+i2400m_rx_ctl_1157 i2400m_rx_ctl 4 1157 NULL
+pfkey_xfrm_policy2msg_size_1176 pfkey_xfrm_policy2msg_size 0 1176 NULL
+ipc_alloc_1192 ipc_alloc 1 1192 NULL
+ib_create_send_mad_1196 ib_create_send_mad 5 1196 NULL
+i2400m_rx_ctl_ack_1199 i2400m_rx_ctl_ack 3 1199 NULL
+i2cdev_read_1206 i2cdev_read 3 1206 NULL
+ipw_packet_received_skb_1230 ipw_packet_received_skb 2 1230 NULL
+acpi_battery_write_alarm_1240 acpi_battery_write_alarm 3 1240 NULL
+ocfs2_extend_file_1266 ocfs2_extend_file 3 1266 NULL
+ioctl_private_iw_point_1273 ioctl_private_iw_point 7 1273 NULL
+ffs_1322 ffs 0 1322 NULL
+push_node_left_1327 push_node_left 0 1327 NULL
+carl9170_rx_stream_1334 carl9170_rx_stream 3 1334 NULL
+btrfs_submit_compressed_write_1347 btrfs_submit_compressed_write 5 1347 NULL
+snd_pcm_lib_write1_1358 snd_pcm_lib_write1 0-3 1358 NULL
+ipx_sendmsg_1362 ipx_sendmsg 4 1362 NULL
+ocfs2_prepare_inode_for_write_1372 ocfs2_prepare_inode_for_write 3 1372 NULL
+sctp_setsockopt_initmsg_1383 sctp_setsockopt_initmsg 3 1383 NULL
+do_msgsnd_1387 do_msgsnd 4 1387 NULL
+file_read_actor_1401 file_read_actor 4 1401 NULL
+hci_si_event_1404 hci_si_event 3 1404 NULL
+init_rs_internal_1436 init_rs_internal 1 1436 NULL
+stack_max_size_read_1445 stack_max_size_read 3 1445 NULL
+xprt_alloc_1475 xprt_alloc 2 1475 NULL
+sta_num_ps_buf_frames_read_1488 sta_num_ps_buf_frames_read 3 1488 NULL
+fpregs_set_1497 fpregs_set 4 1497 NULL
+tomoyo_round2_1518 tomoyo_round2 0 1518 NULL
+ieee80211_if_read_dot11MeshHWMPnetDiameterTraversalTime_1589 ieee80211_if_read_dot11MeshHWMPnetDiameterTraversalTime 3 1589 NULL
+fc_frame_alloc_1596 fc_frame_alloc 2 1596 NULL
+packet_buffer_init_1607 packet_buffer_init 2 1607 NULL
+i915_gem_execbuffer_wait_for_flips_1612 i915_gem_execbuffer_wait_for_flips 0 1612 NULL
+btmrvl_hscmd_read_1614 btmrvl_hscmd_read 3 1614 NULL
+v9fs_fid_xattr_get_1618 v9fs_fid_xattr_get 0 1618 NULL
+btmrvl_hsmode_read_1647 btmrvl_hsmode_read 3 1647 NULL
+ikconfig_read_current_1658 ikconfig_read_current 3 1658 NULL
+configfs_read_file_1683 configfs_read_file 3 1683 NULL
+pdu_write_u_1710 pdu_write_u 3 1710 NULL
+coda_psdev_write_1711 coda_psdev_write 3 1711 NULL
+internal_create_group_1733 internal_create_group 0 1733 NULL
+ieee80211_new_mesh_header_1761 ieee80211_new_mesh_header 0 1761 NULL
+cosa_write_1774 cosa_write 3 1774 NULL
+__nodelist_scnprintf_1815 __nodelist_scnprintf 2-0 1815 NULL
+sb_issue_zeroout_1884 sb_issue_zeroout 0 1884 NULL
+ext3_fiemap_1936 ext3_fiemap 4 1936 NULL
+ieee80211_if_fmt_dot11MeshConfirmTimeout_1945 ieee80211_if_fmt_dot11MeshConfirmTimeout 3 1945 NULL
+sel_read_avc_hash_stats_1984 sel_read_avc_hash_stats 3 1984 NULL
+xfs_trans_count_vecs_1991 xfs_trans_count_vecs 0 1991 NULL
+__alloc_bootmem_node_1992 __alloc_bootmem_node 2 1992 NULL
+ocfs2_global_qinit_alloc_2018 ocfs2_global_qinit_alloc 0 2018 NULL
+write_flush_pipefs_2021 write_flush_pipefs 3 2021 NULL
+ath6kl_fwlog_mask_read_2050 ath6kl_fwlog_mask_read 3 2050 NULL
+ocfs2_expand_inline_dir_2063 ocfs2_expand_inline_dir 3 2063 NULL
+subbuf_read_actor_2071 subbuf_read_actor 3 2071 NULL
+__generic_copy_from_user_intel_2073 __generic_copy_from_user_intel 0-3 2073 NULL
+diva_set_driver_dbg_mask_2077 diva_set_driver_dbg_mask 0 2077 NULL
+iwl_dbgfs_current_sleep_command_read_2081 iwl_dbgfs_current_sleep_command_read 3 2081 NULL
+idetape_chrdev_read_2097 idetape_chrdev_read 3 2097 NULL
+audit_expand_2098 audit_expand 2-0 2098 NULL
+iwl_dbgfs_log_event_read_2107 iwl_dbgfs_log_event_read 3 2107 NULL
+ecryptfs_encrypt_and_encode_filename_2109 ecryptfs_encrypt_and_encode_filename 6 2109 NULL
+enable_read_2117 enable_read 3 2117 NULL
+pcf50633_write_block_2124 pcf50633_write_block 3 2124 NULL
+check_load_and_stores_2143 check_load_and_stores 2 2143 NULL
+mlx4_init_icm_table_2151 mlx4_init_icm_table 5-4 2151 NULL
+iov_iter_count_2152 iov_iter_count 0 2152 NULL
+__copy_to_user_ll_2157 __copy_to_user_ll 0-3 2157 NULL
+_ore_get_io_state_2166 _ore_get_io_state 3-4-5 2166 NULL
+picolcd_debug_reset_write_2195 picolcd_debug_reset_write 3 2195 NULL
+u32_array_read_2219 u32_array_read 3 2219 NULL
+vhci_write_2224 vhci_write 3 2224 NULL
+__ocfs2_journal_access_2241 __ocfs2_journal_access 0 2241 NULL
+ieee80211_if_read_dot11MeshHWMPRannInterval_2249 ieee80211_if_read_dot11MeshHWMPRannInterval 3 2249 NULL
+netlbl_secattr_catmap_walk_2255 netlbl_secattr_catmap_walk 0-2 2255 NULL
+sel_write_avc_cache_threshold_2256 sel_write_avc_cache_threshold 3 2256 NULL
+do_update_counters_2259 do_update_counters 4 2259 NULL
+kvm_clear_guest_page_2308 kvm_clear_guest_page 4 2308 NULL
+__erst_read_to_erange_2341 __erst_read_to_erange 0 2341 NULL
+create_subvol_2347 create_subvol 4 2347 NULL
+rose_recvmsg_2368 rose_recvmsg 4 2368 NULL
+isdn_v110_open_2418 isdn_v110_open 3 2418 NULL
+hfcpci_empty_fifo_2427 hfcpci_empty_fifo 4 2427 NULL
+tty_buffer_find_2443 tty_buffer_find 2 2443 NULL
+__sock_recvmsg_2467 __sock_recvmsg 0 2467 NULL
+b43legacy_debugfs_read_2473 b43legacy_debugfs_read 3 2473 NULL
+xfrm_spdinfo_msgsize_2474 xfrm_spdinfo_msgsize 0 2474 NULL
+fc_fcp_send_data_2479 fc_fcp_send_data 4-3 2479 NULL
+update_pmkid_2481 update_pmkid 4 2481 NULL
+wiphy_new_2482 wiphy_new 2 2482 NULL
+squashfs_read_fragment_index_table_2506 squashfs_read_fragment_index_table 4 2506 NULL
+dm_write_2513 dm_write 3 2513 NULL
+v9fs_cached_file_read_2514 v9fs_cached_file_read 3 2514 NULL
+ext4_get_inode_loc_2516 ext4_get_inode_loc 0 2516 NULL
+pcm_sanity_check_2574 pcm_sanity_check 0 2574 NULL
+smk_write_logging_2618 smk_write_logging 3 2618 NULL
+nlmsg_msg_size_2623 nlmsg_msg_size 0-1 2623 NULL
+lro_gen_skb_2644 lro_gen_skb 6 2644 NULL
+ffs_ep0_read_2672 ffs_ep0_read 3 2672 NULL
+memcpy_fromiovecend_2707 memcpy_fromiovecend 3-4 2707 NULL
+hid_report_raw_event_2762 hid_report_raw_event 4 2762 NULL
+mon_bin_ioctl_2771 mon_bin_ioctl 3 2771 NULL
+usbatm_pdu_length_2786 usbatm_pdu_length 0-1 2786 NULL
+device_add_attrs_2789 device_add_attrs 0 2789 NULL
+iwl_dbgfs_clear_ucode_statistics_write_2804 iwl_dbgfs_clear_ucode_statistics_write 3 2804 NULL
+sel_read_enforce_2828 sel_read_enforce 3 2828 NULL
+wait_for_avail_2847 wait_for_avail 0 2847 NULL
+move_addr_to_user_2868 move_addr_to_user 2 2868 NULL
+nla_padlen_2883 nla_padlen 1 2883 NULL
+cmm_write_2896 cmm_write 3 2896 NULL
+count_esp_combs_2926 count_esp_combs 0 2926 NULL
+nes_read_indexed_2946 nes_read_indexed 0 2946 NULL
+ppp_cp_event_2965 ppp_cp_event 6 2965 NULL
+p9_nr_pages_2992 p9_nr_pages 0-2 2992 NULL
+depth_write_3021 depth_write 3 3021 NULL
+snd_azf3328_codec_inl_3022 snd_azf3328_codec_inl 0 3022 NULL
+xfrm_dst_alloc_copy_3034 xfrm_dst_alloc_copy 3 3034 NULL
+iwl_dbgfs_sleep_level_override_read_3038 iwl_dbgfs_sleep_level_override_read 3 3038 NULL nohasharray
+lpfc_idiag_mbxacc_write_3038 lpfc_idiag_mbxacc_write 3 3038 &iwl_dbgfs_sleep_level_override_read_3038
+nr_free_buffer_pages_3044 nr_free_buffer_pages 0 3044 NULL
+__blk_end_bidi_request_3070 __blk_end_bidi_request 3-4 3070 NULL
+dac960_user_command_proc_write_3071 dac960_user_command_proc_write 3 3071 NULL
+rb_alloc_3102 rb_alloc 1 3102 NULL
+simple_write_to_buffer_3122 simple_write_to_buffer 5-2 3122 NULL
+fill_write_buffer_3142 fill_write_buffer 3 3142 NULL
+b1_get_slice_3145 b1_get_slice 0 3145 NULL
+CIFSSMBSetPosixACL_3154 CIFSSMBSetPosixACL 5 3154 NULL
+compat_sys_migrate_pages_3157 compat_sys_migrate_pages 2 3157 NULL
+encrypted_instantiate_3168 encrypted_instantiate 3 3168 NULL
+uv_num_possible_blades_3177 uv_num_possible_blades 0 3177 NULL
+compat_do_ip6t_set_ctl_3184 compat_do_ip6t_set_ctl 4 3184 NULL
+alloc_context_3194 alloc_context 1 3194 NULL
+codec_reg_write_file_3204 codec_reg_write_file 3 3204 NULL
+ath6kl_mgmt_tx_3230 ath6kl_mgmt_tx 9 3230 NULL
+btrfs_next_leaf_3232 btrfs_next_leaf 0 3232 NULL
+kimage_crash_alloc_3233 kimage_crash_alloc 3 3233 NULL
+write_adapter_mem_3234 write_adapter_mem 3 3234 NULL
+ext3_xattr_find_entry_3237 ext3_xattr_find_entry 0 3237 NULL
+key_key_read_3241 key_key_read 3 3241 NULL
+__ilog2_u64_3284 __ilog2_u64 0 3284 NULL
+__iovec_copy_from_user_inatomic_3314 __iovec_copy_from_user_inatomic 4-3-0 3314 NULL
+i915_gem_gtt_bind_object_3319 i915_gem_gtt_bind_object 0 3319 NULL
+compat_sys_setsockopt_3326 compat_sys_setsockopt 5 3326 NULL
+de600_read_byte_3332 de600_read_byte 0 3332 NULL
+sctp_make_init_ack_3335 sctp_make_init_ack 4 3335 NULL
+sysfs_create_group_3339 sysfs_create_group 0 3339 NULL
+noack_write_3343 noack_write 3 3343 NULL
+gsm_control_rls_3353 gsm_control_rls 3 3353 NULL
+scnprintf_3360 scnprintf 0-2 3360 NULL
+ReadByteAmd7930_3365 ReadByteAmd7930 0 3365 NULL
+send_stream_3397 send_stream 4 3397 NULL
+isdn_readbchan_3401 isdn_readbchan 0-5 3401 NULL
+pci_add_cap_save_buffer_3426 pci_add_cap_save_buffer 3 3426 NULL
+pipe_iov_copy_to_user_3447 pipe_iov_copy_to_user 3 3447 NULL
+jffs2_acl_setxattr_3464 jffs2_acl_setxattr 4 3464 NULL nohasharray
+snd_pcm_lib_readv_transfer_3464 snd_pcm_lib_readv_transfer 5-4-2 3464 &jffs2_acl_setxattr_3464
+alloc_skb_fclone_3467 alloc_skb_fclone 1 3467 NULL
+security_context_to_sid_default_3492 security_context_to_sid_default 2 3492 NULL
+xfrm_migrate_msgsize_3496 xfrm_migrate_msgsize 1-0 3496 NULL
+btrfs_dir_name_len_3549 btrfs_dir_name_len 0 3549 NULL
+b43legacy_read16_3561 b43legacy_read16 0 3561 NULL
+get_interface_3562 get_interface 0 3562 NULL
+alloc_smp_resp_3566 alloc_smp_resp 1 3566 NULL
+evtchn_read_3569 evtchn_read 3 3569 NULL
+vc_resize_3585 vc_resize 3-2 3585 NULL
+compat_sys_semtimedop_3606 compat_sys_semtimedop 3 3606 NULL
+sctp_getsockopt_events_3607 sctp_getsockopt_events 2 3607 NULL
+aligned_kmalloc_3628 aligned_kmalloc 1 3628 NULL
+cm_copy_private_data_3649 cm_copy_private_data 2 3649 NULL
+i915_compat_ioctl_3656 i915_compat_ioctl 2 3656 NULL
+btmrvl_psmode_write_3703 btmrvl_psmode_write 3 3703 NULL nohasharray
+snd_m3_assp_read_3703 snd_m3_assp_read 0 3703 &btmrvl_psmode_write_3703
+ping_sendmsg_3782 ping_sendmsg 4 3782 NULL
+sctp_setsockopt_auth_key_3793 sctp_setsockopt_auth_key 3 3793 NULL
+ncp_file_write_3813 ncp_file_write 3 3813 NULL
+llc_ui_recvmsg_3826 llc_ui_recvmsg 4 3826 NULL
+read_file_tx_chainmask_3829 read_file_tx_chainmask 3 3829 NULL
+ubi_eba_read_leb_3847 ubi_eba_read_leb 0 3847 NULL
+smk_read_onlycap_3855 smk_read_onlycap 3 3855 NULL
+get_fd_set_3866 get_fd_set 1 3866 NULL
+apei_res_sub_3873 apei_res_sub 0 3873 NULL
+garp_attr_create_3883 garp_attr_create 3 3883 NULL
+uea_send_modem_cmd_3888 uea_send_modem_cmd 3 3888 NULL
+nvram_write_3894 nvram_write 3 3894 NULL
+vcs_write_3910 vcs_write 3 3910 NULL
+pm860x_read_device_3958 pm860x_read_device 3 3958 NULL
+i915_gem_object_get_fence_3981 i915_gem_object_get_fence 0 3981 NULL
+do_add_counters_3992 do_add_counters 3 3992 NULL
+userspace_status_4004 userspace_status 4 4004 NULL
+xfs_check_block_4005 xfs_check_block 4 4005 NULL nohasharray
+mei_write_4005 mei_write 3 4005 &xfs_check_block_4005
+snd_hdsp_capture_copy_4011 snd_hdsp_capture_copy 5 4011 NULL
+i915_gem_object_unbind_4016 i915_gem_object_unbind 0 4016 NULL
+blk_end_request_4024 blk_end_request 3 4024 NULL
+ext4_xattr_find_entry_4025 ext4_xattr_find_entry 0 4025 NULL
+b1_get_word_4035 b1_get_word 0 4035 NULL
+i915_gpu_idle_4062 i915_gpu_idle 0 4062 NULL
+get_dmabuf_4065 get_dmabuf 2 4065 NULL
+sctp_make_asconf_4078 sctp_make_asconf 3 4078 NULL
+fbcon_do_set_font_4079 fbcon_do_set_font 2-3 4079 NULL
+mpt_raid_phys_disk_get_num_paths_4155 mpt_raid_phys_disk_get_num_paths 0 4155 NULL
+msg_bits_4158 msg_bits 0-3-4 4158 NULL
+get_alua_req_4166 get_alua_req 3 4166 NULL
+blk_dropped_read_4168 blk_dropped_read 3 4168 NULL
+read_file_bool_4180 read_file_bool 3 4180 NULL
+f1x_determine_channel_4202 f1x_determine_channel 2 4202 NULL
+_osd_req_list_objects_4204 _osd_req_list_objects 6 4204 NULL
+__snd_gf1_read_addr_4210 __snd_gf1_read_addr 0 4210 NULL
+ath6kl_wmi_tcmd_test_report_rx_4314 ath6kl_wmi_tcmd_test_report_rx 3 4314 NULL
+count_strings_4315 count_strings 0 4315 NULL
+snd_rawmidi_kernel_read_4328 snd_rawmidi_kernel_read 3 4328 NULL
+lookup_string_4365 lookup_string 0 4365 NULL nohasharray
+__copy_from_user_inatomic_4365 __copy_from_user_inatomic 0-3 4365 &lookup_string_4365
+sys_setdomainname_4373 sys_setdomainname 2 4373 NULL
+irda_sendmsg_4388 irda_sendmsg 4 4388 NULL
+cxacru_cm_get_array_4412 cxacru_cm_get_array 4 4412 NULL nohasharray
+access_process_vm_4412 access_process_vm 0 4412 &cxacru_cm_get_array_4412
+libfc_vport_create_4415 libfc_vport_create 2 4415 NULL
+do_pages_stat_4437 do_pages_stat 2 4437 NULL
+memparse_4444 memparse 0 4444 NULL
+dn_alloc_send_pskb_4465 dn_alloc_send_pskb 2 4465 NULL
+at76_set_card_command_4471 at76_set_card_command 4 4471 NULL
+snd_seq_expand_var_event_4481 snd_seq_expand_var_event 5-0 4481 NULL
+sys_semtimedop_4486 sys_semtimedop 3 4486 NULL
+udp_sendmsg_4492 udp_sendmsg 4 4492 NULL
+vmbus_establish_gpadl_4495 vmbus_establish_gpadl 3 4495 NULL
+l1oip_socket_parse_4507 l1oip_socket_parse 4 4507 NULL
+sys_llistxattr_4532 sys_llistxattr 3 4532 NULL
+btrfs_file_extent_inline_item_len_4575 btrfs_file_extent_inline_item_len 0 4575 NULL
+bch_alloc_4593 bch_alloc 1 4593 NULL
+rbd_create_rw_ops_4605 rbd_create_rw_ops 2 4605 NULL
+iwl_dbgfs_tx_queue_read_4635 iwl_dbgfs_tx_queue_read 3 4635 NULL
+virtqueue_add_buf_gfp_4662 virtqueue_add_buf_gfp 4-3 4662 NULL
+map_addr_4666 map_addr 6 4666 NULL
+skb_add_data_nocache_4682 skb_add_data_nocache 4 4682 NULL
+short_retry_limit_read_4687 short_retry_limit_read 3 4687 NULL
+round_pipe_size_4701 round_pipe_size 0 4701 NULL
+cxgbi_alloc_big_mem_4707 cxgbi_alloc_big_mem 1 4707 NULL
+trusted_instantiate_4710 trusted_instantiate 3 4710 NULL
+btmrvl_gpiogap_read_4718 btmrvl_gpiogap_read 3 4718 NULL
+ati_create_gatt_pages_4722 ati_create_gatt_pages 1 4722 NULL nohasharray
+show_header_4722 show_header 3 4722 &ati_create_gatt_pages_4722
+ip6_ufo_append_data_4780 ip6_ufo_append_data 5-6-7 4780 NULL
+ncp__vol2io_4804 ncp__vol2io 5 4804 NULL
+gigaset_if_receive_4861 gigaset_if_receive 3 4861 NULL
+key_tx_spec_read_4862 key_tx_spec_read 3 4862 NULL
+ocfs2_defrag_extent_4873 ocfs2_defrag_extent 3-2 4873 NULL
+hid_register_field_4874 hid_register_field 2-3 4874 NULL
+vga_arb_read_4886 vga_arb_read 3 4886 NULL
+sys_ipc_4889 sys_ipc 3 4889 NULL
+del_ptr_4894 del_ptr 0 4894 NULL
+sys_process_vm_writev_4928 sys_process_vm_writev 3-5 4928 NULL
+ieee80211_if_fmt_ave_beacon_4941 ieee80211_if_fmt_ave_beacon 3 4941 NULL
+devm_kzalloc_4966 devm_kzalloc 2 4966 NULL
+compat_rawv6_setsockopt_4967 compat_rawv6_setsockopt 5 4967 NULL
+skb_network_header_len_4971 skb_network_header_len 0 4971 NULL
+do_mincore_5018 do_mincore 0-2-1 5018 NULL
+mtd_device_parse_register_5024 mtd_device_parse_register 5 5024 NULL
+__ip_select_ident_5046 __ip_select_ident 2 5046 NULL
+ocfs2_check_range_for_holes_5066 ocfs2_check_range_for_holes 2-3 5066 NULL
+__kmalloc_track_caller_5071 __kmalloc_track_caller 1 5071 NULL
+snd_mixart_BA1_read_5082 snd_mixart_BA1_read 5 5082 NULL
+snd_emu10k1_ptr20_read_5087 snd_emu10k1_ptr20_read 0 5087 NULL
+get_random_bytes_5091 get_random_bytes 2 5091 NULL nohasharray
+blk_rq_sectors_5091 blk_rq_sectors 0 5091 &get_random_bytes_5091 nohasharray
+kfifo_copy_from_user_5091 kfifo_copy_from_user 3-4-0 5091 &blk_rq_sectors_5091
+sound_write_5102 sound_write 3 5102 NULL
+__uwb_addr_print_5161 __uwb_addr_print 2 5161 NULL
+iwl_dbgfs_status_read_5171 iwl_dbgfs_status_read 3 5171 NULL
+acpi_pcc_get_sqty_5176 acpi_pcc_get_sqty 0 5176 NULL
+pipe_set_size_5204 pipe_set_size 2 5204 NULL
+ppp_cp_parse_cr_5214 ppp_cp_parse_cr 4 5214 NULL
+isdn_ppp_skb_push_5236 isdn_ppp_skb_push 2 5236 NULL
+usb_descriptor_fillbuf_5302 usb_descriptor_fillbuf 0 5302 NULL
+ad714x_i2c_read_5345 ad714x_i2c_read 4 5345 NULL
+cciss_allocate_sg_chain_blocks_5368 cciss_allocate_sg_chain_blocks 3-2 5368 NULL
+xfs_efd_init_5463 xfs_efd_init 3 5463 NULL
+xfs_efi_init_5476 xfs_efi_init 2 5476 NULL
+cifs_security_flags_proc_write_5484 cifs_security_flags_proc_write 3 5484 NULL
+tty_write_5494 tty_write 3 5494 NULL
+tomoyo_update_domain_5498 tomoyo_update_domain 2 5498 NULL nohasharray
+ieee80211_if_fmt_last_beacon_5498 ieee80211_if_fmt_last_beacon 3 5498 &tomoyo_update_domain_5498
+__max_nr_grant_frames_5505 __max_nr_grant_frames 0 5505 NULL
+spidev_message_5518 spidev_message 3 5518 NULL
+sctp_make_op_error_space_5528 sctp_make_op_error_space 3 5528 NULL
+ieee80211_if_fmt_auto_open_plinks_5534 ieee80211_if_fmt_auto_open_plinks 3 5534 NULL
+brcmu_pkt_buf_get_skb_5556 brcmu_pkt_buf_get_skb 1 5556 NULL
+le_readq_5557 le_readq 0 5557 NULL
+inw_5558 inw 0 5558 NULL
+bioset_create_5580 bioset_create 1 5580 NULL
+do_msgrcv_5590 do_msgrcv 4 5590 NULL
+ext4_xattr_get_5661 ext4_xattr_get 0 5661 NULL
+posix_clock_register_5662 posix_clock_register 2 5662 NULL
+get_arg_5694 get_arg 3 5694 NULL
+vmw_kms_readback_5727 vmw_kms_readback 6 5727 NULL
+get_packet_5747 get_packet 3 5747 NULL
+sctp_setsockopt_autoclose_5775 sctp_setsockopt_autoclose 3 5775 NULL
+mlx4_alloc_resize_buf_5778 mlx4_alloc_resize_buf 3 5778 NULL
+compat_sys_writev_5784 compat_sys_writev 3 5784 NULL
+__vxge_hw_blockpool_malloc_5786 __vxge_hw_blockpool_malloc 2 5786 NULL
+skb_copy_datagram_iovec_5806 skb_copy_datagram_iovec 2-4 5806 NULL
+ceph_x_encrypt_buflen_5829 ceph_x_encrypt_buflen 0-1 5829 NULL
+ceph_msg_new_5846 ceph_msg_new 2 5846 NULL
+ixgb_check_copybreak_5847 ixgb_check_copybreak 3 5847 NULL
+setup_req_5848 setup_req 3 5848 NULL
+rx_q_entry_to_length_5855 rx_q_entry_to_length 0-1 5855 NULL
+compat_sys_move_pages_5861 compat_sys_move_pages 2 5861 NULL
+config_buf_5862 config_buf 0 5862 NULL
+ext4_ext_correct_indexes_5865 ext4_ext_correct_indexes 0 5865 NULL
+port_show_regs_5904 port_show_regs 3 5904 NULL
+uhci_debug_read_5911 uhci_debug_read 3 5911 NULL
+lbs_highsnr_read_5931 lbs_highsnr_read 3 5931 NULL
+edac_device_alloc_ctl_info_5941 edac_device_alloc_ctl_info 1 5941 NULL
+tipc_subseq_alloc_5957 tipc_subseq_alloc 1 5957 NULL
+__apu_get_register_5967 __apu_get_register 0 5967 NULL
+ieee80211_if_fmt_rc_rateidx_mask_5ghz_5971 ieee80211_if_fmt_rc_rateidx_mask_5ghz 3 5971 NULL
+device_add_attributes_6058 device_add_attributes 0 6058 NULL
+sctp_setsockopt_connectx_6073 sctp_setsockopt_connectx 3 6073 NULL
+ipmi_addr_length_6110 ipmi_addr_length 0 6110 NULL
+i915_gem_execbuffer_move_to_gpu_6197 i915_gem_execbuffer_move_to_gpu 0 6197 NULL
+nfc_alloc_skb_6216 nfc_alloc_skb 1 6216 NULL
+v4l2_ctrl_new_std_menu_6221 v4l2_ctrl_new_std_menu 4 6221 NULL
+mqueue_read_file_6228 mqueue_read_file 3 6228 NULL
+f_hidg_read_6238 f_hidg_read 3 6238 NULL
+fbcon_prepare_logo_6246 fbcon_prepare_logo 5 6246 NULL
+snd_hda_override_conn_list_6282 snd_hda_override_conn_list 0 6282 NULL nohasharray
+xenbus_file_write_6282 xenbus_file_write 3 6282 &snd_hda_override_conn_list_6282
+iwl4965_rs_sta_dbgfs_stats_table_read_6289 iwl4965_rs_sta_dbgfs_stats_table_read 3 6289 NULL
+set_local_name_6310 set_local_name 4 6310 NULL
+hfa384x_inw_6329 hfa384x_inw 0 6329 NULL
+_proc_do_string_6376 _proc_do_string 2 6376 NULL
+osd_req_read_sg_kern_6378 osd_req_read_sg_kern 5 6378 NULL
+bt_skb_alloc_6404 bt_skb_alloc 1 6404 NULL
+l2up_create_6430 l2up_create 3 6430 NULL
+ipr_change_queue_depth_6431 ipr_change_queue_depth 2 6431 NULL
+__alloc_bootmem_node_nopanic_6432 __alloc_bootmem_node_nopanic 2 6432 NULL
+ceph_sync_write_6466 ceph_sync_write 3 6466 NULL
+ieee80211_if_fmt_dot11MeshMaxRetries_6476 ieee80211_if_fmt_dot11MeshMaxRetries 3 6476 NULL
+cipso_v4_map_lvl_hton_6490 cipso_v4_map_lvl_hton 0 6490 NULL
+dbg_intr_buf_6501 dbg_intr_buf 2 6501 NULL
+ttm_get_pages_6504 ttm_get_pages 4 6504 NULL
+mei_read_6507 mei_read 3 6507 NULL
+read_file_disable_ani_6536 read_file_disable_ani 3 6536 NULL
+rndis_set_oid_6547 rndis_set_oid 4 6547 NULL
+wdm_read_6549 wdm_read 3 6549 NULL
+fb_alloc_cmap_6554 fb_alloc_cmap 2 6554 NULL
+bt_skb_send_alloc_6581 bt_skb_send_alloc 2 6581 NULL
+ecryptfs_filldir_6622 ecryptfs_filldir 3 6622 NULL
+dn_alloc_skb_6631 dn_alloc_skb 2 6631 NULL
+process_rcvd_data_6679 process_rcvd_data 3 6679 NULL
+iwl_dbgfs_clear_traffic_statistics_write_6681 iwl_dbgfs_clear_traffic_statistics_write 3 6681 NULL
+ql_process_mac_rx_skb_6689 ql_process_mac_rx_skb 4 6689 NULL
+ieee80211_build_preq_ies_6691 ieee80211_build_preq_ies 0 6691 NULL
+btrfs_lookup_csums_range_6696 btrfs_lookup_csums_range 2-3 6696 NULL
+ibmpex_query_sensor_count_6709 ibmpex_query_sensor_count 0 6709 NULL
+video_proc_write_6724 video_proc_write 3 6724 NULL
+posix_acl_xattr_count_6725 posix_acl_xattr_count 0-1 6725 NULL
+rds_rdma_pages_6735 rds_rdma_pages 0 6735 NULL
+kobject_add_varg_6781 kobject_add_varg 0 6781 NULL
+iwl_dbgfs_channels_read_6784 iwl_dbgfs_channels_read 3 6784 NULL
+ieee80211_if_read_6785 ieee80211_if_read 3 6785 NULL
+hdlcdrv_register_6792 hdlcdrv_register 2 6792 NULL
+lbs_rdrf_write_6826 lbs_rdrf_write 3 6826 NULL
+calc_pages_for_6838 calc_pages_for 0-1-2 6838 NULL
+mon_bin_read_6841 mon_bin_read 3 6841 NULL
+snd_cs4281_BA0_read_6847 snd_cs4281_BA0_read 5 6847 NULL
+ip_select_ident_segs_6862 ip_select_ident_segs 3 6862 NULL
+ieee80211_if_fmt_path_refresh_time_6888 ieee80211_if_fmt_path_refresh_time 3 6888 NULL nohasharray
+raw_seticmpfilter_6888 raw_seticmpfilter 3 6888 &ieee80211_if_fmt_path_refresh_time_6888
+dlmfs_file_write_6892 dlmfs_file_write 3 6892 NULL
+proc_sessionid_read_6911 proc_sessionid_read 3 6911 NULL nohasharray
+spi_show_regs_6911 spi_show_regs 3 6911 &proc_sessionid_read_6911
+__kfifo_dma_in_finish_r_6913 __kfifo_dma_in_finish_r 2-3 6913 NULL
+ieee80211_rx_mgmt_probe_resp_6918 ieee80211_rx_mgmt_probe_resp 3 6918 NULL
+ieee80211_send_probe_req_6924 ieee80211_send_probe_req 6-4 6924 NULL
+cache_do_downcall_6926 cache_do_downcall 3 6926 NULL
+ipath_verbs_send_dma_6929 ipath_verbs_send_dma 6 6929 NULL
+qsfp_cks_6945 qsfp_cks 2-0 6945 NULL
+ab3100_get_register_page_interruptible_6951 ab3100_get_register_page_interruptible 4 6951 NULL
+tg3_nvram_write_block_unbuffered_6955 tg3_nvram_write_block_unbuffered 3 6955 NULL nohasharray
+dn_ifaddr_nlmsg_size_6955 dn_ifaddr_nlmsg_size 0 6955 &tg3_nvram_write_block_unbuffered_6955
+pch_uart_hal_read_6961 pch_uart_hal_read 0 6961 NULL
+request_key_async_6990 request_key_async 4 6990 NULL
+cipso_v4_gentag_enum_7006 cipso_v4_gentag_enum 0 7006 NULL
+tracing_cpumask_read_7010 tracing_cpumask_read 3 7010 NULL
+ld_usb_write_7022 ld_usb_write 3 7022 NULL
+wimax_msg_7030 wimax_msg 4 7030 NULL
+ipath_get_base_info_7043 ipath_get_base_info 3 7043 NULL
+snd_pcm_oss_bytes_7051 snd_pcm_oss_bytes 2 7051 NULL
+sctp_make_op_error_7057 sctp_make_op_error 6-5 7057 NULL
+hci_sock_recvmsg_7072 hci_sock_recvmsg 4 7072 NULL
+event_enable_read_7074 event_enable_read 3 7074 NULL
+send_mpa_reject_7135 send_mpa_reject 3 7135 NULL
+utf16_strsize_7203 utf16_strsize 0 7203 NULL nohasharray
+__alloc_objio_seg_7203 __alloc_objio_seg 1 7203 &utf16_strsize_7203
+sys32_ipc_7238 sys32_ipc 3 7238 NULL
+hdlc_loop_7255 hdlc_loop 0 7255 NULL
+f_midi_start_ep_7270 f_midi_start_ep 0 7270 NULL
+get_string_7302 get_string 0 7302 NULL
+ieee80211_compatible_rates_7318 ieee80211_compatible_rates 0 7318 NULL
+wait_on_sync_kiocb_7327 wait_on_sync_kiocb 0 7327 NULL
+mgmt_control_7349 mgmt_control 3 7349 NULL
+t1_get_slice_7350 t1_get_slice 0 7350 NULL
+ieee80211_if_read_dot11MeshHWMPactivePathTimeout_7368 ieee80211_if_read_dot11MeshHWMPactivePathTimeout 3 7368 NULL
+hweight_long_7388 hweight_long 0-1 7388 NULL
+sl_change_mtu_7396 sl_change_mtu 2 7396 NULL
+readb_7401 readb 0 7401 NULL
+drm_property_create_blob_7414 drm_property_create_blob 2 7414 NULL
+kvm_pv_mmu_op_7436 kvm_pv_mmu_op 3-2 7436 NULL
+ip_options_get_alloc_7448 ip_options_get_alloc 1 7448 NULL
+rt2x00debug_read_queue_stats_7455 rt2x00debug_read_queue_stats 3 7455 NULL
+__mutex_lock_common_7469 __mutex_lock_common 0 7469 NULL
+garp_request_join_7471 garp_request_join 4 7471 NULL
+compat_sys_msgrcv_7482 compat_sys_msgrcv 2 7482 NULL
+get_stats_7483 get_stats 0 7483 NULL
+snd_pcm_lib_read1_7491 snd_pcm_lib_read1 0-3 7491 NULL
+ahash_instance_headroom_7509 ahash_instance_headroom 0 7509 NULL nohasharray
+sdhci_alloc_host_7509 sdhci_alloc_host 2 7509 &ahash_instance_headroom_7509
+ext4_ext_insert_extent_7576 ext4_ext_insert_extent 0 7576 NULL
+groups_alloc_7614 groups_alloc 1 7614 NULL nohasharray
+create_dir_7614 create_dir 0 7614 &groups_alloc_7614
+cpumask_first_7648 cpumask_first 0 7648 NULL
+set_connectable_7649 set_connectable 4 7649 NULL
+acpi_ex_allocate_name_string_7685 acpi_ex_allocate_name_string 2-1 7685 NULL nohasharray
+skb_copy_expand_7685 skb_copy_expand 2-3 7685 &acpi_ex_allocate_name_string_7685
+acpi_ns_get_pathname_length_7699 acpi_ns_get_pathname_length 0 7699 NULL
+dev_write_7708 dev_write 3 7708 NULL
+pci_raw_set_power_state_7729 pci_raw_set_power_state 0 7729 NULL
+manip_pkt_7741 manip_pkt 3 7741 NULL
+vxge_device_register_7752 vxge_device_register 4 7752 NULL
+osdv2_attr_list_elem_size_7763 osdv2_attr_list_elem_size 0-1 7763 NULL
+ubi_io_read_vid_hdr_7766 ubi_io_read_vid_hdr 0 7766 NULL
+paths_from_inode_7774 paths_from_inode 0 7774 NULL
+alloc_candev_7776 alloc_candev 1-2 7776 NULL
+bnx2_nvram_write_7790 bnx2_nvram_write 4-2 7790 NULL
+diva_os_copy_from_user_7792 diva_os_copy_from_user 4 7792 NULL
+config_desc_7878 config_desc 0 7878 NULL
+xfs_trans_get_efi_7898 xfs_trans_get_efi 2 7898 NULL
+gfs2_tune_get_i_7903 gfs2_tune_get_i 0 7903 NULL
+libfc_host_alloc_7917 libfc_host_alloc 2 7917 NULL
+do_surface_dirty_sou_7920 do_surface_dirty_sou 7 7920 NULL
+f_hidg_write_7932 f_hidg_write 3 7932 NULL
+smk_write_load_self_7958 smk_write_load_self 3 7958 NULL
+sys_mbind_7990 sys_mbind 5 7990 NULL
+vcs_read_8017 vcs_read 3 8017 NULL
+normalize_up_8037 normalize_up 0-2-1 8037 NULL
+vhost_add_used_and_signal_n_8038 vhost_add_used_and_signal_n 4 8038 NULL
+iser_rcv_completion_8048 iser_rcv_completion 2 8048 NULL
+leb_read_lock_8070 leb_read_lock 0 8070 NULL
+ext4_ext_map_blocks_8078 ext4_ext_map_blocks 0 8078 NULL
+venus_lookup_8121 venus_lookup 4 8121 NULL
+ieee80211_if_fmt_num_buffered_multicast_8127 ieee80211_if_fmt_num_buffered_multicast 3 8127 NULL
+__sk_mem_schedule_8185 __sk_mem_schedule 2 8185 NULL
+ieee80211_if_fmt_dot11MeshHoldingTimeout_8187 ieee80211_if_fmt_dot11MeshHoldingTimeout 3 8187 NULL
+__nf_nat_mangle_tcp_packet_8190 __nf_nat_mangle_tcp_packet 5-7 8190 NULL
+recent_mt_proc_write_8206 recent_mt_proc_write 3 8206 NULL
+rt2x00debug_write_bbp_8212 rt2x00debug_write_bbp 3 8212 NULL
+ad7879_spi_multi_read_8218 ad7879_spi_multi_read 3 8218 NULL
+sctp_ssnmap_size_8228 sctp_ssnmap_size 0-1-2 8228 NULL
+check_xattr_ref_inode_8244 check_xattr_ref_inode 0 8244 NULL
+add_rx_skb_8257 add_rx_skb 3 8257 NULL
+t3_init_l2t_8261 t3_init_l2t 1 8261 NULL
+init_cdev_8274 init_cdev 1 8274 NULL
+qib_decode_7220_err_8315 qib_decode_7220_err 3 8315 NULL
+construct_key_and_link_8321 construct_key_and_link 4 8321 NULL
+ipwireless_send_packet_8328 ipwireless_send_packet 4 8328 NULL
+__c4iw_init_resource_fifo_8334 __c4iw_init_resource_fifo 3 8334 NULL
+tracing_entries_read_8345 tracing_entries_read 3 8345 NULL
+ping_getfrag_8360 ping_getfrag 4-3 8360 NULL
+ath6kl_lrssi_roam_write_8362 ath6kl_lrssi_roam_write 3 8362 NULL
+xdi_copy_from_user_8395 xdi_copy_from_user 4 8395 NULL
+zd_rf_scnprint_id_8406 zd_rf_scnprint_id 0-3 8406 NULL
+uvc_v4l2_ioctl_8411 uvc_v4l2_ioctl 2 8411 NULL
+snd_usb_ctl_msg_8436 snd_usb_ctl_msg 8 8436 NULL
+generic_bin_search_8440 generic_bin_search 0 8440 NULL
+afs_cell_lookup_8482 afs_cell_lookup 2 8482 NULL
+fore200e_chunk_alloc_8501 fore200e_chunk_alloc 4-3 8501 NULL
+dev_config_8506 dev_config 3 8506 NULL
+ACL_to_cifs_posix_8509 ACL_to_cifs_posix 3 8509 NULL
+utf16_strnlen_8513 utf16_strnlen 0 8513 NULL
+snd_malloc_sgbuf_pages_8532 snd_malloc_sgbuf_pages 2 8532 NULL
+ocfs2_read_virt_blocks_8538 ocfs2_read_virt_blocks 2-3 8538 NULL
+profile_remove_8556 profile_remove 3 8556 NULL
+cache_slow_downcall_8570 cache_slow_downcall 2 8570 NULL
+tower_write_8580 tower_write 3 8580 NULL
+shash_setkey_unaligned_8620 shash_setkey_unaligned 3 8620 NULL
+it821x_firmware_command_8628 it821x_firmware_command 3 8628 NULL
+scsi_dma_map_8632 scsi_dma_map 0 8632 NULL
+fuse_send_write_pages_8636 fuse_send_write_pages 0 8636 NULL
+nf_nat_mangle_tcp_packet_8643 nf_nat_mangle_tcp_packet 5-7 8643 NULL
+generic_acl_set_8658 generic_acl_set 4 8658 NULL
+ath6kl_tm_rx_report_event_8660 ath6kl_tm_rx_report_event 3 8660 NULL
+lbs_bcnmiss_read_8678 lbs_bcnmiss_read 3 8678 NULL
+skb_frag_size_8695 skb_frag_size 0 8695 NULL
+i_size_read_8703 i_size_read 0 8703 NULL nohasharray
+init_header_8703 init_header 0 8703 &i_size_read_8703
+cifs_writedata_alloc_8710 cifs_writedata_alloc 1 8710 NULL
+ctrl_out_8712 ctrl_out 3-5 8712 NULL
+tracing_max_lat_write_8728 tracing_max_lat_write 3 8728 NULL
+jffs2_acl_count_8729 jffs2_acl_count 0-1 8729 NULL
+yurex_write_8761 yurex_write 3 8761 NULL
+joydev_compat_ioctl_8765 joydev_compat_ioctl 2 8765 NULL
+kstrtoint_from_user_8778 kstrtoint_from_user 2 8778 NULL
+__bitmap_weight_8796 __bitmap_weight 0-2 8796 NULL
+cpuset_common_file_read_8800 cpuset_common_file_read 5 8800 NULL
+intel_ring_begin_8808 intel_ring_begin 0 8808 NULL
+get_queue_depth_8833 get_queue_depth 0 8833 NULL
+usb_ep_queue_8839 usb_ep_queue 0 8839 NULL
+wa_nep_queue_8858 wa_nep_queue 2 8858 NULL
+iwl_dbgfs_debug_level_write_8871 iwl_dbgfs_debug_level_write 3 8871 NULL
+compressed_bio_size_8887 compressed_bio_size 0-2 8887 NULL
+ab3100_get_set_reg_8890 ab3100_get_set_reg 3 8890 NULL nohasharray
+tracing_max_lat_read_8890 tracing_max_lat_read 3 8890 &ab3100_get_set_reg_8890
+sdio_max_byte_size_8907 sdio_max_byte_size 0 8907 NULL
+sysfs_merge_group_8917 sysfs_merge_group 0 8917 NULL
+write_file_ani_8918 write_file_ani 3 8918 NULL
+layout_commit_8926 layout_commit 3 8926 NULL
+adjust_priv_size_8935 adjust_priv_size 0-1 8935 NULL
+driver_stats_read_8944 driver_stats_read 3 8944 NULL
+read_file_tgt_stats_8959 read_file_tgt_stats 3 8959 NULL
+qib_qsfp_dump_8966 qib_qsfp_dump 0-3 8966 NULL
+venus_mkdir_8967 venus_mkdir 4 8967 NULL
+seq_open_net_8968 seq_open_net 4 8968 NULL nohasharray
+vol_cdev_read_8968 vol_cdev_read 3 8968 &seq_open_net_8968
+bio_integrity_get_tag_8974 bio_integrity_get_tag 3 8974 NULL
+snd_emu10k1_ptr_read_9026 snd_emu10k1_ptr_read 0-2 9026 NULL
+fd_ioctl_9028 fd_ioctl 3 9028 NULL
+nla_put_9042 nla_put 3 9042 NULL
+snd_emu10k1_synth_copy_from_user_9061 snd_emu10k1_synth_copy_from_user 3-5 9061 NULL
+snd_gus_dram_peek_9062 snd_gus_dram_peek 4 9062 NULL
+fib_info_hash_alloc_9075 fib_info_hash_alloc 1 9075 NULL
+create_queues_9088 create_queues 2-3 9088 NULL
+ftdi_prepare_write_buffer_9093 ftdi_prepare_write_buffer 3 9093 NULL
+caif_stream_sendmsg_9110 caif_stream_sendmsg 4 9110 NULL
+pmcraid_change_queue_depth_9116 pmcraid_change_queue_depth 2 9116 NULL
+brcmf_sdbrcm_send_buf_9129 brcmf_sdbrcm_send_buf 6 9129 NULL
+apei_resources_merge_9149 apei_resources_merge 0 9149 NULL
+dbg_command_buf_9165 dbg_command_buf 2 9165 NULL
+altera_swap_ir_9194 altera_swap_ir 2 9194 NULL nohasharray
+alloc_group_attrs_9194 alloc_group_attrs 2 9194 &altera_swap_ir_9194
+snd_m3_get_pointer_9206 snd_m3_get_pointer 0 9206 NULL
+sctp_getsockopt_delayed_ack_9232 sctp_getsockopt_delayed_ack 2 9232 NULL
+ext4_mark_iloc_dirty_9239 ext4_mark_iloc_dirty 0 9239 NULL
+schedule_erase_9240 schedule_erase 0 9240 NULL
+ocfs2_clear_ext_refcount_9256 ocfs2_clear_ext_refcount 4 9256 NULL
+tcf_csum_ipv4_icmp_9258 tcf_csum_ipv4_icmp 3 9258 NULL
+btrfs_search_slot_9264 btrfs_search_slot 0 9264 NULL
+sparse_early_usemaps_alloc_node_9269 sparse_early_usemaps_alloc_node 4 9269 NULL
+iwl_dbgfs_stations_read_9309 iwl_dbgfs_stations_read 3 9309 NULL
+ceph_sync_setxattr_9310 ceph_sync_setxattr 4 9310 NULL
+sk_rmem_schedule_9331 sk_rmem_schedule 2 9331 NULL
+ocfs2_orphan_for_truncate_9342 ocfs2_orphan_for_truncate 4 9342 NULL
+read_9397 read 3 9397 NULL
+set_gpio_9412 set_gpio 0 9412 NULL
+bm_realloc_pages_9431 bm_realloc_pages 2 9431 NULL
+ffs_ep0_write_9438 ffs_ep0_write 3 9438 NULL
+kmalloc_array_9444 kmalloc_array 1-2 9444 NULL
+ieee80211_if_fmt_fwded_unicast_9454 ieee80211_if_fmt_fwded_unicast 3 9454 NULL
+mcs_unwrap_mir_9455 mcs_unwrap_mir 3 9455 NULL
+ext3_xattr_set_acl_9467 ext3_xattr_set_acl 4 9467 NULL
+agp_generic_alloc_user_9470 agp_generic_alloc_user 1 9470 NULL
+rbd_coll_end_req_9472 rbd_coll_end_req 3 9472 NULL
+__alloc_preds_9492 __alloc_preds 2 9492 NULL
+sock_recvmsg_9500 sock_recvmsg 0 9500 NULL
+lbs_threshold_write_9502 lbs_threshold_write 5 9502 NULL
+lp_write_9511 lp_write 3 9511 NULL
+mext_calc_swap_extents_9517 mext_calc_swap_extents 4 9517 NULL
+scsi_tgt_kspace_exec_9522 scsi_tgt_kspace_exec 8 9522 NULL
+read_file_dma_9530 read_file_dma 3 9530 NULL
+nlmsg_parse_9536 nlmsg_parse 2 9536 NULL
+audit_log_n_untrustedstring_9548 audit_log_n_untrustedstring 3 9548 NULL
+fw_node_create_9559 fw_node_create 2 9559 NULL
+kobj_map_9566 kobj_map 2-3 9566 NULL
+biovec_create_pools_9575 biovec_create_pools 2 9575 NULL
+ieee80211_tdls_mgmt_9581 ieee80211_tdls_mgmt 8 9581 NULL
+do_sync_9604 do_sync 1 9604 NULL
+snd_emu10k1_fx8010_read_9605 snd_emu10k1_fx8010_read 5-6 9605 NULL
+acpi_ex_insert_into_field_9638 acpi_ex_insert_into_field 3 9638 NULL
+compat_sys_keyctl_9639 compat_sys_keyctl 4 9639 NULL
+ocfs2_xattr_get_rec_9652 ocfs2_xattr_get_rec 0 9652 NULL
+queue_received_packet_9657 queue_received_packet 5 9657 NULL
+snd_opl4_mem_proc_write_9670 snd_opl4_mem_proc_write 5 9670 NULL
+dns_query_9676 dns_query 3-0 9676 NULL nohasharray
+ks8842_read16_9676 ks8842_read16 0 9676 &dns_query_9676
+qib_7322_handle_hwerrors_9678 qib_7322_handle_hwerrors 3 9678 NULL
+__erst_read_from_storage_9690 __erst_read_from_storage 0 9690 NULL
+is_hole_9694 is_hole 2 9694 NULL
+vx_transfer_end_9701 vx_transfer_end 0 9701 NULL
+ieee80211_if_read_aid_9705 ieee80211_if_read_aid 3 9705 NULL
+do_sigpending_9766 do_sigpending 2 9766 NULL
+__blk_queue_init_tags_9778 __blk_queue_init_tags 2 9778 NULL
+snd_mem_proc_write_9786 snd_mem_proc_write 3 9786 NULL
+parse_uac2_sample_rate_range_9801 parse_uac2_sample_rate_range 0 9801 NULL
+tpm_data_in_9802 tpm_data_in 0 9802 NULL
+ttm_bo_fbdev_io_9805 ttm_bo_fbdev_io 4 9805 NULL
+ieee80211_if_read_state_9813 ieee80211_if_read_state 3 9813 NULL nohasharray
+udpv6_recvmsg_9813 udpv6_recvmsg 4 9813 &ieee80211_if_read_state_9813
+cfg80211_send_deauth_9862 cfg80211_send_deauth 3 9862 NULL
+pmcraid_alloc_sglist_9864 pmcraid_alloc_sglist 1 9864 NULL
+snd_midi_event_new_9893 snd_midi_event_new 1 9893 NULL nohasharray
+bm_register_write_9893 bm_register_write 3 9893 &snd_midi_event_new_9893
+snd_gf1_pcm_playback_copy_9895 snd_gf1_pcm_playback_copy 3-5 9895 NULL
+receive_DataRequest_9904 receive_DataRequest 3 9904 NULL
+ext4_map_blocks_9916 ext4_map_blocks 0 9916 NULL
+root_nfs_parse_options_9937 root_nfs_parse_options 3 9937 NULL
+read_file_misc_9948 read_file_misc 3 9948 NULL
+set_rxd_buffer_pointer_9950 set_rxd_buffer_pointer 8 9950 NULL
+csum_partial_copy_fromiovecend_9957 csum_partial_copy_fromiovecend 3-4 9957 NULL
+btrfs_add_link_9973 btrfs_add_link 5 9973 NULL
+gameport_read_9983 gameport_read 0 9983 NULL
+nfs_readdata_alloc_9990 nfs_readdata_alloc 1 9990 NULL
+aat2870_dump_reg_10019 aat2870_dump_reg 0 10019 NULL
+handle_request_10024 handle_request 9 10024 NULL
+rbd_coll_end_req_index_10041 rbd_coll_end_req_index 5 10041 NULL
+userpolicy_type_attrsize_10067 userpolicy_type_attrsize 0 10067 NULL
+cifs_llseek_10091 cifs_llseek 2 10091 NULL
+get_elem_size_10110 get_elem_size 0-2 10110 NULL
+asd_store_update_bios_10165 asd_store_update_bios 4 10165 NULL
+kstrtol_from_user_10168 kstrtol_from_user 2 10168 NULL
+proc_pid_attr_read_10173 proc_pid_attr_read 3 10173 NULL
+jffs2_user_setxattr_10182 jffs2_user_setxattr 4 10182 NULL
+cciss_proc_write_10259 cciss_proc_write 3 10259 NULL
+snd_pcm_lib_preallocate_pages1_10273 snd_pcm_lib_preallocate_pages1 2 10273 NULL
+snd_rme9652_capture_copy_10287 snd_rme9652_capture_copy 5 10287 NULL
+read_emulate_10310 read_emulate 2-4 10310 NULL
+ttm_object_device_init_10321 ttm_object_device_init 2 10321 NULL
+tun_sendmsg_10337 tun_sendmsg 4 10337 NULL
+whci_add_cap_10350 whci_add_cap 0 10350 NULL
+dbAllocAny_10354 dbAllocAny 0 10354 NULL
+sta_ht_capa_read_10366 sta_ht_capa_read 3 10366 NULL
+ecryptfs_decode_and_decrypt_filename_10379 ecryptfs_decode_and_decrypt_filename 5 10379 NULL
+do_compat_pselect_10398 do_compat_pselect 1 10398 NULL
+qib_alloc_fast_reg_page_list_10507 qib_alloc_fast_reg_page_list 2 10507 NULL
+rbd_get_segment_10511 rbd_get_segment 0-3-4 10511 NULL nohasharray
+sel_write_disable_10511 sel_write_disable 3 10511 &rbd_get_segment_10511
+osd_req_write_sg_kern_10514 osd_req_write_sg_kern 5 10514 NULL
+rds_message_alloc_10517 rds_message_alloc 1 10517 NULL
+ocfs2_add_refcounted_extent_10526 ocfs2_add_refcounted_extent 6 10526 NULL
+snd_pcm_lib_read_10536 snd_pcm_lib_read 0-3 10536 NULL nohasharray
+kstrtouint_from_user_10536 kstrtouint_from_user 2 10536 &snd_pcm_lib_read_10536
+i915_write_fence_reg_10551 i915_write_fence_reg 0 10551 NULL
+otp_read_10594 otp_read 2-4-5 10594 NULL
+supply_map_read_file_10608 supply_map_read_file 3 10608 NULL
+ima_show_htable_violations_10619 ima_show_htable_violations 3 10619 NULL
+cxgb3_get_cpl_reply_skb_10620 cxgb3_get_cpl_reply_skb 2 10620 NULL
+write_file_rx_chainmask_10636 write_file_rx_chainmask 3 10636 NULL
+br_nlmsg_size_10645 br_nlmsg_size 0 10645 NULL
+ubi_io_write_vid_hdr_10660 ubi_io_write_vid_hdr 0 10660 NULL
+efx_max_tx_len_10662 efx_max_tx_len 0-2 10662 NULL
+ni65_alloc_mem_10664 ni65_alloc_mem 3 10664 NULL
+parport_write_10669 parport_write 0 10669 NULL
+tcp_push_10680 tcp_push 3 10680 NULL
+selinux_inode_setxattr_10708 selinux_inode_setxattr 4 10708 NULL nohasharray
+inl_10708 inl 0 10708 &selinux_inode_setxattr_10708
+shash_async_setkey_10720 shash_async_setkey 3 10720 NULL
+__iscsi_complete_pdu_10726 __iscsi_complete_pdu 4 10726 NULL
+spi_sync_10731 spi_sync 0 10731 NULL
+sctp_getsockopt_maxseg_10737 sctp_getsockopt_maxseg 2 10737 NULL nohasharray
+apu_get_register_10737 apu_get_register 0 10737 &sctp_getsockopt_maxseg_10737
+compat_sys_msgsnd_10738 compat_sys_msgsnd 2 10738 NULL
+ttm_ref_object_add_10748 ttm_ref_object_add 0 10748 NULL
+vhost_add_used_n_10760 vhost_add_used_n 3 10760 NULL
+kvm_read_guest_atomic_10765 kvm_read_guest_atomic 4 10765 NULL
+posix_acl_to_xattr_10767 posix_acl_to_xattr 0 10767 NULL
+loopback_bytepos_update_10776 loopback_bytepos_update 2 10776 NULL
+i915_gem_wait_for_error_10791 i915_gem_wait_for_error 0 10791 NULL
+sys_bind_10799 sys_bind 3 10799 NULL
+diva_set_trace_filter_10820 diva_set_trace_filter 0-1 10820 NULL
+send_command_10832 send_command 4 10832 NULL
+lbs_sleepparams_read_10840 lbs_sleepparams_read 3 10840 NULL
+fuse_conn_max_background_read_10855 fuse_conn_max_background_read 3 10855 NULL
+ol_chunk_blocks_10864 ol_chunk_blocks 0 10864 NULL
+snd_pcm_oss_write1_10872 snd_pcm_oss_write1 3 10872 NULL
+drm_ht_insert_item_10877 drm_ht_insert_item 0 10877 NULL
+get_scq_10897 get_scq 2 10897 NULL
+cgroup_write_string_10900 cgroup_write_string 5 10900 NULL
+tifm_alloc_adapter_10903 tifm_alloc_adapter 1 10903 NULL
+__copy_from_user_10918 __copy_from_user 3-0 10918 NULL
+kobject_add_10919 kobject_add 0 10919 NULL
+iwl_calib_set_10944 iwl_calib_set 3 10944 NULL
+bm_entry_read_10976 bm_entry_read 3 10976 NULL
+sched_autogroup_write_10984 sched_autogroup_write 3 10984 NULL
+xfrm_hash_alloc_10997 xfrm_hash_alloc 1 10997 NULL
+carl9170_handle_mpdu_11056 carl9170_handle_mpdu 3 11056 NULL
+tcp_send_mss_11079 tcp_send_mss 0 11079 NULL
+count_argc_11083 count_argc 0 11083 NULL
+kvm_write_guest_cached_11106 kvm_write_guest_cached 4 11106 NULL
+tw_change_queue_depth_11116 tw_change_queue_depth 2 11116 NULL
+page_offset_11120 page_offset 0 11120 NULL
+tracing_buffers_read_11124 tracing_buffers_read 3 11124 NULL
+alloc_alien_cache_11127 alloc_alien_cache 2 11127 NULL
+ioat2_alloc_ring_11172 ioat2_alloc_ring 2 11172 NULL nohasharray
+snd_gf1_pcm_playback_silence_11172 snd_gf1_pcm_playback_silence 3-4 11172 &ioat2_alloc_ring_11172
+__swab16p_11220 __swab16p 0 11220 NULL
+hugetlbfs_read_11268 hugetlbfs_read 3 11268 NULL
+ext4_xattr_check_names_11314 ext4_xattr_check_names 0 11314 NULL
+construct_key_11329 construct_key 3 11329 NULL nohasharray
+__kfifo_out_peek_11329 __kfifo_out_peek 0-3 11329 &construct_key_11329
+next_segment_11330 next_segment 0-2-1 11330 NULL
+i915_max_freq_write_11350 i915_max_freq_write 3 11350 NULL
+sel_write_create_11353 sel_write_create 3 11353 NULL
+drm_vblank_init_11362 drm_vblank_init 2 11362 NULL
+qib_get_base_info_11369 qib_get_base_info 3 11369 NULL
+dev_irnet_write_11398 dev_irnet_write 3 11398 NULL
+___alloc_bootmem_11410 ___alloc_bootmem 1 11410 NULL
+str_to_user_11411 str_to_user 2 11411 NULL
+trace_options_read_11419 trace_options_read 3 11419 NULL
+pci_set_power_state_11479 pci_set_power_state 0 11479 NULL
+sd_do_mode_sense_11507 sd_do_mode_sense 5 11507 NULL
+kmem_zalloc_11510 kmem_zalloc 1 11510 NULL
+skb_cow_data_11565 skb_cow_data 0-2 11565 NULL
+mlx4_init_cmpt_table_11569 mlx4_init_cmpt_table 3 11569 NULL
+lpfc_idiag_ctlacc_write_11576 lpfc_idiag_ctlacc_write 3 11576 NULL
+oprofilefs_ulong_to_user_11582 oprofilefs_ulong_to_user 3 11582 NULL
+snd_pcm_action_11589 snd_pcm_action 0 11589 NULL
+fw_device_op_ioctl_11595 fw_device_op_ioctl 2 11595 NULL
+hycapi_rx_capipkt_11602 hycapi_rx_capipkt 3 11602 NULL
+sisusb_send_bridge_packet_11649 sisusb_send_bridge_packet 2 11649 NULL
+nla_total_size_11658 nla_total_size 0-1 11658 NULL
+ide_queue_pc_tail_11673 ide_queue_pc_tail 5 11673 NULL
+btrfs_alloc_delayed_item_11678 btrfs_alloc_delayed_item 1 11678 NULL
+sctp_setsockopt_hmac_ident_11687 sctp_setsockopt_hmac_ident 3 11687 NULL
+split_11691 split 2 11691 NULL
+snd_ctl_elem_user_tlv_11695 snd_ctl_elem_user_tlv 3 11695 NULL
+blk_rq_cur_bytes_11723 blk_rq_cur_bytes 0 11723 NULL
+i2c_master_recv_11734 i2c_master_recv 0-3 11734 NULL
+tcf_csum_ipv6_icmp_11738 tcf_csum_ipv6_icmp 4 11738 NULL
+nfsd4_get_drc_mem_11748 nfsd4_get_drc_mem 0-1-2 11748 NULL
+iwl_dbgfs_qos_read_11753 iwl_dbgfs_qos_read 3 11753 NULL
+rd_regl_11767 rd_regl 0 11767 NULL
+pcpu_fc_alloc_11818 pcpu_fc_alloc 2 11818 NULL
+umc_device_register_11824 umc_device_register 0 11824 NULL
+zerocopy_sg_from_iovec_11828 zerocopy_sg_from_iovec 3 11828 NULL
+sctp_setsockopt_maxseg_11829 sctp_setsockopt_maxseg 3 11829 NULL
+rts51x_read_status_11830 rts51x_read_status 4 11830 NULL
+shmem_xattr_set_11843 shmem_xattr_set 4 11843 NULL
+unix_stream_connect_11844 unix_stream_connect 3 11844 NULL
+ecryptfs_copy_filename_11868 ecryptfs_copy_filename 4 11868 NULL
+_l2_alloc_skb_11883 _l2_alloc_skb 1 11883 NULL
+xstateregs_get_11906 xstateregs_get 4 11906 NULL
+kmalloc_slab_11917 kmalloc_slab 1 11917 NULL
+fs_devrw_entry_11924 fs_devrw_entry 3 11924 NULL
+bitmap_remap_11929 bitmap_remap 5 11929 NULL
+atomic_sub_return_11939 atomic_sub_return 0-1 11939 NULL
+dccp_feat_clone_sp_val_11942 dccp_feat_clone_sp_val 3 11942 NULL
+kvm_set_msr_common_11953 kvm_set_msr_common 3 11953 NULL
+f1x_swap_interleaved_region_11970 f1x_swap_interleaved_region 0-2 11970 NULL
+split_node_11976 split_node 0 11976 NULL
+atmel_read16_11981 atmel_read16 0 11981 NULL
+ftdi_elan_total_command_size_12045 ftdi_elan_total_command_size 0 12045 NULL
+ptc_proc_write_12076 ptc_proc_write 3 12076 NULL
+i915_gem_object_pin_12083 i915_gem_object_pin 0 12083 NULL
+xfs_handle_to_dentry_12135 xfs_handle_to_dentry 3 12135 NULL
+rawv6_seticmpfilter_12137 rawv6_seticmpfilter 5 12137 NULL
+generic_file_llseek_12139 generic_file_llseek 2 12139 NULL
+rawsock_recvmsg_12144 rawsock_recvmsg 4 12144 NULL
+btmrvl_sdio_host_to_card_12152 btmrvl_sdio_host_to_card 3 12152 NULL
+vmbus_open_12154 vmbus_open 2-3 12154 NULL
+tt_update_changes_12155 tt_update_changes 3 12155 NULL
+ddp_make_gl_12179 ddp_make_gl 1 12179 NULL
+compat_do_arpt_set_ctl_12184 compat_do_arpt_set_ctl 4 12184 NULL
+ip_generic_getfrag_12187 ip_generic_getfrag 3-4 12187 NULL
+pair_device_12188 pair_device 4 12188 NULL
+qt2160_read_block_12198 qt2160_read_block 4 12198 NULL
+bl_is_sector_init_12199 bl_is_sector_init 2 12199 NULL
+receive_copy_12216 receive_copy 3 12216 NULL
+snd_pcm_kernel_ioctl_12219 snd_pcm_kernel_ioctl 0 12219 NULL
+aat2870_reg_read_file_12221 aat2870_reg_read_file 3 12221 NULL
+ib_uverbs_unmarshall_recv_12251 ib_uverbs_unmarshall_recv 5 12251 NULL
+ath_descdma_setup_12257 ath_descdma_setup 5 12257 NULL
+shash_compat_setkey_12267 shash_compat_setkey 3 12267 NULL
+add_sctp_bind_addr_12269 add_sctp_bind_addr 3 12269 NULL
+roccat_common_send_12284 roccat_common_send 4 12284 NULL
+note_last_dentry_12285 note_last_dentry 3 12285 NULL
+roundup_to_multiple_of_64_12288 roundup_to_multiple_of_64 0-1 12288 NULL
+__einj_error_trigger_12304 __einj_error_trigger 0 12304 NULL
+bt_sock_recvmsg_12316 bt_sock_recvmsg 4 12316 NULL
+alloc_trace_probe_12323 alloc_trace_probe 6 12323 NULL
+tipc_msg_build_12326 tipc_msg_build 4 12326 NULL
+pcbit_writecmd_12332 pcbit_writecmd 2 12332 NULL
+mptctl_ioctl_12355 mptctl_ioctl 2 12355 NULL
+receive_packet_12367 receive_packet 2 12367 NULL
+xfs_iext_inline_to_direct_12384 xfs_iext_inline_to_direct 2 12384 NULL
+btrfs_file_extent_ram_bytes_12391 btrfs_file_extent_ram_bytes 0 12391 NULL nohasharray
+populate_dir_12391 populate_dir 0 12391 &btrfs_file_extent_ram_bytes_12391
+gfs2_llseek_12464 gfs2_llseek 2 12464 NULL
+skb_do_copy_data_nocache_12465 skb_do_copy_data_nocache 5 12465 NULL
+x25_sendmsg_12487 x25_sendmsg 4 12487 NULL
+nfs_readdir_make_qstr_12509 nfs_readdir_make_qstr 3 12509 NULL
+qib_alloc_fast_reg_mr_12526 qib_alloc_fast_reg_mr 2 12526 NULL
+ceph_osdc_wait_request_12572 ceph_osdc_wait_request 0 12572 NULL
+hvc_alloc_12579 hvc_alloc 4 12579 NULL
+pcpu_extend_area_map_12589 pcpu_extend_area_map 2 12589 NULL
+vhci_put_user_12604 vhci_put_user 4 12604 NULL
+fc_fcp_frame_alloc_12624 fc_fcp_frame_alloc 2 12624 NULL
+pn_sendmsg_12640 pn_sendmsg 4 12640 NULL
+nr_recvmsg_12649 nr_recvmsg 4 12649 NULL
+ocfs2_read_block_12659 ocfs2_read_block 0 12659 NULL
+trusted_update_12664 trusted_update 3 12664 NULL
+sel_read_class_12669 sel_read_class 3 12669 NULL nohasharray
+sparse_mem_maps_populate_node_12669 sparse_mem_maps_populate_node 4 12669 &sel_read_class_12669
+ieee80211_if_read_num_buffered_multicast_12716 ieee80211_if_read_num_buffered_multicast 3 12716 NULL
+inet6_prefix_nlmsg_size_12722 inet6_prefix_nlmsg_size 0 12722 NULL
+key_rx_spec_read_12736 key_rx_spec_read 3 12736 NULL
+ieee80211_if_read_dot11MeshMaxRetries_12756 ieee80211_if_read_dot11MeshMaxRetries 3 12756 NULL
+listxattr_12769 listxattr 3 12769 NULL
+sctp_ssnmap_init_12772 sctp_ssnmap_init 2-3 12772 NULL
+ip_ufo_append_data_12775 ip_ufo_append_data 6-7-8 12775 NULL
+platform_create_bundle_12785 platform_create_bundle 4-6 12785 NULL
+scsi_adjust_queue_depth_12802 scsi_adjust_queue_depth 3 12802 NULL
+xfs_inumbers_fmt_12817 xfs_inumbers_fmt 3 12817 NULL
+TSS_authhmac_12839 TSS_authhmac 3 12839 NULL
+spidev_sync_12842 spidev_sync 0 12842 NULL
+spidev_ioctl_12846 spidev_ioctl 2 12846 NULL
+get_leb_cnt_12892 get_leb_cnt 0-2 12892 NULL
+get_virtual_node_size_12908 get_virtual_node_size 0 12908 NULL
+rds_pages_in_vec_12922 rds_pages_in_vec 0 12922 NULL
+free_tind_blocks_12926 free_tind_blocks 0 12926 NULL
+do_inode_permission_12946 do_inode_permission 0 12946 NULL
+bcsp_prepare_pkt_12961 bcsp_prepare_pkt 3 12961 NULL
+bm_status_write_12964 bm_status_write 3 12964 NULL
+sctp_make_chunk_12986 sctp_make_chunk 4 12986 NULL
+__get_extent_inline_ref_13021 __get_extent_inline_ref 0 13021 NULL
+subsystem_filter_write_13022 subsystem_filter_write 3 13022 NULL
+generic_segment_checks_13041 generic_segment_checks 0 13041 NULL
+ocfs2_write_begin_13045 ocfs2_write_begin 3-4 13045 NULL
+ctnetlink_timestamp_size_13060 ctnetlink_timestamp_size 0 13060 NULL nohasharray
+__dn_setsockopt_13060 __dn_setsockopt 5 13060 &ctnetlink_timestamp_size_13060
+sandybridge_write_fence_reg_13080 sandybridge_write_fence_reg 0 13080 NULL
+xattr_getsecurity_13090 xattr_getsecurity 0 13090 NULL
+blk_rq_map_sg_13092 blk_rq_map_sg 0 13092 NULL
+snd_rme96_playback_copy_13111 snd_rme96_playback_copy 5 13111 NULL
+snd_pcm_lib_preallocate_pages_for_all_13112 snd_pcm_lib_preallocate_pages_for_all 4 13112 NULL
+bfad_debugfs_read_13119 bfad_debugfs_read 3 13119 NULL
+ip_make_skb_13129 ip_make_skb 5-6 13129 NULL
+blk_update_request_13146 blk_update_request 3 13146 NULL
+caif_stream_recvmsg_13173 caif_stream_recvmsg 4 13173 NULL
+mmc_ext_csd_read_13205 mmc_ext_csd_read 3 13205 NULL
+svm_msrpm_offset_13220 svm_msrpm_offset 0-1 13220 NULL
+wait_events_13243 wait_events 0 13243 NULL
+asix_read_cmd_13245 asix_read_cmd 5 13245 NULL
+snd_emu10k1_fx8010_tram_setup_13248 snd_emu10k1_fx8010_tram_setup 2 13248 NULL
+init_tid_tabs_13252 init_tid_tabs 2-3-4 13252 NULL
+hostap_80211_get_hdrlen_13255 hostap_80211_get_hdrlen 0 13255 NULL
+bio_integrity_trim_13259 bio_integrity_trim 3 13259 NULL
+simple_attr_write_13260 simple_attr_write 3 13260 NULL
+carl9170_rx_13272 carl9170_rx 3 13272 NULL
+pmcraid_notify_aen_13274 pmcraid_notify_aen 3 13274 NULL
+lpfc_idiag_mbxacc_get_setup_13282 lpfc_idiag_mbxacc_get_setup 0 13282 NULL
+platform_device_add_resources_13289 platform_device_add_resources 3 13289 NULL
+nf_nat_mangle_udp_packet_13321 nf_nat_mangle_udp_packet 5-7 13321 NULL
+us122l_ctl_msg_13330 us122l_ctl_msg 8 13330 NULL
+kvm_read_nested_guest_page_13337 kvm_read_nested_guest_page 5 13337 NULL
+iso_sched_alloc_13377 iso_sched_alloc 1 13377 NULL
+sky2_receive_13407 sky2_receive 2 13407 NULL
+encrypted_update_13414 encrypted_update 3 13414 NULL
+netxen_alloc_sds_rings_13417 netxen_alloc_sds_rings 2 13417 NULL nohasharray
+i915_gem_execbuffer_sync_rings_13417 i915_gem_execbuffer_sync_rings 0 13417 &netxen_alloc_sds_rings_13417
+keyring_read_13438 keyring_read 3 13438 NULL
+sctp_setsockopt_peer_primary_addr_13440 sctp_setsockopt_peer_primary_addr 3 13440 NULL
+ath6kl_cfg80211_connect_event_13443 ath6kl_cfg80211_connect_event 7-8-9 13443 NULL
+ocfs2_align_bytes_to_blocks_13512 ocfs2_align_bytes_to_blocks 2 13512 NULL
+core_status_13515 core_status 4 13515 NULL
+sctp_tsnmap_mark_13527 sctp_tsnmap_mark 2 13527 NULL
+bm_init_13529 bm_init 2 13529 NULL
+read_file_antenna_13574 read_file_antenna 3 13574 NULL
+cache_write_13589 cache_write 3 13589 NULL
+mpt_lan_receive_post_turbo_13592 mpt_lan_receive_post_turbo 2 13592 NULL
+irias_new_octseq_value_13596 irias_new_octseq_value 2 13596 NULL
+Rd_Indx_13602 Rd_Indx 3-2 13602 NULL
+wm8994_bulk_write_13615 wm8994_bulk_write 3 13615 NULL
+pmcraid_get_minor_13619 pmcraid_get_minor 0 13619 NULL
+packet_snd_13634 packet_snd 3 13634 NULL
+blk_msg_write_13655 blk_msg_write 3 13655 NULL
+cache_downcall_13666 cache_downcall 3 13666 NULL
+ext3_xattr_list_entries_13682 ext3_xattr_list_entries 0 13682 NULL
+usb_get_string_13693 usb_get_string 0 13693 NULL
+cfg80211_testmode_alloc_event_skb_13739 cfg80211_testmode_alloc_event_skb 2 13739 NULL
+audit_unpack_string_13748 audit_unpack_string 3 13748 NULL
+bat_ogm_aggregate_new_13813 bat_ogm_aggregate_new 2 13813 NULL
+random_read_13815 random_read 3 13815 NULL
+mutex_lock_interruptible_nested_13817 mutex_lock_interruptible_nested 0 13817 NULL
+mtd_do_readoob_13850 mtd_do_readoob 4 13850 NULL
+evdev_ioctl_compat_13851 evdev_ioctl_compat 2 13851 NULL
+compat_ip_setsockopt_13870 compat_ip_setsockopt 5 13870 NULL
+snd_pcm_aio_read_13900 snd_pcm_aio_read 3 13900 NULL
+qla2x00_get_ctx_sp_13912 qla2x00_get_ctx_sp 3 13912 NULL
+ext3_xattr_block_get_13936 ext3_xattr_block_get 0 13936 NULL
+ocfs2_xa_value_truncate_13940 ocfs2_xa_value_truncate 2 13940 NULL
+iwl_dbgfs_protection_mode_read_13943 iwl_dbgfs_protection_mode_read 3 13943 NULL
+ieee80211_if_read_min_discovery_timeout_13946 ieee80211_if_read_min_discovery_timeout 3 13946 NULL
+lpfc_idiag_queacc_read_13950 lpfc_idiag_queacc_read 3 13950 NULL
+snd_pcm_plug_slave_size_13967 snd_pcm_plug_slave_size 0-2 13967 NULL
+dsp_read_13980 dsp_read 2 13980 NULL
+ieee80211_bss_info_update_13991 ieee80211_bss_info_update 4 13991 NULL
+create_files_14003 create_files 0 14003 NULL
+sddr09_write_data_14014 sddr09_write_data 3 14014 NULL
+btrfs_get_blocks_direct_14016 btrfs_get_blocks_direct 2 14016 NULL
+_rtl92s_firmware_downloadcode_14021 _rtl92s_firmware_downloadcode 3 14021 NULL
+read_def_modal_eeprom_14041 read_def_modal_eeprom 3 14041 NULL
+ieee80211_if_fmt_aid_14055 ieee80211_if_fmt_aid 3 14055 NULL
+utf8_to_utf16le_14057 utf8_to_utf16le 0 14057 NULL
+sta_agg_status_read_14058 sta_agg_status_read 3 14058 NULL
+do_tcp_sendpages_14083 do_tcp_sendpages 3-4 14083 NULL
+do_proc_readlink_14096 do_proc_readlink 3 14096 NULL
+compat_sys_pselect6_14105 compat_sys_pselect6 1 14105 NULL
+nlmsg_len_14115 nlmsg_len 0 14115 NULL
+gsm_dlci_data_14155 gsm_dlci_data 3 14155 NULL
+ocfs2_xattr_value_truncate_14183 ocfs2_xattr_value_truncate 3 14183 NULL
+datafab_read_data_14186 datafab_read_data 4 14186 NULL
+tcp_manip_pkt_14202 tcp_manip_pkt 2 14202 NULL
+alloc_async_14208 alloc_async 1 14208 NULL
+ath6kl_regread_write_14220 ath6kl_regread_write 3 14220 NULL
+sys_kexec_load_14222 sys_kexec_load 2 14222 NULL
+dma_declare_coherent_memory_14244 dma_declare_coherent_memory 4 14244 NULL
+snd_soc_hw_bulk_write_raw_14245 snd_soc_hw_bulk_write_raw 4 14245 NULL
+ext4_journal_restart_14251 ext4_journal_restart 0 14251 NULL
+ath6kl_connect_event_14267 ath6kl_connect_event 7-8-9 14267 NULL
+add_numbered_child_14273 add_numbered_child 5 14273 NULL
+snd_seq_oss_readq_new_14283 snd_seq_oss_readq_new 2 14283 NULL
+audit_send_reply_14292 audit_send_reply 7 14292 NULL
+rr_status_14293 rr_status 5 14293 NULL
+read_default_ldt_14302 read_default_ldt 2 14302 NULL
+i915_gem_object_finish_gpu_14312 i915_gem_object_finish_gpu 0 14312 NULL
+oo_objects_14319 oo_objects 0 14319 NULL
+p9_client_zc_rpc_14345 p9_client_zc_rpc 7 14345 NULL
+snd_pcm_lib_readv_14363 snd_pcm_lib_readv 3-0 14363 NULL
+ath6kl_regdump_read_14393 ath6kl_regdump_read 3 14393 NULL
+smk_write_onlycap_14400 smk_write_onlycap 3 14400 NULL
+mtd_concat_create_14416 mtd_concat_create 2 14416 NULL
+get_kcore_size_14425 get_kcore_size 0 14425 NULL
+block_size_14443 block_size 0 14443 NULL
+snd_emu10k1_proc_spdif_status_14457 snd_emu10k1_proc_spdif_status 4-5 14457 NULL
+udplite_getfrag_14479 udplite_getfrag 3-4 14479 NULL
+ieee80211_if_read_dot11MeshGateAnnouncementProtocol_14486 ieee80211_if_read_dot11MeshGateAnnouncementProtocol 3 14486 NULL
+cmd_complete_14502 cmd_complete 5 14502 NULL
+ocfs2_debug_read_14507 ocfs2_debug_read 3 14507 NULL
+dataflash_read_user_otp_14536 dataflash_read_user_otp 3-2 14536 NULL nohasharray
+ep0_write_14536 ep0_write 3 14536 &dataflash_read_user_otp_14536 nohasharray
+prepare_data_14536 prepare_data 3 14536 &ep0_write_14536
+picolcd_debug_eeprom_read_14549 picolcd_debug_eeprom_read 3 14549 NULL
+nfqnl_mangle_14583 nfqnl_mangle 2 14583 NULL
+idmap_pipe_downcall_14591 idmap_pipe_downcall 3 14591 NULL
+dbJoin_14644 dbJoin 0 14644 NULL
+profile_replace_14652 profile_replace 3 14652 NULL
+min_bytes_needed_14675 min_bytes_needed 0 14675 NULL
+ieee80211_if_fmt_rc_rateidx_mask_2ghz_14683 ieee80211_if_fmt_rc_rateidx_mask_2ghz 3 14683 NULL
+u_audio_playback_14709 u_audio_playback 3 14709 NULL
+__blk_end_request_14729 __blk_end_request 3 14729 NULL
+sta_dev_read_14782 sta_dev_read 3 14782 NULL
+keys_proc_write_14792 keys_proc_write 3 14792 NULL
+ext4_kvmalloc_14796 ext4_kvmalloc 1 14796 NULL
+__kfifo_in_14797 __kfifo_in 3 14797 NULL
+snd_als300_gcr_read_14801 snd_als300_gcr_read 0 14801 NULL nohasharray
+hpet_readl_14801 hpet_readl 0 14801 &snd_als300_gcr_read_14801
+do_tune_cpucache_14828 do_tune_cpucache 2 14828 NULL
+__mutex_fastpath_lock_retval_14844 __mutex_fastpath_lock_retval 0 14844 NULL
+__krealloc_14857 __krealloc 2 14857 NULL nohasharray
+lcd_write_14857 lcd_write 3 14857 &__krealloc_14857
+get_user_cpu_mask_14861 get_user_cpu_mask 2 14861 NULL
+acpi_os_allocate_14892 acpi_os_allocate 1 14892 NULL
+krealloc_14908 krealloc 2 14908 NULL
+__arch_hweight64_14923 __arch_hweight64 0 14923 NULL
+ocfs2_expand_nonsparse_inode_14936 ocfs2_expand_nonsparse_inode 3-4 14936 NULL
+queue_cnt_14951 queue_cnt 0 14951 NULL
+unix_dgram_recvmsg_14952 unix_dgram_recvmsg 4 14952 NULL
+help_14971 help 4 14971 NULL
+setkey_14987 setkey 3 14987 NULL
+blk_integrity_tuple_size_15027 blk_integrity_tuple_size 0 15027 NULL
+nfs4_write_cached_acl_15070 nfs4_write_cached_acl 4 15070 NULL
+ntfs_copy_from_user_15072 ntfs_copy_from_user 3-5-0 15072 NULL
+pppoe_recvmsg_15073 pppoe_recvmsg 4 15073 NULL
+hex_dump_to_buffer_15121 hex_dump_to_buffer 6 15121 NULL
+start_port_15124 start_port 0 15124 NULL
+ipwireless_ppp_mru_15153 ipwireless_ppp_mru 0 15153 NULL
+iscsi_create_endpoint_15193 iscsi_create_endpoint 1 15193 NULL
+bfad_debugfs_write_regrd_15218 bfad_debugfs_write_regrd 3 15218 NULL
+nlmsg_total_size_15230 nlmsg_total_size 0-1 15230 NULL
+iwl_dbgfs_sram_write_15239 iwl_dbgfs_sram_write 3 15239 NULL
+simple_strtol_15273 simple_strtol 0 15273 NULL
+fw_realloc_buffer_15280 fw_realloc_buffer 2 15280 NULL
+sys_connect_15291 sys_connect 3 15291 NULL
+fcoe_ctlr_send_keep_alive_15308 fcoe_ctlr_send_keep_alive 3 15308 NULL
+__ocfs2_remove_xattr_range_15330 __ocfs2_remove_xattr_range 4-3-5 15330 NULL
+ioread16_15342 ioread16 0 15342 NULL
+alloc_ring_15345 alloc_ring 2-4 15345 NULL
+acpi_ut_create_string_object_15360 acpi_ut_create_string_object 1 15360 NULL
+compat_sys_process_vm_readv_15374 compat_sys_process_vm_readv 3-5 15374 NULL
+alloc_fddidev_15382 alloc_fddidev 1 15382 NULL
+get_modalias_15406 get_modalias 2 15406 NULL
+tcp_mtu_to_mss_15438 tcp_mtu_to_mss 0-2 15438 NULL
+hpsa_change_queue_depth_15449 hpsa_change_queue_depth 2 15449 NULL
+zd_chip_is_zd1211b_15518 zd_chip_is_zd1211b 0 15518 NULL
+p9_check_zc_errors_15534 p9_check_zc_errors 4 15534 NULL
+ql_process_mac_rx_page_15543 ql_process_mac_rx_page 4 15543 NULL
+xfrm_state_mtu_15548 xfrm_state_mtu 0-2 15548 NULL
+mlx4_buf_alloc_15572 mlx4_buf_alloc 2 15572 NULL
+persistent_status_15574 persistent_status 4 15574 NULL
+bnx2fc_process_unsol_compl_15576 bnx2fc_process_unsol_compl 2 15576 NULL
+ocfs2_truncate_rec_15595 ocfs2_truncate_rec 7 15595 NULL
+compat_fillonedir_15620 compat_fillonedir 3 15620 NULL
+dsp_cmx_send_member_15625 dsp_cmx_send_member 2 15625 NULL
+proc_loginuid_read_15631 proc_loginuid_read 3 15631 NULL
+tomoyo_scan_bprm_15642 tomoyo_scan_bprm 2-4 15642 NULL
+joydev_handle_JSIOCSBTNMAP_15643 joydev_handle_JSIOCSBTNMAP 3 15643 NULL
+xsd_read_15653 xsd_read 3 15653 NULL
+unix_bind_15668 unix_bind 3 15668 NULL
+dm_read_15674 dm_read 3 15674 NULL
+i915_gem_object_set_to_cpu_domain_15705 i915_gem_object_set_to_cpu_domain 0 15705 NULL
+inet6_if_nlmsg_size_15711 inet6_if_nlmsg_size 0 15711 NULL
+ocfs2_split_tree_15716 ocfs2_split_tree 5 15716 NULL
+HiSax_readstatus_15752 HiSax_readstatus 2 15752 NULL
+sk_wmem_schedule_15759 sk_wmem_schedule 2 15759 NULL
+smk_read_direct_15803 smk_read_direct 3 15803 NULL
+gnttab_expand_15817 gnttab_expand 1 15817 NULL
+afs_proc_rootcell_write_15822 afs_proc_rootcell_write 3 15822 NULL
+table_size_15851 table_size 0-1-2 15851 NULL
+ubi_io_write_15870 ubi_io_write 0 15870 NULL
+__mptctl_ioctl_15875 __mptctl_ioctl 2 15875 NULL
+native_read_msr_15905 native_read_msr 0 15905 NULL
+power_read_15939 power_read 3 15939 NULL
+lpfc_idiag_drbacc_read_15948 lpfc_idiag_drbacc_read 3 15948 NULL
+snd_pcm_lib_read_transfer_15952 snd_pcm_lib_read_transfer 5-2-4 15952 NULL
+get_entry_16003 get_entry 4 16003 NULL
+got_frame_16028 got_frame 2 16028 NULL
+dccp_recvmsg_16056 dccp_recvmsg 4 16056 NULL
+snd_sgbuf_aligned_pages_16063 snd_sgbuf_aligned_pages 0-1 16063 NULL
+rd_mem_16117 rd_mem 0 16117 NULL
+snd_dma_pointer_16126 snd_dma_pointer 0-2 16126 NULL
+compat_sys_select_16131 compat_sys_select 1 16131 NULL
+fsm_init_16134 fsm_init 2 16134 NULL
+hysdn_rx_netpkt_16136 hysdn_rx_netpkt 3 16136 NULL
+ext4_xattr_block_get_16148 ext4_xattr_block_get 0 16148 NULL
+cipso_v4_map_cat_rng_hton_16203 cipso_v4_map_cat_rng_hton 0 16203 NULL
+create_table_16213 create_table 2 16213 NULL
+atomic_read_file_16227 atomic_read_file 3 16227 NULL
+btrfs_dev_extent_chunk_offset_16247 btrfs_dev_extent_chunk_offset 0 16247 NULL
+mark_written_sectors_16262 mark_written_sectors 2 16262 NULL
+reiserfs_acl_count_16265 reiserfs_acl_count 0-1 16265 NULL
+ocfs2_xattr_bucket_value_truncate_16279 ocfs2_xattr_bucket_value_truncate 4 16279 NULL
+nand_bch_init_16280 nand_bch_init 3-2 16280 NULL nohasharray
+drbd_setsockopt_16280 drbd_setsockopt 5 16280 &nand_bch_init_16280
+account_16283 account 0-4-2 16283 NULL
+jumpshot_read_data_16287 jumpshot_read_data 4 16287 NULL
+rsc_mgr_init_16299 rsc_mgr_init 3 16299 NULL
+total_ps_buffered_read_16365 total_ps_buffered_read 3 16365 NULL
+iscsi_tcp_conn_setup_16376 iscsi_tcp_conn_setup 2 16376 NULL
+nl80211_send_unprot_deauth_16378 nl80211_send_unprot_deauth 4 16378 NULL
+scsi_nl_send_vendor_msg_16394 scsi_nl_send_vendor_msg 5 16394 NULL
+ieee80211_if_read_tsf_16420 ieee80211_if_read_tsf 3 16420 NULL
+rxrpc_server_keyring_16431 rxrpc_server_keyring 3 16431 NULL
+calculate_inocache_hashsize_16449 calculate_inocache_hashsize 0-1 16449 NULL
+netlink_change_ngroups_16457 netlink_change_ngroups 2 16457 NULL
+sock_wmalloc_16472 sock_wmalloc 2 16472 NULL
+tracing_readme_read_16493 tracing_readme_read 3 16493 NULL
+start_this_handle_16519 start_this_handle 0 16519 NULL
+snd_interval_max_16529 snd_interval_max 0 16529 NULL
+lpfc_debugfs_read_16566 lpfc_debugfs_read 3 16566 NULL
+agp_allocate_memory_wrap_16576 agp_allocate_memory_wrap 1 16576 NULL
+__cfg80211_testmode_alloc_skb_16611 __cfg80211_testmode_alloc_skb 2 16611 NULL
+packet_recv_error_16669 packet_recv_error 3 16669 NULL
+dlm_new_lockspace_16688 dlm_new_lockspace 2 16688 NULL
+calc_layout_16690 calc_layout 4 16690 NULL
+iscsi_recv_pdu_16755 iscsi_recv_pdu 4 16755 NULL
+arcmsr_adjust_disk_queue_depth_16756 arcmsr_adjust_disk_queue_depth 2 16756 NULL
+blk_rq_map_user_iov_16772 blk_rq_map_user_iov 5 16772 NULL
+i2o_parm_issue_16790 i2o_parm_issue 0 16790 NULL
+get_server_iovec_16804 get_server_iovec 2 16804 NULL
+tipc_send2name_16809 tipc_send2name 6 16809 NULL
+drm_malloc_ab_16831 drm_malloc_ab 1-2 16831 NULL
+scsi_mode_sense_16835 scsi_mode_sense 5 16835 NULL
+hfsplus_min_io_size_16859 hfsplus_min_io_size 0 16859 NULL
+alloc_idx_lebs_16872 alloc_idx_lebs 2 16872 NULL
+carl9170_debugfs_ampdu_state_read_16873 carl9170_debugfs_ampdu_state_read 3 16873 NULL
+st_write_16874 st_write 3 16874 NULL
+__kfifo_peek_n_16877 __kfifo_peek_n 0 16877 NULL
+ext4_ext_zeroout_16895 ext4_ext_zeroout 0 16895 NULL
+mwifiex_update_curr_bss_params_16908 mwifiex_update_curr_bss_params 5 16908 NULL
+snd_gf1_mem_proc_dump_16926 snd_gf1_mem_proc_dump 5 16926 NULL
+random32_16937 random32 0 16937 NULL
+ip_append_data_16942 ip_append_data 5-6 16942 NULL
+_sp2d_alloc_16944 _sp2d_alloc 1-2-3 16944 NULL
+squashfs_read_table_16945 squashfs_read_table 3 16945 NULL
+cfg80211_send_unprot_disassoc_16951 cfg80211_send_unprot_disassoc 3 16951 NULL
+keyctl_instantiate_key_iov_16969 keyctl_instantiate_key_iov 3 16969 NULL
+ceph_read_dir_17005 ceph_read_dir 3 17005 NULL
+copy_counters_to_user_17027 copy_counters_to_user 5 17027 NULL
+jffs2_trusted_setxattr_17048 jffs2_trusted_setxattr 4 17048 NULL
+__arch_hweight32_17060 __arch_hweight32 0 17060 NULL
+sddr55_read_data_17072 sddr55_read_data 4 17072 NULL
+simple_transaction_read_17076 simple_transaction_read 3 17076 NULL
+carl9170_debugfs_mem_usage_read_17084 carl9170_debugfs_mem_usage_read 3 17084 NULL
+entry_length_17093 entry_length 0 17093 NULL
+sys_preadv_17100 sys_preadv 3 17100 NULL
+write_mem_17114 write_mem 3 17114 NULL
+mwifiex_get_common_rates_17131 mwifiex_get_common_rates 3 17131 NULL
+jumpshot_write_data_17151 jumpshot_write_data 4 17151 NULL
+befs_nls2utf_17163 befs_nls2utf 3 17163 NULL
+pm860x_page_bulk_read_17174 pm860x_page_bulk_read 3 17174 NULL
+access_remote_vm_17189 access_remote_vm 0 17189 NULL nohasharray
+iwl_dbgfs_txfifo_flush_write_17189 iwl_dbgfs_txfifo_flush_write 3 17189 &access_remote_vm_17189
+iscsit_find_cmd_from_itt_or_dump_17194 iscsit_find_cmd_from_itt_or_dump 3 17194 NULL
+dn_recvmsg_17213 dn_recvmsg 4 17213 NULL
+__be16_to_cpup_17261 __be16_to_cpup 0 17261 NULL
+alloc_ep_17269 alloc_ep 1 17269 NULL
+pg_read_17276 pg_read 3 17276 NULL
+raw_recvmsg_17277 raw_recvmsg 4 17277 NULL
+neigh_hash_grow_17283 neigh_hash_grow 2 17283 NULL
+minstrel_stats_read_17290 minstrel_stats_read 3 17290 NULL
+skb_pad_17302 skb_pad 2 17302 NULL
+mb_cache_create_17307 mb_cache_create 2 17307 NULL
+ata_host_alloc_pinfo_17325 ata_host_alloc_pinfo 3 17325 NULL
+lpfc_debugfs_dif_err_write_17424 lpfc_debugfs_dif_err_write 3 17424 NULL
+compat_sys_ppoll_17430 compat_sys_ppoll 2 17430 NULL
+sta_connected_time_read_17435 sta_connected_time_read 3 17435 NULL
+snd_hammerfall_get_buffer_17441 snd_hammerfall_get_buffer 3 17441 NULL
+nla_get_u32_17455 nla_get_u32 0 17455 NULL
+__ref_totlen_17461 __ref_totlen 0 17461 NULL nohasharray
+__send_request_17461 __send_request 0 17461 &__ref_totlen_17461
+probe_kernel_write_17481 probe_kernel_write 3 17481 NULL
+TSS_rawhmac_17486 TSS_rawhmac 3 17486 NULL
+lbs_highrssi_write_17515 lbs_highrssi_write 3 17515 NULL
+restore_i387_fxsave_17528 restore_i387_fxsave 2 17528 NULL
+__cfg80211_roamed_17529 __cfg80211_roamed 5-7 17529 NULL
+__copy_to_user_17551 __copy_to_user 3-0 17551 NULL
+copy_from_user_17559 copy_from_user 3-0 17559 NULL
+acpi_ut_create_package_object_17594 acpi_ut_create_package_object 1 17594 NULL
+neigh_hash_alloc_17595 neigh_hash_alloc 1 17595 NULL
+rts51x_write_mem_17598 rts51x_write_mem 4 17598 NULL
+brcmf_process_nvram_vars_17601 brcmf_process_nvram_vars 0 17601 NULL nohasharray
+iwl_dump_nic_event_log_17601 iwl_dump_nic_event_log 0 17601 &brcmf_process_nvram_vars_17601
+__inode_info_17603 __inode_info 0 17603 NULL
+osst_execute_17607 osst_execute 7-6 17607 NULL
+ocfs2_mark_extent_written_17615 ocfs2_mark_extent_written 6 17615 NULL
+dma_map_page_17628 dma_map_page 0 17628 NULL
+packet_setsockopt_17662 packet_setsockopt 5 17662 NULL nohasharray
+ubi_io_read_data_17662 ubi_io_read_data 0 17662 &packet_setsockopt_17662
+dsp_tone_hw_message_17678 dsp_tone_hw_message 3 17678 NULL
+venus_rename_17707 venus_rename 4-5 17707 NULL
+intel_wait_ring_buffer_17727 intel_wait_ring_buffer 0 17727 NULL
+exofs_read_lookup_dev_table_17733 exofs_read_lookup_dev_table 3 17733 NULL
+sctpprobe_read_17741 sctpprobe_read 3 17741 NULL
+gnet_stats_copy_app_17821 gnet_stats_copy_app 3 17821 NULL
+cipso_v4_gentag_rbm_17836 cipso_v4_gentag_rbm 0 17836 NULL
+count_leafs_17842 count_leafs 0 17842 NULL
+tcp_left_out_17860 tcp_left_out 0 17860 NULL
+sisusb_send_bulk_msg_17864 sisusb_send_bulk_msg 3 17864 NULL
+alloc_sja1000dev_17868 alloc_sja1000dev 1 17868 NULL
+ray_cs_essid_proc_write_17875 ray_cs_essid_proc_write 3 17875 NULL
+orinoco_set_key_17878 orinoco_set_key 5-7 17878 NULL
+init_per_cpu_17880 init_per_cpu 1 17880 NULL
+ieee80211_if_fmt_dot11MeshMaxPeerLinks_17883 ieee80211_if_fmt_dot11MeshMaxPeerLinks 3 17883 NULL
+compat_sys_pwritev_17886 compat_sys_pwritev 3 17886 NULL
+ieee80211_if_fmt_dot11MeshHWMPRootMode_17890 ieee80211_if_fmt_dot11MeshHWMPRootMode 3 17890 NULL
+ocfs2_clusters_to_blocks_17896 ocfs2_clusters_to_blocks 0-2 17896 NULL
+dccp_feat_register_sp_17914 dccp_feat_register_sp 5 17914 NULL
+xfs_buf_associate_memory_17915 xfs_buf_associate_memory 3 17915 NULL
+srp_iu_pool_alloc_17920 srp_iu_pool_alloc 2 17920 NULL
+scsi_bufflen_17933 scsi_bufflen 0 17933 NULL
+calc_nr_buckets_17976 calc_nr_buckets 0 17976 NULL
+smk_write_cipso_17989 smk_write_cipso 3 17989 NULL
+fill_read_18019 fill_read 0 18019 NULL
+cryptd_alloc_instance_18048 cryptd_alloc_instance 2-3 18048 NULL
+ddebug_proc_write_18055 ddebug_proc_write 3 18055 NULL
+fpregs_get_18066 fpregs_get 4 18066 NULL
+kvm_read_guest_page_18074 kvm_read_guest_page 5 18074 NULL
+netlink_kernel_create_18110 netlink_kernel_create 3 18110 NULL
+svc_getnl_18120 svc_getnl 0 18120 NULL
+selinux_inode_setsecurity_18148 selinux_inode_setsecurity 4 18148 NULL
+_has_tag_18169 _has_tag 2 18169 NULL
+pccard_store_cis_18176 pccard_store_cis 6 18176 NULL
+cfpkt_create_18197 cfpkt_create 1 18197 NULL
+orinoco_add_extscan_result_18207 orinoco_add_extscan_result 3 18207 NULL
+gsm_control_message_18209 gsm_control_message 4 18209 NULL
+do_ipv6_setsockopt_18215 do_ipv6_setsockopt 5 18215 NULL
+gnttab_alloc_grant_references_18240 gnttab_alloc_grant_references 1 18240 NULL
+__sysfs_add_one_18258 __sysfs_add_one 0 18258 NULL
+qdisc_class_hash_alloc_18262 qdisc_class_hash_alloc 1 18262 NULL
+gfs2_alloc_sort_buffer_18275 gfs2_alloc_sort_buffer 1 18275 NULL
+alloc_ring_18278 alloc_ring 2-4 18278 NULL
+mmc_send_bus_test_18285 mmc_send_bus_test 4 18285 NULL
+um_idi_write_18293 um_idi_write 3 18293 NULL
+ip6ip6_err_18308 ip6ip6_err 5 18308 NULL
+alloc_and_copy_string_18321 alloc_and_copy_string 2 18321 NULL
+ecryptfs_send_message_18322 ecryptfs_send_message 2 18322 NULL
+bio_integrity_advance_18324 bio_integrity_advance 2 18324 NULL
+lcd_proc_write_18351 lcd_proc_write 3 18351 NULL
+xlbd_reserve_minors_18365 xlbd_reserve_minors 1-2 18365 NULL
+ep_io_18367 ep_io 0 18367 NULL
+snd_hda_get_connections_18437 snd_hda_get_connections 0 18437 NULL
+fuse_perform_write_18457 fuse_perform_write 4 18457 NULL
+regset_tls_set_18459 regset_tls_set 4 18459 NULL
+udpv6_setsockopt_18487 udpv6_setsockopt 5 18487 NULL nohasharray
+write_file_tx_chainmask_18487 write_file_tx_chainmask 3 18487 &udpv6_setsockopt_18487
+__copy_user_zeroing_intel_18510 __copy_user_zeroing_intel 0-3 18510 NULL
+snd_vx_inb_18514 snd_vx_inb 0 18514 NULL
+snd_gus_dram_poke_18525 snd_gus_dram_poke 4 18525 NULL
+seq_copy_in_user_18543 seq_copy_in_user 3 18543 NULL
+sas_change_queue_depth_18555 sas_change_queue_depth 2 18555 NULL
+debug_output_18575 debug_output 3 18575 NULL
+__netdev_alloc_skb_18595 __netdev_alloc_skb 2 18595 NULL
+filemap_fdatawait_range_18600 filemap_fdatawait_range 0 18600 NULL nohasharray
+slabinfo_write_18600 slabinfo_write 3 18600 &filemap_fdatawait_range_18600
+iowarrior_write_18604 iowarrior_write 3 18604 NULL
+from_buffer_18625 from_buffer 3 18625 NULL
+f1x_map_sysaddr_to_csrow_18628 f1x_map_sysaddr_to_csrow 2 18628 NULL
+cfg80211_send_rx_assoc_18638 cfg80211_send_rx_assoc 3 18638 NULL
+snd_pcm_oss_write3_18657 snd_pcm_oss_write3 0-3 18657 NULL
+xfs_iext_insert_18667 xfs_iext_insert 3 18667 NULL nohasharray
+edge_tty_recv_18667 edge_tty_recv 4 18667 &xfs_iext_insert_18667
+iwl_dbgfs_rx_handlers_read_18708 iwl_dbgfs_rx_handlers_read 3 18708 NULL
+ceph_alloc_page_vector_18710 ceph_alloc_page_vector 1 18710 NULL
+ocfs2_trim_extent_18711 ocfs2_trim_extent 3-4 18711 NULL
+blk_rq_bytes_18715 blk_rq_bytes 0 18715 NULL
+snd_als4k_gcr_read_addr_18741 snd_als4k_gcr_read_addr 0 18741 NULL
+o2hb_debug_create_18744 o2hb_debug_create 4 18744 NULL
+__erst_read_to_erange_from_nvram_18748 __erst_read_to_erange_from_nvram 0 18748 NULL
+read_file_dump_nfcal_18766 read_file_dump_nfcal 3 18766 NULL
+ffs_epfile_read_18775 ffs_epfile_read 3 18775 NULL
+alloc_fcdev_18780 alloc_fcdev 1 18780 NULL
+sys_modify_ldt_18824 sys_modify_ldt 3 18824 NULL
+mtf_test_write_18844 mtf_test_write 3 18844 NULL
+drm_ht_create_18853 drm_ht_create 2 18853 NULL
+sctp_setsockopt_events_18862 sctp_setsockopt_events 3 18862 NULL
+ieee80211_if_read_element_ttl_18869 ieee80211_if_read_element_ttl 3 18869 NULL
+xlog_find_verify_log_record_18870 xlog_find_verify_log_record 2 18870 NULL
+ceph_setxattr_18913 ceph_setxattr 4 18913 NULL
+snapshot_write_next_18937 snapshot_write_next 0 18937 NULL
+sctp_tsnmap_num_gabs_18952 sctp_tsnmap_num_gabs 0 18952 NULL
+fdb_nlmsg_size_18957 fdb_nlmsg_size 0 18957 NULL
+__nla_reserve_18974 __nla_reserve 3 18974 NULL
+alc_auto_create_extra_outs_18975 alc_auto_create_extra_outs 2 18975 NULL
+layout_in_gaps_19006 layout_in_gaps 2 19006 NULL
+huge_page_size_19008 huge_page_size 0 19008 NULL
+revalidate_19043 revalidate 2 19043 NULL
+drm_fb_helper_init_19044 drm_fb_helper_init 3-4 19044 NULL
+afs_vnode_store_data_19048 afs_vnode_store_data 2-3-4-5 19048 NULL
+create_gpadl_header_19064 create_gpadl_header 2 19064 NULL
+ieee80211_key_alloc_19065 ieee80211_key_alloc 3 19065 NULL
+copy_and_check_19089 copy_and_check 3 19089 NULL
+sys_process_vm_readv_19090 sys_process_vm_readv 3-5 19090 NULL
+sta_last_seq_ctrl_read_19106 sta_last_seq_ctrl_read 3 19106 NULL
+cifs_readv_from_socket_19109 cifs_readv_from_socket 3 19109 NULL
+skb_gro_offset_19123 skb_gro_offset 0 19123 NULL
+snd_als4k_iobase_readl_19136 snd_als4k_iobase_readl 0 19136 NULL
+alloc_irdadev_19140 alloc_irdadev 1 19140 NULL
+iwl_dbgfs_reply_tx_error_read_19205 iwl_dbgfs_reply_tx_error_read 3 19205 NULL
+vmw_unlocked_ioctl_19212 vmw_unlocked_ioctl 2 19212 NULL
+__copy_to_user_inatomic_19214 __copy_to_user_inatomic 3-0 19214 NULL
+dev_counters_read_19216 dev_counters_read 3 19216 NULL
+snd_mask_max_19224 snd_mask_max 0 19224 NULL
+ocfs2_prepare_inode_for_refcount_19303 ocfs2_prepare_inode_for_refcount 3-4 19303 NULL
+debug_read_19322 debug_read 3 19322 NULL
+cfg80211_inform_bss_19332 cfg80211_inform_bss 8 19332 NULL nohasharray
+lbs_host_sleep_write_19332 lbs_host_sleep_write 3 19332 &cfg80211_inform_bss_19332
+firmware_data_write_19360 firmware_data_write 6-5 19360 NULL
+read_zero_19366 read_zero 3 19366 NULL
+get_n_events_by_type_19401 get_n_events_by_type 0 19401 NULL
+pep_recvmsg_19402 pep_recvmsg 4 19402 NULL
+xfrm_alg_auth_len_19454 xfrm_alg_auth_len 0 19454 NULL
+gnet_stats_copy_19458 gnet_stats_copy 4 19458 NULL
+sky2_read16_19475 sky2_read16 0 19475 NULL
+refill_pool_19477 refill_pool 2 19477 NULL
+efivar_create_sysfs_entry_19485 efivar_create_sysfs_entry 2 19485 NULL
+__read_status_pciv2_19492 __read_status_pciv2 0 19492 NULL
+kstrtoll_from_user_19500 kstrtoll_from_user 2 19500 NULL
+v4l2_event_subscribe_19510 v4l2_event_subscribe 3 19510 NULL
+skb_realloc_headroom_19516 skb_realloc_headroom 2 19516 NULL
+atm_alloc_charge_19517 atm_alloc_charge 2 19517 NULL nohasharray
+dev_alloc_skb_19517 dev_alloc_skb 1 19517 &atm_alloc_charge_19517
+apei_exec_pre_map_gars_19529 apei_exec_pre_map_gars 0 19529 NULL
+ocfs2_control_message_19564 ocfs2_control_message 3 19564 NULL
+ieee80211_if_read_tkip_mic_test_19565 ieee80211_if_read_tkip_mic_test 3 19565 NULL
+nfsd_read_19568 nfsd_read 5 19568 NULL
+cgroup_read_s64_19570 cgroup_read_s64 5 19570 NULL
+bm_status_read_19583 bm_status_read 3 19583 NULL
+load_xattr_datum_19594 load_xattr_datum 0 19594 NULL
+rbd_snap_add_19678 rbd_snap_add 4 19678 NULL
+delay_status_19685 delay_status 4 19685 NULL
+read_reg_19723 read_reg 0 19723 NULL
+memcpy_toiovecend_19736 memcpy_toiovecend 4-3 19736 NULL
+snd_es1968_get_dma_ptr_19747 snd_es1968_get_dma_ptr 0 19747 NULL
+p9_client_read_19750 p9_client_read 5-0 19750 NULL
+pnpbios_proc_write_19758 pnpbios_proc_write 3 19758 NULL
+jffs2_acl_from_medium_19762 jffs2_acl_from_medium 2 19762 NULL
+__set_print_fmt_19776 __set_print_fmt 0 19776 NULL
+irda_setsockopt_19824 irda_setsockopt 5 19824 NULL
+vfs_getxattr_19832 vfs_getxattr 0 19832 NULL
+security_context_to_sid_19839 security_context_to_sid 2 19839 NULL
+cfg80211_mlme_register_mgmt_19852 cfg80211_mlme_register_mgmt 5 19852 NULL
+__nla_put_19857 __nla_put 3 19857 NULL
+cgroup_task_count_19930 cgroup_task_count 0 19930 NULL
+iwl_dbgfs_rx_queue_read_19943 iwl_dbgfs_rx_queue_read 3 19943 NULL
+ax25_send_frame_19964 ax25_send_frame 2 19964 NULL
+attach_hdlc_protocol_19986 attach_hdlc_protocol 3 19986 NULL
+ip_send_reply_19987 ip_send_reply 5 19987 NULL
+diva_um_idi_read_20003 diva_um_idi_read 0 20003 NULL
+rawv6_sendmsg_20080 rawv6_sendmsg 4 20080 NULL
+fuse_conn_limit_read_20084 fuse_conn_limit_read 3 20084 NULL
+aat2870_reg_write_file_20086 aat2870_reg_write_file 3 20086 NULL
+qla2x00_adjust_sdev_qdepth_up_20097 qla2x00_adjust_sdev_qdepth_up 2 20097 NULL
+root_nfs_copy_20111 root_nfs_copy 3 20111 NULL
+hptiop_adjust_disk_queue_depth_20122 hptiop_adjust_disk_queue_depth 2 20122 NULL
+tomoyo_commit_ok_20167 tomoyo_commit_ok 2 20167 NULL
+read_flush_pipefs_20171 read_flush_pipefs 3 20171 NULL
+create_trace_probe_20175 create_trace_probe 1 20175 NULL
+ext4_llseek_20183 ext4_llseek 2 20183 NULL
+rose_sendmsg_20249 rose_sendmsg 4 20249 NULL
+_rtl92s_get_h2c_cmdlen_20312 _rtl92s_get_h2c_cmdlen 0 20312 NULL
+vx_send_msg_nolock_20322 vx_send_msg_nolock 0 20322 NULL
+snd_cs4281_BA1_read_20323 snd_cs4281_BA1_read 5 20323 NULL
+ip_idents_reserve_20328 ip_idents_reserve 2 20328 NULL
+gfs2_glock_nq_m_20347 gfs2_glock_nq_m 1 20347 NULL
+snd_nm256_readl_20394 snd_nm256_readl 0 20394 NULL
+__kfifo_from_user_20399 __kfifo_from_user 3 20399 NULL
+interface_rx_20404 interface_rx 4 20404 NULL
+find_skb_20431 find_skb 2 20431 NULL
+tcp_fragment_20436 tcp_fragment 3 20436 NULL
+nfs3_setxattr_20458 nfs3_setxattr 4 20458 NULL
+ip_vs_icmp_xmit_v6_20464 ip_vs_icmp_xmit_v6 4 20464 NULL
+compat_ipv6_setsockopt_20468 compat_ipv6_setsockopt 5 20468 NULL
+read_buf_20469 read_buf 2 20469 NULL
+hidraw_report_event_20503 hidraw_report_event 3 20503 NULL
+xfs_iext_realloc_direct_20521 xfs_iext_realloc_direct 2 20521 NULL
+drbd_bm_resize_20522 drbd_bm_resize 2 20522 NULL
+amd_create_gatt_pages_20537 amd_create_gatt_pages 1 20537 NULL
+venus_create_20555 venus_create 4 20555 NULL
+crypto_ahash_reqsize_20569 crypto_ahash_reqsize 0 20569 NULL
+i915_max_freq_read_20581 i915_max_freq_read 3 20581 NULL
+qib_qsfp_write_20614 qib_qsfp_write 0-2-4 20614 NULL
+regcache_lzo_block_count_20628 regcache_lzo_block_count 0 20628 NULL
+snd_pcm_oss_prepare_20641 snd_pcm_oss_prepare 0 20641 NULL
+kfifo_copy_to_user_20646 kfifo_copy_to_user 3-4 20646 NULL
+cpulist_scnprintf_20648 cpulist_scnprintf 2-0 20648 NULL
+ceph_osdc_new_request_20654 ceph_osdc_new_request 15-4 20654 NULL
+snd_hdsp_playback_copy_20676 snd_hdsp_playback_copy 5 20676 NULL
+cpumask_size_20683 cpumask_size 0 20683 NULL
+read_file_tgt_int_stats_20697 read_file_tgt_int_stats 3 20697 NULL
+__maestro_read_20700 __maestro_read 0 20700 NULL
+cipso_v4_gentag_rng_20703 cipso_v4_gentag_rng 0 20703 NULL
+pcpu_page_first_chunk_20712 pcpu_page_first_chunk 1 20712 NULL
+ocfs2_read_xattr_bucket_20722 ocfs2_read_xattr_bucket 0 20722 NULL
+security_context_to_sid_force_20724 security_context_to_sid_force 2 20724 NULL
+vring_add_indirect_20737 vring_add_indirect 3-4 20737 NULL
+fb_prepare_logo_20743 fb_prepare_logo 0 20743 NULL
+vol_cdev_direct_write_20751 vol_cdev_direct_write 3 20751 NULL
+ocfs2_align_bytes_to_clusters_20754 ocfs2_align_bytes_to_clusters 2 20754 NULL
+ubi_io_read_20767 ubi_io_read 0 20767 NULL
+fb_alloc_cmap_gfp_20792 fb_alloc_cmap_gfp 2 20792 NULL
+iwl_dbgfs_rxon_flags_read_20795 iwl_dbgfs_rxon_flags_read 3 20795 NULL
+sys_sendto_20809 sys_sendto 6 20809 NULL
+ext4_convert_unwritten_extents_endio_20812 ext4_convert_unwritten_extents_endio 0 20812 NULL
+strndup_user_20819 strndup_user 2 20819 NULL
+uvc_alloc_entity_20836 uvc_alloc_entity 3-4 20836 NULL
+p9_tag_alloc_20845 p9_tag_alloc 3 20845 NULL
+snd_pcm_capture_avail_20867 snd_pcm_capture_avail 0 20867 NULL
+ocfs2_bmap_20874 ocfs2_bmap 2 20874 NULL
+rb_simple_write_20890 rb_simple_write 3 20890 NULL
+sisusb_send_packet_20891 sisusb_send_packet 2 20891 NULL
+key_icverrors_read_20895 key_icverrors_read 3 20895 NULL
+compat_sys_readv_20911 compat_sys_readv 3 20911 NULL
+ixj_write_20912 ixj_write 3 20912 NULL
+lbs_rdbbp_write_20918 lbs_rdbbp_write 3 20918 NULL
+htable_bits_20933 htable_bits 0 20933 NULL
+check_eofblocks_fl_20942 check_eofblocks_fl 0 20942 NULL
+altera_set_ir_post_20948 altera_set_ir_post 2 20948 NULL
+snd_rme9652_playback_copy_20970 snd_rme9652_playback_copy 5 20970 NULL
+brcmf_tx_frame_20978 brcmf_tx_frame 3 20978 NULL
+alg_setsockopt_20985 alg_setsockopt 5 20985 NULL
+qib_verbs_send_20999 qib_verbs_send 5-3 20999 NULL
+ocfs2_free_clusters_21001 ocfs2_free_clusters 4 21001 NULL
+btrfs_inode_ref_name_len_21024 btrfs_inode_ref_name_len 0 21024 NULL
+snd_pcm_lib_preallocate_pages_21031 snd_pcm_lib_preallocate_pages 4 21031 NULL
+lbs_threshold_read_21046 lbs_threshold_read 5 21046 NULL
+proc_fault_inject_write_21058 proc_fault_inject_write 3 21058 NULL
+rose_create_facilities_21067 rose_create_facilities 0 21067 NULL
+__cfg80211_send_disassoc_21096 __cfg80211_send_disassoc 3 21096 NULL
+ath6kl_send_go_probe_resp_21113 ath6kl_send_go_probe_resp 3 21113 NULL
+i2400m_rx_trace_21127 i2400m_rx_trace 3 21127 NULL
+new_skb_21148 new_skb 1 21148 NULL
+ipc_rcu_alloc_21208 ipc_rcu_alloc 1 21208 NULL
+_ocfs2_free_clusters_21220 _ocfs2_free_clusters 4 21220 NULL
+get_numpages_21227 get_numpages 0-1-2 21227 NULL
+input_ff_create_21240 input_ff_create 2 21240 NULL
+cfg80211_notify_new_peer_candidate_21242 cfg80211_notify_new_peer_candidate 4 21242 NULL
+sock_alloc_send_pskb_21246 sock_alloc_send_pskb 2 21246 NULL
+ocfs2_blocks_for_bytes_21268 ocfs2_blocks_for_bytes 0-2 21268 NULL
+get_zeroed_page_21322 get_zeroed_page 0 21322 NULL
+ftrace_profile_read_21327 ftrace_profile_read 3 21327 NULL
+iwl_legacy_tx_queue_init_21332 iwl_legacy_tx_queue_init 3 21332 NULL
+alloc_orinocodev_21371 alloc_orinocodev 1 21371 NULL
+split_leaf_21378 split_leaf 0 21378 NULL
+video_ioctl2_21380 video_ioctl2 2 21380 NULL
+diva_get_driver_dbg_mask_21399 diva_get_driver_dbg_mask 0 21399 NULL
+snd_m3_inw_21406 snd_m3_inw 0 21406 NULL
+snapshot_read_next_21426 snapshot_read_next 0 21426 NULL
+tcp_bound_to_half_wnd_21429 tcp_bound_to_half_wnd 0-2 21429 NULL
+tracing_saved_cmdlines_read_21434 tracing_saved_cmdlines_read 3 21434 NULL
+concat_writev_21451 concat_writev 3 21451 NULL
+ReadISAR_21453 ReadISAR 0 21453 NULL
+read_file_xmit_21487 read_file_xmit 3 21487 NULL
+mmc_alloc_sg_21504 mmc_alloc_sg 1 21504 NULL
+btrfs_file_aio_write_21520 btrfs_file_aio_write 4 21520 NULL
+cipso_v4_map_cat_enum_hton_21540 cipso_v4_map_cat_enum_hton 0 21540 NULL
+rxrpc_send_data_21553 rxrpc_send_data 5 21553 NULL
+snd_es18xx_mixer_read_21586 snd_es18xx_mixer_read 0 21586 NULL
+ocfs2_acl_from_xattr_21604 ocfs2_acl_from_xattr 2 21604 NULL
+ndisc_addr_option_pad_21630 ndisc_addr_option_pad 0 21630 NULL
+__jfs_getxattr_21631 __jfs_getxattr 0 21631 NULL
+carl9170_rx_copy_data_21656 carl9170_rx_copy_data 2 21656 NULL
+atalk_sendmsg_21677 atalk_sendmsg 4 21677 NULL
+ocfs2_xattr_get_nolock_21678 ocfs2_xattr_get_nolock 0 21678 NULL
+evdev_ioctl_handler_21705 evdev_ioctl_handler 2 21705 NULL
+drm_sman_init_21710 drm_sman_init 2-4-3 21710 NULL
+mthca_alloc_init_21754 mthca_alloc_init 2 21754 NULL
+l2down_create_21755 l2down_create 4 21755 NULL
+usbat_flash_read_data_21762 usbat_flash_read_data 4 21762 NULL
+gen_pool_add_21776 gen_pool_add 3 21776 NULL
+xfs_da_grow_inode_int_21785 xfs_da_grow_inode_int 3 21785 NULL
+kmalloc_order_trace_21788 kmalloc_order_trace 1 21788 NULL
+libipw_get_hdrlen_21792 libipw_get_hdrlen 0 21792 NULL
+lpfc_idiag_extacc_avail_get_21865 lpfc_idiag_extacc_avail_get 0-3 21865 NULL
+tcp_cookie_size_check_21873 tcp_cookie_size_check 0-1 21873 NULL nohasharray
+sisusbcon_bmove_21873 sisusbcon_bmove 6-5-7 21873 &tcp_cookie_size_check_21873
+dbAllocCtl_21911 dbAllocCtl 0 21911 NULL
+qsfp_1_read_21915 qsfp_1_read 3 21915 NULL
+rbd_req_read_21952 rbd_req_read 4-5 21952 NULL
+ti_recv_22027 ti_recv 4 22027 NULL
+zd_usb_read_fw_22049 zd_usb_read_fw 4 22049 NULL
+ieee80211_if_fmt_dropped_frames_ttl_22054 ieee80211_if_fmt_dropped_frames_ttl 3 22054 NULL
+btrfs_reloc_clone_csums_22077 btrfs_reloc_clone_csums 2-3 22077 NULL
+mem_rw_22085 mem_rw 3 22085 NULL
+rt2x00debug_read_crypto_stats_22109 rt2x00debug_read_crypto_stats 3 22109 NULL
+snd_hda_codec_read_22130 snd_hda_codec_read 0 22130 NULL
+__kfifo_alloc_22173 __kfifo_alloc 2-3 22173 NULL
+bio_chain_clone_22227 bio_chain_clone 4 22227 NULL
+mem_write_22232 mem_write 3 22232 NULL
+p9_virtio_zc_request_22240 p9_virtio_zc_request 6-5 22240 NULL
+compat_process_vm_rw_22254 compat_process_vm_rw 3-5 22254 NULL
+__btrfs_direct_write_22273 __btrfs_direct_write 4 22273 NULL
+__tun_chr_ioctl_22300 __tun_chr_ioctl 4 22300 NULL
+mesh_table_alloc_22305 mesh_table_alloc 1 22305 NULL
+udpv6_sendmsg_22316 udpv6_sendmsg 4 22316 NULL
+atomic_read_22342 atomic_read 0 22342 NULL
+snd_pcm_alsa_frames_22363 snd_pcm_alsa_frames 2 22363 NULL
+evdev_ioctl_22371 evdev_ioctl 2 22371 NULL
+btmrvl_psmode_read_22395 btmrvl_psmode_read 3 22395 NULL
+queue_reply_22416 queue_reply 3 22416 NULL
+__set_enter_print_fmt_22431 __set_enter_print_fmt 0 22431 NULL
+queue_max_segments_22441 queue_max_segments 0 22441 NULL
+handle_received_packet_22457 handle_received_packet 3 22457 NULL
+rt6_nlmsg_size_22473 rt6_nlmsg_size 0 22473 NULL
+ecryptfs_write_22488 ecryptfs_write 4-3 22488 NULL
+cache_write_procfs_22491 cache_write_procfs 3 22491 NULL
+mutex_lock_interruptible_22505 mutex_lock_interruptible 0 22505 NULL
+pskb_may_pull_22546 pskb_may_pull 2 22546 NULL
+ocfs2_read_extent_block_22550 ocfs2_read_extent_block 0 22550 NULL
+agp_alloc_page_array_22554 agp_alloc_page_array 1 22554 NULL
+dbFindCtl_22587 dbFindCtl 0 22587 NULL
+snapshot_read_22601 snapshot_read 3 22601 NULL
+sctp_setsockopt_connectx_old_22631 sctp_setsockopt_connectx_old 3 22631 NULL
+ide_core_cp_entry_22636 ide_core_cp_entry 3 22636 NULL
+sysfs_attr_ns_22645 sysfs_attr_ns 0 22645 NULL
+l2tp_ip_recvmsg_22681 l2tp_ip_recvmsg 4 22681 NULL
+ocfs2_get_block_22687 ocfs2_get_block 2 22687 NULL
+sys_ppoll_22688 sys_ppoll 2 22688 NULL
+alloc_libipw_22708 alloc_libipw 1 22708 NULL
+brcmf_sdbrcm_read_control_22721 brcmf_sdbrcm_read_control 3 22721 NULL
+aa_features_read_22730 aa_features_read 3 22730 NULL
+ax25_output_22736 ax25_output 2 22736 NULL
+ceph_decode_32_22738 ceph_decode_32 0 22738 NULL
+print_frame_22769 print_frame 0 22769 NULL
+ftrace_arch_read_dyn_info_22773 ftrace_arch_read_dyn_info 0 22773 NULL
+__generic_copy_to_user_intel_22806 __generic_copy_to_user_intel 0-3 22806 NULL
+can_nocow_odirect_22854 can_nocow_odirect 4-3 22854 NULL
+create_attr_set_22861 create_attr_set 1 22861 NULL
+usblp_new_writeurb_22894 usblp_new_writeurb 2 22894 NULL
+mdc800_device_read_22896 mdc800_device_read 3 22896 NULL
+virtqueue_add_buf_22924 virtqueue_add_buf 3-4 22924 NULL
+xstateregs_set_22932 xstateregs_set 4 22932 NULL
+pcpu_mem_zalloc_22948 pcpu_mem_zalloc 1 22948 NULL
+alloc_sglist_22960 alloc_sglist 1-2-3 22960 NULL
+caif_seqpkt_sendmsg_22961 caif_seqpkt_sendmsg 4 22961 NULL
+usb_get_langid_22983 usb_get_langid 0 22983 NULL
+remote_settings_file_write_22987 remote_settings_file_write 3 22987 NULL
+st_status_23032 st_status 5 23032 NULL
+reiserfs_add_entry_23062 reiserfs_add_entry 4 23062 NULL nohasharray
+unix_seqpacket_recvmsg_23062 unix_seqpacket_recvmsg 4 23062 &reiserfs_add_entry_23062
+kvm_mmu_gva_to_gpa_write_23075 kvm_mmu_gva_to_gpa_write 0 23075 NULL
+raw_sendmsg_23078 raw_sendmsg 4 23078 NULL
+rt2x00debug_write_eeprom_23091 rt2x00debug_write_eeprom 3 23091 NULL
+ntfs_ucstonls_23097 ntfs_ucstonls 3-5 23097 NULL
+pipe_iov_copy_from_user_23102 pipe_iov_copy_from_user 3 23102 NULL
+dgram_recvmsg_23104 dgram_recvmsg 4 23104 NULL
+mwl8k_cmd_set_beacon_23110 mwl8k_cmd_set_beacon 4 23110 NULL
+nl80211_send_rx_auth_23111 nl80211_send_rx_auth 4 23111 NULL
+__clear_user_23118 __clear_user 0-2 23118 NULL
+drm_mode_create_tv_properties_23122 drm_mode_create_tv_properties 2 23122 NULL
+ata_scsi_change_queue_depth_23126 ata_scsi_change_queue_depth 2 23126 NULL
+cfg80211_rx_mgmt_23138 cfg80211_rx_mgmt 4 23138 NULL
+read_file_ani_23161 read_file_ani 3 23161 NULL
+usblp_write_23178 usblp_write 3 23178 NULL
+gss_pipe_downcall_23182 gss_pipe_downcall 3 23182 NULL
+ieee80211_get_mesh_hdrlen_23183 ieee80211_get_mesh_hdrlen 0 23183 NULL
+tty_buffer_request_room_23228 tty_buffer_request_room 2-0 23228 NULL
+xlog_get_bp_23229 xlog_get_bp 2 23229 NULL nohasharray
+__read_status_pci_23229 __read_status_pci 0 23229 &xlog_get_bp_23229
+__kmalloc_23231 __kmalloc 1 23231 NULL
+rxrpc_client_sendmsg_23236 rxrpc_client_sendmsg 5 23236 NULL
+sctp_recvmsg_23265 sctp_recvmsg 4 23265 NULL
+uwb_dev_addr_print_23282 uwb_dev_addr_print 2 23282 NULL
+diva_get_trace_filter_23286 diva_get_trace_filter 0 23286 NULL
+i2cdev_write_23310 i2cdev_write 3 23310 NULL
+nl_pid_hash_zalloc_23314 nl_pid_hash_zalloc 1 23314 NULL
+page_readlink_23346 page_readlink 3 23346 NULL
+get_dst_timing_23358 get_dst_timing 0 23358 NULL
+ip_nat_sdp_media_23386 ip_nat_sdp_media 8 23386 NULL
+iscsi_change_queue_depth_23416 iscsi_change_queue_depth 2 23416 NULL
+ulog_alloc_skb_23427 ulog_alloc_skb 1 23427 NULL
+__cxio_init_resource_fifo_23447 __cxio_init_resource_fifo 3 23447 NULL nohasharray
+ocfs2_zero_tail_23447 ocfs2_zero_tail 3 23447 &__cxio_init_resource_fifo_23447
+hidraw_send_report_23449 hidraw_send_report 3 23449 NULL
+dn_nsp_send_disc_23469 dn_nsp_send_disc 2 23469 NULL
+__ata_change_queue_depth_23484 __ata_change_queue_depth 3 23484 NULL
+linear_conf_23485 linear_conf 2 23485 NULL
+event_filter_read_23494 event_filter_read 3 23494 NULL
+ext4_remove_blocks_23497 ext4_remove_blocks 0 23497 NULL
+ima_show_measurements_count_23536 ima_show_measurements_count 3 23536 NULL
+tcp_current_mss_23552 tcp_current_mss 0 23552 NULL
+tcp_match_skb_to_sack_23568 tcp_match_skb_to_sack 4-3 23568 NULL
+venus_symlink_23570 venus_symlink 6-4 23570 NULL
+iwl_dbgfs_interrupt_read_23574 iwl_dbgfs_interrupt_read 3 23574 NULL
+xfpregs_get_23586 xfpregs_get 4 23586 NULL
+cifs_spnego_key_instantiate_23588 cifs_spnego_key_instantiate 3 23588 NULL
+snd_interval_min_23590 snd_interval_min 0 23590 NULL
+cfpkt_create_pfx_23594 cfpkt_create_pfx 1-2 23594 NULL
+_alloc_cdb_cont_23609 _alloc_cdb_cont 2 23609 NULL
+islpci_mgt_transaction_23610 islpci_mgt_transaction 5 23610 NULL
+ocfs2_journal_access_23616 ocfs2_journal_access 0 23616 NULL
+__i2400mu_send_barker_23652 __i2400mu_send_barker 3 23652 NULL
+sInW_23663 sInW 0 23663 NULL
+nftl_partscan_23688 nftl_partscan 0 23688 NULL
+sock_alloc_send_skb_23720 sock_alloc_send_skb 2 23720 NULL
+pack_sg_list_p_23739 pack_sg_list_p 0-2 23739 NULL
+__kfifo_max_r_23768 __kfifo_max_r 0-2-1 23768 NULL
+tt_save_orig_buffer_23779 tt_save_orig_buffer 4 23779 NULL
+security_inode_getxattr_23781 security_inode_getxattr 0 23781 NULL
+__earlyonly_bootmem_alloc_23824 __earlyonly_bootmem_alloc 2 23824 NULL
+xfs_dir2_leaf_getdents_23841 xfs_dir2_leaf_getdents 3 23841 NULL
+iwl_dbgfs_nvm_read_23845 iwl_dbgfs_nvm_read 3 23845 NULL
+p54_init_common_23850 p54_init_common 1 23850 NULL
+ocfs2_xattr_get_clusters_23857 ocfs2_xattr_get_clusters 0 23857 NULL
+ieee80211_if_read_dot11MeshMaxPeerLinks_23878 ieee80211_if_read_dot11MeshMaxPeerLinks 3 23878 NULL
+ieee80211_if_read_channel_type_23884 ieee80211_if_read_channel_type 3 23884 NULL
+iwch_reject_cr_23901 iwch_reject_cr 3 23901 NULL
+device_create_bin_file_23914 device_create_bin_file 0 23914 NULL
+ipath_reg_phys_mr_23918 ipath_reg_phys_mr 3 23918 NULL
+i915_gem_object_bind_to_gtt_23921 i915_gem_object_bind_to_gtt 0 23921 NULL
+kvm_read_guest_23928 kvm_read_guest 4-2 23928 NULL
+__alloc_skb_23940 __alloc_skb 1 23940 NULL
+cifs_setxattr_23957 cifs_setxattr 4 23957 NULL
+ixj_enhanced_write_23973 ixj_enhanced_write 3 23973 NULL
+sddr55_write_data_23983 sddr55_write_data 4 23983 NULL
+zd_usb_iowrite16v_async_23984 zd_usb_iowrite16v_async 3 23984 NULL
+brcmf_sdcard_recv_buf_24006 brcmf_sdcard_recv_buf 6 24006 NULL
+cxgb_alloc_mem_24007 cxgb_alloc_mem 1 24007 NULL
+ocfs2_mark_extent_refcounted_24035 ocfs2_mark_extent_refcounted 6 24035 NULL
+afs_cell_alloc_24052 afs_cell_alloc 2 24052 NULL
+blkcipher_copy_iv_24075 blkcipher_copy_iv 3 24075 NULL
+request_key_auth_read_24109 request_key_auth_read 3 24109 NULL
+mpu401_read_24126 mpu401_read 0-3 24126 NULL
+_picolcd_flash_write_24134 _picolcd_flash_write 4 24134 NULL
+irnet_ctrl_write_24139 irnet_ctrl_write 3 24139 NULL
+adu_read_24177 adu_read 3 24177 NULL
+safe_prepare_write_buffer_24187 safe_prepare_write_buffer 3 24187 NULL
+shrink_tnc_24190 shrink_tnc 0 24190 NULL
+get_order_24203 get_order 0 24203 NULL
+ieee80211_if_read_dot11MeshHWMPpreqMinInterval_24208 ieee80211_if_read_dot11MeshHWMPpreqMinInterval 3 24208 NULL
+tcpprobe_sprint_24222 tcpprobe_sprint 2-0 24222 NULL
+pcpu_embed_first_chunk_24224 pcpu_embed_first_chunk 3-2-1 24224 NULL
+pci_num_vf_24235 pci_num_vf 0 24235 NULL
+sel_read_bool_24236 sel_read_bool 3 24236 NULL
+esp6_get_mtu_24264 esp6_get_mtu 0-2 24264 NULL
+calculate_sizes_24273 calculate_sizes 2 24273 NULL
+msg_size_24288 msg_size 0 24288 NULL
+gserial_connect_24302 gserial_connect 0 24302 NULL
+btmrvl_pscmd_read_24308 btmrvl_pscmd_read 3 24308 NULL
+ocfs2_direct_IO_get_blocks_24333 ocfs2_direct_IO_get_blocks 2 24333 NULL
+kzalloc_node_24352 kzalloc_node 1 24352 NULL
+qla2x00_handle_queue_full_24365 qla2x00_handle_queue_full 2 24365 NULL
+cfi_read_pri_24366 cfi_read_pri 3 24366 NULL
+btrfs_item_size_nr_24367 btrfs_item_size_nr 0 24367 NULL
+igetword_24373 igetword 0 24373 NULL
+max_io_len_24384 max_io_len 0-1 24384 NULL
+getxattr_24398 getxattr 4 24398 NULL
+blk_update_bidi_request_24415 blk_update_bidi_request 3-4 24415 NULL
+b43_debugfs_read_24425 b43_debugfs_read 3 24425 NULL
+xenbus_file_read_24427 xenbus_file_read 3 24427 NULL
+ieee80211_rx_mgmt_beacon_24430 ieee80211_rx_mgmt_beacon 3 24430 NULL
+evdev_do_ioctl_24459 evdev_do_ioctl 2 24459 NULL
+lbs_highsnr_write_24460 lbs_highsnr_write 3 24460 NULL
+ocfs2_write_cluster_by_desc_24466 ocfs2_write_cluster_by_desc 6-5 24466 NULL nohasharray
+skb_copy_and_csum_datagram_iovec_24466 skb_copy_and_csum_datagram_iovec 2 24466 &ocfs2_write_cluster_by_desc_24466
+request_key_with_auxdata_24515 request_key_with_auxdata 4 24515 NULL
+named_prepare_buf_24532 named_prepare_buf 2 24532 NULL
+rtnl_port_size_24537 rtnl_port_size 0 24537 NULL
+write_cache_pages_24562 write_cache_pages 0 24562 NULL
+printer_set_config_24568 printer_set_config 0 24568 NULL
+netlbl_domhsh_init_24576 netlbl_domhsh_init 1 24576 NULL
+ath6kl_wmi_startscan_cmd_24580 ath6kl_wmi_startscan_cmd 7 24580 NULL
+udf_compute_nr_groups_24594 udf_compute_nr_groups 0 24594 NULL
+ip6addrlbl_msgsize_24595 ip6addrlbl_msgsize 0 24595 NULL
+count_preds_24600 count_preds 0 24600 NULL
+alloc_wr_24635 alloc_wr 1-2 24635 NULL
+context_alloc_24645 context_alloc 3 24645 NULL
+blk_rq_err_bytes_24650 blk_rq_err_bytes 0 24650 NULL
+datafab_write_data_24696 datafab_write_data 4 24696 NULL
+simple_attr_read_24738 simple_attr_read 3 24738 NULL
+qla2x00_change_queue_depth_24742 qla2x00_change_queue_depth 2 24742 NULL
+ath_rxbuf_alloc_24745 ath_rxbuf_alloc 2 24745 NULL
+get_dma_residue_24749 get_dma_residue 0 24749 NULL
+kgdb_hex2mem_24755 kgdb_hex2mem 3 24755 NULL
+nfsd4_sanitize_slot_size_24756 nfsd4_sanitize_slot_size 0-1 24756 NULL
+mI_alloc_skb_24770 mI_alloc_skb 1 24770 NULL
+i915_cache_sharing_read_24775 i915_cache_sharing_read 3 24775 NULL
+ocfs2_read_blocks_24777 ocfs2_read_blocks 0 24777 NULL
+skb_make_writable_24783 skb_make_writable 2 24783 NULL
+datablob_hmac_verify_24786 datablob_hmac_verify 4 24786 NULL
+cache_read_24790 cache_read 3 24790 NULL
+user_regset_copyout_24796 user_regset_copyout 7 24796 NULL
+unpack_str_24798 unpack_str 0 24798 NULL
+kvm_read_guest_virt_helper_24804 kvm_read_guest_virt_helper 3-1 24804 NULL
+ath6kl_fwlog_mask_write_24810 ath6kl_fwlog_mask_write 3 24810 NULL
+net2272_read_24825 net2272_read 0 24825 NULL
+snd_als4k_gcr_read_24840 snd_als4k_gcr_read 0 24840 NULL
+snd_pcm_lib_buffer_bytes_24865 snd_pcm_lib_buffer_bytes 0 24865 NULL
+pnp_alloc_24869 pnp_alloc 1 24869 NULL nohasharray
+put_data_to_circ_buf_24869 put_data_to_circ_buf 3 24869 &pnp_alloc_24869
+bnx2fc_cmd_mgr_alloc_24873 bnx2fc_cmd_mgr_alloc 3-2 24873 NULL
+queues_read_24877 queues_read 3 24877 NULL
+codec_list_read_file_24910 codec_list_read_file 3 24910 NULL
+ocfs2_fiemap_24949 ocfs2_fiemap 3-4 24949 NULL
+packet_sendmsg_24954 packet_sendmsg 4 24954 NULL
+sys_rt_sigpending_24961 sys_rt_sigpending 2 24961 NULL
+llc_ui_sendmsg_24987 llc_ui_sendmsg 4 24987 NULL
+key_conf_hw_key_idx_read_25003 key_conf_hw_key_idx_read 3 25003 NULL
+gs_buf_alloc_25067 gs_buf_alloc 2 25067 NULL
+cxio_hal_init_rhdl_resource_25104 cxio_hal_init_rhdl_resource 1 25104 NULL
+ubifs_dir_llseek_25106 ubifs_dir_llseek 2 25106 NULL nohasharray
+snd_rawmidi_kernel_write_25106 snd_rawmidi_kernel_write 3 25106 &ubifs_dir_llseek_25106
+oom_adjust_read_25127 oom_adjust_read 3 25127 NULL
+sys_fgetxattr_25166 sys_fgetxattr 4 25166 NULL
+sethdraddr_25167 sethdraddr 0 25167 NULL nohasharray
+ipath_init_qp_table_25167 ipath_init_qp_table 2 25167 &sethdraddr_25167
+sctp_getsockopt_local_addrs_25178 sctp_getsockopt_local_addrs 2 25178 NULL
+ks8851_rdreg32_25187 ks8851_rdreg32 0 25187 NULL
+mon_stat_read_25238 mon_stat_read 3 25238 NULL
+tcf_csum_ipv6_udp_25241 tcf_csum_ipv6_udp 4 25241 NULL
+compat_rw_copy_check_uvector_25242 compat_rw_copy_check_uvector 0-3 25242 NULL
+snd_pcm_start_25273 snd_pcm_start 0 25273 NULL
+crypto_alloc_instance2_25277 crypto_alloc_instance2 3 25277 NULL
+vfs_writev_25278 vfs_writev 3 25278 NULL
+l2tp_session_create_25286 l2tp_session_create 1 25286 NULL
+ceph_calc_object_layout_25305 ceph_calc_object_layout 0 25305 NULL
+ath9k_debugfs_read_buf_25316 ath9k_debugfs_read_buf 3 25316 NULL
+rng_buffer_size_25348 rng_buffer_size 0 25348 NULL
+i915_gem_execbuffer_relocate_slow_25355 i915_gem_execbuffer_relocate_slow 7-0 25355 NULL
+unix_mkname_25368 unix_mkname 0-2 25368 NULL
+sel_read_mls_25369 sel_read_mls 3 25369 NULL
+dai_list_read_file_25421 dai_list_read_file 3 25421 NULL
+generic_file_buffered_write_25464 generic_file_buffered_write 4 25464 NULL
+crypto_hash_digestsize_25469 crypto_hash_digestsize 0 25469 NULL
+snd_pcm_plugin_build_25505 snd_pcm_plugin_build 5 25505 NULL
+ext3_get_inode_loc_25542 ext3_get_inode_loc 0 25542 NULL
+ieee80211_if_read_path_refresh_time_25545 ieee80211_if_read_path_refresh_time 3 25545 NULL
+c4iw_init_resource_fifo_random_25547 c4iw_init_resource_fifo_random 3 25547 NULL
+wimax_addr_scnprint_25548 wimax_addr_scnprint 2 25548 NULL
+taskstats_packet_size_25553 taskstats_packet_size 0 25553 NULL
+ht_print_chan_25556 ht_print_chan 0 25556 NULL
+skb_tailroom_25567 skb_tailroom 0 25567 NULL
+realloc_packet_buffer_25569 realloc_packet_buffer 2 25569 NULL
+ping_recvmsg_25597 ping_recvmsg 4 25597 NULL
+__devres_alloc_25598 __devres_alloc 2 25598 NULL
+ddp_ppod_write_idata_25610 ddp_ppod_write_idata 5 25610 NULL
+copy_user_generic_25611 copy_user_generic 0 25611 NULL
+proc_coredump_filter_write_25625 proc_coredump_filter_write 3 25625 NULL
+befs_utf2nls_25628 befs_utf2nls 3 25628 NULL nohasharray
+__get_user_pages_25628 __get_user_pages 0 25628 &befs_utf2nls_25628
+aircable_prepare_write_buffer_25669 aircable_prepare_write_buffer 3 25669 NULL
+lpfc_idiag_cmd_get_25672 lpfc_idiag_cmd_get 2 25672 NULL
+sta_inactive_ms_read_25690 sta_inactive_ms_read 3 25690 NULL
+ibmasm_new_command_25714 ibmasm_new_command 2 25714 NULL
+rx_queue_entry_next_25715 rx_queue_entry_next 0 25715 NULL
+sel_write_context_25726 sel_write_context 3 25726 NULL nohasharray
+__alloc_bootmem_low_node_25726 __alloc_bootmem_low_node 2 25726 &sel_write_context_25726
+mcs_unwrap_fir_25733 mcs_unwrap_fir 3 25733 NULL
+cxgbi_device_portmap_create_25747 cxgbi_device_portmap_create 3 25747 NULL
+sg_read_25799 sg_read 3 25799 NULL
+sys32_rt_sigpending_25814 sys32_rt_sigpending 2 25814 NULL
+system_enable_read_25815 system_enable_read 3 25815 NULL
+realloc_buffer_25816 realloc_buffer 2 25816 NULL
+parport_read_25855 parport_read 0 25855 NULL
+xfs_dir2_sf_hdr_size_25858 xfs_dir2_sf_hdr_size 0 25858 NULL
+ath6kl_regread_read_25884 ath6kl_regread_read 3 25884 NULL
+run_delalloc_nocow_25896 run_delalloc_nocow 3-4 25896 NULL
+sisusbcon_scroll_area_25899 sisusbcon_scroll_area 4-3 25899 NULL
+lpfc_change_queue_depth_25905 lpfc_change_queue_depth 2 25905 NULL
+do_jffs2_setxattr_25910 do_jffs2_setxattr 5 25910 NULL
+rcname_read_25919 rcname_read 3 25919 NULL
+_get_word_25929 _get_word 0 25929 NULL
+snd_es1938_capture_copy_25930 snd_es1938_capture_copy 5 25930 NULL
+key_flags_read_25931 key_flags_read 3 25931 NULL
+copy_play_buf_25932 copy_play_buf 3 25932 NULL
+udp_setsockopt_25985 udp_setsockopt 5 25985 NULL
+xfs_xattr_acl_set_26028 xfs_xattr_acl_set 4 26028 NULL
+mptscsih_change_queue_depth_26036 mptscsih_change_queue_depth 2 26036 NULL
+selinux_inode_post_setxattr_26037 selinux_inode_post_setxattr 4 26037 NULL
+keyctl_update_key_26061 keyctl_update_key 3 26061 NULL
+__strnlen_user_26117 __strnlen_user 0-2 26117 NULL nohasharray
+intel_wrap_ring_buffer_26117 intel_wrap_ring_buffer 0 26117 &__strnlen_user_26117
+user_instantiate_26131 user_instantiate 3 26131 NULL
+skb_cow_26138 skb_cow 2 26138 NULL
+copy_oldmem_page_26164 copy_oldmem_page 3 26164 NULL
+gfs2_xattr_acl_get_26166 gfs2_xattr_acl_get 0 26166 NULL
+disk_devt_26180 disk_devt 0 26180 NULL
+get_registers_26187 get_registers 3 26187 NULL
+ieee80211_if_fmt_dot11MeshTTL_26198 ieee80211_if_fmt_dot11MeshTTL 3 26198 NULL
+xfs_idata_realloc_26199 xfs_idata_realloc 2 26199 NULL
+mce_write_26201 mce_write 3 26201 NULL
+mwifiex_regrdwr_write_26225 mwifiex_regrdwr_write 3 26225 NULL
+_scsih_change_queue_depth_26230 _scsih_change_queue_depth 2 26230 NULL
+cxio_num_stags_26233 cxio_num_stags 0 26233 NULL nohasharray
+rxrpc_recvmsg_26233 rxrpc_recvmsg 4 26233 &cxio_num_stags_26233
+bio_split_26235 bio_split 2 26235 NULL
+crypto_ctxsize_26278 crypto_ctxsize 0 26278 NULL
+apei_resources_request_26279 apei_resources_request 0 26279 NULL
+snd_pcm_plug_client_channels_buf_26309 snd_pcm_plug_client_channels_buf 0-3 26309 NULL
+tcp_sacktag_walk_26339 tcp_sacktag_walk 5-6 26339 NULL
+snd_vx_check_reg_bit_26344 snd_vx_check_reg_bit 0 26344 NULL
+ocfs2_duplicate_clusters_by_page_26357 ocfs2_duplicate_clusters_by_page 6-3-5 26357 NULL
+dup_to_netobj_26363 dup_to_netobj 3 26363 NULL
+invalidate_inode_pages2_range_26403 invalidate_inode_pages2_range 0 26403 NULL
+tcp_shift_skb_data_26405 tcp_shift_skb_data 5 26405 NULL
+pagemap_read_26441 pagemap_read 3 26441 NULL
+tower_read_26461 tower_read 3 26461 NULL
+ib_alloc_device_26483 ib_alloc_device 1 26483 NULL
+ulong_write_file_26485 ulong_write_file 3 26485 NULL
+__vhost_add_used_n_26554 __vhost_add_used_n 3 26554 NULL
+rts51x_read_mem_26577 rts51x_read_mem 4 26577 NULL
+drm_ht_find_item_26637 drm_ht_find_item 0 26637 NULL
+irq_alloc_generic_chip_26650 irq_alloc_generic_chip 2 26650 NULL nohasharray
+inb_p_26650 inb_p 0 26650 &irq_alloc_generic_chip_26650
+cipso_v4_map_cat_rbm_hton_26680 cipso_v4_map_cat_rbm_hton 0 26680 NULL
+__alloc_pred_stack_26687 __alloc_pred_stack 2 26687 NULL
+bos_desc_26752 bos_desc 0 26752 NULL
+srp_ring_alloc_26760 srp_ring_alloc 2 26760 NULL
+snd_hda_get_raw_connections_26762 snd_hda_get_raw_connections 0 26762 NULL
+dma_map_single_attrs_26779 dma_map_single_attrs 0 26779 NULL
+qlcnic_alloc_sds_rings_26795 qlcnic_alloc_sds_rings 2 26795 NULL
+cipso_v4_genopt_26812 cipso_v4_genopt 0 26812 NULL
+smk_write_load_26829 smk_write_load 3 26829 NULL
+scnprint_id_26842 scnprint_id 3-0 26842 NULL
+ecryptfs_miscdev_write_26847 ecryptfs_miscdev_write 3 26847 NULL
+svc_print_xprts_26881 svc_print_xprts 0 26881 NULL
+ctnetlink_counters_size_26898 ctnetlink_counters_size 0 26898 NULL
+slhc_uncompress_26905 slhc_uncompress 0-3 26905 NULL
+x25_asy_change_mtu_26928 x25_asy_change_mtu 2 26928 NULL
+scsi_tgt_copy_sense_26933 scsi_tgt_copy_sense 3 26933 NULL
+sctp_setsockopt_adaptation_layer_26935 sctp_setsockopt_adaptation_layer 3 26935 NULL
+extract_entropy_user_26952 extract_entropy_user 3 26952 NULL
+snd_pcm_lib_period_bytes_27071 snd_pcm_lib_period_bytes 0 27071 NULL
+paravirt_read_msr_27077 paravirt_read_msr 0 27077 NULL
+alloc_fdmem_27083 alloc_fdmem 1 27083 NULL
+find_first_bit_27088 find_first_bit 0 27088 NULL
+btmrvl_hscmd_write_27089 btmrvl_hscmd_write 3 27089 NULL
+__devcgroup_inode_permission_27108 __devcgroup_inode_permission 0 27108 NULL
+__ext4_handle_dirty_metadata_27137 __ext4_handle_dirty_metadata 0 27137 NULL
+drbd_get_capacity_27141 drbd_get_capacity 0 27141 NULL
+btmrvl_hscfgcmd_write_27143 btmrvl_hscfgcmd_write 3 27143 NULL
+i2400m_net_rx_27170 i2400m_net_rx 5 27170 NULL
+ieee80211_if_read_rc_rateidx_mask_5ghz_27183 ieee80211_if_read_rc_rateidx_mask_5ghz 3 27183 NULL
+write_kmem_27225 write_kmem 3 27225 NULL
+dbAllocAG_27228 dbAllocAG 0 27228 NULL
+rxrpc_request_key_27235 rxrpc_request_key 3 27235 NULL
+cfpkt_add_trail_27260 cfpkt_add_trail 3 27260 NULL
+nlmsg_new_27263 nlmsg_new 1 27263 NULL
+hpi_read_reg_27302 hpi_read_reg 0 27302 NULL
+copy_from_buf_27308 copy_from_buf 4-2 27308 NULL
+ath6kl_wmi_test_cmd_27312 ath6kl_wmi_test_cmd 3 27312 NULL
+ocfs2_blocks_to_clusters_27327 ocfs2_blocks_to_clusters 0-2 27327 NULL
+snd_pcm_oss_write2_27332 snd_pcm_oss_write2 3-0 27332 NULL
+afs_cell_create_27346 afs_cell_create 2 27346 NULL
+iwl_dbgfs_csr_write_27363 iwl_dbgfs_csr_write 3 27363 NULL
+pcbit_stat_27364 pcbit_stat 2 27364 NULL
+if_nlmsg_size_27404 if_nlmsg_size 0 27404 NULL
+seq_read_27411 seq_read 3 27411 NULL
+ieee80211_if_read_smps_27416 ieee80211_if_read_smps 3 27416 NULL
+pack_sg_list_27425 pack_sg_list 0-2 27425 NULL
+sddr09_read_data_27447 sddr09_read_data 3 27447 NULL
+hcd_buffer_alloc_27495 hcd_buffer_alloc 2 27495 NULL
+ip_set_get_h32_27498 ip_set_get_h32 0 27498 NULL
+garmin_read_process_27509 garmin_read_process 3 27509 NULL
+xfs_buf_read_uncached_27519 xfs_buf_read_uncached 4 27519 NULL
+ib_copy_to_udata_27525 ib_copy_to_udata 3 27525 NULL
+intel_gtt_map_memory_27539 intel_gtt_map_memory 0 27539 NULL
+snd_sonicvibes_getdmaa_27552 snd_sonicvibes_getdmaa 0 27552 NULL
+libipw_alloc_txb_27579 libipw_alloc_txb 1-3-2 27579 NULL
+tipc_cfg_reply_alloc_27606 tipc_cfg_reply_alloc 1 27606 NULL
+iwl4965_rs_sta_dbgfs_rate_scale_data_read_27619 iwl4965_rs_sta_dbgfs_rate_scale_data_read 3 27619 NULL
+ocfs2_xattr_ibody_get_27642 ocfs2_xattr_ibody_get 0 27642 NULL nohasharray
+nl80211_send_connect_result_27642 nl80211_send_connect_result 5-7 27642 &ocfs2_xattr_ibody_get_27642 nohasharray
+read_flush_procfs_27642 read_flush_procfs 3 27642 &nl80211_send_connect_result_27642
+add_new_gdb_27643 add_new_gdb 3 27643 NULL
+ieee80211_build_probe_req_27660 ieee80211_build_probe_req 7-5 27660 NULL
+cdrom_read_cdda_old_27664 cdrom_read_cdda_old 4 27664 NULL
+qword_get_27670 qword_get 0 27670 NULL
+ocfs2_extend_dir_27695 ocfs2_extend_dir 4 27695 NULL
+evm_write_key_27715 evm_write_key 3 27715 NULL
+ieee80211_if_fmt_dot11MeshGateAnnouncementProtocol_27722 ieee80211_if_fmt_dot11MeshGateAnnouncementProtocol 3 27722 NULL
+pstore_write_27724 pstore_write 3 27724 NULL nohasharray
+iwl_dbgfs_traffic_log_write_27724 iwl_dbgfs_traffic_log_write 3 27724 &pstore_write_27724
+xfs_dir2_block_sfsize_27727 xfs_dir2_block_sfsize 0 27727 NULL
+kcalloc_27770 kcalloc 1-2 27770 NULL
+ttm_object_file_init_27804 ttm_object_file_init 2 27804 NULL
+hpt374_read_freq_27828 hpt374_read_freq 0 27828 NULL
+sys_listxattr_27833 sys_listxattr 3 27833 NULL nohasharray
+init_header_complete_27833 init_header_complete 0 27833 &sys_listxattr_27833
+read_profile_27859 read_profile 3 27859 NULL
+sky2_pci_read16_27863 sky2_pci_read16 0 27863 NULL
+mangle_packet_27864 mangle_packet 6-8 27864 NULL
+unix_seqpacket_sendmsg_27893 unix_seqpacket_sendmsg 4 27893 NULL
+sctp_make_abort_violation_27959 sctp_make_abort_violation 4 27959 NULL
+tracing_clock_write_27961 tracing_clock_write 3 27961 NULL
+device_register_27972 device_register 0 27972 NULL
+snd_rawmidi_write_28008 snd_rawmidi_write 3 28008 NULL
+get_packet_pg_28023 get_packet_pg 4 28023 NULL
+raid_status_28025 raid_status 4 28025 NULL
+sctp_setsockopt_maxburst_28041 sctp_setsockopt_maxburst 3 28041 NULL
+init_rs_non_canonical_28059 init_rs_non_canonical 1 28059 NULL
+lpfc_idiag_mbxacc_read_28061 lpfc_idiag_mbxacc_read 3 28061 NULL
+GetRecvByte_28082 GetRecvByte 0 28082 NULL
+mmc_test_alloc_mem_28102 mmc_test_alloc_mem 3-2 28102 NULL
+vgacon_adjust_height_28124 vgacon_adjust_height 2 28124 NULL
+snd_midi_channel_alloc_set_28153 snd_midi_channel_alloc_set 1 28153 NULL
+stats_dot11FCSErrorCount_read_28154 stats_dot11FCSErrorCount_read 3 28154 NULL
+vread_28173 vread 0-3 28173 NULL
+c4iw_reject_cr_28174 c4iw_reject_cr 3 28174 NULL
+macvtap_get_user_28185 macvtap_get_user 4 28185 NULL
+amd_nb_num_28228 amd_nb_num 0 28228 NULL
+usemap_size_28281 usemap_size 0 28281 NULL
+dma_map_sg_attrs_28289 dma_map_sg_attrs 0 28289 NULL
+kstrtos16_from_user_28300 kstrtos16_from_user 2 28300 NULL
+nouveau_compat_ioctl_28305 nouveau_compat_ioctl 2 28305 NULL
+snd_pcm_oss_read_28317 snd_pcm_oss_read 3 28317 NULL
+bm_entry_write_28338 bm_entry_write 3 28338 NULL
+tcp_copy_to_iovec_28344 tcp_copy_to_iovec 3 28344 NULL
+snapshot_write_28351 snapshot_write 3 28351 NULL
+orig_node_del_if_28371 orig_node_del_if 2 28371 NULL
+sys_writev_28384 sys_writev 3 28384 NULL
+dlmfs_file_read_28385 dlmfs_file_read 3 28385 NULL
+subdev_ioctl_28417 subdev_ioctl 2 28417 NULL
+snd_emu10k1_efx_read_28452 snd_emu10k1_efx_read 2 28452 NULL
+alloc_irq_cpu_rmap_28459 alloc_irq_cpu_rmap 1 28459 NULL
+ocfs2_backup_super_blkno_28484 ocfs2_backup_super_blkno 0-2 28484 NULL
+max_response_pages_28492 max_response_pages 0 28492 NULL
+i2400m_tx_stats_read_28527 i2400m_tx_stats_read 3 28527 NULL
+capinc_tty_write_28539 capinc_tty_write 3 28539 NULL
+sel_read_policycap_28544 sel_read_policycap 3 28544 NULL
+mptctl_getiocinfo_28545 mptctl_getiocinfo 2 28545 NULL nohasharray
+run_delalloc_range_28545 run_delalloc_range 3-4 28545 &mptctl_getiocinfo_28545
+sysfs_create_bin_file_28551 sysfs_create_bin_file 0 28551 NULL
+b43legacy_debugfs_write_28556 b43legacy_debugfs_write 3 28556 NULL
+cfg80211_send_rx_auth_28580 cfg80211_send_rx_auth 3 28580 NULL
+oxygen_read32_28582 oxygen_read32 0 28582 NULL
+ocfs2_read_dir_block_28587 ocfs2_read_dir_block 2 28587 NULL
+extract_entropy_28604 extract_entropy 5-3 28604 NULL
+kfifo_unused_28612 kfifo_unused 0 28612 NULL
+snd_nm256_capture_copy_28622 snd_nm256_capture_copy 5-3 28622 NULL
+_set_range_28627 _set_range 3 28627 NULL
+setup_usemap_28636 setup_usemap 3-4 28636 NULL
+btrfs_previous_item_28667 btrfs_previous_item 0 28667 NULL
+blk_queue_resize_tags_28670 blk_queue_resize_tags 2 28670 NULL
+posix_acl_from_xattr_28675 posix_acl_from_xattr 2 28675 NULL
+__dev_alloc_skb_28681 __dev_alloc_skb 1 28681 NULL
+nl80211_send_new_peer_candidate_28692 nl80211_send_new_peer_candidate 5 28692 NULL
+balance_level_28707 balance_level 0 28707 NULL
+spi_execute_28736 spi_execute 5 28736 NULL
+snd_pcm_aio_write_28738 snd_pcm_aio_write 3 28738 NULL
+cxio_init_resource_fifo_28764 cxio_init_resource_fifo 3 28764 NULL
+rpc_pipe_generic_upcall_28766 rpc_pipe_generic_upcall 4 28766 NULL
+atomic_inc_return_unchecked_28778 atomic_inc_return_unchecked 0 28778 NULL
+ath6kl_get_num_reg_28780 ath6kl_get_num_reg 0 28780 NULL
+sel_write_member_28800 sel_write_member 3 28800 NULL
+cgroup_file_read_28804 cgroup_file_read 3 28804 NULL
+iwl_dbgfs_rxon_filter_flags_read_28832 iwl_dbgfs_rxon_filter_flags_read 3 28832 NULL
+vp_request_msix_vectors_28849 vp_request_msix_vectors 2 28849 NULL
+ipv6_renew_options_28867 ipv6_renew_options 5 28867 NULL
+max_io_len_target_boundary_28879 max_io_len_target_boundary 0-1 28879 NULL
+iwl3945_sta_dbgfs_stats_table_read_28882 iwl3945_sta_dbgfs_stats_table_read 3 28882 NULL
+packet_sendmsg_spkt_28885 packet_sendmsg_spkt 4 28885 NULL
+iwl_dbgfs_sleep_level_override_write_28925 iwl_dbgfs_sleep_level_override_write 3 28925 NULL
+push_rx_28939 push_rx 3 28939 NULL
+alloc_sched_domains_28972 alloc_sched_domains 1 28972 NULL
+hci_sock_setsockopt_28993 hci_sock_setsockopt 5 28993 NULL
+bin_uuid_28999 bin_uuid 3 28999 NULL
+rxrpc_sendmsg_29049 rxrpc_sendmsg 4 29049 NULL
+tso_fragment_29050 tso_fragment 3 29050 NULL
+split_bvec_29058 split_bvec 5 29058 NULL
+iso_packets_buffer_init_29061 iso_packets_buffer_init 3-4 29061 NULL
+lpfc_idiag_extacc_drivr_get_29067 lpfc_idiag_extacc_drivr_get 0-3 29067 NULL
+ieee80211_probereq_get_29069 ieee80211_probereq_get 4-6 29069 NULL
+mark_extents_written_29082 mark_extents_written 2-3 29082 NULL
+iwl_dbgfs_log_event_write_29088 iwl_dbgfs_log_event_write 3 29088 NULL
+isdn_ppp_write_29109 isdn_ppp_write 4 29109 NULL
+rbd_req_sync_op_29115 rbd_req_sync_op 10-9 29115 NULL
+snprintf_29125 snprintf 0 29125 NULL
+iov_shorten_29130 iov_shorten 0 29130 NULL
+proc_scsi_write_29142 proc_scsi_write 3 29142 NULL
+reshape_ring_29147 reshape_ring 2 29147 NULL
+wusb_prf_256_29203 wusb_prf_256 7 29203 NULL
+do_shrinker_shrink_29208 do_shrinker_shrink 0 29208 NULL
+security_socket_recvmsg_29224 security_socket_recvmsg 0 29224 NULL nohasharray
+iwl_dbgfs_temperature_read_29224 iwl_dbgfs_temperature_read 3 29224 &security_socket_recvmsg_29224
+security_context_to_sid_core_29248 security_context_to_sid_core 2 29248 NULL
+prism2_set_genericelement_29277 prism2_set_genericelement 3 29277 NULL
+ext4_fiemap_29296 ext4_fiemap 4 29296 NULL
+__alloc_ei_netdev_29338 __alloc_ei_netdev 1 29338 NULL
+alloc_and_copy_ftrace_hash_29368 alloc_and_copy_ftrace_hash 1 29368 NULL
+mempool_create_29437 mempool_create 1 29437 NULL
+crypto_ahash_alignmask_29445 crypto_ahash_alignmask 0 29445 NULL
+p9_client_prepare_req_29448 p9_client_prepare_req 3 29448 NULL
+validate_scan_freqs_29462 validate_scan_freqs 0 29462 NULL
+do_register_entry_29478 do_register_entry 4 29478 NULL
+simple_strtoul_29480 simple_strtoul 0 29480 NULL
+btmrvl_pscmd_write_29504 btmrvl_pscmd_write 3 29504 NULL
+btrfs_file_extent_disk_bytenr_29505 btrfs_file_extent_disk_bytenr 0 29505 NULL
+write_file_regidx_29517 write_file_regidx 3 29517 NULL
+atk_debugfs_ggrp_read_29522 atk_debugfs_ggrp_read 3 29522 NULL
+idetape_queue_rw_tail_29562 idetape_queue_rw_tail 3 29562 NULL
+leaf_dealloc_29566 leaf_dealloc 3 29566 NULL
+kvm_read_guest_virt_system_29569 kvm_read_guest_virt_system 4-2 29569 NULL
+lbs_lowsnr_read_29571 lbs_lowsnr_read 3 29571 NULL
+iwl_dbgfs_missed_beacon_write_29586 iwl_dbgfs_missed_beacon_write 3 29586 NULL
+slots_per_page_29601 slots_per_page 0 29601 NULL
+nla_get_u16_29624 nla_get_u16 0 29624 NULL
+sctp_make_abort_user_29654 sctp_make_abort_user 3 29654 NULL
+br_send_bpdu_29669 br_send_bpdu 3 29669 NULL
+new_lockspace_29674 new_lockspace 2 29674 NULL
+sisusb_write_mem_bulk_29678 sisusb_write_mem_bulk 4 29678 NULL
+jbd2_journal_restart_29692 jbd2_journal_restart 0 29692 NULL
+sd_alloc_ctl_entry_29708 sd_alloc_ctl_entry 1 29708 NULL
+probes_write_29711 probes_write 3 29711 NULL
+emi62_writememory_29731 emi62_writememory 4 29731 NULL
+read_cis_cache_29735 read_cis_cache 4 29735 NULL
+cxio_hal_init_resource_29771 cxio_hal_init_resource 7-6-2 29771 NULL nohasharray
+ip_vs_conn_fill_param_sync_29771 ip_vs_conn_fill_param_sync 6 29771 &cxio_hal_init_resource_29771
+cifs_ucs2_bytes_29790 cifs_ucs2_bytes 0 29790 NULL
+dbAlloc_29794 dbAlloc 0 29794 NULL
+tcp_sendpage_29829 tcp_sendpage 4-3 29829 NULL
+__probe_kernel_write_29842 __probe_kernel_write 3 29842 NULL
+count_partial_29850 count_partial 0 29850 NULL
+ipv6_setsockopt_29871 ipv6_setsockopt 5 29871 NULL
+scsi_end_request_29876 scsi_end_request 3 29876 NULL
+crypto_aead_alignmask_29885 crypto_aead_alignmask 0 29885 NULL
+nfc_targets_found_29886 nfc_targets_found 3 29886 NULL
+pin_code_reply_29893 pin_code_reply 4 29893 NULL
+write_file_queue_29922 write_file_queue 3 29922 NULL
+ext4_xattr_set_acl_29930 ext4_xattr_set_acl 4 29930 NULL
+__btrfs_getxattr_29947 __btrfs_getxattr 0 29947 NULL nohasharray
+ipv6_recv_error_29947 ipv6_recv_error 3 29947 &__btrfs_getxattr_29947
+xfrm_count_auth_supported_29957 xfrm_count_auth_supported 0 29957 NULL
+irias_add_octseq_attrib_29983 irias_add_octseq_attrib 4 29983 NULL
+alloc_netdev_mqs_30030 alloc_netdev_mqs 1 30030 NULL
+scsi_vpd_inquiry_30040 scsi_vpd_inquiry 4 30040 NULL
+cxgbi_ddp_reserve_30091 cxgbi_ddp_reserve 4 30091 NULL
+snd_midi_channel_init_set_30092 snd_midi_channel_init_set 1 30092 NULL
+tg3_run_loopback_30093 tg3_run_loopback 2 30093 NULL
+skb_pagelen_30113 skb_pagelen 0 30113 NULL
+spi_async_locked_30117 spi_async_locked 0 30117 NULL
+_osd_req_sizeof_alist_header_30134 _osd_req_sizeof_alist_header 0 30134 NULL
+recv_stream_30138 recv_stream 4 30138 NULL
+u_memcpya_30139 u_memcpya 2-3 30139 NULL
+i915_gem_object_get_pages_gtt_30154 i915_gem_object_get_pages_gtt 0 30154 NULL
+i915_gem_object_wait_rendering_30173 i915_gem_object_wait_rendering 0 30173 NULL
+mempool_create_page_pool_30189 mempool_create_page_pool 1 30189 NULL
+usblp_ioctl_30203 usblp_ioctl 2 30203 NULL
+preallocate_pcm_pages_30209 preallocate_pcm_pages 2 30209 NULL
+read_4k_modal_eeprom_30212 read_4k_modal_eeprom 3 30212 NULL
+snd_ac97_pcm_assign_30218 snd_ac97_pcm_assign 2 30218 NULL
+dccp_manip_pkt_30229 dccp_manip_pkt 2 30229 NULL
+rawv6_recvmsg_30265 rawv6_recvmsg 4 30265 NULL
+compat_readv_30273 compat_readv 3 30273 NULL
+skcipher_sendmsg_30290 skcipher_sendmsg 4 30290 NULL
+ext4_acl_from_disk_30320 ext4_acl_from_disk 2 30320 NULL
+kstrtou32_from_user_30361 kstrtou32_from_user 2 30361 NULL
+inet_getid_30365 inet_getid 2 30365 NULL
+sys_get_mempolicy_30379 sys_get_mempolicy 3 30379 NULL
+blkdev_issue_zeroout_30392 blkdev_issue_zeroout 0 30392 NULL
+c4iw_init_resource_30393 c4iw_init_resource 3-2 30393 NULL
+enable_write_30456 enable_write 3 30456 NULL
+urandom_read_30462 urandom_read 3 30462 NULL
+i2c_ctrl_read_30467 i2c_ctrl_read 0 30467 NULL
+i915_mutex_lock_interruptible_30474 i915_mutex_lock_interruptible 0 30474 NULL
+adu_write_30487 adu_write 3 30487 NULL
+nouveau_vm_new_30495 nouveau_vm_new 3-2 30495 NULL
+set_config_30526 set_config 0 30526 NULL
+disk_expand_part_tbl_30561 disk_expand_part_tbl 2 30561 NULL
+blk_init_tags_30592 blk_init_tags 1 30592 NULL
+sgl_map_user_pages_30610 sgl_map_user_pages 2 30610 NULL
+macvtap_sendmsg_30629 macvtap_sendmsg 4 30629 NULL
+compat_raw_setsockopt_30634 compat_raw_setsockopt 5 30634 NULL
+nfsd_nrpools_30651 nfsd_nrpools 0 30651 NULL
+jffs2_flash_read_30667 jffs2_flash_read 0 30667 NULL
+dccp_setsockopt_ccid_30701 dccp_setsockopt_ccid 4 30701 NULL
+lbs_wrbbp_write_30712 lbs_wrbbp_write 3 30712 NULL
+lbs_debugfs_read_30721 lbs_debugfs_read 3 30721 NULL
+snd_nm256_playback_silence_30727 snd_nm256_playback_silence 4-3 30727 NULL
+ath6kl_wmi_send_action_cmd_30735 ath6kl_wmi_send_action_cmd 6 30735 NULL
+fuse_conn_limit_write_30777 fuse_conn_limit_write 3 30777 NULL nohasharray
+tcf_csum_ipv4_udp_30777 tcf_csum_ipv4_udp 4 30777 &fuse_conn_limit_write_30777
+smk_read_doi_30813 smk_read_doi 3 30813 NULL
+get_kobj_path_length_30831 get_kobj_path_length 0 30831 NULL
+sctp_setsockopt_auth_chunk_30843 sctp_setsockopt_auth_chunk 3 30843 NULL
+ieee80211_if_fmt_dropped_frames_no_route_30884 ieee80211_if_fmt_dropped_frames_no_route 3 30884 NULL
+pn_recvmsg_30887 pn_recvmsg 4 30887 NULL
+f1x_match_to_this_node_30888 f1x_match_to_this_node 3 30888 NULL
+get_params_30899 get_params 0 30899 NULL
+fc_host_post_vendor_event_30903 fc_host_post_vendor_event 3 30903 NULL
+sctp_setsockopt_rtoinfo_30941 sctp_setsockopt_rtoinfo 3 30941 NULL
+tty_insert_flip_string_flags_30969 tty_insert_flip_string_flags 4 30969 NULL
+huge_page_mask_30981 huge_page_mask 0 30981 NULL
+nlmsg_put_answer_30988 nlmsg_put_answer 4 30988 NULL
+i2400mu_rx_size_grow_30989 i2400mu_rx_size_grow 0 30989 NULL
+lbs_host_sleep_read_31013 lbs_host_sleep_read 3 31013 NULL
+compat_sys_mq_timedsend_31060 compat_sys_mq_timedsend 3 31060 NULL
+lbs_failcount_read_31063 lbs_failcount_read 3 31063 NULL
+find_next_bit_le_31064 find_next_bit_le 0 31064 NULL
+sys_mincore_31079 sys_mincore 2-1 31079 NULL
+scb_status_31084 scb_status 0 31084 NULL
+sctp_setsockopt_context_31091 sctp_setsockopt_context 3 31091 NULL
+compat_sys_get_mempolicy_31109 compat_sys_get_mempolicy 3 31109 NULL
+depth_read_31112 depth_read 3 31112 NULL
+kvm_mmu_pte_write_31120 kvm_mmu_pte_write 2-4 31120 NULL
+ssb_read16_31139 ssb_read16 0 31139 NULL
+kimage_normal_alloc_31140 kimage_normal_alloc 3 31140 NULL
+size_inside_page_31141 size_inside_page 0 31141 NULL
+ch_do_scsi_31171 ch_do_scsi 4 31171 NULL
+input_mt_init_slots_31183 input_mt_init_slots 2 31183 NULL
+r592_read_fifo_pio_31198 r592_read_fifo_pio 3 31198 NULL
+cpumask_weight_31215 cpumask_weight 0 31215 NULL
+__read_reg_31216 __read_reg 0 31216 NULL
+atm_get_addr_31221 atm_get_addr 3 31221 NULL
+tcp_recvmsg_31238 tcp_recvmsg 4 31238 NULL
+cyy_readb_31240 cyy_readb 0 31240 NULL
+_create_sg_bios_31244 _create_sg_bios 4 31244 NULL
+ieee80211_if_read_last_beacon_31257 ieee80211_if_read_last_beacon 3 31257 NULL
+ceph_copy_page_vector_to_user_31270 ceph_copy_page_vector_to_user 3-4 31270 NULL
+uvc_simplify_fraction_31303 uvc_simplify_fraction 3 31303 NULL
+sisusbcon_scroll_31315 sisusbcon_scroll 5-2-3 31315 NULL
+command_file_write_31318 command_file_write 3 31318 NULL
+rbd_do_op_31366 rbd_do_op 8-9 31366 NULL
+xprt_rdma_allocate_31372 xprt_rdma_allocate 2 31372 NULL
+trace_parser_get_init_31379 trace_parser_get_init 2 31379 NULL
+inb_31388 inb 0 31388 NULL
+key_ifindex_read_31411 key_ifindex_read 3 31411 NULL
+mcs7830_set_reg_31413 mcs7830_set_reg 3 31413 NULL nohasharray
+i915_gem_object_put_fence_31413 i915_gem_object_put_fence 0 31413 &mcs7830_set_reg_31413
+TSS_checkhmac1_31429 TSS_checkhmac1 5 31429 NULL
+snd_aw2_saa7146_get_hw_ptr_capture_31431 snd_aw2_saa7146_get_hw_ptr_capture 0 31431 NULL
+xfs_btree_get_numrecs_31477 xfs_btree_get_numrecs 0 31477 NULL
+__ext4_journal_get_write_access_31482 __ext4_journal_get_write_access 0 31482 NULL
+alg_setkey_31485 alg_setkey 3 31485 NULL
+rds_message_map_pages_31487 rds_message_map_pages 2 31487 NULL
+qsfp_2_read_31491 qsfp_2_read 3 31491 NULL
+__alloc_bootmem_31498 __alloc_bootmem 1 31498 NULL
+hidraw_write_31536 hidraw_write 3 31536 NULL
+normalize_31566 normalize 0-1-2 31566 NULL
+inet6_ifaddr_msgsize_31568 inet6_ifaddr_msgsize 0 31568 NULL
+osst_write_31581 osst_write 3 31581 NULL
+iwl_dbgfs_ucode_tx_stats_read_31611 iwl_dbgfs_ucode_tx_stats_read 3 31611 NULL
+xfer_secondary_pool_31661 xfer_secondary_pool 2 31661 NULL
+__lgread_31668 __lgread 4 31668 NULL
+fst_recover_rx_error_31687 fst_recover_rx_error 3 31687 NULL
+handle_interrupt_31689 handle_interrupt 0 31689 NULL
+audit_log_n_string_31705 audit_log_n_string 3 31705 NULL
+sctp_make_asconf_ack_31726 sctp_make_asconf_ack 3 31726 NULL
+utf16s_to_utf8s_31735 utf16s_to_utf8s 0 31735 NULL
+input_abs_get_max_31742 input_abs_get_max 0 31742 NULL nohasharray
+NCR_700_change_queue_depth_31742 NCR_700_change_queue_depth 2 31742 &input_abs_get_max_31742
+snd_seq_device_new_31753 snd_seq_device_new 4 31753 NULL
+usblp_cache_device_id_string_31790 usblp_cache_device_id_string 0 31790 NULL
+get_count_order_31800 get_count_order 0 31800 NULL
+ecryptfs_send_message_locked_31801 ecryptfs_send_message_locked 2 31801 NULL
+strnlen_user_31815 strnlen_user 0-2 31815 NULL
+sta_last_signal_read_31818 sta_last_signal_read 3 31818 NULL
+iwl_dbgfs_disable_ht40_write_31876 iwl_dbgfs_disable_ht40_write 3 31876 NULL
+xattr_permission_31907 xattr_permission 0 31907 NULL
+kmem_alloc_31920 kmem_alloc 1 31920 NULL
+read_mem_31942 read_mem 3 31942 NULL nohasharray
+iov_iter_copy_from_user_31942 iov_iter_copy_from_user 4-0 31942 &read_mem_31942
+copy_from_user_toio_31966 copy_from_user_toio 3 31966 NULL
+vx_read_status_31982 vx_read_status 0 31982 NULL
+find_next_zero_bit_31990 find_next_zero_bit 0 31990 NULL
+sysfs_create_file_31996 sysfs_create_file 0 31996 NULL
+calc_hmac_32010 calc_hmac 3 32010 NULL
+aead_len_32021 aead_len 0 32021 NULL
+ocfs2_remove_extent_32032 ocfs2_remove_extent 4-3 32032 NULL
+posix_acl_set_32037 posix_acl_set 4 32037 NULL
+sys_sched_setaffinity_32046 sys_sched_setaffinity 2 32046 NULL
+proc_scsi_devinfo_write_32064 proc_scsi_devinfo_write 3 32064 NULL
+nlmsg_put_32069 nlmsg_put 5 32069 NULL
+cfg80211_send_unprot_deauth_32080 cfg80211_send_unprot_deauth 3 32080 NULL
+ath6kl_fwlog_read_32101 ath6kl_fwlog_read 3 32101 NULL
+set_discoverable_32102 set_discoverable 4 32102 NULL
+disk_status_32120 disk_status 4 32120 NULL
+kobject_add_internal_32133 kobject_add_internal 0 32133 NULL
+alloc_tx_32143 alloc_tx 2 32143 NULL
+venus_link_32165 venus_link 5 32165 NULL
+drbd_new_dev_size_32171 drbd_new_dev_size 0 32171 NULL
+do_writepages_32173 do_writepages 0 32173 NULL
+ubi_wl_scrub_peb_32196 ubi_wl_scrub_peb 0 32196 NULL
+wusb_ccm_mac_32199 wusb_ccm_mac 7 32199 NULL
+caif_seqpkt_recvmsg_32241 caif_seqpkt_recvmsg 4 32241 NULL
+lbs_lowrssi_read_32242 lbs_lowrssi_read 3 32242 NULL
+ocfs2_xattr_find_entry_32260 ocfs2_xattr_find_entry 0 32260 NULL
+l3_alloc_skb_32289 l3_alloc_skb 1 32289 NULL
+cas_calc_tabort_32316 cas_calc_tabort 0 32316 NULL
+nl80211_send_mlme_event_32337 nl80211_send_mlme_event 4 32337 NULL
+t4_alloc_mem_32342 t4_alloc_mem 1 32342 NULL
+dispatch_ioctl_32357 dispatch_ioctl 2 32357 NULL
+f1x_translate_sysaddr_to_cs_32359 f1x_translate_sysaddr_to_cs 2 32359 NULL
+sel_read_initcon_32362 sel_read_initcon 3 32362 NULL
+send_mpa_reply_32372 send_mpa_reply 3 32372 NULL
+usbtmc_read_32377 usbtmc_read 3 32377 NULL
+xfs_iext_add_indirect_multi_32400 xfs_iext_add_indirect_multi 3 32400 NULL
+hid_input_report_32458 hid_input_report 4 32458 NULL
+fill_readbuf_32464 fill_readbuf 3 32464 NULL
+ieee80211_fill_mesh_addresses_32465 ieee80211_fill_mesh_addresses 0 32465 NULL
+ide_driver_proc_write_32493 ide_driver_proc_write 3 32493 NULL
+qsfp_read_32522 qsfp_read 0-2-4 32522 NULL
+ilo_read_32531 ilo_read 3 32531 NULL
+ieee80211_if_read_estab_plinks_32533 ieee80211_if_read_estab_plinks 3 32533 NULL
+format_devstat_counter_32550 format_devstat_counter 3 32550 NULL
+mem_swapout_entry_32586 mem_swapout_entry 3 32586 NULL
+read_file_beacon_32595 read_file_beacon 3 32595 NULL
+ieee80211_if_read_dropped_frames_congestion_32603 ieee80211_if_read_dropped_frames_congestion 3 32603 NULL
+sys_set_mempolicy_32608 sys_set_mempolicy 3 32608 NULL
+__iter_shared_inline_ref_32610 __iter_shared_inline_ref 0 32610 NULL
+irda_recvmsg_dgram_32631 irda_recvmsg_dgram 4 32631 NULL
+cfg80211_roamed_32632 cfg80211_roamed 5-7 32632 NULL
+ieee80211_hdrlen_32637 ieee80211_hdrlen 0 32637 NULL
+kvmalloc_32646 kvmalloc 1 32646 NULL
+ib_sg_dma_len_32649 ib_sg_dma_len 0 32649 NULL
+generic_readlink_32654 generic_readlink 3 32654 NULL
+move_addr_to_kernel_32673 move_addr_to_kernel 2 32673 NULL
+apei_res_add_32674 apei_res_add 0 32674 NULL
+rt2x00debug_read_queue_dump_32712 rt2x00debug_read_queue_dump 3 32712 NULL
+slhc_remember_32741 slhc_remember 3-0 32741 NULL
+megasas_change_queue_depth_32747 megasas_change_queue_depth 2 32747 NULL
+stats_read_ul_32751 stats_read_ul 3 32751 NULL
+write_file_disable_ani_32761 write_file_disable_ani 3 32761 NULL
+sctp_tsnmap_grow_32784 sctp_tsnmap_grow 2 32784 NULL
+get_register_page_interruptible_32809 get_register_page_interruptible 5 32809 NULL
+orig_node_add_if_32833 orig_node_add_if 2 32833 NULL
+nlmsg_validate_32861 nlmsg_validate 2 32861 NULL
+new_tape_buffer_32866 new_tape_buffer 2 32866 NULL
+blkio_fill_stat_32874 blkio_fill_stat 2 32874 NULL
+zlib_inflate_workspacesize_32927 zlib_inflate_workspacesize 0 32927 NULL
+compat_filldir_32999 compat_filldir 3 32999 NULL
+br_multicast_set_hash_max_33012 br_multicast_set_hash_max 2 33012 NULL
+xfrm_mapping_msgsize_33044 xfrm_mapping_msgsize 0 33044 NULL
+ebt_compat_match_offset_33053 ebt_compat_match_offset 0-2 33053 NULL
+stats_dot11RTSSuccessCount_read_33065 stats_dot11RTSSuccessCount_read 3 33065 NULL
+sel_read_checkreqprot_33068 sel_read_checkreqprot 3 33068 NULL
+acl_permission_check_33083 acl_permission_check 0 33083 NULL
+ieee80211_fragment_33112 ieee80211_fragment 4 33112 NULL
+nfs4_init_slot_table_33152 nfs4_init_slot_table 2 33152 NULL
+tun_get_user_33178 tun_get_user 3 33178 NULL
+dataflash_read_fact_otp_33204 dataflash_read_fact_otp 3-2 33204 NULL
+pp_read_33210 pp_read 3 33210 NULL
+xfs_file_aio_write_33234 xfs_file_aio_write 4 33234 NULL
+snd_pcm_plug_client_size_33267 snd_pcm_plug_client_size 0-2 33267 NULL
+cachefiles_cook_key_33274 cachefiles_cook_key 2 33274 NULL
+i915_gem_object_flush_fence_33304 i915_gem_object_flush_fence 0 33304 NULL
+mcs7830_get_reg_33308 mcs7830_get_reg 3 33308 NULL
+ceph_msgpool_init_33312 ceph_msgpool_init 3 33312 NULL
+vx_send_irq_dsp_33329 vx_send_irq_dsp 0 33329 NULL
+gsm_mux_rx_netchar_33336 gsm_mux_rx_netchar 3 33336 NULL
+joydev_ioctl_33343 joydev_ioctl 2 33343 NULL
+create_xattr_datum_33356 create_xattr_datum 5 33356 NULL
+read_file_regidx_33370 read_file_regidx 3 33370 NULL
+ceph_osdc_writepages_33375 ceph_osdc_writepages 5 33375 NULL
+sctp_ulpevent_new_33377 sctp_ulpevent_new 1 33377 NULL
+ocfs2_quota_read_33382 ocfs2_quota_read 5 33382 NULL
+ieee80211_if_read_dropped_frames_no_route_33383 ieee80211_if_read_dropped_frames_no_route 3 33383 NULL
+scsi_varlen_cdb_length_33385 scsi_varlen_cdb_length 0 33385 NULL
+ocfs2_allocate_unwritten_extents_33394 ocfs2_allocate_unwritten_extents 2-3 33394 NULL
+snd_pcm_capture_ioctl1_33408 snd_pcm_capture_ioctl1 0 33408 NULL
+create_entry_33479 create_entry 2 33479 NULL
+ip_setsockopt_33487 ip_setsockopt 5 33487 NULL
+ol_dqblk_chunk_off_33489 ol_dqblk_chunk_off 2 33489 NULL
+res_counter_read_33499 res_counter_read 4 33499 NULL
+fb_read_33506 fb_read 3 33506 NULL
+ahash_setkey_unaligned_33521 ahash_setkey_unaligned 3 33521 NULL
+nes_alloc_fast_reg_page_list_33523 nes_alloc_fast_reg_page_list 2 33523 NULL
+tomoyo_read_self_33539 tomoyo_read_self 3 33539 NULL
+dup_array_33551 dup_array 3 33551 NULL
+scsi_execute_33596 scsi_execute 5 33596 NULL
+ip6_find_1stfragopt_33608 ip6_find_1stfragopt 0 33608 NULL nohasharray
+xt_compat_target_offset_33608 xt_compat_target_offset 0 33608 &ip6_find_1stfragopt_33608
+inw_p_33668 inw_p 0 33668 NULL
+arp_hdr_len_33671 arp_hdr_len 0 33671 NULL
+rbd_alloc_coll_33678 rbd_alloc_coll 1 33678 NULL
+sys_keyctl_33708 sys_keyctl 4 33708 NULL nohasharray
+netlink_sendmsg_33708 netlink_sendmsg 4 33708 &sys_keyctl_33708
+get_free_de_33714 get_free_de 2 33714 NULL
+ocfs2_extent_map_get_blocks_33720 ocfs2_extent_map_get_blocks 2 33720 NULL
+Read_hfc_33755 Read_hfc 0 33755 NULL
+hashtab_create_33769 hashtab_create 3 33769 NULL
+if_sdio_read_rx_len_33800 if_sdio_read_rx_len 0 33800 NULL
+sky2_rx_pad_33819 sky2_rx_pad 0 33819 NULL nohasharray
+filter_write_33819 filter_write 3 33819 &sky2_rx_pad_33819
+ext4_journal_extend_33835 ext4_journal_extend 0 33835 NULL
+get_user_pages_33908 get_user_pages 0 33908 NULL
+queue_logical_block_size_33918 queue_logical_block_size 0 33918 NULL
+max8649_read_device_33930 max8649_read_device 3 33930 NULL
+sel_read_avc_cache_threshold_33942 sel_read_avc_cache_threshold 3 33942 NULL
+lpfc_idiag_ctlacc_read_33943 lpfc_idiag_ctlacc_read 3 33943 NULL
+read_file_tgt_rx_stats_33944 read_file_tgt_rx_stats 3 33944 NULL
+vga_switcheroo_debugfs_write_33984 vga_switcheroo_debugfs_write 3 33984 NULL
+select_size_34004 select_size 0 34004 NULL
+lbs_lowrssi_write_34025 lbs_lowrssi_write 3 34025 NULL
+ppp_write_34034 ppp_write 3 34034 NULL
+tty_insert_flip_string_34042 tty_insert_flip_string 3-0 34042 NULL
+islpci_mgt_transmit_34133 islpci_mgt_transmit 5 34133 NULL
+mtu2blksize_34139 mtu2blksize 0 34139 NULL
+skb_to_sgvec_34171 skb_to_sgvec 0 34171 NULL
+mtd_write_34207 mtd_write 3 34207 NULL
+setup_nodes_for_search_34248 setup_nodes_for_search 0 34248 NULL
+bl_pipe_downcall_34264 bl_pipe_downcall 3 34264 NULL
+rw_copy_check_uvector_34271 rw_copy_check_uvector 3-0 34271 NULL
+device_private_init_34279 device_private_init 0 34279 NULL
+zone_spanned_pages_in_node_34299 zone_spanned_pages_in_node 0 34299 NULL
+pcpu_need_to_extend_34326 pcpu_need_to_extend 0 34326 NULL nohasharray
+iov_iter_single_seg_count_34326 iov_iter_single_seg_count 0 34326 &pcpu_need_to_extend_34326
+crypto_ablkcipher_ivsize_34363 crypto_ablkcipher_ivsize 0 34363 NULL
+rngapi_reset_34366 rngapi_reset 3 34366 NULL nohasharray
+p54_alloc_skb_34366 p54_alloc_skb 3 34366 &rngapi_reset_34366
+ea_read_34378 ea_read 0 34378 NULL
+read_rbu_image_type_34387 read_rbu_image_type 6 34387 NULL
+sctp_make_heartbeat_ack_34411 sctp_make_heartbeat_ack 4 34411 NULL
+nl80211_send_disassoc_34424 nl80211_send_disassoc 4 34424 NULL
+usbtest_alloc_urb_34446 usbtest_alloc_urb 3-5 34446 NULL
+sctp_make_abort_34459 sctp_make_abort 3 34459 NULL
+mwifiex_regrdwr_read_34472 mwifiex_regrdwr_read 3 34472 NULL
+skcipher_sndbuf_34476 skcipher_sndbuf 0 34476 NULL
+i2o_parm_field_get_34477 i2o_parm_field_get 5 34477 NULL
+security_inode_permission_34488 security_inode_permission 0 34488 NULL
+alloc_buf_34532 alloc_buf 1 34532 NULL
+tracing_stats_read_34537 tracing_stats_read 3 34537 NULL
+hugetlbfs_read_actor_34547 hugetlbfs_read_actor 2-5-4-0 34547 NULL
+dbBackSplit_34561 dbBackSplit 0 34561 NULL
+velocity_rx_copy_34583 velocity_rx_copy 2 34583 NULL
+init_send_hfcd_34586 init_send_hfcd 1 34586 NULL
+inet6_ifla6_size_34591 inet6_ifla6_size 0 34591 NULL
+__jffs2_ref_totlen_34609 __jffs2_ref_totlen 0 34609 NULL
+__cfg80211_disconnected_34622 __cfg80211_disconnected 3 34622 NULL
+cnic_alloc_dma_34641 cnic_alloc_dma 3 34641 NULL
+ieee80211_if_read_num_sta_ps_34722 ieee80211_if_read_num_sta_ps 3 34722 NULL
+platform_list_read_file_34734 platform_list_read_file 3 34734 NULL
+fib_rule_nlmsg_size_34736 fib_rule_nlmsg_size 0 34736 NULL
+sctp_make_datafrag_empty_34737 sctp_make_datafrag_empty 3 34737 NULL
+solos_param_store_34755 solos_param_store 4 34755 NULL
+device_add_34766 device_add 0 34766 NULL
+qib_cdev_init_34778 qib_cdev_init 1 34778 NULL
+tipc_log_resize_34803 tipc_log_resize 1 34803 NULL
+drbd_get_max_capacity_34804 drbd_get_max_capacity 0 34804 NULL
+b43_debugfs_write_34838 b43_debugfs_write 3 34838 NULL
+bl_mark_for_commit_34852 bl_mark_for_commit 2-3 34852 NULL
+acpi_system_write_wakeup_device_34853 acpi_system_write_wakeup_device 3 34853 NULL
+usb_serial_generic_prepare_write_buffer_34857 usb_serial_generic_prepare_write_buffer 3 34857 NULL
+ieee80211_if_write_34894 ieee80211_if_write 3 34894 NULL
+write_msg_34916 write_msg 3 34916 NULL
+iwl_dbgfs_force_reset_write_34930 iwl_dbgfs_force_reset_write 3 34930 NULL
+snd_info_entry_read_34938 snd_info_entry_read 3 34938 NULL
+i2c_transfer_34958 i2c_transfer 0 34958 NULL nohasharray
+skb_gro_header_slow_34958 skb_gro_header_slow 2 34958 &i2c_transfer_34958
+sisusb_copy_memory_35016 sisusb_copy_memory 4 35016 NULL
+generic_file_llseek_size_35024 generic_file_llseek_size 2 35024 NULL
+coda_psdev_read_35029 coda_psdev_read 3 35029 NULL
+btmrvl_gpiogap_write_35053 btmrvl_gpiogap_write 3 35053 NULL
+ext4_split_unwritten_extents_35063 ext4_split_unwritten_extents 0 35063 NULL
+store_ifalias_35088 store_ifalias 4 35088 NULL
+__kfifo_uint_must_check_helper_35097 __kfifo_uint_must_check_helper 0-1 35097 NULL
+capi_write_35104 capi_write 3 35104 NULL
+ide_settings_proc_write_35110 ide_settings_proc_write 3 35110 NULL
+ceph_osdc_start_request_35122 ceph_osdc_start_request 0 35122 NULL
+gntdev_alloc_map_35145 gntdev_alloc_map 2 35145 NULL
+iscsi_conn_setup_35159 iscsi_conn_setup 2 35159 NULL
+ieee80211_if_read_bssid_35161 ieee80211_if_read_bssid 3 35161 NULL
+bat_ogm_aggr_packet_35202 bat_ogm_aggr_packet 3 35202 NULL
+unix_stream_recvmsg_35210 unix_stream_recvmsg 4 35210 NULL
+_osd_req_alist_elem_size_35216 _osd_req_alist_elem_size 0-2 35216 NULL
+security_key_getsecurity_35218 security_key_getsecurity 0 35218 NULL nohasharray
+striped_read_35218 striped_read 2-8-0-3 35218 &security_key_getsecurity_35218
+set_fd_set_35249 set_fd_set 1 35249 NULL
+ioapic_setup_resources_35255 ioapic_setup_resources 1 35255 NULL
+jbd2_journal_get_write_access_35263 jbd2_journal_get_write_access 0 35263 NULL
+dma_show_regs_35266 dma_show_regs 3 35266 NULL
+irda_recvmsg_stream_35280 irda_recvmsg_stream 4 35280 NULL
+i2o_block_end_request_35282 i2o_block_end_request 3 35282 NULL
+__btrfs_buffered_write_35311 __btrfs_buffered_write 3 35311 NULL
+tracing_read_pipe_35312 tracing_read_pipe 3 35312 NULL
+sys_setsockopt_35320 sys_setsockopt 5 35320 NULL
+new_bind_ctl_35324 new_bind_ctl 2 35324 NULL
+pskb_network_may_pull_35336 pskb_network_may_pull 2 35336 NULL
+mlx4_alloc_hwq_res_35339 mlx4_alloc_hwq_res 3 35339 NULL
+hpi_alloc_control_cache_35351 hpi_alloc_control_cache 1 35351 NULL
+compat_filldir64_35354 compat_filldir64 3 35354 NULL
+tt_update_orig_35361 tt_update_orig 4 35361 NULL
+read_kmem_35372 read_kmem 3 35372 NULL
+rawv6_send_hdrinc_35425 rawv6_send_hdrinc 3 35425 NULL
+i915_wedged_read_35474 i915_wedged_read 3 35474 NULL
+async_setkey_35521 async_setkey 3 35521 NULL
+__filemap_fdatawrite_range_35528 __filemap_fdatawrite_range 0 35528 NULL
+iwl_dbgfs_bt_traffic_read_35534 iwl_dbgfs_bt_traffic_read 3 35534 NULL
+ibnl_put_attr_35541 ibnl_put_attr 3 35541 NULL
+ieee80211_if_write_smps_35550 ieee80211_if_write_smps 3 35550 NULL
+sysfs_create_subdir_35567 sysfs_create_subdir 0 35567 NULL
+ext2_acl_from_disk_35580 ext2_acl_from_disk 2 35580 NULL
+ReadZReg_35604 ReadZReg 0 35604 NULL
+rbd_req_sync_read_35615 rbd_req_sync_read 6-5 35615 NULL
+kernel_readv_35617 kernel_readv 3 35617 NULL
+scrub_stripe_35637 scrub_stripe 4-3 35637 NULL
+spi_register_board_info_35651 spi_register_board_info 2 35651 NULL
+compat_sys_kexec_load_35674 compat_sys_kexec_load 2 35674 NULL
+rds_page_copy_user_35691 rds_page_copy_user 4 35691 NULL
+fixup_low_keys_35734 fixup_low_keys 0 35734 NULL
+ext4_truncate_restart_trans_35750 ext4_truncate_restart_trans 0 35750 NULL
+iwl_dbgfs_disable_ht40_read_35761 iwl_dbgfs_disable_ht40_read 3 35761 NULL
+udf_alloc_i_data_35786 udf_alloc_i_data 2 35786 NULL
+read_file_stations_35795 read_file_stations 3 35795 NULL
+vx_query_hbuffer_size_35859 vx_query_hbuffer_size 0 35859 NULL
+mthca_buf_alloc_35861 mthca_buf_alloc 2 35861 NULL
+wait_mgsl_event_35872 wait_mgsl_event 0 35872 NULL
+kvm_dirty_bitmap_bytes_35886 kvm_dirty_bitmap_bytes 0 35886 NULL
+ieee80211_if_fmt_dot11MeshRetryTimeout_35890 ieee80211_if_fmt_dot11MeshRetryTimeout 3 35890 NULL
+uwb_rc_cmd_done_35892 uwb_rc_cmd_done 4 35892 NULL
+tcp_mark_head_lost_35895 tcp_mark_head_lost 2 35895 NULL
+igmpv3_newpack_35912 igmpv3_newpack 2 35912 NULL
+kernel_setsockopt_35913 kernel_setsockopt 5 35913 NULL
+balance_node_right_35920 balance_node_right 0 35920 NULL
+put_cmsg_compat_35937 put_cmsg_compat 4 35937 NULL
+ceph_buffer_new_35974 ceph_buffer_new 1 35974 NULL
+acl_alloc_35979 acl_alloc 1 35979 NULL
+device_add_class_symlinks_35985 device_add_class_symlinks 0 35985 NULL
+generic_file_aio_read_35987 generic_file_aio_read 0 35987 NULL
+write_file_antenna_35998 write_file_antenna 3 35998 NULL
+console_store_36007 console_store 4 36007 NULL
+i965_write_fence_reg_36017 i965_write_fence_reg 0 36017 NULL
+sys_init_module_36047 sys_init_module 2 36047 NULL
+write_emulate_36065 write_emulate 2-4 36065 NULL
+stack_max_size_write_36068 stack_max_size_write 3 36068 NULL
+ieee80211_if_fmt_peer_36071 ieee80211_if_fmt_peer 3 36071 NULL
+ieee80211_if_write_tsf_36077 ieee80211_if_write_tsf 3 36077 NULL
+snd_pcm_plug_read_transfer_36080 snd_pcm_plug_read_transfer 0-3 36080 NULL
+genlmsg_new_36094 genlmsg_new 1 36094 NULL
+vga_arb_write_36112 vga_arb_write 3 36112 NULL
+rx_enable_36125 rx_enable 0 36125 NULL
+iwl_trans_txq_alloc_36147 iwl_trans_txq_alloc 3 36147 NULL
+b1_alloc_card_36155 b1_alloc_card 1 36155 NULL
+btrfs_file_extent_inline_len_36158 btrfs_file_extent_inline_len 0 36158 NULL
+snd_korg1212_copy_from_36169 snd_korg1212_copy_from 6 36169 NULL
+__ip_append_data_36191 __ip_append_data 7-8 36191 NULL
+atomic_stats_read_36228 atomic_stats_read 3 36228 NULL
+compat_sys_mbind_36256 compat_sys_mbind 5 36256 NULL
+modem_input_wait_36278 modem_input_wait 0 36278 NULL
+mangle_sdp_packet_36279 mangle_sdp_packet 9 36279 NULL
+codec_reg_read_file_36280 codec_reg_read_file 3 36280 NULL
+lpfc_debugfs_dif_err_read_36303 lpfc_debugfs_dif_err_read 3 36303 NULL
+ad7879_spi_xfer_36311 ad7879_spi_xfer 3 36311 NULL
+fat_compat_ioctl_filldir_36328 fat_compat_ioctl_filldir 3 36328 NULL
+jbd2_journal_init_revoke_table_36336 jbd2_journal_init_revoke_table 1 36336 NULL
+ath6kl_regwrite_write_36351 ath6kl_regwrite_write 3 36351 NULL
+v9fs_file_readn_36353 v9fs_file_readn 4 36353 NULL
+to_sector_36361 to_sector 0-1 36361 NULL
+mtd_do_writeoob_36373 mtd_do_writeoob 4 36373 NULL
+vring_new_virtqueue_36374 vring_new_virtqueue 1 36374 NULL
+tunables_read_36385 tunables_read 3 36385 NULL
+afs_alloc_flat_call_36399 afs_alloc_flat_call 2-3 36399 NULL
+sierra_write_36402 sierra_write 4 36402 NULL
+rtnl_link_get_size_36436 rtnl_link_get_size 0 36436 NULL
+sctp_tsnmap_init_36446 sctp_tsnmap_init 2 36446 NULL
+alloc_etherdev_mqs_36450 alloc_etherdev_mqs 1 36450 NULL
+b43_nphy_load_samples_36481 b43_nphy_load_samples 3 36481 NULL
+ip6_append_data_36490 ip6_append_data 4-5 36490 NULL
+cmd_loop_36491 cmd_loop 0 36491 NULL
+__hwahc_op_set_ptk_36510 __hwahc_op_set_ptk 5 36510 NULL
+ieee80211_if_read_fwded_frames_36520 ieee80211_if_read_fwded_frames 3 36520 NULL
+crypto_aead_authsize_36537 crypto_aead_authsize 0 36537 NULL
+cpu_type_read_36540 cpu_type_read 3 36540 NULL
+__kfifo_to_user_36555 __kfifo_to_user 3 36555 NULL nohasharray
+macvtap_do_read_36555 macvtap_do_read 4 36555 &__kfifo_to_user_36555
+__erst_read_36579 __erst_read 0 36579 NULL
+put_cmsg_36589 put_cmsg 4 36589 NULL
+pcnet32_realloc_rx_ring_36598 pcnet32_realloc_rx_ring 3 36598 NULL
+fat_ioctl_filldir_36621 fat_ioctl_filldir 3 36621 NULL
+vxge_config_vpaths_36636 vxge_config_vpaths 0 36636 NULL
+lpfc_idiag_extacc_alloc_get_36648 lpfc_idiag_extacc_alloc_get 0-3 36648 NULL
+osd_req_list_collection_objects_36664 osd_req_list_collection_objects 5 36664 NULL
+iscsi_host_alloc_36671 iscsi_host_alloc 2 36671 NULL
+get_txidle_36698 get_txidle 0 36698 NULL
+extract_icmp6_fields_36732 extract_icmp6_fields 2 36732 NULL
+snd_rawmidi_kernel_read1_36740 snd_rawmidi_kernel_read1 4-0 36740 NULL
+cxgbi_device_register_36746 cxgbi_device_register 1-2 36746 NULL
+i915_gem_evict_inactive_36767 i915_gem_evict_inactive 0 36767 NULL
+ip4ip6_err_36772 ip4ip6_err 5 36772 NULL
+llc_mac_header_len_36776 llc_mac_header_len 0 36776 NULL
+proc_fault_inject_read_36802 proc_fault_inject_read 3 36802 NULL
+do_dmabuf_dirty_sou_36807 do_dmabuf_dirty_sou 7 36807 NULL
+hiddev_ioctl_36816 hiddev_ioctl 2 36816 NULL
+int_hardware_entry_36833 int_hardware_entry 3 36833 NULL
+fc_change_queue_depth_36841 fc_change_queue_depth 2 36841 NULL
+keyctl_describe_key_36853 keyctl_describe_key 3 36853 NULL
+cm_write_36858 cm_write 3 36858 NULL
+svc_setsockopt_36876 svc_setsockopt 5 36876 NULL
+ib_ucm_alloc_data_36885 ib_ucm_alloc_data 3 36885 NULL
+selinux_inode_notifysecctx_36896 selinux_inode_notifysecctx 3 36896 NULL
+genlmsg_total_size_36938 genlmsg_total_size 0-1 36938 NULL
+crypto_blkcipher_ivsize_36944 crypto_blkcipher_ivsize 0 36944 NULL
+sparse_early_mem_maps_alloc_node_36971 sparse_early_mem_maps_alloc_node 4 36971 NULL
+setxattr_37006 setxattr 4 37006 NULL
+command_file_read_37038 command_file_read 3 37038 NULL
+ieee80211_if_read_drop_unencrypted_37053 ieee80211_if_read_drop_unencrypted 3 37053 NULL
+parse_command_37079 parse_command 2 37079 NULL
+snd_hda_get_conn_list_37132 snd_hda_get_conn_list 0 37132 NULL
+xfrm_expire_msgsize_37133 xfrm_expire_msgsize 0 37133 NULL
+msg_word_37164 msg_word 0 37164 NULL
+can_set_xattr_37182 can_set_xattr 4 37182 NULL
+vcc_recvmsg_37198 vcc_recvmsg 4 37198 NULL
+sysfs_add_file_37200 sysfs_add_file 0 37200 NULL
+crypto_shash_descsize_37212 crypto_shash_descsize 0 37212 NULL
+uapsd_queues_read_37217 uapsd_queues_read 3 37217 NULL
+regmap_access_read_file_37223 regmap_access_read_file 3 37223 NULL
+__do_replace_37227 __do_replace 5 37227 NULL
+produce_free_peb_37232 produce_free_peb 0 37232 NULL
+ctnetlink_secctx_size_37236 ctnetlink_secctx_size 0 37236 NULL
+prot_queue_del_37258 prot_queue_del 0 37258 NULL
+exofs_max_io_pages_37263 exofs_max_io_pages 0-2 37263 NULL
+srp_target_alloc_37288 srp_target_alloc 3 37288 NULL
+jffs2_write_dirent_37311 jffs2_write_dirent 5 37311 NULL
+send_msg_37323 send_msg 4 37323 NULL
+brcmf_sdbrcm_membytes_37324 brcmf_sdbrcm_membytes 3-5 37324 NULL
+scsi_mode_select_37330 scsi_mode_select 6 37330 NULL
+rxrpc_server_sendmsg_37331 rxrpc_server_sendmsg 4 37331 NULL
+nf_bridge_pad_37351 nf_bridge_pad 0 37351 NULL
+security_inode_getsecurity_37354 security_inode_getsecurity 0 37354 NULL
+sys_getxattr_37418 sys_getxattr 4 37418 NULL
+hci_sock_sendmsg_37420 hci_sock_sendmsg 4 37420 NULL
+acpi_os_allocate_zeroed_37422 acpi_os_allocate_zeroed 1 37422 NULL nohasharray
+find_next_bit_37422 find_next_bit 0 37422 &acpi_os_allocate_zeroed_37422
+tty_insert_flip_string_fixed_flag_37428 tty_insert_flip_string_fixed_flag 4-0 37428 NULL
+iwl_print_last_event_logs_37433 iwl_print_last_event_logs 7-9-0 37433 NULL
+tcp_established_options_37450 tcp_established_options 0 37450 NULL
+cmd_input_size_37457 cmd_input_size 0-1 37457 NULL
+get_est_timing_37484 get_est_timing 0 37484 NULL
+kmem_realloc_37489 kmem_realloc 2 37489 NULL
+xz_dec_test_write_37527 xz_dec_test_write 3 37527 NULL
+hdr_size_37536 hdr_size 0 37536 NULL
+xhci_alloc_streams_37586 xhci_alloc_streams 5 37586 NULL
+qla2x00_debounce_register_37597 qla2x00_debounce_register 0 37597 NULL
+kvm_read_guest_page_mmu_37611 kvm_read_guest_page_mmu 6 37611 NULL
+bio_copy_user_iov_37660 bio_copy_user_iov 4 37660 NULL
+vmw_framebuffer_dmabuf_dirty_37661 vmw_framebuffer_dmabuf_dirty 6 37661 NULL
+regmap_map_read_file_37685 regmap_map_read_file 3 37685 NULL
+__le32_to_cpup_37702 __le32_to_cpup 0 37702 NULL
+read_enabled_file_bool_37744 read_enabled_file_bool 3 37744 NULL
+ocfs2_duplicate_clusters_by_jbd_37749 ocfs2_duplicate_clusters_by_jbd 5-4-6 37749 NULL
+ocfs2_control_cfu_37750 ocfs2_control_cfu 2 37750 NULL
+ipath_cdev_init_37752 ipath_cdev_init 1 37752 NULL
+dccp_setsockopt_cscov_37766 dccp_setsockopt_cscov 2 37766 NULL
+smk_read_logging_37804 smk_read_logging 3 37804 NULL
+jbd2_journal_get_undo_access_37837 jbd2_journal_get_undo_access 0 37837 NULL
+o2hb_debug_read_37851 o2hb_debug_read 3 37851 NULL
+xfs_dir2_block_to_sf_37868 xfs_dir2_block_to_sf 3 37868 NULL
+sys_setxattr_37880 sys_setxattr 4 37880 NULL
+tipc_link_send_sections_fast_37920 tipc_link_send_sections_fast 4 37920 NULL
+pkt_alloc_packet_data_37928 pkt_alloc_packet_data 1 37928 NULL
+read_rbu_packet_size_37939 read_rbu_packet_size 6 37939 NULL
+write_file_bool_37957 write_file_bool 3 37957 NULL
+rds_rdma_extra_size_37990 rds_rdma_extra_size 0 37990 NULL
+vfs_readv_38011 vfs_readv 3 38011 NULL
+aggr_recv_addba_req_evt_38037 aggr_recv_addba_req_evt 4 38037 NULL
+klsi_105_prepare_write_buffer_38044 klsi_105_prepare_write_buffer 3 38044 NULL
+sysfs_do_create_link_38051 sysfs_do_create_link 0 38051 NULL
+nsm_create_handle_38060 nsm_create_handle 4 38060 NULL
+alloc_ltalkdev_38071 alloc_ltalkdev 1 38071 NULL
+uwb_mac_addr_print_38085 uwb_mac_addr_print 2 38085 NULL
+request_key_auth_new_38092 request_key_auth_new 3 38092 NULL
+proc_self_readlink_38094 proc_self_readlink 3 38094 NULL
+ep0_read_38095 ep0_read 3 38095 NULL
+snd_pcm_oss_write_38108 snd_pcm_oss_write 3 38108 NULL
+vmw_kms_present_38130 vmw_kms_present 9 38130 NULL
+__ntfs_copy_from_user_iovec_inatomic_38153 __ntfs_copy_from_user_iovec_inatomic 0-4-3 38153 NULL
+kvm_clear_guest_38164 kvm_clear_guest 3-2 38164 NULL
+cdev_add_38176 cdev_add 2-3 38176 NULL
+rt2x00debug_write_rf_38195 rt2x00debug_write_rf 3 38195 NULL
+get_ucode_user_38202 get_ucode_user 3 38202 NULL
+osd_req_list_partition_collections_38223 osd_req_list_partition_collections 5 38223 NULL
+ceph_decode_16_38239 ceph_decode_16 0 38239 NULL
+_ipw_read_reg32_38245 _ipw_read_reg32 0 38245 NULL
+mthca_alloc_icm_table_38268 mthca_alloc_icm_table 4-3 38268 NULL nohasharray
+ieee80211_if_read_auto_open_plinks_38268 ieee80211_if_read_auto_open_plinks 3 38268 &mthca_alloc_icm_table_38268
+xfs_bmbt_to_bmdr_38275 xfs_bmbt_to_bmdr 3 38275 NULL nohasharray
+xfs_bmdr_to_bmbt_38275 xfs_bmdr_to_bmbt 5 38275 &xfs_bmbt_to_bmdr_38275
+zd_mac_rx_38296 zd_mac_rx 3 38296 NULL
+__snd_gf1_look8_38333 __snd_gf1_look8 0 38333 NULL
+btrfs_file_extent_disk_num_bytes_38363 btrfs_file_extent_disk_num_bytes 0 38363 NULL
+sctp_sf_abort_violation_38380 sctp_sf_abort_violation 6 38380 NULL
+dn_sendmsg_38390 dn_sendmsg 4 38390 NULL
+ttm_put_pages_38411 ttm_put_pages 2 38411 NULL
+ocfs2_which_cluster_group_38413 ocfs2_which_cluster_group 0-2 38413 NULL
+ieee80211_if_read_dtim_count_38419 ieee80211_if_read_dtim_count 3 38419 NULL
+pcnet32_realloc_tx_ring_38428 pcnet32_realloc_tx_ring 3 38428 NULL
+pmcraid_copy_sglist_38431 pmcraid_copy_sglist 3 38431 NULL
+var_name_strnsize_38447 var_name_strnsize 0-2 38447 NULL
+kvm_write_guest_38454 kvm_write_guest 4-2 38454 NULL
+blk_end_bidi_request_38482 blk_end_bidi_request 3-4 38482 NULL
+dev_names_read_38509 dev_names_read 3 38509 NULL
+iscsi_create_iface_38510 iscsi_create_iface 5 38510 NULL
+_osd_req_alist_elem_decode_38527 _osd_req_alist_elem_decode 0 38527 NULL
+ubifs_idx_node_sz_38546 ubifs_idx_node_sz 0-2 38546 NULL
+irda_sendmsg_dgram_38563 irda_sendmsg_dgram 4 38563 NULL
+_ipw_read32_38565 _ipw_read32 0 38565 NULL
+snd_nm256_playback_copy_38567 snd_nm256_playback_copy 5-3 38567 NULL
+sctp_tsnmap_num_dups_38578 sctp_tsnmap_num_dups 0 38578 NULL
+copy_ctl_value_to_user_38587 copy_ctl_value_to_user 4 38587 NULL
+cosa_net_setup_rx_38594 cosa_net_setup_rx 2 38594 NULL
+pep_indicate_38611 pep_indicate 5 38611 NULL
+__css_put_38613 __css_put 2 38613 NULL
+icn_writecmd_38629 icn_writecmd 2 38629 NULL
+write_enabled_file_bool_38630 write_enabled_file_bool 3 38630 NULL
+receive_extralen_38634 receive_extralen 0 38634 NULL
+audit_init_entry_38644 audit_init_entry 1 38644 NULL
+mmc_send_cxd_data_38655 mmc_send_cxd_data 5 38655 NULL
+snd_es1371_wait_src_ready_38673 snd_es1371_wait_src_ready 0 38673 NULL
+cfg80211_send_disassoc_38678 cfg80211_send_disassoc 3 38678 NULL
+iscsit_dump_data_payload_38683 iscsit_dump_data_payload 2 38683 NULL
+v4l2_ctrl_new_38725 v4l2_ctrl_new 7 38725 NULL
+w83977af_sir_interrupt_38738 w83977af_sir_interrupt 0 38738 NULL
+iwl_dbgfs_thermal_throttling_read_38779 iwl_dbgfs_thermal_throttling_read 3 38779 NULL
+snd_gus_dram_write_38784 snd_gus_dram_write 4 38784 NULL
+gre_manip_pkt_38785 gre_manip_pkt 2 38785 NULL
+do_pci_enable_device_38802 do_pci_enable_device 0 38802 NULL
+err_decode_38804 err_decode 2 38804 NULL
+ipv6_renew_option_38813 ipv6_renew_option 3 38813 NULL
+sys_select_38827 sys_select 1 38827 NULL
+b43_txhdr_size_38832 b43_txhdr_size 0 38832 NULL
+direct_entry_38836 direct_entry 3 38836 NULL
+compat_udp_setsockopt_38840 compat_udp_setsockopt 5 38840 NULL
+interfaces_38859 interfaces 2 38859 NULL
+pci_msix_table_size_38867 pci_msix_table_size 0 38867 NULL
+sizeof_gpio_leds_priv_38882 sizeof_gpio_leds_priv 0-1 38882 NULL
+dbgfs_state_38894 dbgfs_state 3 38894 NULL
+traverse_38897 traverse 0 38897 NULL
+__fswab16_38898 __fswab16 0 38898 NULL
+usb_maxpacket_38977 usb_maxpacket 0 38977 NULL
+lpfc_idiag_extacc_write_38998 lpfc_idiag_extacc_write 3 38998 NULL
+t4vf_pktgl_to_skb_39005 t4vf_pktgl_to_skb 2 39005 NULL
+get_nodes_39012 get_nodes 3 39012 NULL
+_zd_iowrite32v_async_locked_39034 _zd_iowrite32v_async_locked 3 39034 NULL
+do_write_kmem_39051 do_write_kmem 0-1-3 39051 NULL
+ReadHFC_39104 ReadHFC 0 39104 NULL
+tomoyo_truncate_39105 tomoyo_truncate 0 39105 NULL
+__kfifo_to_user_r_39123 __kfifo_to_user_r 5-3 39123 NULL
+ttm_mem_global_alloc_zone_39125 ttm_mem_global_alloc_zone 0 39125 NULL
+i915_gem_evict_something_39130 i915_gem_evict_something 0 39130 NULL
+generic_permission_39150 generic_permission 0 39150 NULL
+alloc_ring_39151 alloc_ring 2-4 39151 NULL
+proc_coredump_filter_read_39153 proc_coredump_filter_read 3 39153 NULL
+ext3_xattr_check_names_39174 ext3_xattr_check_names 0 39174 NULL
+init_list_set_39188 init_list_set 2-3 39188 NULL
+ubi_more_update_data_39189 ubi_more_update_data 4 39189 NULL
+drm_order_39244 drm_order 0 39244 NULL
+snd_pcm_capture_forward_39248 snd_pcm_capture_forward 2 39248 NULL
+__skb_cow_39254 __skb_cow 2 39254 NULL
+mei_registration_cdev_39284 mei_registration_cdev 2 39284 NULL
+__cfg80211_connect_result_39326 __cfg80211_connect_result 4-6 39326 NULL
+wimax_msg_alloc_39343 wimax_msg_alloc 4 39343 NULL
+__cfg80211_send_deauth_39344 __cfg80211_send_deauth 3 39344 NULL
+ide_complete_rq_39354 ide_complete_rq 3 39354 NULL
+vortex_wtdma_getlinearpos_39371 vortex_wtdma_getlinearpos 0 39371 NULL
+user_power_read_39414 user_power_read 3 39414 NULL
+alloc_agpphysmem_i8xx_39427 alloc_agpphysmem_i8xx 1 39427 NULL
+sys_semop_39457 sys_semop 3 39457 NULL
+setkey_unaligned_39474 setkey_unaligned 3 39474 NULL
+btrfs_mksubvol_39479 btrfs_mksubvol 3 39479 NULL
+ieee80211_if_fmt_dot11MeshHWMPmaxPREQretries_39499 ieee80211_if_fmt_dot11MeshHWMPmaxPREQretries 3 39499 NULL
+int_proc_write_39542 int_proc_write 3 39542 NULL nohasharray
+wm8350_i2c_read_device_39542 wm8350_i2c_read_device 3 39542 &int_proc_write_39542
+rtnl_port_size_39551 rtnl_port_size 0 39551 NULL
+pp_write_39554 pp_write 3 39554 NULL
+ol_dqblk_block_39558 ol_dqblk_block 0-2-3 39558 NULL
+datablob_format_39571 datablob_format 2 39571 NULL nohasharray
+ieee80211_if_read_fwded_mcast_39571 ieee80211_if_read_fwded_mcast 3 39571 &datablob_format_39571
+handle_response_icmp_39574 handle_response_icmp 7 39574 NULL
+ext_depth_39607 ext_depth 0 39607 NULL
+sdio_readb_39618 sdio_readb 0 39618 NULL
+snd_rme32_capture_copy_39653 snd_rme32_capture_copy 5 39653 NULL
+prism2_info_hostscanresults_39657 prism2_info_hostscanresults 3 39657 NULL
+pfkey_sockaddr_size_39661 pfkey_sockaddr_size 0 39661 NULL
+kvm_read_guest_cached_39666 kvm_read_guest_cached 4 39666 NULL
+sd_completed_bytes_39705 sd_completed_bytes 0 39705 NULL
+ftrace_pid_write_39710 ftrace_pid_write 3 39710 NULL
+tcf_csum_ipv4_tcp_39713 tcf_csum_ipv4_tcp 4 39713 NULL
+tcp_write_xmit_39755 tcp_write_xmit 2 39755 NULL
+ocfs2_pages_per_cluster_39790 ocfs2_pages_per_cluster 0 39790 NULL
+security_inode_listsecurity_39812 security_inode_listsecurity 0 39812 NULL
+snd_pcm_oss_writev3_39818 snd_pcm_oss_writev3 3 39818 NULL
+sys_migrate_pages_39825 sys_migrate_pages 2 39825 NULL
+get_priv_size_39828 get_priv_size 0-1 39828 NULL
+beiscsi_process_async_pdu_39834 beiscsi_process_async_pdu 7 39834 NULL
+pkt_add_39897 pkt_add 3 39897 NULL
+read_file_modal_eeprom_39909 read_file_modal_eeprom 3 39909 NULL
+gen_pool_add_virt_39913 gen_pool_add_virt 4 39913 NULL
+exofs_read_kern_39921 exofs_read_kern 6 39921 NULL nohasharray
+oom_score_adj_read_39921 oom_score_adj_read 3 39921 &exofs_read_kern_39921
+__spi_async_39932 __spi_async 0 39932 NULL
+fwnet_pd_new_39947 fwnet_pd_new 4 39947 NULL
+tty_prepare_flip_string_39955 tty_prepare_flip_string 3-0 39955 NULL
+dma_push_rx_39973 dma_push_rx 2 39973 NULL
+mthca_array_init_39987 mthca_array_init 2 39987 NULL
+fw_device_op_read_39990 fw_device_op_read 3 39990 NULL
+xen_hvm_config_40018 xen_hvm_config 2 40018 NULL
+datablob_hmac_append_40038 datablob_hmac_append 3 40038 NULL
+atomic_xchg_40070 atomic_xchg 0 40070 NULL
+sctp_setsockopt_delayed_ack_40129 sctp_setsockopt_delayed_ack 3 40129 NULL
+iwch_alloc_fastreg_pbl_40153 iwch_alloc_fastreg_pbl 2 40153 NULL
+pt_write_40159 pt_write 3 40159 NULL
+scsi_sg_count_40182 scsi_sg_count 0 40182 NULL
+ipr_alloc_ucode_buffer_40199 ipr_alloc_ucode_buffer 1 40199 NULL
+allocate_probes_40204 allocate_probes 1 40204 NULL
+compress_file_range_40225 compress_file_range 3-4 40225 NULL
+osst_read_40237 osst_read 3 40237 NULL
+brcmf_sdioh_request_buffer_40239 brcmf_sdioh_request_buffer 7 40239 NULL
+ocfs2_zero_extend_get_range_40248 ocfs2_zero_extend_get_range 4 40248 NULL
+fuse_update_attributes_40262 fuse_update_attributes 0 40262 NULL nohasharray
+rs_sta_dbgfs_scale_table_read_40262 rs_sta_dbgfs_scale_table_read 3 40262 &fuse_update_attributes_40262
+ext2_fiemap_40271 ext2_fiemap 4 40271 NULL
+nfs_file_llseek_40306 nfs_file_llseek 2 40306 NULL
+ib_get_mad_data_offset_40336 ib_get_mad_data_offset 0 40336 NULL
+bat_ogm_queue_add_40337 bat_ogm_queue_add 3 40337 NULL
+mmio_read_40348 mmio_read 4 40348 NULL
+ocfs2_release_clusters_40355 ocfs2_release_clusters 4 40355 NULL
+ocfs2_check_range_for_refcount_40365 ocfs2_check_range_for_refcount 2-3 40365 NULL
+get_chars_40373 get_chars 3 40373 NULL
+usb_gadget_config_buf_40374 usb_gadget_config_buf 0 40374 NULL
+fwnet_incoming_packet_40380 fwnet_incoming_packet 3 40380 NULL
+brcmf_sdbrcm_get_image_40397 brcmf_sdbrcm_get_image 0-2 40397 NULL
+fb_prepare_extra_logos_40429 fb_prepare_extra_logos 0-2 40429 NULL
+atmel_rmem16_40450 atmel_rmem16 0 40450 NULL
+tomoyo_update_policy_40458 tomoyo_update_policy 2 40458 NULL
+zd_usb_scnprint_id_40459 zd_usb_scnprint_id 0-3 40459 NULL
+afs_fs_store_data_40484 afs_fs_store_data 3-4-5-6 40484 NULL
+devcgroup_inode_permission_40492 devcgroup_inode_permission 0 40492 NULL
+tty_write_room_40495 tty_write_room 0 40495 NULL
+__ethtool_get_sset_count_40511 __ethtool_get_sset_count 0 40511 NULL
+TSS_checkhmac2_40520 TSS_checkhmac2 5-7 40520 NULL
+i915_gem_execbuffer_relocate_object_slow_40546 i915_gem_execbuffer_relocate_object_slow 0 40546 NULL
+ima_write_policy_40548 ima_write_policy 3 40548 NULL
+esp_alloc_tmp_40558 esp_alloc_tmp 3-2 40558 NULL
+b1_get_byte_40597 b1_get_byte 0 40597 NULL
+skge_rx_get_40598 skge_rx_get 3 40598 NULL
+get_priv_descr_and_size_40612 get_priv_descr_and_size 0 40612 NULL
+sctp_manip_pkt_40620 sctp_manip_pkt 2 40620 NULL
+ext4_mark_inode_dirty_40673 ext4_mark_inode_dirty 0 40673 NULL
+pci_enable_resources_40680 pci_enable_resources 0 40680 NULL
+__seq_open_private_40715 __seq_open_private 3 40715 NULL
+find_next_zero_bit_le_40744 find_next_zero_bit_le 0 40744 NULL nohasharray
+xfs_iext_remove_direct_40744 xfs_iext_remove_direct 3 40744 &find_next_zero_bit_le_40744
+security_inode_listxattr_40752 security_inode_listxattr 0 40752 NULL
+ad1889_readl_40765 ad1889_readl 0 40765 NULL
+pg_write_40766 pg_write 3 40766 NULL
+ecryptfs_readlink_40775 ecryptfs_readlink 3 40775 NULL nohasharray
+show_list_40775 show_list 3-0 40775 &ecryptfs_readlink_40775
+kfifo_out_copy_r_40784 kfifo_out_copy_r 3 40784 NULL
+bitmap_weight_40791 bitmap_weight 2-0 40791 NULL
+netdev_alloc_skb_ip_align_40811 netdev_alloc_skb_ip_align 2 40811 NULL
+nl80211_send_roamed_40825 nl80211_send_roamed 5-7 40825 NULL
+nilfs_mdt_init_40849 nilfs_mdt_init 3 40849 NULL
+__shared_list_add_40850 __shared_list_add 0 40850 NULL
+ocfs2_zero_partial_clusters_40856 ocfs2_zero_partial_clusters 2-3 40856 NULL
+v9fs_file_read_40858 v9fs_file_read 3 40858 NULL
+read_file_queue_40895 read_file_queue 3 40895 NULL
+waiters_read_40902 waiters_read 3 40902 NULL
+isdn_add_channels_40905 isdn_add_channels 3 40905 NULL
+vol_cdev_write_40915 vol_cdev_write 3 40915 NULL
+iterate_extent_inodes_40923 iterate_extent_inodes 0 40923 NULL
+btrfs_setsize_40931 btrfs_setsize 2 40931 NULL
+snd_vx_create_40948 snd_vx_create 4 40948 NULL
+skb_end_offset_40949 skb_end_offset 0 40949 NULL
+tcp_skb_mss_40964 tcp_skb_mss 0 40964 NULL
+rds_sendmsg_40976 rds_sendmsg 4 40976 NULL
+mac80211_format_buffer_41010 mac80211_format_buffer 2 41010 NULL
+_req_append_segment_41031 _req_append_segment 2 41031 NULL
+mISDN_sock_sendmsg_41035 mISDN_sock_sendmsg 4 41035 NULL
+ocfs2_xattr_index_block_find_41040 ocfs2_xattr_index_block_find 0 41040 NULL
+vfs_listxattr_41062 vfs_listxattr 0 41062 NULL
+cfg80211_inform_bss_frame_41078 cfg80211_inform_bss_frame 4 41078 NULL
+roccat_read_41093 roccat_read 3 41093 NULL
+f_audio_buffer_alloc_41110 f_audio_buffer_alloc 1 41110 NULL
+oom_adjust_write_41116 oom_adjust_write 3 41116 NULL
+ol_quota_chunk_block_41177 ol_quota_chunk_block 0-2 41177 NULL
+compat_sys_process_vm_writev_41194 compat_sys_process_vm_writev 3-5 41194 NULL
+xfs_readdir_41200 xfs_readdir 3 41200 NULL
+ocfs2_read_quota_block_41207 ocfs2_read_quota_block 2 41207 NULL
+ceph_calc_raw_layout_41212 ceph_calc_raw_layout 4 41212 NULL
+tun_alloc_skb_41216 tun_alloc_skb 2-4-3 41216 NULL
+nfs_page_array_len_41219 nfs_page_array_len 0-2-1 41219 NULL
+hiddev_compat_ioctl_41255 hiddev_compat_ioctl 2 41255 NULL
+create_dir_41256 create_dir 0 41256 NULL
+erst_read_41260 erst_read 0 41260 NULL
+alloc_context_41283 alloc_context 1 41283 NULL
+user_update_41332 user_update 3 41332 NULL
+twl_change_queue_depth_41342 twl_change_queue_depth 2 41342 NULL
+cnic_init_id_tbl_41354 cnic_init_id_tbl 2 41354 NULL
+kmp_init_41373 kmp_init 2 41373 NULL
+sys_flistxattr_41407 sys_flistxattr 3 41407 NULL
+xfs_iext_add_41422 xfs_iext_add 3 41422 NULL
+isdn_ppp_fill_rq_41428 isdn_ppp_fill_rq 2 41428 NULL
+lbs_rdrf_read_41431 lbs_rdrf_read 3 41431 NULL
+ntfs_file_buffered_write_41442 ntfs_file_buffered_write 6-4 41442 NULL
+pcpu_build_alloc_info_41443 pcpu_build_alloc_info 1-2-3 41443 NULL
+layout_leb_in_gaps_41470 layout_leb_in_gaps 0 41470 NULL
+hpfs_translate_name_41497 hpfs_translate_name 3 41497 NULL
+xfrm_hash_new_size_41505 xfrm_hash_new_size 0-1 41505 NULL
+ldisc_receive_41516 ldisc_receive 4 41516 NULL
+rng_dev_read_41581 rng_dev_read 3 41581 NULL
+read_file_rx_chainmask_41605 read_file_rx_chainmask 3 41605 NULL
+tcp_hdrlen_41610 tcp_hdrlen 0 41610 NULL
+usb_endpoint_maxp_41613 usb_endpoint_maxp 0 41613 NULL nohasharray
+lbs_bcnmiss_write_41613 lbs_bcnmiss_write 3 41613 &usb_endpoint_maxp_41613
+mempool_create_kmalloc_pool_41650 mempool_create_kmalloc_pool 1 41650 NULL
+get_std_timing_41654 get_std_timing 0 41654 NULL
+squashfs_cache_init_41656 squashfs_cache_init 2 41656 NULL
+ieee80211_if_fmt_bssid_41677 ieee80211_if_fmt_bssid 3 41677 NULL
+uapsd_max_sp_len_write_41683 uapsd_max_sp_len_write 3 41683 NULL
+apei_exec_for_each_entry_41717 apei_exec_for_each_entry 0 41717 NULL
+sys_pwritev_41722 sys_pwritev 3 41722 NULL
+hc_gpa_41744 hc_gpa 0-2-3 41744 NULL
+fillonedir_41746 fillonedir 3 41746 NULL
+ocfs2_dx_dir_rebalance_41793 ocfs2_dx_dir_rebalance 7 41793 NULL
+bat_socket_read_41813 bat_socket_read 3 41813 NULL
+do_ip_setsockopt_41852 do_ip_setsockopt 5 41852 NULL
+tcp_packets_in_flight_41853 tcp_packets_in_flight 0 41853 NULL
+keyctl_instantiate_key_41855 keyctl_instantiate_key 3 41855 NULL
+pci_map_single_41869 pci_map_single 0 41869 NULL
+usb_gadget_get_string_41871 usb_gadget_get_string 0 41871 NULL
+get_packet_41914 get_packet 3 41914 NULL
+get_fdb_entries_41916 get_fdb_entries 3 41916 NULL
+ceph_get_direct_page_vector_41917 ceph_get_direct_page_vector 2 41917 NULL
+nfsd_getxattr_41934 nfsd_getxattr 0 41934 NULL
+iscsi_iser_recv_41948 iscsi_iser_recv 4 41948 NULL
+ocfs2_xattr_bucket_get_name_value_41949 ocfs2_xattr_bucket_get_name_value 0 41949 NULL
+efx_tx_queue_insert_41955 efx_tx_queue_insert 2 41955 NULL
+portnames_read_41958 portnames_read 3 41958 NULL
+dst_mtu_41969 dst_mtu 0 41969 NULL
+_get_slice_41991 _get_slice 0 41991 NULL
+flakey_status_42000 flakey_status 4 42000 NULL
+pool_allocate_42012 pool_allocate 3 42012 NULL
+spidev_sync_read_42014 spidev_sync_read 0 42014 NULL
+rs_sta_dbgfs_scale_table_write_42017 rs_sta_dbgfs_scale_table_write 3 42017 NULL
+ensure_wear_leveling_42029 ensure_wear_leveling 0 42029 NULL
+acpi_ut_create_buffer_object_42030 acpi_ut_create_buffer_object 1 42030 NULL
+__hwahc_op_set_gtk_42038 __hwahc_op_set_gtk 4 42038 NULL
+irda_sendmsg_ultra_42047 irda_sendmsg_ultra 4 42047 NULL
+jffs2_do_link_42048 jffs2_do_link 6 42048 NULL
+brcmf_sdbrcm_downloadvars_42064 brcmf_sdbrcm_downloadvars 3 42064 NULL
+scsi_execute_req_42088 scsi_execute_req 5 42088 NULL
+sk_chk_filter_42095 sk_chk_filter 2 42095 NULL
+submit_inquiry_42108 submit_inquiry 3 42108 NULL
+sysfs_read_file_42113 sysfs_read_file 3 42113 NULL
+ext4_do_update_inode_42127 ext4_do_update_inode 0 42127 NULL
+Read_hfc16_stable_42131 Read_hfc16_stable 0 42131 NULL
+ttm_agp_populate_42144 ttm_agp_populate 2 42144 NULL
+v9fs_alloc_rdir_buf_42150 v9fs_alloc_rdir_buf 2 42150 NULL
+mmc_align_data_size_42161 mmc_align_data_size 0-2 42161 NULL
+read_file_base_eeprom_42168 read_file_base_eeprom 3 42168 NULL
+oprofilefs_str_to_user_42182 oprofilefs_str_to_user 3 42182 NULL
+write_file_beacon_42185 write_file_beacon 3 42185 NULL
+get_znodes_to_commit_42201 get_znodes_to_commit 0 42201 NULL
+btmrvl_hsmode_write_42252 btmrvl_hsmode_write 3 42252 NULL
+ctnetlink_proto_size_42270 ctnetlink_proto_size 0 42270 NULL
+__pcpu_size_to_slot_42271 __pcpu_size_to_slot 0 42271 NULL
+snd_pcm_hw_param_value_max_42280 snd_pcm_hw_param_value_max 0 42280 NULL
+rtnl_link_get_af_size_42296 rtnl_link_get_af_size 0 42296 NULL
+crypt_status_42302 crypt_status 4 42302 NULL nohasharray
+sel_read_perm_42302 sel_read_perm 3 42302 &crypt_status_42302
+sctp_setsockopt_del_key_42304 sctp_setsockopt_del_key 3 42304 NULL nohasharray
+ulong_read_file_42304 ulong_read_file 3 42304 &sctp_setsockopt_del_key_42304
+hysdn_conf_read_42324 hysdn_conf_read 3 42324 NULL nohasharray
+tracing_ctrl_write_42324 tracing_ctrl_write 3 42324 &hysdn_conf_read_42324
+tcp_sync_mss_42330 tcp_sync_mss 0-2 42330 NULL
+ide_raw_taskfile_42355 ide_raw_taskfile 4 42355 NULL
+msnd_fifo_read_42406 msnd_fifo_read 0-3 42406 NULL
+krng_get_random_42420 krng_get_random 3 42420 NULL
+gsm_data_alloc_42437 gsm_data_alloc 3 42437 NULL
+key_conf_keyidx_read_42443 key_conf_keyidx_read 3 42443 NULL
+snd_pcm_action_group_42452 snd_pcm_action_group 0 42452 NULL
+tcm_loop_change_queue_depth_42454 tcm_loop_change_queue_depth 2 42454 NULL
+neigh_nlmsg_size_42464 neigh_nlmsg_size 0 42464 NULL
+kernel_recvmsg_42482 kernel_recvmsg 0 42482 NULL
+brcmf_sdbrcm_bus_txctl_42492 brcmf_sdbrcm_bus_txctl 3 42492 NULL
+kvm_write_wall_clock_42520 kvm_write_wall_clock 2 42520 NULL
+smk_write_netlbladdr_42525 smk_write_netlbladdr 3 42525 NULL
+snd_emux_create_port_42533 snd_emux_create_port 3 42533 NULL
+dbAllocNear_42546 dbAllocNear 0 42546 NULL
+udp_recvmsg_42558 udp_recvmsg 4 42558 NULL
+iwl_print_event_log_42566 iwl_print_event_log 7-5-0 42566 NULL
+xfrm_new_hash_mask_42579 xfrm_new_hash_mask 0-1 42579 NULL
+oom_score_adj_write_42594 oom_score_adj_write 3 42594 NULL
+__pskb_pull_42602 __pskb_pull 2 42602 NULL
+sys_move_pages_42626 sys_move_pages 2 42626 NULL
+ieee80211_if_fmt_dot11MeshHWMPactivePathTimeout_42635 ieee80211_if_fmt_dot11MeshHWMPactivePathTimeout 3 42635 NULL
+scsi_activate_tcq_42640 scsi_activate_tcq 2 42640 NULL
+br_mdb_rehash_42643 br_mdb_rehash 2 42643 NULL
+parport_pc_compat_write_block_pio_42644 parport_pc_compat_write_block_pio 3 42644 NULL
+_regmap_raw_write_42652 _regmap_raw_write 4 42652 NULL
+l2tp_xmit_skb_42672 l2tp_xmit_skb 3 42672 NULL
+request_key_and_link_42693 request_key_and_link 4 42693 NULL
+__ocfs2_decrease_refcount_42717 __ocfs2_decrease_refcount 5-4 42717 NULL
+read_status_42722 read_status 0 42722 NULL
+set_aoe_iflist_42737 set_aoe_iflist 2 42737 NULL
+ax25_setsockopt_42740 ax25_setsockopt 5 42740 NULL
+dpm_sysfs_add_42756 dpm_sysfs_add 0 42756 NULL
+qla2x00_get_ctx_bsg_sp_42768 qla2x00_get_ctx_bsg_sp 3 42768 NULL
+x25_recvmsg_42777 x25_recvmsg 4 42777 NULL
+snd_midi_event_decode_42780 snd_midi_event_decode 0 42780 NULL
+cryptd_hash_setkey_42781 cryptd_hash_setkey 3 42781 NULL
+ntfs_attr_extend_allocation_42796 ntfs_attr_extend_allocation 0 42796 NULL
+fw_device_op_compat_ioctl_42804 fw_device_op_compat_ioctl 2 42804 NULL
+drm_ioctl_42813 drm_ioctl 2 42813 NULL
+iwl_dbgfs_ucode_bt_stats_read_42820 iwl_dbgfs_ucode_bt_stats_read 3 42820 NULL
+set_arg_42824 set_arg 3 42824 NULL
+ocfs2_desc_bitmap_to_cluster_off_42831 ocfs2_desc_bitmap_to_cluster_off 2 42831 NULL
+ocfs2_clusters_for_bytes_42872 ocfs2_clusters_for_bytes 0-2 42872 NULL
+pskb_expand_head_42881 pskb_expand_head 2-3 42881 NULL
+tipc_port_recv_sections_42890 tipc_port_recv_sections 4 42890 NULL
+xpc_kmalloc_cacheline_aligned_42895 xpc_kmalloc_cacheline_aligned 1 42895 NULL
+hd_end_request_42904 hd_end_request 2 42904 NULL
+sctp_getsockopt_maxburst_42941 sctp_getsockopt_maxburst 2 42941 NULL
+vx_reset_chk_42946 vx_reset_chk 0 42946 NULL
+sys_sethostname_42962 sys_sethostname 2 42962 NULL
+ixj_enhanced_read_42980 ixj_enhanced_read 3 42980 NULL
+pfkey_xfrm_policy2sec_ctx_size_42981 pfkey_xfrm_policy2sec_ctx_size 0 42981 NULL nohasharray
+compat_udpv6_setsockopt_42981 compat_udpv6_setsockopt 5 42981 &pfkey_xfrm_policy2sec_ctx_size_42981
+uapsd_queues_write_43040 uapsd_queues_write 3 43040 NULL
+_xfer_secondary_pool_43089 _xfer_secondary_pool 2 43089 NULL
+ieee80211_if_fmt_drop_unencrypted_43107 ieee80211_if_fmt_drop_unencrypted 3 43107 NULL
+usb_string_sub_43164 usb_string_sub 0 43164 NULL
+ext4_xattr_ibody_get_43200 ext4_xattr_ibody_get 0 43200 NULL
+teiup_create_43201 teiup_create 3 43201 NULL
+uio_write_43202 uio_write 3 43202 NULL
+iso_callback_43208 iso_callback 3 43208 NULL
+atomic_long_add_return_43217 atomic_long_add_return 1 43217 NULL
+vmemmap_alloc_block_43245 vmemmap_alloc_block 1 43245 NULL
+ide_end_rq_43269 ide_end_rq 4 43269 NULL
+parport_pc_ecp_write_block_pio_43278 parport_pc_ecp_write_block_pio 3 43278 NULL nohasharray
+evtchn_write_43278 evtchn_write 3 43278 &parport_pc_ecp_write_block_pio_43278
+filemap_write_and_wait_range_43279 filemap_write_and_wait_range 0 43279 NULL
+__ext4_get_inode_loc_43332 __ext4_get_inode_loc 0 43332 NULL
+svc_pool_map_get_43386 svc_pool_map_get 0 43386 NULL
+__alloc_bootmem_low_43423 __alloc_bootmem_low 1 43423 NULL
+usb_alloc_urb_43436 usb_alloc_urb 1 43436 NULL
+usb_string_43443 usb_string 0 43443 NULL nohasharray
+usemap_size_43443 usemap_size 0-2-1 43443 &usb_string_43443
+__data_list_add_eb_43472 __data_list_add_eb 0 43472 NULL
+nf_nat_ftp_fmt_cmd_43495 nf_nat_ftp_fmt_cmd 0 43495 NULL
+ieee80211_if_fmt_dot11MeshHWMPnetDiameterTraversalTime_43505 ieee80211_if_fmt_dot11MeshHWMPnetDiameterTraversalTime 3 43505 NULL
+do_readlink_43518 do_readlink 2 43518 NULL
+cachefiles_daemon_write_43535 cachefiles_daemon_write 3 43535 NULL
+request_resource_43548 request_resource 0 43548 NULL
+ath_rx_init_43564 ath_rx_init 2 43564 NULL
+_fc_frame_alloc_43568 _fc_frame_alloc 1 43568 NULL
+rpc_malloc_43573 rpc_malloc 2 43573 NULL
+lpfc_idiag_drbacc_read_reg_43606 lpfc_idiag_drbacc_read_reg 0-3 43606 NULL
+proc_read_43614 proc_read 3 43614 NULL
+prison_create_43623 prison_create 1 43623 NULL
+random_write_43656 random_write 3 43656 NULL
+bio_integrity_tag_43658 bio_integrity_tag 3 43658 NULL
+ext4_acl_count_43659 ext4_acl_count 0-1 43659 NULL
+dmam_declare_coherent_memory_43679 dmam_declare_coherent_memory 4 43679 NULL
+user_confirm_reply_43708 user_confirm_reply 4 43708 NULL
+drbd_md_first_sector_43729 drbd_md_first_sector 0 43729 NULL
+snd_rme32_playback_copy_43732 snd_rme32_playback_copy 5 43732 NULL
+ocfs2_replace_clusters_43733 ocfs2_replace_clusters 5 43733 NULL
+fuse_conn_congestion_threshold_write_43736 fuse_conn_congestion_threshold_write 3 43736 NULL
+osdv1_attr_list_elem_size_43747 osdv1_attr_list_elem_size 0-1 43747 NULL
+gigaset_initcs_43753 gigaset_initcs 2 43753 NULL
+sctp_setsockopt_active_key_43755 sctp_setsockopt_active_key 3 43755 NULL
+ocfs2_xattr_get_value_outside_43787 ocfs2_xattr_get_value_outside 0 43787 NULL nohasharray
+byte_pos_43787 byte_pos 0-2 43787 &ocfs2_xattr_get_value_outside_43787
+btrfs_copy_from_user_43806 btrfs_copy_from_user 3-1-0 43806 NULL
+hci_send_cmd_43810 hci_send_cmd 3 43810 NULL
+ext4_split_extent_43818 ext4_split_extent 0 43818 NULL
+i915_gem_execbuffer_relocate_entry_43822 i915_gem_execbuffer_relocate_entry 0 43822 NULL
+ieee80211_if_fmt_element_ttl_43825 ieee80211_if_fmt_element_ttl 3 43825 NULL
+ieee80211_alloc_hw_43829 ieee80211_alloc_hw 1 43829 NULL
+p54_download_eeprom_43842 p54_download_eeprom 4 43842 NULL
+read_flush_43851 read_flush 3 43851 NULL
+idmap_update_entry_43885 idmap_update_entry 3 43885 NULL
+prism2_sta_send_mgmt_43916 prism2_sta_send_mgmt 5 43916 NULL
+stats_dot11RTSFailureCount_read_43948 stats_dot11RTSFailureCount_read 3 43948 NULL
+i915_ring_idle_43969 i915_ring_idle 0 43969 NULL
+__get_required_blob_size_43980 __get_required_blob_size 0-3-2 43980 NULL
+nla_reserve_43984 nla_reserve 3 43984 NULL
+scsi_command_size_43992 scsi_command_size 0 43992 NULL nohasharray
+bcm_recvmsg_43992 bcm_recvmsg 4 43992 &scsi_command_size_43992 nohasharray
+kvm_read_guest_virt_43992 kvm_read_guest_virt 4-2 43992 &bcm_recvmsg_43992
+write_flush_procfs_44011 write_flush_procfs 3 44011 NULL
+btrfs_prev_leaf_44083 btrfs_prev_leaf 0 44083 NULL
+xlog_recover_add_to_cont_trans_44102 xlog_recover_add_to_cont_trans 4 44102 NULL
+skb_frag_dma_map_44112 skb_frag_dma_map 0 44112 NULL
+tracing_set_trace_read_44122 tracing_set_trace_read 3 44122 NULL
+scsi_get_resid_44147 scsi_get_resid 0 44147 NULL
+ocfs2_xattr_bucket_find_44174 ocfs2_xattr_bucket_find 0 44174 NULL
+handle_eviocgbit_44193 handle_eviocgbit 3 44193 NULL
+srp_alloc_iu_44227 srp_alloc_iu 2 44227 NULL
+scsi_track_queue_full_44239 scsi_track_queue_full 2 44239 NULL
+enlarge_skb_44248 enlarge_skb 2 44248 NULL
+apei_resources_sub_44252 apei_resources_sub 0 44252 NULL
+device_create_file_44285 device_create_file 0 44285 NULL
+ocfs2_zero_range_for_truncate_44294 ocfs2_zero_range_for_truncate 3 44294 NULL
+bitmap_scnprintf_44318 bitmap_scnprintf 2-0 44318 NULL
+dispatch_proc_write_44320 dispatch_proc_write 3 44320 NULL
+rs_init_44327 rs_init 1 44327 NULL
+count_ah_combs_44334 count_ah_combs 0 44334 NULL
+blk_queue_init_tags_44355 blk_queue_init_tags 2 44355 NULL
+rts_threshold_read_44384 rts_threshold_read 3 44384 NULL
+aoedev_flush_44398 aoedev_flush 2 44398 NULL
+strlcpy_44400 strlcpy 3 44400 NULL
+drm_buffer_alloc_44405 drm_buffer_alloc 2 44405 NULL
+osst_do_scsi_44410 osst_do_scsi 4 44410 NULL
+write_file_debug_44476 write_file_debug 3 44476 NULL
+btrfs_chunk_item_size_44478 btrfs_chunk_item_size 0-1 44478 NULL
+sdio_align_size_44489 sdio_align_size 0-2 44489 NULL
+ath6kl_tm_rx_report_44494 ath6kl_tm_rx_report 3 44494 NULL
+ieee80211_if_read_dropped_frames_ttl_44500 ieee80211_if_read_dropped_frames_ttl 3 44500 NULL
+xfrm_sa_len_44502 xfrm_sa_len 0 44502 NULL
+ac_register_board_44504 ac_register_board 3 44504 NULL
+security_getprocattr_44505 security_getprocattr 0 44505 NULL nohasharray
+iwl_dbgfs_sram_read_44505 iwl_dbgfs_sram_read 3 44505 &security_getprocattr_44505
+spidev_write_44510 spidev_write 3 44510 NULL
+sys_msgsnd_44537 sys_msgsnd 3 44537 NULL nohasharray
+comm_write_44537 comm_write 3 44537 &sys_msgsnd_44537
+sysfs_add_one_44629 sysfs_add_one 0 44629 NULL
+cfpkt_add_body_44630 cfpkt_add_body 3 44630 NULL
+alloc_ctrl_packet_44667 alloc_ctrl_packet 1 44667 NULL
+sysfs_create_link_44685 sysfs_create_link 0 44685 NULL
+i915_wait_request_44703 i915_wait_request 0 44703 NULL
+__generic_block_fiemap_44713 __generic_block_fiemap 4 44713 NULL
+mempool_create_node_44715 mempool_create_node 1 44715 NULL
+_zd_iowrite32v_locked_44725 _zd_iowrite32v_locked 3 44725 NULL
+clusterip_proc_write_44729 clusterip_proc_write 3 44729 NULL
+fib_count_nexthops_44730 fib_count_nexthops 0 44730 NULL
+key_tx_rx_count_read_44742 key_tx_rx_count_read 3 44742 NULL
+tnode_new_44757 tnode_new 3 44757 NULL nohasharray
+pty_write_44757 pty_write 3 44757 &tnode_new_44757
+sctp_setsockopt_44788 sctp_setsockopt 5 44788 NULL
+x25_pacsize_to_bytes_44812 x25_pacsize_to_bytes 0 44812 NULL
+sisusb_write_44834 sisusb_write 3 44834 NULL
+nl80211_send_unprot_disassoc_44846 nl80211_send_unprot_disassoc 4 44846 NULL
+qib_verbs_send_dma_44850 qib_verbs_send_dma 6 44850 NULL
+init_rs_44873 init_rs 1 44873 NULL
+skb_availroom_44883 skb_availroom 0 44883 NULL
+nf_bridge_encap_header_len_44890 nf_bridge_encap_header_len 0 44890 NULL
+do_tty_write_44896 do_tty_write 5 44896 NULL
+ftdi_process_packet_45005 ftdi_process_packet 5 45005 NULL
+i915_gem_do_execbuffer_45012 i915_gem_do_execbuffer 0 45012 NULL
+ptrace_writedata_45021 ptrace_writedata 4 45021 NULL
+vhci_get_user_45039 vhci_get_user 3 45039 NULL
+sel_write_user_45060 sel_write_user 3 45060 NULL
+snd_mixart_BA0_read_45069 snd_mixart_BA0_read 5 45069 NULL
+orig_hash_del_if_45080 orig_hash_del_if 2 45080 NULL
+usbdev_read_45114 usbdev_read 3 45114 NULL
+send_to_tty_45141 send_to_tty 3 45141 NULL
+crypto_aead_blocksize_45148 crypto_aead_blocksize 0 45148 NULL
+device_write_45156 device_write 3 45156 NULL nohasharray
+ocfs2_remove_inode_range_45156 ocfs2_remove_inode_range 3-4 45156 &device_write_45156
+tomoyo_write_self_45161 tomoyo_write_self 3 45161 NULL
+sta_agg_status_write_45164 sta_agg_status_write 3 45164 NULL
+snd_sb_csp_load_user_45190 snd_sb_csp_load_user 3 45190 NULL nohasharray
+sctp_pack_cookie_45190 sctp_pack_cookie 6 45190 &snd_sb_csp_load_user_45190
+add_child_45201 add_child 4 45201 NULL
+iso_alloc_urb_45206 iso_alloc_urb 4-5 45206 NULL
+spi_alloc_master_45223 spi_alloc_master 2 45223 NULL
+ieee80211_if_read_peer_45233 ieee80211_if_read_peer 3 45233 NULL
+event_enable_write_45238 event_enable_write 3 45238 NULL
+gfs2_fiemap_45282 gfs2_fiemap 4 45282 NULL
+snd_pcm_oss_sync1_45298 snd_pcm_oss_sync1 2 45298 NULL
+e1000_tx_map_45309 e1000_tx_map 5 45309 NULL
+copy_vm86_regs_from_user_45340 copy_vm86_regs_from_user 3 45340 NULL
+lane2_associate_req_45398 lane2_associate_req 4 45398 NULL
+__data_list_add_45403 __data_list_add 0 45403 NULL
+ath6kl_wmi_send_probe_response_cmd_45422 ath6kl_wmi_send_probe_response_cmd 5 45422 NULL
+tty_buffer_alloc_45437 tty_buffer_alloc 2 45437 NULL
+__node_remap_45458 __node_remap 4 45458 NULL
+rds_ib_set_wr_signal_state_45463 rds_ib_set_wr_signal_state 0 45463 NULL
+tracing_read_dyn_info_45468 tracing_read_dyn_info 3 45468 NULL
+rds_message_copy_from_user_45510 rds_message_copy_from_user 3 45510 NULL
+sys_lgetxattr_45531 sys_lgetxattr 4 45531 NULL
+cgroup_read_u64_45532 cgroup_read_u64 5 45532 NULL
+copy_macs_45534 copy_macs 4 45534 NULL
+nla_attr_size_45545 nla_attr_size 0-1 45545 NULL
+v9fs_direct_read_45546 v9fs_direct_read 3 45546 NULL
+stats_dot11ACKFailureCount_read_45558 stats_dot11ACKFailureCount_read 3 45558 NULL
+posix_acl_xattr_size_45561 posix_acl_xattr_size 0-1 45561 NULL
+venus_rmdir_45564 venus_rmdir 4 45564 NULL
+rdma_set_ib_paths_45592 rdma_set_ib_paths 3 45592 NULL
+hidraw_get_report_45609 hidraw_get_report 3 45609 NULL
+audit_log_n_hex_45617 audit_log_n_hex 3 45617 NULL
+i915_gem_evict_everything_45629 i915_gem_evict_everything 0 45629 NULL
+ext4_reserve_inode_write_45654 ext4_reserve_inode_write 0 45654 NULL
+compat_mpctl_ioctl_45671 compat_mpctl_ioctl 2 45671 NULL
+dgram_sendmsg_45679 dgram_sendmsg 4 45679 NULL
+smk_write_ambient_45691 smk_write_ambient 3 45691 NULL
+ip_nat_sip_expect_45693 ip_nat_sip_expect 7 45693 NULL
+bscnl_emit_45699 bscnl_emit 2-5-0 45699 NULL nohasharray
+unix_dgram_sendmsg_45699 unix_dgram_sendmsg 4 45699 &bscnl_emit_45699
+sg_proc_write_adio_45704 sg_proc_write_adio 3 45704 NULL
+snd_cs46xx_io_read_45734 snd_cs46xx_io_read 5 45734 NULL
+v4l2_ctrl_new_std_45748 v4l2_ctrl_new_std 5 45748 NULL
+lkdtm_debugfs_read_45752 lkdtm_debugfs_read 3 45752 NULL
+i915_gem_object_flush_gpu_write_domain_45755 i915_gem_object_flush_gpu_write_domain 0 45755 NULL
+alloc_ts_config_45775 alloc_ts_config 1 45775 NULL
+raw_setsockopt_45800 raw_setsockopt 5 45800 NULL
+rds_tcp_inc_copy_to_user_45804 rds_tcp_inc_copy_to_user 3 45804 NULL
+lbs_rdbbp_read_45805 lbs_rdbbp_read 3 45805 NULL
+pcpu_alloc_alloc_info_45813 pcpu_alloc_alloc_info 1-2 45813 NULL
+ipv6_recv_rxpmtu_45830 ipv6_recv_rxpmtu 3 45830 NULL
+amthi_read_45831 amthi_read 4 45831 NULL
+audit_make_reply_45835 audit_make_reply 7 45835 NULL
+__ip_select_ident_45851 __ip_select_ident 3 45851 NULL
+smp_build_cmd_45853 smp_build_cmd 3 45853 NULL
+isdn_write_45863 isdn_write 3 45863 NULL
+rbd_get_num_segments_45864 rbd_get_num_segments 0-2-3 45864 NULL
+tpm_config_in_45880 tpm_config_in 0 45880 NULL
+get_rdac_req_45882 get_rdac_req 3 45882 NULL
+ocfs2_xattr_block_find_45891 ocfs2_xattr_block_find 0 45891 NULL
+__svc_create_45903 __svc_create 3 45903 NULL
+dbgfs_frame_45917 dbgfs_frame 3 45917 NULL
+alloc_mr_45935 alloc_mr 1 45935 NULL
+cma_user_data_offset_45954 cma_user_data_offset 0 45954 NULL
+ndisc_opt_addr_space_45959 ndisc_opt_addr_space 0 45959 NULL
+rb_simple_read_45972 rb_simple_read 3 45972 NULL
+ezusb_writememory_45976 ezusb_writememory 4 45976 NULL
+ioat2_dca_count_dca_slots_45984 ioat2_dca_count_dca_slots 0 45984 NULL
+sierra_setup_urb_46029 sierra_setup_urb 5 46029 NULL
+get_free_entries_46030 get_free_entries 1 46030 NULL
+__access_remote_vm_46031 __access_remote_vm 0 46031 NULL
+snd_emu10k1x_ptr_read_46049 snd_emu10k1x_ptr_read 0 46049 NULL
+__ocfs2_move_extent_46060 __ocfs2_move_extent 3-4-6-5 46060 NULL
+slhc_toss_46066 slhc_toss 0 46066 NULL
+mgmt_event_46069 mgmt_event 4 46069 NULL
+xfrm_sadinfo_msgsize_46073 xfrm_sadinfo_msgsize 0 46073 NULL
+sel_commit_bools_write_46077 sel_commit_bools_write 3 46077 NULL
+ata_host_alloc_46094 ata_host_alloc 2 46094 NULL
+mlx4_ib_alloc_fast_reg_page_list_46119 mlx4_ib_alloc_fast_reg_page_list 2 46119 NULL
+ddp_clear_map_46152 ddp_clear_map 4 46152 NULL
+__netlink_change_ngroups_46156 __netlink_change_ngroups 2 46156 NULL
+qlcnic_alloc_msix_entries_46160 qlcnic_alloc_msix_entries 2 46160 NULL
+vxge_os_dma_malloc_46184 vxge_os_dma_malloc 2 46184 NULL
+i2400m_op_msg_from_user_46213 i2400m_op_msg_from_user 4 46213 NULL
+dsp_write_46218 dsp_write 2 46218 NULL
+tx_abort_46232 tx_abort 0 46232 NULL
+xen_setup_msi_irqs_46245 xen_setup_msi_irqs 2 46245 NULL
+ReadReg_46277 ReadReg 0 46277 NULL
+pep_alloc_skb_46303 pep_alloc_skb 3 46303 NULL
+sg_proc_write_dressz_46316 sg_proc_write_dressz 3 46316 NULL
+__hwahc_dev_set_key_46328 __hwahc_dev_set_key 5 46328 NULL
+iwl_dbgfs_chain_noise_read_46355 iwl_dbgfs_chain_noise_read 3 46355 NULL
+smk_write_direct_46363 smk_write_direct 3 46363 NULL
+fib_nlmsg_size_46383 fib_nlmsg_size 0 46383 NULL
+fuse_file_aio_write_46399 fuse_file_aio_write 4 46399 NULL
+crypto_ablkcipher_reqsize_46411 crypto_ablkcipher_reqsize 0 46411 NULL
+ttm_page_pool_get_pages_46431 ttm_page_pool_get_pages 0-5 46431 NULL
+cp210x_set_config_46447 cp210x_set_config 4 46447 NULL
+parport_pc_fifo_write_block_46455 parport_pc_fifo_write_block 3 46455 NULL
+filldir64_46469 filldir64 3 46469 NULL
+mthca_alloc_cq_buf_46512 mthca_alloc_cq_buf 3 46512 NULL
+nl80211_send_rx_assoc_46538 nl80211_send_rx_assoc 4 46538 NULL
+mv_get_hc_count_46554 mv_get_hc_count 0 46554 NULL
+link_send_sections_long_46556 link_send_sections_long 4 46556 NULL
+dn_current_mss_46574 dn_current_mss 0 46574 NULL
+serverworks_create_gatt_pages_46582 serverworks_create_gatt_pages 1 46582 NULL
+vscnprintf_46617 vscnprintf 0-2 46617 NULL
+__kfifo_out_r_46623 __kfifo_out_r 3 46623 NULL
+request_key_async_with_auxdata_46624 request_key_async_with_auxdata 4 46624 NULL
+aircable_process_packet_46639 aircable_process_packet 5 46639 NULL
+pci_enable_device_46642 pci_enable_device 0 46642 NULL
+e1000_tx_map_46672 e1000_tx_map 4 46672 NULL
+alloc_data_packet_46698 alloc_data_packet 1 46698 NULL
+__ilog2_u32_46706 __ilog2_u32 0 46706 NULL
+erst_dbg_write_46715 erst_dbg_write 3 46715 NULL
+ctnetlink_nlmsg_size_46736 ctnetlink_nlmsg_size 0 46736 NULL
+hest_ghes_dev_register_46766 hest_ghes_dev_register 1 46766 NULL
+int_hw_irq_en_46776 int_hw_irq_en 3 46776 NULL
+_xfs_buf_get_pages_46811 _xfs_buf_get_pages 2 46811 NULL
+xfs_iroot_realloc_46826 xfs_iroot_realloc 2 46826 NULL
+ieee80211_rx_radiotap_len_46846 ieee80211_rx_radiotap_len 0 46846 NULL
+spi_async_46857 spi_async 0 46857 NULL
+vsnprintf_46863 vsnprintf 0 46863 NULL
+hpi_read_word_nolock_46881 hpi_read_word_nolock 0 46881 NULL
+sk_mem_pages_46896 sk_mem_pages 0-1 46896 NULL
+ol_dqblk_off_46904 ol_dqblk_off 2-3 46904 NULL
+tracing_ctrl_read_46922 tracing_ctrl_read 3 46922 NULL
+fb_write_46924 fb_write 3 46924 NULL
+btmrvl_curpsmode_read_46939 btmrvl_curpsmode_read 3 46939 NULL
+kvm_register_read_46948 kvm_register_read 0 46948 NULL
+__sctp_setsockopt_connectx_46949 __sctp_setsockopt_connectx 3 46949 NULL
+crypto_tfm_alg_alignmask_46971 crypto_tfm_alg_alignmask 0 46971 NULL
+ath6kl_add_bss_if_needed_46978 ath6kl_add_bss_if_needed 5 46978 NULL
+strlcat_46985 strlcat 3 46985 NULL
+gfs2_xattr_system_set_46996 gfs2_xattr_system_set 4 46996 NULL nohasharray
+sel_write_bool_46996 sel_write_bool 3 46996 &gfs2_xattr_system_set_46996
+ttm_bo_io_47000 ttm_bo_io 5 47000 NULL
+blk_rq_map_kern_47004 blk_rq_map_kern 4 47004 NULL
+ext4_xattr_list_entries_47070 ext4_xattr_list_entries 0 47070 NULL
+xfrm_report_msgsize_47077 xfrm_report_msgsize 0 47077 NULL
+scsi_deactivate_tcq_47086 scsi_deactivate_tcq 2 47086 NULL
+set_params_47113 set_params 0 47113 NULL
+mousedev_read_47123 mousedev_read 3 47123 NULL
+acpi_ut_initialize_buffer_47143 acpi_ut_initialize_buffer 2 47143 NULL nohasharray
+ses_recv_diag_47143 ses_recv_diag 4 47143 &acpi_ut_initialize_buffer_47143
+cxio_init_resource_fifo_random_47151 cxio_init_resource_fifo_random 3 47151 NULL
+rs_sta_dbgfs_rate_scale_data_read_47165 rs_sta_dbgfs_rate_scale_data_read 3 47165 NULL
+svc_pool_map_alloc_arrays_47181 svc_pool_map_alloc_arrays 2 47181 NULL
+can_set_system_xattr_47182 can_set_system_xattr 4 47182 NULL
+l2headersize_47238 l2headersize 0 47238 NULL
+options_write_47243 options_write 3 47243 NULL
+portcntrs_1_read_47253 portcntrs_1_read 3 47253 NULL
+ablkcipher_next_slow_47274 ablkcipher_next_slow 4-3 47274 NULL
+tty_audit_log_47280 tty_audit_log 8 47280 NULL
+vsnprintf_47291 vsnprintf 0 47291 NULL
+channel_type_read_47308 channel_type_read 3 47308 NULL
+ieee80211_if_read_dot11MeshHoldingTimeout_47356 ieee80211_if_read_dot11MeshHoldingTimeout 3 47356 NULL
+avc_get_hash_stats_47359 avc_get_hash_stats 0 47359 NULL
+__bio_map_kern_47379 __bio_map_kern 3 47379 NULL
+trace_options_core_read_47390 trace_options_core_read 3 47390 NULL
+pfkey_sendmsg_47394 pfkey_sendmsg 4 47394 NULL
+lbs_wrmac_write_47400 lbs_wrmac_write 3 47400 NULL
+crypto_ablkcipher_alignmask_47410 crypto_ablkcipher_alignmask 0 47410 NULL
+lbs_wrrf_write_47418 lbs_wrrf_write 3 47418 NULL
+posix_acl_from_disk_47445 posix_acl_from_disk 2 47445 NULL
+newpart_47485 newpart 6-4 47485 NULL
+core_sys_select_47494 core_sys_select 1 47494 NULL
+alloc_arraycache_47505 alloc_arraycache 2 47505 NULL
+unlink_simple_47506 unlink_simple 3 47506 NULL
+process_vm_rw_47533 process_vm_rw 3-5 47533 NULL nohasharray
+vscnprintf_47533 vscnprintf 0-2 47533 &process_vm_rw_47533
+einj_check_trigger_header_47534 einj_check_trigger_header 0 47534 NULL
+ieee80211_if_fmt_min_discovery_timeout_47539 ieee80211_if_fmt_min_discovery_timeout 3 47539 NULL
+set_printer_interface_47551 set_printer_interface 0 47551 NULL
+read_ldt_47570 read_ldt 2 47570 NULL
+ext4_kvzalloc_47605 ext4_kvzalloc 1 47605 NULL
+sctp_ssnmap_new_47608 sctp_ssnmap_new 2-1 47608 NULL
+uea_request_47613 uea_request 4 47613 NULL
+cache_read_pipefs_47615 cache_read_pipefs 3 47615 NULL
+kvm_pv_mmu_write_47630 kvm_pv_mmu_write 2 47630 NULL
+__build_packet_message_47643 __build_packet_message 3-9 47643 NULL
+packet_recvmsg_47700 packet_recvmsg 4 47700 NULL
+bits_to_user_47733 bits_to_user 2-3 47733 NULL
+carl9170_debugfs_read_47738 carl9170_debugfs_read 3 47738 NULL
+ir_prepare_write_buffer_47747 ir_prepare_write_buffer 3 47747 NULL
+mvumi_alloc_mem_resource_47750 mvumi_alloc_mem_resource 3 47750 NULL
+alloc_sched_domains_47756 alloc_sched_domains 1 47756 NULL
+i915_wedged_write_47771 i915_wedged_write 3 47771 NULL
+uwb_ie_dump_hex_47774 uwb_ie_dump_hex 4 47774 NULL
+tt_len_47789 tt_len 0-1 47789 NULL
+stmmac_set_bfsize_47834 stmmac_set_bfsize 0 47834 NULL
+ath6kl_wmi_set_appie_cmd_47855 ath6kl_wmi_set_appie_cmd 4 47855 NULL
+vhci_read_47878 vhci_read 3 47878 NULL
+keyctl_instantiate_key_common_47889 keyctl_instantiate_key_common 4 47889 NULL
+osd_req_read_sg_47905 osd_req_read_sg 5 47905 NULL
+nf_nat_ftp_47948 nf_nat_ftp 5 47948 NULL
+cfg80211_testmode_alloc_reply_skb_47966 cfg80211_testmode_alloc_reply_skb 2 47966 NULL
+mempool_resize_47983 mempool_resize 2 47983 NULL nohasharray
+iwl_dbgfs_ucode_tracing_read_47983 iwl_dbgfs_ucode_tracing_read 3 47983 &mempool_resize_47983
+mgmt_pending_add_47990 mgmt_pending_add 5 47990 NULL nohasharray
+dbg_port_buf_47990 dbg_port_buf 2 47990 &mgmt_pending_add_47990
+ib_umad_write_47993 ib_umad_write 3 47993 NULL
+ffs_epfile_write_48014 ffs_epfile_write 3 48014 NULL
+bio_integrity_set_tag_48035 bio_integrity_set_tag 3 48035 NULL
+pppoe_sendmsg_48039 pppoe_sendmsg 4 48039 NULL
+wpan_phy_alloc_48056 wpan_phy_alloc 1 48056 NULL
+posix_acl_alloc_48063 posix_acl_alloc 1 48063 NULL
+c4iw_init_resource_fifo_48090 c4iw_init_resource_fifo 3 48090 NULL
+mmc_alloc_host_48097 mmc_alloc_host 1 48097 NULL
+skb_copy_datagram_const_iovec_48102 skb_copy_datagram_const_iovec 4-2-5 48102 NULL
+vmw_framebuffer_surface_dirty_48132 vmw_framebuffer_surface_dirty 6 48132 NULL
+dn_fib_count_nhs_48145 dn_fib_count_nhs 0 48145 NULL
+__tcp_push_pending_frames_48148 __tcp_push_pending_frames 2 48148 NULL
+init_ipath_48187 init_ipath 1 48187 NULL
+snd_seq_dump_var_event_48209 snd_seq_dump_var_event 0 48209 NULL
+uv_blade_nr_possible_cpus_48226 uv_blade_nr_possible_cpus 0 48226 NULL
+read_file_recv_48232 read_file_recv 3 48232 NULL
+blk_rq_pos_48233 blk_rq_pos 0 48233 NULL
+nfsctl_transaction_read_48250 nfsctl_transaction_read 3 48250 NULL
+cache_write_pipefs_48270 cache_write_pipefs 3 48270 NULL
+trace_options_write_48275 trace_options_write 3 48275 NULL
+pkt_bio_alloc_48284 pkt_bio_alloc 1 48284 NULL
+lpfc_idiag_extacc_read_48301 lpfc_idiag_extacc_read 3 48301 NULL
+hash_setkey_48310 hash_setkey 3 48310 NULL
+skb_add_data_48363 skb_add_data 3 48363 NULL
+eexp_start_irq_48364 eexp_start_irq 2 48364 NULL
+iscsi_complete_pdu_48372 iscsi_complete_pdu 4 48372 NULL
+lbs_debugfs_write_48413 lbs_debugfs_write 3 48413 NULL
+nfs4_alloc_pages_48426 nfs4_alloc_pages 1 48426 NULL
+wm8994_write_48439 wm8994_write 3 48439 NULL
+tun_recvmsg_48463 tun_recvmsg 4 48463 NULL
+mlx4_en_create_tx_ring_48501 mlx4_en_create_tx_ring 4 48501 NULL
+diva_os_copy_to_user_48508 diva_os_copy_to_user 4 48508 NULL
+phantom_get_free_48514 phantom_get_free 0 48514 NULL
+ubi_dbg_check_write_48525 ubi_dbg_check_write 0 48525 NULL
+drbd_bm_capacity_48530 drbd_bm_capacity 0 48530 NULL
+do_ip_vs_set_ctl_48641 do_ip_vs_set_ctl 4 48641 NULL
+lc_create_48662 lc_create 3 48662 NULL
+sm501_create_subdev_48668 sm501_create_subdev 3-4 48668 NULL nohasharray
+sys_setgroups_48668 sys_setgroups 1 48668 &sm501_create_subdev_48668
+hysdn_log_write_48694 hysdn_log_write 3 48694 NULL
+altera_drscan_48698 altera_drscan 2 48698 NULL
+kvm_set_irq_routing_48704 kvm_set_irq_routing 3 48704 NULL
+recv_msg_48709 recv_msg 4 48709 NULL
+lpfc_idiag_drbacc_write_48712 lpfc_idiag_drbacc_write 3 48712 NULL
+disconnect_48738 disconnect 4 48738 NULL
+ath6kl_regwrite_read_48747 ath6kl_regwrite_read 3 48747 NULL
+icmp_manip_pkt_48801 icmp_manip_pkt 2 48801 NULL
+twa_change_queue_depth_48808 twa_change_queue_depth 2 48808 NULL
+tcp_push_one_48816 tcp_push_one 2 48816 NULL
+atomic_counters_read_48827 atomic_counters_read 3 48827 NULL
+azx_get_position_48841 azx_get_position 0 48841 NULL
+vc_do_resize_48842 vc_do_resize 3-4 48842 NULL
+__ffs_ep0_read_events_48868 __ffs_ep0_read_events 3 48868 NULL
+sys_setgroups16_48882 sys_setgroups16 1 48882 NULL
+get_num_ops_48886 get_num_ops 0 48886 NULL
+crypto_cipher_ctxsize_48890 crypto_cipher_ctxsize 0 48890 NULL
+joydev_handle_JSIOCSAXMAP_48898 joydev_handle_JSIOCSAXMAP 3 48898 NULL nohasharray
+mac_drv_rx_init_48898 mac_drv_rx_init 2 48898 &joydev_handle_JSIOCSAXMAP_48898
+xdi_copy_to_user_48900 xdi_copy_to_user 4 48900 NULL
+msg_hdr_sz_48908 msg_hdr_sz 0 48908 NULL
+lpfc_sli4_get_els_iocb_cnt_48926 lpfc_sli4_get_els_iocb_cnt 0 48926 NULL
+_alloc_set_attr_list_48991 _alloc_set_attr_list 4 48991 NULL
+rds_rm_size_48996 rds_rm_size 0-2 48996 NULL
+sel_write_enforce_48998 sel_write_enforce 3 48998 NULL
+transient_status_49027 transient_status 4 49027 NULL
+mirror_status_49073 mirror_status 4 49073 NULL
+vmx_set_msr_49090 vmx_set_msr 3 49090 NULL
+scsi_register_49094 scsi_register 2 49094 NULL
+compat_do_readv_writev_49102 compat_do_readv_writev 4 49102 NULL
+receive_client_update_packet_49104 receive_client_update_packet 3 49104 NULL
+xfrm_replay_state_esn_len_49119 xfrm_replay_state_esn_len 0 49119 NULL
+pt_read_49136 pt_read 3 49136 NULL
+tipc_multicast_49144 tipc_multicast 5 49144 NULL
+ipwireless_tty_received_49154 ipwireless_tty_received 3 49154 NULL
+ipw_queue_tx_init_49161 ipw_queue_tx_init 3 49161 NULL
+__jfs_setxattr_49175 __jfs_setxattr 5 49175 NULL
+root_nfs_cat_49192 root_nfs_cat 3 49192 NULL
+iwl_dbgfs_ucode_general_stats_read_49199 iwl_dbgfs_ucode_general_stats_read 3 49199 NULL
+do_jffs2_getxattr_49210 do_jffs2_getxattr 0 49210 NULL
+osd_req_add_get_attr_list_49278 osd_req_add_get_attr_list 3 49278 NULL
+__ext4_ext_dirty_49284 __ext4_ext_dirty 0 49284 NULL
+uio_read_49300 uio_read 3 49300 NULL
+cfpkt_setlen_49343 cfpkt_setlen 2 49343 NULL
+joydev_ioctl_common_49359 joydev_ioctl_common 2 49359 NULL
+ocfs2_remove_btree_range_49370 ocfs2_remove_btree_range 4-3-5 49370 NULL
+px_raw_event_49371 px_raw_event 4 49371 NULL
+iscsi_alloc_session_49390 iscsi_alloc_session 3 49390 NULL
+applesmc_create_nodes_49392 applesmc_create_nodes 2 49392 NULL
+tnode_alloc_49407 tnode_alloc 1 49407 NULL
+samples_to_bytes_49426 samples_to_bytes 0-2 49426 NULL
+i915_gem_object_set_to_gtt_domain_49450 i915_gem_object_set_to_gtt_domain 0 49450 NULL
+agp_3_5_isochronous_node_enable_49465 agp_3_5_isochronous_node_enable 3 49465 NULL
+xfs_iformat_local_49472 xfs_iformat_local 4 49472 NULL
+dn_nsp_do_disc_49474 dn_nsp_do_disc 6-2 49474 NULL
+esp4_get_mtu_49483 esp4_get_mtu 0-2 49483 NULL
+__sock_recvmsg_nosec_49520 __sock_recvmsg_nosec 0 49520 NULL nohasharray
+emulator_write_phys_49520 emulator_write_phys 2-4 49520 &__sock_recvmsg_nosec_49520
+smk_write_access_49561 smk_write_access 3 49561 NULL
+alloc_chunk_49575 alloc_chunk 1 49575 NULL
+sctp_setsockopt_default_send_param_49578 sctp_setsockopt_default_send_param 3 49578 NULL
+readfifo_49583 readfifo 1 49583 NULL
+heap_init_49617 heap_init 2 49617 NULL
+smk_write_doi_49621 smk_write_doi 3 49621 NULL
+port_fops_read_49626 port_fops_read 3 49626 NULL
+svm_set_msr_49643 svm_set_msr 3 49643 NULL
+aa_simple_write_to_buffer_49683 aa_simple_write_to_buffer 3-4 49683 NULL
+sys_gethostname_49698 sys_gethostname 2 49698 NULL
+write_pool_49718 write_pool 3 49718 NULL
+sys_fsetxattr_49736 sys_fsetxattr 4 49736 NULL
+check_frame_49741 check_frame 0 49741 NULL
+zd_usb_iowrite16v_49744 zd_usb_iowrite16v 3 49744 NULL
+btrfs_chunk_num_stripes_49751 btrfs_chunk_num_stripes 0 49751 NULL
+nci_skb_alloc_49757 nci_skb_alloc 2 49757 NULL
+key_conf_keylen_read_49758 key_conf_keylen_read 3 49758 NULL
+fuse_conn_waiting_read_49762 fuse_conn_waiting_read 3 49762 NULL
+w83977af_fir_interrupt_49775 w83977af_fir_interrupt 0 49775 NULL
+ceph_osdc_readpages_49789 ceph_osdc_readpages 10-4-0 49789 NULL
+nfs4_acl_new_49806 nfs4_acl_new 1 49806 NULL
+ntfs_copy_from_user_iovec_49829 ntfs_copy_from_user_iovec 3-6-0 49829 NULL
+iraw_loop_49842 iraw_loop 0-1 49842 NULL
+vmw_execbuf_process_49845 vmw_execbuf_process 5 49845 NULL
+scsi_dispatch_cmd_entry_49848 scsi_dispatch_cmd_entry 3 49848 NULL
+timeradd_entry_49850 timeradd_entry 3 49850 NULL
+ubifs_destroy_tnc_subtree_49853 ubifs_destroy_tnc_subtree 0 49853 NULL
+sctp_setsockopt_bindx_49870 sctp_setsockopt_bindx 3 49870 NULL
+ceph_get_caps_49890 ceph_get_caps 0 49890 NULL
+config_ep_by_speed_49939 config_ep_by_speed 0 49939 NULL
+b43legacy_pio_read_49978 b43legacy_pio_read 0 49978 NULL
+ieee80211_if_fmt_dtim_count_49987 ieee80211_if_fmt_dtim_count 3 49987 NULL
+drm_buffer_copy_from_user_49990 drm_buffer_copy_from_user 3 49990 NULL
+dn_mss_from_pmtu_50011 dn_mss_from_pmtu 0-2 50011 NULL
+isdn_read_50021 isdn_read 3 50021 NULL
+rbd_req_write_50041 rbd_req_write 4-5 50041 NULL
+alloc_ebda_hpc_50046 alloc_ebda_hpc 1-2 50046 NULL
+fuse_conn_max_background_write_50061 fuse_conn_max_background_write 3 50061 NULL
+__kfifo_dma_in_prepare_50081 __kfifo_dma_in_prepare 4 50081 NULL
+dev_set_alias_50084 dev_set_alias 3 50084 NULL
+pcpu_get_vm_areas_50085 pcpu_get_vm_areas 3 50085 NULL
+sock_setsockopt_50088 sock_setsockopt 5 50088 NULL
+altera_swap_dr_50090 altera_swap_dr 2 50090 NULL
+read_file_slot_50111 read_file_slot 3 50111 NULL
+pn544_fw_read_50112 pn544_fw_read 0 50112 NULL
+copy_items_50140 copy_items 6 50140 NULL
+kmalloc_node_50163 kmalloc_node 1 50163 NULL
+ahd_probe_stack_size_50168 ahd_probe_stack_size 0 50168 NULL
+ubi_resize_volume_50172 ubi_resize_volume 2 50172 NULL nohasharray
+ieee80211_if_fmt_dot11MeshHWMPRannInterval_50172 ieee80211_if_fmt_dot11MeshHWMPRannInterval 3 50172 &ubi_resize_volume_50172
+ib_send_cm_drep_50186 ib_send_cm_drep 3 50186 NULL
+ieee80211_skb_resize_50211 ieee80211_skb_resize 3 50211 NULL
+mon_bin_compat_ioctl_50234 mon_bin_compat_ioctl 3 50234 NULL
+sg_kmalloc_50240 sg_kmalloc 1 50240 NULL
+afs_extract_data_50261 afs_extract_data 5 50261 NULL
+rxrpc_setsockopt_50286 rxrpc_setsockopt 5 50286 NULL
+soc_codec_reg_show_50302 soc_codec_reg_show 0-3 50302 NULL
+iterate_irefs_50313 iterate_irefs 0 50313 NULL
+cifs_readdata_alloc_50318 cifs_readdata_alloc 1 50318 NULL
+do_launder_page_50329 do_launder_page 0 50329 NULL
+lpfc_idiag_pcicfg_read_50334 lpfc_idiag_pcicfg_read 3 50334 NULL
+ocfs2_block_to_cluster_group_50337 ocfs2_block_to_cluster_group 2 50337 NULL nohasharray
+snd_pcm_lib_writev_50337 snd_pcm_lib_writev 3-0 50337 &ocfs2_block_to_cluster_group_50337
+tpm_read_50344 tpm_read 3 50344 NULL
+isdn_ppp_read_50356 isdn_ppp_read 4 50356 NULL
+unpack_u16_chunk_50357 unpack_u16_chunk 0 50357 NULL
+iwl_dbgfs_echo_test_write_50362 iwl_dbgfs_echo_test_write 3 50362 NULL
+xfrm_send_migrate_50365 xfrm_send_migrate 5 50365 NULL
+sl_alloc_bufs_50380 sl_alloc_bufs 2 50380 NULL
+inet_nlmsg_size_50399 inet_nlmsg_size 0 50399 NULL
+l2tp_ip_sendmsg_50411 l2tp_ip_sendmsg 4 50411 NULL
+iscsi_create_conn_50425 iscsi_create_conn 2 50425 NULL
+pgctrl_write_50453 pgctrl_write 3 50453 NULL
+device_create_sys_dev_entry_50458 device_create_sys_dev_entry 0 50458 NULL
+cdrom_read_cdda_50478 cdrom_read_cdda 4 50478 NULL
+fwnet_receive_packet_50537 fwnet_receive_packet 9 50537 NULL
+ath6kl_set_ap_probe_resp_ies_50539 ath6kl_set_ap_probe_resp_ies 3 50539 NULL
+usbat_flash_write_data_50553 usbat_flash_write_data 4 50553 NULL
+hme_read_desc32_50574 hme_read_desc32 0 50574 NULL
+pep_reply_50582 pep_reply 5 50582 NULL
+iwl_dbgfs_missed_beacon_read_50584 iwl_dbgfs_missed_beacon_read 3 50584 NULL
+sge_rx_50594 sge_rx 3 50594 NULL
+GET_WORD_50624 GET_WORD 0 50624 NULL
+macvtap_alloc_skb_50629 macvtap_alloc_skb 2-4-3 50629 NULL
+simple_transaction_get_50633 simple_transaction_get 3 50633 NULL
+ocfs2_readlink_50656 ocfs2_readlink 3 50656 NULL
+sys_readv_50664 sys_readv 3 50664 NULL
+btmrvl_psstate_read_50683 btmrvl_psstate_read 3 50683 NULL
+prism2_read_fid_reg_50689 prism2_read_fid_reg 0 50689 NULL
+__ext3_get_inode_loc_50744 __ext3_get_inode_loc 0 50744 NULL
+skb_padto_50759 skb_padto 2 50759 NULL
+udp_manip_pkt_50770 udp_manip_pkt 2 50770 NULL
+ocfs2_xattr_block_get_50773 ocfs2_xattr_block_get 0 50773 NULL
+pipe_handler_request_50774 pipe_handler_request 5 50774 NULL
+bio_alloc_map_data_50782 bio_alloc_map_data 1-2 50782 NULL
+tpm_write_50798 tpm_write 3 50798 NULL
+tun_do_read_50800 tun_do_read 4 50800 NULL
+write_flush_50803 write_flush 3 50803 NULL
+pstore_mkfile_50830 pstore_mkfile 5 50830 NULL
+carl9170_debugfs_write_50857 carl9170_debugfs_write 3 50857 NULL
+netlbl_secattr_catmap_walk_rng_50894 netlbl_secattr_catmap_walk_rng 0-2 50894 NULL
+osd_req_write_sg_50908 osd_req_write_sg 5 50908 NULL
+xfs_iext_remove_50909 xfs_iext_remove 3 50909 NULL
+blk_rq_cur_sectors_50910 blk_rq_cur_sectors 0 50910 NULL
+hash_recvmsg_50924 hash_recvmsg 4 50924 NULL
+sock_bindtodevice_50942 sock_bindtodevice 3 50942 NULL
+mld_newpack_50950 mld_newpack 2 50950 NULL
+ocfs2_add_refcount_flag_50952 ocfs2_add_refcount_flag 6 50952 NULL
+sdio_uart_write_50954 sdio_uart_write 3 50954 NULL
+iwl_statistics_flag_50981 iwl_statistics_flag 3-0 50981 NULL
+timeout_write_50991 timeout_write 3 50991 NULL
+proc_write_51003 proc_write 3 51003 NULL
+jbd2_journal_extend_51012 jbd2_journal_extend 0 51012 NULL
+lbs_dev_info_51023 lbs_dev_info 3 51023 NULL
+fuse_conn_congestion_threshold_read_51028 fuse_conn_congestion_threshold_read 3 51028 NULL
+dump_midi_51040 dump_midi 3 51040 NULL
+usb_get_descriptor_51041 usb_get_descriptor 0 51041 NULL
+do_arpt_set_ctl_51053 do_arpt_set_ctl 4 51053 NULL
+wusb_prf_64_51065 wusb_prf_64 7 51065 NULL
+jbd2_journal_init_revoke_51088 jbd2_journal_init_revoke 2 51088 NULL
+__ocfs2_find_path_51096 __ocfs2_find_path 0 51096 NULL
+read_file_wiphy_51103 read_file_wiphy 3 51103 NULL
+iscsi_nop_out_rsp_51117 iscsi_nop_out_rsp 4 51117 NULL
+xfs_trans_get_efd_51148 xfs_trans_get_efd 3 51148 NULL
+snd_pcm_write_51235 snd_pcm_write 3 51235 NULL
+tipc_send_51238 tipc_send 4 51238 NULL
+drm_property_create_51239 drm_property_create 4 51239 NULL
+st_read_51251 st_read 3 51251 NULL
+compat_dccp_setsockopt_51263 compat_dccp_setsockopt 5 51263 NULL
+ipwireless_network_packet_received_51277 ipwireless_network_packet_received 4 51277 NULL
+xfrm_count_enc_supported_51290 xfrm_count_enc_supported 0 51290 NULL
+alloc_hippi_dev_51320 alloc_hippi_dev 1 51320 NULL
+ext2_xattr_get_51327 ext2_xattr_get 0 51327 NULL
+alloc_smp_req_51337 alloc_smp_req 1 51337 NULL
+ipw_get_event_log_len_51341 ipw_get_event_log_len 0 51341 NULL
+ieee80211_if_fmt_estab_plinks_51370 ieee80211_if_fmt_estab_plinks 3 51370 NULL
+ceph_sync_read_51410 ceph_sync_read 3-0 51410 NULL
+blk_register_region_51424 blk_register_region 1-2 51424 NULL
+mwifiex_rdeeprom_read_51429 mwifiex_rdeeprom_read 3 51429 NULL
+ieee80211_if_read_dot11MeshHWMPRootMode_51441 ieee80211_if_read_dot11MeshHWMPRootMode 3 51441 NULL
+print_devstats_dot11ACKFailureCount_51443 print_devstats_dot11ACKFailureCount 3 51443 NULL
+____alloc_ei_netdev_51475 ____alloc_ei_netdev 1 51475 NULL
+xfs_buf_get_uncached_51477 xfs_buf_get_uncached 2 51477 NULL
+kvm_fetch_guest_virt_51493 kvm_fetch_guest_virt 4-2 51493 NULL
+__alloc_eip_netdev_51549 __alloc_eip_netdev 1 51549 NULL
+ixgb_get_eeprom_len_51586 ixgb_get_eeprom_len 0 51586 NULL
+table_size_to_number_of_entries_51613 table_size_to_number_of_entries 0-1 51613 NULL
+dns_resolve_server_name_to_ip_51632 dns_resolve_server_name_to_ip 0 51632 NULL
+sctp_auth_create_key_51641 sctp_auth_create_key 1 51641 NULL
+iscsi_create_session_51647 iscsi_create_session 3 51647 NULL
+get_new_cssid_51665 get_new_cssid 2 51665 NULL
+sctp_setsockopt_associnfo_51684 sctp_setsockopt_associnfo 3 51684 NULL
+sel_write_access_51704 sel_write_access 3 51704 NULL
+gem_alloc_skb_51715 gem_alloc_skb 2 51715 NULL
+drm_compat_ioctl_51717 drm_compat_ioctl 2 51717 NULL
+sg_read_oxfer_51724 sg_read_oxfer 3 51724 NULL
+cm4040_read_51732 cm4040_read 3 51732 NULL
+hid_parse_report_51737 hid_parse_report 3 51737 NULL
+get_user_pages_fast_51751 get_user_pages_fast 0 51751 NULL
+ifx_spi_insert_flip_string_51752 ifx_spi_insert_flip_string 3 51752 NULL
+if_write_51756 if_write 3 51756 NULL
+swiotlb_init_with_tbl_51770 swiotlb_init_with_tbl 2 51770 NULL
+qib_alloc_devdata_51819 qib_alloc_devdata 2 51819 NULL
+ioread32_51847 ioread32 0 51847 NULL nohasharray
+read_file_tgt_tx_stats_51847 read_file_tgt_tx_stats 3 51847 &ioread32_51847
+do_readv_writev_51849 do_readv_writev 4 51849 NULL
+pointer_size_read_51863 pointer_size_read 3 51863 NULL
+get_indirect_ea_51869 get_indirect_ea 4 51869 NULL
+user_read_51881 user_read 3 51881 NULL
+dbAdjCtl_51888 dbAdjCtl 0 51888 NULL
+dbg_status_buf_51930 dbg_status_buf 2 51930 NULL
+xfrm_alg_len_51940 xfrm_alg_len 0 51940 NULL
+scsi_get_vpd_page_51951 scsi_get_vpd_page 4 51951 NULL
+snd_mask_min_51969 snd_mask_min 0 51969 NULL
+__blkdev_get_51972 __blkdev_get 0 51972 NULL
+ath6kl_sdio_alloc_prep_scat_req_51986 ath6kl_sdio_alloc_prep_scat_req 2 51986 NULL
+skb_copy_datagram_from_iovec_52014 skb_copy_datagram_from_iovec 4-2-5 52014 NULL
+vxge_rx_alloc_52024 vxge_rx_alloc 3 52024 NULL
+override_release_52032 override_release 2 52032 NULL
+end_port_52042 end_port 0 52042 NULL
+msnd_fifo_write_52052 msnd_fifo_write 0-3 52052 NULL
+nsm_get_handle_52089 nsm_get_handle 4 52089 NULL
+o2net_debug_read_52105 o2net_debug_read 3 52105 NULL
+hysdn_conf_write_52145 hysdn_conf_write 3 52145 NULL
+wait_gpio_52146 wait_gpio 0 52146 NULL
+__le16_to_cpup_52155 __le16_to_cpup 0 52155 NULL
+ieee80211_if_read_dot11MeshRetryTimeout_52168 ieee80211_if_read_dot11MeshRetryTimeout 3 52168 NULL
+proc_pid_readlink_52186 proc_pid_readlink 3 52186 NULL
+iscsi_if_send_reply_52219 iscsi_if_send_reply 7 52219 NULL nohasharray
+iwl_dbgfs_wd_timeout_write_52219 iwl_dbgfs_wd_timeout_write 3 52219 &iscsi_if_send_reply_52219
+_alloc_mISDN_skb_52232 _alloc_mISDN_skb 3 52232 NULL
+sisusbcon_do_font_op_52271 sisusbcon_do_font_op 9 52271 NULL
+smk_write_load_list_52280 smk_write_load_list 3 52280 NULL
+ath6kl_wmi_get_new_buf_52304 ath6kl_wmi_get_new_buf 1 52304 NULL
+kobject_set_name_vargs_52309 kobject_set_name_vargs 0 52309 NULL
+hwflags_read_52318 hwflags_read 3 52318 NULL
+test_unaligned_bulk_52333 test_unaligned_bulk 3 52333 NULL
+bytes_to_frames_52362 bytes_to_frames 0-2 52362 NULL
+copy_entries_to_user_52367 copy_entries_to_user 1 52367 NULL
+iwl_dump_fh_52371 iwl_dump_fh 0 52371 NULL
+pfkey_sockaddr_pair_size_52378 pfkey_sockaddr_pair_size 0 52378 NULL
+isdn_writebuf_stub_52383 isdn_writebuf_stub 4 52383 NULL
+jfs_setxattr_52389 jfs_setxattr 4 52389 NULL
+aer_inject_write_52399 aer_inject_write 3 52399 NULL
+cgroup_file_write_52417 cgroup_file_write 3 52417 NULL
+hso_serial_common_create_52428 hso_serial_common_create 4 52428 NULL
+ieee80211_if_fmt_num_sta_ps_52438 ieee80211_if_fmt_num_sta_ps 3 52438 NULL
+nl80211_send_mgmt_tx_status_52445 nl80211_send_mgmt_tx_status 5 52445 NULL
+alauda_read_data_52452 alauda_read_data 3 52452 NULL
+ip6_skb_dst_mtu_52457 ip6_skb_dst_mtu 0 52457 NULL
+ocfs2_extend_no_holes_52483 ocfs2_extend_no_holes 3-4 52483 NULL
+skb_cow_head_52495 skb_cow_head 2 52495 NULL
+int_tasklet_entry_52500 int_tasklet_entry 3 52500 NULL
+netlbl_unlabel_init_52506 netlbl_unlabel_init 1 52506 NULL
+pm_qos_power_write_52513 pm_qos_power_write 3 52513 NULL
+bt_sock_stream_recvmsg_52518 bt_sock_stream_recvmsg 4 52518 NULL
+dup_variable_bug_52525 dup_variable_bug 3 52525 NULL
+raw_recvmsg_52529 raw_recvmsg 4 52529 NULL
+dccpprobe_read_52549 dccpprobe_read 3 52549 NULL
+ocfs2_make_right_split_rec_52562 ocfs2_make_right_split_rec 3 52562 NULL
+debug_level_proc_write_52572 debug_level_proc_write 3 52572 NULL
+xfs_file_buffered_aio_write_52609 xfs_file_buffered_aio_write 4 52609 NULL
+__iter_shared_inline_ref_inodes_52668 __iter_shared_inline_ref_inodes 0 52668 NULL
+blkcipher_next_slow_52733 blkcipher_next_slow 3-4 52733 NULL
+relay_alloc_page_array_52735 relay_alloc_page_array 1 52735 NULL
+carl9170_debugfs_vif_dump_read_52755 carl9170_debugfs_vif_dump_read 3 52755 NULL
+debug_lpm_write_52830 debug_lpm_write 3 52830 NULL
+bl_mark_sectors_init_52831 bl_mark_sectors_init 3-2 52831 NULL
+ext2_xattr_set_acl_52857 ext2_xattr_set_acl 4 52857 NULL
+mon_bin_get_event_52863 mon_bin_get_event 4-6 52863 NULL
+cache_read_procfs_52882 cache_read_procfs 3 52882 NULL
+__kfifo_out_peek_r_52919 __kfifo_out_peek_r 3 52919 NULL
+ip_nat_sdp_port_52938 ip_nat_sdp_port 6 52938 NULL
+__nodes_remap_52951 __nodes_remap 5 52951 NULL
+send_packet_52960 send_packet 4 52960 NULL
+ieee80211_if_fmt_fwded_mcast_52961 ieee80211_if_fmt_fwded_mcast 3 52961 NULL
+num_node_state_52989 num_node_state 0 52989 NULL
+bio_cur_bytes_53037 bio_cur_bytes 0 53037 NULL
+cfi_read_query_53066 cfi_read_query 0 53066 NULL
+iwl_dbgfs_interrupt_write_53069 iwl_dbgfs_interrupt_write 3 53069 NULL
+mwifiex_debug_read_53074 mwifiex_debug_read 3 53074 NULL
+pcbit_readw_53084 pcbit_readw 0 53084 NULL
+clear_capture_buf_53192 clear_capture_buf 2 53192 NULL
+__pci_enable_device_flags_53213 __pci_enable_device_flags 0 53213 NULL
+sctp_make_fwdtsn_53265 sctp_make_fwdtsn 3 53265 NULL
+btrfs_file_extent_num_bytes_53269 btrfs_file_extent_num_bytes 0 53269 NULL
+pn544_i2c_read_53270 pn544_i2c_read 0 53270 NULL
+lirc_buffer_init_53282 lirc_buffer_init 3-2 53282 NULL
+ftrace_profile_write_53327 ftrace_profile_write 3 53327 NULL
+gsm_control_reply_53333 gsm_control_reply 4 53333 NULL
+bnx2i_send_nl_mesg_53353 bnx2i_send_nl_mesg 4 53353 NULL
+get_random_bytes_arch_53370 get_random_bytes_arch 2 53370 NULL
+roccat_common_receive_53407 roccat_common_receive 4 53407 NULL
+i915_gem_execbuffer_relocate_object_53435 i915_gem_execbuffer_relocate_object 0 53435 NULL
+mwifiex_info_read_53447 mwifiex_info_read 3 53447 NULL nohasharray
+snd_dma_alloc_pages_53447 snd_dma_alloc_pages 3 53447 &mwifiex_info_read_53447
+apei_exec_run_optional_53452 apei_exec_run_optional 0 53452 NULL
+rds_tcp_data_recv_53476 rds_tcp_data_recv 3-4 53476 NULL
+iowarrior_read_53483 iowarrior_read 3 53483 NULL
+osd_req_write_kern_53486 osd_req_write_kern 5 53486 NULL
+do_verify_xattr_datum_53499 do_verify_xattr_datum 0 53499 NULL
+snd_pcm_format_physical_width_53505 snd_pcm_format_physical_width 0 53505 NULL
+dbAllocNext_53506 dbAllocNext 0 53506 NULL
+ocfs2_xattr_set_acl_53508 ocfs2_xattr_set_acl 4 53508 NULL
+check_acl_53512 check_acl 0 53512 NULL
+set_registers_53582 set_registers 3 53582 NULL
+pfkey_recvmsg_53604 pfkey_recvmsg 4 53604 NULL
+___alloc_bootmem_nopanic_53626 ___alloc_bootmem_nopanic 1 53626 NULL
+ccid_getsockopt_builtin_ccids_53634 ccid_getsockopt_builtin_ccids 2 53634 NULL
+uapsd_max_sp_len_read_53651 uapsd_max_sp_len_read 3 53651 NULL
+nr_sendmsg_53656 nr_sendmsg 4 53656 NULL
+orig_hash_add_if_53676 orig_hash_add_if 2 53676 NULL nohasharray
+_preload_range_53676 _preload_range 3-2 53676 &orig_hash_add_if_53676
+fuse_fill_write_pages_53682 fuse_fill_write_pages 4 53682 NULL
+bdev_logical_block_size_53690 bdev_logical_block_size 0 53690 NULL
+i830_write_fence_reg_53695 i830_write_fence_reg 0 53695 NULL
+phy_read_1bit_53708 phy_read_1bit 0 53708 NULL
+find_overflow_devnum_53711 find_overflow_devnum 0 53711 NULL
+bio_integrity_split_53714 bio_integrity_split 3 53714 NULL
+wdm_write_53735 wdm_write 3 53735 NULL
+amdtp_out_stream_get_max_payload_53755 amdtp_out_stream_get_max_payload 0 53755 NULL nohasharray
+lpfc_idiag_queacc_read_qe_53755 lpfc_idiag_queacc_read_qe 0-2 53755 &amdtp_out_stream_get_max_payload_53755
+ext2_acl_count_53773 ext2_acl_count 0-1 53773 NULL
+__kfifo_dma_in_prepare_r_53792 __kfifo_dma_in_prepare_r 4-5 53792 NULL
+regmap_raw_write_53803 regmap_raw_write 4 53803 NULL
+lpfc_idiag_ctlacc_read_reg_53809 lpfc_idiag_ctlacc_read_reg 0-3 53809 NULL
+nls_nullsize_53815 nls_nullsize 0 53815 NULL
+setup_data_read_53822 setup_data_read 3 53822 NULL
+multipath_status_53836 multipath_status 4 53836 NULL
+i915_gem_flush_ring_53843 i915_gem_flush_ring 0 53843 NULL
+ieee80211_if_fmt_dropped_frames_congestion_53883 ieee80211_if_fmt_dropped_frames_congestion 3 53883 NULL
+ocfs2_rm_xattr_cluster_53900 ocfs2_rm_xattr_cluster 4-5-3 53900 NULL
+proc_file_read_53905 proc_file_read 3 53905 NULL
+tcp_mss_split_point_53925 tcp_mss_split_point 0-3-4 53925 NULL
+usb_serial_generic_write_53927 usb_serial_generic_write 4 53927 NULL
+ocfs2_make_clusters_writable_53938 ocfs2_make_clusters_writable 5-4 53938 NULL
+mlx4_num_eq_uar_53965 mlx4_num_eq_uar 0 53965 NULL
+idetape_chrdev_write_53976 idetape_chrdev_write 3 53976 NULL
+__ocfs2_xattr_set_value_outside_53981 __ocfs2_xattr_set_value_outside 5 53981 NULL
+snd_pcm_lib_write_transfer_54018 snd_pcm_lib_write_transfer 5-2-4 54018 NULL
+ipxrtr_route_packet_54036 ipxrtr_route_packet 4 54036 NULL
+nl80211_send_disconnected_54056 nl80211_send_disconnected 5 54056 NULL
+bitmap_bitremap_54096 bitmap_bitremap 4 54096 NULL
+altera_set_ir_pre_54103 altera_set_ir_pre 2 54103 NULL
+create_xattr_54106 create_xattr 5 54106 NULL
+strn_len_54122 strn_len 0 54122 NULL
+i2400m_zrealloc_2x_54166 i2400m_zrealloc_2x 3 54166 NULL nohasharray
+memcpy_toiovec_54166 memcpy_toiovec 3 54166 &i2400m_zrealloc_2x_54166
+p9_client_prepare_req_54175 p9_client_prepare_req 3 54175 NULL
+do_sys_poll_54221 do_sys_poll 2 54221 NULL
+__register_chrdev_54223 __register_chrdev 2-3 54223 NULL
+_format_mac_addr_54229 _format_mac_addr 2-0 54229 NULL
+pi_read_regr_54231 pi_read_regr 0 54231 NULL
+jbd2__journal_restart_54249 jbd2__journal_restart 0 54249 NULL
+xfs_dir2_sf_addname_hard_54254 xfs_dir2_sf_addname_hard 3 54254 NULL
+ceph_msgpool_get_54258 ceph_msgpool_get 2 54258 NULL
+wusb_prf_54261 wusb_prf 7 54261 NULL nohasharray
+audio_write_54261 audio_write 4 54261 &wusb_prf_54261
+mwifiex_getlog_read_54269 mwifiex_getlog_read 3 54269 NULL
+kstrtou16_from_user_54274 kstrtou16_from_user 2 54274 NULL
+altera_set_dr_post_54291 altera_set_dr_post 2 54291 NULL
+dlm_alloc_pagevec_54296 dlm_alloc_pagevec 1 54296 NULL
+ttm_mem_global_alloc_54299 ttm_mem_global_alloc 0 54299 NULL
+sprintf_54306 sprintf 0 54306 NULL
+pn_raw_send_54330 pn_raw_send 2 54330 NULL
+br_fdb_fillbuf_54339 br_fdb_fillbuf 0 54339 NULL
+__alloc_dev_table_54343 __alloc_dev_table 2 54343 NULL
+_osd_realloc_seg_54352 _osd_realloc_seg 3 54352 NULL nohasharray
+__get_free_pages_54352 __get_free_pages 0 54352 &_osd_realloc_seg_54352
+tcf_hash_create_54360 tcf_hash_create 4 54360 NULL
+read_file_credit_dist_stats_54367 read_file_credit_dist_stats 3 54367 NULL
+vfs_readlink_54368 vfs_readlink 3 54368 NULL
+do_dccp_setsockopt_54377 do_dccp_setsockopt 5 54377 NULL
+ah_alloc_tmp_54378 ah_alloc_tmp 3-2 54378 NULL
+sysfs_dir_llseek_54385 sysfs_dir_llseek 2 54385 NULL
+snd_pcm_oss_read2_54387 snd_pcm_oss_read2 0-3 54387 NULL
+iwl_dbgfs_power_save_status_read_54392 iwl_dbgfs_power_save_status_read 3 54392 NULL
+add_packet_54433 add_packet 3 54433 NULL
+simple_strtoull_54493 simple_strtoull 0 54493 NULL
+cifs_idmap_key_instantiate_54503 cifs_idmap_key_instantiate 3 54503 NULL
+btrfs_ordered_sum_size_54509 btrfs_ordered_sum_size 0-2 54509 NULL
+cgroup_write_X64_54514 cgroup_write_X64 5 54514 NULL
+rfc4106_set_key_54519 rfc4106_set_key 3 54519 NULL
+unix_dgram_connect_54535 unix_dgram_connect 3 54535 NULL
+setsockopt_54539 setsockopt 5 54539 NULL
+lbs_lowsnr_write_54549 lbs_lowsnr_write 3 54549 NULL
+nfsd_vfs_write_54577 nfsd_vfs_write 6 54577 NULL
+fw_iso_buffer_init_54582 fw_iso_buffer_init 3 54582 NULL
+xfrm_polexpire_msgsize_54589 xfrm_polexpire_msgsize 0 54589 NULL
+port_fops_write_54627 port_fops_write 3 54627 NULL
+dns_resolver_read_54658 dns_resolver_read 3 54658 NULL
+bus_add_device_54665 bus_add_device 0 54665 NULL
+bio_kmalloc_54672 bio_kmalloc 2 54672 NULL
+evm_read_key_54674 evm_read_key 3 54674 NULL
+addtgt_54703 addtgt 3 54703 NULL
+rfkill_fop_read_54711 rfkill_fop_read 3 54711 NULL
+_add_sg_continuation_descriptor_54721 _add_sg_continuation_descriptor 3 54721 NULL
+ocfs2_control_write_54737 ocfs2_control_write 3 54737 NULL
+kzalloc_54740 kzalloc 1 54740 NULL
+drm_mode_crtc_set_gamma_size_54742 drm_mode_crtc_set_gamma_size 2 54742 NULL
+wep_iv_read_54744 wep_iv_read 3 54744 NULL
+lpfc_idiag_pcicfg_write_54749 lpfc_idiag_pcicfg_write 3 54749 NULL
+nfsd_write_54809 nfsd_write 6 54809 NULL
+crypto_tfm_ctx_alignment_54815 crypto_tfm_ctx_alignment 0 54815 NULL
+generic_perform_write_54832 generic_perform_write 3 54832 NULL
+write_rio_54837 write_rio 3 54837 NULL
+ext3_acl_from_disk_54839 ext3_acl_from_disk 2 54839 NULL
+edac_mc_alloc_54846 edac_mc_alloc 1 54846 NULL
+printer_read_54851 printer_read 3 54851 NULL
+alloc_ep_req_54860 alloc_ep_req 2 54860 NULL
+prism_build_supp_rates_54865 prism_build_supp_rates 0 54865 NULL
+tcf_csum_ipv6_tcp_54877 tcf_csum_ipv6_tcp 4 54877 NULL
+iscsi_pool_init_54913 iscsi_pool_init 2-4 54913 NULL nohasharray
+kobject_set_name_vargs_54913 kobject_set_name_vargs 0 54913 &iscsi_pool_init_54913
+btrfs_stack_chunk_num_stripes_54923 btrfs_stack_chunk_num_stripes 0 54923 NULL
+add_port_54941 add_port 2 54941 NULL
+alauda_write_data_54967 alauda_write_data 3 54967 NULL
+c4_add_card_54968 c4_add_card 3 54968 NULL
+__proc_file_read_54978 __proc_file_read 3 54978 NULL
+brcmf_sdcard_send_buf_54980 brcmf_sdcard_send_buf 6 54980 NULL
+_queue_data_54983 _queue_data 4 54983 NULL
+ext3_xattr_get_54989 ext3_xattr_get 0 54989 NULL
+ext4_ext_handle_uninitialized_extents_55059 ext4_ext_handle_uninitialized_extents 0-6 55059 NULL
+__netdev_alloc_skb_ip_align_55067 __netdev_alloc_skb_ip_align 2 55067 NULL
+apei_exec_run_55075 apei_exec_run 0 55075 NULL
+set_interface_55085 set_interface 0 55085 NULL
+kmalloc_large_55111 kmalloc_large 1 55111 NULL
+crypto_ahash_setkey_55134 crypto_ahash_setkey 3 55134 NULL
+filldir_55137 filldir 3 55137 NULL nohasharray
+ocfs2_prepare_refcount_change_for_del_55137 ocfs2_prepare_refcount_change_for_del 3 55137 &filldir_55137
+ocfs2_truncate_file_55148 ocfs2_truncate_file 3 55148 NULL
+sel_write_relabel_55195 sel_write_relabel 3 55195 NULL
+sched_feat_write_55202 sched_feat_write 3 55202 NULL
+isdn_net_ciscohdlck_alloc_skb_55209 isdn_net_ciscohdlck_alloc_skb 2 55209 NULL nohasharray
+ht40allow_map_read_55209 ht40allow_map_read 3 55209 &isdn_net_ciscohdlck_alloc_skb_55209
+__kfifo_dma_out_prepare_r_55211 __kfifo_dma_out_prepare_r 4-5 55211 NULL
+do_raw_setsockopt_55215 do_raw_setsockopt 5 55215 NULL
+sctp_abort_pkt_new_55218 sctp_abort_pkt_new 5 55218 NULL
+dbAllocDmap_55227 dbAllocDmap 0 55227 NULL
+tipc_port_reject_sections_55229 tipc_port_reject_sections 5 55229 NULL
+ext4_ext_convert_to_initialized_55235 ext4_ext_convert_to_initialized 0 55235 NULL
+memcpy_fromiovec_55247 memcpy_fromiovec 3 55247 NULL
+lbs_failcount_write_55276 lbs_failcount_write 3 55276 NULL
+gsm_control_modem_55303 gsm_control_modem 3 55303 NULL
+wimax_msg_len_55304 wimax_msg_len 0 55304 NULL
+__wa_xfer_setup_sizes_55342 __wa_xfer_setup_sizes 0 55342 NULL nohasharray
+sctp_datamsg_from_user_55342 sctp_datamsg_from_user 4 55342 &__wa_xfer_setup_sizes_55342
+acpi_system_read_event_55362 acpi_system_read_event 3 55362 NULL
+iwl_dbgfs_plcp_delta_read_55407 iwl_dbgfs_plcp_delta_read 3 55407 NULL
+alloc_skb_55439 alloc_skb 1 55439 NULL
+__vxge_hw_channel_allocate_55462 __vxge_hw_channel_allocate 3 55462 NULL
+isdnhdlc_decode_55466 isdnhdlc_decode 0 55466 NULL
+snd_pcm_lib_write_55483 snd_pcm_lib_write 0-3 55483 NULL
+i2o_pool_alloc_55485 i2o_pool_alloc 4 55485 NULL
+ocfs2_rec_clusters_55501 ocfs2_rec_clusters 0 55501 NULL
+cfpkt_pad_trail_55511 cfpkt_pad_trail 2 55511 NULL
+ea_get_55522 ea_get 3-0 55522 NULL
+set_msr_interception_55538 set_msr_interception 2 55538 NULL
+add_partition_55588 add_partition 2 55588 NULL
+kstrtou8_from_user_55599 kstrtou8_from_user 2 55599 NULL
+macvtap_put_user_55609 macvtap_put_user 4 55609 NULL
+selinux_setprocattr_55611 selinux_setprocattr 4 55611 NULL
+reiserfs_xattr_get_55628 reiserfs_xattr_get 0 55628 NULL nohasharray
+pktgen_if_write_55628 pktgen_if_write 3 55628 &reiserfs_xattr_get_55628
+xfs_bmbt_maxrecs_55649 xfs_bmbt_maxrecs 0-2 55649 NULL
+read_oldmem_55658 read_oldmem 3 55658 NULL
+lpfc_idiag_queinfo_read_55662 lpfc_idiag_queinfo_read 3 55662 NULL
+get_info_55681 get_info 3 55681 NULL
+iwl_dbgfs_plcp_delta_write_55682 iwl_dbgfs_plcp_delta_write 3 55682 NULL
+pm8001_store_update_fw_55716 pm8001_store_update_fw 4 55716 NULL
+prepare_reply_55734 prepare_reply 4 55734 NULL
+strlen_55778 strlen 0 55778 NULL
+req_bio_endio_55786 req_bio_endio 3 55786 NULL
+rtnl_vfinfo_size_55794 rtnl_vfinfo_size 0 55794 NULL
+uwb_rc_neh_grok_event_55799 uwb_rc_neh_grok_event 3 55799 NULL
+sb16_copy_from_user_55836 sb16_copy_from_user 10-6-7 55836 NULL
+xfs_da_buf_make_55845 xfs_da_buf_make 1 55845 NULL
+ip_hdrlen_55849 ip_hdrlen 0 55849 NULL
+hcd_alloc_coherent_55862 hcd_alloc_coherent 5 55862 NULL
+shmem_setxattr_55867 shmem_setxattr 4 55867 NULL
+__check_block_validity_55869 __check_block_validity 0 55869 NULL
+pm_qos_power_read_55891 pm_qos_power_read 3 55891 NULL
+snd_pcm_hw_param_value_min_55917 snd_pcm_hw_param_value_min 0 55917 NULL
+kvm_write_guest_virt_system_55944 kvm_write_guest_virt_system 4-2 55944 NULL
+sel_read_policy_55947 sel_read_policy 3 55947 NULL
+handle_response_55951 handle_response 5 55951 NULL
+simple_read_from_buffer_55957 simple_read_from_buffer 2-5 55957 NULL
+dccp_sendmsg_56058 dccp_sendmsg 4 56058 NULL
+pscsi_get_bio_56103 pscsi_get_bio 1 56103 NULL
+sel_read_handle_status_56139 sel_read_handle_status 3 56139 NULL
+write_file_frameerrors_56145 write_file_frameerrors 3 56145 NULL
+ath6kl_wmi_bssinfo_event_rx_56146 ath6kl_wmi_bssinfo_event_rx 3 56146 NULL
+rawv6_setsockopt_56165 rawv6_setsockopt 5 56165 NULL
+skb_headroom_56200 skb_headroom 0 56200 NULL
+ocfs2_find_xe_in_bucket_56224 ocfs2_find_xe_in_bucket 0 56224 NULL
+cp210x_get_config_56229 cp210x_get_config 4 56229 NULL
+do_ipt_set_ctl_56238 do_ipt_set_ctl 4 56238 NULL
+fd_copyin_56247 fd_copyin 3 56247 NULL
+btmrvl_hscfgcmd_read_56303 btmrvl_hscfgcmd_read 3 56303 NULL
+journal_init_revoke_table_56331 journal_init_revoke_table 1 56331 NULL
+snd_rawmidi_read_56337 snd_rawmidi_read 3 56337 NULL
+vxge_os_dma_malloc_async_56348 vxge_os_dma_malloc_async 3 56348 NULL
+iov_iter_copy_from_user_atomic_56368 iov_iter_copy_from_user_atomic 4-0 56368 NULL
+dev_read_56369 dev_read 3 56369 NULL
+ocfs2_control_read_56405 ocfs2_control_read 3 56405 NULL
+do_get_write_access_56410 do_get_write_access 0 56410 NULL
+store_msg_56417 store_msg 3 56417 NULL
+pppol2tp_sendmsg_56420 pppol2tp_sendmsg 4 56420 NULL
+fl_create_56435 fl_create 5 56435 NULL
+gnttab_map_56439 gnttab_map 2 56439 NULL
+osd_req_list_partition_objects_56464 osd_req_list_partition_objects 5 56464 NULL
+lbs_rdmac_write_56471 lbs_rdmac_write 3 56471 NULL
+calc_linear_pos_56472 calc_linear_pos 0-3 56472 NULL
+crypto_shash_alignmask_56486 crypto_shash_alignmask 0 56486 NULL
+cfg80211_connect_result_56515 cfg80211_connect_result 4-6 56515 NULL
+l1oip_socket_recv_56537 l1oip_socket_recv 6 56537 NULL
+ip_options_get_56538 ip_options_get 4 56538 NULL
+tcp_cwnd_test_56547 tcp_cwnd_test 0 56547 NULL
+ocfs2_change_extent_flag_56549 ocfs2_change_extent_flag 5 56549 NULL
+alloc_apertures_56561 alloc_apertures 1 56561 NULL
+rs_sta_dbgfs_stats_table_read_56573 rs_sta_dbgfs_stats_table_read 3 56573 NULL
+portcntrs_2_read_56586 portcntrs_2_read 3 56586 NULL
+event_filter_write_56609 event_filter_write 3 56609 NULL
+gather_array_56641 gather_array 3 56641 NULL
+dlm_dir_lookup_56662 dlm_dir_lookup 4 56662 NULL
+tg3_nvram_write_block_56666 tg3_nvram_write_block 3 56666 NULL
+btrfs_cow_block_56678 btrfs_cow_block 0 56678 NULL
+snd_gus_dram_read_56686 snd_gus_dram_read 4 56686 NULL
+sta_flags_read_56710 sta_flags_read 3 56710 NULL
+ipv6_getsockopt_sticky_56711 ipv6_getsockopt_sticky 5 56711 NULL
+__wa_xfer_setup_segs_56725 __wa_xfer_setup_segs 2 56725 NULL
+__copy_from_user_ll_56738 __copy_from_user_ll 0-3 56738 NULL
+drm_agp_bind_pages_56748 drm_agp_bind_pages 3 56748 NULL
+mfd_add_devices_56753 mfd_add_devices 4 56753 NULL
+__carl9170_rx_56784 __carl9170_rx 3 56784 NULL
+ttm_alloc_new_pages_56792 ttm_alloc_new_pages 5 56792 NULL
+ext4_ext_rm_idx_56827 ext4_ext_rm_idx 0 56827 NULL
+snd_rawmidi_kernel_write1_56847 snd_rawmidi_kernel_write1 4-0 56847 NULL
+ext3_xattr_ibody_get_56880 ext3_xattr_ibody_get 0 56880 NULL
+__kfifo_out_56927 __kfifo_out 0-3 56927 NULL
+journal_init_revoke_56933 journal_init_revoke 2 56933 NULL
+diva_get_driver_info_56967 diva_get_driver_info 0 56967 NULL
+vlsi_alloc_ring_57003 vlsi_alloc_ring 3-4 57003 NULL
+btrfs_super_csum_size_57004 btrfs_super_csum_size 0 57004 NULL
+snd_dma_alloc_pages_fallback_57029 snd_dma_alloc_pages_fallback 3 57029 NULL
+skb_network_offset_57043 skb_network_offset 0 57043 NULL nohasharray
+ieee80211_if_fmt_state_57043 ieee80211_if_fmt_state 3 57043 &skb_network_offset_57043
+bytes_to_samples_57049 bytes_to_samples 0-2 57049 NULL
+pcmcia_replace_cis_57066 pcmcia_replace_cis 3 57066 NULL
+sis190_try_rx_copy_57069 sis190_try_rx_copy 3 57069 NULL
+thin_status_57084 thin_status 4 57084 NULL
+tracing_set_trace_write_57096 tracing_set_trace_write 3 57096 NULL
+crypto_compress_ctxsize_57109 crypto_compress_ctxsize 0 57109 NULL
+sysfs_write_file_57116 sysfs_write_file 3 57116 NULL
+cipso_v4_gentag_loc_57119 cipso_v4_gentag_loc 0 57119 NULL
+rds_ib_sub_signaled_57136 rds_ib_sub_signaled 2 57136 NULL nohasharray
+nl80211_send_deauth_57136 nl80211_send_deauth 4 57136 &rds_ib_sub_signaled_57136 nohasharray
+ima_show_htable_value_57136 ima_show_htable_value 2 57136 &nl80211_send_deauth_57136
+snd_sonicvibes_getdmac_57140 snd_sonicvibes_getdmac 0 57140 NULL
+extent_from_logical_57179 extent_from_logical 0 57179 NULL
+sys_poll_57190 sys_poll 2 57190 NULL
+ieee80211_if_fmt_tsf_57249 ieee80211_if_fmt_tsf 3 57249 NULL
+oprofilefs_ulong_from_user_57251 oprofilefs_ulong_from_user 3 57251 NULL
+lbs_sleepparams_write_57283 lbs_sleepparams_write 3 57283 NULL
+pstore_file_read_57288 pstore_file_read 3 57288 NULL
+snd_pcm_read_57289 snd_pcm_read 3 57289 NULL
+ath6kl_buf_alloc_57304 ath6kl_buf_alloc 1 57304 NULL
+ftdi_elan_write_57309 ftdi_elan_write 3 57309 NULL
+write_file_regval_57313 write_file_regval 3 57313 NULL
+ocfs2_xattr_shrink_size_57328 ocfs2_xattr_shrink_size 3 57328 NULL
+usblp_read_57342 usblp_read 3 57342 NULL
+print_devstats_dot11RTSFailureCount_57347 print_devstats_dot11RTSFailureCount 3 57347 NULL
+read_file_blob_57406 read_file_blob 3 57406 NULL
+enclosure_register_57412 enclosure_register 3 57412 NULL
+compat_keyctl_instantiate_key_iov_57431 compat_keyctl_instantiate_key_iov 3 57431 NULL nohasharray
+alloc_ftrace_hash_57431 alloc_ftrace_hash 1 57431 &compat_keyctl_instantiate_key_iov_57431
+copy_to_user_fromio_57432 copy_to_user_fromio 3 57432 NULL
+sys_pselect6_57449 sys_pselect6 1 57449 NULL
+ReadReg_57453 ReadReg 0 57453 NULL
+__roundup_pow_of_two_57461 __roundup_pow_of_two 0 57461 NULL
+crypto_tfm_alg_blocksize_57463 crypto_tfm_alg_blocksize 0 57463 NULL
+sisusb_clear_vram_57466 sisusb_clear_vram 2-3 57466 NULL
+ieee80211_if_read_flags_57470 ieee80211_if_read_flags 3 57470 NULL
+ocfs2_write_cluster_57483 ocfs2_write_cluster 9-8-2 57483 NULL
+nl80211_send_mgmt_57497 nl80211_send_mgmt 6 57497 NULL
+skb_headlen_57501 skb_headlen 0 57501 NULL
+copy_in_user_57502 copy_in_user 3 57502 NULL
+ckhdid_printf_57505 ckhdid_printf 2 57505 NULL nohasharray
+ks8842_read32_57505 ks8842_read32 0 57505 &ckhdid_printf_57505
+init_tag_map_57515 init_tag_map 3 57515 NULL
+cmm_read_57520 cmm_read 3 57520 NULL
+inode_permission_57531 inode_permission 0 57531 NULL
+ReadHDLCPnP_57559 ReadHDLCPnP 0 57559 NULL
+snd_pcm_playback_ioctl1_57569 snd_pcm_playback_ioctl1 0 57569 NULL
+get_bridge_ifindices_57579 get_bridge_ifindices 0 57579 NULL
+iwl4965_rs_sta_dbgfs_scale_table_write_57595 iwl4965_rs_sta_dbgfs_scale_table_write 3 57595 NULL
+sk_stream_alloc_skb_57622 sk_stream_alloc_skb 2 57622 NULL
+osdmap_set_max_osd_57630 osdmap_set_max_osd 2 57630 NULL nohasharray
+sisusbcon_putcs_57630 sisusbcon_putcs 3 57630 &osdmap_set_max_osd_57630
+mem_read_57631 mem_read 3 57631 NULL
+sys_mq_timedsend_57661 sys_mq_timedsend 3 57661 NULL
+r3964_write_57662 r3964_write 4 57662 NULL
+__lgwrite_57669 __lgwrite 4 57669 NULL
+i2400m_rx_stats_read_57706 i2400m_rx_stats_read 3 57706 NULL
+aa_matching_read_57720 aa_matching_read 3 57720 NULL
+pppol2tp_recvmsg_57742 pppol2tp_recvmsg 4 57742 NULL nohasharray
+compat_sys_set_mempolicy_57742 compat_sys_set_mempolicy 3 57742 &pppol2tp_recvmsg_57742
+ieee80211_if_fmt_dot11MeshHWMPpreqMinInterval_57762 ieee80211_if_fmt_dot11MeshHWMPpreqMinInterval 3 57762 NULL
+read_block_for_search_57781 read_block_for_search 0 57781 NULL
+apei_exec_collect_resources_57788 apei_exec_collect_resources 0 57788 NULL
+ld2_57794 ld2 0 57794 NULL
+bfad_debugfs_read_regrd_57830 bfad_debugfs_read_regrd 3 57830 NULL
+copy_to_user_57835 copy_to_user 3-0 57835 NULL
+flash_read_57843 flash_read 3 57843 NULL
+tt_response_fill_table_57902 tt_response_fill_table 1 57902 NULL
+xt_alloc_table_info_57903 xt_alloc_table_info 1 57903 NULL
+emi26_writememory_57908 emi26_writememory 4 57908 NULL
+atomic_add_return_unchecked_57910 atomic_add_return_unchecked 0-1 57910 NULL
+__snd_gf1_look16_57925 __snd_gf1_look16 0 57925 NULL
+sel_read_handle_unknown_57933 sel_read_handle_unknown 3 57933 NULL
+xfs_mru_cache_create_57943 xfs_mru_cache_create 3 57943 NULL
+rx_57944 rx 4 57944 NULL
+key_algorithm_read_57946 key_algorithm_read 3 57946 NULL
+ip_set_alloc_57953 ip_set_alloc 1 57953 NULL nohasharray
+ioat3_dca_count_dca_slots_57953 ioat3_dca_count_dca_slots 0 57953 &ip_set_alloc_57953
+i915_cache_sharing_write_57961 i915_cache_sharing_write 3 57961 NULL
+hfc_empty_fifo_57972 hfc_empty_fifo 2 57972 NULL
+stripe_status_57985 stripe_status 4 57985 NULL
+regcache_rbtree_insert_to_block_58009 regcache_rbtree_insert_to_block 5 58009 NULL
+iwl_dbgfs_ucode_rx_stats_read_58023 iwl_dbgfs_ucode_rx_stats_read 3 58023 NULL
+io_playback_transfer_58030 io_playback_transfer 4 58030 NULL
+ocfs2_find_leaf_58065 ocfs2_find_leaf 0 58065 NULL
+cm4040_write_58079 cm4040_write 3 58079 NULL
+i915_add_request_58096 i915_add_request 0 58096 NULL
+savemem_58129 savemem 3 58129 NULL
+ipv6_flowlabel_opt_58135 ipv6_flowlabel_opt 3 58135 NULL nohasharray
+slhc_init_58135 slhc_init 1-2 58135 &ipv6_flowlabel_opt_58135
+garmin_write_bulk_58191 garmin_write_bulk 3 58191 NULL
+asix_write_cmd_58192 asix_write_cmd 5 58192 NULL
+ieee80211_if_fmt_flags_58205 ieee80211_if_fmt_flags 3 58205 NULL
+nci_send_cmd_58206 nci_send_cmd 3 58206 NULL
+sysfs_add_file_mode_58222 sysfs_add_file_mode 0 58222 NULL
+read_file_debug_58256 read_file_debug 3 58256 NULL
+cfg80211_mgmt_tx_status_58266 cfg80211_mgmt_tx_status 4 58266 NULL
+profile_load_58267 profile_load 3 58267 NULL
+kstrtos8_from_user_58268 kstrtos8_from_user 2 58268 NULL
+acpi_ds_build_internal_package_obj_58271 acpi_ds_build_internal_package_obj 3 58271 NULL
+iscsi_decode_text_input_58292 iscsi_decode_text_input 4 58292 NULL
+my_skb_head_push_58297 my_skb_head_push 2 58297 NULL
+ieee80211_if_read_dot11MeshTTL_58307 ieee80211_if_read_dot11MeshTTL 3 58307 NULL
+ext4_ext_truncate_extend_restart_58331 ext4_ext_truncate_extend_restart 0 58331 NULL
+sctp_make_init_58401 sctp_make_init 4 58401 NULL
+idetape_pad_zeros_58406 idetape_pad_zeros 2 58406 NULL
+i2400m_pld_size_58415 i2400m_pld_size 0 58415 NULL
+iscsi_offload_mesg_58425 iscsi_offload_mesg 5 58425 NULL
+capabilities_read_58457 capabilities_read 3 58457 NULL
+lpfc_idiag_baracc_read_58466 lpfc_idiag_baracc_read 3 58466 NULL nohasharray
+compat_do_ipt_set_ctl_58466 compat_do_ipt_set_ctl 4 58466 &lpfc_idiag_baracc_read_58466
+snd_gf1_read_addr_58483 snd_gf1_read_addr 0 58483 NULL
+snd_rme96_capture_copy_58484 snd_rme96_capture_copy 5 58484 NULL
+rndis_add_response_58544 rndis_add_response 2 58544 NULL
+efx_tsoh_heap_alloc_58545 efx_tsoh_heap_alloc 2 58545 NULL
+scnprint_mac_oui_58578 scnprint_mac_oui 3-0 58578 NULL
+ea_read_inline_58589 ea_read_inline 0 58589 NULL
+xip_file_read_58592 xip_file_read 3 58592 NULL
+ecryptfs_write_end_58594 ecryptfs_write_end 5-3 58594 NULL
+ixj_read_58615 ixj_read 3 58615 NULL
+skb_copy_to_page_nocache_58624 skb_copy_to_page_nocache 6 58624 NULL
+module_alloc_update_bounds_rx_58634 module_alloc_update_bounds_rx 1 58634 NULL
+ocfs2_block_to_cluster_start_58653 ocfs2_block_to_cluster_start 2 58653 NULL
+iwl_dbgfs_rx_handlers_write_58655 iwl_dbgfs_rx_handlers_write 3 58655 NULL
+uwb_bce_print_IEs_58686 uwb_bce_print_IEs 4 58686 NULL
+vx_send_msg_58711 vx_send_msg 0 58711 NULL
+csum_exist_in_range_58730 csum_exist_in_range 2-3 58730 NULL
+frames_to_bytes_58741 frames_to_bytes 0-2 58741 NULL
+ieee80211_if_write_tkip_mic_test_58748 ieee80211_if_write_tkip_mic_test 3 58748 NULL
+agp_allocate_memory_58761 agp_allocate_memory 2 58761 NULL
+__do_config_autodelink_58763 __do_config_autodelink 3 58763 NULL
+regmap_calc_reg_len_58795 regmap_calc_reg_len 0 58795 NULL
+raw_send_hdrinc_58803 raw_send_hdrinc 4 58803 NULL
+ep_read_58813 ep_read 3 58813 NULL
+command_write_58841 command_write 3 58841 NULL
+ocfs2_truncate_log_append_58850 ocfs2_truncate_log_append 3 58850 NULL
+iwl_dbgfs_traffic_log_read_58870 iwl_dbgfs_traffic_log_read 3 58870 NULL
+gs_alloc_req_58883 gs_alloc_req 2 58883 NULL
+print_devstats_dot11FCSErrorCount_58919 print_devstats_dot11FCSErrorCount 3 58919 NULL
+st5481_isoc_flatten_58952 st5481_isoc_flatten 0 58952 NULL
+netpoll_send_udp_58955 netpoll_send_udp 3 58955 NULL
+wait_table_hash_nr_entries_58962 wait_table_hash_nr_entries 0 58962 NULL
+crypto_aead_ivsize_58970 crypto_aead_ivsize 0 58970 NULL
+max3107_handlerx_58978 max3107_handlerx 2 58978 NULL
+handle_rx_packet_58993 handle_rx_packet 3 58993 NULL
+ep_write_59008 ep_write 3 59008 NULL
+lpfc_idiag_baracc_write_59014 lpfc_idiag_baracc_write 3 59014 NULL
+receive_server_sync_packet_59021 receive_server_sync_packet 3 59021 NULL
+selinux_transaction_write_59038 selinux_transaction_write 3 59038 NULL
+crypto_aead_reqsize_59039 crypto_aead_reqsize 0 59039 NULL
+mmc_sd_num_wr_blocks_59112 mmc_sd_num_wr_blocks 0 59112 NULL
+scsi_io_completion_59122 scsi_io_completion 2 59122 NULL
+print_devstats_dot11RTSSuccessCount_59145 print_devstats_dot11RTSSuccessCount 3 59145 NULL nohasharray
+framebuffer_alloc_59145 framebuffer_alloc 1 59145 &print_devstats_dot11RTSSuccessCount_59145
+ocfs2_move_extent_59187 ocfs2_move_extent 3-2-5 59187 NULL
+validate_exec_list_59204 validate_exec_list 0 59204 NULL
+xfs_iext_realloc_indirect_59211 xfs_iext_realloc_indirect 2 59211 NULL
+fast_rx_path_59214 fast_rx_path 3 59214 NULL
+inftl_partscan_59216 inftl_partscan 0 59216 NULL
+tcp_try_rmem_schedule_59231 tcp_try_rmem_schedule 2 59231 NULL
+tty_prepare_flip_string_flags_59240 tty_prepare_flip_string_flags 4 59240 NULL
+nla_len_59258 nla_len 0 59258 NULL
+btrfs_insert_dir_item_59304 btrfs_insert_dir_item 4 59304 NULL
+fd_copyout_59323 fd_copyout 3 59323 NULL
+read_9287_modal_eeprom_59327 read_9287_modal_eeprom 3 59327 NULL
+xfs_attrmulti_attr_set_59346 xfs_attrmulti_attr_set 4 59346 NULL
+__map_request_59350 __map_request 0 59350 NULL
+xfs_dir2_sf_entsize_59366 xfs_dir2_sf_entsize 0-2 59366 NULL
+journal_init_dev_59384 journal_init_dev 5 59384 NULL
+fc_frame_alloc_fill_59394 fc_frame_alloc_fill 2 59394 NULL
+pci_ctrl_read_59424 pci_ctrl_read 0 59424 NULL
+vxge_hw_ring_rxds_per_block_get_59425 vxge_hw_ring_rxds_per_block_get 0 59425 NULL
+squashfs_read_data_59440 squashfs_read_data 6 59440 NULL
+shrink_tnc_trees_59481 shrink_tnc_trees 0 59481 NULL
+ib_copy_from_udata_59502 ib_copy_from_udata 3 59502 NULL
+rds_pin_pages_59507 rds_pin_pages 0 59507 NULL
+tunables_write_59563 tunables_write 3 59563 NULL
+__copy_from_user_ll_nozero_59571 __copy_from_user_ll_nozero 0-3 59571 NULL
+write_pbl_59583 write_pbl 4 59583 NULL
+memdup_user_59590 memdup_user 2 59590 NULL
+fcoe_ctlr_vn_send_59607 fcoe_ctlr_vn_send 4 59607 NULL
+mtrr_write_59622 mtrr_write 3 59622 NULL
+ip_vs_icmp_xmit_59624 ip_vs_icmp_xmit 4 59624 NULL
+find_first_zero_bit_59636 find_first_zero_bit 0 59636 NULL
+dn_fib_nlmsg_size_59643 dn_fib_nlmsg_size 0 59643 NULL
+ubifs_setxattr_59650 ubifs_setxattr 4 59650 NULL nohasharray
+hidraw_read_59650 hidraw_read 3 59650 &ubifs_setxattr_59650
+v9fs_xattr_set_acl_59651 v9fs_xattr_set_acl 4 59651 NULL
+tcp_skb_pcount_59664 tcp_skb_pcount 0 59664 NULL
+alloc_dca_provider_59670 alloc_dca_provider 2 59670 NULL
+ieee80211_mgmt_tx_59699 ieee80211_mgmt_tx 9 59699 NULL
+ioperm_get_59701 ioperm_get 4-3 59701 NULL
+prism2_info_scanresults_59729 prism2_info_scanresults 3 59729 NULL
+sock_rmalloc_59740 sock_rmalloc 2 59740 NULL nohasharray
+ieee80211_if_read_fwded_unicast_59740 ieee80211_if_read_fwded_unicast 3 59740 &sock_rmalloc_59740
+qib_decode_7220_sdma_errs_59745 qib_decode_7220_sdma_errs 4 59745 NULL
+strnlen_59746 strnlen 0 59746 NULL nohasharray
+fuse_file_llseek_59746 fuse_file_llseek 2 59746 &strnlen_59746
+ext3_acl_count_59754 ext3_acl_count 0-1 59754 NULL
+long_retry_limit_read_59766 long_retry_limit_read 3 59766 NULL
+venus_remove_59781 venus_remove 4 59781 NULL
+ipw_write_59807 ipw_write 3 59807 NULL
+ubi_dbg_check_all_ff_59810 ubi_dbg_check_all_ff 0 59810 NULL
+scsi_init_shared_tag_map_59812 scsi_init_shared_tag_map 2 59812 NULL
+ieee80211_if_read_dot11MeshHWMPmaxPREQretries_59829 ieee80211_if_read_dot11MeshHWMPmaxPREQretries 3 59829 NULL
+tun_put_user_59849 tun_put_user 4 59849 NULL
+format_array_59854 format_array 0 59854 NULL
+ffs_prepare_buffer_59892 ffs_prepare_buffer 2 59892 NULL
+dapm_widget_power_read_file_59950 dapm_widget_power_read_file 3 59950 NULL
+__arch_hweight16_59975 __arch_hweight16 0 59975 NULL
+osd_req_read_kern_59990 osd_req_read_kern 5 59990 NULL
+ghash_async_setkey_60001 ghash_async_setkey 3 60001 NULL
+rawsock_sendmsg_60010 rawsock_sendmsg 4 60010 NULL
+mthca_init_cq_60011 mthca_init_cq 2 60011 NULL
+osd_req_list_dev_partitions_60027 osd_req_list_dev_partitions 4 60027 NULL
+xlog_bread_offset_60030 xlog_bread_offset 3 60030 NULL
+sys_sched_getaffinity_60033 sys_sched_getaffinity 2 60033 NULL
+bio_integrity_hw_sectors_60039 bio_integrity_hw_sectors 0-2 60039 NULL
+do_ip6t_set_ctl_60040 do_ip6t_set_ctl 4 60040 NULL
+vcs_size_60050 vcs_size 0 60050 NULL
+load_module_60056 load_module 2 60056 NULL nohasharray
+gru_alloc_gts_60056 gru_alloc_gts 3-2 60056 &load_module_60056
+compat_writev_60063 compat_writev 3 60063 NULL
+c4iw_num_stags_60073 c4iw_num_stags 0 60073 NULL
+rxrpc_kernel_send_data_60083 rxrpc_kernel_send_data 3 60083 NULL
+ieee80211_if_fmt_fwded_frames_60103 ieee80211_if_fmt_fwded_frames 3 60103 NULL
+ld_usb_read_60156 ld_usb_read 3 60156 NULL
+jmb38x_ms_count_slots_60164 jmb38x_ms_count_slots 0 60164 NULL
+init_state_60165 init_state 2 60165 NULL
+jffs2_alloc_full_dirent_60179 jffs2_alloc_full_dirent 1 60179 NULL nohasharray
+sg_build_sgat_60179 sg_build_sgat 3 60179 &jffs2_alloc_full_dirent_60179
+ib_send_cm_mra_60202 ib_send_cm_mra 4 60202 NULL nohasharray
+qib_reg_phys_mr_60202 qib_reg_phys_mr 3 60202 &ib_send_cm_mra_60202
+printer_write_60276 printer_write 3 60276 NULL
+__pskb_pull_tail_60287 __pskb_pull_tail 2 60287 NULL
+dn_nsp_return_disc_60296 dn_nsp_return_disc 2 60296 NULL
+do_xip_mapping_read_60297 do_xip_mapping_read 5 60297 NULL
+ext3_dir_llseek_60298 ext3_dir_llseek 2 60298 NULL
+getDataLength_60301 getDataLength 0 60301 NULL
+__kfifo_from_user_r_60345 __kfifo_from_user_r 5-3 60345 NULL
+brcmf_alloc_wdev_60347 brcmf_alloc_wdev 1 60347 NULL
+dccp_setsockopt_60367 dccp_setsockopt 5 60367 NULL
+mthca_alloc_resize_buf_60394 mthca_alloc_resize_buf 3 60394 NULL
+ocfs2_zero_extend_60396 ocfs2_zero_extend 3 60396 NULL
+driver_names_read_60399 driver_names_read 3 60399 NULL
+simple_alloc_urb_60420 simple_alloc_urb 3 60420 NULL
+kmalloc_60432 kmalloc 1 60432 NULL nohasharray
+tstats_write_60432 tstats_write 3 60432 &kmalloc_60432
+tipc_buf_acquire_60437 tipc_buf_acquire 1 60437 NULL
+rx_data_60442 rx_data 4 60442 NULL
+tcf_csum_ipv4_igmp_60446 tcf_csum_ipv4_igmp 3 60446 NULL
+crypto_shash_setkey_60483 crypto_shash_setkey 3 60483 NULL
+ath_tx_init_60515 ath_tx_init 2 60515 NULL
+ubi_wl_get_peb_60525 ubi_wl_get_peb 0 60525 NULL
+hysdn_sched_rx_60533 hysdn_sched_rx 3 60533 NULL
+v9fs_fid_readn_60544 v9fs_fid_readn 4 60544 NULL
+tracing_entries_write_60563 tracing_entries_write 3 60563 NULL
+skb_transport_offset_60619 skb_transport_offset 0 60619 NULL
+acl_alloc_stack_init_60630 acl_alloc_stack_init 1 60630 NULL
+free_dind_blocks_60635 free_dind_blocks 0 60635 NULL
+if_sdio_host_to_card_60666 if_sdio_host_to_card 4 60666 NULL
+ieee80211_if_read_dot11MeshConfirmTimeout_60670 ieee80211_if_read_dot11MeshConfirmTimeout 3 60670 NULL
+init_data_container_60709 init_data_container 1 60709 NULL
+snd_ice1712_ds_read_60754 snd_ice1712_ds_read 0 60754 NULL
+sel_write_checkreqprot_60774 sel_write_checkreqprot 3 60774 NULL
+opticon_write_60775 opticon_write 4 60775 NULL
+acl_alloc_num_60778 acl_alloc_num 1-2 60778 NULL
+snd_pcm_oss_readv3_60792 snd_pcm_oss_readv3 3 60792 NULL
+pool_status_60861 pool_status 4 60861 NULL
+ieee80211_send_auth_60865 ieee80211_send_auth 5 60865 NULL
+generic_writepages_60871 generic_writepages 0 60871 NULL
+mgt_set_varlen_60916 mgt_set_varlen 4 60916 NULL
+set_powered_60938 set_powered 4 60938 NULL
+pti_char_write_60960 pti_char_write 3 60960 NULL
+mwifiex_alloc_sdio_mpa_buffers_60961 mwifiex_alloc_sdio_mpa_buffers 2-3 60961 NULL
+blkio_get_key_name_61014 blkio_get_key_name 4 61014 NULL
+ath6kl_lrssi_roam_read_61022 ath6kl_lrssi_roam_read 3 61022 NULL
+lpfc_idiag_queacc_write_61043 lpfc_idiag_queacc_write 3 61043 NULL
+symtab_init_61050 symtab_init 2 61050 NULL
+fuse_send_write_61053 fuse_send_write 0 61053 NULL
+bitmap_scnlistprintf_61062 bitmap_scnlistprintf 2-0 61062 NULL
+ahash_align_buffer_size_61070 ahash_align_buffer_size 0-1-2 61070 NULL
+get_derived_key_61100 get_derived_key 4 61100 NULL
+alloc_chrdev_region_61112 alloc_chrdev_region 0 61112 NULL
+__probe_kernel_read_61119 __probe_kernel_read 3 61119 NULL
+proto_ports_offset_61125 proto_ports_offset 0 61125 NULL
+vmemmap_alloc_block_buf_61126 vmemmap_alloc_block_buf 1 61126 NULL
+afs_proc_cells_write_61139 afs_proc_cells_write 3 61139 NULL
+sys_lsetxattr_61177 sys_lsetxattr 4 61177 NULL
+cfpkt_append_61206 cfpkt_append 3 61206 NULL
+arch_hibernation_header_save_61212 arch_hibernation_header_save 0 61212 NULL
+pn544_write_61215 pn544_write 3 61215 NULL
+smk_read_ambient_61220 smk_read_ambient 3 61220 NULL
+find_get_pages_tag_61270 find_get_pages_tag 0 61270 NULL
+kick_a_thread_61273 kick_a_thread 0 61273 NULL
+vortex_adbdma_getlinearpos_61283 vortex_adbdma_getlinearpos 0 61283 NULL
+sys_add_key_61288 sys_add_key 4 61288 NULL
+xfrm_user_sec_ctx_size_61320 xfrm_user_sec_ctx_size 0 61320 NULL
+st5481_setup_isocpipes_61340 st5481_setup_isocpipes 6-4 61340 NULL
+set_params_61373 set_params 0 61373 NULL
+change_xattr_61390 change_xattr 5 61390 NULL
+system_enable_write_61396 system_enable_write 3 61396 NULL
+pm860x_bulk_read_61415 pm860x_bulk_read 3 61415 NULL
+i915_emit_box_61436 i915_emit_box 0 61436 NULL
+unix_stream_sendmsg_61455 unix_stream_sendmsg 4 61455 NULL
+snd_pcm_lib_writev_transfer_61483 snd_pcm_lib_writev_transfer 5-4-2 61483 NULL
+btrfs_item_size_61485 btrfs_item_size 0 61485 NULL
+clone_bio_61526 clone_bio 5 61526 NULL nohasharray
+erst_errno_61526 erst_errno 0 61526 &clone_bio_61526
+trace_options_core_write_61551 trace_options_core_write 3 61551 NULL
+rbd_do_request_61561 rbd_do_request 6-7 61561 NULL
+parport_pc_fifo_write_block_dma_61568 parport_pc_fifo_write_block_dma 3 61568 NULL
+fan_proc_write_61569 fan_proc_write 3 61569 NULL
+ieee80211_if_read_rc_rateidx_mask_2ghz_61570 ieee80211_if_read_rc_rateidx_mask_2ghz 3 61570 NULL
+seq_open_private_61589 seq_open_private 3 61589 NULL
+netlink_recvmsg_61600 netlink_recvmsg 4 61600 NULL
+configfs_write_file_61621 configfs_write_file 3 61621 NULL
+ieee80211_rx_bss_info_61630 ieee80211_rx_bss_info 3 61630 NULL
+i2o_parm_table_get_61635 i2o_parm_table_get 6 61635 NULL
+snd_pcm_oss_read3_61643 snd_pcm_oss_read3 0-3 61643 NULL
+resize_stripes_61650 resize_stripes 2 61650 NULL
+ttm_page_pool_free_61661 ttm_page_pool_free 2-0 61661 NULL
+insert_one_name_61668 insert_one_name 7 61668 NULL
+lock_loop_61681 lock_loop 1 61681 NULL
+filter_read_61692 filter_read 3 61692 NULL
+iov_length_61716 iov_length 0 61716 NULL
+fragmentation_threshold_read_61718 fragmentation_threshold_read 3 61718 NULL
+read_file_interrupt_61742 read_file_interrupt 3 61742 NULL nohasharray
+read_file_regval_61742 read_file_regval 3 61742 &read_file_interrupt_61742
+mls_compute_context_len_61812 mls_compute_context_len 0 61812 NULL
+btrfs_file_llseek_61838 btrfs_file_llseek 2 61838 NULL
+bfad_debugfs_write_regwr_61841 bfad_debugfs_write_regwr 3 61841 NULL
+evdev_compute_buffer_size_61863 evdev_compute_buffer_size 0 61863 NULL
+get_fw_name_61874 get_fw_name 3 61874 NULL
+ax25_addr_size_61899 ax25_addr_size 0 61899 NULL nohasharray
+cxgb4_pktgl_to_skb_61899 cxgb4_pktgl_to_skb 2 61899 &ax25_addr_size_61899
+clear_refs_write_61904 clear_refs_write 3 61904 NULL
+sctp_sendmsg_61919 sctp_sendmsg 4 61919 NULL
+send_bulk_static_data_61932 send_bulk_static_data 3 61932 NULL
+squashfs_read_id_index_table_61961 squashfs_read_id_index_table 4 61961 NULL
+ocfs2_quota_write_61972 ocfs2_quota_write 5-4 61972 NULL
+fd_locked_ioctl_61978 fd_locked_ioctl 3 61978 NULL
+cow_file_range_61979 cow_file_range 3 61979 NULL
+module_alloc_exec_61991 module_alloc_exec 1 61991 NULL
+virtnet_send_command_61993 virtnet_send_command 5-6 61993 NULL
+dequeue_event_62000 dequeue_event 3 62000 NULL
+xt_compat_match_offset_62011 xt_compat_match_offset 0 62011 NULL
+jffs2_do_unlink_62020 jffs2_do_unlink 4 62020 NULL
+pmcraid_build_passthrough_ioadls_62034 pmcraid_build_passthrough_ioadls 2 62034 NULL
+proc_fdinfo_read_62043 proc_fdinfo_read 3 62043 NULL
+ppp_tx_cp_62044 ppp_tx_cp 5 62044 NULL
+sctp_user_addto_chunk_62047 sctp_user_addto_chunk 2-3 62047 NULL
+do_pselect_62061 do_pselect 1 62061 NULL
+pcpu_alloc_bootmem_62074 pcpu_alloc_bootmem 2 62074 NULL
+jffs2_security_setxattr_62107 jffs2_security_setxattr 4 62107 NULL
+ip_recv_error_62117 ip_recv_error 3 62117 NULL
+generic_block_fiemap_62122 generic_block_fiemap 4 62122 NULL
+llc_ui_header_len_62131 llc_ui_header_len 0 62131 NULL
+kobject_add_varg_62133 kobject_add_varg 0 62133 NULL nohasharray
+qib_diag_write_62133 qib_diag_write 3 62133 &kobject_add_varg_62133
+ql_status_62135 ql_status 5 62135 NULL nohasharray
+device_add_attrs_62135 device_add_attrs 0 62135 &ql_status_62135
+video_usercopy_62151 video_usercopy 2 62151 NULL
+prism54_wpa_bss_ie_get_62173 prism54_wpa_bss_ie_get 0 62173 NULL
+alloc_upcall_62186 alloc_upcall 2 62186 NULL
+btrfs_xattr_acl_set_62203 btrfs_xattr_acl_set 4 62203 NULL
+sock_kmalloc_62205 sock_kmalloc 2 62205 NULL
+check_unicast_packet_62217 check_unicast_packet 2 62217 NULL
+hash_new_62224 hash_new 1 62224 NULL
+nfsd_read_file_62241 nfsd_read_file 6 62241 NULL
+subsystem_filter_read_62310 subsystem_filter_read 3 62310 NULL
+udf_sb_alloc_partition_maps_62313 udf_sb_alloc_partition_maps 2 62313 NULL
+hfcpci_empty_bfifo_62323 hfcpci_empty_bfifo 4 62323 NULL
+flash_write_62354 flash_write 3 62354 NULL
+xfpregs_set_62363 xfpregs_set 4 62363 NULL
+altera_irscan_62396 altera_irscan 2 62396 NULL
+udplite_manip_pkt_62433 udplite_manip_pkt 2 62433 NULL
+netdev_alloc_skb_62437 netdev_alloc_skb 2 62437 NULL
+e1000_check_copybreak_62448 e1000_check_copybreak 3 62448 NULL
+pep_sendmsg_62524 pep_sendmsg 4 62524 NULL
+test_iso_queue_62534 test_iso_queue 5 62534 NULL
+debugfs_read_62535 debugfs_read 3 62535 NULL
+qib_refresh_qsfp_cache_62547 qib_refresh_qsfp_cache 0 62547 NULL
+xfrm_user_policy_62573 xfrm_user_policy 4 62573 NULL
+packet_alloc_skb_62602 packet_alloc_skb 2-5-4 62602 NULL
+nfsd_vfs_read_62605 nfsd_vfs_read 6 62605 NULL nohasharray
+prism2_send_mgmt_62605 prism2_send_mgmt 4 62605 &nfsd_vfs_read_62605
+iwl_dbgfs_force_reset_read_62628 iwl_dbgfs_force_reset_read 3 62628 NULL
+lpfc_sli4_queue_alloc_62646 lpfc_sli4_queue_alloc 3 62646 NULL
+tt_changes_fill_buffer_62649 tt_changes_fill_buffer 3 62649 NULL
+write_62671 write 3 62671 NULL
+printer_req_alloc_62687 printer_req_alloc 2 62687 NULL nohasharray
+iwl_dbgfs_rx_statistics_read_62687 iwl_dbgfs_rx_statistics_read 3 62687 &printer_req_alloc_62687
+ext4_ind_map_blocks_62690 ext4_ind_map_blocks 0 62690 NULL
+adxl34x_i2c_read_block_62691 adxl34x_i2c_read_block 3 62691 NULL
+bioset_integrity_create_62708 bioset_integrity_create 2 62708 NULL
+key_replays_read_62746 key_replays_read 3 62746 NULL
+mwifiex_rdeeprom_write_62754 mwifiex_rdeeprom_write 3 62754 NULL
+ax25_sendmsg_62770 ax25_sendmsg 4 62770 NULL
+scrub_chunk_62771 scrub_chunk 4 62771 NULL
+tracing_total_entries_read_62817 tracing_total_entries_read 3 62817 NULL
+__rounddown_pow_of_two_62836 __rounddown_pow_of_two 0 62836 NULL
+xlog_recover_add_to_trans_62839 xlog_recover_add_to_trans 4 62839 NULL
+genlmsg_msg_size_62845 genlmsg_msg_size 0-1 62845 NULL
+hpi_read_word_62862 hpi_read_word 0 62862 NULL
+nfs_writedata_alloc_62868 nfs_writedata_alloc 1 62868 NULL
+aoechr_write_62883 aoechr_write 3 62883 NULL
+resize_info_buffer_62889 resize_info_buffer 2 62889 NULL
+if_spi_host_to_card_62890 if_spi_host_to_card 4 62890 NULL
+ocfs2_validate_gd_parent_62905 ocfs2_validate_gd_parent 0 62905 NULL
+mempool_create_slab_pool_62907 mempool_create_slab_pool 1 62907 NULL
+getdqbuf_62908 getdqbuf 1 62908 NULL
+agp_create_user_memory_62955 agp_create_user_memory 1 62955 NULL
+get_skb_63008 get_skb 2 63008 NULL
+kstrtoull_from_user_63026 kstrtoull_from_user 2 63026 NULL
+scsi_host_alloc_63041 scsi_host_alloc 2 63041 NULL
+unlink1_63059 unlink1 3 63059 NULL
+ocfs2_decrease_refcount_63078 ocfs2_decrease_refcount 4-3 63078 NULL
+brcmf_alloc_pkt_and_read_63116 brcmf_alloc_pkt_and_read 2 63116 NULL nohasharray
+iwl_dbgfs_sensitivity_read_63116 iwl_dbgfs_sensitivity_read 3 63116 &brcmf_alloc_pkt_and_read_63116
+ib_send_cm_rtu_63138 ib_send_cm_rtu 3 63138 NULL
+snd_pcm_lib_malloc_pages_63182 snd_pcm_lib_malloc_pages 2 63182 NULL
+module_alloc_update_bounds_rw_63233 module_alloc_update_bounds_rw 1 63233 NULL
+ptp_read_63251 ptp_read 4 63251 NULL
+readword_63288 readword 0 63288 NULL
+tcp_collapse_63294 tcp_collapse 6-5 63294 NULL
+isdn_ppp_ccp_xmit_reset_63297 isdn_ppp_ccp_xmit_reset 6 63297 NULL
+dns_resolver_instantiate_63314 dns_resolver_instantiate 3 63314 NULL
+proc_info_read_63344 proc_info_read 3 63344 NULL
+idmouse_read_63374 idmouse_read 3 63374 NULL
+edac_pci_alloc_ctl_info_63388 edac_pci_alloc_ctl_info 1 63388 NULL
+noack_read_63419 noack_read 3 63419 NULL
+iwl_dbgfs_debug_level_read_63430 iwl_dbgfs_debug_level_read 3 63430 NULL
+brcmu_pkttotlen_63431 brcmu_pkttotlen 0 63431 NULL
+nfsd_symlink_63442 nfsd_symlink 6 63442 NULL
+snd_info_entry_write_63474 snd_info_entry_write 3 63474 NULL
+do_work_63483 do_work 0 63483 NULL
+get_gpio_63488 get_gpio 0 63488 NULL nohasharray
+read_kcore_63488 read_kcore 3 63488 &get_gpio_63488
+snd_pcm_plug_write_transfer_63503 snd_pcm_plug_write_transfer 0-3 63503 NULL
+ubi_more_leb_change_data_63534 ubi_more_leb_change_data 4 63534 NULL
+snapshot_status_63538 snapshot_status 4 63538 NULL
+if_sdio_read_scratch_63540 if_sdio_read_scratch 0 63540 NULL
+append_to_buffer_63550 append_to_buffer 3 63550 NULL
+kvm_write_guest_page_63555 kvm_write_guest_page 5 63555 NULL
+ocfs2_calc_trunc_pos_63576 ocfs2_calc_trunc_pos 4 63576 NULL
+mlx4_ib_alloc_cq_buf_63610 mlx4_ib_alloc_cq_buf 3 63610 NULL
+module_alloc_63630 module_alloc 1 63630 NULL
+symbol_build_supp_rates_63634 symbol_build_supp_rates 0 63634 NULL
+ext4_ext_get_access_63642 ext4_ext_get_access 0 63642 NULL
+proc_loginuid_write_63648 proc_loginuid_write 3 63648 NULL
+nand_ecc_test_63654 nand_ecc_test 1 63654 NULL
+hidraw_ioctl_63658 hidraw_ioctl 2 63658 NULL
+iwl4965_rs_sta_dbgfs_scale_table_read_63672 iwl4965_rs_sta_dbgfs_scale_table_read 3 63672 NULL
+bin_search_63697 bin_search 0 63697 NULL
+btrfs_insert_delayed_dir_index_63720 btrfs_insert_delayed_dir_index 4 63720 NULL
+nfs4_reset_slot_table_63721 nfs4_reset_slot_table 2 63721 NULL
+i915_gem_execbuffer_relocate_63728 i915_gem_execbuffer_relocate 0 63728 NULL
+selinux_secctx_to_secid_63744 selinux_secctx_to_secid 2 63744 NULL
+i915_gem_execbuffer_flush_63749 i915_gem_execbuffer_flush 0 63749 NULL
+snd_pcm_oss_read1_63771 snd_pcm_oss_read1 3 63771 NULL
+snd_opl4_mem_proc_read_63774 snd_opl4_mem_proc_read 5 63774 NULL
+spidev_compat_ioctl_63778 spidev_compat_ioctl 2 63778 NULL
+mwifiex_11n_create_rx_reorder_tbl_63806 mwifiex_11n_create_rx_reorder_tbl 4 63806 NULL
+copy_nodes_to_user_63807 copy_nodes_to_user 2 63807 NULL
+sel_write_load_63830 sel_write_load 3 63830 NULL
+proc_pid_attr_write_63845 proc_pid_attr_write 3 63845 NULL
+ieee80211_if_fmt_channel_type_63855 ieee80211_if_fmt_channel_type 3 63855 NULL
+init_map_ipmac_63896 init_map_ipmac 4-3 63896 NULL
+xhci_alloc_stream_info_63902 xhci_alloc_stream_info 3 63902 NULL
+uvc_alloc_urb_buffers_63922 uvc_alloc_urb_buffers 0-2-3 63922 NULL
+tipc_send2port_63935 tipc_send2port 5 63935 NULL
+afs_send_simple_reply_63940 afs_send_simple_reply 3 63940 NULL
+macvtap_recvmsg_63949 macvtap_recvmsg 4 63949 NULL
+read_file_frameerrors_64001 read_file_frameerrors 3 64001 NULL
+kmemdup_64015 kmemdup 2 64015 NULL
+tcf_csum_skb_nextlayer_64025 tcf_csum_skb_nextlayer 3 64025 NULL
+dbAllocDmapLev_64030 dbAllocDmapLev 0 64030 NULL
+frequency_read_64031 frequency_read 3 64031 NULL
+sl_realloc_bufs_64086 sl_realloc_bufs 2 64086 NULL
+lbs_highrssi_read_64089 lbs_highrssi_read 3 64089 NULL
+do_load_xattr_datum_64118 do_load_xattr_datum 0 64118 NULL
+ol_quota_entries_per_block_64122 ol_quota_entries_per_block 0 64122 NULL
+i915_gem_execbuffer_reserve_64127 i915_gem_execbuffer_reserve 0 64127 NULL
+init_bch_64130 init_bch 1-2 64130 NULL
+uea_idma_write_64139 uea_idma_write 3 64139 NULL
+ablkcipher_copy_iv_64140 ablkcipher_copy_iv 3 64140 NULL
+cpumask_scnprintf_64170 cpumask_scnprintf 2 64170 NULL
+alloc_session_64171 alloc_session 2-1 64171 NULL
+ea_len_64229 ea_len 0 64229 NULL
+header_len_64232 header_len 0 64232 NULL
+xfrm_acquire_msgsize_64239 xfrm_acquire_msgsize 0 64239 NULL
+fuse_do_getattr_64245 fuse_do_getattr 0 64245 NULL
+io_capture_transfer_64276 io_capture_transfer 4 64276 NULL
+btrfs_file_extent_offset_64278 btrfs_file_extent_offset 0 64278 NULL
+xfs_dir_cilookup_result_64288 xfs_dir_cilookup_result 3 64288 NULL nohasharray
+event_id_read_64288 event_id_read 3 64288 &xfs_dir_cilookup_result_64288
+ocfs2_block_check_validate_bhs_64302 ocfs2_block_check_validate_bhs 0 64302 NULL
+snd_hda_get_sub_nodes_64304 snd_hda_get_sub_nodes 0 64304 NULL
+sisusbcon_clear_64329 sisusbcon_clear 4-3-5 64329 NULL
+usbtmc_write_64340 usbtmc_write 3 64340 NULL
+user_regset_copyin_64360 user_regset_copyin 7 64360 NULL
+llc_alloc_frame_64366 llc_alloc_frame 4 64366 NULL
+ilo_write_64378 ilo_write 3 64378 NULL
+ir_lirc_transmit_ir_64403 ir_lirc_transmit_ir 3 64403 NULL
+pidlist_allocate_64404 pidlist_allocate 1 64404 NULL
+snd_card_create_64418 snd_card_create 4 64418 NULL nohasharray
+keyctl_get_security_64418 keyctl_get_security 3 64418 &snd_card_create_64418
+ax25_recvmsg_64441 ax25_recvmsg 4 64441 NULL
+pfkey_sockaddr_len_64453 pfkey_sockaddr_len 0 64453 NULL
+ip_vs_create_timeout_table_64478 ip_vs_create_timeout_table 2 64478 NULL
+alloc_large_system_hash_64490 alloc_large_system_hash 2 64490 NULL
+p54_parse_rssical_64493 p54_parse_rssical 3 64493 NULL
+emulator_cmpxchg_emulated_64501 emulator_cmpxchg_emulated 5 64501 NULL
+msg_data_sz_64503 msg_data_sz 0 64503 NULL
+crypto_blkcipher_alignmask_64520 crypto_blkcipher_alignmask 0 64520 NULL
+iwl_dbgfs_ucode_tracing_write_64524 iwl_dbgfs_ucode_tracing_write 3 64524 NULL
+ses_send_diag_64527 ses_send_diag 4 64527 NULL
+lm8323_read_64547 lm8323_read 4 64547 NULL
+__spi_sync_64561 __spi_sync 0 64561 NULL
+__apei_exec_run_64563 __apei_exec_run 0 64563 NULL
+diva_os_alloc_message_buffer_64568 diva_os_alloc_message_buffer 1 64568 NULL
+kstrtoul_from_user_64569 kstrtoul_from_user 2 64569 NULL
+use_pool_64607 use_pool 2 64607 NULL
+fanotify_write_64623 fanotify_write 3 64623 NULL
+ocfs2_read_xattr_block_64661 ocfs2_read_xattr_block 0 64661 NULL
+nr_free_zone_pages_64680 nr_free_zone_pages 0 64680 NULL
+ip_select_ident_more_64707 ip_select_ident_more 4 64707 NULL
+__feat_register_sp_64712 __feat_register_sp 6 64712 NULL
+snd_pcm_oss_capture_position_fixup_64713 snd_pcm_oss_capture_position_fixup 0 64713 NULL
+dapm_bias_read_file_64715 dapm_bias_read_file 3 64715 NULL
+atomic_add_return_64720 atomic_add_return 0-1 64720 NULL
+i2400m_msg_to_dev_64722 i2400m_msg_to_dev 3 64722 NULL
+AscGetChipVersion_64737 AscGetChipVersion 0 64737 NULL
+squashfs_read_inode_lookup_table_64739 squashfs_read_inode_lookup_table 4 64739 NULL
+bio_map_kern_64751 bio_map_kern 3 64751 NULL
+rt2x00debug_write_csr_64753 rt2x00debug_write_csr 3 64753 NULL
+nfsctl_transaction_write_64800 nfsctl_transaction_write 3 64800 NULL
+rfkill_fop_write_64808 rfkill_fop_write 3 64808 NULL
+megaraid_change_queue_depth_64815 megaraid_change_queue_depth 2 64815 NULL
+ecryptfs_send_miscdev_64816 ecryptfs_send_miscdev 2 64816 NULL
+do_kimage_alloc_64827 do_kimage_alloc 3 64827 NULL
+altera_set_dr_pre_64862 altera_set_dr_pre 2 64862 NULL
+ffs_epfile_io_64886 ffs_epfile_io 3 64886 NULL
+ieee80211_if_read_ave_beacon_64924 ieee80211_if_read_ave_beacon 3 64924 NULL
+ip_options_get_from_user_64958 ip_options_get_from_user 4 64958 NULL
+pskb_pull_65005 pskb_pull 2 65005 NULL
+crypto_ahash_digestsize_65014 crypto_ahash_digestsize 0 65014 NULL
+insert_dent_65034 insert_dent 7 65034 NULL
+brcmf_sdcard_rwdata_65041 brcmf_sdcard_rwdata 5 65041 NULL
+ath9k_multi_regread_65056 ath9k_multi_regread 4 65056 NULL
+pcibios_enable_device_65059 pcibios_enable_device 0 65059 NULL
+bnx2fc_process_l2_frame_compl_65072 bnx2fc_process_l2_frame_compl 3 65072 NULL
+__alloc_bootmem_node_high_65076 __alloc_bootmem_node_high 2 65076 NULL
+ocfs2_truncate_cluster_pages_65086 ocfs2_truncate_cluster_pages 2 65086 NULL
+nf_bridge_mtu_reduction_65192 nf_bridge_mtu_reduction 0 65192 NULL
+nfulnl_alloc_skb_65207 nfulnl_alloc_skb 2-1 65207 NULL
+whci_n_caps_65247 whci_n_caps 0 65247 NULL
+kmalloc_parameter_65279 kmalloc_parameter 1 65279 NULL
+compat_core_sys_select_65285 compat_core_sys_select 1 65285 NULL
+redirected_tty_write_65297 redirected_tty_write 3 65297 NULL
+get_var_len_65304 get_var_len 0 65304 NULL
+unpack_array_65318 unpack_array 0 65318 NULL
+dccp_setsockopt_service_65336 dccp_setsockopt_service 4 65336 NULL
+alloc_cpu_rmap_65363 alloc_cpu_rmap 1 65363 NULL
+__alloc_bootmem_nopanic_65397 __alloc_bootmem_nopanic 1 65397 NULL
+trace_seq_to_user_65398 trace_seq_to_user 3 65398 NULL
+usb_ep_enable_65405 usb_ep_enable 0 65405 NULL
+ocfs2_write_begin_nolock_65410 ocfs2_write_begin_nolock 4-3 65410 NULL
+drm_calloc_large_65421 drm_calloc_large 1-2 65421 NULL
+device_add_groups_65423 device_add_groups 0 65423 NULL
+xpc_kzalloc_cacheline_aligned_65433 xpc_kzalloc_cacheline_aligned 1 65433 NULL
+usb_alloc_coherent_65444 usb_alloc_coherent 2 65444 NULL
+clear_user_65470 clear_user 2 65470 NULL
+ath_rx_edma_init_65483 ath_rx_edma_init 2 65483 NULL
+alloc_dr_65495 alloc_dr 2 65495 NULL
+selnl_msglen_65499 selnl_msglen 0 65499 NULL
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/size_overflow_plugin.c linux-3.2.71-pax/tools/gcc/size_overflow_plugin/size_overflow_plugin.c
--- linux-3.2.71/tools/gcc/size_overflow_plugin/size_overflow_plugin.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/size_overflow_plugin.c	2014-07-27 23:41:39.593093822 +0200
@@ -0,0 +1,259 @@
+/*
+ * Copyright 2011-2014 by Emese Revfy <re.emese@gmail.com>
+ * Licensed under the GPL v2, or (at your option) v3
+ *
+ * Homepage:
+ * http://www.grsecurity.net/~ephox/overflow_plugin/
+ *
+ * Documentation:
+ * http://forums.grsecurity.net/viewtopic.php?f=7&t=3043
+ *
+ * This plugin recomputes expressions of function arguments marked by a size_overflow attribute
+ * with double integer precision (DImode/TImode for 32/64 bit integer types).
+ * The recomputed argument is checked against TYPE_MAX and an event is logged on overflow and the triggering process is killed.
+ *
+ * Usage:
+ * $ make
+ * $ make run
+ */
+
+#include "gcc-common.h"
+#include "size_overflow.h"
+
+int plugin_is_GPL_compatible;
+
+tree report_size_overflow_decl;
+
+tree size_overflow_type_HI;
+tree size_overflow_type_SI;
+tree size_overflow_type_DI;
+tree size_overflow_type_TI;
+
+static struct plugin_info size_overflow_plugin_info = {
+	.version	= "20140725",
+	.help		= "no-size-overflow\tturn off size overflow checking\n",
+};
+
+static tree handle_size_overflow_attribute(tree *node, tree __unused name, tree args, int __unused flags, bool *no_add_attrs)
+{
+	unsigned int arg_count;
+	enum tree_code code = TREE_CODE(*node);
+
+	switch (code) {
+	case FUNCTION_DECL:
+		arg_count = type_num_arguments(TREE_TYPE(*node));
+		break;
+	case FUNCTION_TYPE:
+	case METHOD_TYPE:
+		arg_count = type_num_arguments(*node);
+		break;
+	default:
+		*no_add_attrs = true;
+		error("%s: %qE attribute only applies to functions", __func__, name);
+		return NULL_TREE;
+	}
+
+	for (; args; args = TREE_CHAIN(args)) {
+		tree position = TREE_VALUE(args);
+		if (TREE_CODE(position) != INTEGER_CST || TREE_INT_CST_LOW(position) > arg_count ) {
+			error("%s: parameter %u is outside range.", __func__, (unsigned int)TREE_INT_CST_LOW(position));
+			*no_add_attrs = true;
+		}
+	}
+	return NULL_TREE;
+}
+
+static tree handle_intentional_overflow_attribute(tree *node, tree __unused name, tree args, int __unused flags, bool *no_add_attrs)
+{
+	unsigned int arg_count;
+	enum tree_code code = TREE_CODE(*node);
+
+	switch (code) {
+	case FUNCTION_DECL:
+		arg_count = type_num_arguments(TREE_TYPE(*node));
+		break;
+	case FUNCTION_TYPE:
+	case METHOD_TYPE:
+		arg_count = type_num_arguments(*node);
+		break;
+	case FIELD_DECL:
+		return NULL_TREE;
+	default:
+		*no_add_attrs = true;
+		error("%qE attribute only applies to functions", name);
+		return NULL_TREE;
+	}
+
+	if (TREE_INT_CST_HIGH(TREE_VALUE(args)) != 0)
+		return NULL_TREE;
+
+	for (; args; args = TREE_CHAIN(args)) {
+		tree position = TREE_VALUE(args);
+		if (TREE_CODE(position) != INTEGER_CST || TREE_INT_CST_LOW(position) > arg_count ) {
+			error("%s: parameter %u is outside range.", __func__, (unsigned int)TREE_INT_CST_LOW(position));
+			*no_add_attrs = true;
+		}
+	}
+	return NULL_TREE;
+}
+
+static struct attribute_spec size_overflow_attr = {
+	.name				= "size_overflow",
+	.min_length			= 1,
+	.max_length			= -1,
+	.decl_required			= true,
+	.type_required			= false,
+	.function_type_required		= false,
+	.handler			= handle_size_overflow_attribute,
+#if BUILDING_GCC_VERSION >= 4007
+	.affects_type_identity		= false
+#endif
+};
+
+static struct attribute_spec intentional_overflow_attr = {
+	.name				= "intentional_overflow",
+	.min_length			= 1,
+	.max_length			= -1,
+	.decl_required			= true,
+	.type_required			= false,
+	.function_type_required		= false,
+	.handler			= handle_intentional_overflow_attribute,
+#if BUILDING_GCC_VERSION >= 4007
+	.affects_type_identity		= false
+#endif
+};
+
+static void register_attributes(void __unused *event_data, void __unused *data)
+{
+	register_attribute(&size_overflow_attr);
+	register_attribute(&intentional_overflow_attr);
+}
+
+static tree create_typedef(tree type, const char* ident)
+{
+	tree new_type, decl;
+
+	new_type = build_variant_type_copy(type);
+	decl = build_decl(BUILTINS_LOCATION, TYPE_DECL, get_identifier(ident), new_type);
+	DECL_ORIGINAL_TYPE(decl) = type;
+	TYPE_NAME(new_type) = decl;
+	return new_type;
+}
+
+// Create the noreturn report_size_overflow() function decl.
+static void size_overflow_start_unit(void __unused *gcc_data, void __unused *user_data)
+{
+	tree const_char_ptr_type_node;
+	tree fntype;
+
+	const_char_ptr_type_node = build_pointer_type(build_type_variant(char_type_node, 1, 0));
+
+	size_overflow_type_HI = create_typedef(intHI_type_node, "size_overflow_type_HI");
+	size_overflow_type_SI = create_typedef(intSI_type_node, "size_overflow_type_SI");
+	size_overflow_type_DI = create_typedef(intDI_type_node, "size_overflow_type_DI");
+	size_overflow_type_TI = create_typedef(intTI_type_node, "size_overflow_type_TI");
+
+	// void report_size_overflow(const char *loc_file, unsigned int loc_line, const char *current_func, const char *ssa_var)
+	fntype = build_function_type_list(void_type_node,
+					  const_char_ptr_type_node,
+					  unsigned_type_node,
+					  const_char_ptr_type_node,
+					  const_char_ptr_type_node,
+					  NULL_TREE);
+	report_size_overflow_decl = build_fn_decl("report_size_overflow", fntype);
+
+	DECL_ASSEMBLER_NAME(report_size_overflow_decl);
+	TREE_PUBLIC(report_size_overflow_decl) = 1;
+	DECL_EXTERNAL(report_size_overflow_decl) = 1;
+	DECL_ARTIFICIAL(report_size_overflow_decl) = 1;
+	TREE_THIS_VOLATILE(report_size_overflow_decl) = 1;
+}
+
+
+extern struct gimple_opt_pass pass_dce;
+
+static struct opt_pass *make_dce_pass(void)
+{
+#if BUILDING_GCC_VERSION >= 4009
+	return make_pass_dce(g);
+#else
+	return &pass_dce.pass;
+#endif
+}
+
+
+int plugin_init(struct plugin_name_args *plugin_info, struct plugin_gcc_version *version)
+{
+	int i;
+	const char * const plugin_name = plugin_info->base_name;
+	const int argc = plugin_info->argc;
+	const struct plugin_argument * const argv = plugin_info->argv;
+	bool enable = true;
+	struct register_pass_info insert_size_overflow_asm_pass_info;
+	struct register_pass_info __unused dump_before_pass_info;
+	struct register_pass_info __unused dump_after_pass_info;
+	struct register_pass_info insert_size_overflow_check_info;
+	struct register_pass_info dce_pass_info;
+	static const struct ggc_root_tab gt_ggc_r_gt_size_overflow[] = {
+		{
+			.base = &report_size_overflow_decl,
+			.nelt = 1,
+			.stride = sizeof(report_size_overflow_decl),
+			.cb = &gt_ggc_mx_tree_node,
+			.pchw = &gt_pch_nx_tree_node
+		},
+		LAST_GGC_ROOT_TAB
+	};
+
+	insert_size_overflow_asm_pass_info.pass				= make_insert_size_overflow_asm_pass();
+	insert_size_overflow_asm_pass_info.reference_pass_name		= "ssa";
+	insert_size_overflow_asm_pass_info.ref_pass_instance_number	= 1;
+	insert_size_overflow_asm_pass_info.pos_op			= PASS_POS_INSERT_AFTER;
+
+	dump_before_pass_info.pass			= make_dump_pass();
+	dump_before_pass_info.reference_pass_name	= "increase_alignment";
+	dump_before_pass_info.ref_pass_instance_number	= 1;
+	dump_before_pass_info.pos_op			= PASS_POS_INSERT_BEFORE;
+
+	insert_size_overflow_check_info.pass			= make_insert_size_overflow_check();
+	insert_size_overflow_check_info.reference_pass_name	= "increase_alignment";
+	insert_size_overflow_check_info.ref_pass_instance_number	= 1;
+	insert_size_overflow_check_info.pos_op			= PASS_POS_INSERT_BEFORE;
+
+	dump_after_pass_info.pass			= make_dump_pass();
+	dump_after_pass_info.reference_pass_name	= "increase_alignment";
+	dump_after_pass_info.ref_pass_instance_number	= 1;
+	dump_after_pass_info.pos_op			= PASS_POS_INSERT_BEFORE;
+
+	dce_pass_info.pass				= make_dce_pass();
+	dce_pass_info.reference_pass_name		= "vrp";
+	dce_pass_info.ref_pass_instance_number	= 1;
+	dce_pass_info.pos_op			= PASS_POS_INSERT_AFTER;
+
+	if (!plugin_default_version_check(version, &gcc_version)) {
+		error(G_("incompatible gcc/plugin versions"));
+		return 1;
+	}
+
+	for (i = 0; i < argc; ++i) {
+		if (!strcmp(argv[i].key, "no-size-overflow")) {
+			enable = false;
+			continue;
+		}
+		error(G_("unkown option '-fplugin-arg-%s-%s'"), plugin_name, argv[i].key);
+	}
+
+	register_callback(plugin_name, PLUGIN_INFO, NULL, &size_overflow_plugin_info);
+	if (enable) {
+		register_callback(plugin_name, PLUGIN_START_UNIT, &size_overflow_start_unit, NULL);
+		register_callback(plugin_name, PLUGIN_REGISTER_GGC_ROOTS, NULL, (void *)&gt_ggc_r_gt_size_overflow);
+		register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &insert_size_overflow_asm_pass_info);
+//		register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &dump_before_pass_info);
+		register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &insert_size_overflow_check_info);
+//		register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &dump_after_pass_info);
+		register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &dce_pass_info);
+	}
+	register_callback(plugin_name, PLUGIN_ATTRIBUTES, register_attributes, NULL);
+
+	return 0;
+}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/size_overflow_plugin/size_overflow_plugin_hash.c linux-3.2.71-pax/tools/gcc/size_overflow_plugin/size_overflow_plugin_hash.c
--- linux-3.2.71/tools/gcc/size_overflow_plugin/size_overflow_plugin_hash.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/size_overflow_plugin/size_overflow_plugin_hash.c	2014-06-02 18:46:28.282285436 +0200
@@ -0,0 +1,364 @@
+/*
+ * Copyright 2011-2014 by Emese Revfy <re.emese@gmail.com>
+ * Licensed under the GPL v2, or (at your option) v3
+ *
+ * Homepage:
+ * http://www.grsecurity.net/~ephox/overflow_plugin/
+ *
+ * Documentation:
+ * http://forums.grsecurity.net/viewtopic.php?f=7&t=3043
+ *
+ * This plugin recomputes expressions of function arguments marked by a size_overflow attribute
+ * with double integer precision (DImode/TImode for 32/64 bit integer types).
+ * The recomputed argument is checked against TYPE_MAX and an event is logged on overflow and the triggering process is killed.
+ *
+ * Usage:
+ * $ make
+ * $ make run
+ */
+
+#include "gcc-common.h"
+#include "size_overflow.h"
+
+#include "size_overflow_hash.h"
+#include "size_overflow_hash_aux.h"
+
+#define CODES_LIMIT 32
+
+static unsigned char get_tree_code(const_tree type)
+{
+	switch (TREE_CODE(type)) {
+	case ARRAY_TYPE:
+		return 0;
+	case BOOLEAN_TYPE:
+		return 1;
+	case ENUMERAL_TYPE:
+		return 2;
+	case FUNCTION_TYPE:
+		return 3;
+	case INTEGER_TYPE:
+		return 4;
+	case POINTER_TYPE:
+		return 5;
+	case RECORD_TYPE:
+		return 6;
+	case UNION_TYPE:
+		return 7;
+	case VOID_TYPE:
+		return 8;
+	case REAL_TYPE:
+		return 9;
+	case VECTOR_TYPE:
+		return 10;
+	case REFERENCE_TYPE:
+		return 11;
+	case OFFSET_TYPE:
+		return 12;
+	case COMPLEX_TYPE:
+		return 13;
+	default:
+		debug_tree((tree)type);
+		gcc_unreachable();
+	}
+}
+
+struct function_hash {
+	size_t tree_codes_len;
+	unsigned char tree_codes[CODES_LIMIT];
+	const_tree fndecl;
+	unsigned int hash;
+};
+
+// http://www.team5150.com/~andrew/noncryptohashzoo2~/CrapWow.html
+static unsigned int CrapWow(const char *key, unsigned int len, unsigned int seed)
+{
+#define cwfold( a, b, lo, hi ) { p = (unsigned int)(a) * (unsigned long long)(b); lo ^= (unsigned int)p; hi ^= (unsigned int)(p >> 32); }
+#define cwmixa( in ) { cwfold( in, m, k, h ); }
+#define cwmixb( in ) { cwfold( in, n, h, k ); }
+
+	unsigned int m = 0x57559429;
+	unsigned int n = 0x5052acdb;
+	const unsigned int *key4 = (const unsigned int *)key;
+	unsigned int h = len;
+	unsigned int k = len + seed + n;
+	unsigned long long p;
+
+	while (len >= 8) {
+		cwmixb(key4[0]) cwmixa(key4[1]) key4 += 2;
+		len -= 8;
+	}
+	if (len >= 4) {
+		cwmixb(key4[0]) key4 += 1;
+		len -= 4;
+	}
+	if (len)
+		cwmixa(key4[0] & ((1 << (len * 8)) - 1 ));
+	cwmixb(h ^ (k + n));
+	return k ^ h;
+
+#undef cwfold
+#undef cwmixa
+#undef cwmixb
+}
+
+static void set_hash(const char *fn_name, struct function_hash *fn_hash_data)
+{
+	unsigned int fn, codes, seed = 0;
+
+	fn = CrapWow(fn_name, strlen(fn_name), seed) & 0xffff;
+	codes = CrapWow((const char*)fn_hash_data->tree_codes, fn_hash_data->tree_codes_len, seed) & 0xffff;
+
+	fn_hash_data->hash = fn ^ codes;
+}
+
+static void set_node_codes(const_tree type, struct function_hash *fn_hash_data)
+{
+	gcc_assert(type != NULL_TREE);
+	gcc_assert(TREE_CODE_CLASS(TREE_CODE(type)) == tcc_type);
+
+	while (type && fn_hash_data->tree_codes_len < CODES_LIMIT) {
+		fn_hash_data->tree_codes[fn_hash_data->tree_codes_len] = get_tree_code(type);
+		fn_hash_data->tree_codes_len++;
+		type = TREE_TYPE(type);
+	}
+}
+
+static void set_result_codes(const_tree node, struct function_hash *fn_hash_data)
+{
+	const_tree result;
+
+	gcc_assert(node != NULL_TREE);
+
+	if (DECL_P(node)) {
+		result = DECL_RESULT(node);
+		if (result != NULL_TREE)
+			return set_node_codes(TREE_TYPE(result), fn_hash_data);
+		return set_result_codes(TREE_TYPE(node), fn_hash_data);
+	}
+
+	gcc_assert(TYPE_P(node));
+
+	if (TREE_CODE(node) == FUNCTION_TYPE)
+		return set_result_codes(TREE_TYPE(node), fn_hash_data);
+
+	return set_node_codes(node, fn_hash_data);
+}
+
+static void set_function_codes(struct function_hash *fn_hash_data)
+{
+	const_tree arg, type = TREE_TYPE(fn_hash_data->fndecl);
+	enum tree_code code = TREE_CODE(type);
+
+	gcc_assert(code == FUNCTION_TYPE || code == METHOD_TYPE);
+
+	set_result_codes(fn_hash_data->fndecl, fn_hash_data);
+
+	for (arg = TYPE_ARG_TYPES(type); arg != NULL_TREE && fn_hash_data->tree_codes_len < CODES_LIMIT; arg = TREE_CHAIN(arg))
+		set_node_codes(TREE_VALUE(arg), fn_hash_data);
+}
+
+static const struct size_overflow_hash *get_proper_hash_chain(const struct size_overflow_hash *entry, const char *func_name)
+{
+	while (entry) {
+		if (!strcmp(entry->name, func_name))
+			return entry;
+		entry = entry->next;
+	}
+	return NULL;
+}
+
+const struct size_overflow_hash *get_function_hash(const_tree fndecl)
+{
+	const struct size_overflow_hash *entry;
+	struct function_hash fn_hash_data;
+	const char *func_name;
+
+	// skip builtins __builtin_constant_p
+	if (DECL_BUILT_IN(fndecl))
+		return NULL;
+
+	fn_hash_data.fndecl = fndecl;
+	fn_hash_data.tree_codes_len = 0;
+
+	set_function_codes(&fn_hash_data);
+	gcc_assert(fn_hash_data.tree_codes_len != 0);
+
+	func_name = DECL_NAME_POINTER(fn_hash_data.fndecl);
+	set_hash(func_name, &fn_hash_data);
+
+	entry = size_overflow_hash[fn_hash_data.hash];
+	entry = get_proper_hash_chain(entry, func_name);
+	if (entry)
+		return entry;
+	entry = size_overflow_hash_aux[fn_hash_data.hash];
+	return get_proper_hash_chain(entry, func_name);
+}
+
+static void print_missing_msg(const_tree func, unsigned int argnum)
+{
+	location_t loc;
+	const char *curfunc;
+	struct function_hash fn_hash_data;
+
+	fn_hash_data.fndecl = DECL_ORIGIN(func);
+	fn_hash_data.tree_codes_len = 0;
+
+	loc = DECL_SOURCE_LOCATION(fn_hash_data.fndecl);
+	curfunc = DECL_NAME_POINTER(fn_hash_data.fndecl);
+
+	set_function_codes(&fn_hash_data);
+	set_hash(curfunc, &fn_hash_data);
+
+	inform(loc, "Function %s is missing from the size_overflow hash table +%s+%u+%u+", curfunc, curfunc, argnum, fn_hash_data.hash);
+}
+
+unsigned int find_arg_number_tree(const_tree arg, const_tree func)
+{
+	tree var;
+	unsigned int argnum = 1;
+
+	if (TREE_CODE(arg) == SSA_NAME)
+		arg = SSA_NAME_VAR(arg);
+
+	for (var = DECL_ARGUMENTS(func); var; var = TREE_CHAIN(var), argnum++) {
+		if (!operand_equal_p(arg, var, 0) && strcmp(DECL_NAME_POINTER(var), DECL_NAME_POINTER(arg)))
+			continue;
+		if (!skip_types(var))
+			return argnum;
+	}
+
+	return CANNOT_FIND_ARG;
+}
+
+static const char *get_asm_string(const_gimple stmt)
+{
+	if (!stmt)
+		return NULL;
+	if (gimple_code(stmt) != GIMPLE_ASM)
+		return NULL;
+
+	return gimple_asm_string(stmt);
+}
+
+bool is_size_overflow_intentional_asm_turn_off(const_gimple stmt)
+{
+	const char *str;
+
+	str = get_asm_string(stmt);
+	if (!str)
+		return false;
+	return !strncmp(str, TURN_OFF_ASM_STR, sizeof(TURN_OFF_ASM_STR) - 1);
+}
+
+bool is_size_overflow_intentional_asm_yes(const_gimple stmt)
+{
+	const char *str;
+
+	str = get_asm_string(stmt);
+	if (!str)
+		return false;
+	return !strncmp(str, YES_ASM_STR, sizeof(YES_ASM_STR) - 1);
+}
+
+bool is_size_overflow_asm(const_gimple stmt)
+{
+	const char *str;
+
+	str = get_asm_string(stmt);
+	if (!str)
+		return false;
+	return !strncmp(str, OK_ASM_STR, sizeof(OK_ASM_STR) - 1);
+}
+
+bool is_a_return_check(const_tree node)
+{
+	if (TREE_CODE(node) == FUNCTION_DECL)
+		return true;
+
+	gcc_assert(TREE_CODE(node) == PARM_DECL);
+	return false;
+}
+
+// Get the argnum of a function decl, if node is a return then the argnum is 0
+unsigned int get_function_num(const_tree node, const_tree orig_fndecl)
+{
+	if (is_a_return_check(node))
+		return 0;
+	else
+		return find_arg_number_tree(node, orig_fndecl);
+}
+
+unsigned int get_correct_arg_count(unsigned int argnum, const_tree fndecl)
+{
+	const struct size_overflow_hash *hash;
+	unsigned int new_argnum;
+	tree arg;
+	const_tree origarg;
+
+	if (argnum == 0)
+		return argnum;
+
+	hash = get_function_hash(fndecl);
+	if (hash && hash->param & (1U << argnum))
+		return argnum;
+
+	if (DECL_EXTERNAL(fndecl))
+		return argnum;
+
+	origarg = DECL_ARGUMENTS(DECL_ORIGIN(fndecl));
+	argnum--;
+	while (origarg && argnum) {
+		origarg = TREE_CHAIN(origarg);
+		argnum--;
+	}
+	gcc_assert(argnum == 0);
+	gcc_assert(origarg != NULL_TREE);
+
+	for (arg = DECL_ARGUMENTS(fndecl), new_argnum = 1; arg; arg = TREE_CHAIN(arg), new_argnum++)
+		if (operand_equal_p(origarg, arg, 0) || !strcmp(DECL_NAME_POINTER(origarg), DECL_NAME_POINTER(arg)))
+			return new_argnum;
+
+	return CANNOT_FIND_ARG;
+}
+
+static bool is_in_hash_table(const_tree fndecl, unsigned int num)
+{
+	const struct size_overflow_hash *hash;
+
+	hash = get_function_hash(fndecl);
+	if (hash && (hash->param & (1U << num)))
+		return true;
+	return false;
+}
+
+/* Check if the function has a size_overflow attribute or it is in the size_overflow hash table.
+ * If the function is missing everywhere then print the missing message into stderr.
+ */
+bool is_missing_function(const_tree orig_fndecl, unsigned int num)
+{
+	switch (DECL_FUNCTION_CODE(orig_fndecl)) {
+#if BUILDING_GCC_VERSION >= 4008
+	case BUILT_IN_BSWAP16:
+#endif
+	case BUILT_IN_BSWAP32:
+	case BUILT_IN_BSWAP64:
+	case BUILT_IN_EXPECT:
+	case BUILT_IN_MEMCMP:
+		return false;
+	default:
+		break;
+	}
+
+	// skip test.c
+	if (strcmp(DECL_NAME_POINTER(current_function_decl), "coolmalloc")) {
+		if (lookup_attribute("size_overflow", DECL_ATTRIBUTES(orig_fndecl)))
+			warning(0, "unnecessary size_overflow attribute on: %s\n", DECL_NAME_POINTER(orig_fndecl));
+	}
+
+	if (is_in_hash_table(orig_fndecl, num))
+		return false;
+
+	print_missing_msg(orig_fndecl, num);
+	return true;
+}
+
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/stackleak_plugin.c linux-3.2.71-pax/tools/gcc/stackleak_plugin.c
--- linux-3.2.71/tools/gcc/stackleak_plugin.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/stackleak_plugin.c	2015-07-14 00:12:35.677915370 +0200
@@ -0,0 +1,436 @@
+/*
+ * Copyright 2011-2015 by the PaX Team <pageexec@freemail.hu>
+ * Licensed under the GPL v2
+ *
+ * Note: the choice of the license means that the compilation process is
+ *       NOT 'eligible' as defined by gcc's library exception to the GPL v3,
+ *       but for the kernel it doesn't matter since it doesn't link against
+ *       any of the gcc libraries
+ *
+ * gcc plugin to help implement various PaX features
+ *
+ * - track lowest stack pointer
+ *
+ * TODO:
+ * - initialize all local variables
+ *
+ * BUGS:
+ * - none known
+ */
+
+#include "gcc-common.h"
+
+int plugin_is_GPL_compatible;
+
+static int track_frame_size = -1;
+static const char track_function[] = "pax_track_stack";
+static const char check_function[] = "pax_check_alloca";
+static GTY(()) tree track_function_decl;
+static GTY(()) tree check_function_decl;
+static bool init_locals;
+
+static struct plugin_info stackleak_plugin_info = {
+	.version	= "201504282245",
+	.help		= "track-lowest-sp=nn\ttrack sp in functions whose frame size is at least nn bytes\n"
+//			  "initialize-locals\t\tforcibly initialize all stack frames\n"
+};
+
+static void stackleak_check_alloca(gimple_stmt_iterator *gsi)
+{
+	gimple stmt;
+	gcall *check_alloca;
+	tree alloca_size;
+	cgraph_node_ptr node;
+	int frequency;
+	basic_block bb;
+
+	// insert call to void pax_check_alloca(unsigned long size)
+	alloca_size = gimple_call_arg(gsi_stmt(*gsi), 0);
+	stmt = gimple_build_call(check_function_decl, 1, alloca_size);
+	check_alloca = as_a_gcall(stmt);
+	gsi_insert_before(gsi, check_alloca, GSI_SAME_STMT);
+
+	// update the cgraph
+	bb = gimple_bb(check_alloca);
+	node = cgraph_get_create_node(check_function_decl);
+	gcc_assert(node);
+	frequency = compute_call_stmt_bb_frequency(current_function_decl, bb);
+	cgraph_create_edge(cgraph_get_node(current_function_decl), node, check_alloca, bb->count, frequency, bb->loop_depth);
+}
+
+static void stackleak_add_instrumentation(gimple_stmt_iterator *gsi)
+{
+	gimple stmt;
+	gcall *track_stack;
+	cgraph_node_ptr node;
+	int frequency;
+	basic_block bb;
+
+	// insert call to void pax_track_stack(void)
+	stmt = gimple_build_call(track_function_decl, 0);
+	track_stack = as_a_gcall(stmt);
+	gsi_insert_after(gsi, track_stack, GSI_CONTINUE_LINKING);
+
+	// update the cgraph
+	bb = gimple_bb(track_stack);
+	node = cgraph_get_create_node(track_function_decl);
+	gcc_assert(node);
+	frequency = compute_call_stmt_bb_frequency(current_function_decl, bb);
+	cgraph_create_edge(cgraph_get_node(current_function_decl), node, track_stack, bb->count, frequency, bb->loop_depth);
+}
+
+static bool is_alloca(gimple stmt)
+{
+	if (gimple_call_builtin_p(stmt, BUILT_IN_ALLOCA))
+		return true;
+
+#if BUILDING_GCC_VERSION >= 4007
+	if (gimple_call_builtin_p(stmt, BUILT_IN_ALLOCA_WITH_ALIGN))
+		return true;
+#endif
+
+	return false;
+}
+
+static unsigned int execute_stackleak_tree_instrument(void)
+{
+	basic_block bb, entry_bb;
+	bool prologue_instrumented = false, is_leaf = true;
+
+	entry_bb = ENTRY_BLOCK_PTR_FOR_FN(cfun)->next_bb;
+
+	// 1. loop through BBs and GIMPLE statements
+	FOR_EACH_BB_FN(bb, cfun) {
+		gimple_stmt_iterator gsi;
+
+		for (gsi = gsi_start_bb(bb); !gsi_end_p(gsi); gsi_next(&gsi)) {
+			gimple stmt;
+
+			stmt = gsi_stmt(gsi);
+
+			if (is_gimple_call(stmt))
+				is_leaf = false;
+
+			// gimple match: align 8 built-in BUILT_IN_NORMAL:BUILT_IN_ALLOCA attributes <tree_list 0xb7576450>
+			if (!is_alloca(stmt))
+				continue;
+
+			// 2. insert stack overflow check before each __builtin_alloca call
+			stackleak_check_alloca(&gsi);
+
+			// 3. insert track call after each __builtin_alloca call
+			stackleak_add_instrumentation(&gsi);
+			if (bb == entry_bb)
+				prologue_instrumented = true;
+		}
+	}
+
+	// special cases for some bad linux code: taking the address of static inline functions will materialize them
+	// but we mustn't instrument some of them as the resulting stack alignment required by the function call ABI
+	// will break other assumptions regarding the expected (but not otherwise enforced) register clobbering  ABI.
+	// case in point: native_save_fl on amd64 when optimized for size clobbers rdx if it were instrumented here.
+	if (is_leaf && !TREE_PUBLIC(current_function_decl) && DECL_DECLARED_INLINE_P(current_function_decl))
+		return 0;
+	if (is_leaf && !strncmp(IDENTIFIER_POINTER(DECL_NAME(current_function_decl)), "_paravirt_", 10))
+		return 0;
+
+	// 4. insert track call at the beginning
+	if (!prologue_instrumented) {
+		gimple_stmt_iterator gsi;
+
+		bb = split_block_after_labels(ENTRY_BLOCK_PTR_FOR_FN(cfun))->dest;
+		if (dom_info_available_p(CDI_DOMINATORS))
+			set_immediate_dominator(CDI_DOMINATORS, bb, ENTRY_BLOCK_PTR_FOR_FN(cfun));
+		gsi = gsi_start_bb(bb);
+		stackleak_add_instrumentation(&gsi);
+	}
+
+	return 0;
+}
+
+static unsigned int execute_stackleak_final(void)
+{
+	rtx_insn *insn, *next;
+
+	if (cfun->calls_alloca)
+		return 0;
+
+	// keep calls only if function frame is big enough
+	if (get_frame_size() >= track_frame_size)
+		return 0;
+
+	// 1. find pax_track_stack calls
+	for (insn = get_insns(); insn; insn = next) {
+		// rtl match: (call_insn 8 7 9 3 (call (mem (symbol_ref ("pax_track_stack") [flags 0x41] <function_decl 0xb7470e80 pax_track_stack>) [0 S1 A8]) (4)) -1 (nil) (nil))
+		rtx body;
+
+		next = NEXT_INSN(insn);
+		if (!CALL_P(insn))
+			continue;
+		body = PATTERN(insn);
+		if (GET_CODE(body) != CALL)
+			continue;
+		body = XEXP(body, 0);
+		if (GET_CODE(body) != MEM)
+			continue;
+		body = XEXP(body, 0);
+		if (GET_CODE(body) != SYMBOL_REF)
+			continue;
+//		if (strcmp(XSTR(body, 0), track_function))
+		if (SYMBOL_REF_DECL(body) != track_function_decl)
+			continue;
+//		warning(0, "track_frame_size: %d %ld %d", cfun->calls_alloca, get_frame_size(), track_frame_size);
+		// 2. delete call
+		delete_insn_and_edges(insn);
+#if BUILDING_GCC_VERSION >= 4007
+		if (GET_CODE(next) == NOTE && NOTE_KIND(next) == NOTE_INSN_CALL_ARG_LOCATION) {
+			insn = next;
+			next = NEXT_INSN(insn);
+			delete_insn_and_edges(insn);
+		}
+#endif
+	}
+
+//	print_simple_rtl(stderr, get_insns());
+//	print_rtl(stderr, get_insns());
+//	warning(0, "track_frame_size: %d %ld %d", cfun->calls_alloca, get_frame_size(), track_frame_size);
+
+	return 0;
+}
+
+static bool gate_stackleak_track_stack(void)
+{
+	tree section;
+
+	if (ix86_cmodel != CM_KERNEL)
+		return false;
+
+	section = lookup_attribute("section", DECL_ATTRIBUTES(current_function_decl));
+	if (section && TREE_VALUE(section)) {
+		section = TREE_VALUE(TREE_VALUE(section));
+
+		if (!strncmp(TREE_STRING_POINTER(section), ".init.text", 10))
+			return false;
+		if (!strncmp(TREE_STRING_POINTER(section), ".devinit.text", 13))
+			return false;
+		if (!strncmp(TREE_STRING_POINTER(section), ".cpuinit.text", 13))
+			return false;
+		if (!strncmp(TREE_STRING_POINTER(section), ".meminit.text", 13))
+			return false;
+	}
+
+	return track_frame_size >= 0;
+}
+
+static void stackleak_start_unit(void *gcc_data, void *user_data)
+{
+	tree fntype;
+
+	// void pax_track_stack(void)
+	fntype = build_function_type_list(void_type_node, NULL_TREE);
+	track_function_decl = build_fn_decl(track_function, fntype);
+	DECL_ASSEMBLER_NAME(track_function_decl); // for LTO
+	TREE_PUBLIC(track_function_decl) = 1;
+	TREE_USED(track_function_decl) = 1;
+	DECL_EXTERNAL(track_function_decl) = 1;
+	DECL_ARTIFICIAL(track_function_decl) = 1;
+	DECL_PRESERVE_P(track_function_decl) = 1;
+
+	// void pax_check_alloca(unsigned long)
+	fntype = build_function_type_list(void_type_node, long_unsigned_type_node, NULL_TREE);
+	check_function_decl = build_fn_decl(check_function, fntype);
+	DECL_ASSEMBLER_NAME(check_function_decl); // for LTO
+	TREE_PUBLIC(check_function_decl) = 1;
+	TREE_USED(check_function_decl) = 1;
+	DECL_EXTERNAL(check_function_decl) = 1;
+	DECL_ARTIFICIAL(check_function_decl) = 1;
+	DECL_PRESERVE_P(check_function_decl) = 1;
+}
+
+#if BUILDING_GCC_VERSION >= 4009
+namespace {
+static const struct pass_data stackleak_tree_instrument_pass_data = {
+#else
+static struct gimple_opt_pass stackleak_tree_instrument_pass = {
+	.pass = {
+#endif
+		.type			= GIMPLE_PASS,
+		.name			= "stackleak_tree_instrument",
+#if BUILDING_GCC_VERSION >= 4008
+		.optinfo_flags		= OPTGROUP_NONE,
+#endif
+#if BUILDING_GCC_VERSION >= 5000
+#elif BUILDING_GCC_VERSION == 4009
+		.has_gate		= true,
+		.has_execute		= true,
+#else
+		.gate			= gate_stackleak_track_stack,
+		.execute		= execute_stackleak_tree_instrument,
+		.sub			= NULL,
+		.next			= NULL,
+		.static_pass_number	= 0,
+#endif
+		.tv_id			= TV_NONE,
+		.properties_required	= PROP_gimple_leh | PROP_cfg,
+		.properties_provided	= 0,
+		.properties_destroyed	= 0,
+		.todo_flags_start	= 0, //TODO_verify_ssa | TODO_verify_flow | TODO_verify_stmts,
+		.todo_flags_finish	= TODO_verify_ssa | TODO_verify_stmts | TODO_dump_func | TODO_update_ssa | TODO_rebuild_cgraph_edges
+#if BUILDING_GCC_VERSION < 4009
+	}
+#endif
+};
+
+#if BUILDING_GCC_VERSION >= 4009
+static const struct pass_data stackleak_final_rtl_opt_pass_data = {
+#else
+static struct rtl_opt_pass stackleak_final_rtl_opt_pass = {
+	.pass = {
+#endif
+		.type			= RTL_PASS,
+		.name			= "stackleak_final",
+#if BUILDING_GCC_VERSION >= 4008
+		.optinfo_flags		= OPTGROUP_NONE,
+#endif
+#if BUILDING_GCC_VERSION >= 5000
+#elif BUILDING_GCC_VERSION == 4009
+		.has_gate		= true,
+		.has_execute		= true,
+#else
+		.gate			= gate_stackleak_track_stack,
+		.execute		= execute_stackleak_final,
+		.sub			= NULL,
+		.next			= NULL,
+		.static_pass_number	= 0,
+#endif
+		.tv_id			= TV_NONE,
+		.properties_required	= 0,
+		.properties_provided	= 0,
+		.properties_destroyed	= 0,
+		.todo_flags_start	= 0,
+		.todo_flags_finish	= TODO_dump_func
+#if BUILDING_GCC_VERSION < 4009
+	}
+#endif
+};
+
+#if BUILDING_GCC_VERSION >= 4009
+class stackleak_tree_instrument_pass : public gimple_opt_pass {
+public:
+	stackleak_tree_instrument_pass() : gimple_opt_pass(stackleak_tree_instrument_pass_data, g) {}
+#if BUILDING_GCC_VERSION >= 5000
+	virtual bool gate(function *) { return gate_stackleak_track_stack(); }
+	virtual unsigned int execute(function *) { return execute_stackleak_tree_instrument(); }
+#else
+	bool gate() { return gate_stackleak_track_stack(); }
+	unsigned int execute() { return execute_stackleak_tree_instrument(); }
+#endif
+};
+
+class stackleak_final_rtl_opt_pass : public rtl_opt_pass {
+public:
+	stackleak_final_rtl_opt_pass() : rtl_opt_pass(stackleak_final_rtl_opt_pass_data, g) {}
+#if BUILDING_GCC_VERSION >= 5000
+	virtual bool gate(function *) { return gate_stackleak_track_stack(); }
+	virtual unsigned int execute(function *) { return execute_stackleak_final(); }
+#else
+	bool gate() { return gate_stackleak_track_stack(); }
+	unsigned int execute() { return execute_stackleak_final(); }
+#endif
+};
+}
+
+static opt_pass *make_stackleak_tree_instrument_pass(void)
+{
+	return new stackleak_tree_instrument_pass();
+}
+
+static opt_pass *make_stackleak_final_rtl_opt_pass(void)
+{
+	return new stackleak_final_rtl_opt_pass();
+}
+#else
+static struct opt_pass *make_stackleak_tree_instrument_pass(void)
+{
+	return &stackleak_tree_instrument_pass.pass;
+}
+
+static struct opt_pass *make_stackleak_final_rtl_opt_pass(void)
+{
+	return &stackleak_final_rtl_opt_pass.pass;
+}
+#endif
+
+int plugin_init(struct plugin_name_args *plugin_info, struct plugin_gcc_version *version)
+{
+	const char * const plugin_name = plugin_info->base_name;
+	const int argc = plugin_info->argc;
+	const struct plugin_argument * const argv = plugin_info->argv;
+	int i;
+	struct register_pass_info stackleak_tree_instrument_pass_info;
+	struct register_pass_info stackleak_final_pass_info;
+	static const struct ggc_root_tab gt_ggc_r_gt_stackleak[] = {
+		{
+			.base = &track_function_decl,
+			.nelt = 1,
+			.stride = sizeof(track_function_decl),
+			.cb = &gt_ggc_mx_tree_node,
+			.pchw = &gt_pch_nx_tree_node
+		},
+		{
+			.base = &check_function_decl,
+			.nelt = 1,
+			.stride = sizeof(check_function_decl),
+			.cb = &gt_ggc_mx_tree_node,
+			.pchw = &gt_pch_nx_tree_node
+		},
+		LAST_GGC_ROOT_TAB
+	};
+
+	stackleak_tree_instrument_pass_info.pass			= make_stackleak_tree_instrument_pass();
+//	stackleak_tree_instrument_pass_info.reference_pass_name		= "tree_profile";
+	stackleak_tree_instrument_pass_info.reference_pass_name		= "optimized";
+	stackleak_tree_instrument_pass_info.ref_pass_instance_number	= 1;
+	stackleak_tree_instrument_pass_info.pos_op 			= PASS_POS_INSERT_BEFORE;
+
+	stackleak_final_pass_info.pass				= make_stackleak_final_rtl_opt_pass();
+	stackleak_final_pass_info.reference_pass_name		= "final";
+	stackleak_final_pass_info.ref_pass_instance_number	= 1;
+	stackleak_final_pass_info.pos_op 			= PASS_POS_INSERT_BEFORE;
+
+	if (!plugin_default_version_check(version, &gcc_version)) {
+		error(G_("incompatible gcc/plugin versions"));
+		return 1;
+	}
+
+	register_callback(plugin_name, PLUGIN_INFO, NULL, &stackleak_plugin_info);
+
+	for (i = 0; i < argc; ++i) {
+		if (!strcmp(argv[i].key, "track-lowest-sp")) {
+			if (!argv[i].value) {
+				error(G_("no value supplied for option '-fplugin-arg-%s-%s'"), plugin_name, argv[i].key);
+				continue;
+			}
+			track_frame_size = atoi(argv[i].value);
+			if (argv[i].value[0] < '0' || argv[i].value[0] > '9' || track_frame_size < 0)
+				error(G_("invalid option argument '-fplugin-arg-%s-%s=%s'"), plugin_name, argv[i].key, argv[i].value);
+			continue;
+		}
+		if (!strcmp(argv[i].key, "initialize-locals")) {
+			if (argv[i].value) {
+				error(G_("invalid option argument '-fplugin-arg-%s-%s=%s'"), plugin_name, argv[i].key, argv[i].value);
+				continue;
+			}
+			init_locals = true;
+			continue;
+		}
+		error(G_("unkown option '-fplugin-arg-%s-%s'"), plugin_name, argv[i].key);
+	}
+
+	register_callback(plugin_name, PLUGIN_START_UNIT, &stackleak_start_unit, NULL);
+	register_callback(plugin_name, PLUGIN_REGISTER_GGC_ROOTS, NULL, (void *)&gt_ggc_r_gt_stackleak);
+	register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &stackleak_tree_instrument_pass_info);
+	register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &stackleak_final_pass_info);
+
+	return 0;
+}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/gcc/structleak_plugin.c linux-3.2.71-pax/tools/gcc/structleak_plugin.c
--- linux-3.2.71/tools/gcc/structleak_plugin.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-3.2.71-pax/tools/gcc/structleak_plugin.c	2015-05-17 21:36:39.597244394 +0200
@@ -0,0 +1,287 @@
+/*
+ * Copyright 2013-2015 by PaX Team <pageexec@freemail.hu>
+ * Licensed under the GPL v2
+ *
+ * Note: the choice of the license means that the compilation process is
+ *       NOT 'eligible' as defined by gcc's library exception to the GPL v3,
+ *       but for the kernel it doesn't matter since it doesn't link against
+ *       any of the gcc libraries
+ *
+ * gcc plugin to forcibly initialize certain local variables that could
+ * otherwise leak kernel stack to userland if they aren't properly initialized
+ * by later code
+ *
+ * Homepage: http://pax.grsecurity.net/
+ *
+ * Usage:
+ * $ # for 4.5/4.6/C based 4.7
+ * $ gcc -I`gcc -print-file-name=plugin`/include -I`gcc -print-file-name=plugin`/include/c-family -fPIC -shared -O2 -o structleak_plugin.so structleak_plugin.c
+ * $ # for C++ based 4.7/4.8+
+ * $ g++ -I`g++ -print-file-name=plugin`/include -I`g++ -print-file-name=plugin`/include/c-family -fPIC -shared -O2 -o structleak_plugin.so structleak_plugin.c
+ * $ gcc -fplugin=./structleak_plugin.so test.c -O2
+ *
+ * TODO: eliminate redundant initializers
+ *       increase type coverage
+ */
+
+#include "gcc-common.h"
+
+// unused C type flag in all versions 4.5-5.0
+#define TYPE_USERSPACE(TYPE) TYPE_LANG_FLAG_5(TYPE)
+
+int plugin_is_GPL_compatible;
+
+static struct plugin_info structleak_plugin_info = {
+	.version	= "201401260140",
+	.help		= "disable\tdo not activate plugin\n",
+};
+
+static tree handle_user_attribute(tree *node, tree name, tree args, int flags, bool *no_add_attrs)
+{
+	*no_add_attrs = true;
+
+	// check for types? for now accept everything linux has to offer
+	if (TREE_CODE(*node) != FIELD_DECL)
+		return NULL_TREE;
+
+	*no_add_attrs = false;
+	return NULL_TREE;
+}
+
+static struct attribute_spec user_attr = {
+	.name			= "user",
+	.min_length		= 0,
+	.max_length		= 0,
+	.decl_required		= false,
+	.type_required		= false,
+	.function_type_required	= false,
+	.handler		= handle_user_attribute,
+#if BUILDING_GCC_VERSION >= 4007
+	.affects_type_identity	= true
+#endif
+};
+
+static void register_attributes(void *event_data, void *data)
+{
+	register_attribute(&user_attr);
+//	register_attribute(&force_attr);
+}
+
+static tree get_field_type(tree field)
+{
+	return strip_array_types(TREE_TYPE(field));
+}
+
+static bool is_userspace_type(tree type)
+{
+	tree field;
+
+	for (field = TYPE_FIELDS(type); field; field = TREE_CHAIN(field)) {
+		tree fieldtype = get_field_type(field);
+		enum tree_code code = TREE_CODE(fieldtype);
+
+		if (code == RECORD_TYPE || code == UNION_TYPE)
+			if (is_userspace_type(fieldtype))
+				return true;
+
+		if (lookup_attribute("user", DECL_ATTRIBUTES(field)))
+			return true;
+	}
+	return false;
+}
+
+static void finish_type(void *event_data, void *data)
+{
+	tree type = (tree)event_data;
+
+	if (type == NULL_TREE || type == error_mark_node)
+		return;
+
+#if BUILDING_GCC_VERSION >= 5000
+	if (TREE_CODE(type) == ENUMERAL_TYPE)
+		return;
+#endif
+
+	if (TYPE_USERSPACE(type))
+		return;
+
+	if (is_userspace_type(type))
+		TYPE_USERSPACE(type) = 1;
+}
+
+static void initialize(tree var)
+{
+	basic_block bb;
+	gimple_stmt_iterator gsi;
+	tree initializer;
+	gimple init_stmt;
+
+	// this is the original entry bb before the forced split
+	// TODO: check further BBs in case more splits occured before us
+	bb = ENTRY_BLOCK_PTR_FOR_FN(cfun)->next_bb->next_bb;
+
+	// first check if the variable is already initialized, warn otherwise
+	for (gsi = gsi_start_bb(bb); !gsi_end_p(gsi); gsi_next(&gsi)) {
+		gimple stmt = gsi_stmt(gsi);
+		tree rhs1;
+
+		// we're looking for an assignment of a single rhs...
+		if (!gimple_assign_single_p(stmt))
+			continue;
+		rhs1 = gimple_assign_rhs1(stmt);
+#if BUILDING_GCC_VERSION >= 4007
+		// ... of a non-clobbering expression...
+		if (TREE_CLOBBER_P(rhs1))
+			continue;
+#endif
+		// ... to our variable...
+		if (gimple_get_lhs(stmt) != var)
+			continue;
+		// if it's an initializer then we're good
+		if (TREE_CODE(rhs1) == CONSTRUCTOR)
+			return;
+	}
+
+	// these aren't the 0days you're looking for
+//	inform(DECL_SOURCE_LOCATION(var), "userspace variable will be forcibly initialized");
+
+	// build the initializer expression
+	initializer = build_constructor(TREE_TYPE(var), NULL);
+
+	// build the initializer stmt
+	init_stmt = gimple_build_assign(var, initializer);
+	gsi = gsi_start_bb(ENTRY_BLOCK_PTR_FOR_FN(cfun)->next_bb);
+	gsi_insert_before(&gsi, init_stmt, GSI_NEW_STMT);
+	update_stmt(init_stmt);
+}
+
+static unsigned int handle_function(void)
+{
+	basic_block bb;
+	unsigned int ret = 0;
+	tree var;
+	unsigned int i;
+
+	// split the first bb where we can put the forced initializers
+	bb = split_block_after_labels(ENTRY_BLOCK_PTR_FOR_FN(cfun))->dest;
+	if (dom_info_available_p(CDI_DOMINATORS))
+		set_immediate_dominator(CDI_DOMINATORS, bb, ENTRY_BLOCK_PTR_FOR_FN(cfun));
+
+	// enumarate all local variables and forcibly initialize our targets
+	FOR_EACH_LOCAL_DECL(cfun, i, var) {
+		tree type = TREE_TYPE(var);
+
+		gcc_assert(DECL_P(var));
+		if (!auto_var_in_fn_p(var, current_function_decl))
+			continue;
+
+		// only care about structure types
+		if (TREE_CODE(type) != RECORD_TYPE && TREE_CODE(type) != UNION_TYPE)
+			continue;
+
+		// if the type is of interest, examine the variable
+		if (TYPE_USERSPACE(type))
+			initialize(var);
+	}
+
+	return ret;
+}
+
+#if BUILDING_GCC_VERSION >= 4009
+namespace {
+static const struct pass_data structleak_pass_data = {
+#else
+static struct gimple_opt_pass structleak_pass = {
+	.pass = {
+#endif
+		.type			= GIMPLE_PASS,
+		.name			= "structleak",
+#if BUILDING_GCC_VERSION >= 4008
+		.optinfo_flags		= OPTGROUP_NONE,
+#endif
+#if BUILDING_GCC_VERSION >= 5000
+#elif BUILDING_GCC_VERSION == 4009
+		.has_gate		= false,
+		.has_execute		= true,
+#else
+		.gate			= NULL,
+		.execute		= handle_function,
+		.sub			= NULL,
+		.next			= NULL,
+		.static_pass_number	= 0,
+#endif
+		.tv_id			= TV_NONE,
+		.properties_required	= PROP_cfg,
+		.properties_provided	= 0,
+		.properties_destroyed	= 0,
+		.todo_flags_start	= 0,
+		.todo_flags_finish	= TODO_verify_ssa | TODO_verify_stmts | TODO_dump_func | TODO_remove_unused_locals | TODO_update_ssa | TODO_ggc_collect | TODO_verify_flow
+#if BUILDING_GCC_VERSION < 4009
+	}
+#endif
+};
+
+#if BUILDING_GCC_VERSION >= 4009
+class structleak_pass : public gimple_opt_pass {
+public:
+	structleak_pass() : gimple_opt_pass(structleak_pass_data, g) {}
+#if BUILDING_GCC_VERSION >= 5000
+	virtual unsigned int execute(function *) { return handle_function(); }
+#else
+	unsigned int execute() { return handle_function(); }
+#endif
+};
+}
+
+static opt_pass *make_structleak_pass(void)
+{
+	return new structleak_pass();
+}
+#else
+static struct opt_pass *make_structleak_pass(void)
+{
+	return &structleak_pass.pass;
+}
+#endif
+
+int plugin_init(struct plugin_name_args *plugin_info, struct plugin_gcc_version *version)
+{
+	int i;
+	const char * const plugin_name = plugin_info->base_name;
+	const int argc = plugin_info->argc;
+	const struct plugin_argument * const argv = plugin_info->argv;
+	bool enable = true;
+	struct register_pass_info structleak_pass_info;
+
+	structleak_pass_info.pass			= make_structleak_pass();
+	structleak_pass_info.reference_pass_name	= "ssa";
+	structleak_pass_info.ref_pass_instance_number	= 1;
+	structleak_pass_info.pos_op			= PASS_POS_INSERT_AFTER;
+
+	if (!plugin_default_version_check(version, &gcc_version)) {
+		error(G_("incompatible gcc/plugin versions"));
+		return 1;
+	}
+
+	if (strncmp(lang_hooks.name, "GNU C", 5) && !strncmp(lang_hooks.name, "GNU C+", 6)) {
+		inform(UNKNOWN_LOCATION, G_("%s supports C only"), plugin_name);
+		enable = false;
+	}
+
+	for (i = 0; i < argc; ++i) {
+		if (!strcmp(argv[i].key, "disable")) {
+			enable = false;
+			continue;
+		}
+		error(G_("unkown option '-fplugin-arg-%s-%s'"), plugin_name, argv[i].key);
+	}
+
+	register_callback(plugin_name, PLUGIN_INFO, NULL, &structleak_plugin_info);
+	if (enable) {
+		register_callback(plugin_name, PLUGIN_PASS_MANAGER_SETUP, NULL, &structleak_pass_info);
+		register_callback(plugin_name, PLUGIN_FINISH_TYPE, finish_type, NULL);
+	}
+	register_callback(plugin_name, PLUGIN_ATTRIBUTES, register_attributes, NULL);
+
+	return 0;
+}
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/perf/util/include/asm/alternative-asm.h linux-3.2.71-pax/tools/perf/util/include/asm/alternative-asm.h
--- linux-3.2.71/tools/perf/util/include/asm/alternative-asm.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/tools/perf/util/include/asm/alternative-asm.h	2012-07-04 19:24:49.080063009 +0200
@@ -5,4 +5,7 @@
 
 #define altinstruction_entry #
 
+	.macro pax_force_retaddr rip=0, reload=0
+	.endm
+
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/tools/perf/util/include/linux/compiler.h linux-3.2.71-pax/tools/perf/util/include/linux/compiler.h
--- linux-3.2.71/tools/perf/util/include/linux/compiler.h	2012-07-04 06:44:35.000000000 +0200
+++ linux-3.2.71-pax/tools/perf/util/include/linux/compiler.h	2013-03-28 05:02:23.771764791 +0100
@@ -11,4 +11,12 @@
 
 #define __used		__attribute__((__unused__))
 
+#ifndef __size_overflow
+# define __size_overflow(...)
+#endif
+
+#ifndef __intentional_overflow
+# define __intentional_overflow(...)
+#endif
+
 #endif
diff -NurpX linux-3.2.71-pax/Documentation/dontdiff linux-3.2.71/virt/kvm/kvm_main.c linux-3.2.71-pax/virt/kvm/kvm_main.c
--- linux-3.2.71/virt/kvm/kvm_main.c	2014-12-14 21:13:45.366055386 +0100
+++ linux-3.2.71-pax/virt/kvm/kvm_main.c	2014-12-14 21:13:52.854069374 +0100
@@ -76,12 +76,17 @@ LIST_HEAD(vm_list);
 
 static cpumask_var_t cpus_hardware_enabled;
 static int kvm_usage_count = 0;
-static atomic_t hardware_enable_failed;
+static atomic_unchecked_t hardware_enable_failed;
 
 struct kmem_cache *kvm_vcpu_cache;
 EXPORT_SYMBOL_GPL(kvm_vcpu_cache);
 
-static __read_mostly struct preempt_ops kvm_preempt_ops;
+static void kvm_sched_in(struct preempt_notifier *pn, int cpu);
+static void kvm_sched_out(struct preempt_notifier *pn, struct task_struct *next);
+static struct preempt_ops kvm_preempt_ops = {
+	.sched_in = kvm_sched_in,
+	.sched_out = kvm_sched_out,
+};
 
 struct dentry *kvm_debugfs_dir;
 
@@ -660,7 +665,7 @@ int __kvm_set_memory_region(struct kvm *
 	/* We can read the guest memory with __xxx_user() later on. */
 	if (user_alloc &&
 	    ((mem->userspace_addr & (PAGE_SIZE - 1)) ||
-	     !access_ok(VERIFY_WRITE,
+	     !access_ok_noprefault(VERIFY_WRITE,
 			(void __user *)(unsigned long)mem->userspace_addr,
 			mem->memory_size)))
 		goto out;
@@ -1494,8 +1499,17 @@ EXPORT_SYMBOL_GPL(kvm_read_guest_cached)
 
 int kvm_clear_guest_page(struct kvm *kvm, gfn_t gfn, int offset, int len)
 {
-	return kvm_write_guest_page(kvm, gfn, (const void *) empty_zero_page,
-				    offset, len);
+	int r;
+	unsigned long addr;
+
+	addr = gfn_to_hva(kvm, gfn);
+	if (kvm_is_error_hva(addr))
+		return -EFAULT;
+	r = __clear_user((void __user *)addr + offset, len);
+	if (r)
+		return -EFAULT;
+	mark_page_dirty(kvm, gfn);
+	return 0;
 }
 EXPORT_SYMBOL_GPL(kvm_clear_guest_page);
 
@@ -1661,7 +1675,7 @@ static int kvm_vcpu_release(struct inode
 	return 0;
 }
 
-static struct file_operations kvm_vcpu_fops = {
+static file_operations_no_const kvm_vcpu_fops __read_only = {
 	.release        = kvm_vcpu_release,
 	.unlocked_ioctl = kvm_vcpu_ioctl,
 #ifdef CONFIG_COMPAT
@@ -2187,7 +2201,7 @@ static int kvm_vm_mmap(struct file *file
 	return 0;
 }
 
-static struct file_operations kvm_vm_fops = {
+static file_operations_no_const kvm_vm_fops __read_only = {
 	.release        = kvm_vm_release,
 	.unlocked_ioctl = kvm_vm_ioctl,
 #ifdef CONFIG_COMPAT
@@ -2285,7 +2299,7 @@ out:
 	return r;
 }
 
-static struct file_operations kvm_chardev_ops = {
+static file_operations_no_const kvm_chardev_ops __read_only = {
 	.unlocked_ioctl = kvm_dev_ioctl,
 	.compat_ioctl   = kvm_dev_ioctl,
 	.llseek		= noop_llseek,
@@ -2311,7 +2325,7 @@ static void hardware_enable_nolock(void
 
 	if (r) {
 		cpumask_clear_cpu(cpu, cpus_hardware_enabled);
-		atomic_inc(&hardware_enable_failed);
+		atomic_inc_unchecked(&hardware_enable_failed);
 		printk(KERN_INFO "kvm: enabling virtualization on "
 				 "CPU%d failed\n", cpu);
 	}
@@ -2365,10 +2379,10 @@ static int hardware_enable_all(void)
 
 	kvm_usage_count++;
 	if (kvm_usage_count == 1) {
-		atomic_set(&hardware_enable_failed, 0);
+		atomic_set_unchecked(&hardware_enable_failed, 0);
 		on_each_cpu(hardware_enable_nolock, NULL, 1);
 
-		if (atomic_read(&hardware_enable_failed)) {
+		if (atomic_read_unchecked(&hardware_enable_failed)) {
 			hardware_disable_all_nolock();
 			r = -EBUSY;
 		}
@@ -2719,7 +2733,7 @@ static void kvm_sched_out(struct preempt
 	kvm_arch_vcpu_put(vcpu);
 }
 
-int kvm_init(void *opaque, unsigned vcpu_size, unsigned vcpu_align,
+int kvm_init(const void *opaque, unsigned vcpu_size, unsigned vcpu_align,
 		  struct module *module)
 {
 	int r;
@@ -2782,7 +2796,7 @@ int kvm_init(void *opaque, unsigned vcpu
 	if (!vcpu_align)
 		vcpu_align = __alignof__(struct kvm_vcpu);
 	kvm_vcpu_cache = kmem_cache_create("kvm_vcpu", vcpu_size, vcpu_align,
-					   0, NULL);
+					   SLAB_USERCOPY, NULL);
 	if (!kvm_vcpu_cache) {
 		r = -ENOMEM;
 		goto out_free_3;
@@ -2792,9 +2806,11 @@ int kvm_init(void *opaque, unsigned vcpu
 	if (r)
 		goto out_free;
 
+	pax_open_kernel();
 	kvm_chardev_ops.owner = module;
 	kvm_vm_fops.owner = module;
 	kvm_vcpu_fops.owner = module;
+	pax_close_kernel();
 
 	r = misc_register(&kvm_dev);
 	if (r) {
@@ -2804,9 +2820,6 @@ int kvm_init(void *opaque, unsigned vcpu
 
 	register_syscore_ops(&kvm_syscore_ops);
 
-	kvm_preempt_ops.sched_in = kvm_sched_in;
-	kvm_preempt_ops.sched_out = kvm_sched_out;
-
 	kvm_init_debug();
 
 	return 0;
